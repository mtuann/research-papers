title,author,venue_name,publish_date,url,code,created_date
Neural Fingerprints for Adversarial Attack Detection,"Haim Fisher, Moni Shahar, Yehezkel S. Resheff",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.04533"" target=""_blank"">2411.04533</a>",,2024-12-11
Identify Backdoored Model in Federated Learning via Individual Unlearning,"Jiahao Xu, Zikai Zhang, Rui Hu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01040"" target=""_blank"">2411.01040</a>","<a href=""https://github.com/JiiahaoXU/MASA"" target=""_blank"">JiiahaoXU</a>",2024-12-11
Rotation Perturbation Robustness in Point Cloud Analysis: A Perspective of Manifold Distillation,"Xinyu Xu, Huazhen Liu, Feiming Wei, Huilin Xiong, Wenxian Yu, Tao Zhang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01748"" target=""_blank"">2411.01748</a>",,2024-12-11
TabSec: A Collaborative Framework for Novel Insider Threat Detection,"Zilin Huang, Xiangyan Tang, Hongyu Li, Xinyi Cao, Jieren Cheng",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01779"" target=""_blank"">2411.01779</a>",,2024-12-11
Learning predictable and robust neural representations by straightening image sequences,"Xueyan Niu, Cristina Savin, Eero P. Simoncelli",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01777"" target=""_blank"">2411.01777</a>",,2024-12-11
$B^4$: A Black-Box Scrubbing Attack on LLM Watermarks,"Baizhou Huang, Xiao Pu, Xiaojun Wan",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01222"" target=""_blank"">2411.01222</a>",,2024-12-11
What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks,"Nathalie Maria Kirch, Severin Field, Stephen Casper",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03343"" target=""_blank"">2411.03343</a>",,2024-12-11
Replace-then-Perturb: Targeted Adversarial Attacks With Visual Reasoning for Vision-Language Models,"Jonggyu Jang, Hyeonsu Lyu, Jungyeon Koh, Hyun Jong Yang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00898"" target=""_blank"">2411.00898</a>",,2024-12-11
Defense Against Prompt Injection Attack by Leveraging Attack Techniques,"Yulin Chen, Haoran Li, Zihao Zheng, Yangqiu Song, Dekai Wu, Bryan Hooi",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00459"" target=""_blank"">2411.00459</a>",,2024-12-11
Certified Robustness for Deep Equilibrium Models via Serialized Random Smoothing,"Weizhi Gao, Zhichao Hou, Han Xu, Xiaorui Liu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00899"" target=""_blank"">2411.00899</a>","<a href=""https://github.com/WeizhiGao/Serialized-Randomized-Smoothing"" target=""_blank"">WeizhiGao</a>",2024-12-11
Attention Tracker: Detecting Prompt Injection Attacks in LLMs,"Kuo-Han Hung, Ching-Yun Ko, Ambrish Rawat, I-Hsin Chung, Winston H. Hsu, Pin-Yu Chen",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00348"" target=""_blank"">2411.00348</a>",,2024-12-11
Emoji Attack: A Method for Misleading Judge LLMs in Safety Risk Detection,"Zhipeng Wei, Yuqi Liu, N. Benjamin Erichson",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01077"" target=""_blank"">2411.01077</a>",,2024-12-11
Outlier-Oriented Poisoning Attack: A Grey-box Approach to Disturb Decision Boundaries by Perturbing Outliers in Multiclass Learning,"Anum Paracha, Junaid Arshad, Mohamed Ben Farah, Khalid Ismail",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00519"" target=""_blank"">2411.00519</a>",,2024-12-11
Plentiful Jailbreaks with String Compositions,Brian R. Y. Huang,arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01084"" target=""_blank"">2411.01084</a>",,2024-12-11
Undermining Image and Text Classification Algorithms Using Adversarial Attacks,"Langalibalele Lunga, Suhas Sreehari",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03348"" target=""_blank"">2411.03348</a>",,2024-12-11
Uncertainty-based Offline Variational Bayesian Reinforcement Learning for Robustness under Diverse Data Corruptions,"Rui Yang, Jie Wang, Guoping Wu, Bin Li",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00465"" target=""_blank"">2411.00465</a>",,2024-12-11
B-cosification: Transforming Deep Neural Networks to be Inherently Interpretable,"Shreyash Arya, Sukrut Rao, Moritz BÃ¶hle, Bernt Schiele",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00715"" target=""_blank"">2411.00715</a>","<a href=""https://github.com/shrebox/B-cosification"" target=""_blank"">shrebox</a>",2024-12-11
Towards Building Secure UAV Navigation with FHE-aware Knowledge Distillation,"Arjun Ramesh Kaushik, Charanjit Jutla, Nalini Ratha",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00403"" target=""_blank"">2411.00403</a>",,2024-12-11
Attention Masks Help Adversarial Attacks to Bypass Safety Detectors,Yunfan Shi,arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.04772"" target=""_blank"">2411.04772</a>",,2024-12-11
Protecting Feed-Forward Networks from Adversarial Attacks Using Predictive Coding,"Ehsan Ganjidoost, Jeff Orchard",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00222"" target=""_blank"">2411.00222</a>",,2024-12-11
I Can Hear You: Selective Robust Training for Deepfake Audio Detection,"Zirui Zhang, Wei Hao, Aroon Sankoh, William Lin, Emanuel Mendiola-Ortiz, Junfeng Yang, Chengzhi Mao",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00121"" target=""_blank"">2411.00121</a>",,2024-12-11
Optical Lens Attack on Monocular Depth Estimation for Autonomous Driving,"Ce Michigan State University Zhou, Qiben Michigan State University Yan, Daniel Michigan State University Kent, Guangjing University of South Florida Wang, Weikang Michigan State University Ding, Ziqi Peking University Zhang, Hayder Michigan State University Radha",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00192"" target=""_blank"">2411.00192</a>",,2024-12-11
CausAdv: A Causal-based Framework for Detecting Adversarial Examples,Hichem Debbi,arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00839"" target=""_blank"">2411.00839</a>","<a href=""https://github.com/HichemDebbi/CausAdv"" target=""_blank"">HichemDebbi</a>",2024-12-11
IDEATOR: Jailbreaking VLMs Using VLMs,"Ruofan Wang, Bo Wang, Xingjun Ma, Yu-Gang Jiang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00827"" target=""_blank"">2411.00827</a>",,2024-12-11
Longitudinal Mammogram Exam-based Breast Cancer Diagnosis Models: Vulnerability to Adversarial Attacks,"Zhengbo Zhou, Degan Hao, Dooman Arefan, Margarita Zuley, Jules Sumkin, Shandong Wu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00837"" target=""_blank"">2411.00837</a>",,2024-12-11
DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models,"Chengke Zou, Xingang Guo, Rui Yang, Junyu Zhang, Bin Hu, Huan Zhang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00836"" target=""_blank"">2411.00836</a>",,2024-12-11
SQL Injection Jailbreak: a structural disaster of large language models,"Jiawei Zhao, Kejiang Chen, Weiming Zhang, Nenghai Yu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01565"" target=""_blank"">2411.01565</a>","<a href=""https://github.com/weiyezhimeng/SQL-Injection-Jailbreak"" target=""_blank"">weiyezhimeng</a>",2024-12-11
Examining Attacks on Consensus and Incentive Systems in Proof-of-Work Blockchains: A Systematic Literature Review,"Dinitha Wijewardhana, Sugandima Vidanagamachchi, Nalin Arachchilage",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00349"" target=""_blank"">2411.00349</a>",,2024-12-11
Differentially Private Integrated Decision Gradients (IDG-DP) for Radar-based Human Activity Recognition,"Idris Zakariyya, Linda Tran, Kaushik Bhargav Sivangi, Paul Henderson, Fani Deligianni",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02099"" target=""_blank"">2411.02099</a>",,2024-12-11
Formal Logic-guided Robust Federated Learning against Poisoning Attacks,"Dung Thuy Nguyen, Ziyan An, Taylor T. Johnson, Meiyi Ma, Kevin Leach",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03231"" target=""_blank"">2411.03231</a>",,2024-12-11
Deferred Poisoning: Making the Model More Vulnerable via Hessian Singularization,"Yuhao He, Jinyu Tian, Xianwei Zheng, Li Dong, Yuanman Li, Leo Yu Zhang, Jiantao Zhou",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03752"" target=""_blank"">2411.03752</a>",,2024-12-11
Game-Theoretic Defenses for Robust Conformal Prediction Against Adversarial Attacks in Medical Imaging,"Rui Luo, Jie Bao, Zhixin Zhou, Chuangyin Dang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.04376"" target=""_blank"">2411.04376</a>",,2024-12-11
MISGUIDE: Security-Aware Attack Analytics for Smart Grid Load Frequency Control,"Nur Imtiazul Haque, Prabin Mali, Mohammad Zakaria Haider, Mohammad Ashiqur Rahman, Sumit Paudyal",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.04731"" target=""_blank"">2411.04731</a>",,2024-12-11
Stochastic Monkeys at Play: Random Augmentations Cheaply Break LLM Safety Alignment,"Jason Vega, Junsheng Huang, Gaokai Zhang, Hangoo Kang, Minjia Zhang, Gagandeep Singh",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02785"" target=""_blank"">2411.02785</a>",,2024-12-11
FedRISE: Rating Induced Sign Election of Gradients for Byzantine Tolerant Federated Aggregation,"Joseph Geo Benjamin, Mothilal Asokan, Mohammad Yaqub, Karthik Nandakumar",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03861"" target=""_blank"">2411.03861</a>",,2024-12-11
Defending Deep Regression Models against Backdoor Attacks,"Lingyu Du, Yupei Liu, Jinyuan Jia, Guohao Lan",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.04811"" target=""_blank"">2411.04811</a>",,2024-12-11
MRJ-Agent: An Effective Jailbreak Agent for Multi-Round Dialogue,"Fengxiang Wang, Ranjie Duan, Peng Xiao, Xiaojun Jia, YueFeng Chen, Chongwen Wang, Jialing Tao, Hang Su, Jun Zhu, Hui Xue",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03814"" target=""_blank"">2411.03814</a>",,2024-12-11
Region-Guided Attack on the Segment Anything Model (SAM),"Xiaoliang Liu, Furao Shen, Jian Zhao",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02974"" target=""_blank"">2411.02974</a>",,2024-12-11
Enhancing Adversarial Robustness via Uncertainty-Aware Distributional Adversarial Training,"Junhao Dong, Xinghua Qu, Z. Jane Wang, Yew-Soon Ong",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02871"" target=""_blank"">2411.02871</a>",,2024-12-11
Double Whammy: Stealthy Data Manipulation aided Reconstruction Attack on Graph Federated Learning,"Jinyin Chen, Minying Ma, Haibin Zheng, Qi Xuan",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02866"" target=""_blank"">2411.02866</a>",,2024-12-11
Flashy Backdoor: Real-world Environment Backdoor Attack on SNNs with DVS Cameras,"Roberto RiaÃ±o, Gorka Abad, Stjepan Picek, Aitor Urbieta",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03022"" target=""_blank"">2411.03022</a>",,2024-12-11
Towards Secured Smart Grid 2,"Lan-Huong Nguyen, Van-Linh Nguyen, Ren-Hung Hwang, Jian-Jhih Kuo, Yu-Wen Chen, Chien-Chung Huang, Ping-I Pan",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.04365"" target=""_blank"">2411.04365</a>",,2024-12-11
Oblivious Defense in ML Models: Backdoor Removal without Detection,"Shafi Goldwasser, Jonathan Shafer, Neekon Vafa, Vinod Vaikuntanathan",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03279"" target=""_blank"">2411.03279</a>",,2024-12-11
DM4Steal: Diffusion Model For Link Stealing Attack On Graph Neural Networks,"Jinyin Chen, Haonan Ma, Haibin Zheng",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03364"" target=""_blank"">2411.03364</a>",,2024-12-11
FEDLAD: Federated Evaluation of Deep Leakage Attacks and Defenses,"Isaac Baglin, Xiatian Zhu, Simon Hadfield",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03019"" target=""_blank"">2411.03019</a>",,2024-12-11
Lost in Context: The Influence of Context on Feature Attribution Methods for Object Recognition,"Sayanta Adhikari, Rishav Kumar, Konda Reddy Mopuri, Rajalakshmi Pachamuthu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02833"" target=""_blank"">2411.02833</a>",,2024-12-11
FactTest: Factuality Testing in Large Language Models with Statistical Guarantees,"Fan Nie, Xiaotian Hou, Shuhang Lin, James Zou, Huaxiu Yao, Linjun Zhang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02603"" target=""_blank"">2411.02603</a>",,2024-12-11
Benchmarking Vision Language Model Unlearning via Fictitious Facial Identity Dataset,"Yingzi Ma, Jiongxiao Wang, Fei Wang, Siyuan Ma, Jiazhao Li, Xiujun Li, Furong Huang, Lichao Sun, Bo Li, Yejin Choi, Muhao Chen, Chaowei Xiao",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03554"" target=""_blank"">2411.03554</a>",,2024-12-11
Query-Efficient Adversarial Attack Against Vertical Federated Graph Learning,"Jinyin Chen, Wenbo Mu, Luxin Zhang, Guohan Huang, Haibin Zheng, Yao Cheng",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02809"" target=""_blank"">2411.02809</a>",,2024-12-11
Semantic-Aligned Adversarial Evolution Triangle for High-Transferability Vision-Language Attack,"Xiaojun Jia, Sensen Gao, Qing Guo, Ke Ma, Yihao Huang, Simeng Qin, Yang Liu, Ivor Tsang Fellow, Xiaochun Cao",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02669"" target=""_blank"">2411.02669</a>","<a href=""https://github.com/jiaxiaojunQAQ/SA-AET"" target=""_blank"">jiaxiaojunQAQ</a>",2024-12-11
Attacking Vision-Language Computer Agents via Pop-ups,"Yanzhe Zhang, Tao Yu, Diyi Yang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02391"" target=""_blank"">2411.02391</a>",,2024-12-11
Alignment-Based Adversarial Training (ABAT) for Improving the Robustness and Accuracy of EEG-Based BCIs,"Xiaoqing Chen, Ziwei Wang, Dongrui Wu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02094"" target=""_blank"">2411.02094</a>",,2024-12-11
LiDAttack: Robust Black-box Attack on LiDAR-based Object Detection,"Jinyin Chen, Danxin Liao, Sheng Xiang, Haibin Zheng",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01889"" target=""_blank"">2411.01889</a>",,2024-12-11
Invisibility Cloak: Disappearance under Human Pose Estimation via Backdoor Attacks,"Minxing Zhang, Michael Backes, Xiao Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.07670"" target=""_blank"">2410.07670</a>",,2024-12-11
Adversarial Robustness Overestimation and Instability in TRADES,"Jonathan Weiping Li, Ren-Wei Liang, Cheng-Han Yeh, Cheng-Chang Tsai, Kuanchun Yu, Chun-Shien Lu, Shang-Tse Chen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.07675"" target=""_blank"">2410.07675</a>",,2024-12-11
Bilinear MLPs enable weight-based mechanistic interpretability,"Michael T. Pearce, Thomas Dooms, Alice Rigg, Jose M. Oramas, Lee Sharkey",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08417"" target=""_blank"">2410.08417</a>",,2024-12-11
Towards Assurance of LLM Adversarial Robustness using Ontology-Driven Argumentation,"Tomas Bueno Momcilovic, Beat Buesser, Giulio Zizzo, Mark Purcell, Dian Balta",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.07962"" target=""_blank"">2410.07962</a>",,2024-12-11
A Survey on Physical Adversarial Attacks against Face Recognition Systems,"Mingsi Wang, Jiachen Zhou, Tianlin Li, Guozhu Meng, Kai Chen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16317"" target=""_blank"">2410.16317</a>",,2024-12-11
Adversarial Training Can Provably Improve Robustness: Theoretical Analysis of Feature Learning Process Under Structured Data,"Binghui Li, Yuanzhi Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08503"" target=""_blank"">2410.08503</a>",,2024-12-11
Understanding Adversarially Robust Generalization via Weight-Curvature Index,"Yuelin Xu, Xiao Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.07719"" target=""_blank"">2410.07719</a>",,2024-12-11
Time Traveling to Defend Against Adversarial Example Attacks in Image Classification,"Anthony Etim, Jakub Szefer",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08338"" target=""_blank"">2410.08338</a>",,2024-12-11
Impeding LLM-assisted Cheating in Introductory Programming Assignments via Adversarial Perturbation,"Saiful Islam Salim, Rubin Yuchan Yang, Alexander Cooper, Suryashree Ray, Saumya Debray, Sazzadur Rahaman",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09318"" target=""_blank"">2410.09318</a>",,2024-12-11
JAILJUDGE: A Comprehensive Jailbreak Judge Benchmark with Multi-Agent Enhanced Explanation Evaluation Framework,"Fan Liu, Yue Feng, Zhao Xu, Lixin Su, Xinyu Ma, Dawei Yin, Hao Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12855"" target=""_blank"">2410.12855</a>",,2024-12-11
RePD: Defending Jailbreak Attack through a Retrieval-based Prompt Decomposition Process,"Peiran Wang, Xiaogeng Liu, Chaowei Xiao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08660"" target=""_blank"">2410.08660</a>",,2024-12-11
F2A: An Innovative Approach for Prompt Injection by Utilizing Feign Security Detection Agents,Yupeng Ren,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08776"" target=""_blank"">2410.08776</a>",,2024-12-11
Poison-splat: Computation Cost Attack on 3D Gaussian Splatting,"Jiahao Lu, Yifan Zhang, Qiuhong Shen, Xinchao Wang, Shuicheng Yan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08190"" target=""_blank"">2410.08190</a>",,2024-12-11
RAB$^2$-DEF: Dynamic and explainable defense against adversarial attacks in Federated Learning to fair poor clients,"Nuria RodrÃ­guez-Barroso, M. Victoria LuzÃ³n, Francisco Herrera",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08244"" target=""_blank"">2410.08244</a>",,2024-12-11
Cheating Automatic LLM Benchmarks: Null Models Achieve High Win Rates,"Xiaosen Zheng, Tianyu Pang, Chao Du, Qian Liu, Jing Jiang, Min Lin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.07137"" target=""_blank"">2410.07137</a>","<a href=""https://github.com/sail-sg/Cheating-LLM-Benchmarks"" target=""_blank"">sail-sg</a>",2024-12-11
A Closer Look at Machine Unlearning for Large Language Models,"Xiaojian Yuan, Tianyu Pang, Chao Du, Kejiang Chen, Weiming Zhang, Min Lin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08109"" target=""_blank"">2410.08109</a>","<a href=""https://github.com/sail-sg/closer-look-LLM-unlearning"" target=""_blank"">sail-sg</a>",2024-12-11
Break the Visual Perception: Adversarial Attacks Targeting Encoded Visual Tokens of Large Vision-Language Models,"Yubo Wang, Chaohu Liu, Yanqiu Qu, Haoyu Cao, Deqiang Jiang, Linli Xu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06699"" target=""_blank"">2410.06699</a>",,2024-12-11
AttnGCG: Enhancing Jailbreaking Attacks on LLMs with Attention Manipulation,"Zijun Wang, Haoqin Tu, Jieru Mei, Bingchen Zhao, Yisen Wang, Cihang Xie",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09040"" target=""_blank"">2410.09040</a>","<a href=""https://github.com/UCSC-VLAA/AttnGCG-attack"" target=""_blank"">UCSC-VLAA</a>",2024-12-11
Filtered Randomized Smoothing: A New Defense for Robust Modulation Classification,"Wenhan Zhang, Meiyu Zhong, Ravi Tandon, Marwan Krunz",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06339"" target=""_blank"">2410.06339</a>",,2024-12-11
DiffusionGuard: A Robust Defense Against Malicious Diffusion-based Image Editing,"June Suk Choi, Kyungmin Lee, Jongheon Jeong, Saining Xie, Jinwoo Shin, Kimin Lee",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05694"" target=""_blank"">2410.05694</a>","<a href=""https://github.com/choi403/DiffusionGuard"" target=""_blank"">choi403</a>",2024-12-11
Hyper Adversarial Tuning for Boosting Adversarial Robustness of Pretrained Large Vision Models,"Kangtao Lv, Huangsen Cao, Kainan Tu, Yihuai Xu, Zhimeng Zhang, Xin Ding, Yongwei Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05951"" target=""_blank"">2410.05951</a>",,2024-12-11
PII-Scope: A Benchmark for Training Data PII Leakage Assessment in LLMs,"Krishna Kanth Nakka, Ahmed Frikha, Ricardo Mendes, Xue Jiang, Xuebing Zhou",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06704"" target=""_blank"">2410.06704</a>",,2024-12-11
AdaRC: Mitigating Graph Structure Shifts during Test-Time,"Wenxuan Bao, Zhichen Zeng, Zhining Liu, Hanghang Tong, Jingrui He",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06976"" target=""_blank"">2410.06976</a>",,2024-12-11
Utilize the Flow before Stepping into the Same River Twice: Certainty Represented Knowledge Flow for Refusal-Aware Instruction Tuning,"Runchuan Zhu, Zhipeng Ma, Jiang Wu, Junyuan Gao, Jiaqi Wang, Dahua Lin, Conghui He",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06913"" target=""_blank"">2410.06913</a>",,2024-12-11
Mind Your Questions! Towards Backdoor Attacks on Text-to-Visualization Models,"Shuaimin Li, Yuanfeng Song, Xuanang Chen, Anni Peng, Zhuoyue Wan, Chen Jason Zhang, Raymond Chi-Wing Wong",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06782"" target=""_blank"">2410.06782</a>",,2024-12-11
Adversarial Vulnerability as a Consequence of On-Manifold Inseparibility,"Rajdeep Haldar, Yue Xing, Qifan Song, Guang Lin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06921"" target=""_blank"">2410.06921</a>",,2024-12-11
JPEG Inspired Deep Learning,"Ahmed H. Salamah, Kaixiang Zheng, Yiwen Liu, En-Hui Yang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.07081"" target=""_blank"">2410.07081</a>","<a href=""https://github.com/JpegInspiredDl/JPEG-Inspired-DL"" target=""_blank"">JpegInspiredDl</a>",2024-12-11
Average Certified Radius is a Poor Metric for Randomized Smoothing,"Chenhao Sun, Yuhao Mao, Mark Niklas MÃ¼ller, Martin Vechev",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06895"" target=""_blank"">2410.06895</a>",,2024-12-11
Data Taggants: Dataset Ownership Verification via Harmless Targeted Data Poisoning,"Wassim Bouaziz, El-Mahdi El-Mhamdi, Nicolas Usunier",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09101"" target=""_blank"">2410.09101</a>",,2024-12-11
Can DeepFake Speech be Reliably Detected? (62%),"Hongbin Liu, Youzheng Chen, Arun Narayanan, Athula Balachandran, Pedro J. Moreno, Lun Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06572"" target=""_blank"">2410.06572</a>",,2024-12-11
Secure Video Quality Assessment Resisting Adversarial Attacks,"Ao-Xiang Zhang, Yu Ran, Weixuan Tang, Yuan-Gen Wang, Qingxiao Guan, Chunsheng Yang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06866"" target=""_blank"">2410.06866</a>",,2024-12-11
Understanding Model Ensemble in Transferable Adversarial Attack,"Wei Yao, Zeliang Zhang, Huayi Tang, Yong Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06851"" target=""_blank"">2410.06851</a>",,2024-12-11
"The Good, the Bad and the Ugly: Watermarks, Transferable Attacks and Adversarial Defenses","Grzegorz GÅuch, Berkant Turan, Sai Ganesh Nagarajan, Sebastian Pokutta",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08864"" target=""_blank"">2410.08864</a>",,2024-12-11
Generalized Adversarial Code-Suggestions: Exploiting Contexts of LLM-based Code-Completion,"Karl Rubel, Maximilian Noppel, Christian Wressnegger",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10526"" target=""_blank"">2410.10526</a>",,2024-12-11
PoisonBench: Assessing Large Language Model Vulnerability to Data Poisoning,"Tingchen Fu, Mrinank Sharma, Philip Torr, Shay B. Cohen, David Krueger, Fazl Barez",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08811"" target=""_blank"">2410.08811</a>",,2024-12-11
Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance,"Sachin Goyal, Christina Baek, J. Zico Kolter, Aditi Raghunathan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10796"" target=""_blank"">2410.10796</a>",,2024-12-11
DiffGAN: A Test Generation Approach for Differential Testing of Deep Neural Networks,"Zohreh Aghababaeyan, Manel Abdellatif, Lionel Briand, Ramesh S",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.19794"" target=""_blank"">2410.19794</a>",,2024-12-11
Multi-round jailbreak attack on large language models,"Yihua Zhou, Xiaochuan Shi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11533"" target=""_blank"">2410.11533</a>",,2024-12-11
Geometric Inductive Biases of Deep Networks: The Role of Data and Architecture,"Sajad Movahedi, Antonio Orvieto, Seyed-Mohsen Moosavi-Dezfooli",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12025"" target=""_blank"">2410.12025</a>",,2024-12-11
G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks,"Guibin Zhang, Yanwei Yue, Xiangguo Sun, Guancheng Wan, Miao Yu, Junfeng Fang, Kun Wang, Dawei Cheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11782"" target=""_blank"">2410.11782</a>",,2024-12-11
Denial-of-Service Poisoning Attacks against Large Language Models,"Kuofeng Gao, Tianyu Pang, Chao Du, Yong Yang, Shu-Tao Xia, Min Lin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10760"" target=""_blank"">2410.10760</a>","<a href=""https://github.com/sail-sg/P-DoS"" target=""_blank"">sail-sg</a>",2024-12-11
Towards Calibrated Losses for Adversarial Robust Reject Option Classification,"Vrund Shah, Tejas Chaudhari, Naresh Manwani",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10736"" target=""_blank"">2410.10736</a>",,2024-12-11
Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings,"Hossein Mirzaei, Mackenzie W. Mathis",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10744"" target=""_blank"">2410.10744</a>",,2024-12-11
Adversarially Guided Stateful Defense Against Backdoor Attacks in Federated Deep Learning,"Hassan Ali, Surya Nepal, Salil S. Kanhere, Sanjay Jha",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11205"" target=""_blank"">2410.11205</a>","<a href=""https://github.com/hassanalikhatim/AGSD"" target=""_blank"">hassanalikhatim</a>",2024-12-11
Feature Averaging: An Implicit Bias of Gradient Descent Leading to Non-Robustness in Neural Networks,"Binghui Li, Zhixuan Pan, Kaifeng Lyu, Jian Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10322"" target=""_blank"">2410.10322</a>",,2024-12-11
ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection,"Martin Aubard, LÃ¡szlÃ³ Antal, Ana Madureira, Luis F. Teixeira, Erika ÃbrahÃ¡m",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10554"" target=""_blank"">2410.10554</a>","<a href=""https://github.com/remaro-network/ROSAR-framework"" target=""_blank"">remaro-network</a>",2024-12-11
Polynomial Time Cryptanalytic Extraction of Deep Neural Networks in the Hard-Label Setting,"Nicholas Carlini, Jorge ChÃ¡vez-Saab, Anna Hambitzer, Francisco RodrÃ­guez-HenrÃ­quez, Adi Shamir",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05750"" target=""_blank"">2410.05750</a>",,2024-12-11
Enhancing Robustness in Deep Reinforcement Learning: A Lyapunov Exponent Approach,"Rory Young, Nicolas Pugeault",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10674"" target=""_blank"">2410.10674</a>",,2024-12-11
How to Backdoor Consistency Models? (12%),"Chengen Wang, Murat Kantarcioglu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.19785"" target=""_blank"">2410.19785</a>",,2024-12-11
The Implicit Bias of Structured State Space Models Can Be Poisoned With Clean Labels,"Yonatan Slutzky, Yotam Alexander, Noam Razin, Nadav Cohen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10473"" target=""_blank"">2410.10473</a>",,2024-12-11
On Calibration of LLM-based Guard Models for Reliable Content Moderation,"Hongfu Liu, Hengguan Huang, Hao Wang, Xiangming Gu, Ye Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10414"" target=""_blank"">2410.10414</a>",,2024-12-11
Training on Fake Labels: Mitigating Label Leakage in Split Learning via Secure Dimension Transformation,"Yukun Jiang, Peiran Wang, Chengguo Lin, Ziyue Huang, Yong Cheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09125"" target=""_blank"">2410.09125</a>",,2024-12-11
Regularized Robustly Reliable Learners and Instance Targeted Attacks,"Avrim Blum, Donya Saless",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10572"" target=""_blank"">2410.10572</a>",,2024-12-11
Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models,"Zhongye Liu, Hongbin Liu, Yuepeng Hu, Zedian Shao, Neil Zhenqiang Gong",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11242"" target=""_blank"">2410.11242</a>","<a href=""https://github.com/lycheeefish/VHExpansion"" target=""_blank"">lycheeefish</a>",2024-12-11
"S$^4$ST: A Strong, Self-transferable, faSt, and Simple Scale Transformation for Transferable Targeted Attack","Yongxiang Liu, Bowen Peng, Li Liu, Xiang Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13891"" target=""_blank"">2410.13891</a>",,2024-12-11
Understanding Robustness of Parameter-Efficient Tuning for Image Classification,"Jiacheng Ruan, Xian Gao, Suncheng Xiang, Mingye Xie, Ting Liu, Yuzhuo Fu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09845"" target=""_blank"">2410.09845</a>","<a href=""https://github.com/JCruan519/PETRobustness"" target=""_blank"">JCruan519</a>",2024-12-11
Out-of-Bounding-Box Triggers: A Stealthy Approach to Cheat Object Detectors,"Tao Lin, Lijia Yu, Gaojie Jin, Renjue Li, Peng Wu, Lijun Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10091"" target=""_blank"">2410.10091</a>","<a href=""https://github.com/linToTao/Out-of-bbox-attack"" target=""_blank"">linToTao</a>",2024-12-11
"Uncovering, Explaining, and Mitigating the Superficial Safety of Backdoor Defense","Rui Min, Zeyu Qin, Nevin L. Zhang, Li Shen, Minhao Cheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09838"" target=""_blank"">2410.09838</a>",,2024-12-11
BlackDAN: A Black-Box Multi-Objective Approach for Effective and Contextual Jailbreaking of Large Language Models,"Xinyuan Wang, Victor Shea-Jay Huang, Renmiao Chen, Hao Wang, Chengwei Pan, Lei Sha, Minlie Huang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09804"" target=""_blank"">2410.09804</a>",,2024-12-11
Targeted Vaccine: Safety Alignment for Large Language Models against Harmful Fine-Tuning via Layer-wise Perturbation,"Guozhi Liu, Weiwei Lin, Tiansheng Huang, Ruichao Mo, Qi Mu, Li Shen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09760"" target=""_blank"">2410.09760</a>","<a href=""https://github.com/Lslland/T-Vaccine"" target=""_blank"">Lslland</a>",2024-12-11
Unlearn and Burn: Adversarial Machine Unlearning Requests Destroy Model Accuracy,"Yangsibo Huang, Daogao Liu, Lynn Chua, Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Milad Nasr, Amer Sinha, Chiyuan Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09591"" target=""_blank"">2410.09591</a>",,2024-12-11
Robust 3D Point Clouds Classification based on Declarative Defenders,"Kaidong Li, Tianxiao Zhang, Cuncong Zhong, Ziming Zhang, Guanghui Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09691"" target=""_blank"">2410.09691</a>","<a href=""https://github.com/KaidongLi/pytorch-LatticePointClassifier"" target=""_blank"">KaidongLi</a>",2024-12-11
"On the Adversarial Transferability of Generalized ""Skip Connections""","Yisen Wang, Yichuan Mo, Dongxian Wu, Mingjie Li, Xingjun Ma, Zhouchen Lin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08950"" target=""_blank"">2410.08950</a>","<a href=""https://github.com/mo666666/SGM"" target=""_blank"">mo666666</a>",2024-12-11
Natural Language Induced Adversarial Images,"Xiaopei Zhu, Peiyang Xu, Guanning Zeng, Yingpeng Dong, Xiaolin Hu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08620"" target=""_blank"">2410.08620</a>","<a href=""https://github.com/zxp555/Natural-Language-Induced-Adversarial-Images"" target=""_blank"">zxp555</a>",2024-12-11
Fragile Giants: Understanding the Susceptibility of Models to Subpopulation Attacks,"Isha Gupta, Hidde Lycklama, Emanuel Opel, Evan Rose, Anwar Hithnawi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08872"" target=""_blank"">2410.08872</a>",,2024-12-11
AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents,"Maksym Andriushchenko, Alexandra Souly, Mateusz Dziemian, Derek Duenas, Maxwell Lin, Justin Wang, Dan Hendrycks, Andy Zou, Zico Kolter, Matt Fredrikson, Eric Winsor, Jerome Wynne, Yarin Gal, Xander Davies",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09024"" target=""_blank"">2410.09024</a>",,2024-12-11
CALoR: Towards Comprehensive Model Inversion Defense,"Hongyao Yu, Yixiang Qiu, Hao Fang, Bin Chen, Sijin Yu, Bin Wang, Shu-Tao Xia, Ke Xu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05814"" target=""_blank"">2410.05814</a>",,2024-12-11
A Brain-Inspired Regularizer for Adversarial Robustness,"Elie Attias, Cengiz Pehlevan, Dina Obeid",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03952"" target=""_blank"">2410.03952</a>",,2024-12-11
Training-free LLM-generated Text Detection by Mining Token Probability Sequences,"Yihuai Xu, Yongwei Wang, Yifei Bi, Huangsen Cao, Zhouhan Lin, Yu Zhao, Fei Wu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06072"" target=""_blank"">2410.06072</a>",,2024-12-11
Signal Adversarial Examples Generation for Signal Detection Network via White-Box Attack,"Dongyang Li, Linyuan Wang, Guangwei Xiong, Bin Yan, Dekui Ma, Jinxian Peng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01393"" target=""_blank"">2410.01393</a>",,2024-12-11
Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents,"Hanrong Zhang, Jingyuan Huang, Kai Mei, Yifei Yao, Zhenting Wang, Chenlu Zhan, Hongwei Wang, Yongfeng Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02644"" target=""_blank"">2410.02644</a>","<a href=""https://github.com/agiresearch/ASB"" target=""_blank"">agiresearch</a>",2024-12-11
AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs,"Xiaogeng Liu, Peiran Li, Edward Suh, Yevgeniy Vorobeychik, Zhuoqing Mao, Somesh Jha, Patrick McDaniel, Huan Sun, Bo Li, Chaowei Xiao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05295"" target=""_blank"">2410.05295</a>",,2024-12-11
Demonstration Attack against In-Context Learning for Code Intelligence,"Yifei Ge, Weisong Sun, Yihang Lou, Chunrong Fang, Yiran Zhang, Yiming Li, Xiaofang Zhang, Yang Liu, Zhihong Zhao, Zhenyu Chen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02841"" target=""_blank"">2410.02841</a>",,2024-12-11
"Unveiling AI's Blind Spots: An Oracle for In-Domain, Out-of-Domain, and Adversarial Errors","Shuangpeng Han, Mengmi Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02384"" target=""_blank"">2410.02384</a>",,2024-12-11
Jailbreak Antidote: Runtime Safety-Utility Balance via Sparse Representation Adjustment in Large Language Models,"Guobin Shen, Dongcheng Zhao, Yiting Dong, Xiang He, Yi Zeng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02298"" target=""_blank"">2410.02298</a>",,2024-12-11
MTDNS: Moving Target Defense for Resilient DNS Infrastructure,"Abdullah Aydeger, Pei Zhou, Sanzida Hoque, Marco Carvalho, Engin Zeydan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02254"" target=""_blank"">2410.02254</a>",,2024-12-11
Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems,"Guibin Zhang, Yanwei Yue, Zhixun Li, Sukwon Yun, Guancheng Wan, Kun Wang, Dawei Cheng, Jeffrey Xu Yu, Tianlong Chen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02506"" target=""_blank"">2410.02506</a>",,2024-12-11
IndicSentEval: How Effectively do Multilingual Transformer Models encode Linguistic Properties for Indic Languages? (1%),"Akhilesh Aravapalli, Mounika Marreddy, Subba Reddy Oota, Radhika Mamidi, Manish Gupta",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02611"" target=""_blank"">2410.02611</a>",,2024-12-11
BACKTIME: Backdoor Attacks on Multivariate Time Series Forecasting,"Xiao Lin, Zhining Liu, Dongqi Fu, Ruizhong Qiu, Hanghang Tong",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02195"" target=""_blank"">2410.02195</a>","<a href=""https://github.com/xiaolin-cs/BackTime"" target=""_blank"">xiaolin-cs</a>",2024-12-11
Optimizing Adaptive Attacks against Content Watermarks for Language Models,"Abdulrahman Diaa, Toluwani Aremu, Nils Lukas",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02440"" target=""_blank"">2410.02440</a>",,2024-12-11
Universally Optimal Watermarking Schemes for LLMs: from Theory to Practice,"Haiyun He, Yepeng Liu, Ziqiao Wang, Yongyi Mao, Yuheng Bu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02890"" target=""_blank"">2410.02890</a>",,2024-12-11
Buckle Up: Robustifying LLMs at Every Customization Stage via Data Curation,"Xiaoqun Liu, Jiacheng Liang, Luoxi Tang, Chenyu You, Muchao Ye, Zhaohan Xi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02220"" target=""_blank"">2410.02220</a>",,2024-12-11
On Using Certified Training towards Empirical Robustness,"Palma Alessandro De, Serge Durand, Zakaria Chihani, FranÃ§ois Terrier, Caterina Urban",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01617"" target=""_blank"">2410.01617</a>",,2024-12-11
Impact of White-Box Adversarial Attacks on Convolutional Neural Networks,"Rakesh Podder, Sudipto Ghosh",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02043"" target=""_blank"">2410.02043</a>",,2024-12-11
Fake It Until You Break It: On the Adversarial Robustness of AI-generated Image Detectors,"Sina Mavali, Jonas Ricker, David Pape, Yash Sharma, Asja Fischer, Lea SchÃ¶nherr",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01574"" target=""_blank"">2410.01574</a>",,2024-12-11
SCA: Highly Efficient Semantic-Consistent Unrestricted Adversarial Attack,"Zihao Pan, Weibin Wu, Yuhang Cao, Zibin Zheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02240"" target=""_blank"">2410.02240</a>",,2024-12-11
"""No Matter What You Do!"": Mitigating Backdoor Attacks in Graph Neural Networks","Jiale Zhang, Chengcheng Zhu, Bosen Rao, Hao Sui, Xiaobing Sun, Bing Chen, Chunyi Zhou, Shouling Ji",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01272"" target=""_blank"">2410.01272</a>",,2024-12-11
Social Media Authentication and Combating Deepfakes using Semi-fragile Invisible Image Watermarking,"Aakash Varma Nadimpalli, Ajita Rattani",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01906"" target=""_blank"">2410.01906</a>",,2024-12-11
The Unlikely Hero: Nonideality in Analog Photonic Neural Networks as Built-in Defender Against Adversarial Attacks,"Haotian Lu, Ziang Yin, Partho Bhoumik, Sanmitra Banerjee, Krishnendu Chakrabarty, Jiaqi Gu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01289"" target=""_blank"">2410.01289</a>","<a href=""https://github.com/ScopeX-ASU/Unlikely_Hero"" target=""_blank"">ScopeX-ASU</a>",2024-12-11
BadCM: Invisible Backdoor Attack Against Cross-Modal Learning,"Zheng Zhang, Xu Yuan, Lei Zhu, Jingkuan Song, Liqiang Nie",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02182"" target=""_blank"">2410.02182</a>","<a href=""https://github.com/xandery-geek/BadCM"" target=""_blank"">xandery-geek</a>",2024-12-11
Controlled Generation of Natural Adversarial Documents for Stealthy Retrieval Poisoning,"Collin Zhang, Tingwei Zhang, Vitaly Shmatikov",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02163"" target=""_blank"">2410.02163</a>",,2024-12-11
Automated Red Teaming with GOAT: the Generative Offensive Agent Tester,"Maya Pavlova, Erik Brinkman, Krithika Iyer, Vitor Albiero, Joanna Bitton, Hailey Nguyen, Joe Li, Cristian Canton Ferrer, Ivan Evtimov, Aaron Grattafiori",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01606"" target=""_blank"">2410.01606</a>",,2024-12-11
Information-Theoretical Principled Trade-off between Jailbreakability and Stealthiness on Vision Language Models,"Ching-Chia Kao, Chia-Mu Yu, Chun-Shien Lu, Chu-Song Chen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01438"" target=""_blank"">2410.01438</a>",,2024-12-11
One Wave to Explain Them All: A Unifying Perspective on Post-hoc Explainability,"Gabriel Kasmi, Amandine Brunetto, Thomas Fel, Jayneel Parekh",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01482"" target=""_blank"">2410.01482</a>",,2024-12-11
Empirical Perturbation Analysis of Linear System Solvers from a Data Poisoning Perspective,"Yixin Liu, Arielle Carr, Lichao Sun",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.00878"" target=""_blank"">2410.00878</a>",,2024-12-11
Adversarial Suffixes May Be Features Too! (15%),"Wei Zhao, Zhe Li, Yige Li, Jun Sun",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.00451"" target=""_blank"">2410.00451</a>","<a href=""https://github.com/suffix-maybe-feature/adver-suffix-maybe-features"" target=""_blank"">suffix-maybe-feature</a>",2024-12-11
Resonance Reduction Against Adversarial Attacks in Dynamic Networks via Eigenspectrum Optimization,"Alp Sahin, Nicolas Kozachuk, Rick S. Blum, Subhrajit Bhattacharya",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.00126"" target=""_blank"">2410.00126</a>",,2024-12-11
VLMGuard: Defending VLMs against Malicious Prompts via Unlabeled Data,"Xuefeng Du, Reshmi Ghosh, Robert Sim, Ahmed Salem, Vitor Carvalho, Emily Lawton, Yixuan Li, Jack W. Stokes",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.00296"" target=""_blank"">2410.00296</a>",,2024-12-11
Survey of Security and Data Attacks on Machine Unlearning In Financial and E-Commerce,Carl E. J. Brodzinski,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.00055"" target=""_blank"">2410.00055</a>",,2024-12-11
Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving,"Ehsan Ahmadi, Ray Mercurius, Soheil Alizadeh, Kasra Rezaee, Amir Rasouli",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.07191"" target=""_blank"">2410.07191</a>","<a href=""https://critic-model.github.io/"" target=""_blank"">critic-model.github.io</a>",2024-12-11
Towards Universal Certified Robustness with Multi-Norm Training,"Enyi Jiang, Gagandeep Singh",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03000"" target=""_blank"">2410.03000</a>",,2024-12-11
Chain-of-Jailbreak Attack for Image Generation Models via Editing Step by Step,"Wenxuan Wang, Kuiyi Gao, Zihan Jia, Youliang Yuan, Jen-tse Huang, Qiuzhi Liu, Shuai Wang, Wenxiang Jiao, Zhaopeng Tu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03869"" target=""_blank"">2410.03869</a>",,2024-12-11
PFAttack: Stealthy Attack Bypassing Group Fairness in Federated Learning,"Jiashi Gao, Ziwei Wang, Xiangyu Zhao, Xin Yao, Xuetao Wei",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06509"" target=""_blank"">2410.06509</a>",,2024-12-11
On the Adversarial Risk of Test Time Adaptation: An Investigation into Realistic Test-Time Data Poisoning,"Yongyi Su, Yushu Li, Nanqing Liu, Kui Jia, Xulei Yang, Chuan-Sheng Foo, Xun Xu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04682"" target=""_blank"">2410.04682</a>",,2024-12-11
"Recent advancements in LLM Red-Teaming: Techniques, Defenses, and Ethical Considerations","Tarun Raheja, Nilay Pochhi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09097"" target=""_blank"">2410.09097</a>",,2024-12-11
TaeBench: Improving Quality of Toxic Adversarial Examples,"Xuan Zhu, Dmitriy Bespalov, Liwen You, Ninad Kulkarni, Yanjun Qi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05573"" target=""_blank"">2410.05573</a>",,2024-12-11
AnyAttack: Towards Large-scale Self-supervised Generation of Targeted Adversarial Examples for Vision-Language Models,"Jiaming Zhang, Junhong Ye, Xingjun Ma, Yige Li, Yunfan Yang, Jitao Sang, Dit-Yan Yeung",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05346"" target=""_blank"">2410.05346</a>",,2024-12-11
LOTOS: Layer-wise Orthogonalization for Training Robust Ensembles,"Ali Ebrahimpour-Boroojeny, Hari Sundaram, Varun Chandrasekaran",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05136"" target=""_blank"">2410.05136</a>",,2024-12-11
Patch is Enough: Naturalistic Adversarial Patch against Vision-Language Pre-training Models,"Dehong Kong, Siyuan Liang, Xiaopeng Zhu, Yuansheng Zhong, Wenqi Ren",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04884"" target=""_blank"">2410.04884</a>",,2024-12-11
MIBench: A Comprehensive Benchmark for Model Inversion Attack and Defense,"Yixiang Qiu, Hongyao Yu, Hao Fang, Wenbo Yu, Bin Chen, Xuan Wang, Shu-Tao Xia, Ke Xu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05159"" target=""_blank"">2410.05159</a>",,2024-12-11
STOP! Camera Spoofing via the in-Vehicle IP Network,"Dror Peri, Avishai Wool",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05417"" target=""_blank"">2410.05417</a>",,2024-12-11
Double Oracle Neural Architecture Search for Game Theoretic Deep Learning Models,"Aye Phyu Phyu Aung, Xinrun Wang, Ruiyu Wang, Hau Chan, Bo An, Xiaoli Li, J. Senthilnath",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04764"" target=""_blank"">2410.04764</a>",,2024-12-11
Collaboration! Towards Robust Neural Methods for Routing Problems,"Jianan Zhou, Yaoxin Wu, Zhiguang Cao, Wen Song, Jie Zhang, Zhiqi Shen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04968"" target=""_blank"">2410.04968</a>",,2024-12-11
Aligning LLMs to Be Robust Against Prompt Injection,"Sizhe Chen, Arman Zharmagambetov, Saeed Mahloujifar, Kamalika Chaudhuri, Chuan Guo",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05451"" target=""_blank"">2410.05451</a>","<a href=""https://github.com/facebookresearch/SecAlign"" target=""_blank"">facebookresearch</a>",2024-12-11
CAT: Concept-level backdoor ATtacks for Concept Bottleneck Models,"Songning Lai, Jiayu Yang, Yu Huang, Lijie Hu, Tianlang Xue, Zhangyi Hu, Jiaxu Li, Haicheng Liao, Yutao Yue",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04823"" target=""_blank"">2410.04823</a>",,2024-12-11
Defense-as-a-Service: Black-box Shielding against Backdoored Graph Models,"Xiao Yang, Kai Zhou, Yuni Lai, Gaolei Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04916"" target=""_blank"">2410.04916</a>",,2024-12-11
Towards World Simulator: Crafting Physical Commonsense-Based Benchmark for Video Generation,"Fanqing Meng, Jiaqi Liao, Xinyu Tan, Wenqi Shao, Quanfeng Lu, Kaipeng Zhang, Yu Cheng, Dianqi Li, Yu Qiao, Ping Luo",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05363"" target=""_blank"">2410.05363</a>","<a href=""https://github.com/OpenGVLab/PhyGenBench"" target=""_blank"">OpenGVLab</a>",2024-12-11
Suspiciousness of Adversarial Texts to Human,"Shakila Mahjabin Tonni, Pedro Faustini, Mark Dras",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04377"" target=""_blank"">2410.04377</a>",,2024-12-11
TA3: Testing Against Adversarial Attacks on Machine Learning Models,"Yuanzhe Jin, Min Chen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05334"" target=""_blank"">2410.05334</a>",,2024-12-11
BN-SCAFFOLD: controlling the drift of Batch Normalization statistics in Federated Learning,"Gonzalo IÃ±aki Quintana, Laurence Vancamberg, Vincent Jugnon, Mathilde Mougeot, AgnÃ¨s Desolneux",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03281"" target=""_blank"">2410.03281</a>",,2024-12-11
Robustness Reprogramming for Representation Learning,"Zhichao Hou, MohamadAli Torkamani, Hamid Krim, Xiaorui Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04577"" target=""_blank"">2410.04577</a>",,2024-12-11
Towards Understanding and Enhancing Security of Proof-of-Training for DNN Model Ownership Verification,"Yijia Chang, Hanrui Jiang, Chao Lin, Xinyi Huang, Jian Weng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04397"" target=""_blank"">2410.04397</a>",,2024-12-11
Federated Learning Nodes Can Reconstruct Peers' Image Data,"Ethan Wilson, Kai Yue, Chau-Wai Wong, Huaiyu Dai",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04661"" target=""_blank"">2410.04661</a>",,2024-12-11
Harnessing Task Overload for Scalable Jailbreak Attacks on Large Language Models,"Yiting Dong, Guobin Shen, Dongcheng Zhao, Xiang He, Yi Zeng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04190"" target=""_blank"">2410.04190</a>",,2024-12-11
ConDa: Fast Federated Unlearning with Contribution Dampening,"Vikram S Chundawat, Pushkar Niroula, Prasanna Dhungana, Stefan Schoepf, Murari Mandal, Alexandra Brintrup",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04144"" target=""_blank"">2410.04144</a>",,2024-12-11
Mitigating Adversarial Perturbations for Deep Reinforcement Learning via Vector Quantization,"Tung M. Luu, Thanh Nguyen, Tee Joshua Tian Jin, Sungwoon Kim, Chang D. Yoo",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03376"" target=""_blank"">2410.03376</a>",,2024-12-11
RAFT: Realistic Attacks to Fool Text Detectors,"James Wang, Ran Li, Junfeng Yang, Chengzhi Mao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03658"" target=""_blank"">2410.03658</a>",,2024-12-11
AdvBDGen: Adversarially Fortified Prompt-Specific Fuzzy Backdoor Generator Against LLM Alignment,"Pankayaraj Pathmanathan, Udari Madhushani Sehwag, Michael-Andrei Panaitescu-Liess, Furong Huang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11283"" target=""_blank"">2410.11283</a>",,2024-12-11
Gradient-based Jailbreak Images for Multimodal Fusion Models,"Javier Rando, Hannah Korevaar, Erik Brinkman, Ivan Evtimov, Florian TramÃ¨r",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03489"" target=""_blank"">2410.03489</a>",,2024-12-11
You Know What I'm Saying -- Jailbreak Attack via Implicit Reference,"Tianyu Wu, Lingrui Mei, Ruibin Yuan, Lujun Li, Wei Xue, Yike Guo",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03857"" target=""_blank"">2410.03857</a>","<a href=""https://github.com/Lucas-TY/llm_Implicit_reference"" target=""_blank"">Lucas-TY</a>",2024-12-11
Impact of Regularization on Calibration and Robustness: from the Representation Space Perspective,"Jonghyun Park, Juyeop Kim, Jong-Seok Lee",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03999"" target=""_blank"">2410.03999</a>",,2024-12-11
Make Interval Bound Propagation great again,"Patryk Krukowski, Daniel Wilczak, Jacek Tabor, Anna Bielawska, PrzemysÅaw Spurek",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03373"" target=""_blank"">2410.03373</a>",,2024-12-11
Classification-Denoising Networks,"Louis Thiry, Florentin Guth",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03505"" target=""_blank"">2410.03505</a>",,2024-12-11
Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs,"Tomas Bueno Momcilovic, Dian Balta, Beat Buesser, Giulio Zizzo, Mark Purcell",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09078"" target=""_blank"">2410.09078</a>",,2024-12-11
Backdoor Attack on Vertical Federated Graph Neural Network Learning,"Jirui Yang, Peng Chen, Zhihui Lu, Ruijun Deng, Qiang Duan, Jianping Zeng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11290"" target=""_blank"">2410.11290</a>",,2024-12-11
MOREL: Enhancing Adversarial Robustness through Multi-Objective Representation Learning,"Sedjro Salomon Hotegni, Sebastian Peitz",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01697"" target=""_blank"">2410.01697</a>","<a href=""https://github.com/salomonhotegni/MOREL"" target=""_blank"">salomonhotegni</a>",2024-12-11
Cognitive Overload Attack:Prompt Injection for Long Context,"Bibek Upadhayay, Vahid Behzadan, Amin Karbasi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11272"" target=""_blank"">2410.11272</a>",,2024-12-11
Fine-tuned Large Language Models (LLMs): Improved Prompt Injection Attacks Detection,"Md Abdur Rahman, Fan Wu, Alfredo Cuzzocrea, Sheikh Iqbal Ahamed",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21337"" target=""_blank"">2410.21337</a>",,2024-12-11
GPT-4o System Card,"Tony OpenAI, Tony :, Aaron Tony Hurst, Adam Tony Lerer, Adam P. Tony Goucher, Adam Tony Perelman, Aditya Tony Ramesh, Aidan Tony Clark, AJ Tony Ostrow, Akila Tony Welihinda, Alan Tony Hayes, Alec Tony Radford, Aleksander Tony MÄdry, Alex Tony Baker-Whitcomb, Alex Tony Beutel, Alex Tony Borzunov, Alex Tony Carney, Alex Tony Chow, Alex Tony Kirillov, Alex Tony Nichol, Alex Tony Paino, Alex Tony Renzin, Alex Tachard Tony Passos, Alexander Tony Kirillov, Alexi Tony Christakis, Alexis Tony Conneau, Ali Tony Kamali, Allan Tony Jabri, Allison Tony Moyer, Allison Tony Tam, Amadou Tony Crookes, Amin Tony Tootoochian, Amin Tony Tootoonchian, Ananya Tony Kumar, Andrea Tony Vallone, Andrej Tony Karpathy, Andrew Tony Braunstein, Andrew Tony Cann, Andrew Tony Codispoti, Andrew Tony Galu, Andrew Tony Kondrich, Andrew Tony Tulloch, Andrey Tony Mishchenko, Angela Tony Baek, Angela Tony Jiang, Antoine Tony Pelisse, Antonia Tony Woodford, Anuj Tony Gosalia, Arka Tony Dhar, Ashley Tony Pantuliano, Avi Tony Nayak, Avital Tony Oliver, Barret Tony Zoph, Behrooz Tony Ghorbani, Ben Tony Leimberger, Ben Tony Rossen, Ben Tony Sokolowsky, Ben Tony Wang, Benjamin Tony Zweig, Beth Tony Hoover, Blake Tony Samic, Bob Tony McGrew, Bobby Tony Spero, Bogo Tony Giertler, Bowen Tony Cheng, Brad Tony Lightcap, Brandon Tony Walkin, Brendan Tony Quinn, Brian Tony Guarraci, Brian Tony Hsu, Bright Tony Kellogg, Brydon Tony Eastman, Camillo Tony Lugaresi, Carroll Tony Wainwright, Cary Tony Bassin, Cary Tony Hudson, Casey Tony Chu, Chad Tony Nelson, Chak Tony Li, Chan Jun Tony Shern, Channing Tony Conger, Charlotte Tony Barette, Chelsea Tony Voss, Chen Tony Ding, Cheng Tony Lu, Chong Tony Zhang, Chris Tony Beaumont, Chris Tony Hallacy, Chris Tony Koch, Christian Tony Gibson, Christina Tony Kim, Christine Tony Choi, Christine Tony McLeavey, Christopher Tony Hesse, Claudia Tony Fischer, Clemens Tony Winter, Coley Tony Czarnecki, Colin Tony Jarvis, Colin Tony Wei, Constantin Tony Koumouzelis, Dane Tony Sherburn, Daniel Tony Kappler, Daniel Tony Levin, Daniel Tony Levy, David Tony Carr, David Tony Farhi, David Tony Mely, David Tony Robinson, David Tony Sasaki, Denny Tony Jin, Dev Tony Valladares, Dimitris Tony Tsipras, Doug Tony Li, Duc Phong Tony Nguyen, Duncan Tony Findlay, Edede Tony Oiwoh, Edmund Tony Wong, Ehsan Tony Asdar, Elizabeth Tony Proehl, Elizabeth Tony Yang, Eric Tony Antonow, Eric Tony Kramer, Eric Tony Peterson, Eric Tony Sigler, Eric Tony Wallace, Eugene Tony Brevdo, Evan Tony Mays, Farzad Tony Khorasani, Felipe Petroski Tony Such, Filippo Tony Raso, Francis Tony Zhang, Lohmann Fred Tony von, Freddie Tony Sulit, Gabriel Tony Goh, Gene Tony Oden, Geoff Tony Salmon, Giulio Tony Starace, Greg Tony Brockman, Hadi Tony Salman, Haiming Tony Bao, Haitang Tony Hu, Hannah Tony Wong, Haoyu Tony Wang, Heather Tony Schmidt, Heather Tony Whitney, Heewoo Tony Jun, Hendrik Tony Kirchner, Henrique Ponde de Oliveira Tony Pinto, Hongyu Tony Ren, Huiwen Tony Chang, Hyung Won Tony Chung, Ian Tony Kivlichan, Ian Tony O'Connell, Ian Tony O'Connell, Ian Tony Osband, Ian Tony Silber, Ian Tony Sohl, Ibrahim Tony Okuyucu, Ikai Tony Lan, Ilya Tony Kostrikov, Ilya Tony Sutskever, Ingmar Tony Kanitscheider, Ishaan Tony Gulrajani, Jacob Tony Coxon, Jacob Tony Menick, Jakub Tony Pachocki, James Tony Aung, James Tony Betker, James Tony Crooks, James Tony Lennon, Jamie Tony Kiros, Jan Tony Leike, Jane Tony Park, Jason Tony Kwon, Jason Tony Phang, Jason Tony Teplitz, Jason Tony Wei, Jason Tony Wolfe, Jay Tony Chen, Jeff Tony Harris, Jenia Tony Varavva, Jessica Gan Tony Lee, Jessica Tony Shieh, Ji Tony Lin, Jiahui Tony Yu, Jiayi Tony Weng, Jie Tony Tang, Jieqi Tony Yu, Joanne Tony Jang, Joaquin Quinonero Tony Candela, Joe Tony Beutler, Joe Tony Landers, Joel Tony Parish, Johannes Tony Heidecke, John Tony Schulman, Jonathan Tony Lachman, Jonathan Tony McKay, Jonathan Tony Uesato, Jonathan Tony Ward, Jong Wook Tony Kim, Joost Tony Huizinga, Jordan Tony Sitkin, Jos Tony Kraaijeveld, Josh Tony Gross, Josh Tony Kaplan, Josh Tony Snyder, Joshua Tony Achiam, Joy Tony Jiao, Joyce Tony Lee, Juntang Tony Zhuang, Justyn Tony Harriman, Kai Tony Fricke, Kai Tony Hayashi, Karan Tony Singhal, Katy Tony Shi, Kavin Tony Karthik, Kayla Tony Wood, Kendra Tony Rimbach, Kenny Tony Hsu, Kenny Tony Nguyen, Keren Tony Gu-Lemberg, Kevin Tony Button, Kevin Tony Liu, Kiel Tony Howe, Krithika Tony Muthukumar, Kyle Tony Luther, Lama Tony Ahmad, Larry Tony Kai, Lauren Tony Itow, Lauren Tony Workman, Leher Tony Pathak, Leo Tony Chen, Li Tony Jing, Lia Tony Guy, Liam Tony Fedus, Liang Tony Zhou, Lien Tony Mamitsuka, Lilian Tony Weng, Lindsay Tony McCallum, Lindsey Tony Held, Long Tony Ouyang, Louis Tony Feuvrier, Lu Tony Zhang, Lukas Tony Kondraciuk, Lukasz Tony Kaiser, Luke Tony Hewitt, Luke Tony Metz, Lyric Tony Doshi, Mada Tony Aflak, Maddie Tony Simens, Madelaine Tony Boyd, Madeleine Tony Thompson, Marat Tony Dukhan, Mark Tony Chen, Mark Tony Gray, Mark Tony Hudnall, Marvin Tony Zhang, Marwan Tony Aljubeh, Mateusz Tony Litwin, Matthew Tony Zeng, Max Tony Johnson, Maya Tony Shetty, Mayank Tony Gupta, Meghan Tony Shah, Mehmet Tony Yatbaz, Meng Jia Tony Yang, Mengchao Tony Zhong, Mia Tony Glaese, Mianna Tony Chen, Michael Tony Janner, Michael Tony Lampe, Michael Tony Petrov, Michael Tony Wu, Michele Tony Wang, Michelle Tony Fradin, Michelle Tony Pokrass, Miguel Tony Castro, Castro Miguel Oom Temudo Tony de, Mikhail Tony Pavlov, Miles Tony Brundage, Miles Tony Wang, Minal Tony Khan, Mira Tony Murati, Mo Tony Bavarian, Molly Tony Lin, Murat Tony Yesildal, Nacho Tony Soto, Natalia Tony Gimelshein, Natalie Tony Cone, Natalie Tony Staudacher, Natalie Tony Summers, Natan Tony LaFontaine, Neil Tony Chowdhury, Nick Tony Ryder, Nick Tony Stathas, Nick Tony Turley, Nik Tony Tezak, Niko Tony Felix, Nithanth Tony Kudige, Nitish Tony Keskar, Noah Tony Deutsch, Noel Tony Bundick, Nora Tony Puckett, Ofir Tony Nachum, Ola Tony Okelola, Oleg Tony Boiko, Oleg Tony Murk, Oliver Tony Jaffe, Olivia Tony Watkins, Olivier Tony Godement, Owen Tony Campbell-Moore, Patrick Tony Chao, Paul Tony McMillan, Pavel Tony Belov, Peng Tony Su, Peter Tony Bak, Peter Tony Bakkum, Peter Tony Deng, Peter Tony Dolan, Peter Tony Hoeschele, Peter Tony Welinder, Phil Tony Tillet, Philip Tony Pronin, Philippe Tony Tillet, Prafulla Tony Dhariwal, Qiming Tony Yuan, Rachel Tony Dias, Rachel Tony Lim, Rahul Tony Arora, Rajan Tony Troll, Randall Tony Lin, Rapha Gontijo Tony Lopes, Raul Tony Puri, Reah Tony Miyara, Reimar Tony Leike, Renaud Tony Gaubert, Reza Tony Zamani, Ricky Tony Wang, Rob Tony Donnelly, Rob Tony Honsby, Rocky Tony Smith, Rohan Tony Sahai, Rohit Tony Ramchandani, Romain Tony Huet, Rory Tony Carmichael, Rowan Tony Zellers, Roy Tony Chen, Ruby Tony Chen, Ruslan Tony Nigmatullin, Ryan Tony Cheu, Saachi Tony Jain, Sam Tony Altman, Sam Tony Schoenholz, Sam Tony Toizer, Samuel Tony Miserendino, Sandhini Tony Agarwal, Sara Tony Culver, Scott Tony Ethersmith, Scott Tony Gray, Sean Tony Grove, Sean Tony Metzger, Shamez Tony Hermani, Shantanu Tony Jain, Shengjia Tony Zhao, Sherwin Tony Wu, Shino Tony Jomoto, Shirong Tony Wu, Tony Shuaiqi, Xia, Sonia Phene, Spencer Papay, Srinivas Narayanan, Steve Coffey, Steve Lee, Stewart Hall, Suchir Balaji, Tal Broda, Tal Stramer, Tao Xu, Tarun Gogineni, Taya Christianson, Ted Sanders, Tejal Patwardhan, Thomas Cunninghman, Thomas Degry, Thomas Dimson, Thomas Raoux, Thomas Shadwell, Tianhao Zheng, Todd Underwood, Todor Markov, Toki Sherbakov, Tom Rubin, Tom Stasi, Tomer Kaftan, Tristan Heywood, Troy Peterson, Tyce Walters, Tyna Eloundou, Valerie Qi, Veit Moeller, Vinnie Monaco, Vishal Kuo, Vlad Fomenko, Wayne Chang, Weiyi Zheng, Wenda Zhou, Wesam Manassra, Will Sheu, Wojciech Zaremba, Yash Patil, Yilei Qian, Yongjik Kim, Youlong Cheng, Yu Zhang, Yuchen He, Yuchen Zhang, Yujia Jin, Yunxing Dai, Yury Malkov",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21276"" target=""_blank"">2410.21276</a>",,2024-12-11
Robust Model Evaluation over Large-scale Federated Networks,"Amir Najafi, Samin Mahdizadeh Sani, Farzan Farnia",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20250"" target=""_blank"">2410.20250</a>",,2024-12-11
CodePurify: Defend Backdoor Attacks on Neural Code Models via Entropy-based Purification,"Fangwen Mu, Junjie Wang, Zhuohao Yu, Lin Shi, Song Wang, Mingyang Li, Qing Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20136"" target=""_blank"">2410.20136</a>",,2024-12-11
Generative Adversarial Patches for Physical Attacks on Cross-Modal Pedestrian Re-Identification,"Yue Su, Hao Li, Maoguo Gong",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20097"" target=""_blank"">2410.20097</a>",,2024-12-11
Transferable Adversarial Attacks on SAM and Its Downstream Models,"Song Xia, Wenhan Yang, Yi Yu, Xun Lin, Henghui Ding, Lingyu Duan, Xudong Jiang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20197"" target=""_blank"">2410.20197</a>","<a href=""https://github.com/xiasong0501/GRAT"" target=""_blank"">xiasong0501</a>",2024-12-11
Adversarial Attacks Against Double RIS-Assisted MIMO Systems-based Autoencoder in Finite-Scattering Environments,"Bui Duc Son, Ngo Nam Khanh, Chien Trinh Van, Dong In Kim",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20103"" target=""_blank"">2410.20103</a>",,2024-12-11
LLM Robustness Against Misinformation in Biomedical Question Answering,"Alexander Bondarenko, Adrian Viehweger",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21330"" target=""_blank"">2410.21330</a>",,2024-12-11
Test-time Adversarial Defense with Opposite Adversarial Path and High Attack Time Cost,"Cheng-Han Yeh, Kuanchun Yu, Chun-Shien Lu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16805"" target=""_blank"">2410.16805</a>",,2024-12-11
Integrating uncertainty quantification into randomized smoothing based robustness guarantees,"Sina DÃ¤ubener, Kira Maag, David Krueger, Asja Fischer",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20432"" target=""_blank"">2410.20432</a>",,2024-12-11
Palisade -- Prompt Injection Detection Framework,"Sahasra Kokkula, Somanathan R, Nandavardhan R, Aashishkumar, G Divya",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21146"" target=""_blank"">2410.21146</a>",,2024-12-11
Mitigating Unauthorized Speech Synthesis for Voice Protection,"Zhisheng Zhang, Qianyi Yang, Derui Wang, Pengyang Huang, Yuxin Cao, Kai Ye, Jie Hao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20742"" target=""_blank"">2410.20742</a>",,2024-12-11
Stealthy Jailbreak Attacks on Large Language Models via Benign Data Mirroring,"Honglin Mu, Han He, Yuxin Zhou, Yunlong Feng, Yang Xu, Libo Qin, Xiaoming Shi, Zeming Liu, Xudong Han, Qi Shi, Qingfu Zhu, Wanxiang Che",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21083"" target=""_blank"">2410.21083</a>",,2024-12-11
Hacking Back the AI-Hacker: Prompt Injection as a Defense Against LLM-driven Cyberattacks,"Dario Pasquini, Evgenios M. Kornaropoulos, Giuseppe Ateniese",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20911"" target=""_blank"">2410.20911</a>","<a href=""https://github.com/pasquini-dario/project_mantis"" target=""_blank"">pasquini-dario</a>",2024-12-11
Attacking Misinformation Detection Using Adversarial Examples Generated by Language Models,Piotr PrzybyÅa,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20940"" target=""_blank"">2410.20940</a>",,2024-12-11
RobustKV: Defending Large Language Models against Jailbreak Attacks via KV Eviction,"Tanqiu Jiang, Zian Wang, Jiacheng Liang, Changjiang Li, Yuhui Wang, Ting Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.19937"" target=""_blank"">2410.19937</a>",,2024-12-11
Attacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions,"Poojitha Thota, Shirin Nilizadeh",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20019"" target=""_blank"">2410.20019</a>",,2024-12-11
Expose Before You Defend: Unifying and Enhancing Backdoor Defenses via Exposed Models,"Yige Li, Hanxun Huang, Jiaming Zhang, Xingjun Ma, Yu-Gang Jiang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.19427"" target=""_blank"">2410.19427</a>","<a href=""https://github.com/bboylyg/Expose-Before-You-Defend"" target=""_blank"">bboylyg</a>",2024-12-11
Towards Robust Algorithms for Surgical Phase Recognition via Digital Twin-based Scene Representation,"Hao Ding, Yuqian Zhang, Hongchao Shu, Xu Lian, Ji Woong Kim, Axel Krieger, Mathias Unberath",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20026"" target=""_blank"">2410.20026</a>",,2024-12-11
GADT: Enhancing Transferable Adversarial Attacks through Gradient-guided Adversarial Data Transformation,"Yating Ma, Xiaogang Xu, Liming Fang, Zhe Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18648"" target=""_blank"">2410.18648</a>",,2024-12-11
Adversarial Attacks on Large Language Models Using Regularized Relaxation,"Samuel Jacob Chacko, Sajib Biswas, Chashi Mahiul Islam, Fatema Tabassum Liza, Xiuwen Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.19160"" target=""_blank"">2410.19160</a>",,2024-12-11
Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities,"Chung-En Sun, Xiaodong Liu, Weiwei Yang, Tsui-Wei Weng, Hao Cheng, Aidan San, Michel Galley, Jianfeng Gao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18469"" target=""_blank"">2410.18469</a>",,2024-12-11
Humanizing the Machine: Proxy Attacks to Mislead LLM Detectors,"Tianchun Wang, Yuanzhou Chen, Zichuan Liu, Zhanwen Chen, Haifeng Chen, Xiang Zhang, Wei Cheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.19230"" target=""_blank"">2410.19230</a>",,2024-12-11
Complexity Matters: Effective Dimensionality as a Measure for Adversarial Robustness,"David Khachaturov, Robert Mullins",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18556"" target=""_blank"">2410.18556</a>",,2024-12-11
Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances,"Shilin Lu, Zihan Zhou, Jiayou Lu, Yuanzhi Zhu, Adams Wai-Kin Kong",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18775"" target=""_blank"">2410.18775</a>","<a href=""https://github.com/Shilin-LU/VINE"" target=""_blank"">Shilin-LU</a>",2024-12-11
Advancing NLP Security by Leveraging LLMs as Adversarial Engines,"Sudarshan Srinivasan, Maria Mahbub, Amir Sadovnik",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18215"" target=""_blank"">2410.18215</a>",,2024-12-11
Backdoor in Seconds: Unlocking Vulnerabilities in Large Pre-trained Models via Model Editing,"Dongliang Guo, Mengxuan Hu, Zihan Guan, Junfeng Guo, Thomas Hartvigsen, Sheng Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18267"" target=""_blank"">2410.18267</a>",,2024-12-11
Breaking the Illusion: Real-world Challenges for Adversarial Patches in Object Detection,"Jakob Shack, Katarina Petrovic, Olga Saukh",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.19863"" target=""_blank"">2410.19863</a>",,2024-12-11
Slot: Provenance-Driven APT Detection through Graph Reinforcement Learning,"Wei Qiao, Yebo Feng, Teng Li, Zijian Zhang, Zhengzi Xu, Zhuo Ma, Yulong Shen, JianFeng Ma, Yang Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17910"" target=""_blank"">2410.17910</a>",,2024-12-11
Guide for Defense (G4D): Dynamic Guidance for Robust and Balanced Defense in Large Language Models,"He Cao, Weidi Luo, Yu Wang, Zijing Liu, Bing Feng, Yuan Yao, Yu Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17922"" target=""_blank"">2410.17922</a>",,2024-12-11
Towards Understanding the Fragility of Multilingual LLMs against Fine-Tuning Attacks,"Samuele Poppi, Zheng-Xin Yong, Yifei He, Bobbie Chern, Han Zhao, Aobo Yang, Jianfeng Chi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18210"" target=""_blank"">2410.18210</a>",,2024-12-11
Countering Autonomous Cyber Threats,"Kade M. Heckel, Adrian Weller",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18312"" target=""_blank"">2410.18312</a>",,2024-12-11
TACO: Adversarial Camouflage Optimization on Trucks to Fool Object Detectors,"Adonisz Dimitriu, TamÃ¡s Michaletzky, Viktor Remeli",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21443"" target=""_blank"">2410.21443</a>",,2024-12-11
FATH: Authentication-based Test-time Defense against Indirect Prompt Injection Attacks,"Jiongxiao Wang, Fangzhou Wu, Wendi Li, Jinsheng Pan, Edward Suh, Z. Morley Mao, Muhao Chen, Chaowei Xiao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21492"" target=""_blank"">2410.21492</a>","<a href=""https://github.com/Jayfeather1024/FATH"" target=""_blank"">Jayfeather1024</a>",2024-12-11
BlueSuffix: Reinforced Blue Teaming for Vision-Language Models Against Jailbreak Attacks,"Yunhan Zhao, Xiang Zheng, Lin Luo, Yige Li, Xingjun Ma, Yu-Gang Jiang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20971"" target=""_blank"">2410.20971</a>",,2024-12-11
Teaching a Language Model to Distinguish Between Similar Details using a Small Adversarial Training Set,Chris Achard,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23118"" target=""_blank"">2410.23118</a>",,2024-12-11
BeniFul: Backdoor Defense via Middle Feature Analysis for Deep Neural Networks,"Xinfu Li, Junying Zhang, Xindi Ma",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14723"" target=""_blank"">2410.14723</a>",,2024-12-11
Wide Two-Layer Networks can Learn from Adversarial Perturbations,"Soichiro Kumano, Hiroshi Kera, Toshihiko Yamasaki",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23677"" target=""_blank"">2410.23677</a>","<a href=""https://github.com/s-kumano/perturbation-learning"" target=""_blank"">s-kumano</a>",2024-12-11
DiffPAD: Denoising Diffusion-based Adversarial Patch Decontamination,"Jia Fu, Xiao Zhang, Sepideh Pashami, Fatemeh Rahimian, Anders Holst",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.24006"" target=""_blank"">2410.24006</a>",,2024-12-11
Noise as a Double-Edged Sword: Reinforcement Learning Exploits Randomized Defenses in Neural Networks,"Steve Bakos, Pooria Madani, Heidar Davoudi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23870"" target=""_blank"">2410.23870</a>",,2024-12-11
Pseudo-Conversation Injection for LLM Goal Hijacking,"Zheng Chen, Buhui Yao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23678"" target=""_blank"">2410.23678</a>",,2024-12-11
ARQ: A Mixed-Precision Quantization Framework for Accurate and Certifiably Robust DNNs,"Yuchen Yang, Shubham Ugare, Yifan Zhao, Gagandeep Singh, Sasa Misailovic",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.24214"" target=""_blank"">2410.24214</a>",,2024-12-11
Adversarial Attacks of Vision Tasks in the Past 10 Years: A Survey,"Chiyu Zhang, Xiaogang Xu, Jiafei Wu, Zhe Liu, Lu Zhou",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23687"" target=""_blank"">2410.23687</a>",,2024-12-11
FAIR-TAT: Improving Model Fairness Using Targeted Adversarial Training,"Tejaswini Medi, Steffen Jung, Margret Keuper",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23142"" target=""_blank"">2410.23142</a>",,2024-12-11
Keep on Swimming: Real Attackers Only Need Partial Knowledge of a Multi-Model System,"Julian Collado, Kevin Stangl",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23483"" target=""_blank"">2410.23483</a>",,2024-12-11
CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense,"Mingkun Zhang, Keping Bi, Wei Chen, Quanrun Chen, Jiafeng Guo, Xueqi Cheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23091"" target=""_blank"">2410.23091</a>",,2024-12-11
One Prompt to Verify Your Models: Black-Box Text-to-Image Models Verification via Non-Transferable Adversarial Attacks,"Ji Guo, Wenbo Jiang, Rui Zhang, Guoming Lu, Hongwei Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22725"" target=""_blank"">2410.22725</a>",,2024-12-11
Effective and Efficient Adversarial Detection for Vision-Language Models via A Single Vector,"Youcheng Huang, Fengbin Zhu, Jingkun Tang, Pan Zhou, Wenqiang Lei, Jiancheng Lv, Tat-Seng Chua",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22888"" target=""_blank"">2410.22888</a>","<a href=""https://github.com/mob-scu/RADAR-NEARSIDE"" target=""_blank"">mob-scu</a>",2024-12-11
HijackRAG: Hijacking Attacks against Retrieval-Augmented Large Language Models,"Yucheng Zhang, Qinfeng Li, Tianyu Du, Xuhong Zhang, Xinkui Zhao, Zhengwen Feng, Jianwei Yin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22832"" target=""_blank"">2410.22832</a>",,2024-12-11
Understanding and Improving Adversarial Collaborative Filtering for Robust Recommendation,"Kaike Zhang, Qi Cao, Yunfan Wu, Fei Sun, Huawei Shen, Xueqi Cheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22844"" target=""_blank"">2410.22844</a>",,2024-12-11
Backdoor Attack Against Vision Transformers via Attention Gradient-Based Image Erosion,"Ji Guo, Hongwei Li, Wenbo Jiang, Guoming Lu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22678"" target=""_blank"">2410.22678</a>",,2024-12-11
AdvI2I: Adversarial Image Attack on Image-to-Image Diffusion models,"Yaopei Zeng, Yuanpu Cao, Bochuan Cao, Yurui Chang, Jinghui Chen, Lu Lin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21471"" target=""_blank"">2410.21471</a>",,2024-12-11
Geometry Cloak: Preventing TGS-based 3D Reconstruction from Copyrighted Images,"Qi Song, Ziyuan Luo, Ka Chun Cheung, Simon See, Renjie Wan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22705"" target=""_blank"">2410.22705</a>","<a href=""https://qsong2001.github.io/geometry_cloak"" target=""_blank"">qsong2001.github.io</a>",2024-12-11
Byzantine-Robust Federated Learning: An Overview With Focus on Developing Sybil-based Attacks to Backdoor Augmented Secure Aggregation Protocols,Atharv Deshmukh,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22680"" target=""_blank"">2410.22680</a>",,2024-12-11
ProTransformer: Robustify Transformers via Plug-and-Play Paradigm,"Zhichao Hou, Weizhi Gao, Yuchen Shen, Feiyi Wang, Xiaorui Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23182"" target=""_blank"">2410.23182</a>",,2024-12-11
Stealing User Prompts from Mixture of Experts,"Itay Yona, Ilia Shumailov, Jamie Hayes, Nicholas Carlini",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22884"" target=""_blank"">2410.22884</a>",,2024-12-11
InjecGuard: Benchmarking and Mitigating Over-defense in Prompt Injection Guardrail Models,"Hao Li, Xiaogeng Liu, Chaowei Xiao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22770"" target=""_blank"">2410.22770</a>","<a href=""https://github.com/SaFoLab-WISC/InjecGuard"" target=""_blank"">SaFoLab-WISC</a>",2024-12-11
On the Robustness of Adversarial Training Against Uncertainty Attacks,"Emanuele Ledda, Giovanni Scodeller, Daniele Angioni, Giorgio Piras, Antonio Emanuele CinÃ , Giorgio Fumera, Battista Biggio, Fabio Roli",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21952"" target=""_blank"">2410.21952</a>",,2024-12-11
Text-Guided Attention is All You Need for Zero-Shot Robustness in Vision-Language Models,"Lu Yu, Haiyang Zhang, Changsheng Xu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21802"" target=""_blank"">2410.21802</a>","<a href=""https://github.com/zhyblue424/TGA-ZSR"" target=""_blank"">zhyblue424</a>",2024-12-11
Automated Trustworthiness Oracle Generation for Machine Learning Text Classifiers,"Lam Nguyen Tung, Steven Cho, Xiaoning Du, Neelofar Neelofar, Valerio Terragni, Stefano Ruberto, Aldeida Aleti",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22663"" target=""_blank"">2410.22663</a>",,2024-12-11
AmpleGCG-Plus: A Strong Generative Model of Adversarial Suffixes to Jailbreak LLMs with Higher Success Rates in Fewer Attempts,"Vishal Kumar, Zeyi Liao, Jaylen Jones, Huan Sun",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22143"" target=""_blank"">2410.22143</a>",,2024-12-11
Embedding-based classifiers can detect prompt injection attacks,"Md. Ahsan Ayub, Subhabrata Majumdar",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22284"" target=""_blank"">2410.22284</a>",,2024-12-11
Enhancing Adversarial Attacks through Chain of Thought,Jingbo Su,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21791"" target=""_blank"">2410.21791</a>","<a href=""https://github.com/sujingbo0217/CS222W24-LLM-Attack"" target=""_blank"">sujingbo0217</a>",2024-12-11
Power side-channel leakage localization through adversarial training of deep neural networks,"Jimmy Gammell, Anand Raghunathan, Kaushik Roy",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22425"" target=""_blank"">2410.22425</a>",,2024-12-11
Enhancing Safety and Robustness of Vision-Based Controllers via Reachability Analysis,"Kaustav Chakraborty, Aryaman Gupta, Somil Bansal",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21736"" target=""_blank"">2410.21736</a>",,2024-12-11
Evaluating the Robustness of LiDAR Point Cloud Tracking Against Adversarial Attack,"Shengjing Tian, Yinan Han, Xiantong Zhao, Bin Liu, Xiuping Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20893"" target=""_blank"">2410.20893</a>",,2024-12-11
Detecting Adversarial Examples,"Furkan Mumcu, Yasin Yilmaz",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17442"" target=""_blank"">2410.17442</a>",,2024-12-11
Attribute-to-Delete: Machine Unlearning via Datamodel Matching,"Kristian Georgiev, Roy Rinberg, Sung Min Park, Shivam Garg, Andrew Ilyas, Aleksander Madry, Seth Neel",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23232"" target=""_blank"">2410.23232</a>",,2024-12-11
AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents,"Chejian Xu, Mintong Kang, Jiawei Zhang, Zeyi Liao, Lingbo Mo, Mengqi Yuan, Huan Sun, Bo Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17401"" target=""_blank"">2410.17401</a>","<a href=""https://ai-secure.github.io/AdvWeb/"" target=""_blank"">AdvWeb</a>",2024-12-11
Perseus: Leveraging Common Data Patterns with Curriculum Learning for More Robust Graph Neural Networks,"Kaiwen Xia, Huijun Wu, Duanyu Li, Min Xie, Ruibo Wang, Wenzhe Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12425"" target=""_blank"">2410.12425</a>",,2024-12-11
Real-time Fake News from Adversarial Feedback,"Sanxing Chen, Yukun Huang, Bhuwan Dhingra",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14651"" target=""_blank"">2410.14651</a>",,2024-12-11
Adversarial Score identity Distillation: Rapidly Surpassing the Teacher in One Step,"Mingyuan Zhou, Huangjie Zheng, Yi Gu, Zhendong Wang, Hai Huang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14919"" target=""_blank"">2410.14919</a>",,2024-12-11
MMAD-Purify: A Precision-Optimized Framework for Efficient and Scalable Multi-Modal Attacks,"Xinxin Liu, Zhongliang Guo, Siyuan Huang, Chun Pong Lau",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14089"" target=""_blank"">2410.14089</a>",,2024-12-11
DMGNN: Detecting and Mitigating Backdoor Attacks in Graph Neural Networks,"Hao Sui, Bing Chen, Jiale Zhang, Chengcheng Zhu, Di Wu, Qinghua Lu, Guodong Long",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14105"" target=""_blank"">2410.14105</a>",,2024-12-11
Adversarial Inception for Bounded Backdoor Poisoning in Deep Reinforcement Learning,"Ethan Rathbun, Christopher Amato, Alina Oprea",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13995"" target=""_blank"">2410.13995</a>",,2024-12-11
SPIN: Self-Supervised Prompt INjection,"Leon Zhou, Junfeng Yang, Chengzhi Mao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13236"" target=""_blank"">2410.13236</a>",,2024-12-11
Jailbreaking LLM-Controlled Robots,"Alexander Robey, Zachary Ravichandran, Vijay Kumar, Hamed Hassani, George J. Pappas",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13691"" target=""_blank"">2410.13691</a>",,2024-12-11
Persistent Pre-Training Poisoning of LLMs,"Yiming Zhang, Javier Rando, Ivan Evtimov, Jianfeng Chi, Eric Michael Smith, Nicholas Carlini, Florian TramÃ¨r, Daphne Ippolito",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13722"" target=""_blank"">2410.13722</a>",,2024-12-11
Trojan Prompt Attacks on Graph Neural Networks,"Minhua Lin, Zhiwei Zhang, Enyan Dai, Zongyu Wu, Yilong Wang, Xiang Zhang, Suhang Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13974"" target=""_blank"">2410.13974</a>",,2024-12-11
Do LLMs Have Political Correctness? Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems,"Isack Lee, Haebin Seong",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13334"" target=""_blank"">2410.13334</a>",,2024-12-11
"Golyadkin's Torment: Doppelg\""angers and Adversarial Vulnerability",George I. Kamberov,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13193"" target=""_blank"">2410.13193</a>",,2024-12-11
DAT: Improving Adversarial Robustness via Generative Amplitude Mix-up in Frequency Domain,"Fengpeng Li, Kemou Li, Haiwei Wu, Jinyu Tian, Jiantao Zhou",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12307"" target=""_blank"">2410.12307</a>",,2024-12-11
Boosting Imperceptibility of Stable Diffusion-based Adversarial Examples Generation with Momentum,"Nashrah Haque, Xiang Li, Zhehui Chen, Yanzhao Wu, Lei Yu, Arun Iyengar, Wenqi Wei",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13122"" target=""_blank"">2410.13122</a>",,2024-12-11
New Paradigm of Adversarial Training: Breaking Inherent Trade-Off between Accuracy and Robustness via Dummy Classes,"Yanyun Wang, Li Liu, Zi Liang, Qingqing Ye, Haibo Hu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12671"" target=""_blank"">2410.12671</a>",,2024-12-11
Low-Rank Adversarial PGD Attack,"Dayana Savostianova, Emanuele Zangrando, Francesco Tudisco",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12607"" target=""_blank"">2410.12607</a>",,2024-12-11
Stochastic Gradient Descent Jittering for Inverse Problems: Alleviating the Accuracy-Robustness Tradeoff,"Peimeng Guan, Mark A. Davenport",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14667"" target=""_blank"">2410.14667</a>",,2024-12-11
Data Defenses Against Large Language Models,"William Agnew, Harry H. Jiang, Cella Sum, Maarten Sap, Sauvik Das",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13138"" target=""_blank"">2410.13138</a>","<a href=""https://github.com/wagnew3/LLMDataDefenses"" target=""_blank"">wagnew3</a>",2024-12-11
Hiding-in-Plain-Sight (HiPS) Attack on CLIP for Targetted Object Removal from Images,"Arka Daw, Megan Hong-Thanh Chung, Maria Mahbub, Amir Sadovnik",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13010"" target=""_blank"">2410.13010</a>",,2024-12-11
Reconstruction of Differentially Private Text Sanitization via Large Language Models,"Shuchao Pang, Zhigang Lu, Haichen Wang, Peng Fu, Yongbin Zhou, Minhui Xue, Bo Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12443"" target=""_blank"">2410.12443</a>",,2024-12-11
Unitary Multi-Margin BERT for Robust Natural Language Processing,"Hao-Yuan Chang, Kang L. Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12759"" target=""_blank"">2410.12759</a>",,2024-12-11
Mitigating the Backdoor Effect for Multi-Task Model Merging via Safety-Aware Subspace,"Jinluan Yang, Anke Tang, Didi Zhu, Zhengyu Chen, Li Shen, Fei Wu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13910"" target=""_blank"">2410.13910</a>",,2024-12-11
FedGTST: Boosting Global Transferability of Federated Models via Statistics Tuning,"Evelyn Ma, Chao Pan, Rasoul Etesami, Han Zhao, Olgica Milenkovic",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13045"" target=""_blank"">2410.13045</a>",,2024-12-11
Consistency Calibration: Improving Uncertainty Calibration via Consistency among Perturbed Neighbors,"Linwei Tao, Haolan Guo, Minjing Dong, Chang Xu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12295"" target=""_blank"">2410.12295</a>",,2024-12-11
Efficient Optimization Algorithms for Linear Adversarial Training,"AntÃ´nio H. RIbeiro, Thomas B. SchÃ¶n, Dave Zahariah, Francis Bach",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12677"" target=""_blank"">2410.12677</a>",,2024-12-11
PromptExp: Multi-granularity Prompt Explanation of Large Language Models,"Ximing Dong, Shaowei Wang, Dayi Lin, Gopi Krishnan Rajbahadur, Boquan Zhou, Shichao Liu, Ahmed E. Hassan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13073"" target=""_blank"">2410.13073</a>",,2024-12-11
Long-Tailed Backdoor Attack Using Dynamic Data Augmentation Operations,"Lu Pang, Tao Sun, Weimin Lyu, Haibin Ling, Chao Chen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12955"" target=""_blank"">2410.12955</a>",,2024-12-11
Deciphering the Chaos: Enhancing Jailbreak Attacks via Adversarial Prompt Translation,"Qizhang Li, Xiaochen Yang, Wangmeng Zuo, Yiwen Guo",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11317"" target=""_blank"">2410.11317</a>","<a href=""https://github.com/qizhangli/Adversarial-Prompt-Translator"" target=""_blank"">qizhangli</a>",2024-12-11
Taking off the Rose-Tinted Glasses: A Critical Look at Adversarial ML Through the Lens of Evasion Attacks,"Kevin Eykholt, Farhan Ahmed, Pratik Vaishnavi, Amir Rahmati",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12076"" target=""_blank"">2410.12076</a>",,2024-12-11
Meta Stackelberg Game: Robust Federated Learning against Adaptive and Mixed Poisoning Attacks,"Tao Li, Henger Li, Yunian Pan, Tianyi Xu, Zizhan Zheng, Quanyan Zhu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17431"" target=""_blank"">2410.17431</a>",,2024-12-11
Efficient and Effective Universal Adversarial Attack against Vision-Language Pre-training Models,"Fan Yang, Yihao Huang, Kailong Wang, Ling Shi, Geguang Pu, Yang Liu, Haoyu Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11639"" target=""_blank"">2410.11639</a>",,2024-12-11
Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation,"Shuai Zhao, Xiaobao Wu, Cong-Duy Nguyen, Meihuizi Jia, Yichao Feng, Luu Anh Tuan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14425"" target=""_blank"">2410.14425</a>",,2024-12-11
NSmark: Null Space Based Black-box Watermarking Defense Framework for Pre-trained Language Models,"Haodong Zhao, Jinming Hu, Peixuan Li, Fangqi Li, Jinrui Sha, Peixuan Chen, Zhuosheng Zhang, Gongshen Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13907"" target=""_blank"">2410.13907</a>","<a href=""https://github.com/dongdongzhaoUP/NSmark"" target=""_blank"">dongdongzhaoUP</a>",2024-12-11
Feint and Attack: Attention-Based Strategies for Jailbreaking and Protecting LLMs,"Rui Pu, Chaozhuo Li, Rui Ha, Zejian Chen, Litian Zhang, Zheng Liu, Lirong Qiu, Xi Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16327"" target=""_blank"">2410.16327</a>",,2024-12-11
A Hybrid Simulation of DNN-based Gray Box Models,"Aayushya Agarwal, Yihan Ruan, Larry Pileggi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17103"" target=""_blank"">2410.17103</a>",,2024-12-11
Vulnerabilities in Machine Learning-Based Voice Disorder Detection Systems,"Gianpaolo Perelli, Andrea Panzino, Roberto Casula, Marco Micheletto, Giulia OrrÃ¹, Gian Luca Marcialis",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16341"" target=""_blank"">2410.16341</a>",,2024-12-11
A Realistic Threat Model for Large Language Model Jailbreaks,"Valentyn Boreiko, Alexander Panfilov, Vaclav Voracek, Matthias Hein, Jonas Geiping",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16222"" target=""_blank"">2410.16222</a>",,2024-12-11
Metric as Transform: Exploring beyond Affine Transform for Interpretable Neural Network,Suman Sapkota,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16159"" target=""_blank"">2410.16159</a>",,2024-12-11
Dual-Model Defense: Safeguarding Diffusion Models from Membership Inference Attacks through Disjoint Data Splitting,"Bao Q. Tran, Viet Nguyen, Anh Tran, Toan Tran",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16657"" target=""_blank"">2410.16657</a>",,2024-12-11
Robust Feature Learning for Multi-Index Models in High Dimensions,"Alireza Mousavi-Hosseini, Adel Javanmard, Murat A. Erdogdu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16449"" target=""_blank"">2410.16449</a>",,2024-12-11
Conflict-Aware Adversarial Training,"Zhiyu Xue, Haohan Wang, Yao Qin, Ramtin Pedarsani",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16579"" target=""_blank"">2410.16579</a>",,2024-12-11
Invisible Manipulation Deep Reinforcement Learning Enhanced Stealthy Attacks on Battery Energy Management Systems,"Qi Xiao, Lidong Song, Jongha Woo, Rongxing Hu, Bei Xu, Ning Lu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17402"" target=""_blank"">2410.17402</a>",,2024-12-11
Boosting Jailbreak Transferability for Large Language Models,"Hanqing Liu, Lifeng Zhou, Huanqian Yan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15645"" target=""_blank"">2410.15645</a>",,2024-12-11
BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers,"Jiaqi Xue, Qian Lou, Mengxin Zheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17492"" target=""_blank"">2410.17492</a>",,2024-12-11
Hierarchical Multi-agent Reinforcement Learning for Cyber Network Defense,"Aditya Vikram Singh, Ethan Rathbun, Emma Graham, Lisa Oakley, Simona Boboila, Alina Oprea, Peter Chin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17351"" target=""_blank"">2410.17351</a>",,2024-12-11
Attack as Defense: Run-time Backdoor Implantation for Image Content Protection,"Haichuan Zhang, Meiyu Lin, Zhaoyi Liu, Renyuan Li, Zhiyuan Cheng, Carl Yang, Mingjie Tang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14966"" target=""_blank"">2410.14966</a>",,2024-12-11
Evaluating the Effectiveness of Attack-Agnostic Features for Morphing Attack Detection,"Laurent Colbois, SÃ©bastien Marcel",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16802"" target=""_blank"">2410.16802</a>",,2024-12-11
Context-aware Prompt Tuning: Advancing In-Context Learning with Adversarial Methods,"Tsachi Blau, Moshe Kimhi, Yonatan Belinkov, Alexander Bronstein, Chaim Baskin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17222"" target=""_blank"">2410.17222</a>",,2024-12-11
On the Vulnerability of Text Sanitization,"Meng Tong, Kejiang Chen, Xiaojian Yuang, Jiayang Liu, Weiming Zhang, Nenghai Yu, Jie Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17052"" target=""_blank"">2410.17052</a>","<a href=""https://github.com/mengtong0110/On-the-Vulnerability-of-Text-Sanitization"" target=""_blank"">mengtong0110</a>",2024-12-11
On the Geometry of Regularization in Adversarial Training: High-Dimensional Asymptotics and Generalization Bounds,"Matteo Vilucchio, Nikolaos Tsilivis, Bruno Loureiro, Julia Kempe",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16073"" target=""_blank"">2410.16073</a>",,2024-12-11
Model Mimic Attack: Knowledge Distillation for Provably Transferable Adversarial Examples,"Kirill Lukyanov, Andrew Perminov, Denis Turdakov, Mikhail Pautov",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15889"" target=""_blank"">2410.15889</a>",,2024-12-11
Extracting Spatiotemporal Data from Gradients with Large Language Models,"Lele Zheng, Yang Cao, Renhe Jiang, Kenjiro Taura, Yulong Shen, Sheng Li, Masatoshi Yoshikawa",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16121"" target=""_blank"">2410.16121</a>",,2024-12-11
Adversarial Training: A Survey,"Mengnan Zhao, Lihe Zhang, Jingwen Ye, Huchuan Lu, Baocai Yin, Xinchao Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15042"" target=""_blank"">2410.15042</a>",,2024-12-11
Class-RAG: Content Moderation with Retrieval Augmented Generation,"Jianfa Chen, Emily Shen, Trupti Bavalatti, Xiaowen Lin, Yongkai Wang, Shuming Hu, Harihar Subramanyam, Ksheeraj Sai Vepuri, Ming Jiang, Ji Qi, Li Chen, Nan Jiang, Ankit Jain",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14881"" target=""_blank"">2410.14881</a>",,2024-12-11
A Hybrid Defense Strategy for Boosting Adversarial Robustness in Vision-Language Models,"Yuhan Liang, Yijun Li, Yumeng Niu, Qianhe Shen, Hangyu Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14911"" target=""_blank"">2410.14911</a>",,2024-12-11
DynaMO: Protecting Mobile DL Models through Coupling Obfuscated DL Operators,"Mingyi Zhou, Xiang Gao, Xiao Chen, Chunyang Chen, John Grundy, Li Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15033"" target=""_blank"">2410.15033</a>",,2024-12-11
SLIC: Secure Learned Image Codec through Compressed Domain Watermarking to Defend Image Manipulation,"Chen-Hsiu Huang, Ja-Ling Wu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15075"" target=""_blank"">2410.15075</a>",,2024-12-11
Beyond Pruning Criteria: The Dominant Role of Fine-Tuning and Adaptive Ratios in Neural Network Robustness,"Lincen Bai, Hedi Tabia, RaÃºl Santos-RodrÃ­guez",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15176"" target=""_blank"">2410.15176</a>",,2024-12-11
Toward Robust RALMs: Revealing the Impact of Imperfect Retrieval on Retrieval-Augmented Language Models,"Seong-Il Park, Jay-Yoon Lee",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15107"" target=""_blank"">2410.15107</a>",,2024-12-11
Jailbreaking and Mitigation of Vulnerabilities in Large Language Models,"Benji Peng, Ziqian Bi, Qian Niu, Ming Liu, Pohsun Feng, Tianyang Wang, Lawrence K. Q. Yan, Yizhu Wen, Yichao Zhang, Caitlyn Heqi Yin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15236"" target=""_blank"">2410.15236</a>",,2024-12-11
Bayesian Concept Bottleneck Models with LLM Priors,"Jean Feng, Avni Kothari, Luke Zier, Chandan Singh, Yan Shuo Tan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15555"" target=""_blank"">2410.15555</a>",,2024-12-11
Faster-GCG: Efficient Discrete Optimization Jailbreak Attacks against Aligned Large Language Models,"Xiao Li, Zhuhong Li, Qiongxiu Li, Bingze Lee, Jinghao Cui, Xiaolin Hu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15362"" target=""_blank"">2410.15362</a>",,2024-12-11
The Best Defense is a Good Offense: Countering LLM-Powered Cyberattacks,"Daniel Ayzenshteyn, Roy Weiss, Yisroel Mirsky",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15396"" target=""_blank"">2410.15396</a>",,2024-12-11
PEAS: A Strategy for Crafting Transferable Adversarial Examples,"Bar Avraham, Yisroel Mirsky",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15409"" target=""_blank"">2410.15409</a>",,2024-12-11
Efficient Model Extraction via Boundary Sampling,"Maor Biton Dor, Yisroel Mirsky",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15429"" target=""_blank"">2410.15429</a>",,2024-12-11
D-CAPTCHA++: A Study of Resilience of Deepfake CAPTCHA under Transferable Imperceptible Adversarial Attack,"Hong-Hanh Nguyen-Le, Van-Tuan Tran, Dinh-Thuc Nguyen, Nhien-An Le-Khac",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07390"" target=""_blank"">2409.07390</a>",,2024-12-11
Adversarial Attacks to Multi-Modal Models,"Zhihao Dou, Xin Hu, Haibo Yang, Zhuqing Liu, Minghong Fang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.06793"" target=""_blank"">2409.06793</a>",,2024-12-11
Attack End-to-End Autonomous Driving through Module-Wise Noise,"Lu Wang, Tianyuan Zhang, Yikai Han, Muyang Fang, Ting Jin, Jiaqi Kang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07706"" target=""_blank"">2409.07706</a>",,2024-12-11
On the Vulnerability of Applying Retrieval-Augmented Generation within Knowledge-Intensive Application Domains,"Xun Xian, Ganghua Wang, Xuan Bi, Jayanth Srinivasa, Ashish Kundu, Charles Fleming, Mingyi Hong, Jie Ding",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17275"" target=""_blank"">2409.17275</a>",,2024-12-11
Enhancing adversarial robustness in Natural Language Inference using explanations,"Alexandros Koulakos, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07423"" target=""_blank"">2409.07423</a>",,2024-12-11
AdvLogo: Adversarial Patch Attack against Object Detectors based on Diffusion Models,"Boming Miao, Chunxiao Li, Yao Zhu, Weixiang Sun, Zizhe Wang, Xiaoyi Wang, Chuanlong Xie",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07002"" target=""_blank"">2409.07002</a>",,2024-12-11
Understanding Knowledge Drift in LLMs through Misinformation,"Alina Fastowski, Gjergji Kasneci",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07085"" target=""_blank"">2409.07085</a>","<a href=""https://github.com/afastowski/knowledge_drift"" target=""_blank"">afastowski</a>",2024-12-11
Natias: Neuron Attribution based Transferable Image Adversarial Steganography,"Zexin Fan, Kejiang Chen, Kai Zeng, Jiansong Zhang, Weiming Zhang, Nenghai Yu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04968"" target=""_blank"">2409.04968</a>",,2024-12-11
Unrevealed Threats: A Comprehensive Study of the Adversarial Robustness of Underwater Image Enhancement Models,"Siyu Zhai, Zhibo He, Xiaofeng Cong, Junming Hou, Jie Gui, Jian Wei You, Xin Gong, James Tin-Yau Kwok, Yuan Yan Tang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.06420"" target=""_blank"">2409.06420</a>",,2024-12-11
Advancing Hybrid Defense for Byzantine Attacks in Federated Learning,"Kai Yue, Richeng Jin, Chau-Wai Wong, Huaiyu Dai",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.06474"" target=""_blank"">2409.06474</a>",,2024-12-11
Seeing Through the Mask: Rethinking Adversarial Examples for CAPTCHAs,"Yahya Jabary, Andreas Plesner, Turlan Kuzhagaliyev, Roger Wattenhofer",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.05558"" target=""_blank"">2409.05558</a>",,2024-12-11
DV-FSR: A Dual-View Target Attack Framework for Federated Sequential Recommendation,"Qitao Qin, Yucong Luo, Mingyue Cheng, Qingyang Mao, Chenyi Lei",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07500"" target=""_blank"">2409.07500</a>",,2024-12-11
Vision-fused Attack: Advancing Aggressive and Stealthy Adversarial Text against Neural Machine Translation,"Yanni Xue, Haojie Hao, Jiakai Wang, Qiang Sheng, Renshuai Tao, Yu Liang, Pu Feng, Xianglong Liu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.05021"" target=""_blank"">2409.05021</a>",,2024-12-11
PIXHELL Attack: Leaking Sensitive Information from Air-Gap Computers via `Singing Pixels',Mordechai Guri,arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04930"" target=""_blank"">2409.04930</a>",,2024-12-11
Adversarial Attacks on Data Attribution,"Xinhe Wang, Pingbang Hu, Junwei Deng, Jiaqi W. Ma",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.05657"" target=""_blank"">2409.05657</a>",,2024-12-11
Input Space Mode Connectivity in Deep Neural Networks,"Jakub Vrabel, Ori Shem-Ur, Yaron Oz, David Krueger",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.05800"" target=""_blank"">2409.05800</a>",,2024-12-11
Phrase-Level Adversarial Training for Mitigating Bias in Neural Network-based Automatic Essay Scoring,"Haddad Philip, Tsegaye Misikir Tashu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04795"" target=""_blank"">2409.04795</a>",,2024-12-11
Unlearning or Concealment? A Critical Analysis and Evaluation Metrics for Unlearning in Diffusion Models,"Aakash Sen Sharma, Niladri Sarkar, Vikram Chundawat, Ankur A Mali, Murari Mandal",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.05668"" target=""_blank"">2409.05668</a>","<a href=""https://respailab.github.io/unlearning-or-concealment"" target=""_blank"">respailab.github.io</a>",2024-12-11
On the Weaknesses of Backdoor-based Model Watermarking: An Information-theoretic Perspective,"Aoting Hu, Yanzhi Chen, Renjie Xie, Adrian Weller",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.06130"" target=""_blank"">2409.06130</a>",,2024-12-11
PIP: Detecting Adversarial Examples in Large Vision-Language Models via Attention Patterns of Irrelevant Probe Questions,"Yudong Zhang, Ruobing Xie, Jiansheng Chen, Xingwu Sun, Yu Wang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.05076"" target=""_blank"">2409.05076</a>","<a href=""https://github.com/btzyd/pip"" target=""_blank"">btzyd</a>",2024-12-11
2DSig-Detect: a semi-supervised framework for anomaly detection on image data using 2D-signatures,"Xinheng Xie, Kureha Yamaguchi, Margaux Leblanc, Simon Malzard, Varun Chhabra, Victoria Nockles, Yue Wu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04982"" target=""_blank"">2409.04982</a>",,2024-12-11
A Cost-Aware Approach to Adversarial Robustness in Neural Networks,"Charles Meyers, Mohammad Reza Saleh Sedghpour, Tommy LÃ¶fstedt, Erik Elmroth",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07609"" target=""_blank"">2409.07609</a>",,2024-12-11
Are Existing Road Design Guidelines Suitable for Autonomous Vehicles? (41%),"Yang Sun, Christopher M. Poskitt, Jun Sun",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.10562"" target=""_blank"">2409.10562</a>",,2024-12-11
Introducing Perturb-ability Score (PS) to Enhance Robustness Against Evasion Adversarial Attacks on ML-NIDS,"Mohamed elShehaby, Ashraf Matrawy",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07448"" target=""_blank"">2409.07448</a>",,2024-12-11
Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks,"Md Zarif Hossain, Ahmed Imteaj",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07353"" target=""_blank"">2409.07353</a>","<a href=""https://github.com/speedlab-git/Robust-Encoder-against-Jailbreak-attack"" target=""_blank"">speedlab-git</a>",2024-12-11
Hard-Label Cryptanalytic Extraction of Neural Network Models,"Yi Chen, Xiaoyang Dong, Jian Guo, Yantian Shen, Anyu Wang, Xiaoyun Wang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.11646"" target=""_blank"">2409.11646</a>",,2024-12-11
Towards Physically-Realizable Adversarial Attacks in Embodied Vision Navigation,"Meng Chen, Jiawei Tu, Chao Qi, Yonghao Dang, Feng Zhou, Wei Wei, Jianqin Yin",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.10071"" target=""_blank"">2409.10071</a>","<a href=""https://github.com/chen37058/Physical-Attacks-in-Embodied-Navigation]"" target=""_blank"">chen37058</a>",2024-12-11
Learning to Learn Transferable Generative Attack for Person Re-Identification,"Yuan Bian, Min Liu, Xueping Wang, Yunfeng Ma, Yaonan Wang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04208"" target=""_blank"">2409.04208</a>",,2024-12-11
CaBaGe: Data-Free Model Extraction using ClAss BAlanced Generator Ensemble,"Jonathan Rosenthal, Shanchao Liang, Kevin Zhang, Lin Tan",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.10643"" target=""_blank"">2409.10643</a>",,2024-12-11
Realistic Extreme Behavior Generation for Improved AV Testing,"Robert Dyro, Matthew Foutter, Ruolin Li, Lillo Luigi Di, Edward Schmerling, Xilin Zhou, Marco Pavone",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.10669"" target=""_blank"">2409.10669</a>",,2024-12-11
Jailbreaking Large Language Models with Symbolic Mathematics,"Emet Bethany, Mazal Bethany, Juan Arturo Nolazco Flores, Sumit Kumar Jha, Peyman Najafirad",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.11445"" target=""_blank"">2409.11445</a>",,2024-12-11
Speaker Contrastive Learning for Source Speaker Tracing,"Qing Wang, Hongmei Guo, Jian Kang, Mengjie Du, Jie Li, Xiao-Lei Zhang, Lei Xie",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.10072"" target=""_blank"">2409.10072</a>",,2024-12-11
Revisiting Physical-World Adversarial Attack on Traffic Sign Recognition: A Commercial Systems Perspective,"Ningfei Wang, Shaoyuan Xie, Takami Sato, Yunpeng Luo, Kaidi Xu, Qi Alfred Chen",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.09860"" target=""_blank"">2409.09860</a>",,2024-12-11
Federated Learning in Adversarial Environments: Testbed Design and Poisoning Resilience in Cybersecurity,"Hao Jian Huang, Bekzod Iskandarov, Mizanur Rahman, Hakan T. Otal, M. Abdullah Canbaz",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.09794"" target=""_blank"">2409.09794</a>",,2024-12-11
Real-world Adversarial Defense against Patch Attacks based on Diffusion Model,"Xingxing Wei, Caixin Kang, Yinpeng Dong, Zhengyi Wang, Shouwei Ruan, Yubo Chen, Hang Su",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.09406"" target=""_blank"">2409.09406</a>",,2024-12-11
XSub: Explanation-Driven Adversarial Attack against Blackbox Classifiers via Feature Substitution,"Kiana Vu, Phung Lai, Truc Nguyen",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08919"" target=""_blank"">2409.08919</a>",,2024-12-11
Clean Label Attacks against SLU Systems,"Henry Li Xinyuan, Sonal Joshi, Thomas Thebaud, Jesus Villalba, Najim Dehak, Sanjeev Khudanpur",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08985"" target=""_blank"">2409.08985</a>",,2024-12-11
FAST: Boosting Uncertainty-based Test Prioritization Methods for Neural Networks via Feature Selection,"Jialuo Chen, Jingyi Wang, Xiyue Zhang, Youcheng Sun, Marta Kwiatkowska, Jiming Chen, Peng Cheng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.09130"" target=""_blank"">2409.09130</a>",,2024-12-11
LoRID: Low-Rank Iterative Diffusion for Adversarial Purification,"Geigh Zollicoffer, Minh Vu, Ben Nebgen, Juan Castorena, Boian Alexandrov, Manish Bhattarai",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08255"" target=""_blank"">2409.08255</a>",,2024-12-11
High-Frequency Anti-DreamBooth: Robust Defense against Personalized Image Synthesis,"Takuto Onikubo, Yusuke Matsui",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08167"" target=""_blank"">2409.08167</a>",,2024-12-11
FedProphet: Memory-Efficient Federated Adversarial Training via Theoretic-Robustness and Low-Inconsistency Cascade Learning,"Minxue Tang, Yitu Wang, Jingyang Zhang, Louis DiValentin, Aolin Ding, Amin Hass, Yiran Chen, Hai ""Helen"" Li",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08372"" target=""_blank"">2409.08372</a>",,2024-12-11
Exploiting Supervised Poison Vulnerability to Strengthen Self-Supervised Defense,"Jeremy Styborski, Mingzhi Lyu, Yi Huang, Adams Kong",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08509"" target=""_blank"">2409.08509</a>",,2024-12-11
Sub-graph Based Diffusion Model for Link Prediction,"Hang Li, Wei Jin, Geri Skenderi, Harry Shomer, Wenzhuo Tang, Wenqi Fan, Jiliang Tang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08487"" target=""_blank"">2409.08487</a>",,2024-12-11
Unleashing Worms and Extracting Data: Escalating the Outcome of Attacks against RAG-based Inference in Scale and Severity Using Jailbreaking,"Stav Cohen, Ron Bitton, Ben Nassi",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08045"" target=""_blank"">2409.08045</a>",,2024-12-11
Risks When Sharing LoRA Fine-Tuned Diffusion Model Weights,Dixi Yao,arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08482"" target=""_blank"">2409.08482</a>",,2024-12-11
Module-wise Adaptive Adversarial Training for End-to-end Autonomous Driving,"Tianyuan Zhang, Lu Wang, Jiaqi Kang, Xinwei Zhang, Siyuan Liang, Yuwei Chen, Aishan Liu, Xianglong Liu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07321"" target=""_blank"">2409.07321</a>",,2024-12-11
"Top-GAP: Integrating Size Priors in CNNs for more Interpretability, Robustness, and Bias Mitigation","Lars Nieradzik, Henrike Stephani, Janis Keuper",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04819"" target=""_blank"">2409.04819</a>",,2024-12-11
Purification-Agnostic Proxy Learning for Agentic Copyright Watermarking against Adversarial Evidence Forgery,"Erjin Bao, Ching-Chun Chang, Hanrui Wang, Isao Echizen",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01541"" target=""_blank"">2409.01541</a>",,2024-12-11
PANTS: Practical Adversarial Network Traffic Samples against ML-powered Networking Classifiers,"Minhao Jin, Maria Apostolaki",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04691"" target=""_blank"">2409.04691</a>",,2024-12-11
On the Vulnerability of Skip Connections to Model Inversion Attacks,"Jun Hao Koh, Sy-Tuyen Ho, Ngoc-Bao Nguyen, Ngai-man Cheung",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01696"" target=""_blank"">2409.01696</a>","<a href=""https://Pillowkoh.github.io/projects/RoLSS/"" target=""_blank"">RoLSS</a>",2024-12-11
Adversarial Pruning: A Survey and Benchmark of Pruning Methods for Adversarial Robustness,"Giorgio Piras, Maura Pintor, Ambra Demontis, Battista Biggio, Giorgio Giacinto, Fabio Roli",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01249"" target=""_blank"">2409.01249</a>","<a href=""https://github.com/pralab/AdversarialPruningBenchmark"" target=""_blank"">pralab</a>",2024-12-11
Phantom: Untargeted Poisoning Attacks on Semi-Supervised Learning (Full Version),"Jonathan Knauer, Phillip Rieger, Hossein Fereidooni, Ahmad-Reza Sadeghi",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01470"" target=""_blank"">2409.01470</a>",,2024-12-11
Defending against Model Inversion Attacks via Random Erasing,"Viet-Hung Tran, Ngoc-Bao Nguyen, Son T. Mai, Hans Vandierendonck, Ngai-man Cheung",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01062"" target=""_blank"">2409.01062</a>",,2024-12-11
CLIBE: Detecting Dynamic Backdoors in Transformer-based NLP Models,"Rui Zeng, Xi Chen, Yuwen Pu, Xuhong Zhang, Tianyu Du, Shouling Ji",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01193"" target=""_blank"">2409.01193</a>",,2024-12-11
Unveiling the Vulnerability of Private Fine-Tuning in Split-Based Frameworks for Large Language Models: A Bidirectionally Enhanced Attack,"Guanzhong Chen, Zhenghan Qin, Mingxin Yang, Yajie Zhou, Tao Fan, Tianyu Du, Zenglin Xu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00960"" target=""_blank"">2409.00960</a>",,2024-12-11
A Review of Image Retrieval Techniques: Data Augmentation and Adversarial Learning Approaches,Kim Jinwoo,arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01219"" target=""_blank"">2409.01219</a>",,2024-12-11
Spatial-Aware Conformal Prediction for Trustworthy Hyperspectral Image Classification,"Kangdao Liu, Tianhao Sun, Hao Zeng, Yongshan Zhang, Chi-Man Pun, Chi-Man Vong",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01236"" target=""_blank"">2409.01236</a>","<a href=""https://github.com/J4ckLiu/SACP"" target=""_blank"">J4ckLiu</a>",2024-12-11
"Comprehensive Botnet Detection by Mitigating Adversarial Attacks, Navigating the Subtleties of Perturbation Distances and Fortifying Predictions with Conformal Layers","Rahul Yumlembam, Biju Issac, Seibu Mary Jacob, Longzhi Yang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00667"" target=""_blank"">2409.00667</a>",,2024-12-11
Accurate Forgetting for All-in-One Image Restoration Model,"Xin Su, Zhuoran Zheng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00685"" target=""_blank"">2409.00685</a>",,2024-12-11
The Dark Side of Human Feedback: Poisoning Large Language Models via User Inputs,"Bocheng Chen, Hanqing Guo, Guangjing Wang, Yuanda Wang, Qiben Yan",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00787"" target=""_blank"">2409.00787</a>",,2024-12-11
Fisher Information guided Purification against Backdoor Attacks,"Nazmul Karim, Abdullah Al Arafat, Adnan Siraj Rakin, Zhishan Guo, Nazanin Rahnavard",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00863"" target=""_blank"">2409.00863</a>",,2024-12-11
HSF: Defending against Jailbreak Attacks with Hidden State Filtering,"Cheng Qian, Hainan Zhang, Lei Sha, Zhiming Zheng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03788"" target=""_blank"">2409.03788</a>",,2024-12-11
Is Difficulty Calibration All We Need? Towards More Practical Membership Inference Attacks,"Yu He, Boheng Li, Yao Wang, Mengda Yang, Juan Wang, Hongxin Hu, Xingyu Zhao",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00426"" target=""_blank"">2409.00426</a>",,2024-12-11
Robust off-policy Reinforcement Learning via Soft Constrained Adversary,"Kosuke Nakanishi, Akihiro Kubo, Yuji Yasui, Shin Ishii",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00418"" target=""_blank"">2409.00418</a>",,2024-12-11
LightPure: Realtime Adversarial Image Purification for Mobile Devices Using Diffusion Models,"Hossein Khalili, Seongbin Park, Vincent Li, Brandan Bright, Ali Payani, Ramana Rao Kompella, Nader Sehatbakhsh",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00340"" target=""_blank"">2409.00340</a>",,2024-12-11
PRADA: Proactive Risk Assessment and Mitigation of Misinformed Demand Attacks on Navigational Route Recommendations,"Ya-Ting Yang, Haozhe Lei, Quanyan Zhu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00243"" target=""_blank"">2409.00243</a>",,2024-12-11
Feedback-based Modal Mutual Search for Attacking Vision-Language Pre-training Models,"Renhua Ding, Xinze Zhang, Xiao Yang, Kun He",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.06726"" target=""_blank"">2409.06726</a>",,2024-12-11
Dual Adversarial Perturbators Generate rich Views for Recommendation,"Lijun Zhang, Yuan Yao, Haibo Ye",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.06719"" target=""_blank"">2409.06719</a>",,2024-12-11
Cognitive Networks and Performance Drive fMRI-Based State Classification Using DNN Models,"Murat Kucukosmanoglu, Javier O. Garcia, Justin Brooks, Kanika Bansal",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00003"" target=""_blank"">2409.00003</a>",,2024-12-11
Attack Anything: Blind DNNs via Universal Background Adversarial Attack,"Jiawei Lian, Shaohui Mei, Xiaofei Wang, Yi Wang, Lefan Wang, Yingjie Lu, Mingyang Ma, Lap-Pui Chau",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00029"" target=""_blank"">2409.00029</a>","<a href=""https://github.com/JiaweiLian/Attack_Anything"" target=""_blank"">JiaweiLian</a>",2024-12-11
EIA: Environmental Injection Attack on Generalist Web Agents for Privacy Leakage,"Zeyi Liao, Lingbo Mo, Chejian Xu, Mintong Kang, Jiawei Zhang, Chaowei Xiao, Yuan Tian, Bo Li, Huan Sun",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.11295"" target=""_blank"">2409.11295</a>",,2024-12-11
One-Index Vector Quantization Based Adversarial Attack on Image Classification,"Haiju Fan, Xiaona Qin, Shuang Chen, Hubert P. H. Shum, Ming Li",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01282"" target=""_blank"">2409.01282</a>",,2024-12-11
Reassessing Noise Augmentation Methods in the Context of Adversarial Speech,"Karla Pizzi, MatÃ­as Pizarro, Asja Fischer",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01813"" target=""_blank"">2409.01813</a>",,2024-12-11
Secure Traffic Sign Recognition: An Attention-Enabled Universal Image Inpainting Mechanism against Light Patch Attacks,"Hangcheng Cao, Longzhi Yuan, Guowen Xu, Ziyang He, Zhengru Fang, Yuguang Fang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04133"" target=""_blank"">2409.04133</a>",,2024-12-11
NoiseAttack: An Evasive Sample-Specific Multi-Targeted Backdoor Attack Through White Gaussian Noise,"Abdullah Arafat Miah, Kaan Icer, Resit Sendag, Yu Bi",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02251"" target=""_blank"">2409.02251</a>","<a href=""https://github.com/SiSL-URI/NoiseAttack/tree/main"" target=""_blank"">tree</a>",2024-12-11
Mind The Gap: Can Air-Gaps Keep Your Private Data Secure? (74%),Mordechai Guri,arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04190"" target=""_blank"">2409.04190</a>",,2024-12-11
Exploiting the Data Gap: Utilizing Non-ignorable Missingness to Manipulate Model Learning,"Deniz Koyuncu, Alex Gittens, BÃ¼lent Yener, Moti Yung",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04407"" target=""_blank"">2409.04407</a>",,2024-12-11
Context is the Key: Backdoor Attacks for In-Context Learning with Vision Transformers,"Gorka Abad, Stjepan Picek, Lorenzo Cavallaro, Aitor Urbieta",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04142"" target=""_blank"">2409.04142</a>",,2024-12-11
Dual-stream Feature Augmentation for Domain Generalization,"Shanshan Wang, ALuSi, Xun Yang, Ke Xu, Huibin Tan, Xingyi Zhang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04699"" target=""_blank"">2409.04699</a>","<a href=""https://github.com/alusi123/DFA"" target=""_blank"">alusi123</a>",2024-12-11
A practical approach to evaluating the adversarial distance for machine learning classifiers,"Georg Siedel, Ekagra Gupta, Andrey Morozov",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03598"" target=""_blank"">2409.03598</a>",,2024-12-11
Non-Uniform Illumination Attack for Fooling Convolutional Neural Networks,"Akshay Jain, Shiv Ram Dubey, Satish Kumar Singh, KC Santosh, Bidyut Baran Chaudhuri",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03458"" target=""_blank"">2409.03458</a>",,2024-12-11
Limited but consistent gains in adversarial robustness by co-training object recognition models with human EEG,"Manshan Guo, Bhavin Choksi, Sari Sadiya, Alessandro T. Gifford, Martina G. Vilas, Radoslaw M. Cichy, Gemma Roig",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03646"" target=""_blank"">2409.03646</a>",,2024-12-11
Recent Advances in Attack and Defense Approaches of Large Language Models,"Jing Cui, Yishi Xu, Zhewei Huang, Shuchang Zhou, Jianbin Jiao, Junge Zhang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03274"" target=""_blank"">2409.03274</a>",,2024-12-11
WaterMAS: Sharpness-Aware Maximization for Neural Network Watermarking,"Carl De Sousa Trias, Mihai Mitrea, Attilio Fiandrotti, Marco Cagnazzo, Sumanta Chaudhuri, Enzo Tartaglione",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03902"" target=""_blank"">2409.03902</a>",,2024-12-11
Understanding Data Importance in Machine Learning Attacks: Does Valuable Data Pose Greater Harm? (1%),"Rui Wen, Michael Backes, Yang Zhang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03741"" target=""_blank"">2409.03741</a>",,2024-12-11
Bypassing DARCY Defense: Indistinguishable Universal Adversarial Triggers,"Zuquan Peng, Yuanyuan He, Jianbing Ni, Ben Niu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03183"" target=""_blank"">2409.03183</a>",,2024-12-11
OpenFact at CheckThat! 2024: Combining Multiple Attack Methods for Effective Adversarial Text Generation,"WÅodzimierz Lewoniewski, Piotr Stolarski, Milena StrÃ³Å¼yna, Elzbieta LewaÅska, Aleksandra Wojewoda, Ewelina KsiÄÅ¼niak, Marcin SawiÅski",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02649"" target=""_blank"">2409.02649</a>",,2024-12-11
TASAR: Transferable Attack on Skeletal Action Recognition,"Yunfeng Diao, Baiqi Wu, Ruixuan Zhang, Ajian Liu, Xingxing Wei, Meng Wang, He Wang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02483"" target=""_blank"">2409.02483</a>",,2024-12-11
Adversarial Attacks on Machine Learning-Aided Visualizations,"Takanori Fujiwara, Kostiantyn Kucher, Junpeng Wang, Rafael M. Martins, Andreas Kerren, Anders Ynnerman",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02485"" target=""_blank"">2409.02485</a>",,2024-12-11
Transfer-based Adversarial Poisoning Attacks for Online (MIMO-)Deep Receviers,"Kunze Wu, Weiheng Jiang, Dusit Niyato, Yinghuan Li, Chuang Luo",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02430"" target=""_blank"">2409.02430</a>",,2024-12-11
Boosting Certificate Robustness for Time Series Classification with Efficient Self-Ensemble,"Chang Dong, Zhengyang Li, Liangwei Zheng, Weitong Chen, Wei Emma Zhang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02802"" target=""_blank"">2409.02802</a>",,2024-12-11
AdvSecureNet: A Python Toolkit for Adversarial Machine Learning,"Melih Catal, Manuel GÃ¼nther",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02629"" target=""_blank"">2409.02629</a>",,2024-12-11
Active Fake: DeepFake Camouflage,"Pu Sun, Honggang Qi, Yuezun Li",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03200"" target=""_blank"">2409.03200</a>",,2024-12-11
"Well, that escalated quickly: The Single-Turn Crescendo Attack (STCA)",Alan Aqrawi,arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03131"" target=""_blank"">2409.03131</a>",,2024-12-11
Exploiting the Vulnerability of Large Language Models via Defense-Aware Architectural Backdoor,"Abdullah Arafat Miah, Yu Bi",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01952"" target=""_blank"">2409.01952</a>","<a href=""https://github.com/SiSL-URI/Arch_Backdoor_LLM"" target=""_blank"">SiSL-URI</a>",2024-12-11
Dynamic Guidance Adversarial Distillation with Enhanced Teacher Knowledge,"Hyejin Park, Dongbo Min",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01627"" target=""_blank"">2409.01627</a>",,2024-12-11
Contextual Breach: Assessing the Robustness of Transformer-based QA Models,"Asir Saadat, Nahian Ibn Asad, Md Farhan Ishmam",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.10997"" target=""_blank"">2409.10997</a>",,2024-12-11
On the Feasibility of Fully AI-automated Vishing Attacks,"JoÃ£o Figueiredo, Afonso Carvalho, Daniel Castro, Daniel GonÃ§alves, Nuno Santos",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13793"" target=""_blank"">2409.13793</a>",,2024-12-11
Golden Ratio Search: A Low-Power Adversarial Attack for Deep Learning based Modulation Classification,"Deepsayan Sadhukhan, Nitin Priyadarshini Shankar, Sheetal Kalyani",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.11454"" target=""_blank"">2409.11454</a>",,2024-12-11
Adversarial Watermarking for Face Recognition,"Yuguang Yao, Anil Jain, Sijia Liu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.16056"" target=""_blank"">2409.16056</a>",,2024-12-11
Improving Fast Adversarial Training via Self-Knowledge Guidance,"Chengze Jiang, Junkai Wang, Minjing Dong, Jie Gui, Xinli Shi, Yuan Cao, Yuan Yan Tang, James Tin-Yau Kwok",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17589"" target=""_blank"">2409.17589</a>",,2024-12-11
Faithfulness and the Notion of Adversarial Sensitivity in NLP Explanations,"Supriya Manna, Niladri Sett",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17774"" target=""_blank"">2409.17774</a>",,2024-12-11
TA-Cleaner: A Fine-grained Text Alignment Backdoor Defense Strategy for Multimodal Contrastive Learning,"Yuan Xun, Siyuan Liang, Xiaojun Jia, Xinwei Liu, Xiaochun Cao",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17601"" target=""_blank"">2409.17601</a>",,2024-12-11
DarkSAM: Fooling Segment Anything Model to Segment Nothing,"Ziqi Zhou, Yufei Song, Minghui Li, Shengshan Hu, Xianlong Wang, Leo Yu Zhang, Dezhong Yao, Hai Jin",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17874"" target=""_blank"">2409.17874</a>",,2024-12-11
"Perturb, Attend, Detect and Localize (PADL): Robust Proactive Image Defense","Filippo Bartolucci, Iacopo Masi, Giuseppe Lisanti",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17941"" target=""_blank"">2409.17941</a>",,2024-12-11
Development of an Edge Resilient ML Ensemble to Tolerate ICS Adversarial Attacks,"Likai Yao, Qinxuan Shi, Zhanglong Yang, Sicong Shao, Salim Hariri",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18244"" target=""_blank"">2409.18244</a>",,2024-12-11
Backdoor Attacks for LLMs with Weak-To-Strong Knowledge Distillation,"Shuai Zhao, Leilei Gan, Zhongliang Guo, Xiaobao Wu, Luwei Xiao, Xiaoyu Xu, Cong-Duy Nguyen, Luu Anh Tuan",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17946"" target=""_blank"">2409.17946</a>",,2024-12-11
Harmful Fine-tuning Attacks and Defenses for Large Language Models: A Survey,"Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim Furkan Tekin, Ling Liu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18169"" target=""_blank"">2409.18169</a>","<a href=""https://github.com/git-disl/awesome_LLM-harmful-fine-tuning-papers"" target=""_blank"">git-disl</a>",2024-12-11
Dark Miner: Defend against unsafe generation for text-to-image diffusion models,"Zheling Meng, Bo Peng, Xiaochuan Jin, Yue Jiang, Jing Dong, Wei Wang, Tieniu Tan",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17682"" target=""_blank"">2409.17682</a>",,2024-12-11
An Adversarial Perspective on Machine Unlearning for AI Safety,"Jakub Åucki, Boyi Wei, Yangsibo Huang, Peter Henderson, Florian TramÃ¨r, Javier Rando",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18025"" target=""_blank"">2409.18025</a>",,2024-12-11
Revolutionizing Payload Inspection: A Self-Supervised Journey to Precision with Few Shots,"Kyle Stein, Arash Mahyari, Guillermo III Francia, Eman El-Sheikh",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18219"" target=""_blank"">2409.18219</a>",,2024-12-11
Improving the Shortest Plank: Vulnerability-Aware Adversarial Training for Robust Recommender System,"Kaike Zhang, Qi Cao, Yunfan Wu, Fei Sun, Huawei Shen, Xueqi Cheng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17476"" target=""_blank"">2409.17476</a>",,2024-12-11
A Hybrid Quantum-Classical AI-Based Detection Strategy for Generative Adversarial Network-Based Deepfake Attacks on an Autonomous Vehicle Traffic Sign Classification System,"M Sabbir Salek, Shaozhi Li, Mashrur Chowdhury",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17311"" target=""_blank"">2409.17311</a>",,2024-12-11
RED QUEEN: Safeguarding Large Language Models against Concealed Multi-Turn Jailbreaking,"Yifan Jiang, Kriti Aggarwal, Tanmay Laud, Kashif Munir, Jay Pujara, Subhabrata Mukherjee",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17458"" target=""_blank"">2409.17458</a>","<a href=""https://github.com/kriti-hippo/red_queen"" target=""_blank"">kriti-hippo</a>",2024-12-11
Transient Adversarial 3D Projection Attacks on Object Detection in Autonomous Driving,"Ce Zhou, Qiben Yan, Sijia Liu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17403"" target=""_blank"">2409.17403</a>",,2024-12-11
Examining the Rat in the Tunnel: Interpretable Multi-Label Classification of Tor-based Malware,"Ishan Karunanayake, Mashael AlSabah, Nadeem Ahmed, Sanjay Jha",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.16639"" target=""_blank"">2409.16639</a>",,2024-12-11
SWE2: SubWord Enriched and Significant Word Emphasized Framework for Hate Speech Detection,"Guanyi Mou, Pengyi Ye, Kyumin Lee",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.16673"" target=""_blank"">2409.16673</a>",,2024-12-11
SHEATH: Defending Horizontal Collaboration for Distributed CNNs against Adversarial Noise,"Muneeba Asif, Mohammad Kumail Kazmi, Mohammad Ashiqur Rahman, Syed Rafay Hasan, Soamar Homsi",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17279"" target=""_blank"">2409.17279</a>",,2024-12-11
Claim-Guided Textual Backdoor Attack for Practical Applications,"Minkyoo Song, Hanna Kim, Jaehan Kim, Youngjin Jin, Seungwon Shin",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.16618"" target=""_blank"">2409.16618</a>","<a href=""https://github.com/PaperCGBA/CGBA"" target=""_blank"">PaperCGBA</a>",2024-12-11
Cat-and-Mouse Satellite Dynamics: Divergent Adversarial Reinforcement Learning for Contested Multi-Agent Space Operations,"Cameron Mehlman, Joseph Abramov, Gregory Falco",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17443"" target=""_blank"">2409.17443</a>",,2024-12-11
Adversarial Backdoor Defense in CLIP,"Junhao Kuang, Siyuan Liang, Jiawei Liang, Kuanrong Liu, Xiaochun Cao",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15968"" target=""_blank"">2409.15968</a>",,2024-12-11
Cross-Modality Attack Boosted by Gradient-Evolutionary Multiform Optimization,"Yunpeng Gong, Qingyuan Zeng, Dejun Xu, Zhenzhong Wang, Min Jiang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17977"" target=""_blank"">2409.17977</a>",,2024-12-11
Showing Many Labels in Multi-label Classification Models: An Empirical Study of Adversarial Examples,"Yujiang Liu, Wenjian Luo, Zhijian Chen, Muhammad Luqman Naseem",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17568"" target=""_blank"">2409.17568</a>",,2024-12-11
In-depth Analysis of Privacy Threats in Federated Learning for Medical Data,"Badhan Chandra Das, M. Hadi Amini, Yanzhao Wu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18907"" target=""_blank"">2409.18907</a>",,2024-12-11
Infighting in the Dark: Multi-Labels Backdoor Attack in Federated Learning,"Ye Li, Yanchao Zhao, Chengcheng Zhu, Jiale Zhang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19601"" target=""_blank"">2409.19601</a>",,2024-12-11
Robust LLM safeguarding via refusal feature adversarial training,"Lei Yu, Virginie Do, Karen Hambardzumyan, Nicola Cancedda",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.20089"" target=""_blank"">2409.20089</a>",,2024-12-11
Navigating Threats: A Survey of Physical Adversarial Attacks on LiDAR Perception Systems in Autonomous Vehicles,"Amira Guesmi, Muhammad Shafique",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.20426"" target=""_blank"">2409.20426</a>",,2024-12-11
Characterizing Model Robustness via Natural Input Gradients,"AdriÃ¡n RodrÃ­guez-MuÃ±oz, Tongzhou Wang, Antonio Torralba",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.20139"" target=""_blank"">2409.20139</a>",,2024-12-11
Understanding Implosion in Text-to-Image Generative Models,"Wenxin Ding, Cathy Y. Li, Shawn Shan, Ben Y. Zhao, Haitao Zheng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12314"" target=""_blank"">2409.12314</a>",,2024-12-11
MASKDROID: Robust Android Malware Detection with Masked Graph Representations,"Jingnan Zheng, Jiaohao Liu, An Zhang, Jun Zeng, Ziqi Yang, Zhenkai Liang, Tat-Seng Chua",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19594"" target=""_blank"">2409.19594</a>",,2024-12-11
Adversarial Examples for DNA Classification,Hyunwoo Yoo,arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19788"" target=""_blank"">2409.19788</a>",,2024-12-11
Discerning the Chaos: Detecting Adversarial Perturbations while Disentangling Intentional from Unintentional Noises,"Anubhooti Jain, Susim Roy, Kwanit Gupta, Mayank Vatsa, Richa Singh",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19619"" target=""_blank"">2409.19619</a>",,2024-12-11
BadHMP: Backdoor Attack against Human Motion Prediction,"Chaohui Xu, Si Wang, Chip-Hong Chang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19638"" target=""_blank"">2409.19638</a>",,2024-12-11
Nonideality-aware training makes memristive networks more robust to adversarial attacks,"Dovydas Joksas, Luis MuÃ±oz-GonzÃ¡lez, Emil Lupu, Adnan Mehonic",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19671"" target=""_blank"">2409.19671</a>",,2024-12-11
Towards Robust Extractive Question Answering Models: Rethinking the Training Methodology,"Son Quoc Tran, Matt Kretchmar",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19766"" target=""_blank"">2409.19766</a>",,2024-12-11
Efficient Noise Mitigation for Enhancing Inference Accuracy in DNNs on Mixed-Signal Accelerators,"Seyedarmin Azizi, Mohammad Erfan Sadeghi, Mehdi Kamal, Massoud Pedram",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18553"" target=""_blank"">2409.18553</a>",,2024-12-11
Learning Robust Policies via Interpretable Hamilton-Jacobi Reachability-Guided Disturbances,"Hanyang Hu, Xilun Zhang, Xubo Lyu, Mo Chen",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19746"" target=""_blank"">2409.19746</a>",,2024-12-11
IDEAW: Robust Neural Audio Watermarking with Invertible Dual-Embedding,"Pengcheng Li, Xulong Zhang, Jing Xiao, Jianzong Wang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19627"" target=""_blank"">2409.19627</a>",,2024-12-11
Can Models Learn Skill Composition from Examples? (1%),"Haoyu Zhao, Simran Kaur, Dingli Yu, Anirudh Goyal, Sanjeev Arora",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19808"" target=""_blank"">2409.19808</a>",,2024-12-11
Efficient Backdoor Defense in Multimodal Contrastive Learning: A Token-Level Unlearning Method for Mitigating Threats,"Kuanrong Liu, Siyuan Liang, Jiawei Liang, Pengwen Dai, Xiaochun Cao",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19526"" target=""_blank"">2409.19526</a>",,2024-12-11
GenTel-Safe: A Unified Benchmark and Shielding Framework for Defending Against Prompt Injection Attacks,"Rongchang Li, Minjie Chen, Chang Hu, Han Chen, Wenpeng Xing, Meng Han",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19521"" target=""_blank"">2409.19521</a>","<a href=""https://gentellab.github.io/gentel-safe.github.io/"" target=""_blank"">gentel-safe.github.io</a>",2024-12-11
Leveraging MTD to Mitigate Poisoning Attacks in Decentralized FL with Non-IID Data,"Chao Feng, Alberto Huertas CeldrÃ¡n, Zien Zeng, Zi Ye, der Assen Jan von, Gerome Bovet, Burkhard Stiller",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19302"" target=""_blank"">2409.19302</a>",,2024-12-11
Privacy Attack in Federated Learning is Not Easy: An Experimental Study,"Hangyu Zhu, Liyuan Huang, Zhenping Xie",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19301"" target=""_blank"">2409.19301</a>",,2024-12-11
Adversarial Challenges in Network Intrusion Detection Systems: Research Insights and Future Prospects,"Sabrine Ennaji, Gaspari Fabio De, Dorjan Hitaj, Alicia K/Bidi, Luigi V. Mancini",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18736"" target=""_blank"">2409.18736</a>",,2024-12-11
Enhancing Robustness of Graph Neural Networks through p-Laplacian,"Anuj Kumar Sirohi, Subhanu Halder, Kabir Kumar, Sandeep Kumar",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19096"" target=""_blank"">2409.19096</a>",,2024-12-11
Revisiting Acoustic Features for Robust ASR,"Muhammad A. Shah, Bhiksha Raj",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.16399"" target=""_blank"">2409.16399</a>",,2024-12-11
Discovering New Shadow Patterns for Black-Box Attacks on Lane Detection of Autonomous Vehicles,"Pedram MohajerAnsari, Alkim Domeke, Voor Jan de, Arkajyoti Mitra, Grace Johnson, Amir Salarpour, Habeeb Olufowobi, Mohammad Hamad, Mert D. PesÃ©",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18248"" target=""_blank"">2409.18248</a>",,2024-12-11
Proactive Schemes: A Survey of Adversarial Attacks for Social Good,"Vishal Asnani, Xi Yin, Xiaoming Liu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.16491"" target=""_blank"">2409.16491</a>",,2024-12-11
Perfect Gradient Inversion in Federated Learning: A New Paradigm from the Hidden Subset Sum Problem,"Qiongxiu Li, Lixia Luo, Agnese Gini, Changlong Ji, Zhanhao Hu, Xiao Li, Chengfang Fang, Jie Shi, Xiaolin Hu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14260"" target=""_blank"">2409.14260</a>",,2024-12-11
Efficient Visualization of Neural Networks with Generative Models and Adversarial Perturbations,Athanasios Karagounis,arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13559"" target=""_blank"">2409.13559</a>",,2024-12-11
ViTGuard: Attention-aware Detection against Adversarial Examples for Vision Transformer,"Shihua Sun, Kenechukwu Nwodo, Shridatt Sugrim, Angelos Stavrou, Haining Wang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13828"" target=""_blank"">2409.13828</a>",,2024-12-11
Certified Adversarial Robustness via Partition-based Randomized Smoothing,"Hossein Goli, Farzan Farnia",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13546"" target=""_blank"">2409.13546</a>",,2024-12-11
ID-Guard: A Universal Framework for Combating Facial Manipulation via Breaking Identification,"Zuomin Qu, Wei Lu, Xiangyang Luo, Qian Wang, Xiaochun Cao",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13349"" target=""_blank"">2409.13349</a>",,2024-12-11
Persistent Backdoor Attacks in Continual Learning,"Zhen Guo, Abhinav Kumar, Reza Tourani",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13864"" target=""_blank"">2409.13864</a>",,2024-12-11
Relationship between Uncertainty in DNNs and Adversarial Attacks,"Abigail Adeniran, Adewale Adeyemo",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13232"" target=""_blank"">2409.13232</a>",,2024-12-11
PureDiffusion: Using Backdoor to Counter Backdoor in Generative Diffusion Models,"Vu Tuan Truong, Long Bao Le",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13945"" target=""_blank"">2409.13945</a>",,2024-12-11
Deep generative models as an adversarial attack strategy for tabular machine learning,"Salijona Dyrmishi, Mihaela CÄtÄlina Stoian, Eleonora Giunchiglia, Maxime Cordy",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12642"" target=""_blank"">2409.12642</a>",,2024-12-11
TEAM: Temporal Adversarial Examples Attack Model against Network Intrusion Detection System Applied to RNN,"Ziyi Liu, Dengpan Ye, Long Tang, Yunming Zhang, Jiacheng Deng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12472"" target=""_blank"">2409.12472</a>",,2024-12-11
Defending against Reverse Preference Attacks is Difficult,"Domenic Rosati, Giles Edkins, Harsh Raj, David Atanasov, Subhabrata Majumdar, Janarthanan Rajendran, Frank Rudzicz, Hassan Sajjad",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12914"" target=""_blank"">2409.12914</a>",,2024-12-11
Revisiting Semi-supervised Adversarial Robustness via Noise-aware Online Robust Distillation,"Tsung-Han Wu, Hung-Ting Su, Shang-Tse Chen, Winston H. Hsu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12946"" target=""_blank"">2409.12946</a>",,2024-12-11
VCAT: Vulnerability-aware and Curiosity-driven Adversarial Training for Enhancing Autonomous Vehicle Robustness,"Xuan Cai, Zhiyong Cui, Xuesong Bai, Ruimin Ke, Zhenshu Ma, Haiyang Yu, Yilong Ren",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12997"" target=""_blank"">2409.12997</a>","<a href=""https://github.com/caixxuan/VCAT"" target=""_blank"">caixxuan</a>",2024-12-11
Data Poisoning and Leakage Analysis in Federated Learning,"Wenqi Wei, Tiansheng Huang, Zachary Yahn, Anoop Singhal, Margaret Loper, Ling Liu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13004"" target=""_blank"">2409.13004</a>",,2024-12-11
Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End Vision Language Action Models,"Hao Cheng, Erjia Xiao, Chengyuan Yu, Zhao Yao, Jiahang Cao, Qiang Zhang, Jiaxu Wang, Mengshu Sun, Kaidi Xu, Jindong Gu, Renjing Xu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13174"" target=""_blank"">2409.13174</a>","<a href=""https://chaducheng.github.io/Manipulat-Facing-Threats/"" target=""_blank"">Manipulat-Facing-Threats</a>",2024-12-11
"Hidden in Plain Sound: Environmental Backdoor Poisoning Attacks on Whisper, and Mitigations","Jonatan Bartolini, Todor Stoyanov, Alberto Giaretta",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12553"" target=""_blank"">2409.12553</a>",,2024-12-11
Enhancing 3D Robotic Vision Robustness by Minimizing Adversarial Mutual Information through a Curriculum Training Approach,"Nastaran Darabi, Dinithi Jayasuriya, Devashri Naik, Theja Tulabandhula, Amit Ranjan Trivedi",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12379"" target=""_blank"">2409.12379</a>","<a href=""https://github.com/nstrndrbi/Mine-N-Learn"" target=""_blank"">nstrndrbi</a>",2024-12-11
ITPatch: An Invisible and Triggered Physical Adversarial Patch against Traffic Sign Recognition,"Shuai Yuan, Hongwei Li, Xingshuo Han, Guowen Xu, Wenbo Jiang, Tao Ni, Qingchuan Zhao, Yuguang Fang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12394"" target=""_blank"">2409.12394</a>",,2024-12-11
Privacy Evaluation Benchmarks for NLP Models,"Wei Huang, Yinggui Wang, Cen Chen",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15868"" target=""_blank"">2409.15868</a>","<a href=""https://github.com/user2311717757/nlp_doctor"" target=""_blank"">user2311717757</a>",2024-12-11
NPAT Null-Space Projected Adversarial Training Towards Zero Deterioration,"Hanyi Hu, Qiao Han, Kui Chen, Yao Yang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.11754"" target=""_blank"">2409.11754</a>",,2024-12-11
LLM-Powered Text Simulation Attack Against ID-Free Recommender Systems,"Zongwei Wang, Min Gao, Junliang Yu, Xinyi Gao, Quoc Viet Hung Nguyen, Shazia Sadiq, Hongzhi Yin",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.11690"" target=""_blank"">2409.11690</a>",,2024-12-11
PAD-FT: A Lightweight Defense for Backdoor Attacks via Data Purification and Fine-Tuning,"Yukai Xu, Yujie Gu, Kouichi Sakurai",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12072"" target=""_blank"">2409.12072</a>",,2024-12-11
Data-centric NLP Backdoor Defense from the Lens of Memorization,"Zhenting Wang, Zhizhi Wang, Mingyu Jin, Mengnan Du, Juan Zhai, Shiqing Ma",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14200"" target=""_blank"">2409.14200</a>",,2024-12-11
Hidden Activations Are Not Enough: A General Approach to Neural Network Predictions,"Samuel Leblanc, Aiky Rasolomanana, Marco Armenta",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13163"" target=""_blank"">2409.13163</a>","<a href=""https://github.com/MarcoArmenta/Hidden-Activations-are-not-Enough"" target=""_blank"">MarcoArmenta</a>",2024-12-11
Interpretability-Guided Test-Time Adversarial Defense,"Akshay Kulkarni, Tsui-Wei Weng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15190"" target=""_blank"">2409.15190</a>",,2024-12-11
Room Impulse Responses help attackers to evade Deep Fake Detection,"Hieu-Thi Luong, Duc-Tuan Truong, Kong Aik Lee, Eng Siong Chng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14712"" target=""_blank"">2409.14712</a>",,2024-12-11
Towards Robust Object Detection: Identifying and Removing Backdoors via Module Inconsistency Analysis,"Xianda Zhang, Siyuan Liang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.16057"" target=""_blank"">2409.16057</a>",,2024-12-11
PACE: Poisoning Attacks on Learned Cardinality Estimation,"Jintao Tsinghua University Zhang, Chao Tsinghua University Zhang, Guoliang Tsinghua University Li, Chengliang Beijing Institute of Technology Chai",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15990"" target=""_blank"">2409.15990</a>",,2024-12-11
Improving Adversarial Robustness for 3D Point Cloud Recognition at Test-Time through Purified Self-Training,"Jinpeng Lin, Xulei Yang, Tianrui Li, Xun Xu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14940"" target=""_blank"">2409.14940</a>",,2024-12-11
ESPERANTO: Evaluating Synthesized Phrases to Enhance Robustness in AI Detection for Text Origination,"Navid Ayoobi, Lily Knab, Wen Cheng, David Pantoja, Hamidreza Alikhani, Sylvain Flamant, Jin Kim, Arjun Mukherjee",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14285"" target=""_blank"">2409.14285</a>",,2024-12-11
Effective and Evasive Fuzz Testing-Driven Jailbreaking Attacks against LLMs,"Xueluan Gong, Mingzhe Li, Yilin Zhang, Fengyuan Ran, Chen Chen, Yanjiao Chen, Qian Wang, Kwok-Yan Lam",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14866"" target=""_blank"">2409.14866</a>",,2024-12-11
Data Poisoning-based Backdoor Attack Framework against Supervised Learning Rules of Spiking Neural Networks,"Lingxin Jin, Meiyu Lin, Wei Jiang, Jinyu Zhan",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15670"" target=""_blank"">2409.15670</a>",,2024-12-11
Attack Atlas: A Practitioner's Perspective on Challenges and Pitfalls in Red Teaming GenAI,"Ambrish Rawat, Stefan Schoepf, Giulio Zizzo, Giandomenico Cornacchia, Muhammad Zaid Hameed, Kieran Fraser, Erik Miehling, Beat Buesser, Elizabeth M. Daly, Mark Purcell, Prasanna Sattigeri, Pin-Yu Chen, Kush R. Varshney",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15398"" target=""_blank"">2409.15398</a>",,2024-12-11
PROMPTFUZZ: Harnessing Fuzzing Techniques for Robust Testing of Prompt Injection in LLMs,"Jiahao Yu, Yangguang Shao, Hanwen Miao, Junzheng Shi, Xinyu Xing",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14729"" target=""_blank"">2409.14729</a>",,2024-12-11
Log-normal Mutations and their Use in Detecting Surreptitious Fake Images,"Ismail Labiad, Thomas BÃ¤ck, Pierre Fernandez, Laurent Najman, Tom Sander, Furong Ye, Mariia Zameshina, Olivier Teytaud",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15119"" target=""_blank"">2409.15119</a>",,2024-12-11
Toward Mixture-of-Experts Enabled Trustworthy Semantic Communication for 6G Networks,"Jiayi He, Xiaofeng Luo, Jiawen Kang, Hongyang Du, Zehui Xiong, Ci Chen, Dusit Niyato, Xuemin Shen",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15695"" target=""_blank"">2409.15695</a>",,2024-12-11
A constrained optimization approach to improve robustness of neural networks,"Shudian Zhao, Jan Kronqvist",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13770"" target=""_blank"">2409.13770</a>",,2024-12-11
AIM 2024 Sparse Neural Rendering Challenge: Dataset and Benchmark,"Michal Nazarczuk, Thomas Tanay, Sibi Catley-Chandar, Richard Shaw, Radu Timofte, Eduardo PÃ©rez-Pellitero",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15041"" target=""_blank"">2409.15041</a>","<a href=""https://sparebenchmark.github.io/"" target=""_blank"">sparebenchmark.github.io</a>",2024-12-11
Evaluating the Performance and Robustness of LLMs in Materials Science Q&A and Property Predictions,"Hongchen Wang, Kangming Li, Scott Ramsay, Yao Fehlis, Edward Kim, Jason Hattrick-Simpers",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14572"" target=""_blank"">2409.14572</a>",,2024-12-11
When Witnesses Defend: A Witness Graph Topological Layer for Adversarial Graph Learning,"Naheed Anjum Arafat, Debabrota Basu, Yulia Gel, Yuzhou Chen",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14161"" target=""_blank"">2409.14161</a>",,2024-12-11
Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation,"G M Shahariar, Jia Chen, Jiachen Li, Yue Dong",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15381"" target=""_blank"">2409.15381</a>","<a href=""https://github.com/shahariar-shibli/Adversarial-Attack-on-POS-Tags"" target=""_blank"">shahariar-shibli</a>",2024-12-11
PathSeeker: Exploring LLM Security Vulnerabilities with a Reinforcement Learning-Based Jailbreak Approach,"Zhihao Lin, Wei Ma, Mingyi Zhou, Yanjie Zhao, Haoyu Wang, Yang Liu, Jun Wang, Li Li",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14177"" target=""_blank"">2409.14177</a>",,2024-12-11
Cloud Adversarial Example Generation for Remote Sensing Image Classification,"Fei Ma, Yuqiang Feng, Fan Zhang, Yongsheng Zhou",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14240"" target=""_blank"">2409.14240</a>",,2024-12-11
Enhancing LLM-based Autonomous Driving Agents to Mitigate Perception Attacks,"Ruoyu Song, Muslum Ozgur Ozmen, Hyungsub Kim, Antonio Bianchi, Z. Berkay Celik",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14488"" target=""_blank"">2409.14488</a>",,2024-12-11
SDBA: A Stealthy and Long-Lasting Durable Backdoor Attack in Federated Learning,"Minyeong Choe, Cheolhee Park, Changho Seo, Hyunil Kim",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14805"" target=""_blank"">2409.14805</a>",,2024-12-11
UTrace: Poisoning Forensics for Private Collaborative Learning,"Evan Rose, Hidde Lycklama, Harsh Chaudhari, Anwar Hithnawi, Alina Oprea",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15126"" target=""_blank"">2409.15126</a>",,2024-12-11
Kov: Transferable and Naturalistic Black-Box LLM Attacks using Markov Decision Processes and Tree Search,Robert J. Moss,arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08899"" target=""_blank"">2408.08899</a>","<a href=""https://github.com/sisl/Kov.jl"" target=""_blank"">sisl</a>",2024-12-11
ReToMe-VA: Recursive Token Merging for Video Diffusion-based Unrestricted Adversarial Attack,"Ziyi Gao, Kai Chen, Zhipeng Wei, Tingshu Mou, Jingjing Chen, Zhiyu Tan, Hao Li, Yu-Gang Jiang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05479"" target=""_blank"">2408.05479</a>",,2024-12-11
Ensemble everything everywhere: Multi-scale aggregation for adversarial robustness,"Stanislav Fort, Balaji Lakshminarayanan",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05446"" target=""_blank"">2408.05446</a>",,2024-12-11
StealthDiffusion: Towards Evading Diffusion Forensic Detection through Diffusion Model,"Ziyin Zhou, Ke Sun, Zhongxi Chen, Huafeng Kuang, Xiaoshuai Sun, Rongrong Ji",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05669"" target=""_blank"">2408.05669</a>",,2024-12-11
PointNCBW: Towards Dataset Ownership Verification for Point Clouds via Negative Clean-label Backdoor Watermark,"Cheng Wei, Yang Wang, Kuofeng Gao, Shuo Shao, Yiming Li, Zhibo Wang, Zhan Qin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05500"" target=""_blank"">2408.05500</a>",,2024-12-11
Modeling Electromagnetic Signal Injection Attacks on Camera-based Smart Systems: Applications and Mitigation,"Youqian Zhang, Michael Cheung, Chunxi Yang, Xinwei Zhai, Zitong Shen, Xinyu Ji, Eugene Y. Fu, Sze-Yiu Chau, Xiapu Luo",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05124"" target=""_blank"">2408.05124</a>",,2024-12-11
A Jailbroken GenAI Model Can Cause Substantial Harm: GenAI-powered Applications are Vulnerable to PromptWares,"Stav Cohen, Ron Bitton, Ben Nassi",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05061"" target=""_blank"">2408.05061</a>",,2024-12-11
Rag and Roll: An End-to-End Evaluation of Indirect Prompt Manipulations in LLM-based Application Frameworks,"Stefano Gianluca De, Lea SchÃ¶nherr, Giancarlo Pellegrino",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05025"" target=""_blank"">2408.05025</a>",,2024-12-11
TrajFM: A Vehicle Trajectory Foundation Model for Region and Task Transferability,"Yan Lin, Tonglong Wei, Zeyu Zhou, Haomin Wen, Jilin Hu, Shengnan Guo, Youfang Lin, Huaiyu Wan",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15251"" target=""_blank"">2408.15251</a>",,2024-12-11
Adversarially Robust Industrial Anomaly Detection Through Diffusion Model,"Yuanpu Cao, Lu Lin, Jinghui Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04839"" target=""_blank"">2408.04839</a>",,2024-12-11
Unveiling Hidden Visual Information: A Reconstruction Attack Against Adversarial Visual Information Hiding,"Jonggyu Jang, Hyeonsu Lyu, Seongjin Hwang, Hyun Jong Yang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04261"" target=""_blank"">2408.04261</a>",,2024-12-11
Eliminating Backdoors in Neural Code Models via Trigger Inversion,"Weisong Sun, Yuchen Chen, Chunrong Fang, Yebo Feng, Yuan Xiao, An Guo, Quanjun Zhang, Yang Liu, Baowen Xu, Zhenyu Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04683"" target=""_blank"">2408.04683</a>",,2024-12-11
Improving Network Interpretability via Explanation Consistency Evaluation,"Hefeng Wu, Hao Jiang, Keze Wang, Ziyi Tang, Xianghuan He, Liang Lin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04600"" target=""_blank"">2408.04600</a>",,2024-12-11
Classifier Guidance Enhances Diffusion-based Adversarial Purification by Preserving Predictive Information,"Mingkun Zhang, Jianing Li, Wei Chen, Jiafeng Guo, Xueqi Cheng",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05900"" target=""_blank"">2408.05900</a>",,2024-12-11
"Towards Resilient and Efficient LLMs: A Comparative Study of Efficiency, Performance, and Adversarial Robustness","Xiaojing Fan, Chunliang Tao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04585"" target=""_blank"">2408.04585</a>",,2024-12-11
Stability Analysis of Equivariant Convolutional Representations Through The Lens of Equivariant Multi-layered CKNs,Soutrik Roy Chowdhury,arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04277"" target=""_blank"">2408.04277</a>",,2024-12-11
h4rm3l: A Dynamic Benchmark of Composable Jailbreak Attacks for LLM Safety Assessment,"Moussa Koulako Bala Doumbouya, Ananjan Nandi, Gabriel Poesia, Davide Ghilardi, Anna Goldie, Federico Bianchi, Dan Jurafsky, Christopher D. Manning",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04811"" target=""_blank"">2408.04811</a>",,2024-12-11
VideoQA in the Era of LLMs: An Empirical Study,"Junbin Xiao, Nanxin Huang, Hangyu Qin, Dongyang Li, Yicong Li, Fengbin Zhu, Zhulin Tao, Jianxing Yu, Liang Lin, Tat-Seng Chua, Angela Yao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04223"" target=""_blank"">2408.04223</a>",,2024-12-11
Investigating Adversarial Attacks in Software Analytics via Machine Learning Explainability,"MD Abdul Awal, Mrigank Rochan, Chanchal K. Roy",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04124"" target=""_blank"">2408.04124</a>",,2024-12-11
Enhancing Output Diversity Improves Conjugate Gradient-based Adversarial Attacks,"Keiichiro Yamamura, Issa Oe, Hiroki Ishikura, Katsuki Fujisawa",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03972"" target=""_blank"">2408.03972</a>","<a href=""https://github.com/yamamura-k/ReACG"" target=""_blank"">yamamura-k</a>",2024-12-11
EdgeShield: A Universal and Efficient Edge Computing Framework for Robust AI,"Duo Zhong, Bojing Li, Xiang Chen, Chenchen Liu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04181"" target=""_blank"">2408.04181</a>",,2024-12-11
EnJa: Ensemble Jailbreak on Large Language Models,"Jiahao Zhang, Zilong Wang, Ruofan Wang, Xingjun Ma, Yu-Gang Jiang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03603"" target=""_blank"">2408.03603</a>",,2024-12-11
MORTAR: A Model-based Runtime Action Repair Framework for AI-enabled Cyber-Physical Systems,"Renzhi Wang, Zhehua Zhou, Jiayang Song, Xuan Xie, Xiaofei Xie, Lei Ma",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03892"" target=""_blank"">2408.03892</a>",,2024-12-11
Efficient Image-to-Image Diffusion Classifier for Adversarial Robustness,"Hefei Mei, Minjing Dong, Chang Xu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08502"" target=""_blank"">2408.08502</a>","<a href=""https://github.com/hfmei/IDC"" target=""_blank"">hfmei</a>",2024-12-11
Improving Adversarial Transferability with Neighbourhood Gradient Information,"Haijing Guo, Jiafeng Wang, Zhaoyu Chen, Kaixun Jiang, Lingyi Hong, Pinxue Guo, Jinglun Li, Wenqiang Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05745"" target=""_blank"">2408.05745</a>",,2024-12-11
Understanding Byzantine Robustness in Federated Learning with A Black-box Server,"Fangyuan Zhao, Yuexiang Xie, Xuebin Ren, Bolin Ding, Shusen Yang, Yaliang Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.06042"" target=""_blank"">2408.06042</a>","<a href=""https://github.com/alibaba/FederatedScope/tree/Byzantine_attack_defense"" target=""_blank"">tree</a>",2024-12-11
MTDSense: AI-Based Fingerprinting of Moving Target Defense Techniques in Software-Defined Networking,"Tina Moghaddam, Guowei Yang, Chandra Thapa, Seyit Camtepe, Dan Dongseong Kim",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03758"" target=""_blank"">2408.03758</a>",,2024-12-11
Evaluating Text Classification Robustness to Part-of-Speech Adversarial Examples,"Anahita Samadi, Allison Sullivan",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08374"" target=""_blank"">2408.08374</a>",,2024-12-11
Unlearnable Examples Detection via Iterative Filtering,"Yi Yu, Qichen Zheng, Siyuan Yang, Wenhan Yang, Jun Liu, Shijian Lu, Yap-Peng Tan, Kwok-Yan Lam, Alex Kot",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08143"" target=""_blank"">2408.08143</a>",,2024-12-11
A Survey of Trojan Attacks and Defenses to Deep Neural Networks,"Lingxin Jin, Xianyu Wen, Wei Jiang, Jinyu Zhan",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08920"" target=""_blank"">2408.08920</a>",,2024-12-11
Prefix Guidance: A Steering Wheel for Large Language Models to Defend Against Jailbreak Attacks,"Jiawei Zhao, Kejiang Chen, Xiaojian Yuan, Weiming Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08924"" target=""_blank"">2408.08924</a>",,2024-12-11
$\textit{MMJ-Bench}$: A Comprehensive Study on Jailbreak Attacks and Defenses for Multimodal Large Language Models,"Fenghua Weng, Yue Xu, Chengyan Fu, Wenjie Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08464"" target=""_blank"">2408.08464</a>",,2024-12-11
Random Gradient Masking as a Defensive Measure to Deep Leakage in Federated Learning,"Joon Kim, Sejin Park",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08430"" target=""_blank"">2408.08430</a>",,2024-12-11
A Robust Multi-Stage Intrusion Detection System for In-Vehicle Network Security using Hierarchical Federated Learning,"Muzun Althunayyan, Amir Javed, Omer Rana",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08433"" target=""_blank"">2408.08433</a>",,2024-12-11
Enhancing Adversarial Attacks via Parameter Adaptive Adversarial Attack,"Zhibo Jin, Jiayu Zhang, Zhiyu Zhu, Chenyu Zhang, Jiahao Huang, Jianlong Zhou, Fang Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07733"" target=""_blank"">2408.07733</a>",,2024-12-11
TabularBench: Benchmarking Adversarial Robustness for Tabular Deep Learning in Real-world Use-cases,"Thibault Simonetto, Salah Ghamizi, Maxime Cordy",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07579"" target=""_blank"">2408.07579</a>","<a href=""https://github.com/serval-uni-lu/tabularbench"" target=""_blank"">serval-uni-lu</a>",2024-12-11
Robust Active Learning (RoAL): Countering Dynamic Adversaries in Active Learning with Elastic Weight Consolidation,"Ricky Maulana Fajri, Yulong Pei, Lu Yin, Mykola Pechenizkiy",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07364"" target=""_blank"">2408.07364</a>",,2024-12-11
Achieving Data Efficient Neural Networks with Hybrid Concept-based Models,"Tobias A. Opsahl, Vegard Antun",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07438"" target=""_blank"">2408.07438</a>",,2024-12-11
DFT-Based Adversarial Attack Detection in MRI Brain Imaging: Enhancing Diagnostic Accuracy in Alzheimer's Case Studies,"Mohammad Hossein Najafi, Mohammad Morsali, Mohammadmahdi Vahediahmar, Saeed Bagheri Shouraki",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08489"" target=""_blank"">2408.08489</a>",,2024-12-11
Sonic: Fast and Transferable Data Poisoning on Clustering Algorithms,"Francesco Villani, Dario Lazzaro, Antonio Emanuele CinÃ , Matteo Dell'Amico, Battista Biggio, Fabio Roli",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07558"" target=""_blank"">2408.07558</a>",,2024-12-11
BadMerging: Backdoor Attacks Against Model Merging,"Jinghuai Zhang, Jianfeng Chi, Zheng Li, Kunlin Cai, Yang Zhang, Yuan Tian",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07362"" target=""_blank"">2408.07362</a>",,2024-12-11
BAPLe: Backdoor Attacks on Medical Foundational Models using Prompt Learning,"Asif Hanif, Fahad Shamshad, Muhammad Awais, Muzammal Naseer, Fahad Shahbaz Khan, Karthik Nandakumar, Salman Khan, Rao Muhammad Anwer",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07440"" target=""_blank"">2408.07440</a>","<a href=""https://asif-hanif.github.io/baple/"" target=""_blank"">baple</a>",2024-12-11
DePatch: Towards Robust Adversarial Patch for Evading Person Detectors in the Real World,"Jikang Cheng, Ying Zhang, Zhongyuan Wang, Zou Qin, Chen Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.06625"" target=""_blank"">2408.06625</a>",,2024-12-11
Robust Black-box Testing of Deep Neural Networks using Co-Domain Coverage,"Aishwarya Gupta, Indranil Saha, Piyush Rai",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.06766"" target=""_blank"">2408.06766</a>",,2024-12-11
Imagen 3,"Imagen-Team-Google, :, Jason Baldridge, Jakob Bauer, Mukul Bhutani, Nicole Brichtova, Andrew Bunner, Kelvin Chan, Yichang Chen, Sander Dieleman, Yuqing Du, Zach Eaton-Rosen, Hongliang Fei, Freitas Nando de, Yilin Gao, Evgeny Gladchenko, Sergio GÃ³mez Colmenarejo, Mandy Guo, Alex Haig, Will Hawkins, Hexiang Hu, Huilian Huang, Tobenna Peter Igwe, Christos Kaplanis, Siavash Khodadadeh, Yelin Kim, Ksenia Konyushkova, Karol Langner, Eric Lau, Shixin Luo, SoÅa MokrÃ¡, Henna Nandwani, Yasumasa Onoe, AÃ¤ron van den Oord, Zarana Parekh, Jordi Pont-Tuset, Hang Qi, Rui Qian, Deepak Ramachandran, Poorva Rane, Abdullah Rashwan, Ali Razavi, Robert Riachi, Hansa Srinivasan, Srivatsan Srinivasan, Robin Strudel, Benigno Uria, Oliver Wang, Su Wang, Austin Waters, Chris Wolff, Auriel Wright, Zhisheng Xiao, Hao Xiong, Keyang Xu, Zee Marc van, Junlin Zhang, Katie Zhang, Wenlei Zhou, Konrad Zolna, Ola Aboubakar, Canfer Akbulut, Oscar Akerlund, Isabela Albuquerque, Nina Anderson, Marco Andreetto, Lora Aroyo, Ben Bariach, David Barker, Sherry Ben, Dana Berman, Courtney Biles, Irina Blok, Pankil Botadra, Jenny Brennan, Karla Brown, John Buckley, Rudy Bunel, Elie Bursztein, Christina Butterfield, Ben Caine, Viral Carpenter, Norman Casagrande, Ming-Wei Chang, Solomon Chang, Shamik Chaudhuri, Tony Chen, John Choi, Dmitry Churbanau, Nathan Clement, Matan Cohen, Forrester Cole, Mikhail Dektiarev, Vincent Du, Praneet Dutta, Tom Eccles, Ndidi Elue, Ashley Feden, Shlomi Fruchter, Frankie Garcia, Roopal Garg, Weina Ge, Ahmed Ghazy, Bryant Gipson, Andrew Goodman, Dawid GÃ³rny, Sven Gowal, Khyatti Gupta, Yoni Halpern, Yena Han, Susan Hao, Jamie Hayes, Amir Hertz, Ed Hirst, Tingbo Hou, Heidi Howard, Mohamed Ibrahim, Dirichi Ike-Njoku, Joana Iljazi, Vlad Ionescu, William Isaac, Reena Jana, Gemma Jennings, Donovon Jenson, Xuhui Jia, Kerry Jones, Xiaoen Ju, Ivana Kajic, Christos Kaplanis, Burcu Karagol Ayan, Jacob Kelly, Suraj Kothawade, Christina Kouridi, Ira Ktena, Jolanda Kumakaw, Dana Kurniawan, Dmitry Lagun, Lily Lavitas, Jason Lee, Tao Li, Marco Liang, Maggie Li-Calis, Yuchi Liu, Javier Lopez Alberca, Peggy Lu, Kristian Lum, Yukun Ma, Chase Malik, John Mellor, Inbar Mosseri, Tom Murray, Aida Nematzadeh, Paul Nicholas, JoÃ£o Gabriel Oliveira, Guillermo Ortiz-Jimenez, Michela Paganini, Tom Le Paine, Roni Paiss, Alicia Parrish, Anne Peckham, Vikas Peswani, Igor Petrovski, Tobias Pfaff, Alex Pirozhenko, Ryan Poplin, Utsav Prabhu, Yuan Qi, Matthew Rahtz, Cyrus Rashtchian, Charvi Rastogi, Amit Raul, Ali Razavi, Sylvestre-Alvise Rebuffi, Susanna Ricco, Felix Riedel, Dirk Robinson, Pankaj Rohatgi, Bill Rosgen, Sarah Rumbley, Moonkyung Ryu, Anthony Salgado, Sahil Singla, Florian Schroff, Candice Schumann, Tanmay Shah, Brendan Shillingford, Kaushik Shivakumar, Dennis Shtatnov, Zach Singer, Evgeny Sluzhaev, Valerii Sokolov, Thibault Sottiaux, Florian Stimberg, Brad Stone, David Stutz, Yu-Chuan Su, Eric Tabellion, Shuai Tang, David Tao, Kurt Thomas, Gregory Thornton, Andeep Toor, Cristian Udrescu, Aayush Upadhyay, Cristina Vasconcelos, Alex Vasiloff, Andrey Voynov, Amanda Walker, Luyu Wang, Miaosen Wang, Simon Wang, Stanley Wang, Qifei Wang, Yuxiao Wang, Ãgoston Weisz, Olivia Wiles, Chenxia Wu, Xingyu Federico Xu, Andrew Xue, Jianbo Yang, Luo Yu, Mete Yurtoglu, Ali Zand, Han Zhang, Jiageng Zhang, Catherine Zhao, Adilet Zhaxybay, Miao Zhou, Shengqi Zhu, Zhenkai Zhu, Dawn Bloxwich, Mahyar Bordbar, Luis C. Cobo, Eli Collins, Shengyang Dai, Tulsee Doshi, Anca Dragan, Douglas Eck, Demis Hassabis, Sissie Hsiao, Tom Hume, Koray Kavukcuoglu, Helen King, Jack Krawczyk, Yeqing Li, Kathy Meier-Hellstern, Andras Orban, Yury Pinsky, Amar Subramanya, Oriol Vinyals, Ting Yu, Yori Zwols",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07009"" target=""_blank"">2408.07009</a>",,2024-12-11
Towards Adversarial Robustness via Debiased High-Confidence Logit Alignment,"Kejia Zhang, Juanjuan Weng, Zhiming Luo, Shaozi Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.06079"" target=""_blank"">2408.06079</a>",,2024-12-11
Fooling SHAP with Output Shuffling Attacks,"Jun Yuan, Aritra Dasgupta",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.06509"" target=""_blank"">2408.06509</a>",,2024-12-11
LaFA: Latent Feature Attacks on Non-negative Matrix Factorization,"Minh Vu, Ben Nebgen, Erik Skau, Geigh Zollicoffer, Juan Castorena, Kim Rasmussen, Boian Alexandrov, Manish Bhattarai",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03909"" target=""_blank"">2408.03909</a>",,2024-12-11
Vera Verto: Multimodal Hijacking Attack,"Minxing Zhang, Ahmed Salem, Michael Backes, Yang Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00129"" target=""_blank"">2408.00129</a>",,2024-12-11
FDI: Attack Neural Code Generation Systems through User Feedback Channel,"Zhensu Sun, Xiaoning Du, Xiapu Luo, Fu Song, David Lo, Li Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04194"" target=""_blank"">2408.04194</a>",,2024-12-11
CERT-ED: Certifiably Robust Text Classification for Edit Distance,"Zhuoqun Huang, Neil G Marchant, Olga Ohrimenko, Benjamin I. P. Rubinstein",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00728"" target=""_blank"">2408.00728</a>",,2024-12-11
Guardians of Image Quality: Benchmarking Defenses Against Adversarial Attacks on Image Quality Metrics,"Alexander Gushchin, Khaled Abud, Georgii Bychkov, Ekaterina Shumitskaya, Anna Chistyakova, Sergey Lavrushkin, Bader Rasheed, Kirill Malyshev, Dmitriy Vatolin, Anastasia Antsiferova",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01541"" target=""_blank"">2408.01541</a>",,2024-12-11
Trustworthy Machine Learning under Social and Adversarial Data Sources,Han Shao,arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01596"" target=""_blank"">2408.01596</a>",,2024-12-11
EmoBack: Backdoor Attacks Against Speaker Identification Using Emotional Prosody,"Coen Schoof, Stefanos Koffas, Mauro Conti, Stjepan Picek",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01178"" target=""_blank"">2408.01178</a>",,2024-12-11
Interpreting Global Perturbation Robustness of Image Models using Axiomatic Spectral Importance Decomposition,"RÃ³isÃ­n Luo, James McDermott, Colm O'Riordan",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01139"" target=""_blank"">2408.01139</a>",,2024-12-11
Assessing Robustness of Machine Learning Models using Covariate Perturbations,"Arun Prakash R, Anwesha Bhattacharyya, Joel Vaughan, Vijayan N. Nair",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01300"" target=""_blank"">2408.01300</a>",,2024-12-11
Certifiably Robust Encoding Schemes,"Aman Saxena, Tom WollschlÃ¤ger, Nicola Franco, Jeanette Miriam Lorenz, Stephan GÃ¼nnemann",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01200"" target=""_blank"">2408.01200</a>",,2024-12-11
Hallu-PI: Evaluating Hallucination in Multi-modal Large Language Models within Perturbed Inputs,"Peng Ding, Jingyu Wu, Jun Kuang, Dan Ma, Xuezhi Cao, Xunliang Cai, Shi Chen, Jiajun Chen, Shujian Huang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01355"" target=""_blank"">2408.01355</a>","<a href=""https://github.com/NJUNLP/Hallu-PI"" target=""_blank"">NJUNLP</a>",2024-12-11
Autonomous LLM-Enhanced Adversarial Attack for Text-to-Motion,"Honglei Miao, Fan Ma, Ruijie Quan, Kun Zhan, Yi Yang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00352"" target=""_blank"">2408.00352</a>",,2024-12-11
OTAD: An Optimal Transport-Induced Robust Model for Agnostic Adversarial Attack,"Kuo Gai, Sicong Wang, Shihua Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00329"" target=""_blank"">2408.00329</a>",,2024-12-11
Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks,"Angona Biswas, MD Abdullah Al Nasim, Kishor Datta Gupta, Roy George, Abdur Rashid",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00348"" target=""_blank"">2408.00348</a>",,2024-12-11
ADBM: Adversarial diffusion bridge model for reliable adversarial purification,"Xiao Li, Wenxuan Sun, Huanran Chen, Qiongxiu Li, Yining Liu, Yingzhe He, Jie Shi, Xiaolin Hu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00315"" target=""_blank"">2408.00315</a>",,2024-12-11
Hard to Explain: On the Computational Hardness of In-Distribution Model Interpretation,"Guy Amir, Shahaf Bassan, Guy Katz",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03915"" target=""_blank"">2408.03915</a>",,2024-12-11
Discrete Randomized Smoothing Meets Quantum Computing,"Tom WollschlÃ¤ger, Aman Saxena, Nicola Franco, Jeanette Miriam Lorenz, Stephan GÃ¼nnemann",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00895"" target=""_blank"">2408.00895</a>",,2024-12-11
Adversarial Text Rewriting for Text-aware Recommender Systems,"Sejoon Oh, Gaurav Verma, Srijan Kumar",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00312"" target=""_blank"">2408.00312</a>",,2024-12-11
MAARS: Multi-Rate Attack-Aware Randomized Scheduling for Securing Real-time Systems,"Arkaprava Sain, Sunandan Adhikary, Ipsita Koley, Soumyajit Dey",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00341"" target=""_blank"">2408.00341</a>",,2024-12-11
"Pathway to Secure and Trustworthy 6G for LLMs: Attacks, Defense, and Opportunities","Sunder Ali Khowaja, Parus Khuwaja, Kapal Dev, Hussam Al Hamadi, Engin Zeydan",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00722"" target=""_blank"">2408.00722</a>",,2024-12-11
On the Perturbed States for Transformed Input-robust Reinforcement Learning,"Tung M. Luu, Haeyong Kang, Tri Ton, Thanh Nguyen, Chang D. Yoo",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00023"" target=""_blank"">2408.00023</a>",,2024-12-11
Certifying Robustness of Learning-Based Keypoint Detection and Pose Estimation Methods,"Xusheng Luo, Tianhao Wei, Simin Liu, Ziwei Wang, Luis Mattei-Mendez, Taylor Loper, Joshua Neighbor, Casidhe Hutchison, Changliu Liu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00117"" target=""_blank"">2408.00117</a>",,2024-12-11
On Feasibility of Intent Obfuscating Attacks,"Zhaobin Li, Patrick Shafto",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02674"" target=""_blank"">2408.02674</a>",,2024-12-11
Taxonomy Driven Fast Adversarial Training,"Kun Tong, Chengze Jiang, Jie Gui, Yuan Cao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03944"" target=""_blank"">2408.03944</a>","<a href=""https://github.com/bookman233/TDAT"" target=""_blank"">bookman233</a>",2024-12-11
Explainable AI-based Intrusion Detection System for Industry 5,"Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03335"" target=""_blank"">2408.03335</a>",,2024-12-11
Transferable Adversarial Facial Images for Privacy Protection,"Minghui Li, Jiangxiong Wang, Hao Zhang, Ziqi Zhou, Shengshan Hu, Xiaobing Pei",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01428"" target=""_blank"">2408.01428</a>",,2024-12-11
Downstream Transfer Attack: Adversarial Attacks on Downstream Models with Pre-trained Vision Transformers,"Weijie Zheng, Xingjun Ma, Hanxun Huang, Zuxuan Wu, Yu-Gang Jiang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01705"" target=""_blank"">2408.01705</a>",,2024-12-11
Joint Universal Adversarial Perturbations with Interpretations,"Liang-bo Ning, Zeyu Dai, Wenqi Fan, Jingran Su, Chao Pan, Luning Wang, Qing Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01715"" target=""_blank"">2408.01715</a>",,2024-12-11
ALIF: Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms using Linguistic Features,"Peng Cheng, Yuwei Wang, Peng Huang, Zhongjie Ba, Xiaodong Lin, Feng Lin, Li Lu, Kui Ren",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01808"" target=""_blank"">2408.01808</a>",,2024-12-11
FovEx: Human-inspired Explanations for Vision Transformers and Convolutional Neural Networks,"Mahadev Prasad Panda, Matteo Tiezzi, Martina Vilas, Gemma Roig, Bjoern M. Eskofier, Dario Zanca",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02123"" target=""_blank"">2408.02123</a>",,2024-12-11
Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models,"Shachi H Kumar, Saurav Sahay, Sahisnu Mazumder, Eda Okur, Ramesh Manuvinakurike, Nicole Beckage, Hsuan Su, Hung-yi Lee, Lama Nachman",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03907"" target=""_blank"">2408.03907</a>",,2024-12-11
Adversarial Robustness of Open-source Text Classification Models and Fine-Tuning Chains,"Hao Qin, Mingyang Li, Junjie Wang, Qing Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02963"" target=""_blank"">2408.02963</a>",,2024-12-11
Sample-agnostic Adversarial Perturbation for Vision-Language Pre-training Models,"Haonan Zheng, Wen Jiang, Xinyang Deng, Wenrui Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02980"" target=""_blank"">2408.02980</a>","<a href=""https://github.com/LibertazZ/MUAP"" target=""_blank"">LibertazZ</a>",2024-12-11
Simple Perturbations Subvert Ethereum Phishing Transactions Detection: An Empirical Analysis,"Ahod Alghureid, David Mohaisen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03441"" target=""_blank"">2408.03441</a>",,2024-12-11
Attacks and Defenses for Generative Diffusion Models: A Comprehensive Survey,"Vu Tuan Truong, Luan Ba Dang, Long Bao Le",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03400"" target=""_blank"">2408.03400</a>",,2024-12-11
A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems,"Wenxiao Zhang, Xiangrui Kong, Conan Dewitt, Thomas Braunl, Jin B. Hong",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03515"" target=""_blank"">2408.03515</a>",,2024-12-11
On the Robustness of Malware Detectors to Adversarial Samples,"Muhammad Salman, Benjamin Zi Hao Zhao, Hassan Jameel Asghar, Muhammad Ikram, Sidharth Kaushik, Mohamed Ali Kaafar",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02310"" target=""_blank"">2408.02310</a>",,2024-12-11
Mitigating Malicious Attacks in Federated Learning via Confidence-aware Defense,"Qilei Li, Ahmed M. Abdelmoniem",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02813"" target=""_blank"">2408.02813</a>",,2024-12-11
SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models,"Muxi Diao, Rumei Li, Shiyang Liu, Guogang Liao, Jingang Wang, Xunliang Cai, Weiran Xu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02632"" target=""_blank"">2408.02632</a>",,2024-12-11
Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models,"Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, Haoyang Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02416"" target=""_blank"">2408.02416</a>","<a href=""https://github.com/liangzid/PromptExtractionEval"" target=""_blank"">liangzid</a>",2024-12-11
Pre-trained Encoder Inference: Revealing Upstream Encoders In Downstream Machine Learning Services,"Shaopeng Fu, Xuexue Sun, Ke Qing, Tianhang Zheng, Di Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02814"" target=""_blank"">2408.02814</a>","<a href=""https://github.com/fshp971/encoder-inference"" target=""_blank"">fshp971</a>",2024-12-11
Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models? (8%),"Mohammad Bahrami Karkevandi, Nishant Vishwamitra, Peyman Najafirad",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02651"" target=""_blank"">2408.02651</a>",,2024-12-11
RCDM: Enabling Robustness for Conditional Diffusion Model,"Weifeng Xu, Xiang Zhu, Xiaoyong Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02710"" target=""_blank"">2408.02710</a>",,2024-12-11
Compromising Embodied Agents with Contextual Backdoor Attacks,"Aishan Liu, Yuguang Zhou, Xianglong Liu, Tianyuan Zhang, Siyuan Liang, Jiakai Wang, Yanjun Pu, Tianlin Li, Junqi Zhang, Wenbo Zhou, Qing Guo, Dacheng Tao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02882"" target=""_blank"">2408.02882</a>",,2024-12-11
Practical Attacks against Black-box Code Completion Engines,"Slobodan Jenko, Jingxuan He, Niels MÃ¼ndler, Mark Vero, Martin Vechev",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02509"" target=""_blank"">2408.02509</a>",,2024-12-11
A Survey and Evaluation of Adversarial Attacks for Object Detection,"Khoi Nguyen Tiet Nguyen, Wenyu Zhang, Kangkang Lu, Yuhuan Wu, Xingjian Zheng, Hui Li Tan, Liangli Zhen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01934"" target=""_blank"">2408.01934</a>",,2024-12-11
AdvQDet: Detecting Query-Based Adversarial Attacks with Adversarial Contrastive Prompt Tuning,"Xin Wang, Kai Chen, Xingjun Ma, Zhineng Chen, Jingjing Chen, Yu-Gang Jiang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01978"" target=""_blank"">2408.01978</a>","<a href=""https://github.com/xinwong/AdvQDet"" target=""_blank"">xinwong</a>",2024-12-11
Label Augmentation for Neural Networks Robustness,"Fatemeh Amerehi, Patrick Healy",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01977"" target=""_blank"">2408.01977</a>",,2024-12-11
Top K Enhanced Reinforcement Learning Attacks on Heterogeneous Graph Node Classification,"Honglin Gao, Gaoxi Xiao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01964"" target=""_blank"">2408.01964</a>",,2024-12-11
Model Hijacking Attack in Federated Learning,"Zheng Li, Siyuan Wu, Ruichuan Chen, Paarijaat Aditya, Istemi Ekin Akkus, Manohar Vanga, Min Zhang, Hao Li, Yang Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02131"" target=""_blank"">2408.02131</a>",,2024-12-11
Robustness of Watermarking on Text-to-Image Diffusion Models,"Xiaodong Wu, Xiangman Li, Jianbing Ni",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02035"" target=""_blank"">2408.02035</a>",,2024-12-11
A Multi-task Adversarial Attack Against Face Authentication,"Hanrui Wang, Shuo Wang, Cunjian Chen, Massimo Tistarelli, Zhe Jin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08205"" target=""_blank"">2408.08205</a>",,2024-12-11
Constructing Adversarial Examples for Vertical Federated Learning: Optimal Client Corruption through Multi-Armed Bandit,"Duanyi Yao, Songze Li, Ye Xue, Jin Liu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04310"" target=""_blank"">2408.04310</a>",,2024-12-11
Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons,"Binbin Ding, Penghui Yang, Zeqing Ge, Shengjun Huang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08655"" target=""_blank"">2408.08655</a>",,2024-12-11
Protecting against simultaneous data poisoning attacks,"Neel Alex, Shoaib Ahmed Siddiqui, Amartya Sanyal, David Krueger",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13221"" target=""_blank"">2408.13221</a>",,2024-12-11
Surprisingly Fragile: Assessing and Addressing Prompt Instability in Multimodal Foundation Models,"Ian Stewart, Sameera Horawalavithana, Brendan Kennedy, Sai Munikoti, Karl Pazdernik",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14595"" target=""_blank"">2408.14595</a>",,2024-12-11
On the Robustness of Kolmogorov-Arnold Networks: An Adversarial Perspective,"Tal Alter, Raz Lapid, Moshe Sipper",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13809"" target=""_blank"">2408.13809</a>",,2024-12-11
RT-Attack: Jailbreaking Text-to-Image Models via Random Token,"Sensen Gao, Xiaojun Jia, Yihao Huang, Ranjie Duan, Jindong Gu, Yang Liu, Qing Guo",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13896"" target=""_blank"">2408.13896</a>",,2024-12-11
TF-Attack: Transferable and Fast Adversarial Attacks on Large Language Models,"Zelin Li, Kehai Chen, Lemao Liu, Xuefeng Bai, Mingming Yang, Yang Xiang, Min Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13985"" target=""_blank"">2408.13985</a>",,2024-12-11
Generalization of Graph Neural Networks is Robust to Model Mismatch,"Zhiyang Wang, Juan Cervino, Alejandro Ribeiro",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13878"" target=""_blank"">2408.13878</a>",,2024-12-11
Probing the Robustness of Vision-Language Pretrained Models: A Multimodal Adversarial Attack Approach,"Jiwei Guan, Tianyu Ding, Longbing Cao, Lei Pan, Chen Wang, Xi Zheng",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13461"" target=""_blank"">2408.13461</a>",,2024-12-11
Evaluating the Robustness of LiDAR-based 3D Obstacles Detection and Its Impacts on Autonomous Driving Systems,"Tri Minh Triet Pham, Bo Yang, Jinqiu Yang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13653"" target=""_blank"">2408.13653</a>",,2024-12-11
Dynamic Label Adversarial Training for Deep Learning Robustness Against Adversarial Attacks,"Zhenyu Liu, Haoran Duan, Huizhi Liang, Yang Long, Vaclav Snasel, Guiseppe Nicosia, Rajiv Ranjan, Varun Ojha",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13102"" target=""_blank"">2408.13102</a>",,2024-12-11
Toward Improving Synthetic Audio Spoofing Detection Robustness via Meta-Learning and Disentangled Training With Adversarial Examples,"Zhenyu Wang, John H. L. Hansen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13341"" target=""_blank"">2408.13341</a>",,2024-12-11
Disentangled Training with Adversarial Examples For Robust Small-footprint Keyword Spotting,"Zhenyu Wang, Li Wan, Biqiao Zhang, Yiteng Huang, Shang-Wen Li, Ming Sun, Xin Lei, Zhaojun Yang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13355"" target=""_blank"">2408.13355</a>",,2024-12-11
Enhancing Transferability of Adversarial Attacks with GE-AdvGAN+: A Comprehensive Framework for Gradient Editing,"Zhibo Jin, Jiayu Zhang, Zhiyu Zhu, Yuchen Zhang, Jiahao Huang, Jianlong Zhou, Fang Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12673"" target=""_blank"">2408.12673</a>","<a href=""https://github.com/GEAdvGANP"" target=""_blank"">github.com</a>",2024-12-11
PromptSmooth: Certifying Robustness of Medical Vision-Language Models via Prompt Learning,"Noor Hussein, Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.16769"" target=""_blank"">2408.16769</a>","<a href=""https://github.com/nhussein/promptsmooth"" target=""_blank"">nhussein</a>",2024-12-11
Leveraging Information Consistency in Frequency and Spatial Domain for Adversarial Attacks,"Zhibo Jin, Jiayu Zhang, Zhiyu Zhu, Xinyi Wang, Yiyun Huang, Huaming Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12670"" target=""_blank"">2408.12670</a>","<a href=""https://github.com/LMBTough/FSA"" target=""_blank"">LMBTough</a>",2024-12-11
MakeupAttack: Feature Space Black-box Backdoor Attack on Face Recognition via Makeup Transfer,"Ming Sun, Lihua Jing, Zixuan Zhu, Rui Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12312"" target=""_blank"">2408.12312</a>",,2024-12-11
BankTweak: Adversarial Attack against Multi-Object Trackers by Manipulating Feature Banks,"Woojin Shin, Donghwa Kang, Daejin Choi, Brent Kang, Jinkyu Lee, Hyeongboo Baek",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12727"" target=""_blank"">2408.12727</a>",,2024-12-11
On the Credibility of Backdoor Attacks Against Object Detectors in the Physical World,"Bao Gia Doan, Dang Quang Nguyen, Callum Lindquist, Paul Montague, Tamas Abraham, Vel Olivier De, Seyit Camtepe, Salil S. Kanhere, Ehsan Abbasnejad, Damith C. Ranasinghe",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12122"" target=""_blank"">2408.12122</a>",,2024-12-11
Quantifying Psychological Sophistication of Malicious Emails,"Theodore Longtchi, Rosana MontaÃ±ez Rodriguez, Kora Gwartney, Ekzhin Ear, David P. Azari, Christopher P. Kelley, Shouhuai Xu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12217"" target=""_blank"">2408.12217</a>",,2024-12-11
Is Generative AI the Next Tactical Cyber Weapon For Threat Actors? Unforeseen Implications of AI Generated Cyber Attacks,"Yusuf Usman, Aadesh Upadhyay, Prashnna Gyawali, Robin Chataut",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12806"" target=""_blank"">2408.12806</a>",,2024-12-11
VALE: A Multimodal Visual and Language Explanation Framework for Image Classifiers using eXplainable AI and Language Models,"Purushothaman Natarajan, Athira Nambiar",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12808"" target=""_blank"">2408.12808</a>",,2024-12-11
BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks on Large Language Models,"Yige Li, Hanxun Huang, Yunhan Zhao, Xingjun Ma, Jun Sun",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12798"" target=""_blank"">2408.12798</a>","<a href=""https://github.com/bboylyg/BackdoorLLM"" target=""_blank"">bboylyg</a>",2024-12-11
Query-Efficient Video Adversarial Attack with Stylized Logo,"Duoxun Tang, Yuxin Cao, Xi Xiao, Derui Wang, Sheng Wen, Tianqing Zhu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12099"" target=""_blank"">2408.12099</a>",,2024-12-11
Pixel Is Not A Barrier: An Effective Evasion Attack for Pixel-Domain Diffusion Models,"Chun-Yen Shih, Li-Xuan Peng, Jia-Wei Liao, Ernie Chu, Cheng-Fu Chou, Jun-Cheng Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11810"" target=""_blank"">2408.11810</a>",,2024-12-11
Investigating the Effectiveness of Bayesian Spam Filters in Detecting LLM-modified Spam Mails,"Malte Josten, Torben Weis",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14293"" target=""_blank"">2408.14293</a>",,2024-12-11
2D-Malafide: Adversarial Attacks Against Face Deepfake Detection Systems,"Chiara Galdi, Michele Panariello, Massimiliano Todisco, Nicholas Evans",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14143"" target=""_blank"">2408.14143</a>",,2024-12-11
First line of defense: A robust first layer mitigates adversarial attacks,"Janani Suresh, Nancy Nayak, Sheetal Kalyani",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11680"" target=""_blank"">2408.11680</a>","<a href=""https://github.com/janani-suresh-97/first-line-defence"" target=""_blank"">janani-suresh-97</a>",2024-12-11
Fusing Pruned and Backdoored Models: Optimal Transport-based Data-free Backdoor Mitigation,"Weilin Lin, Li Liu, Jianze Li, Hui Xiong",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15861"" target=""_blank"">2408.15861</a>",,2024-12-11
STEREO: Towards Adversarially Robust Concept Erasing from Text-to-Image Generation Models,"Koushik Srivatsan, Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.16807"" target=""_blank"">2408.16807</a>","<a href=""https://github.com/koushiksrivats/robust-concept-erasing"" target=""_blank"">koushiksrivats</a>",2024-12-11
SFR-GNN: Simple and Fast Robust GNNs against Structural Attacks,"Xing Ai, Guanyu Zhu, Yulin Zhu, Yu Zheng, Gaolei Li, Jianhua Li, Kai Zhou",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.16537"" target=""_blank"">2408.16537</a>",,2024-12-11
Evaluating Reliability in Medical DNNs: A Critical Analysis of Feature and Confidence-Based OOD Detection,"Harry Anthony, Konstantinos Kamnitsas",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.17337"" target=""_blank"">2408.17337</a>","<a href=""https://github.com/HarryAnthony/Evaluating_OOD_detection"" target=""_blank"">HarryAnthony</a>",2024-12-11
Instant Adversarial Purification with Adversarial Consistency Distillation,"Chun Tong Lei, Hon Ming Yam, Zhongliang Guo, Chun Pong Lau",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.17064"" target=""_blank"">2408.17064</a>",,2024-12-11
Analyzing Inference Privacy Risks Through Gradients in Machine Learning,"Zhuohang Li, Andrew Lowy, Jing Liu, Toshiaki Koike-Akino, Kieran Parsons, Bradley Malin, Ye Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.16913"" target=""_blank"">2408.16913</a>",,2024-12-11
"Tex-ViT: A Generalizable, Robust, Texture-based dual-branch cross-attention deepfake detector","Deepak Dagar, Dinesh Kumar Vishwakarma",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.16892"" target=""_blank"">2408.16892</a>",,2024-12-11
Evaluating Model Robustness Using Adaptive Sparse L0 Regularization,"Weiyou Liu, Zhenyang Li, Weitong Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15702"" target=""_blank"">2408.15702</a>",,2024-12-11
Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks? (75%),"Zhongjian Zhang, Xiao Wang, Huichi Zhou, Yue Yu, Mengmei Zhang, Cheng Yang, Chuan Shi",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08685"" target=""_blank"">2408.08685</a>",,2024-12-11
Network transferability of adversarial patches in real-time object detection,"Jens Bayer, Stefan Becker, David MÃ¼nch, Michael Arens",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15833"" target=""_blank"">2408.15833</a>",,2024-12-11
Defending Text-to-image Diffusion Models: Surprising Efficacy of Textual Perturbations Against Backdoor Attacks,"Oscar Chew, Po-Yi Lu, Jayden Lin, Hsuan-Tien Lin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15721"" target=""_blank"">2408.15721</a>","<a href=""https://github.com/oscarchew/t2i-backdoor-defense"" target=""_blank"">oscarchew</a>",2024-12-11
VFLIP: A Backdoor Defense for Vertical Federated Learning via Identification and Purification,"Yungi Cho, Woorim Han, Miseon Yu, Younghan Lee, Ho Bae, Yunheung Paek",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15591"" target=""_blank"">2408.15591</a>","<a href=""https://github.com/blingcho/VFLIP-esorics24"" target=""_blank"">blingcho</a>",2024-12-11
TART: Boosting Clean Accuracy Through Tangent Direction Guided Adversarial Training,"Bongsoo Yi, Rongjie Lai, Yao Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14728"" target=""_blank"">2408.14728</a>",,2024-12-11
FRACTURED-SORRY-Bench: Framework for Revealing Attacks in Conversational Turns Undermining Refusal Efficacy and Defenses over SORRY-Bench (Automated Multi-shot Jailbreaks),"Aman Priyanshu, Supriti Vijay",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.16163"" target=""_blank"">2408.16163</a>",,2024-12-11
Adversarial Attacks and Defenses in Multivariate Time-Series Forecasting for Smart and Connected Infrastructures,"Pooja Krishan, Rohan Mohapatra, Saptarshi Sengupta",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14875"" target=""_blank"">2408.14875</a>",,2024-12-11
Certified Causal Defense with Generalizable Robustness,"Yiran Qiao, Yu Yin, Chen Chen, Jing Ma",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15451"" target=""_blank"">2408.15451</a>",,2024-12-11
Improving Adversarial Robustness in Android Malware Detection by Reducing the Impact of Spurious Correlations,"Hamid Bostani, Zhengyu Zhao, Veelasha Moonsamy",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.16025"" target=""_blank"">2408.16025</a>",,2024-12-11
Adversarial Manhole: Challenging Monocular Depth Estimation and Semantic Segmentation Models with Patch Attack,"Naufal Suryanto, Andro Aprila Adiputra, Ahmada Yusril Kadiptya, Yongsu Kim, Howon Kim",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14879"" target=""_blank"">2408.14879</a>",,2024-12-11
LLM Defenses Are Not Robust to Multi-Turn Human Jailbreaks Yet,"Nathaniel Li, Ziwen Han, Ian Steneker, Willow Primack, Riley Goodside, Hugh Zhang, Zifan Wang, Cristina Menghini, Summer Yue",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15221"" target=""_blank"">2408.15221</a>",,2024-12-11
Investigating Coverage Criteria in Large Language Models: An In-Depth Study Through Jailbreak Attacks,"Shide Zhou, Tianlin Li, Kailong Wang, Yihao Huang, Ling Shi, Yang Liu, Haoyu Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15207"" target=""_blank"">2408.15207</a>",,2024-12-11
Detecting AI Flaws: Target-Driven Attacks on Internal Faults in Language Models,"Yuhao Du, Zhuo Li, Pengyu Cheng, Xiang Wan, Anningzhe Gao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14853"" target=""_blank"">2408.14853</a>",,2024-12-11
SpecGuard: Specification Aware Recovery for Robotic Autonomous Vehicles from Physical Attacks,"Pritam Dash, Ethan Chan, Karthik Pattabiraman",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15200"" target=""_blank"">2408.15200</a>",,2024-12-11
EmoAttack: Utilizing Emotional Voice Conversion for Speech Backdoor Attacks on Deep Speech Classification Models,"Wenhan Yao, Zedong XingXiarun Chen, Jia Liu, yongqiang He, Weiping Wen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15508"" target=""_blank"">2408.15508</a>",,2024-12-11
A Practical Trigger-Free Backdoor Attack on Neural Networks,"Jiahao Wang, Xianglong Zhang, Xiuzhen Cheng, Pengfei Hu, Guoming Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11444"" target=""_blank"">2408.11444</a>",,2024-12-11
Celtibero: Robust Layered Aggregation for Federated Learning,Borja Molina-Coronado,arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14240"" target=""_blank"">2408.14240</a>",,2024-12-11
Exploring Robustness of Visual State Space model against Backdoor Attacks,"Cheng-Yi Lee, Cheng-Chang Tsai, Chia-Mu Yu, Chun-Shien Lu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11679"" target=""_blank"">2408.11679</a>",,2024-12-11
DiffZOO: A Purely Query-Based Black-Box Attack for Red-teaming Text-to-Image Generative Model via Zeroth Order Optimization,"Pucheng Dang, Xing Hu, Dong Li, Rui Zhang, Qi Guo, Kaidi Xu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11071"" target=""_blank"">2408.11071</a>",,2024-12-11
Criticality Leveraged Adversarial Training (CLAT) for Boosted Performance via Parameter Efficiency,"Bhavna Gopal, Huanrui Yang, Jingyang Zhang, Mark Horton, Yiran Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10204"" target=""_blank"">2408.10204</a>",,2024-12-11
The Brittleness of AI-Generated Image Watermarking Techniques: Examining Their Robustness Against Visual Paraphrasing Attacks,"Niyar R Barman, Krish Sharma, Ashhar Aziz, Shashwat Bajpai, Shwetangshu Biswas, Vasu Sharma, Vinija Jain, Aman Chadha, Amit Sheth, Amitava Das",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10446"" target=""_blank"">2408.10446</a>",,2024-12-11
Transferring Backdoors between Large Language Models by Knowledge Distillation,"Pengzhou Cheng, Zongru Wu, Tianjie Ju, Wei Du, Zhuosheng Zhang Gongshen Liu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09878"" target=""_blank"">2408.09878</a>",,2024-12-11
Enhance Modality Robustness in Text-Centric Multimodal Alignment with Adversarial Prompting,"Yun-Da Tsai, Ting-Yu Yen, Keng-Te Liao, Shou-De Lin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09798"" target=""_blank"">2408.09798</a>",,2024-12-11
Perfectly Undetectable Reflection and Scaling False Data Injection Attacks via Affine Transformation on Mobile Robot Trajectory Tracking Control,"Jun Ueda, Hyukbin Kwon",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10177"" target=""_blank"">2408.10177</a>",,2024-12-11
Enhancing Adversarial Transferability with Adversarial Weight Tuning,"Jiahao Chen, Zhou Feng, Rui Zeng, Yuwen Pu, Chunyi Zhou, Yi Jiang, Yuyou Gan, Jinbao Li, Shouling Ji, Shouling_Ji",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09469"" target=""_blank"">2408.09469</a>",,2024-12-11
Regularization for Adversarial Robust Learning,"Jie Wang, Rui Gao, Yao Xie",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09672"" target=""_blank"">2408.09672</a>",,2024-12-11
Adversarial Attacked Teacher for Unsupervised Domain Adaptive Object Detection,"Kaiwen Wang, Yinzhe Shen, Martin Lauer",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09431"" target=""_blank"">2408.09431</a>",,2024-12-11
Global BGP Attacks that Evade Route Monitoring,"Henry Birge-Lee, Maria Apostolaki, Jennifer Rexford",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09622"" target=""_blank"">2408.09622</a>",,2024-12-11
Training Verifiably Robust Agents Using Set-Based Reinforcement Learning,"Manuel Wendl, Lukas Koller, Tobias Ladner, Matthias Althoff",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09112"" target=""_blank"">2408.09112</a>",,2024-12-11
PADetBench: Towards Benchmarking Physical Attacks against Object Detection,"Jiawei Lian, Jianhong Pan, Lefan Wang, Yi Wang, Lap-Pui Chau, Shaohui Mei",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09181"" target=""_blank"">2408.09181</a>","<a href=""https://github.com/JiaweiLian/Benchmarking_Physical_Attack"" target=""_blank"">JiaweiLian</a>",2024-12-11
Detecting Adversarial Attacks in Semantic Segmentation via Uncertainty Estimation: A Deep Analysis,"Kira Maag, Roman Resner, Asja Fischer",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10021"" target=""_blank"">2408.10021</a>",,2024-12-11
Malacopula: adversarial automatic speaker verification attacks using a neural-based generalised Hammerstein model,"Massimiliano Todisco, Michele Panariello, Xin Wang, HÃ©ctor Delgado, Kong Aik Lee, Nicholas Evans",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09300"" target=""_blank"">2408.09300</a>",,2024-12-11
BaThe: Defense against the Jailbreak Attack in Multimodal Large Language Models by Treating Harmful Instruction as Backdoor Trigger,"Yulin Chen, Haoran Li, Zihao Zheng, Yangqiu Song",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09093"" target=""_blank"">2408.09093</a>",,2024-12-11
Characterizing and Evaluating the Reliability of LLMs against Jailbreak Attacks,"Kexin Chen, Yi Liu, Dongxia Wang, Jiaying Chen, Wenhai Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09326"" target=""_blank"">2408.09326</a>",,2024-12-11
PREMAP: A Unifying PREiMage APproximation Framework for Neural Networks,"Xiyue Zhang, Benjie Wang, Marta Kwiatkowska, Huan Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09262"" target=""_blank"">2408.09262</a>",,2024-12-11
Out-of-distribution materials property prediction using adversarial learning based fine-tuning,"Qinyang Li, Nicholas Miklaucic, Jianjun Hu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09297"" target=""_blank"">2408.09297</a>",,2024-12-11
"Ask, Attend, Attack: A Effective Decision-Based Black-Box Targeted Attack for Image-to-Text Models","Qingyuan Zeng, Zhenzhong Wang, Yiu-ming Cheung, Min Jiang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08989"" target=""_blank"">2408.08989</a>",,2024-12-11
Visual-Friendly Concept Protection via Selective Adversarial Perturbations,"Xiaoyue Mi, Fan Tang, Juan Cao, Peng Li, Yang Liu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08518"" target=""_blank"">2408.08518</a>",,2024-12-11
"Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks","Yiyi Chen, Russa Biswas, Heather Lent, Johannes Bjerva",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11749"" target=""_blank"">2408.11749</a>",,2024-12-11
LEVIS: Large Exact Verifiable Input Spaces for Neural Networks,"Mohamad Fares El Hajj Chehade, Brian Wesley Bell, Russell Bent, Hao Zhu, Wenting Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08824"" target=""_blank"">2408.08824</a>",,2024-12-11
Towards Physical World Backdoor Attacks against Skeleton Action Recognition,"Qichen Zheng, Yi Yu, Siyuan Yang, Jun Liu, Kwok-Yan Lam, Alex Kot",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08671"" target=""_blank"">2408.08671</a>","<a href=""https://qichenzheng.github.io/psba-website"" target=""_blank"">qichenzheng.github.io</a>",2024-12-11
Segment-Anything Models Achieve Zero-shot Robustness in Autonomous Driving,"Jun Yan, Pengyu Wang, Danni Wang, Weiquan Huang, Daniel Watzenig, Huilin Yin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09839"" target=""_blank"">2408.09839</a>","<a href=""https://github.com/momo1986/robust_sam_iv"" target=""_blank"">momo1986</a>",2024-12-11
GANPrompt: Enhancing Robustness in LLM-Based Recommendations with GAN-Enhanced Diversity Prompts,"Xinyu Li, Chuang Zhao, Hongke Zhao, Likang Wu, Ming HE",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09671"" target=""_blank"">2408.09671</a>",,2024-12-11
Robust Image Classification: Defensive Strategies against FGSM and PGD Adversarial Attacks,"Hetvi Waghela, Jaydip Sen, Sneha Rakshit",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13274"" target=""_blank"">2408.13274</a>",,2024-12-11
A Grey-box Attack against Latent Diffusion Model-based Image Editing by Posterior Collapse,"Zhongliang Guo, Lei Fang, Jingyu Lin, Yifei Qian, Shuai Zhao, Zeyu Wang, Junhao Dong, Cunjian Chen, Ognjen ArandjeloviÄ, Chun Pong Lau",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10901"" target=""_blank"">2408.10901</a>",,2024-12-11
Latent Feature and Attention Dual Erasure Attack against Multi-View Diffusion Models for 3D Assets Protection,"Jingwei Sun, Xuchong Zhang, Changfeng Sun, Qicheng Bai, Hongbin Sun",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11408"" target=""_blank"">2408.11408</a>",,2024-12-11
Large Language Models are Good Attackers: Efficient and Stealthy Textual Backdoor Attacks,"Ziqiang Li, Yueqi Zeng, Pengfei Xia, Lei Liu, Zhangjie Fu, Bin Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11587"" target=""_blank"">2408.11587</a>",,2024-12-11
GAIM: Attacking Graph Neural Networks via Adversarial Influence Maximization,"Xiaodong Yang, Xiaoting Li, Huiyuan Chen, Yiwei Cai",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10948"" target=""_blank"">2408.10948</a>",,2024-12-11
Learning Randomized Algorithms with Transformers,"Oswald Johannes von, Seijin Kobayashi, Yassir Akram, Angelika Steger",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10818"" target=""_blank"">2408.10818</a>",,2024-12-11
Correlation Analysis of Adversarial Attack in Time Series Classification,"Zhengyang Li, Wenhao Liang, Chang Dong, Weitong Chen, Dong Huang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11264"" target=""_blank"">2408.11264</a>",,2024-12-11
Privacy-preserving Universal Adversarial Defense for Black-box Models,"Qiao Li, Cong Wu, Jing Chen, Zijun Zhang, Kun He, Ruiying Du, Xinxin Wang, Qingchuang Zhao, Yang Liu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10647"" target=""_blank"">2408.10647</a>",,2024-12-11
MsMemoryGAN: A Multi-scale Memory GAN for Palm-vein Adversarial Purification,"Huafeng Qin, Yuming Fu, Huiyan Zhang, Mounim A. El-Yacoubi, Xinbo Gao, Qun Song, Jun Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10694"" target=""_blank"">2408.10694</a>",,2024-12-11
Revisiting Min-Max Optimization Problem in Adversarial Training,"Sina Hajer Ahmadi, Hassan Bahrami",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11218"" target=""_blank"">2408.11218</a>",,2024-12-11
Iterative Window Mean Filter: Thwarting Diffusion-based Adversarial Purification,"Hanrui Wang, Ruoxi Sun, Cunjian Chen, Minhui Xue, Lay-Ki Soon, Shuo Wang, Zhe Jin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10673"" target=""_blank"">2408.10673</a>",,2024-12-11
Adversarial Attack for Explanation Robustness of Rationalization Models,"Yuankai Zhang, Lingxiao Kong, Haozhao Wang, Ruixuan Li, Jun Wang, Yuhua Li, Wei Liu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10795"" target=""_blank"">2408.10795</a>",,2024-12-11
Towards Robust Knowledge Unlearning: An Adversarial Framework for Assessing and Improving Unlearning Robustness in Large Language Models,"Hongbang Yuan, Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10682"" target=""_blank"">2408.10682</a>",,2024-12-11
Prompt-Agnostic Adversarial Perturbation for Customized Diffusion Models,"Cong Wan, Yuhang He, Xiang Song, Yihong Gong",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10571"" target=""_blank"">2408.10571</a>",,2024-12-11
Security Assessment of Hierarchical Federated Deep Learning,"D Alqattan, R Sun, H Liang, G Nicosia, V Snasel, R Ranjan, V Ojha",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10752"" target=""_blank"">2408.10752</a>",,2024-12-11
MEGen: Generative Backdoor in Large Language Models via Model Editing,"Jiyang Qiu, Xinbei Ma, Zhuosheng Zhang, Hai Zhao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10722"" target=""_blank"">2408.10722</a>",,2024-12-11
Ferret: Faster and Effective Automated Red Teaming with Reward-Based Scoring Technique,"Tej Deep Pala, Vernon Y. H. Toh, Rishabh Bhardwaj, Soujanya Poria",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10701"" target=""_blank"">2408.10701</a>","<a href=""https://github.com/declare-lab/ferret"" target=""_blank"">declare-lab</a>",2024-12-11
Security Attacks on LLM-based Code Completion Tools,"Wen Cheng, Ke Sun, Xinyu Zhang, Wei Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11006"" target=""_blank"">2408.11006</a>",,2024-12-11
Makeup-Guided Facial Privacy Protection via Untrained Neural Network Priors,"Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12387"" target=""_blank"">2408.12387</a>","<a href=""https://github.com/fahadshamshad/deep-facial-privacy-prior"" target=""_blank"">fahadshamshad</a>",2024-12-11
EEG-Defender: Defending against Jailbreak through Early Exit Generation of Large Language Models,"Chongwen Zhao, Zhihao Dou, Kaizhu Huang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11308"" target=""_blank"">2408.11308</a>",,2024-12-11
Accelerating the Surrogate Retraining for Poisoning Attacks against Recommender Systems,"Yunfan Wu, Qi Cao, Shuchang Tao, Kaike Zhang, Fei Sun, Huawei Shen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10666"" target=""_blank"">2408.10666</a>",,2024-12-11
Improving Out-of-Distribution Data Handling and Corruption Resistance via Modern Hopfield Networks,"Saleh Sargolzaei, Luis Rueda",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11309"" target=""_blank"">2408.11309</a>","<a href=""https://github.com/salehsargolzaee/Hopfield-integrated-test"" target=""_blank"">salehsargolzaee</a>",2024-12-11
Unlocking Adversarial Suffix Optimization Without Affirmative Phrases: Efficient Black-box Jailbreaking via LLM as Optimizer,"Weipeng Jiang, Zhenting Wang, Juan Zhai, Shiqing Ma, Zhengyu Zhao, Chao Shen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11313"" target=""_blank"">2408.11313</a>",,2024-12-11
Distribution System Reconfiguration to Mitigate Load Altering Attacks via Stackelberg Games,"Sajjad Maleki, Subhash Lakshminarayana, Charalambos Konstantinou, E. Veronica Belmaga",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07065"" target=""_blank"">2407.07065</a>",,2024-12-11
Exposing Privacy Gaps: Membership Inference Attack on Preference Data for LLM Alignment,"Qizhang Feng, Siva Rajesh Kasa, Hyokun Yun, Choon Hui Teo, Sravan Babu Bodapati",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06443"" target=""_blank"">2407.06443</a>",,2024-12-11
Non-Robust Features are Not Always Useful in One-Class Classification,"Matthew Lau, Haoran Wang, Alec Helbling, Matthew Hul, ShengYun Peng, Martin Andreoni, Willian T. Lunardi, Wenke Lee",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06372"" target=""_blank"">2407.06372</a>",,2024-12-11
Shedding More Light on Robust Classifiers under the lens of Energy-based Models,"Mujtaba Hussain Mirza, Maria Rosaria Briglia, Senad Beadini, Iacopo Masi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06315"" target=""_blank"">2407.06315</a>","<a href=""http://github.com/OmnAI-Lab/Robust-Classifiers-under-the-lens-of-EBM/"" target=""_blank"">Robust-Classifiers-under-the-lens-of-EBM</a>",2024-12-11
Performance Evaluation of Knowledge Graph Embedding Approaches under Non-adversarial Attacks,"Sourabh Kapoor, Arnab Sharma, Michael RÃ¶der, Caglar Demir, Axel-Cyrille Ngonga Ngomo",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06855"" target=""_blank"">2407.06855</a>",,2024-12-11
Exploring the Causality of End-to-End Autonomous Driving,"Jiankun Li, Hao Li, Jiangjiang Liu, Zhikang Zou, Xiaoqing Ye, Fan Wang, Jizhou Huang, Hua Wu, Haifeng Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06546"" target=""_blank"">2407.06546</a>","<a href=""https://github.com/bdvisl/DriveInsight"" target=""_blank"">bdvisl</a>",2024-12-11
The Quantum Imitation Game: Reverse Engineering of Quantum Machine Learning Models,"Archisman Ghosh, Swaroop Ghosh",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07237"" target=""_blank"">2407.07237</a>",,2024-12-11
Attack GAN (AGAN ): A new Security Evaluation Tool for Perceptual Encryption,"Umesh Kashyap, Sudev Kumar Padhi, Sk. Subidh Ali",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06570"" target=""_blank"">2407.06570</a>",,2024-12-11
Gradient Diffusion: A Perturbation-Resilient Gradient Leakage Attack,"Xuan Liu, Siqi Cai, Qihua Zhou, Song Guo, Ruibin Li, Kaiwei Lin",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.05285"" target=""_blank"">2407.05285</a>",,2024-12-11
Robust Neural Information Retrieval: An Adversarial and Out-of-distribution Perspective,"Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Rijke Maarten de, Yixing Fan, Xueqi Cheng",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06992"" target=""_blank"">2407.06992</a>","<a href=""https://sigir2024-robust-information-retrieval.github.io"" target=""_blank""></a>",2024-12-11
Rethinking Targeted Adversarial Attacks For Neural Machine Translation,"Junjie Wu, Lemao Liu, Wei Bi, Dit-Yan Yeung",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.05319"" target=""_blank"">2407.05319</a>","<a href=""https://github.com/wujunjie1998/TWGA"" target=""_blank"">wujunjie1998</a>",2024-12-11
Controlling Whisper: Universal Acoustic Adversarial Attacks to Control Speech Foundation Models,"Vyas Raina, Mark Gales",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04482"" target=""_blank"">2407.04482</a>",,2024-12-11
An accurate detection is not all you need to combat label noise in web-noisy datasets,"Paul Albert, Jack Valmadre, Eric Arazo, Tarun Krishna, Noel E. O'Connor, Kevin McGuinness",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.05528"" target=""_blank"">2407.05528</a>",,2024-12-11
Detecting new obfuscated malware variants: A lightweight and interpretable machine learning approach,"Oladipo A. Madamidola, Felix Ngobigha, Adnane Ez-zizi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07918"" target=""_blank"">2407.07918</a>",,2024-12-11
Evolutionary Trigger Detection and Lightweight Model Repair Based Backdoor Defense,"Qi Zhou, Zipeng Ye, Yubo Tang, Wenjian Luo, Yuhui Shi, Yan Jia",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.05396"" target=""_blank"">2407.05396</a>",,2024-12-11
A Novel Bifurcation Method for Observation Perturbation Attacks on Reinforcement Learning Agents: Load Altering Attacks on a Cyber Physical Power System,"Kiernan Broda-Milian, Ranwa Al-Mallah, Hanane Dagdougui",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.05182"" target=""_blank"">2407.05182</a>",,2024-12-11
Releasing Malevolence from Benevolence: The Menace of Benign Data on Machine Unlearning,"Binhao Ma, Tianhang Zheng, Hongsheng Hu, Di Wang, Shuo Wang, Zhongjie Ba, Zhan Qin, Kui Ren",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.05112"" target=""_blank"">2407.05112</a>",,2024-12-11
GCON: Differentially Private Graph Convolutional Network via Objective Perturbation,"Jianxin Wei, Yizheng Zhu, Xiaokui Xiao, Ergute Bao, Yin Yang, Kuntai Cai, Beng Chin Ooi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.05034"" target=""_blank"">2407.05034</a>",,2024-12-11
Remembering Everything Makes You Vulnerable: A Limelight on Machine Unlearning for Personalized Healthcare Sector,"Ahan Chatterjee, Sai Anirudh Aryasomayajula, Rajat Chaudhari, Subhajit Paul, Vishwa Mohan Singh",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04589"" target=""_blank"">2407.04589</a>",,2024-12-11
Jailbreak Attacks and Defenses Against Large Language Models: A Survey,"Sibo Yi, Yule Liu, Zhen Sun, Tianshuo Cong, Xinlei He, Jiaxing Song, Ke Xu, Qi Li",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04295"" target=""_blank"">2407.04295</a>",,2024-12-11
Self-Supervised Representation Learning for Adversarial Attack Detection,"Yi Li, Plamen Angelov, Neeraj Suri",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04382"" target=""_blank"">2407.04382</a>",,2024-12-11
Improving the Transferability of Adversarial Examples by Feature Augmentation,"Donghua Wang, Wen Yao, Tingsong Jiang, Xiaohu Zheng, Junqi Wu, Xiaoqian Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06714"" target=""_blank"">2407.06714</a>",,2024-12-11
On Evaluating The Performance of Watermarked Machine-Generated Texts Under Adversarial Attacks,"Zesen Liu, Tianshuo Cong, Xinlei He, Qi Li",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04794"" target=""_blank"">2407.04794</a>",,2024-12-11
Tracing Back the Malicious Clients in Poisoning Attacks to Federated Learning,"Yuqi Jia, Minghong Fang, Hongbin Liu, Jinghuai Zhang, Neil Zhenqiang Gong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07221"" target=""_blank"">2407.07221</a>",,2024-12-11
Rethinking the Threat and Accessibility of Adversarial Attacks against Face Recognition Systems,"Yuxin Cao, Yumeng Zhu, Derui Wang, Sheng Wen, Minhui Xue, Jin Lu, Hao Ge",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08514"" target=""_blank"">2407.08514</a>",,2024-12-11
Countermeasures Against Adversarial Examples in Radio Signal Classification,"Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Basil AsSadhan, Fabio Roli",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06796"" target=""_blank"">2407.06796</a>",,2024-12-11
DLOVE: A new Security Evaluation Tool for Deep Learning Based Watermarking Techniques,"Sudev Kumar Padhi, Sk. Subidh Ali",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06552"" target=""_blank"">2407.06552</a>",,2024-12-11
Refusing Safe Prompts for Multi-modal Large Language Models,"Zedian Shao, Hongbin Liu, Yuepeng Hu, Neil Zhenqiang Gong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09050"" target=""_blank"">2407.09050</a>","<a href=""https://github.com/Sadcardation/MLLM-Refusal"" target=""_blank"">Sadcardation</a>",2024-12-11
Security Matrix for Multimodal Agents on Mobile Devices: A Systematic and Proof of Concept Study,"Yulong Yang, Xinshan Yang, Shuaidong Li, Chenhao Lin, Zhengyu Zhao, Chao Shen, Tianwei Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09295"" target=""_blank"">2407.09295</a>",,2024-12-11
MaPPing Your Model: Assessing the Impact of Adversarial Attacks on LLM-based Programming Assistants,"John Heibel, Daniel Lowd",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11072"" target=""_blank"">2407.11072</a>",,2024-12-11
BoBa: Boosting Backdoor Detection through Data Distribution Inference in Federated Learning,"Ning Wang, Shanghao Shi, Yang Xiao, Yimin Chen, Y. Thomas Hou, Wenjing Lou",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09658"" target=""_blank"">2407.09658</a>",,2024-12-11
Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training,"Youliang Yuan, Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Jiahao Xu, Tian Liang, Pinjia He, Zhaopeng Tu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09121"" target=""_blank"">2407.09121</a>","<a href=""https://github.com/RobustNLP/DeRTa"" target=""_blank"">RobustNLP</a>",2024-12-11
Boosting Adversarial Transferability for Skeleton-based Action Recognition via Exploring the Model Posterior Space,"Yunfeng Diao, Baiqi Wu, Ruixuan Zhang, Xun Yang, Meng Wang, He Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08572"" target=""_blank"">2407.08572</a>",,2024-12-11
HO-FMN: Hyperparameter Optimization for Fast Minimum-Norm Attacks,"Raffaele Mura, Giuseppe Floris, Luca Scionis, Giorgio Piras, Maura Pintor, Ambra Demontis, Giorgio Giacinto, Battista Biggio, Fabio Roli",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08806"" target=""_blank"">2407.08806</a>","<a href=""https://github.com/pralab/HO-FMN"" target=""_blank"">pralab</a>",2024-12-11
DeCE: Deceptive Cross-Entropy Loss Designed for Defending Backdoor Attacks,"Guang Yang, Yu Zhou, Xiang Chen, Xiangyu Zhang, Terry Yue Zhuo, David Lo, Taolue Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08956"" target=""_blank"">2407.08956</a>",,2024-12-11
How to beat a Bayesian adversary,"Zihan Ding, Kexin Jin, Jonas Latz, Chenguang Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08678"" target=""_blank"">2407.08678</a>",,2024-12-11
Soft Prompts Go Hard: Steering Visual Language Models with Hidden Meta-Instructions,"Tingwei Zhang, Collin Zhang, John X. Morris, Eugene Bagdasarian, Vitaly Shmatikov",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08970"" target=""_blank"">2407.08970</a>",,2024-12-11
DART: A Solution for Decentralized Federated Learning Model Robustness Analysis,"Chao Feng, Alberto Huertas CeldrÃ¡n, der Assen Jan von, Enrique TomÃ¡s MartÃ­nez BeltrÃ¡n, GÃ©rÃ´me Bovet, Burkhard Stiller",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08652"" target=""_blank"">2407.08652</a>",,2024-12-11
Quantitative Evaluation of the Saliency Map for Alzheimer's Disease Classifier with Anatomical Segmentation,"Yihan Zhang, Xuanshuo Zhang, Wei Wu, Haohan Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08546"" target=""_blank"">2407.08546</a>",,2024-12-11
Enhancing Privacy of Spatiotemporal Federated Learning against Gradient Inversion Attacks,"Lele Zheng, Yang Cao, Renhe Jiang, Kenjiro Taura, Yulong Shen, Sheng Li, Masatoshi Yoshikawa",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08529"" target=""_blank"">2407.08529</a>",,2024-12-11
Are Large Language Models Really Bias-Free? Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation,"Riccardo Cantini, Giada Cosenza, Alessio Orsino, Domenico Talia",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08441"" target=""_blank"">2407.08441</a>",,2024-12-11
Deep Learning for Network Anomaly Detection under Data Contamination: Evaluating Robustness and Mitigating Performance Degradation,"D'Jeff K. Nkashama, Jordan Masakuna FÃ©licien, Arian Soltani, Jean-Charles Verdier, Pierre-Martin Tardif, Marc Frappier, Froduald Kabanza",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08838"" target=""_blank"">2407.08838</a>",,2024-12-11
Adversarial Attacks and Defenses on Text-to-Image Diffusion Models: A Survey,"Chenyu Zhang, Mingwang Hu, Wenhui Li, Lanjun Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15861"" target=""_blank"">2407.15861</a>","<a href=""https://github.com/datar001/Awesome-AD-on-T2IDM"" target=""_blank"">datar001</a>",2024-12-11
"A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends","Daizong Liu, Mingyu Yang, Xiaoye Qu, Pan Zhou, Wei Hu, Yu Cheng",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07403"" target=""_blank"">2407.07403</a>","<a href=""https://github.com/liudaizong/Awesome-LVLM-Attack"" target=""_blank"">liudaizong</a>",2024-12-11
Model-agnostic clean-label backdoor mitigation in cybersecurity environments,"Giorgio Severi, Simona Boboila, John Holodnak, Kendra Kratkiewicz, Rauf Izmailov, Lucia Michael J. De, Alina Oprea",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08159"" target=""_blank"">2407.08159</a>",,2024-12-11
Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities,"Tianjie Ju, Yiting Wang, Xinbei Ma, Pengzhou Cheng, Haodong Zhao, Yulong Wang, Lifeng Liu, Jian Xie, Zhuosheng Zhang, Gongshen Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07791"" target=""_blank"">2407.07791</a>",,2024-12-11
Invisible Optical Adversarial Stripes on Traffic Sign against Autonomous Vehicles,"Dongfang Guo, Yuting Wu, Yimin Dai, Pengfei Zhou, Xin Lou, Rui Tan",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07510"" target=""_blank"">2407.07510</a>",,2024-12-11
"A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities","Arastoo Zibaeirad, Farnoosh Koleini, Shengping Bi, Tao Hou, Tao Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07966"" target=""_blank"">2407.07966</a>",,2024-12-11
Was it Slander? Towards Exact Inversion of Generative Language Models,"Adrians Skapars, Edoardo Manino, Youcheng Sun, Lucas C. Cordeiro",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11059"" target=""_blank"">2407.11059</a>",,2024-12-11
CHILLI: A data context-aware perturbation method for XAI,"Saif Anwar, Nathan Griffiths, Abhir Bhalerao, Thomas Popham",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07521"" target=""_blank"">2407.07521</a>",,2024-12-11
A Hybrid Training-time and Run-time Defense Against Adversarial Attacks in Modulation Classification,"Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Guisheng Liao, Ambra Demontis, Fabio Roli",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06807"" target=""_blank"">2407.06807</a>",,2024-12-11
Universal Multi-view Black-box Attack against Object Detectors via Layout Optimization,"Donghua Wang, Wen Yao, Tingsong Jiang, Chao Li, Xiaoqian Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06688"" target=""_blank"">2407.06688</a>",,2024-12-11
Late Breaking Results: Fortifying Neural Networks: Safeguarding Against Adversarial Attacks with Stochastic Computing,"Faeze S. Banitaba, Sercan Aygun, M. Hassan Najafi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04861"" target=""_blank"">2407.04861</a>",,2024-12-11
Unaligning Everything: Or Aligning Any Text to Any Image in Multimodal Models,"Shaeke Salman, Md Montasir Bin Shams, Xiuwen Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01157"" target=""_blank"">2407.01157</a>",,2024-12-11
Regulating Model Reliance on Non-Robust Features by Smoothing Input Marginal Density,"Peiyu Yang, Naveed Akhtar, Mubarak Shah, Ajmal Mian",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04370"" target=""_blank"">2407.04370</a>",,2024-12-11
Formal Verification of Object Detection,"Avraham Raviv, Yizhak Y. Elboher, Michelle Aluf-Medina, Yael Leibovich Weiss, Omer Cohen, Roy Assa, Guy Katz, Hillel Kugler",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01295"" target=""_blank"">2407.01295</a>",,2024-12-11
Light-weight Fine-tuning Method for Defending Adversarial Noise in Pre-trained Medical Vision-Language Models,"Xu Han, Linghao Jin, Xuezhe Ma, Xiaofeng Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02716"" target=""_blank"">2407.02716</a>",,2024-12-11
Parameter Matching Attack: Enhancing Practical Applicability of Availability Attacks,"Yu Zhe, Jun Sakuma",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02437"" target=""_blank"">2407.02437</a>",,2024-12-11
On the Robustness of Graph Reduction Against GNN Backdoor,"Yuxuan Zhu, Michael Mandulak, Kerui Wu, George Slota, Yuseok Jeon, Ka-Ho Chow, Lei Yu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02431"" target=""_blank"">2407.02431</a>",,2024-12-11
MALT Powers Up Adversarial Attacks,"Odelia Melamed, Gilad Yehudai, Adi Shamir",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02240"" target=""_blank"">2407.02240</a>",,2024-12-11
Towards More Realistic Extraction Attacks: An Adversarial Perspective,"Yash More, Prakhar Ganesh, Golnoosh Farnadi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02596"" target=""_blank"">2407.02596</a>",,2024-12-11
Face Reconstruction Transfer Attack as Out-of-Distribution Generalization,"Yoon Gyo Jung, Jaewoo Park, Xingbo Dong, Hojin Park, Andrew Beng Jin Teoh, Octavia Camps",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02403"" target=""_blank"">2407.02403</a>",,2024-12-11
Robust ADAS: Enhancing Robustness of Machine Learning-based Advanced Driver Assistance Systems for Adverse Weather,"Muhammad Zaeem Shahzad, Muhammad Abdullah Hanif, Muhammad Shafique",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02581"" target=""_blank"">2407.02581</a>",,2024-12-11
Multi-View Black-Box Physical Attacks on Infrared Pedestrian Detectors Using Adversarial Infrared Grid,"Kalibinuer Tiliwalidi, Chengyin Hu, Weiwen Shi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01168"" target=""_blank"">2407.01168</a>",,2024-12-11
DeepiSign-G: Generic Watermark to Stamp Hidden DNN Parameters for Self-contained Tracking,"Alsharif Abuadbba, Nicholas Rhodes, Kristen Moore, Bushra Sabir, Shuo Wang, Yansong Gao",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01260"" target=""_blank"">2407.01260</a>",,2024-12-11
Looking From the Future: Multi-order Iterations Can Enhance Adversarial Attack Transferability,"Zijian Ying, Qianmu Li, Tao Wang, Zhichao Lian, Shunmei Meng, Xuyun Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01925"" target=""_blank"">2407.01925</a>",,2024-12-11
QUEEN: Query Unlearning against Model Extraction,"Huajie Chen, Tianqing Zhu, Lefeng Zhang, Bo Liu, Derui Wang, Wanlei Zhou, Minhui Xue",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01251"" target=""_blank"">2407.01251</a>",,2024-12-11
SoP: Unlock the Power of Social Facilitation for Automatic Jailbreak Attack,"Yan Yang, Zeguan Xiao, Xin Lu, Hongru Wang, Hailiang Huang, Guanhua Chen, Yun Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01902"" target=""_blank"">2407.01902</a>","<a href=""https://github.com/Yang-Yan-Yang-Yan/SoP"" target=""_blank"">Yang-Yan-Yang-Yan</a>",2024-12-11
Adversarial Magnification to Deceive Deepfake Detection through Super Resolution,"Davide Alessandro Coccomini, Roberto Caldelli, Giuseppe Amato, Fabrizio Falchi, Claudio Gennaro",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02670"" target=""_blank"">2407.02670</a>","<a href=""https://github.com/davide-coccomini/Adversarial-Magnification-to-Deceive-Deepfake-Detection-through-Super-Resolution"" target=""_blank"">davide-coccomini</a>",2024-12-11
Securing Distributed Network Digital Twin Systems Against Model Poisoning Attacks,"Zifan Zhang, Minghong Fang, Mingzhe Chen, Gaolei Li, Xi Lin, Yuchen Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01917"" target=""_blank"">2407.01917</a>",,2024-12-11
A Fingerprint for Large Language Models,"Zhiguang Yang, Hanzhou Wu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01235"" target=""_blank"">2407.01235</a>",,2024-12-11
Unveiling the Unseen: Exploring Whitebox Membership Inference through the Lens of Explainability,"Chenxi Li, Abhinav Kumar, Zhen Guo, Jie Hou, Reza Tourani",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01306"" target=""_blank"">2407.01306</a>",,2024-12-11
Deep Adversarial Defense Against Multilevel-Lp Attacks,"Ren Wang, Yuxuan Li, Alfred Hero",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09251"" target=""_blank"">2407.09251</a>",,2024-12-11
Learning Robust 3D Representation from CLIP via Dual Denoising,"Shuqing Luo, Bowen Qu, Wei Gao",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.00905"" target=""_blank"">2407.00905</a>","<a href=""https://github.com/luoshuqing2001/Dual_Denoising"" target=""_blank"">luoshuqing2001</a>",2024-12-11
Consistency Purification: Effective and Efficient Diffusion Purification towards Certified Robustness,"Yiquan Li, Zhongzhu Chen, Kun Jin, Jiongxiao Wang, Bo Li, Chaowei Xiao",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.00623"" target=""_blank"">2407.00623</a>",,2024-12-11
UWBAD: Towards Effective and Imperceptible Jamming Attacks Against UWB Ranging Systems with COTS Chips,"Yuqiao Yang, Zhongjie Wu, Yongzhao Zhang, Ting Chen, Jun Li, Jie Yang, Wenhao Liu, Xiaosong Zhang, Ruicong Shi, Jingwei Li, Yu Jiang, Zhuo Su",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.00682"" target=""_blank"">2407.00682</a>",,2024-12-11
Query-Efficient Hard-Label Black-Box Attack against Vision Transformers,"Chao Zhou, Xiaowen Shi, Yuan-Gen Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.00389"" target=""_blank"">2407.00389</a>",,2024-12-11
DiffuseDef: Improved Robustness to Adversarial Attacks,"Zhenhao Li, Marek Rei, Lucia Specia",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.00248"" target=""_blank"">2407.00248</a>",,2024-12-11
On Discrete Prompt Optimization for Diffusion Models,"Ruochen Wang, Ting Liu, Cho-Jui Hsieh, Boqing Gong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01606"" target=""_blank"">2407.01606</a>",,2024-12-11
Logicbreaks: A Framework for Understanding Subversion of Rule-based Inference,"Anton Xue, Avishree Khare, Rajeev Alur, Surbhi Goel, Eric Wong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.00075"" target=""_blank"">2407.00075</a>",,2024-12-11
Breach By A Thousand Leaks: Unsafe Information Leakage in `Safe' AI Responses,"David Glukhov, Ziwen Han, Ilia Shumailov, Vardan Papyan, Nicolas Papernot",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02551"" target=""_blank"">2407.02551</a>",,2024-12-11
EvolBA: Evolutionary Boundary Attack under Hard-label Black Box condition,"Ayane Tajima, Satoshi Ono",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02248"" target=""_blank"">2407.02248</a>",,2024-12-11
Data Poisoning Attacks in Intelligent Transportation Systems: A Survey,"Feilong Wang, Xin Wang, Xuegang Ban",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15855"" target=""_blank"">2407.15855</a>",,2024-12-11
A Wolf in Sheep's Clothing: Practical Black-box Adversarial Attacks for Evading Learning-based Windows Malware Detection in the Wild,"Xiang Ling, Zhiyu Wu, Bin Wang, Wei Deng, Jingzheng Wu, Shouling Ji, Tianyue Luo, Yanjun Wu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02886"" target=""_blank"">2407.02886</a>",,2024-12-11
Non-Cooperative Backdoor Attacks in Federated Learning: A New Threat Landscape,"Tuan Nguyen, Dung Thuy Nguyen, Khoa D Doan, Kok-Seng Wong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07917"" target=""_blank"">2407.07917</a>",,2024-12-11
Adversarial Robustness of VAEs across Intersectional Subgroups,"Chethan Krishnamurthy Ramanaik, Arjun Roy, Eirini Ntoutsi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03864"" target=""_blank"">2407.03864</a>",,2024-12-11
Protecting Deep Learning Model Copyrights with Adversarial Example-Free Reuse Detection,"Xiaokun Luan, Xiyue Zhang, Jingyi Wang, Meng Sun",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03883"" target=""_blank"">2407.03883</a>",,2024-12-11
Mitigating Low-Frequency Bias: Feature Recalibration and Frequency Attention Regularization for Adversarial Robustness,"Kejia Zhang, Juanjuan Weng, Yuanzheng Cai, Zhiming Luo, Shaozi Li",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04016"" target=""_blank"">2407.04016</a>",,2024-12-11
TrackPGD: A White-box Attack using Binary Masks against Robust Transformer Trackers,"Fatemeh Nourilenjan Nokabadi, Yann Batiste Pequignot, Jean-Francois Lalonde, Christian GagnÃ©",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03946"" target=""_blank"">2407.03946</a>",,2024-12-11
Securing Multi-turn Conversational Language Models Against Distributed Backdoor Triggers,"Terry Tong, Jiashu Xu, Qin Liu, Muhao Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04151"" target=""_blank"">2407.04151</a>",,2024-12-11
Charging Ahead: A Hierarchical Adversarial Framework for Counteracting Advanced Cyber Threats in EV Charging Stations,"Mohammed Al-Mehdhar, Abdullatif Albaseer, Mohamed Abdallah, Ala Al-Fuqaha",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03729"" target=""_blank"">2407.03729</a>",,2024-12-11
T2IShield: Defending Against Backdoors on Text-to-Image Diffusion Models,"Zhongqi Wang, Jie Zhang, Shiguang Shan, Xilin Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04215"" target=""_blank"">2407.04215</a>","<a href=""https://github.com/Robin-WZQ/T2IShield"" target=""_blank"">Robin-WZQ</a>",2024-12-11
Automated Progressive Red Teaming,"Bojian Jiang, Yi Jing, Tianhao Shen, Tong Wu, Qing Yang, Deyi Xiong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03876"" target=""_blank"">2407.03876</a>",,2024-12-11
Quantifying Prediction Consistency Under Model Multiplicity in Tabular LLMs,"Faisal Hamman, Pasan Dissanayake, Saumitra Mishra, Freddy Lecue, Sanghamitra Dutta",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04173"" target=""_blank"">2407.04173</a>",,2024-12-11
Certifiably Robust Image Watermark,"Zhengyuan Jiang, Moyang Guo, Yuepeng Hu, Jinyuan Jia, Neil Zhenqiang Gong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04086"" target=""_blank"">2407.04086</a>","<a href=""https://github.com/zhengyuan-jiang/Watermark-Library"" target=""_blank"">zhengyuan-jiang</a>",2024-12-11
$L_p$-norm Distortion-Efficient Adversarial Attack,"Chao Zhou, Yuan-Gen Wang, Zi-jia Wang, Xiangui Kang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03115"" target=""_blank"">2407.03115</a>",,2024-12-11
Secure Semantic Communication via Paired Adversarial Residual Networks,"Boxiang He, Fanggang Wang, Tony Q. S. Quek",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02053"" target=""_blank"">2407.02053</a>",,2024-12-11
SPLITZ: Certifiable Robustness via Split Lipschitz Randomized Smoothing,"Meiyu Zhong, Ravi Tandon",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02811"" target=""_blank"">2407.02811</a>",,2024-12-11
JailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets,"Zhihua Jin, Shiyi Liu, Haotian Li, Xun Zhao, Huamin Qu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03045"" target=""_blank"">2407.03045</a>",,2024-12-11
Venomancer: Towards Imperceptible and Target-on-Demand Backdoor Attacks in Federated Learning,"Son Nguyen, Thinh Nguyen, Khoa Doan, Kok-Seng Wong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03144"" target=""_blank"">2407.03144</a>",,2024-12-11
A Geometric Framework for Adversarial Vulnerability in Machine Learning,Brian Bell,arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11029"" target=""_blank"">2407.11029</a>",,2024-12-11
Self-Evaluation as a Defense Against Adversarial Attacks on LLMs,"Hannah Brown, Leon Lin, Kenji Kawaguchi, Michael Shieh",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03234"" target=""_blank"">2407.03234</a>","<a href=""https://github.com/Linlt-leon/self-eval"" target=""_blank"">Linlt-leon</a>",2024-12-11
Backdoor Graph Condensation,"Jiahao Wu, Ning Lu, Zeiyu Dai, Wenqi Fan, Shengcai Liu, Qing Li, Ke Tang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11025"" target=""_blank"">2407.11025</a>",,2024-12-11
Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks,"Zhexin Zhang, Junxiao Yang, Pei Ke, Shiyao Cui, Chujie Zheng, Hongning Wang, Minlie Huang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02855"" target=""_blank"">2407.02855</a>","<a href=""https://github.com/thu-coai/SafeUnlearning"" target=""_blank"">thu-coai</a>",2024-12-11
Federated Learning for Zero-Day Attack Detection in 5G and Beyond V2X Networks,"Abdelaziz Amara korba, Abdelwahab Boualouache, Bouziane Brik, Rabah Rahal, Yacine Ghamri-Doudane, Sidi Mohammed Senouci",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03070"" target=""_blank"">2407.03070</a>",,2024-12-11
An Empirical Study on Capability of Large Language Models in Understanding Code Semantics,"Thu-Trang Nguyen, Thanh Trong Vu, Hieu Dinh Vo, Son Nguyen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03611"" target=""_blank"">2407.03611</a>",,2024-12-11
On Large Language Models in National Security Applications,"William N. Caballero, Phillip R. Jenkins",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03453"" target=""_blank"">2407.03453</a>",,2024-12-11
Purification Of Contaminated Convolutional Neural Networks Via Robust Recovery: An Approach with Theoretical Guarantee in One-Hidden-Layer Case,"Hanxiao Lu, Zeyu Huang, Ren Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11031"" target=""_blank"">2407.11031</a>",,2024-12-11
Robust Yet Efficient Conformal Prediction Sets,"Soroush H. Zargarbashi, Mohammad Sadegh Akhondzadeh, Aleksandar Bojchevski",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09165"" target=""_blank"">2407.09165</a>",,2024-12-11
Distributed Backdoor Attacks on Federated Graph Learning and Certified Defenses,"Yuxin College of Computer Science and Technology, Jilin University Illinois Institute of Technology Yang, Qiang College of Computer Science and Technology, Jilin University Li, Jinyuan The Pennsylvania State University Jia, Yuan University of Connecticut Hong, Binghui Illinois Institute of Technology Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08935"" target=""_blank"">2407.08935</a>","<a href=""https://github.com/Yuxin104/Opt-GDBA"" target=""_blank"">Yuxin104</a>",2024-12-11
TAPI: Towards Target-Specific and Adversarial Prompt Injection against Code LLMs,"Yuchen Yang, Hongwei Yao, Bingrun Yang, Yiling He, Yiming Li, Tianwei Zhang, Zhan Qin, Kui Ren",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09164"" target=""_blank"">2407.09164</a>",,2024-12-11
Algebraic Adversarial Attacks on Integrated Gradients,"Lachlan Simpson, Federico Costanza, Kyle Millar, Adriel Cheng, Cheng-Chew Lim, Hong Gunn Chew",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.16233"" target=""_blank"">2407.16233</a>",,2024-12-11
Sparse vs Contiguous Adversarial Pixel Perturbations in Multimodal Models: An Empirical Analysis,"Cristian-Alexandru Botocan, Raphael Meier, Ljiljana Dolamic",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18251"" target=""_blank"">2407.18251</a>",,2024-12-11
Effects of Scale on Language Model Robustness,"Nikolaus Howe, Ian McKenzie, Oskar Hollinsworth, MichaÅ Zajac, Tom Tseng, Aaron Tucker, Pierre-Luc Bacon, Adam Gleave",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18213"" target=""_blank"">2407.18213</a>",,2024-12-11
A Unified Understanding of Adversarial Vulnerability Regarding Unimodal Models and Vision-Language Pre-training Models,"Haonan Zheng, Xinyang Deng, Wen Jiang, Wenrui Li",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.17797"" target=""_blank"">2407.17797</a>",,2024-12-11
RIDA: A Robust Attack Framework on Incomplete Graphs,"Jianke Yu, Hanchen Wang, Chen Chen, Xiaoyang Wang, Wenjie Zhang, Ying Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18170"" target=""_blank"">2407.18170</a>",,2024-12-11
Adversarially Robust Decision Transformer,"Xiaohang Tang, Afonso Marques, Parameswaran Kamalaruban, Ilija Bogunovic",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18414"" target=""_blank"">2407.18414</a>",,2024-12-11
Peak-Controlled Logits Poisoning Attack in Federated Distillation,"Yuhan Tang, Aoxu Zhang, Zhiyuan Wu, Bo Gao, Tian Wen, Yuwei Wang, Sheng Sun",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18039"" target=""_blank"">2407.18039</a>",,2024-12-11
Network Inversion of Convolutional Neural Nets,"Pirzada Suhail, Amit Sethi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18002"" target=""_blank"">2407.18002</a>",,2024-12-11
Regret-Optimal Defense Against Stealthy Adversaries: A System Level Approach,"Hiroyasu Tsukamoto, Joudi Hajar, Soon-Jo Chung, Fred Y. Hadaegh",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18448"" target=""_blank"">2407.18448</a>",,2024-12-11
Physical Adversarial Attack on Monocular Depth Estimation via Shape-Varying Patches,"Chenxing Zhao, Yang Li, Shihao Wu, Wenyi Tan, Shuangju Zhou, Quan Pan",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.17312"" target=""_blank"">2407.17312</a>",,2024-12-11
FLRT: Fluent Student-Teacher Redteaming,"T. Ben Confirm Labs Thompson, Michael Confirm Labs Sklar",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.17447"" target=""_blank"">2407.17447</a>",,2024-12-11
S-E Pipeline: A Vision Transformer (ViT) based Resilient Classification Pipeline for Medical Imaging Against Adversarial Attacks,"Neha A S, Vivek Chaturvedi, Muhammad Shafique",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.17587"" target=""_blank"">2407.17587</a>",,2024-12-11
Multimodal Unlearnable Examples: Protecting Data against Multimodal Contrastive Learning,"Xinwei Liu, Xiaojun Jia, Yuan Xun, Siyuan Liang, Xiaochun Cao",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.16307"" target=""_blank"">2407.16307</a>","<a href=""https://github.com/thinwayliu/Multimodal-Unlearnable-Examples"" target=""_blank"">thinwayliu</a>",2024-12-11
Unveiling Privacy Vulnerabilities: Investigating the Role of Structure in Graph Data,"Hanyang Yuan, Jiarong Xu, Cong Wang, Ziqi Yang, Chunping Wang, Keting Yin, Yang Yang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18564"" target=""_blank"">2407.18564</a>",,2024-12-11
When AI Defeats Password Deception! A Deep Learning Framework to Distinguish Passwords and Honeywords,"Jimmy Dani, Brandon McCulloh, Nitesh Saxena",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.16964"" target=""_blank"">2407.16964</a>",,2024-12-11
Figure it Out: Analyzing-based Jailbreak Attack on Large Language Models,"Shi Lin, Rongchang Li, Xun Wang, Changting Lin, Wenpeng Xing, Meng Han",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.16205"" target=""_blank"">2407.16205</a>","<a href=""https://github.com/theshi-1128/ABJ-Attack"" target=""_blank"">theshi-1128</a>",2024-12-11
RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent,"Huiyu Xu, Wenhui Zhang, Zhibo Wang, Feng Xiao, Rui Zheng, Yunhe Feng, Zhongjie Ba, Kui Ren",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.16667"" target=""_blank"">2407.16667</a>",,2024-12-11
Enhancing Transferability of Targeted Adversarial Examples: A Self-Universal Perspective,"Bowen Peng, Li Liu, Tianpeng Liu, Zhen Liu, Yongxiang Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15683"" target=""_blank"">2407.15683</a>",,2024-12-11
Towards Robust Vision Transformer via Masked Adaptive Ensemble,"Fudong Lin, Jiadong Lou, Xu Yuan, Nian-Feng Tzeng",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15385"" target=""_blank"">2407.15385</a>",,2024-12-11
Towards Efficient Transferable Preemptive Adversarial Defense,"Hanrui Wang, Ching-Chun Chang, Chun-Shien Lu, Isao Echizen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15524"" target=""_blank"">2407.15524</a>",,2024-12-11
Poisoning with A Pill: Circumventing Detection in Federated Learning,"Hanxi Guo, Hao Wang, Tao Song, Tianhang Zheng, Yang Hua, Haibing Guan, Xiangyu Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15389"" target=""_blank"">2407.15389</a>",,2024-12-11
Revisiting the Robust Alignment of Circuit Breakers,"Leo Schwinn, Simon Geisler",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15902"" target=""_blank"">2407.15902</a>","<a href=""https://github.com/SchwinnL/circuit-breakers-eval"" target=""_blank"">SchwinnL</a>",2024-12-11
Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs,"Abhay Sheshadri, Aidan Ewart, Phillip Guo, Aengus Lynch, Cindy Wu, Vivek Hebbar, Henry Sleight, Asa Cooper Stickland, Ethan Perez, Dylan Hadfield-Menell, Stephen Casper",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15549"" target=""_blank"">2407.15549</a>",,2024-12-11
Imposter,"Xiao Liu, Liangzhi Li, Tong Xiang, Fuying Ye, Lu Wei, Wangyue Li, Noa Garcia",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15399"" target=""_blank"">2407.15399</a>",,2024-12-11
Virtual Reality and Augmented Reality Security: A Reconnaissance and Vulnerability Assessment Approach,Sarina Dastgerdy,arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15984"" target=""_blank"">2407.15984</a>",,2024-12-11
UniForensics: Face Forgery Detection via General Facial Representation,"Ziyuan Fang, Hanqing Zhao, Tianyi Wei, Wenbo Zhou, Ming Wan, Zhanyi Wang, Weiming Zhang, Nenghai Yu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19079"" target=""_blank"">2407.19079</a>",,2024-12-11
Adversarial Robustification via Text-to-Image Diffusion Models,"Daewon Choi, Jongheon Jeong, Huiwon Jang, Jinwoo Shin",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18658"" target=""_blank"">2407.18658</a>",,2024-12-11
A Learning-Based Attack Framework to Break SOTA Poisoning Defenses in Federated Learning,"Yuxin College of Computer Science and Technology, Jilin University Illinois Institute of Technology Yang, Qiang College of Computer Science and Technology, Jilin University Li, Chenfei College of Computer Science and Technology, Jilin University Nie, Yuan University of Connecticut Hong, Meng Nanchang University Pang, Binghui Illinois Institute of Technology Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15267"" target=""_blank"">2407.15267</a>","<a href=""https://github.com/Yuxin104/"" target=""_blank"">Yuxin104</a>",2024-12-11
Adversarial Robustness in RGB-Skeleton Action Recognition: Leveraging Attention Modality Reweighter,"Chao Liu, Xin Liu, Zitong Yu, Yonghong Hou, Huanjing Yue, Jingyu Yang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19981"" target=""_blank"">2407.19981</a>",,2024-12-11
Cross-modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models,"Yue Xu, Xiuyuan Qi, Zhan Qin, Wenjie Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.21659"" target=""_blank"">2407.21659</a>",,2024-12-11
The Llama 3 Herd of Models,"Abhimanyu Jack Dubey, Abhinav Jack Jauhri, Abhinav Jack Pandey, Abhishek Jack Kadian, Ahmad Jack Al-Dahle, Aiesha Jack Letman, Akhil Jack Mathur, Alan Jack Schelten, Amy Jack Yang, Angela Jack Fan, Anirudh Jack Goyal, Anthony Jack Hartshorn, Aobo Jack Yang, Archi Jack Mitra, Archie Jack Sravankumar, Artem Jack Korenev, Arthur Jack Hinsvark, Arun Jack Rao, Aston Jack Zhang, Aurelien Jack Rodriguez, Austen Jack Gregerson, Ava Jack Spataru, Baptiste Jack Roziere, Bethany Jack Biron, Binh Jack Tang, Bobbie Jack Chern, Charlotte Jack Caucheteux, Chaya Jack Nayak, Chloe Jack Bi, Chris Jack Marra, Chris Jack McConnell, Christian Jack Keller, Christophe Jack Touret, Chunyang Jack Wu, Corinne Jack Wong, Cristian Canton Jack Ferrer, Cyrus Jack Nikolaidis, Damien Jack Allonsius, Daniel Jack Song, Danielle Jack Pintz, Danny Jack Livshits, David Jack Esiobu, Dhruv Jack Choudhary, Dhruv Jack Mahajan, Diego Jack Garcia-Olano, Diego Jack Perino, Dieuwke Jack Hupkes, Egor Jack Lakomkin, Ehab Jack AlBadawy, Elina Jack Lobanova, Emily Jack Dinan, Eric Michael Jack Smith, Filip Jack Radenovic, Frank Jack Zhang, Gabriel Jack Synnaeve, Gabrielle Jack Lee, Georgia Lewis Jack Anderson, Graeme Jack Nail, Gregoire Jack Mialon, Guan Jack Pang, Guillem Jack Cucurell, Hailey Jack Nguyen, Hannah Jack Korevaar, Hu Jack Xu, Hugo Jack Touvron, Iliyan Jack Zarov, Imanol Arrieta Jack Ibarra, Isabel Jack Kloumann, Ishan Jack Misra, Ivan Jack Evtimov, Jade Jack Copet, Jaewon Jack Lee, Jan Jack Geffert, Jana Jack Vranes, Jason Jack Park, Jay Jack Mahadeokar, Jeet Jack Shah, der Linde Jelmer Jack van, Jennifer Jack Billock, Jenny Jack Hong, Jenya Jack Lee, Jeremy Jack Fu, Jianfeng Jack Chi, Jianyu Jack Huang, Jiawen Jack Liu, Jie Jack Wang, Jiecao Jack Yu, Joanna Jack Bitton, Joe Jack Spisak, Jongsoo Jack Park, Joseph Jack Rocca, Joshua Jack Johnstun, Joshua Jack Saxe, Junteng Jack Jia, Kalyan Vasuden Jack Alwala, Kartikeya Jack Upasani, Kate Jack Plawiak, Ke Jack Li, Kenneth Jack Heafield, Kevin Jack Stone, Khalid Jack El-Arini, Krithika Jack Iyer, Kshitiz Jack Malik, Kuenley Jack Chiu, Kunal Jack Bhalla, Lauren Jack Rantala-Yeary, der Maaten Laurens Jack van, Lawrence Jack Chen, Liang Jack Tan, Liz Jack Jenkins, Louis Jack Martin, Lovish Jack Madaan, Lubo Jack Malo, Lukas Jack Blecher, Lukas Jack Landzaat, Oliveira Luke Jack de, Madeline Jack Muzzi, Mahesh Jack Pasupuleti, Mannat Jack Singh, Manohar Jack Paluri, Marcin Jack Kardas, Mathew Jack Oldham, Mathieu Jack Rita, Maya Jack Pavlova, Melanie Jack Kambadur, Mike Jack Lewis, Min Jack Si, Mitesh Kumar Jack Singh, Mona Jack Hassan, Naman Jack Goyal, Narjes Jack Torabi, Nikolay Jack Bashlykov, Nikolay Jack Bogoychev, Niladri Jack Chatterji, Olivier Jack Duchenne, Onur Jack Ãelebi, Patrick Jack Alrassy, Pengchuan Jack Zhang, Pengwei Jack Li, Petar Jack Vasic, Peter Jack Weng, Prajjwal Jack Bhargava, Pratik Jack Dubal, Praveen Jack Krishnan, Punit Singh Jack Koura, Puxin Jack Xu, Qing Jack He, Qingxiao Jack Dong, Ragavan Jack Srinivasan, Raj Jack Ganapathy, Ramon Jack Calderer, Ricardo Silveira Jack Cabral, Robert Jack Stojnic, Roberta Jack Raileanu, Rohit Jack Girdhar, Rohit Jack Patel, Romain Jack Sauvestre, Ronnie Jack Polidoro, Roshan Jack Sumbaly, Ross Jack Taylor, Ruan Jack Silva, Rui Jack Hou, Rui Jack Wang, Saghar Jack Hosseini, Sahana Jack Chennabasappa, Sanjay Jack Singh, Sean Jack Bell, Seohyun Sonia Jack Kim, Sergey Jack Edunov, Shaoliang Jack Nie, Sharan Jack Narang, Sharath Jack Raparthy, Sheng Jack Shen, Shengye Jack Wan, Shruti Jack Bhosale, Shun Jack Zhang, Simon Jack Vandenhende, Soumya Jack Batra, Spencer Jack Whitman, Sten Jack Sootla, Stephane Jack Collot, Suchin Jack Gururangan, Sydney Jack Borodinsky, Tamar Jack Herman, Tara Jack Fowler, Tarek Jack Sheasha, Thomas Jack Georgiou, Thomas Jack Scialom, Tobias Jack Speckbacher, Todor Jack Mihaylov, Tong Jack Xiao, Ujjwal Jack Karn, Vedanuj Jack Goswami, Vibhor Jack Gupta, Vignesh Jack Ramanathan, Viktor Jack Kerkez, Vincent Jack Gonguet, Virginie Jack Do, Vish Jack Vogeti, Vladan Jack Petrovic, Weiwei Jack Chu, Wenhan Jack Xiong, Wenyin Jack Fu, Whitney Jack Meers, Xavier Jack Martinet, Xiaodong Jack Wang, Xiaoqing Ellen Jack Tan, Xinfeng Jack Xie, Xuchao Jack Jia, Xuewei Jack Wang, Yaelle Jack Goldschlag, Yashesh Jack Gaur, Yasmine Jack Babaei, Yi Jack Wen, Yiwen Jack Song, Yuchen Jack Zhang, Yue Jack Li, Yuning Jack Mao, Zacharie Delpierre Jack Coudert, Zheng Jack Yan, Zhengxing Jack Chen, Zoe Jack Papakipos, Aaditya Jack Singh, Aaron Jack Grattafiori, Abha Jack Jain, Adam Jack Kelsey, Adam Jack Shajnfeld, Adithya Jack Gangidi, Adolfo Jack Victoria, Ahuva Jack Goldstand, Ajay Jack Menon, Ajay Jack Sharma, Alex Jack Boesenberg, Alex Jack Vaughan, Alexei Jack Baevski, Allie Jack Feinstein, Amanda Jack Kallet, Amit Jack Sangani, Anam Jack Yunus, Andrei Jack Lupu, Andres Jack Alvarado, Andrew Jack Caples, Andrew Jack Gu, Andrew Jack Ho, Andrew Jack Poulton, Andrew Jack Ryan, Ankit Jack Ramchandani, Annie Jack Franco, Aparajita Jack Saraf, Arkabandhu Jack Chowdhury, Ashley Jack Gabriel, Ashwin Jack Bharambe, Assaf Jack Eisenman, Azadeh Jack Yazdan, Beau Jack James, Ben Jack Maurer, Benjamin Jack Leonhardi, Bernie Jack Huang, Beth Jack Loyd, Paola Beto Jack De, Bhargavi Jack Paranjape, Bing Jack Liu, Bo Jack Wu, Boyu Jack Ni, Braden Jack Hancock, Bram Jack Wasti, Brandon Jack Spence, Brani Jack Stojkovic, Brian Jack Gamido, Britt Jack Montalvo, Carl Jack Parker, Carly Jack Burton, Catalina Jack Mejia, Changhan Jack Wang, Changkyu Jack Kim, Chao Jack Zhou, Chester Jack Hu, Ching-Hsiang Jack Chu, Chris Jack Cai, Chris Jack Tindal, Christoph Jack Feichtenhofer, Damon Jack Civin, Dana Jack Beaty, Daniel Jack Kreymer, Daniel Jack Li, Danny Jack Wyatt, David Jack Adkins, David Jack Xu, Davide Jack Testuggine, Delia Jack David, Devi Jack Parikh, Diana Jack Liskovich, Didem Jack Foss, Dingkang Jack Wang, Duc Jack Le, Dustin Jack Holland, Edward Jack Dowling, Eissa Jack Jamil, Elaine Jack Montgomery, Eleonora Jack Presani, Emily Jack Hahn, Emily Jack Wood, Erik Jack Brinkman, Esteban Jack Arcaute, Evan Jack Dunbar, Evan Jack Smothers, Fei Jack Sun, Felix Jack Kreuk, Feng Jack Tian, Firat Jack Ozgenel, Francesco Jack Caggioni, Francisco Jack GuzmÃ¡n, Frank Jack Kanayet, Frank Jack Seide, Gabriela Medina Jack Florez, Gabriella Jack Schwarz, Gada Jack Badeer, Georgia Jack Swee, Gil Jack Halpern, Govind Jack Thattai, Grant Jack Herman, Grigory Jack Sizov, Jack Guangyi, Sid Zhang, Guna Sid Lakshminarayanan, Hamid Sid Shojanazeri, Han Sid Zou, Hannah Sid Wang, Hanwen Sid Zha, Haroun Sid Habeeb, Harrison Sid Rudolph, Helen Sid Suk, Henry Sid Aspegren, Hunter Sid Goldman, Igor Sid Molybog, Igor Sid Tufanov, Irina-Elena Sid Veliche, Itai Sid Gat, Jake Sid Weissman, James Sid Geboski, James Sid Kohli, Japhet Sid Asher, Jean-Baptiste Sid Gaya, Jeff Sid Marcus, Jeff Sid Tang, Jennifer Sid Chan, Jenny Sid Zhen, Jeremy Sid Reizenstein, Jeremy Sid Teboul, Jessica Sid Zhong, Jian Sid Jin, Jingyi Sid Yang, Joe Sid Cummings, Jon Sid Carvill, Jon Sid Shepard, Jonathan Sid McPhie, Jonathan Sid Torres, Josh Sid Ginsburg, Junjie Sid Wang, Kai Sid Wu, Kam Hou Sid U, Karan Sid Saxena, Karthik Sid Prasad, Kartikay Sid Khandelwal, Katayoun Sid Zand, Kathy Sid Matosich, Kaushik Sid Veeraraghavan, Kelly Sid Michelena, Keqian Sid Li, Kun Sid Huang, Kunal Sid Chawla, Kushal Sid Lakhotia, Kyle Sid Huang, Lailin Sid Chen, Lakshya Sid Garg, Lavender Sid A, Leandro Sid Silva, Lee Sid Bell, Lei Sid Zhang, Liangpeng Sid Guo, Licheng Sid Yu, Liron Sid Moshkovich, Luca Sid Wehrstedt, Madian Sid Khabsa, Manav Sid Avalani, Manish Sid Bhatt, Maria Sid Tsimpoukelli, Martynas Sid Mankus, Matan Sid Hasson, Matthew Sid Lennie, Matthias Sid Reso, Maxim Sid Groshev, Maxim Sid Naumov, Maya Sid Lathi, Meghan Sid Keneally, Michael L. Sid Seltzer, Michal Sid Valko, Michelle Sid Restrepo, Mihir Sid Patel, Mik Sid Vyatskov, Mikayel Sid Samvelyan, Mike Sid Clark, Mike Sid Macey, Mike Sid Wang, Miquel Jubert Sid Hermoso, Mo Sid Metanat, Mohammad Sid Rastegari, Munish Sid Bansal, Nandhini Sid Santhanam, Natascha Sid Parks, Natasha Sid White, Navyata Sid Bawa, Nayan Sid Singhal, Nick Sid Egebo, Nicolas Sid Usunier, Nikolay Pavlovich Sid Laptev, Ning Sid Dong, Ning Sid Zhang, Norman Sid Cheng, Oleg Sid Chernoguz, Olivia Sid Hart, Omkar Sid Salpekar, Ozlem Sid Kalinli, Parkin Sid Kent, Parth Sid Parekh, Paul Sid Saab, Pavan Sid Balaji, Pedro Sid Rittner, Philip Sid Bontrager, Pierre Sid Roux, Piotr Sid Dollar, Polina Sid Zvyagina, Prashant Sid Ratanchandani, Pritish Sid Yuvraj, Qian Sid Liang, Rachad Sid Alao, Rachel Sid Rodriguez, Rafi Sid Ayub, Raghotham Sid Murthy, Raghu Sid Nayani, Rahul Sid Mitra, Raymond Sid Li, Rebekkah Sid Hogan, Robin Sid Battey, Rocky Sid Wang, Rohan Sid Maheswari, Russ Sid Howes, Ruty Sid Rinott, Sai Jayesh Sid Bondu, Samyak Sid Datta, Sara Sid Chugh, Sara Sid Hunt, Sargun Sid Dhillon, Sasha Sid Sidorov, Satadru Sid Pan, Saurabh Sid Verma, Seiji Sid Yamamoto, Sharadh Sid Ramaswamy, Shaun Sid Lindsay, Shaun Sid Lindsay, Sheng Sid Feng, Shenghao Sid Lin, Shengxin Cindy Sid Zha, Shiva Sid Shankar, Shuqiang Sid Zhang, Shuqiang Sid Zhang, Sinong Sid Wang, Sneha Sid Agarwal, Soji Sid Sajuyigbe, Soumith Sid Chintala, Stephanie Sid Max, Stephen Sid Chen, Steve Sid Kehoe, Steve Sid Satterfield, Sudarshan Sid Govindaprasad, Sumit Sid Gupta, Sungmin Sid Cho, Sunny Sid Virk, Suraj Sid Subramanian, Sy Sid Choudhury, Sydney Sid Goldman, Tal Sid Remez, Tamar Sid Glaser, Tamara Sid Best, Thilo Sid Kohler, Thomas Sid Robinson, Tianhe Sid Li, Tianjun Sid Zhang, Tim Sid Matthews, Timothy Sid Chou, Tzook Sid Shaked, Varun Sid Vontimitta, Victoria Sid Ajayi, Victoria Sid Montanez, Vijai Sid Mohan, Vinay Satish Sid Kumar, Vishal Sid Mangla, Vlad Sid Ionescu, Vlad Sid Poenaru, Vlad Tiberiu Sid Mihailescu, Vladimir Sid Ivanov, Wei Sid Li, Wenchen Sid Wang, Wenwen Sid Jiang, Wes Sid Bouaziz, Will Sid Constable, Xiaocheng Sid Tang, Xiaofang Sid Wang, Xiaojian Sid Wu, Xiaolan Sid Wang, Xide Sid Xia, Xilun Sid Wu, Xinbo Sid Gao, Yanjun Sid Chen, Ye Sid Hu, Ye Sid Jia, Ye Sid Qi, Yenda Sid Li, Yilin Sid Zhang, Ying Sid Zhang, Yossi Sid Adi, Youngjin Sid Nam, Sid Yu, Wang, Yuchen Hao, Yundi Qian, Yuzi He, Zach Rait, Zachary DeVito, Zef Rosnbrick, Zhaoduo Wen, Zhenyu Yang, Zhiwei Zhao",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.21783"" target=""_blank"">2407.21783</a>",,2024-12-11
Evaluating the Adversarial Robustness of Semantic Segmentation: Trying Harder Pays Off,"Levente Halmosi, BÃ¡lint Mohos, MÃ¡rk Jelasity",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09150"" target=""_blank"">2407.09150</a>",,2024-12-11
Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks,"Hunmin Yang, Jongoh Jeong, Kuk-Jin Yoon",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20657"" target=""_blank"">2407.20657</a>",,2024-12-11
AI Safety in Practice: Enhancing Adversarial Robustness in Multimodal Image Captioning,"Maisha Binte Rashid, Pablo Rivas",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.21174"" target=""_blank"">2407.21174</a>",,2024-12-11
FACL-Attack: Frequency-Aware Contrastive Learning for Transferable Adversarial Attacks,"Hunmin Yang, Jongoh Jeong, Kuk-Jin Yoon",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20653"" target=""_blank"">2407.20653</a>",,2024-12-11
Vulnerabilities in AI-generated Image Detection: The Challenge of Adversarial Attacks,"Yunfeng Diao, Naixin Zhai, Changtao Miao, Xun Yang, Meng Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20836"" target=""_blank"">2407.20836</a>",,2024-12-11
Diff-Cleanse: Identifying and Mitigating Backdoor Attacks in Diffusion Models,"Jiang Hao, Xiao Jin, Hu Xiaoguang, Chen Tianyou",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.21316"" target=""_blank"">2407.21316</a>","<a href=""https://github.com/shymuel/diff-cleanse"" target=""_blank"">shymuel</a>",2024-12-11
DeepBaR: Fault Backdoor Attack on Deep Neural Network Layers,"C. A. MartÃ­nez-MejÃ­a, J. Solano, J. Breier, D. Bucko, X. Hou",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.21220"" target=""_blank"">2407.21220</a>",,2024-12-11
Breaking Agents: Compromising Autonomous LLM Agents Through Malfunction Amplification,"Boyang Zhang, Yicong Tan, Yun Shen, Ahmed Salem, Michael Backes, Savvas Zannettou, Yang Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20859"" target=""_blank"">2407.20859</a>",,2024-12-11
Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Neural Networks,"Bao Gia Doan, Afshar Shamsi, Xiao-Yu Guo, Arash Mohammadi, Hamid Alinejad-Rokny, Dino Sejdinovic, Damith C. Ranasinghe, Ehsan Abbasnejad",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20891"" target=""_blank"">2407.20891</a>",,2024-12-11
Enhancing Adversarial Text Attacks on BERT Models with Projected Gradient Descent,"Hetvi Waghela, Jaydip Sen, Sneha Rakshit",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.21073"" target=""_blank"">2407.21073</a>",,2024-12-11
Robust VAEs via Generating Process of Noise Augmented Data,"Hiroo Irobe, Wataru Aoki, Kimihiro Yamazaki, Yuhui Zhang, Takumi Nakagawa, Hiroki Waida, Yuichiro Wada, Takafumi Kanamori",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18632"" target=""_blank"">2407.18632</a>",,2024-12-11
Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability,"Jorge GarcÃ­a-Carrasco, Alejandro MatÃ©, Juan Trujillo",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19842"" target=""_blank"">2407.19842</a>",,2024-12-11
From ML to LLM: Evaluating the Robustness of Phishing Webpage Detection Models against Adversarial Attacks,"Aditya Kulkarni, Vivek Balachandran, Dinil Mon Divakaran, Tamal Das",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20361"" target=""_blank"">2407.20361</a>",,2024-12-11
DDAP: Dual-Domain Anti-Personalization against Text-to-Image Diffusion Models,"Jing Yang, Runping Xi, Yingxin Lai, Xun Lin, Zitong Yu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20141"" target=""_blank"">2407.20141</a>",,2024-12-11
RSC-SNN: Exploring the Trade-off Between Adversarial Robustness and Accuracy in Spiking Neural Networks via Randomized Smoothing Coding,"Keming Wu, Man Yao, Yuhong Chou, Xuerui Qiu, Rui Yang, Bo Xu, Guoqi Li",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20099"" target=""_blank"">2407.20099</a>","<a href=""https://github.com/KemingWu/RSC-SNN"" target=""_blank"">KemingWu</a>",2024-12-11
Can Editing LLMs Inject Harm? (9%),"Canyu Chen, Baixiang Huang, Zekun Li, Zhaorun Chen, Shiyang Lai, Xiongxiao Xu, Jia-Chen Gu, Jindong Gu, Huaxiu Yao, Chaowei Xiao, Xifeng Yan, William Yang Wang, Philip Torr, Dawn Song, Kai Shu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20224"" target=""_blank"">2407.20224</a>",,2024-12-11
BackdoorBench: A Comprehensive Benchmark and Analysis of Backdoor Learning,"Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Mingli Zhu, Ruotong Wang, Li Liu, Chao Shen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19845"" target=""_blank"">2407.19845</a>",,2024-12-11
ImagiNet: A Multi-Content Dataset for Generalizable Synthetic Image Detection via Contrastive Learning,"Delyan Boychev, Radostin Cholakov",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20020"" target=""_blank"">2407.20020</a>","<a href=""https://github.com/delyan-boychev/imaginet"" target=""_blank"">delyan-boychev</a>",2024-12-11
Exploring the Adversarial Robustness of CLIP for AI-generated Image Detection,"Rosa Vincenzo De, Fabrizio Guillaro, Giovanni Poggi, Davide Cozzolino, Luisa Verdoliva",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19553"" target=""_blank"">2407.19553</a>",,2024-12-11
EaTVul: ChatGPT-based Evasion Attack Against Software Vulnerability Detection,"Shigang Liu, Di Cao, Junae Kim, Tamas Abraham, Paul Montague, Seyit Camtepe, Jun Zhang, Yang Xiang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19216"" target=""_blank"">2407.19216</a>",,2024-12-11
Towards Clean-Label Backdoor Attacks in the Physical World,"Thinh Dao, Cuong Chi Le, Khoa D Doan, Kok-Seng Wong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19203"" target=""_blank"">2407.19203</a>",,2024-12-11
Debiased Graph Poisoning Attack via Contrastive Surrogate Objective,"Kanghoon Yoon, Yeonjun In, Namkyeong Lee, Kibum Kim, Chanyoung Park",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19155"" target=""_blank"">2407.19155</a>",,2024-12-11
When Do Universal Image Jailbreaks Transfer Between Vision-Language Models? (74%),"Rylan Schaeffer, Dan Valentine, Luke Bailey, James Chua, CristÃ³bal Eyzaguirre, Zane Durante, Joe Benton, Brando Miranda, Henry Sleight, John Hughes, Rajashree Agrawal, Mrinank Sharma, Scott Emmons, Sanmi Koyejo, Ethan Perez",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15211"" target=""_blank"">2407.15211</a>",,2024-12-11
A Survey of Malware Detection Using Deep Learning,"Ahmed Bensaoud, Jugal Kalita, Mahmoud Bensaoud",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19153"" target=""_blank"">2407.19153</a>",,2024-12-11
SeqMIA: Sequential-Metric Based Membership Inference Attack,"Hao Li, Zheng Li, Siyuan Wu, Chengrui Hu, Yutong Ye, Min Zhang, Dengguo Feng, Yang Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15098"" target=""_blank"">2407.15098</a>",,2024-12-11
Provable Robustness of (Graph) Neural Networks Against Data Poisoning and Backdoor Attacks,"Lukas Gosch, Mahalakshmi Sabanayagam, Debarghya Ghoshdastidar, Stephan GÃ¼nnemann",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10867"" target=""_blank"">2407.10867</a>",,2024-12-11
Relaxing Graph Transformers for Adversarial Attacks,"Philipp Foth, Lukas Gosch, Simon Geisler, Leo Schwinn, Stephan GÃ¼nnemann",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11764"" target=""_blank"">2407.11764</a>",,2024-12-11
Turning Generative Models Degenerate: The Power of Data Poisoning Attacks,"Shuli Jiang, Swanand Ravindra Kadhe, Yi Zhou, Farhan Ahmed, Ling Cai, Nathalie Baracaldo",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12281"" target=""_blank"">2407.12281</a>",,2024-12-11
Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness,"Kai Guo, Zewen Liu, Zhikai Chen, Hongzhi Wen, Wei Jin, Jiliang Tang, Yi Chang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12068"" target=""_blank"">2407.12068</a>",,2024-12-11
SegSTRONG-C: Segmenting Surgical Tools Robustly On Non-adversarial Generated Corruptions -- An EndoVis'24 Challenge,"Hao Ding, Tuxun Lu, Yuqian Zhang, Ruixing Liang, Hongchao Shu, Lalithkumar Seenivasan, Yonghao Long, Qi Dou, Cong Gao, Mathias Unberath",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11906"" target=""_blank"">2407.11906</a>",,2024-12-11
Does Refusal Training in LLMs Generalize to the Past Tense? (15%),"Maksym Andriushchenko, Nicolas Flammarion",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11969"" target=""_blank"">2407.11969</a>","<a href=""https://github.com/tml-epfl/llm-past-tense"" target=""_blank"">tml-epfl</a>",2024-12-11
Cover-separable Fixed Neural Network Steganography via Deep Generative Models,"Guobiao Li, Sheng Li, Zhenxing Qian, Xinpeng Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11405"" target=""_blank"">2407.11405</a>",,2024-12-11
Model Inversion Attacks Through Target-Specific Conditional Diffusion Models,"Ouxiang Li, Yanbin Hao, Zhicai Wang, Bin Zhu, Shuo Wang, Zaixi Zhang, Fuli Feng",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11424"" target=""_blank"">2407.11424</a>",,2024-12-11
IPA-NeRF: Illusory Poisoning Attack Against Neural Radiance Fields,"Wenxiang Ocean University of China Jiang, Hanwei Saarland University Institute of Intelligent Software, Guangzhou Zhang, Shuo Ocean University of China Zhao, Zhongwen Ocean University of China Guo, Hao Xidian University, China Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11921"" target=""_blank"">2407.11921</a>","<a href=""https://github.com/jiang-wenxiang/IPA-NeRF"" target=""_blank"">jiang-wenxiang</a>",2024-12-11
Wicked Oddities: Selectively Poisoning for Effective Clean-Label Backdoor Attacks,"Quang H. Nguyen, Nguyen Ngoc-Hieu, The-Anh Ta, Thanh Nguyen-Tang, Kok-Seng Wong, Hoang Thanh-Tung, Khoa D. Doan",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10825"" target=""_blank"">2407.10825</a>",,2024-12-11
Backdoor Attacks against Image-to-Image Networks,"Wenbo Jiang, Hongwei Li, Jiaming He, Rui Zhang, Guowen Xu, Tianwei Zhang, Rongxing Lu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10445"" target=""_blank"">2407.10445</a>",,2024-12-11
Towards Adversarially Robust Vision-Language Models: Insights from Design Choices and Prompt Formatting Techniques,"Rishika Bhagwatkar, Shravan Nayak, Reza Bayat, Alexis Roger, Daniel Z Kaplan, Pouya Bashivan, Irina Rish",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11121"" target=""_blank"">2407.11121</a>",,2024-12-11
Uncertainty is Fragile: Manipulating Uncertainty in Large Language Models,"Qingcheng Zeng, Mingyu Jin, Qinkai Yu, Zhenting Wang, Wenyue Hua, Zihao Zhou, Guangyan Sun, Yanda Meng, Shiqing Ma, Qifan Wang, Felix Juefei-Xu, Kaize Ding, Fan Yang, Ruixiang Tang, Yongfeng Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11282"" target=""_blank"">2407.11282</a>","<a href=""https://github.com/qcznlp/uncertainty_attack"" target=""_blank"">qcznlp</a>",2024-12-11
Enhancing TinyML Security: Study of Adversarial Attack Transferability,"Parin Shah, Yuvaraj Govindarajulu, Pavan Kulkarni, Manojkumar Parmar",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11599"" target=""_blank"">2407.11599</a>",,2024-12-11
Feature Inference Attack on Shapley Values,"Xinjian Luo, Yangfan Jiang, Xiaokui Xiao",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11359"" target=""_blank"">2407.11359</a>",,2024-12-11
Transferable 3D Adversarial Shape Completion using Diffusion Models,"Xuelong Dai, Bin Xiao",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10077"" target=""_blank"">2407.10077</a>",,2024-12-11
Towards Robust Recommendation via Decision Boundary-aware Graph Contrastive Learning,"Jiakai Tang, Sunhao Dai, Zexu Sun, Xu Chen, Jun Xu, Wenhui Yu, Lantao Hu, Peng Jiang, Han Li",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10184"" target=""_blank"">2407.10184</a>",,2024-12-11
Defending Against Repetitive-based Backdoor Attacks on Semi-supervised Learning through Lens of Rate-Distortion-Perception Trade-off,"Cheng-Yi Lee, Ching-Chia Kao, Cheng-Han Yeh, Chun-Shien Lu, Chia-Mu Yu, Chu-Song Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10180"" target=""_blank"">2407.10180</a>",,2024-12-11
CLIP-Guided Networks for Transferable Targeted Attacks,"Hao Fang, Jiawei Kong, Bin Chen, Tao Dai, Hao Wu, Shu-Tao Xia",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10179"" target=""_blank"">2407.10179</a>",,2024-12-11
SENTINEL: Securing Indoor Localization against Adversarial Attacks with Capsule Neural Networks,"Danish Gufran, Pooja Anandathirtha, Sudeep Pasricha",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11091"" target=""_blank"">2407.11091</a>",,2024-12-11
Augmented Neural Fine-Tuning for Efficient Backdoor Purification,"Nazmul Karim, Abdullah Al Arafat, Umar Khalid, Zhishan Guo, Nazanin Rahnavard",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10052"" target=""_blank"">2407.10052</a>",,2024-12-11
Assessing Brittleness of Image-Text Retrieval Benchmarks from Vision-Language Models Perspective,"Mariya Hendriksen, Shuo Zhang, Ridho Reinanda, Mohamed Yahya, Edgar Meij, Rijke Maarten de",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15239"" target=""_blank"">2407.15239</a>",,2024-12-11
Partner in Crime: Boosting Targeted Poisoning Attacks against Federated Learning,"Shihua Sun, Shridatt Sugrim, Angelos Stavrou, Haining Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09958"" target=""_blank"">2407.09958</a>",,2024-12-11
Team up GBDTs and DNNs: Advancing Efficient and Effective Tabular Prediction with Tree-hybrid MLPs,"Jiahuan Yan, Jintai Chen, Qianxing Wang, Danny Z. Chen, Jian Wu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09790"" target=""_blank"">2407.09790</a>",,2024-12-11
SemiAdv: Query-Efficient Black-Box Adversarial Attack with Unlabeled Images,"Mingyuan Fan, Yang Liu, Cen Chen, Ximeng Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11073"" target=""_blank"">2407.11073</a>",,2024-12-11
UNIT: Backdoor Mitigation via Automated Neural Distribution Tightening,"Siyuan Cheng, Guangyu Shen, Kaiyuan Zhang, Guanhong Tao, Shengwei An, Hanxi Guo, Shiqing Ma, Xiangyu Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11372"" target=""_blank"">2407.11372</a>","<a href=""https://github.com/Megum1/UNIT"" target=""_blank"">Megum1</a>",2024-12-11
PartImageNet++ Dataset: Scaling up Part-based Models for Robust Recognition,"Xiao Li, Yining Liu, Na Dong, Sitian Qin, Xiaolin Hu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10918"" target=""_blank"">2407.10918</a>",,2024-12-11
On the Robustness of Fully-Spiking Neural Networks in Open-World Scenarios using Forward-Only Learning Algorithms,"Erik B. Terres-Escudero, Ser Javier Del, Aitor MartÃ­nez-Seras, Pablo Garcia-Bringas",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.14097"" target=""_blank"">2407.14097</a>",,2024-12-11
Data Poisoning: An Overlooked Threat to Power Grid Resilience,"Nora Agah, Javad Mohammadi, Alex Aved, David Ferris, Erika Ardiles Cruz, Philip Morrone",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.14684"" target=""_blank"">2407.14684</a>",,2024-12-11
Adversarial Databases Improve Success in Retrieval-based Large Language Models,"Sean Wu, Michael Koo, Li Yo Kao, Andy Black, Lesley Blum, Fabien Scalzo, Ira Kurtz",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.14609"" target=""_blank"">2407.14609</a>",,2024-12-11
Investigating Imperceptibility of Adversarial Attacks on Tabular Data: An Empirical Analysis,"Zhipeng He, Chun Ouyang, Laith Alzubaidi, Alistair Barros, Catarina Moreira",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11463"" target=""_blank"">2407.11463</a>",,2024-12-11
Sim-CLIP: Unsupervised Siamese Adversarial Fine-Tuning for Robust and Semantically-Rich Vision-Language Models,"Md Zarif Hossain, Ahmed Imteaj",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.14971"" target=""_blank"">2407.14971</a>",,2024-12-11
Cross-Task Attack: A Self-Supervision Generative Framework Based on Attention Shift,"Qingyuan Zeng, Yunpeng Gong, Min Jiang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13700"" target=""_blank"">2407.13700</a>",,2024-12-11
Beyond Dropout: Robust Convolutional Neural Networks Based on Local Feature Masking,"Yunpeng Gong, Chuangliang Zhang, Yongjie Hou, Lifei Chen, Min Jiang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13646"" target=""_blank"">2407.13646</a>",,2024-12-11
Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation of Large Language Models,"Zhuo Chen, Jiawei Liu, Haotan Liu, Qikai Cheng, Fan Zhang, Wei Lu, Xiaozhong Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13757"" target=""_blank"">2407.13757</a>",,2024-12-11
Prover-Verifier Games improve legibility of LLM outputs,"Jan Hendrik Kirchner, Yining Chen, Harri Edwards, Jan Leike, Nat McAleese, Yuri Burda",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13692"" target=""_blank"">2407.13692</a>",,2024-12-11
Compressed models are NOT miniature versions of large models,"Rohit Raj Rai, Rishant Pal, Amit Awekar",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13174"" target=""_blank"">2407.13174</a>",,2024-12-11
Distributionally and Adversarially Robust Logistic Regression via Intersecting Wasserstein Balls,"Aras Selvi, Eleonora Kreacic, Mohsen Ghassemi, Vamsi Potluru, Tucker Balch, Manuela Veloso",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13625"" target=""_blank"">2407.13625</a>",,2024-12-11
Human-Interpretable Adversarial Prompt Attack on Large Language Models with Situational Context,"Nilanjana Das, Edward Raff, Manas Gaur",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.14644"" target=""_blank"">2407.14644</a>",,2024-12-11
PG-Attack: A Precision-Guided Adversarial Attack Framework Against Vision Foundation Models for Autonomous Driving,"Jiyuan Fu, Zhaoyu Chen, Kaixun Jiang, Haijing Guo, Shuyong Gao, Wenqiang Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13111"" target=""_blank"">2407.13111</a>","<a href=""https://github.com/fuhaha824/PG-Attack"" target=""_blank"">fuhaha824</a>",2024-12-11
A Closer Look at GAN Priors: Exploiting Intermediate Features for Enhanced Model Inversion Attacks,"Yixiang Qiu, Hao Fang, Hongyao Yu, Bin Chen, MeiKang Qiu, Shu-Tao Xia",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13863"" target=""_blank"">2407.13863</a>","<a href=""https://github.com/final-solution/IF-GMI"" target=""_blank"">final-solution</a>",2024-12-11
Preventing Catastrophic Overfitting in Fast Adversarial Training: A Bi-level Optimization Perspective,"Zhaoxin Wang, Handing Wang, Cong Tian, Yaochu Jin",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12443"" target=""_blank"">2407.12443</a>",,2024-12-11
Context-Aware Fuzzing for Robustness Enhancement of Deep Learning Models,"Haipeng Wang, Zhengyuan Wei, Qilin Zhou, Wing-Kwong Chan",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12428"" target=""_blank"">2407.12428</a>",,2024-12-11
Krait: A Backdoor Attack Against Graph Prompt Tuning,"Ying Song, Rita Singh, Balaji Palanisamy",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13068"" target=""_blank"">2407.13068</a>",,2024-12-11
AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases,"Zhaorun Chen, Zhen Xiang, Chaowei Xiao, Dawn Song, Bo Li",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12784"" target=""_blank"">2407.12784</a>",,2024-12-11
Benchmarking Robust Self-Supervised Learning Across Diverse Downstream Tasks,"Antoni Kowalczuk, Jan DubiÅski, Atiyeh Ashari Ghomi, Yi Sui, George Stein, Jiapeng Wu, Jesse C. Cresswell, Franziska Boenisch, Adam Dziedzic",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12588"" target=""_blank"">2407.12588</a>",,2024-12-11
Direct Unlearning Optimization for Robust and Safe Text-to-Image Models,"Yong-Hyun Park, Sangdoo Yun, Jin-Hwa Kim, Junho Kim, Geonhui Jang, Yonghyun Jeong, Junghyo Jo, Gayoung Lee",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.21035"" target=""_blank"">2407.21035</a>",,2024-12-11
Contrastive Adversarial Training for Unsupervised Domain Adaptation,"Jiahong Chen, Zhilin Zhang, Lucy Li, Behzad Shahrasbi, Arjun Mishra",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12782"" target=""_blank"">2407.12782</a>",,2024-12-11
Rethinking Video-Text Understanding: Retrieval from Counterfactually Augmented Data,"Wufei Ma, Kai Li, Zhongshi Jiang, Moustafa Meshry, Qihao Liu, Huiyu Wang, Christian HÃ¤ne, Alan Yuille",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13094"" target=""_blank"">2407.13094</a>","<a href=""https://feint6k.github.io"" target=""_blank""></a>",2024-12-11
Any Target Can be Offense: Adversarial Example Generation via Generalized Latent Infection,"Youheng Sun, Shengming Yuan, Xuanhan Wang, Lianli Gao, Jingkuan Song",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12292"" target=""_blank"">2407.12292</a>","<a href=""https://github.com/VL-Group/GAKer"" target=""_blank"">VL-Group</a>",2024-12-11
Variational Randomized Smoothing for Sample-Wise Adversarial Robustness,"Ryo Hase, Ye Wang, Toshiaki Koike-Akino, Jing Liu, Kieran Parsons",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11844"" target=""_blank"">2407.11844</a>",,2024-12-11
AEMIM: Adversarial Examples Meet Masked Image Modeling,"Wenzhao Xiang, Chang Liu, Hang Su, Hongyang Yu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11537"" target=""_blank"">2407.11537</a>",,2024-12-11
Safety Alignment Should Be Made More Than Just a Few Tokens Deep,"Xiangyu Qi, Ashwinee Panda, Kaifeng Lyu, Xiao Ma, Subhrajit Roy, Ahmad Beirami, Prateek Mittal, Peter Henderson",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05946"" target=""_blank"">2406.05946</a>",,2024-12-11
A Relevance Model for Threat-Centric Ranking of Cybersecurity Vulnerabilities,"Corren McCoy, Ross Gore, Michael L. Nelson, Michele C. Weigle",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05933"" target=""_blank"">2406.05933</a>",,2024-12-11
PSBD: Prediction Shift Uncertainty Unlocks Backdoor Detection,"Wei Li, Pin-Yu Chen, Sijia Liu, Ren Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05826"" target=""_blank"">2406.05826</a>",,2024-12-11
Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents,"Avital Shafran, Roei Schuster, Vitaly Shmatikov",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05870"" target=""_blank"">2406.05870</a>",,2024-12-11
Certified Robustness to Data Poisoning in Gradient-Based Training,"Philip Sosnin, Mark N. MÃ¼ller, Maximilian Baader, Calvin Tsay, Matthew Wicker",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05670"" target=""_blank"">2406.05670</a>",,2024-12-11
Stealthy Targeted Backdoor Attacks against Image Captioning,"Wenshu Fan, Hongwei Li, Wenbo Jiang, Meng Hao, Shui Yu, Xiao Zhang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05874"" target=""_blank"">2406.05874</a>",,2024-12-11
ProFeAT: Projected Feature Adversarial Training for Self-Supervised Learning of Robust Representations,"Sravanti Addepalli, Priyam Dey, R. Venkatesh Babu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05796"" target=""_blank"">2406.05796</a>",,2024-12-11
SlowPerception: Physical-World Latency Attack against Visual Perception in Autonomous Driving,"Chen Ma, Ningfei Wang, Zhengyu Zhao, Qi Alfred Chen, Chao Shen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05800"" target=""_blank"">2406.05800</a>",,2024-12-11
Self-supervised Adversarial Training of Monocular Depth Estimation against Physical-World Attacks,"Zhiyuan Cheng, Cheng Han, James Liang, Qifan Wang, Xiangyu Zhang, Dongfang Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05857"" target=""_blank"">2406.05857</a>",,2024-12-11
ControlLoc: Physical-World Hijacking Attack on Visual Perception in Autonomous Driving,"Chen Ma, Ningfei Wang, Zhengyu Zhao, Qian Wang, Qi Alfred Chen, Chao Shen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05810"" target=""_blank"">2406.05810</a>",,2024-12-11
SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner,"Xunguang Wang, Daoyuan Wu, Zhenlan Ji, Zongjie Li, Pingchuan Ma, Shuai Wang, Yingjiu Li, Yang Liu, Ning Liu, Juergen Rahmel",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05498"" target=""_blank"">2406.05498</a>",,2024-12-11
MeanSparse: Post-Training Robustness Enhancement Through Mean-Centered Feature Sparsification,"Sajjad Amini, Mohammadreza Teymoorianfard, Shiqing Ma, Amir Houmansadr",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05927"" target=""_blank"">2406.05927</a>","<a href=""https://github.com/SPIN-UMass/MeanSparse"" target=""_blank"">SPIN-UMass</a>",2024-12-11
Injecting Undetectable Backdoors in Obfuscated Neural Networks and Language Models,"Alkis Kalavasis, Amin Karbasi, Argyris Oikonomou, Katerina Sotiraki, Grigoris Velegkas, Manolis Zampetakis",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05660"" target=""_blank"">2406.05660</a>",,2024-12-11
The Price of Implicit Bias in Adversarially Robust Generalization,"Nikolaos Tsilivis, Natalie Frank, Nathan Srebro, Julia Kempe",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04981"" target=""_blank"">2406.04981</a>",,2024-12-11
One Perturbation is Enough: On Generating Universal Adversarial Perturbations against Vision-Language Pre-training Models,"Hao Fang, Jiawei Kong, Wenbo Yu, Bin Chen, Jiawei Li, Shutao Xia, Ke Xu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05491"" target=""_blank"">2406.05491</a>",,2024-12-11
Bridging the Gap: Rademacher Complexity in Robust and Standard Generalization,"Jiancong Xiao, Ruoyu Sun, Qi Long, Weijie J. Su",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05372"" target=""_blank"">2406.05372</a>",,2024-12-11
Perturbation Towards Easy Samples Improves Targeted Adversarial Transferability,"Junqi Gao, Biqing Qi, Yao Li, Zhichang Guo, Dong Li, Yuming Xing, Dazhi Zhang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05535"" target=""_blank"">2406.05535</a>","<a href=""https://github.com/gjq100/ESMA"" target=""_blank"">gjq100</a>",2024-12-11
Enhancing Adversarial Transferability via Information Bottleneck Constraints,"Biqing Qi, Junqi Gao, Jianxing Liu, Ligang Wu, Bowen Zhou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05531"" target=""_blank"">2406.05531</a>","<a href=""https://github.com/Biqing-Qi/Enhancing-Adversarial-Transferability-via-Information-Bottleneck-Constraints"" target=""_blank"">Biqing-Qi</a>",2024-12-11
Exploring Adversarial Robustness of Deep State Space Models,"Biqing Qi, Yang Luo, Junqi Gao, Pengfei Li, Kai Tian, Zhiyuan Ma, Bowen Zhou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05532"" target=""_blank"">2406.05532</a>",,2024-12-11
Adversarial flows: A gradient flow characterization of adversarial attacks,"Lukas Weigand, Tim Roith, Martin Burger",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05376"" target=""_blank"">2406.05376</a>",,2024-12-11
ADBA:Approximation Decision Boundary Approach for Black-Box Adversarial Attacks,"Feiyang Wang, Xingquan Zuo, Hai Huang, Gang Chen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04998"" target=""_blank"">2406.04998</a>","<a href=""https://github.com/BUPTAIOC/ADBA"" target=""_blank"">BUPTAIOC</a>",2024-12-11
Probabilistic Perspectives on Error Minimization in Adversarial Reinforcement Learning,"Roman Belaire, Arunesh Sinha, Pradeep Varakantham",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04724"" target=""_blank"">2406.04724</a>",,2024-12-11
Corpus Poisoning via Approximate Greedy Gradient Descent,"Jinyan Su, Preslav Nakov, Claire Cardie",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05087"" target=""_blank"">2406.05087</a>",,2024-12-11
Compositional Curvature Bounds for Deep Neural Networks,"Taha Entesari, Sina Sharifi, Mahyar Fazlyab",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05119"" target=""_blank"">2406.05119</a>",,2024-12-11
Adversarial Tuning: Defending Against Jailbreak Attacks for LLMs,"Fan Liu, Zhao Xu, Hao Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06622"" target=""_blank"">2406.06622</a>",,2024-12-11
"Clarifying Myths About the Relationship Between Shape Bias, Accuracy, and Robustness","Zahra Golpayegani, Patrick St-Amant, Nizar Bouguila",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05006"" target=""_blank"">2406.05006</a>",,2024-12-11
GENIE: Watermarking Graph Neural Networks for Link Prediction,"Venkata Sai Pranav Bachina, Ankit Gangwal, Aaryan Ajay Sharma, Charu Sharma",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04805"" target=""_blank"">2406.04805</a>",,2024-12-11
Unveiling the Safety of GPT-4o: An Empirical Study using Jailbreak Attacks,"Zonghao Ying, Aishan Liu, Xianglong Liu, Dacheng Tao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06302"" target=""_blank"">2406.06302</a>","<a href=""https://github.com/NY1024/Jailbreak_GPT4o"" target=""_blank"">NY1024</a>",2024-12-11
DMS: Addressing Information Loss with More Steps for Pragmatic Adversarial Attacks,"Zhiyu Zhu, Jiayu Zhang, Xinyi Wang, Zhibo Jin, Huaming Chen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07580"" target=""_blank"">2406.07580</a>",,2024-12-11
On Security Weaknesses and Vulnerabilities in Deep Learning Systems,"Zhongzheng Lai, Huaming Chen, Ruoxi Sun, Yu Zhang, Minhui Xue, Dong Yuan",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08688"" target=""_blank"">2406.08688</a>","<a href=""https://github.com/codelzz/Vulnerabilities4DLSystem"" target=""_blank"">codelzz</a>",2024-12-11
Fast White-Box Adversarial Streaming Without a Random Oracle,"Ying Feng, Aayush Jain, David P. Woodruff",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06808"" target=""_blank"">2406.06808</a>",,2024-12-11
"On the H\""{o}lder Stability of Multiset and Graph Neural Networks","Yair Davidson, Nadav Dym",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06984"" target=""_blank"">2406.06984</a>",,2024-12-11
LLM Whisperer: An Inconspicuous Attack to Bias LLM Responses,"Weiran Lin, Anna Gerchanovsky, Omer Akgul, Lujo Bauer, Matt Fredrikson, Zifan Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04755"" target=""_blank"">2406.04755</a>",,2024-12-11
Transformation-Dependent Adversarial Attacks,"Yaoteng Tan, Zikui Cai, M. Salman Asif",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08443"" target=""_blank"">2406.08443</a>",,2024-12-11
When LLM Meets DRL: Advancing Jailbreaking Efficiency via DRL-guided Search,"Xuan Chen, Yuzhou Nie, Wenbo Guo, Xiangyu Zhang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08705"" target=""_blank"">2406.08705</a>",,2024-12-11
RL-JACK: Reinforcement Learning-powered Black-box Jailbreaking Attack against LLMs,"Xuan Chen, Yuzhou Nie, Lu Yan, Yunshu Mao, Wenbo Guo, Xiangyu Zhang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08725"" target=""_blank"">2406.08725</a>",,2024-12-11
AdaNCA: Neural Cellular Automata As Adaptors For More Robust Vision Transformer,"Yitao Xu, Tong Zhang, Sabine SÃ¼sstrunk",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08298"" target=""_blank"">2406.08298</a>",,2024-12-11
Graph Transductive Defense: a Two-Stage Defense for Graph Membership Inference Attacks,"Peizhi Niu, Chao Pan, Siheng Chen, Olgica Milenkovic",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07917"" target=""_blank"">2406.07917</a>",,2024-12-11
Dataset and Lessons Learned from the 2024 SaTML LLM Capture-the-Flag Competition,"Edoardo Debenedetti, Javier Rando, Daniel Paleka, Silaghi Fineas Florin, Dragos Albastroiu, Niv Cohen, Yuval Lemberg, Reshmi Ghosh, Rui Wen, Ahmed Salem, Giovanni Cherubin, Santiago Zanella-Beguelin, Robin Schmid, Victor Klemm, Takahiro Miki, Chenhao Li, Stefan Kraft, Mario Fritz, Florian TramÃ¨r, Sahar Abdelnabi, Lea SchÃ¶nherr",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07954"" target=""_blank"">2406.07954</a>",,2024-12-11
Improving Noise Robustness through Abstractions and its Impact on Machine Learning,"Alfredo Personal Health Data Science, Sano - Centre for Computational Personalised Medicine Ibias, Karol Personal Health Data Science, Sano - Centre for Computational Personalised Medicine Capala, Varun Ravi Personal Health Data Science, Sano - Centre for Computational Personalised Medicine Varma, Anna Personal Health Data Science, Sano - Centre for Computational Personalised Medicine Drozdz, Jose Personal Health Data Science, Sano - Centre for Computational Personalised Medicine Sousa",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08428"" target=""_blank"">2406.08428</a>",,2024-12-11
Exploiting Uncommon Text-Encoded Structures for Automated Jailbreaks in LLMs,"Bangxin Li, Hengrui Xing, Chao Huang, Jin Qian, Huangqing Xiao, Linfeng Feng, Cong Tian",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08754"" target=""_blank"">2406.08754</a>",,2024-12-11
Adversarial Patch for 3D Local Feature Extractor,"Yu Wen Pao, Li Chang Lai, Hong-Yi Lin",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08102"" target=""_blank"">2406.08102</a>",,2024-12-11
Erasing Radio Frequency Fingerprints via Active Adversarial Perturbation,"Zhaoyi Lu, Wenchao Xu, Ming Tu, Xin Xie, Cunqing Hua, Nan Cheng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07349"" target=""_blank"">2406.07349</a>",,2024-12-11
AudioMarkBench: Benchmarking Robustness of Audio Watermarking,"Hongbin Liu, Moyang Guo, Zhengyuan Jiang, Lun Wang, Neil Zhenqiang Gong",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06979"" target=""_blank"">2406.06979</a>","<a href=""https://github.com/moyangkuo/AudioMarkBench"" target=""_blank"">moyangkuo</a>",2024-12-11
A Study of Backdoors in Instruction Fine-tuned Language Models,"Jayaram Raghuram, George Kesidis, David J. Miller",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07778"" target=""_blank"">2406.07778</a>",,2024-12-11
An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection,"Shenao Yan, Shen Wang, Yue Duan, Hanbin Hong, Kiho Lee, Doowon Kim, Yuan Hong",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06822"" target=""_blank"">2406.06822</a>",,2024-12-11
Merging Improves Self-Critique Against Jailbreak Attacks,Victor Gallego,arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07188"" target=""_blank"">2406.07188</a>","<a href=""https://github.com/vicgalle/merging-self-critique-jailbreaks"" target=""_blank"">vicgalle</a>",2024-12-11
Benchmarking Trustworthiness of Multimodal Large Language Models: A Comprehensive Study,"Yichi Zhang, Yao Huang, Yitong Sun, Chang Liu, Zhe Zhao, Zhengwei Fang, Yifan Wang, Huanran Chen, Xiao Yang, Xingxing Wei, Hang Su, Yinpeng Dong, Jun Zhu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07057"" target=""_blank"">2406.07057</a>","<a href=""https://multi-trust.github.io/"" target=""_blank"">multi-trust.github.io</a>",2024-12-11
Dual Thinking and Perceptual Analysis of Deep Learning Models using Human Adversarial Examples,"Kailas Dayanandan, Anand Sinha, Brejesh Lall",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06967"" target=""_blank"">2406.06967</a>",,2024-12-11
MoreauPruner: Robust Pruning of Large Language Models against Weight Perturbations,"Zixiao Wang, Jingwei Zhang, Wenqian Zhao, Farzan Farnia, Bei Yu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07017"" target=""_blank"">2406.07017</a>","<a href=""https://github.com/ShiningSord/MoreauPruner"" target=""_blank"">ShiningSord</a>",2024-12-11
Rethinking the impact of noisy labels in graph classification: A utility and privacy perspective,"De Li, Xianxian Li, Zeming Gan, Qiyu Li, Bin Qu, Jinyan Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07314"" target=""_blank"">2406.07314</a>",,2024-12-11
Agnostic Sharpness-Aware Minimization,"Van-Anh Nguyen, Quyen Tran, Tuan Truong, Thanh-Toan Do, Dinh Phung, Trung Le",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07107"" target=""_blank"">2406.07107</a>",,2024-12-11
Texture Re-scalable Universal Adversarial Perturbation,"Yihao Huang, Qing Guo, Felix Juefei-Xu, Ming Hu, Xiaojun Jia, Xiaochun Cao, Geguang Pu, Yang Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06089"" target=""_blank"">2406.06089</a>",,2024-12-11
Explainable Graph Neural Networks Under Fire,"Zhong Li, Simon Geisler, Yuhang Wang, Stephan GÃ¼nnemann, Leeuwen Matthijs van",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06417"" target=""_blank"">2406.06417</a>",,2024-12-11
Lurking in the shadows: Unveiling Stealthy Backdoor Attacks against Personalized Federated Learning,"Xiaoting Lyu, Yufei Han, Wei Wang, Jingkai Liu, Yongsheng Zhu, Guangquan Xu, Jiqiang Liu, Xiangliang Zhang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06207"" target=""_blank"">2406.06207</a>",,2024-12-11
Reinforced Compressive Neural Architecture Search for Versatile Adversarial Robustness,"Dingrong Wang, Hitesh Sapkota, Zhiqiang Tao, Qi Yu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06792"" target=""_blank"">2406.06792</a>",,2024-12-11
Raccoon: Prompt Extraction Benchmark of LLM-Integrated Applications,"Junlin Wang, Tianyi Yang, Roy Xie, Bhuwan Dhingra",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06737"" target=""_blank"">2406.06737</a>","<a href=""https://github.com/M0gician/RaccoonBench"" target=""_blank"">M0gician</a>",2024-12-11
A Survey of Backdoor Attacks and Defenses on Large Language Models: Implications for Security Measures,"Shuai Zhao, Meihuizi Jia, Zhongliang Guo, Leilei Gan, Jie Fu, Yichao Feng, Fengjun Pan, Luu Anh Tuan",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06852"" target=""_blank"">2406.06852</a>",,2024-12-11
Contextual fusion enhances robustness to image blurring,"Shruti Joshi, Aiswarya Akumalla, Seth Haney, Maxim Bazhenov",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05120"" target=""_blank"">2406.05120</a>",,2024-12-11
Assessing the Adversarial Security of Perceptual Hashing Algorithms,"Jordan Madden, Moxanki Bhavsar, Lhamo Dorje, Xiaohua Li",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.00918"" target=""_blank"">2406.00918</a>",,2024-12-11
Batch-in-Batch: a new adversarial training framework for initial perturbation and sample selection,"Yinting School of Mathematics and Statistics, and Key Lab NAA--MOE, Central China Normal University Wu, Pai School of Mathematics and Computer Science, Jianghan University Peng, Bo Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, and School of Cyber Science and Engineering, Wuhan University Cai, Le School of Mathematics and Statistics, and Key Lab NAA--MOE, Central China Normal University Li, .",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04070"" target=""_blank"">2406.04070</a>",,2024-12-11
Talos: A More Effective and Efficient Adversarial Defense for GNN Models Based on the Global Homophily of Graphs,"Duanyu Li, Huijun Wu, Min Xie, Xugang Wu, Zhenwei Wu, Wenzhe Zhang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03833"" target=""_blank"">2406.03833</a>",,2024-12-11
QROA: A Black-Box Query-Response Optimization Attack on LLMs,"Hussein LaMME Jawad, Nicolas J. -B. LaMME BRUNEL",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02044"" target=""_blank"">2406.02044</a>",,2024-12-11
The Crystal Ball Hypothesis in diffusion models: Anticipating object positions from initial noise,"Yuanhao Ban, Ruochen Wang, Tianyi Zhou, Boqing Gong, Cho-Jui Hsieh, Minhao Cheng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01970"" target=""_blank"">2406.01970</a>",,2024-12-11
Can Dense Connectivity Benefit Outlier Detection? An Odyssey with NAS,"Hao Fu, Tunhou Zhang, Hai Li, Yiran Chen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01975"" target=""_blank"">2406.01975</a>",,2024-12-11
Constraint-based Adversarial Example Synthesis,"Fang Yu, Ya-Yu Chi, Yu-Fang Chen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01219"" target=""_blank"">2406.01219</a>",,2024-12-11
SVASTIN: Sparse Video Adversarial Attack via Spatio-Temporal Invertible Neural Networks,"Yi Pan, Jun-Jie Huang, Zihan Chen, Wentao Zhao, Ziyue Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01894"" target=""_blank"">2406.01894</a>","<a href=""https://github.com/Brittany-Chen/SVASTIN"" target=""_blank"">Brittany-Chen</a>",2024-12-11
Reproducibility Study on Adversarial Attacks Against Robust Transformer Trackers,"Fatemeh Nourilenjan Nokabadi, Jean-FranÃ§ois Lalonde, Christian GagnÃ©",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01765"" target=""_blank"">2406.01765</a>","<a href=""https://github.com/fatemehN/ReproducibilityStudy"" target=""_blank"">fatemehN</a>",2024-12-11
CR-UTP: Certified Robustness against Universal Text Perturbations on Large Language Models,"Qian Lou, Xin Liang, Jiaqi Xue, Yancheng Zhang, Rui Xie, Mengxin Zheng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01873"" target=""_blank"">2406.01873</a>","<a href=""https://github.com/UCFML-Research/CR-UTP"" target=""_blank"">UCFML-Research</a>",2024-12-11
Are AI-Generated Text Detectors Robust to Adversarial Perturbations? (80%),"Guanhua Huang, Yuchen Zhang, Zhe Li, Yongjian You, Mingze Wang, Zhouwang Yang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01179"" target=""_blank"">2406.01179</a>","<a href=""https://github.com/CarlanLark/Robust-AIGC-Detector"" target=""_blank"">CarlanLark</a>",2024-12-11
Model for Peanuts: Hijacking ML Models without Training Access is Possible,"Mahmoud Ghorbel, Halima Bouzidi, Ioan Marius Bilasco, Ihsen Alouani",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01708"" target=""_blank"">2406.01708</a>",,2024-12-11
SLANT: Spurious Logo ANalysis Toolkit,"Maan Qraitem, Piotr Teterwak, Kate Saenko, Bryan A. Plummer",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01449"" target=""_blank"">2406.01449</a>",,2024-12-11
MedFuzz: Exploring the Robustness of Large Language Models in Medical Question Answering,"Robert Osazuwa Ness, Katie Matton, Hayden Helm, Sheng Zhang, Junaid Bajwa, Carey E. Priebe, Eric Horvitz",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06573"" target=""_blank"">2406.06573</a>",,2024-12-11
From Feature Visualization to Visual Circuits: Effect of Adversarial Model Manipulation,"Geraldin Nanfack, Michael Eickenberg, Eugene Belilovsky",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01365"" target=""_blank"">2406.01365</a>",,2024-12-11
A Game-Theoretic Approach to Privacy-Utility Tradeoff in Sharing Genomic Summary Statistics,"Tao Zhang, Rajagopal Venkatesaramani, Rajat K. De, Bradley A. Malin, Yevgeniy Vorobeychik",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01811"" target=""_blank"">2406.01811</a>",,2024-12-11
Poisoning Attacks and Defenses in Recommender Systems: A Survey,"Zongwei Wang, Junliang Yu, Min Gao, Wei Yuan, Guanhua Ye, Shazia Sadiq, Hongzhi Yin",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01022"" target=""_blank"">2406.01022</a>",,2024-12-11
Unelicitable Backdoors in Language Models via Cryptographic Transformer Circuits,"Andis Draguns, Andrew Gritsevskiy, Sumeet Ramesh Motwani, Charlie Rogers-Smith, Jeffrey Ladish, Witt Christian Schroeder de",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02619"" target=""_blank"">2406.02619</a>",,2024-12-11
PRICE: A Pretrained Model for Cross-Database Cardinality Estimation,"Tianjing Zeng, Junwei Lan, Jiahong Ma, Wenqing Wei, Rong Zhu, Pengfei Li, Bolin Ding, Defu Lian, Zhewei Wei, Jingren Zhou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01027"" target=""_blank"">2406.01027</a>","<a href=""https://github.com/StCarmen/PRICE"" target=""_blank"">StCarmen</a>",2024-12-11
Constrained Adaptive Attack: Effective Adversarial Attack Against Deep Neural Networks for Tabular Data,"Thibault Simonetto, Salah Ghamizi, Maxime Cordy",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.00775"" target=""_blank"">2406.00775</a>",,2024-12-11
Improving Accuracy-robustness Trade-off via Pixel Reweighted Adversarial Training,"Jiacheng Zhang, Feng Liu, Dawei Zhou, Jingfeng Zhang, Tongliang Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.00685"" target=""_blank"">2406.00685</a>",,2024-12-11
A Novel Defense Against Poisoning Attacks on Federated Learning: LayerCAM Augmented with Autoencoder,"Jingjing Zheng, Xin Yuan, Kai Li, Wei Ni, Eduardo Tovar, Jon Crowcroft",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02605"" target=""_blank"">2406.02605</a>","<a href=""https://github.com/jjzgeeks/LayerCAM-AE"" target=""_blank"">jjzgeeks</a>",2024-12-11
Towards General Robustness Verification of MaxPool-based Convolutional Neural Networks via Tightening Linear Approximation,"Yuan Xiao, Shiqing Ma, Juan Zhai, Chunrong Fang, Jinyuan Jia, Zhenyu Chen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.00699"" target=""_blank"">2406.00699</a>","<a href=""https://github.com/xiaoyuanpigo/maxlin"" target=""_blank"">xiaoyuanpigo</a>",2024-12-11
Invisible Backdoor Attacks on Diffusion Models,"Sen Li, Junchi Ma, Minhao Cheng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.00816"" target=""_blank"">2406.00816</a>","<a href=""https://github.com/invisibleTriggerDiffusion/invisible_triggers_for_diffusion"" target=""_blank"">invisibleTriggerDiffusion</a>",2024-12-11
Robust Knowledge Distillation Based on Feature Variance Against Backdoored Teacher Model,"Jinyin Chen, Xiaoming Zhao, Haibin Zheng, Xiao Li, Sheng Xiang, Haifeng Guo",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03409"" target=""_blank"">2406.03409</a>",,2024-12-11
Exploring Vulnerabilities and Protections in Large Language Models: A Survey,"Frank Weizhen Liu, Chenhui Hu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.00240"" target=""_blank"">2406.00240</a>",,2024-12-11
StyDeSty: Min-Max Stylization and Destylization for Single Domain Generalization,"Songhua Liu, Xin Jin, Xingyi Yang, Jingwen Ye, Xinchao Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.00275"" target=""_blank"">2406.00275</a>","<a href=""https://github.com/Huage001/StyDeSty"" target=""_blank"">Huage001</a>",2024-12-11
Deep Learning Approaches for Detecting Adversarial Cyberbullying and Hate Speech in Social Networks,"Sylvia Worlali Azumah, Nelly Elsayed, Zag ElSayed, Murat Ozer, Guardia Amanda La",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17793"" target=""_blank"">2406.17793</a>",,2024-12-11
Investigating the Robustness of LLMs on Math Word Problems,"Ujjwala Anantheswaran, Himanshu Gupta, Kevin Scaria, Shreyas Verma, Chitta Baral, Swaroop Mishra",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15444"" target=""_blank"">2406.15444</a>",,2024-12-11
On Evaluating Adversarial Robustness of Volumetric Medical Segmentation Models,"Hashmat Shadab Malik, Numan Saeed, Asif Hanif, Muzammal Naseer, Mohammad Yaqub, Salman Khan, Fahad Shahbaz Khan",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08486"" target=""_blank"">2406.08486</a>","<a href=""https://github.com/HashmatShadab/Robustness-of-Volumetric-Medical-Segmentation-Models"" target=""_blank"">HashmatShadab</a>",2024-12-11
"Inference Attacks: A Taxonomy, Survey, and Promising Directions","Feng Wu, Lei Cui, Shaowen Yao, Shui Yu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02027"" target=""_blank"">2406.02027</a>",,2024-12-11
Nonlinear Transformations Against Unlearnable Datasets,"Thushari Hapuarachchi, Jing Lin, Kaiqi Xiong, Mohamed Rahouti, Gitte Ost",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02883"" target=""_blank"">2406.02883</a>",,2024-12-11
Large Language Models as Carriers of Hidden Messages,"Jakub Hoscilowicz, Pawel Popiolek, Jan Rudkowski, Jedrzej Bieniasz, Artur Janicki",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02481"" target=""_blank"">2406.02481</a>",,2024-12-11
Graph Neural Network Explanations are Fragile,"Jiate Li, Meng Pang, Yun Dong, Jinyuan Jia, Binghui Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03193"" target=""_blank"">2406.03193</a>",,2024-12-11
Improving Alignment and Robustness with Circuit Breakers,"Andy Zou, Long Phan, Justin Wang, Derek Duenas, Maxwell Lin, Maksym Andriushchenko, Rowan Wang, Zico Kolter, Matt Fredrikson, Dan Hendrycks",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04313"" target=""_blank"">2406.04313</a>",,2024-12-11
Behavior-Targeted Attack on Reinforcement Learning with Limited Access to Victim's Policy,"Shojiro Yamabe, Kazuto Fukuchi, Ryoma Senda, Jun Sakuma",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03862"" target=""_blank"">2406.03862</a>",,2024-12-11
AutoJailbreak: Exploring Jailbreak Attacks and Defenses through a Dependency Lens,"Lin Lu, Hai Yan, Zenghui Yuan, Jiawen Shi, Wenqi Wei, Pin-Yu Chen, Pan Zhou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03805"" target=""_blank"">2406.03805</a>",,2024-12-11
Neural Codec-based Adversarial Sample Detection for Speaker Verification,"Xuanjun Chen, Jiawei Du, Haibin Wu, Jyh-Shing Roger Jang, Hung-yi Lee",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04582"" target=""_blank"">2406.04582</a>",,2024-12-11
Interpreting the Second-Order Effects of Neurons in CLIP,"Yossi Gandelsman, Alexei A. Efros, Jacob Steinhardt",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04341"" target=""_blank"">2406.04341</a>",,2024-12-11
Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt,"Zonghao Ying, Aishan Liu, Tianyuan Zhang, Zhengmin Yu, Siyuan Liang, Xianglong Liu, Dacheng Tao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04031"" target=""_blank"">2406.04031</a>",,2024-12-11
Memorization in deep learning: A survey,"Jiaheng Wei, Yanjun Zhang, Leo Yu Zhang, Ming Ding, Chao Chen, Kok-Leong Ong, Jun Zhang, Yang Xiang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03880"" target=""_blank"">2406.03880</a>",,2024-12-11
ZeroPur: Succinct Training-Free Adversarial Purification,"Xiuli Bi, Zonglin Yang, Bo Liu, Xiaodong Cun, Chi-Man Pun, Pietro Lio, Bin Xiao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03143"" target=""_blank"">2406.03143</a>",,2024-12-11
VQUNet: Vector Quantization U-Net for Defending Adversarial Atacks by Regularizing Unwanted Noise,"Zhixun He, Mukesh Singhal",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03117"" target=""_blank"">2406.03117</a>",,2024-12-11
DifAttack++: Query-Efficient Black-Box Adversarial Attack via Hierarchical Disentangled Feature Space in Cross-Domain,"Jun Liu, Jiantao Zhou, Jiandian Zeng, Jinyu Tian, Zheng Li",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03017"" target=""_blank"">2406.03017</a>","<a href=""https://github.com/csjunjun/DifAttack"" target=""_blank"">csjunjun</a>",2024-12-11
Distributional Adversarial Loss,"Saba Ahmadi, Siddharth Bhandari, Avrim Blum, Chen Dan, Prabhav Jain",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03458"" target=""_blank"">2406.03458</a>",,2024-12-11
Defending Large Language Models Against Attacks With Residual Stream Activation Analysis,"Amelia Kawasaki, Andrew Davis, Houssam Abbas",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03230"" target=""_blank"">2406.03230</a>",,2024-12-11
A Geometric View of Data Complexity: Efficient Local Intrinsic Dimension Estimation with Diffusion Models,"Hamidreza Kamkari, Brendan Leigh Ross, Rasa Hosseinzadeh, Jesse C. Cresswell, Gabriel Loaiza-Ganem",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03537"" target=""_blank"">2406.03537</a>",,2024-12-11
Verifying the Generalization of Deep Learning to Out-of-Distribution Domains,"Guy Amir, Osher Maayan, Tom Zelazny, Guy Katz, Michael Schapira",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02024"" target=""_blank"">2406.02024</a>",,2024-12-11
Principles of Designing Robust Remote Face Anti-Spoofing Systems,"Xiang Xu, Tianchen Zhao, Zheng Zhang, Zhihua Li, Jon Wu, Alessandro Achille, Mani Srivastava",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03684"" target=""_blank"">2406.03684</a>",,2024-12-11
Fully Exploiting Every Real Sample: SuperPixel Sample Gradient Model Stealing,"Yunlong Zhao, Xiaoheng Deng, Yijing Liu, Xinjun Pei, Jiazhi Xia, Wei Chen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18540"" target=""_blank"">2406.18540</a>","<a href=""https://github.com/zyl123456aB/SPSG_attack"" target=""_blank"">zyl123456aB</a>",2024-12-11
Mutual Information Guided Backdoor Mitigation for Pre-trained Encoders,"Tingxu Han, Weisong Sun, Ziqi Ding, Chunrong Fang, Hanwei Qian, Jiaxun Li, Zhenyu Chen, Xiangyu Zhang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03508"" target=""_blank"">2406.03508</a>",,2024-12-11
JIGMARK: A Black-Box Approach for Enhancing Image Watermarks against Diffusion Model Edits,"Minzhou Pan, Yi Zeng, Xue Lin, Ning Yu, Cho-Jui Hsieh, Peter Henderson, Ruoxi Jia",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03720"" target=""_blank"">2406.03720</a>",,2024-12-11
Are Your Models Still Fair? Fairness Attacks on Graph Neural Networks via Node Injections,"Zihan Luo, Hong Huang, Yongkang Zhou, Jiping Zhang, Nuo Chen, Hai Jin",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03052"" target=""_blank"">2406.03052</a>","<a href=""https://github.com/CGCL-codes/NIFA"" target=""_blank"">CGCL-codes</a>",2024-12-11
Enhancing the Resilience of Graph Neural Networks to Topological Perturbations in Sparse Graphs,"Shuqi He, Jun Zhuang, Ding Wang, Luyao Peng, Jun Song",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03097"" target=""_blank"">2406.03097</a>",,2024-12-11
Reconstructing training data from document understanding models,"JÃ©rÃ©mie Dentan, Arnaud Paran, Aymen Shabou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03182"" target=""_blank"">2406.03182</a>",,2024-12-11
FREA: Feasibility-Guided Generation of Safety-Critical Scenarios with Reasonable Adversariality,"Keyu Chen, Yuheng Lei, Hao Cheng, Haoran Wu, Wenchao Sun, Sifa Zheng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02983"" target=""_blank"">2406.02983</a>",,2024-12-11
Advancing Generalized Transfer Attack with Initialization Derived Bilevel Optimization and Dynamic Sequence Truncation,"Yaohua Liu, Jiaxin Gao, Xuan Liu, Xianghao Jiao, Xin Fan, Risheng Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02064"" target=""_blank"">2406.02064</a>","<a href=""https://github.com/callous-youth/BETAK"" target=""_blank"">callous-youth</a>",2024-12-11
Effects of Exponential Gaussian Distribution on (Double Sampling) Randomized Smoothing,"Youwei Shu, Xi Xiao, Derui Wang, Yuxin Cao, Siji Chen, Jason Xue, Linyi Li, Bo Li",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02309"" target=""_blank"">2406.02309</a>",,2024-12-11
PuFace: Defending against Facial Cloaking Attacks for Facial Recognition Models,Jing Wen,arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02253"" target=""_blank"">2406.02253</a>",,2024-12-11
A Risk Estimation Study of Native Code Vulnerabilities in Android Applications,"Silvia Lucia Sanna, Diego Soi, Davide Maiorca, Giorgio Fumera, Giorgio Giacinto",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02011"" target=""_blank"">2406.02011</a>",,2024-12-11
Adversarial Evasion Attack Efficiency against Large Language Models,"JoÃ£o Vitorino, Eva Maia, Isabel PraÃ§a",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08050"" target=""_blank"">2406.08050</a>",,2024-12-11
"UNICAD: A Unified Approach for Attack Detection, Noise Reduction and Novel Class Identification","Alvaro Lopez Pellicer, Kittipos Giatgong, Yi Li, Neeraj Suri, Plamen Angelov",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16501"" target=""_blank"">2406.16501</a>",,2024-12-11
"I Don't Know You, But I Can Catch You: Real-Time Defense against Diverse Adversarial Patches for Object Detectors","Zijin Lin, Yue Zhao, Kai Chen, Jinwen He",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10285"" target=""_blank"">2406.10285</a>",,2024-12-11
Explainable AI Security: Exploring Robustness of Graph Neural Networks to Adversarial Attacks,"Tao Wu, Canyixing Cui, Xingping Xian, Shaojie Qiao, Chao Wang, Lin Yuan, Shui Yu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13920"" target=""_blank"">2406.13920</a>",,2024-12-11
Towards unlocking the mystery of adversarial fragility of neural networks,"Jingchao Gao, Raghu Mudumbai, Xiaodong Wu, Jirong Yi, Catherine Xu, Hui Xie, Weiyu Xu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16200"" target=""_blank"">2406.16200</a>",,2024-12-11
CBPF: Filtering Poisoned Data Based on Composite Backdoor Attack,"Hanfeng Xia, Haibo Hong, Ruili Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16125"" target=""_blank"">2406.16125</a>",,2024-12-11
Investigating the Influence of Prompt-Specific Shortcuts in AI Generated Text Detection,"Choonghyun Park, Hyuhng Joon Kim, Junyeob Kim, Youna Kim, Taeuk Kim, Hyunsoo Cho, Hwiyeol Jo, Sang-goo Lee, Kang Min Yoo",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16275"" target=""_blank"">2406.16275</a>","<a href=""https://github.com/zxcvvxcz/FAILOpt"" target=""_blank"">zxcvvxcz</a>",2024-12-11
On Instabilities of Unsupervised Denoising Diffusion Models in Magnetic Resonance Imaging Reconstruction,"Tianyu Han, Sven Nebelung, Firas Khader, Jakob Nikolas Kather, Daniel Truhn",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16983"" target=""_blank"">2406.16983</a>",,2024-12-11
Understanding and Diagnosing Deep Reinforcement Learning,Ezgi Korkmaz,arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16979"" target=""_blank"">2406.16979</a>",,2024-12-11
The Effect of Similarity Measures on Accurate Stability Estimates for Local Surrogate Models in Text-based Explainable AI,"Christopher Burger, Charles Walter, Thai Le",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15839"" target=""_blank"">2406.15839</a>",,2024-12-11
Federated Adversarial Learning for Robust Autonomous Landing Runway Detection,"Yi Li, Plamen Angelov, Zhengxin Yu, Alvaro Lopez Pellicer, Neeraj Suri",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15925"" target=""_blank"">2406.15925</a>",,2024-12-11
Privacy Implications of Explainable AI in Data-Driven Systems,Fatima Ezzeddine,arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15789"" target=""_blank"">2406.15789</a>",,2024-12-11
ECLIPSE: Expunging Clean-label Indiscriminate Poisons via Sparse Diffusion Purification,"Xianlong Wang, Shengshan Hu, Yechao Zhang, Ziqi Zhou, Leo Yu Zhang, Peng Xu, Wei Wan, Hai Jin",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15093"" target=""_blank"">2406.15093</a>","<a href=""https://github.com/CGCL-codes/ECLIPSE"" target=""_blank"">CGCL-codes</a>",2024-12-11
Deciphering the Definition of Adversarial Robustness for post-hoc OOD Detectors,"Peter Lorenz, Mario Fernandez, Jens MÃ¼ller, Ullrich KÃ¶the",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15104"" target=""_blank"">2406.15104</a>",,2024-12-11
DataFreeShield: Defending Adversarial Attacks without Training Data,"Hyeyoon Lee, Kanghyun Choi, Dain Kwon, Sunjong Park, Mayoore Selvarasa Jaiswal, Noseong Park, Jonghyun Choi, Jinho Lee",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15635"" target=""_blank"">2406.15635</a>",,2024-12-11
Large Language Models for Link Stealing Attacks Against Graph Neural Networks,"Faqian Guan, Tianqing Zhu, Hui Sun, Wanlei Zhou, Philip S. Yu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16963"" target=""_blank"">2406.16963</a>",,2024-12-11
MOUNTAINEER: Topology-Driven Visual Analytics for Comparing Local Explanations,"Parikshit Solunke, Vitoria Guardieiro, Joao Rulff, Peter Xenopoulos, Gromit Yeuk-Yin Chan, Brian Barr, Luis Gustavo Nonato, Claudio Silva",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15613"" target=""_blank"">2406.15613</a>",,2024-12-11
Enhancing robustness of data-driven SHM models: adversarial training with circle loss,"Xiangli Yang, Xijie Deng, Hanwei Zhang, Yang Zou, Jianxi Yang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14232"" target=""_blank"">2406.14232</a>",,2024-12-11
Exploring Layerwise Adversarial Robustness Through the Lens of t-SNE,"InÃªs Valentim, Nuno Antunes, Nuno LourenÃ§o",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14073"" target=""_blank"">2406.14073</a>",,2024-12-11
Defending Against Sophisticated Poisoning Attacks with RL-based Aggregation in Federated Learning,"Yujing Wang, Hainan Zhang, Sijia Wen, Wangjie Qiu, Binghui Guo",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14217"" target=""_blank"">2406.14217</a>",,2024-12-11
Jailbreaking as a Reward Misspecification Problem,"Zhihui Xie, Jiahui Gao, Lei Li, Zhenguo Li, Qi Liu, Lingpeng Kong",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14393"" target=""_blank"">2406.14393</a>",,2024-12-11
Uniform Convergence of Adversarially Robust Classifiers,"Rachel Morris, Ryan Murray",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14682"" target=""_blank"">2406.14682</a>",,2024-12-11
Prompt Injection Attacks in Defended Systems,"Daniil Khomsky, Narek Maloyan, Bulat Nutfullin",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14048"" target=""_blank"">2406.14048</a>",,2024-12-11
MEAT: Median-Ensemble Adversarial Training for Improving Robustness and Generalization,"Zhaozhe Hu, Jia-Li Yin, Bin Chen, Luojun Lin, Bo-Hao Chen, Ximeng Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14259"" target=""_blank"">2406.14259</a>",,2024-12-11
Countering adversarial perturbations in graphs using error correcting codes,Saif Eddin Jabari,arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14245"" target=""_blank"">2406.14245</a>",,2024-12-11
Steering Without Side Effects: Improving Post-Deployment Control of Language Models,"Asa Cooper Stickland, Alexander Lyzhov, Jacob Pfau, Salsabila Mahdi, Samuel R. Bowman",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15518"" target=""_blank"">2406.15518</a>","<a href=""https://github.com/AsaCooperStickland/kl-then-steer"" target=""_blank"">AsaCooperStickland</a>",2024-12-11
Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective,"Yuchen Wen, Keping Bi, Wei Chen, Jiafeng Guo, Xueqi Cheng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14023"" target=""_blank"">2406.14023</a>",,2024-12-11
PoseBench: Benchmarking the Robustness of Pose Estimation Models under Corruptions,"Sihan Ma, Jing Zhang, Qiong Cao, Dacheng Tao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14367"" target=""_blank"">2406.14367</a>","<a href=""https://xymsh.github.io/PoseBench"" target=""_blank"">xymsh.github.io</a>",2024-12-11
Can you trust your explanations? A robustness test for feature attribution methods,"Ilaria Vascotto, Alex Rodriguez, Alessandro Bonaita, Luca Bortolussi",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14349"" target=""_blank"">2406.14349</a>",,2024-12-11
SeCTIS: A Framework to Secure CTI Sharing,"Dincy R. Arikkat, Mert Cihangiroglu, Mauro Conti, Rafidha Rehiman K. A., Serena Nicolazzo, Antonino Nocera, Vinod P",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14102"" target=""_blank"">2406.14102</a>",,2024-12-11
GraphMU: Repairing Robustness of Graph Neural Networks via Machine Unlearning,"Tao Wu, Xinwen Cao, Chao Wang, Shaojie Qiao, Xingping Xian, Lin Yuan, Canyixing Cui, Yanbing Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13499"" target=""_blank"">2406.13499</a>",,2024-12-11
Machine Unlearning Fails to Remove Data Poisoning Attacks,"Martin Pawelczyk, Jimmy Z. Di, Yiwei Lu, Gautam Kamath, Ayush Sekhari, Seth Neel",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17216"" target=""_blank"">2406.17216</a>",,2024-12-11
BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models,"Yi Zeng, Weiyu Sun, Tran Ngoc Huynh, Dawn Song, Bo Li, Ruoxi Jia",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17092"" target=""_blank"">2406.17092</a>",,2024-12-11
Improving robustness to corruptions with multiplicative weight perturbations,"Trung Trinh, Markus Heinonen, Luigi Acerbi, Samuel Kaski",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16540"" target=""_blank"">2406.16540</a>",,2024-12-11
Context Matters: An Empirical Study of the Impact of Contextual Information in Temporal Question Answering Systems,"Dan Schumacher, Fatemeh Haji, Tara Grey, Niharika Bandlamudi, Nupoor Karnik, Gagana Uday Kumar, Jason Cho-Yu Chiang, Paul Rad, Nishant Vishwamitra, Anthony Rios",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19538"" target=""_blank"">2406.19538</a>",,2024-12-11
Deceptive Diffusion: Generating Synthetic Adversarial Examples,"Lucas Beerens, Catherine F. Higham, Desmond J. Higham",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19807"" target=""_blank"">2406.19807</a>",,2024-12-11
Emotion Loss Attacking: Adversarial Attack Perception for Skeleton based on Multi-dimensional Features,"Feng Liu, Qing Xu, Qijian Zheng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19815"" target=""_blank"">2406.19815</a>",,2024-12-11
Steering cooperation: Adversarial attacks on prisoner's dilemma in complex networks,Kazuhiro Takemoto,arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19692"" target=""_blank"">2406.19692</a>",,2024-12-11
Understanding Hallucinations in Diffusion Models through Mode Interpolation,"Sumukh K Aithal, Pratyush Maini, Zachary C. Lipton, J. Zico Kolter",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09358"" target=""_blank"">2406.09358</a>","<a href=""https://github.com/locuslab/diffusion-model-hallucination"" target=""_blank"">locuslab</a>",2024-12-11
IDT: Dual-Task Adversarial Attacks for Privacy Protection,"Pedro Faustini, Shakila Mahjabin Tonni, Annabelle McIver, Qiongkai Xu, Mark Dras",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19642"" target=""_blank"">2406.19642</a>",,2024-12-11
Backdoor Attack in Prompt-Based Continual Learning,"Trang Nguyen, Anh Tran, Nhat Ho",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19753"" target=""_blank"">2406.19753</a>",,2024-12-11
Virtual Context: Enhancing Jailbreak Attacks with Special Token Injection,"Yuqi Zhou, Lin Lu, Hanchi Sun, Pan Zhou, Lichao Sun",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19845"" target=""_blank"">2406.19845</a>",,2024-12-11
GRACE: Graph-Regularized Attentive Convolutional Entanglement with Laplacian Smoothing for Robust DeepFake Video Detection,"Chih-Chung Hsu, Shao-Ning Chen, Mei-Hsuan Wu, Yi-Fang Wang, Chia-Ming Lee, Yi-Shiuan Chou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19941"" target=""_blank"">2406.19941</a>","<a href=""https://github.com/ming053l/GRACE"" target=""_blank"">ming053l</a>",2024-12-11
Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems,"Zheng Fang, Tao Wang, Lingchen Zhao, Shenyi Zhang, Bowen Li, Yunjie Ge, Qi Li, Chao Shen, Qian Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19311"" target=""_blank"">2406.19311</a>",,2024-12-11
Data-Driven Lipschitz Continuity: A Cost-Effective Approach to Improve Adversarial Robustness,"Erh-Chung Chen, Pin-Yu Chen, I-Hsin Chung, Che-Rung Lee",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19622"" target=""_blank"">2406.19622</a>",,2024-12-11
Investigating and Defending Shortcut Learning in Personalized Diffusion Models,"Yixin Liu, Ruoxi Chen, Lichao Sun",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18944"" target=""_blank"">2406.18944</a>","<a href=""https://github.com/liuyixin-louis/DiffShortcut"" target=""_blank"">liuyixin-louis</a>",2024-12-11
Data Poisoning Attacks to Locally Differentially Private Frequent Itemset Mining Protocols,"Wei Tong, Haoyu Chen, Jiacheng Niu, Sheng Zhong",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19466"" target=""_blank"">2406.19466</a>",,2024-12-11
Detecting Brittle Decisions for Free: Leveraging Margin Consistency in Deep Robust Classifiers,"Jonas NgnawÃ©, Sabyasachi Sahoo, Yann Pequignot, FrÃ©dÃ©ric Precioso, Christian GagnÃ©",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18451"" target=""_blank"">2406.18451</a>",,2024-12-11
Automated Adversarial Discovery for Safety Classifiers,"Yash Kumar Lal, Preethi Lahoti, Aradhana Sinha, Yao Qin, Ananth Balashankar",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17104"" target=""_blank"">2406.17104</a>",,2024-12-11
Breaking the Barrier: Enhanced Utility and Robustness in Smoothed DRL Agents,"Chung-En Sun, Sicun Gao, Tsui-Wei Weng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18062"" target=""_blank"">2406.18062</a>",,2024-12-11
Poisoned LangChain: Jailbreak LLMs by LangChain,"Ziqiu Wang, Jun Liu, Shengkai Zhang, Yang Yang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18122"" target=""_blank"">2406.18122</a>",,2024-12-11
Revisiting Backdoor Attacks against Large Vision-Language Models,"Siyuan Liang, Jiawei Liang, Tianyu Pang, Chao Du, Aishan Liu, Ee-Chien Chang, Xiaochun Cao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18844"" target=""_blank"">2406.18844</a>",,2024-12-11
WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models,"Liwei Jiang, Kavel Rao, Seungju Han, Allyson Ettinger, Faeze Brahman, Sachin Kumar, Niloofar Mireshghallah, Ximing Lu, Maarten Sap, Yejin Choi, Nouha Dziri",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18510"" target=""_blank"">2406.18510</a>",,2024-12-11
Adversarial Search Engine Optimization for Large Language Models,"Fredrik Nestaas, Edoardo Debenedetti, Florian TramÃ¨r",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18382"" target=""_blank"">2406.18382</a>",,2024-12-11
CuDA2: An approach for Incorporating Traitor Agents into Cooperative Multi-Agent Systems,"Zhen Chen, Yong Liao, Youpeng Zhao, Zipeng Dai, Jian Zhao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17425"" target=""_blank"">2406.17425</a>",,2024-12-11
Diffusion-based Adversarial Purification for Intrusion Detection,"Mohamed Amine Merzouk, Erwan Beurier, Reda Yaich, Nora Boulahia-Cuppens, FrÃ©dÃ©ric Cuppens",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17606"" target=""_blank"">2406.17606</a>",,2024-12-11
Semantic Deep Hiding for Robust Unlearnable Examples,"Ruohan Meng, Chenyu Yi, Yi Yu, Siyuan Yang, Bingquan Shen, Alex C. Kot",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17349"" target=""_blank"">2406.17349</a>",,2024-12-11
Treatment of Statistical Estimation Problems in Randomized Smoothing for Adversarial Robustness,Vaclav Voracek,arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17830"" target=""_blank"">2406.17830</a>",,2024-12-11
Robustly Optimized Deep Feature Decoupling Network for Fatty Liver Diseases Detection,"Peng Huang, Shu Hu, Bo Peng, Jiashu Zhang, Xi Wu, Xin Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17338"" target=""_blank"">2406.17338</a>","<a href=""https://github.com/HP-ML/MICCAI2024"" target=""_blank"">HP-ML</a>",2024-12-11
Evaluating the Robustness of Deep-Learning Algorithm-Selection Models by Evolving Adversarial Instances,"Emma Hart, Quentin Renau, Kevin Sim, Mohamad Alissa",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16609"" target=""_blank"">2406.16609</a>",,2024-12-11
ADVSCORE: A Metric for the Evaluation and Creation of Adversarial Benchmarks,"Yoo Yeon Sung, Eve Fleisig, Ishani Mondal, Jordan Lee Boyd-Graber",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16342"" target=""_blank"">2406.16342</a>",,2024-12-11
AGSOA:Graph Neural Network Targeted Attack Based on Average Gradient and Structure Optimization,"Yang Chen, Bin Zhou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13228"" target=""_blank"">2406.13228</a>",,2024-12-11
From Perfect to Noisy World Simulation: Customizable Embodied Multi-modal Perturbations for SLAM Robustness Benchmarking,"Xiaohao Xu, Tianyi Zhang, Sibo Wang, Xiang Li, Yongqi Chen, Ye Li, Bhiksha Raj, Matthew Johnson-Roberson, Xiaonan Huang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16850"" target=""_blank"">2406.16850</a>","<a href=""https://github.com/Xiaohao-Xu/SLAM-under-Perturbation"" target=""_blank"">Xiaohao-Xu</a>",2024-12-11
AgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents,"Edoardo Debenedetti, Jie Zhang, Mislav BalunoviÄ, Luca Beurer-Kellner, Marc Fischer, Florian TramÃ¨r",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13352"" target=""_blank"">2406.13352</a>","<a href=""https://github.com/ethz-spylab/agentdojo"" target=""_blank"">ethz-spylab</a>",2024-12-11
Do Parameters Reveal More than Loss for Membership Inference? (1%),"Anshuman Suri, Xiao Zhang, David Evans",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11544"" target=""_blank"">2406.11544</a>",,2024-12-11
Improving Adversarial Robustness via Decoupled Visual Representation Masking,"Decheng Liu, Tao Chen, Chunlei Peng, Nannan Wang, Ruimin Hu, Xinbo Gao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10933"" target=""_blank"">2406.10933</a>","<a href=""https://github.com/chenboluo/Adversarial-defense"" target=""_blank"">chenboluo</a>",2024-12-11
Imperceptible Face Forgery Attack via Adversarial Semantic Mask,"Decheng Liu, Qixuan Su, Chunlei Peng, Nannan Wang, Xinbo Gao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10887"" target=""_blank"">2406.10887</a>","<a href=""https://github.com/clawerO-O/ASMA"" target=""_blank"">clawerO-O</a>",2024-12-11
KGPA: Robustness Evaluation for Large Language Models via Cross-Domain Knowledge Graphs,"Aihua Waseda University Pei, Zehua Waseda University Yang, Shunan Waseda University Zhu, Ruoxi Southeast University Cheng, Ju Southeast University Jia, Lina Wuhan University Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10802"" target=""_blank"">2406.10802</a>",,2024-12-11
NBA: defensive distillation for backdoor removal via neural behavior alignment,"Zonghao Ying, Bin Wu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10846"" target=""_blank"">2406.10846</a>",,2024-12-11
RWKU: Benchmarking Real-World Knowledge Unlearning for Large Language Models,"Zhuoran Jin, Pengfei Cao, Chenhao Wang, Zhitao He, Hongbang Yuan, Jiachun Li, Yubo Chen, Kang Liu, Jun Zhao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10890"" target=""_blank"">2406.10890</a>","<a href=""http://rwku-bench.github.io"" target=""_blank""></a>",2024-12-11
ChatBug: A Common Vulnerability of Aligned LLMs Induced by Chat Templates,"Fengqing Jiang, Zhangchen Xu, Luyao Niu, Bill Yuchen Lin, Radha Poovendran",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12935"" target=""_blank"">2406.12935</a>",,2024-12-11
Imperceptible Rhythm Backdoor Attacks: Exploring Rhythm Transformation for Embedding Undetectable Vulnerabilities on Speech Recognition,"Wenhan Yao, Jiangkun Yang, Yongqiang He, Jia Liu, Weiping Wen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10932"" target=""_blank"">2406.10932</a>",,2024-12-11
RUPBench: Benchmarking Reasoning Under Perturbations for Robustness Evaluation in Large Language Models,"Yuqing Wang, Yun Zhao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11020"" target=""_blank"">2406.11020</a>",,2024-12-11
Robust Image Classification in the Presence of Out-of-Distribution and Adversarial Samples Using Attractors in Neural Networks,"Nasrin Alipour, Seyyed Ali SeyyedSalehi",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10579"" target=""_blank"">2406.10579</a>",,2024-12-11
E-SAGE: Explainability-based Defense Against Backdoor Attacks on Graph Neural Networks,"Dingqiang Yuan, Xiaohua Xu, Lei Yu, Tongchang Han, Rongchang Li, Meng Han",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10655"" target=""_blank"">2406.10655</a>",,2024-12-11
Emerging Safety Attack and Defense in Federated Instruction Tuning of Large Language Models,"Rui Ye, Jingyi Chai, Xiangrui Liu, Yaodong Yang, Yanfeng Wang, Siheng Chen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10630"" target=""_blank"">2406.10630</a>",,2024-12-11
Enhancing Anomaly Detection Generalization through Knowledge Exposure: The Dual Effects of Augmentation,"Mohammad Akhavan Anvari, Rojina Kashefi, Vahid Reza Khazaie, Mohammad Khalooei, Mohammad Sabokrou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10617"" target=""_blank"">2406.10617</a>",,2024-12-11
Adaptive Randomized Smoothing: Certified Adversarial Robustness for Multi-Step Defences,"Saiyue Lyu, Shadab Shaikh, Frederick Shpilevskiy, Evan Shelhamer, Mathias LÃ©cuyer",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10427"" target=""_blank"">2406.10427</a>","<a href=""https://github.com/ubc-systopia/adaptive-randomized-smoothing"" target=""_blank"">ubc-systopia</a>",2024-12-11
Robustness-Inspired Defense Against Backdoor Attacks on Graph Neural Networks,"Zhiwei Zhang, Minhua Lin, Junjie Xu, Zongyu Wu, Enyan Dai, Suhang Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09836"" target=""_blank"">2406.09836</a>",,2024-12-11
Automated Design of Linear Bounding Functions for Sigmoidal Nonlinearities in Neural Networks,"Matthias KÃ¶nig, Xiyue Zhang, Holger H. Hoos, Marta Kwiatkowska, Rijn Jan N. van",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10154"" target=""_blank"">2406.10154</a>",,2024-12-11
Beyond Slow Signs in High-fidelity Model Extraction,"Hanna Foerster, Robert Mullins, Ilia Shumailov, Jamie Hayes",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10011"" target=""_blank"">2406.10011</a>",,2024-12-11
Byzantine-Robust Decentralized Federated Learning,"Minghong Fang, Zifan Zhang, Hairi, Prashant Khanduri, Jia Liu, Songtao Lu, Yuchen Liu, Neil Gong",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10416"" target=""_blank"">2406.10416</a>",,2024-12-11
Improving Adversarial Robustness via Feature Pattern Consistency Constraint,"Jiacong Hu, Jingwen Ye, Zunlei Feng, Jiazhen Yang, Shunyu Liu, Xiaotian Yu, Lingxiang Jia, Mingli Song",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08829"" target=""_blank"">2406.08829</a>",,2024-12-11
Watch the Watcher! Backdoor Attacks on Security-Enhancing Diffusion Models,"Changjiang Li, Ren Pang, Bochuan Cao, Jinghui Chen, Fenglong Ma, Shouling Ji, Ting Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09669"" target=""_blank"">2406.09669</a>",,2024-12-11
MirrorCheck: Efficient Adversarial Defense for Vision-Language Models,"Samar Fares, Klea Ziu, Toluwani Aremu, Nikita Durasov, Martin TakÃ¡Ä, Pascal Fua, Karthik Nandakumar, Ivan Laptev",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09250"" target=""_blank"">2406.09250</a>",,2024-12-11
Towards Evaluating the Robustness of Visual State Space Models,"Hashmat Shadab Malik, Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar, Fahad Shahbaz Khan, Salman Khan",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09407"" target=""_blank"">2406.09407</a>","<a href=""https://github.com/HashmatShadab/MambaRobustness"" target=""_blank"">HashmatShadab</a>",2024-12-11
Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs,"Zhao Xu, Fan Liu, Hao Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09324"" target=""_blank"">2406.09324</a>","<a href=""https://github.com/usail-hkust/Bag_of_Tricks_for_LLM_Jailbreaking"" target=""_blank"">usail-hkust</a>",2024-12-11
Enhancing Cross-Prompt Transferability in Vision-Language Models through Contextual Injection of Target Tokens,"Xikang Yang, Xuehai Tang, Fuqing Zhu, Jizhong Han, Songlin Hu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13294"" target=""_blank"">2406.13294</a>",,2024-12-11
Steganalysis on Digital Watermarking: Is Your Defense Truly Impervious? (4%),"Pei Yang, Hai Ci, Yiren Song, Mike Zheng Shou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09026"" target=""_blank"">2406.09026</a>",,2024-12-11
Validation of human benchmark models for Automated Driving System approval: How competent and careful are they really? (1%),"Pierluigi Olleja, Gustav Markkula, Jonas BÃ¤rgman",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09493"" target=""_blank"">2406.09493</a>",,2024-12-11
An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records,"Joakim Edin, Maria Maistro, Lars MaalÃ¸e, Lasse Borgholt, Jakob D. Havtorn, Tuukka Ruotsalo",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08958"" target=""_blank"">2406.08958</a>",,2024-12-11
Large-Scale Evaluation of Open-Set Image Classification Techniques,"Halil Bisgin, Andres Palechor, Mike Suter, Manuel GÃ¼nther",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09112"" target=""_blank"">2406.09112</a>",,2024-12-11
Adversaries With Incentives: A Strategic Alternative to Adversarial Robustness,"Maayan Ehrenberg, Roy Ganz, Nir Rosenfeld",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11458"" target=""_blank"">2406.11458</a>",,2024-12-11
Over-parameterization and Adversarial Robustness in Neural Networks: An Overview and Empirical Analysis,"Zhang Chen, Luca Demetrio, Srishti Gupta, Xiaoyi Feng, Zhaoqiang Xia, Antonio Emanuele CinÃ , Maura Pintor, Luca Oneto, Ambra Demontis, Battista Biggio, Fabio Roli",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10090"" target=""_blank"">2406.10090</a>",,2024-12-11
Saliency Attention and Semantic Similarity-Driven Adversarial Perturbation,"Hetvi Waghela, Jaydip Sen, Sneha Rakshit",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19413"" target=""_blank"">2406.19413</a>",,2024-12-11
SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation,"Xiaoze Liu, Ting Sun, Tianyang Xu, Feijie Wu, Cunxiang Wang, Xiaoqian Wang, Jing Gao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12975"" target=""_blank"">2406.12975</a>","<a href=""https://github.com/xz-liu/SHIELD"" target=""_blank"">xz-liu</a>",2024-12-11
Textual Unlearning Gives a False Sense of Unlearning,"Jiacheng Du, Zhibo Wang, Kui Ren",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13348"" target=""_blank"">2406.13348</a>",,2024-12-11
DPO: Dual-Perturbation Optimization for Test-time Adaptation in 3D Object Detection,"Zhuoxiao Chen, Zixin Wang, Sen Wang, Zi Huang, Yadan Luo",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13891"" target=""_blank"">2406.13891</a>",,2024-12-11
ModSec-Learn: Boosting ModSecurity with Machine Learning,"Christian Scano, Giuseppe Floris, Biagio Montaruli, Luca Demetrio, Andrea Valenza, Luca Compagna, Davide Ariu, Luca Piras, Davide Balzarotti, Battista Biggio",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13547"" target=""_blank"">2406.13547</a>","<a href=""https://github.com/pralab/modsec-learn"" target=""_blank"">pralab</a>",2024-12-11
RobGC: Towards Robust Graph Condensation,"Xinyi Gao, Hongzhi Yin, Tong Chen, Guanhua Ye, Wentao Zhang, Bin Cui",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13200"" target=""_blank"">2406.13200</a>",,2024-12-11
SoK: A Literature and Engineering Review of Regular Expression Denial of Service,"Masudul Hasan Masud Bhuiyan, Berk Ãakar, Ethan H Burmane, James C Davis, Cristian-Alexandru Staicu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11618"" target=""_blank"">2406.11618</a>",,2024-12-11
NoiSec: Harnessing Noise for Security against Adversarial and Backdoor Attacks,"Md Hasan Shahriar, Ning Wang, Y. Thomas Hou, Wenjing Lou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13073"" target=""_blank"">2406.13073</a>",,2024-12-11
MaskPure: Improving Defense Against Text Adversaries with Stochastic Purification,"Harrison Gietz, Jugal Kalita",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13066"" target=""_blank"">2406.13066</a>",,2024-12-11
"Towards Trustworthy Unsupervised Domain Adaptation: A Representation Learning Perspective for Enhancing Robustness, Discrimination, and Generalization","Jia-Li Yin, Haoyuan Zheng, Ximeng Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13180"" target=""_blank"">2406.13180</a>",,2024-12-11
Adversarial Attacks on Large Language Models in Medicine,"Yifan Yang, Qiao Jin, Furong Huang, Zhiyong Lu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12259"" target=""_blank"">2406.12259</a>",,2024-12-11
Can Go AIs be adversarially robust? (61%),"Tom Tseng, Euan McLean, Kellin Pelrine, Tony T. Wang, Adam Gleave",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12843"" target=""_blank"">2406.12843</a>",,2024-12-11
DLP: towards active defense against backdoor attacks with decoupled learning process,"Zonghao Ying, Bin Wu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13098"" target=""_blank"">2406.13098</a>",,2024-12-11
Attack and Defense of Deep Learning Models in the Field of Web Attack Detection,"Lijia Shi, Shihao Dong",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12605"" target=""_blank"">2406.12605</a>",,2024-12-11
Adversarial Attacks on Multimodal Agents,"Chen Henry Wu, Jing Yu Koh, Ruslan Salakhutdinov, Daniel Fried, Aditi Raghunathan",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12814"" target=""_blank"">2406.12814</a>","<a href=""https://github.com/ChenWu98/agent-attack"" target=""_blank"">ChenWu98</a>",2024-12-11
A First Physical-World Trajectory Prediction Attack via LiDAR-induced Deceptions in Autonomous Driving,"Yang Lou, Yi Zhu, Qun Song, Rui Tan, Chunming Qiao, Wei-Bin Lee, Jianping Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11707"" target=""_blank"">2406.11707</a>",,2024-12-11
Harmonizing Feature Maps: A Graph Convolutional Approach for Enhancing Adversarial Robustness,"Kejia Zhang, Juanjuan Weng, Junwei Wu, Guoqing Yang, Shaozi Li, Zhiming Luo",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11576"" target=""_blank"">2406.11576</a>",,2024-12-11
BadSampler: Harnessing the Power of Catastrophic Forgetting to Poison Byzantine-robust Federated Learning,"Yi Liu, Cong Wang, Xingliang Yuan",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12222"" target=""_blank"">2406.12222</a>",,2024-12-11
Evading AI-Generated Content Detectors using Homoglyphs,"Aldan Creo, Shushanta Pudasaini",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11239"" target=""_blank"">2406.11239</a>",,2024-12-11
ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations,"Yunze Xiao, Yujia Hu, Kenny Tsu Wei Choo, Roy Ka-wei Lee",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12223"" target=""_blank"">2406.12223</a>",,2024-12-11
Adversarial Perturbations Cannot Reliably Protect Artists From Generative AI,"Robert HÃ¶nig, Javier Rando, Nicholas Carlini, Florian TramÃ¨r",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12027"" target=""_blank"">2406.12027</a>",,2024-12-11
CleanGen: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models,"Yuetai Li, Zhangchen Xu, Fengqing Jiang, Luyao Niu, Dinuka Sahabandu, Bhaskar Ramasubramanian, Radha Poovendran",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12257"" target=""_blank"">2406.12257</a>",,2024-12-11
Large-Scale Dataset Pruning in Adversarial Training through Data Importance Extrapolation,"BjÃ¶rn Nieth, Thomas Altstidl, Leo Schwinn, BjÃ¶rn Eskofier",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13283"" target=""_blank"">2406.13283</a>",,2024-12-11
FullCert: Deterministic End-to-End Certification for Training and Inference of Neural Networks,"Tobias Lorenz, Marta Kwiatkowska, Mario Fritz",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11522"" target=""_blank"">2406.11522</a>",,2024-12-11
Obfuscating IoT Device Scanning Activity via Adversarial Example Generation,"Haocong Li, Yaxin Zhang, Long Cheng, Wenjia Niu, Haining Wang, Qiang Li",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11515"" target=""_blank"">2406.11515</a>",,2024-12-11
PRePair: Pointwise Reasoning Enhance Pairwise Evaluating for Robust Instruction-Following Assessments,"Hawon Jeong, ChaeHun Park, Jimin Hong, Jaegul Choo",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12319"" target=""_blank"">2406.12319</a>",,2024-12-11
Stealth edits for provably fixing or attacking large language models,"Oliver J. Sutton, Qinghua Zhou, Wei Wang, Desmond J. Higham, Alexander N. Gorban, Alexander Bastounis, Ivan Y. Tyukin",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12670"" target=""_blank"">2406.12670</a>","<a href=""https://github.com/qinghua-zhou/stealth-edits"" target=""_blank"">qinghua-zhou</a>",2024-12-11
Properties that allow or prohibit transferability of adversarial attacks among quantized networks,"Abhishek Shrestha, JÃ¼rgen GroÃmann",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09598"" target=""_blank"">2405.09598</a>",,2024-12-11
Certifying Robustness of Graph Convolutional Networks for Node Perturbation with Polyhedra Abstract Interpretation,"Boqi Chen, KristÃ³f Marussy, OszkÃ¡r SemerÃ¡th, Gunter Mussbacher, DÃ¡niel VarrÃ³",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08645"" target=""_blank"">2405.08645</a>",,2024-12-11
Achieving Resolution-Agnostic DNN-based Image Watermarking:A Novel Perspective of Implicit Neural Representation,"Yuchen Wang, Xingyu Zhu, Guanhui Ye, Shiyao Zhang, Xuetao Wei",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08340"" target=""_blank"">2405.08340</a>",,2024-12-11
Pointwise Lipschitz Continuous Graph Algorithms via Proximal Gradient Analysis,"Quanquan C. Liu, Grigoris Velegkas, Yuichi Yoshida, Felix Zhou",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08938"" target=""_blank"">2405.08938</a>",,2024-12-11
The RoboDrive Challenge: Drive Anytime Anywhere in Any Condition,"Lingdong Kong, Shaoyuan Xie, Hanjiang Hu, Yaru Niu, Wei Tsang Ooi, Benoit R. Cottereau, Lai Xing Ng, Yuexin Ma, Wenwei Zhang, Liang Pan, Kai Chen, Ziwei Liu, Weichao Qiu, Wei Zhang, Xu Cao, Hao Lu, Ying-Cong Chen, Caixin Kang, Xinning Zhou, Chengyang Ying, Wentao Shang, Xingxing Wei, Yinpeng Dong, Bo Yang, Shengyin Jiang, Zeliang Ma, Dengyi Ji, Haiwen Li, Xingliang Huang, Yu Tian, Genghua Kou, Fan Jia, Yingfei Liu, Tiancai Wang, Ying Li, Xiaoshuai Hao, Yifan Yang, Hui Zhang, Mengchuan Wei, Yi Zhou, Haimei Zhao, Jing Zhang, Jinke Li, Xiao He, Xiaoqiang Cheng, Bingyang Zhang, Lirong Zhao, Dianlei Ding, Fangsheng Liu, Yixiang Yan, Hongming Wang, Nanfei Ye, Lun Luo, Yubo Tian, Yiwei Zuo, Zhe Cao, Yi Ren, Yunfan Li, Wenjie Liu, Xun Wu, Yifan Mao, Ming Li, Jian Liu, Jiayang Liu, Zihan Qin, Cunxi Chu, Jialei Xu, Wenbo Zhao, Junjun Jiang, Xianming Liu, Ziyan Wang, Chiwei Li, Shilong Li, Chendong Yuan, Songyue Yang, Wentao Liu, Peng Chen, Bin Zhou, Yubo Wang, Chi Zhang, Jianhang Sun, Hai Chen, Xiao Yang, Lizhong Wang, Dongyi Fu, Yongchun Lin, Huitong Yang, Haoang Li, Yadan Luo, Xianjing Cheng, Yong Xu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08816"" target=""_blank"">2405.08816</a>",,2024-12-11
The Pitfalls and Promise of Conformal Inference Under Adversarial Attacks,"Ziquan Liu, Yufei Cui, Yan Yan, Yi Xu, Xiangyang Ji, Xue Liu, Antoni B. Chan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08886"" target=""_blank"">2405.08886</a>",,2024-12-11
Optimizing Sensor Network Design for Multiple Coverage,"Lukas Taus, Yen-Hsi Richard Tsai",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09096"" target=""_blank"">2405.09096</a>",,2024-12-11
SpeechGuard: Exploring the Adversarial Robustness of Multimodal Large Language Models,"Raghuveer Peri, Sai Muralidhar Jayanthi, Srikanth Ronanki, Anshu Bhatia, Karel Mundnich, Saket Dingliwal, Nilaksh Das, Zejiang Hou, Goeric Huybrechts, Srikanth Vishnubhotla, Daniel Garcia-Romero, Sundararajan Srinivasan, Kyu J Han, Katrin Kirchhoff",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08317"" target=""_blank"">2405.08317</a>",,2024-12-11
Towards Evaluating the Robustness of Automatic Speech Recognition Systems via Audio Style Transfer,"Weifei Jin, Yuxin Cao, Junjie Su, Qi Shen, Kai Ye, Derui Wang, Jie Hao, Ziyao Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09470"" target=""_blank"">2405.09470</a>",,2024-12-11
Neural Collapse Meets Differential Privacy: Curious Behaviors of NoisyGD with Near-perfect Representation Learning,"Chendi Wang, Yuqing Zhu, Weijie J. Su, Yu-Xiang Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08920"" target=""_blank"">2405.08920</a>",,2024-12-11
Themis: Automatic and Efficient Deep Learning System Testing with Strong Fault Detection Capability,"Tsz On Li, Dong Huang, Xiaofei Xie, Heming Cui",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09314"" target=""_blank"">2405.09314</a>",,2024-12-11
IBD-PSC: Input-level Backdoor Detection via Parameter-oriented Scaling Consistency,"Linshan Hou, Ruili Feng, Zhongyun Hua, Wei Luo, Leo Yu Zhang, Yiming Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09786"" target=""_blank"">2405.09786</a>",,2024-12-11
Cross-Input Certified Training for Universal Perturbations,"Changming Xu, Gagandeep Singh",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09176"" target=""_blank"">2405.09176</a>",,2024-12-11
"Dealing Doubt: Unveiling Threat Models in Gradient Inversion Attacks under Federated Learning, A Survey and Taxonomy","Yichuan Shi, Olivera Kotevska, Viktor Reshniak, Abhishek Singh, Ramesh Raskar",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10376"" target=""_blank"">2405.10376</a>",,2024-12-11
PUMA: margin-based data pruning,"Javier Maroto, Pascal Frossard",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06298"" target=""_blank"">2405.06298</a>",,2024-12-11
UnMarker: A Universal Attack on Defensive Watermarking,"Andre Kassis, Urs Hengartner",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08363"" target=""_blank"">2405.08363</a>",,2024-12-11
RS-Reg: Probabilistic and Robust Certified Regression Through Randomized Smoothing,"Aref Miri Rekavandi, Olga Ohrimenko, Benjamin I. P. Rubinstein",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08892"" target=""_blank"">2405.08892</a>","<a href=""https://github.com/arekavandi/Certified_Robust_Regression"" target=""_blank"">arekavandi</a>",2024-12-11
Environmental Matching Attack Against Unmanned Aerial Vehicles Object Detection,"Dehong Kong, Siyuan Liang, Wenqi Ren",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.07595"" target=""_blank"">2405.07595</a>",,2024-12-11
CrossCert: A Cross-Checking Detection Approach to Patch Robustness Certification for Deep Learning Models,"Qilin Zhou, Zhengyuan Wei, Haipeng Wang, Bo Jiang, W. K. Chan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.07668"" target=""_blank"">2405.07668</a>",,2024-12-11
RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors,"Liam Dugan, Alyssa Hwang, Filip Trhlik, Josh Magnus Ludan, Andrew Zhu, Hainiu Xu, Daphne Ippolito, Chris Callison-Burch",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.07940"" target=""_blank"">2405.07940</a>",,2024-12-11
GLiRA: Black-Box Membership Inference Attack via Knowledge Distillation,"Andrey V. Galichin, Mikhail Pautov, Alexey Zhavoronkin, Oleg Y. Rogov, Ivan Oseledets",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.07562"" target=""_blank"">2405.07562</a>",,2024-12-11
Backdoor Removal for Generative Large Language Models,"Haoran Li, Yulin Chen, Zihao Zheng, Qi Hu, Chunkit Chan, Heshan Liu, Yangqiu Song",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.07667"" target=""_blank"">2405.07667</a>",,2024-12-11
Stealthy Imitation: Reward-guided Environment-free Policy Stealing,"Zhixiong Zhuang, Maria-Irina Nicolae, Mario Fritz",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.07004"" target=""_blank"">2405.07004</a>",,2024-12-11
Improving Transferable Targeted Adversarial Attack via Normalized Logit Calibration and Truncated Feature Mixing,"Juanjuan Weng, Zhiming Luo, Shaozi Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06340"" target=""_blank"">2405.06340</a>",,2024-12-11
Disttack: Graph Adversarial Attacks Toward Distributed GNN Training,"Yuxiang Zhang, Xin Liu, Meng Wu, Wei Yan, Mingyu Yan, Xiaochun Ye, Dongrui Fan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06247"" target=""_blank"">2405.06247</a>",,2024-12-11
Exploring the Interplay of Interpretability and Robustness in Deep Neural Networks: A Saliency-guided Approach,"Amira Guesmi, Nishant Suresh Aswani, Muhammad Shafique",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06278"" target=""_blank"">2405.06278</a>",,2024-12-11
Evaluating Adversarial Robustness in the Spatial Frequency Domain,"Keng-Hsin Liao, Chin-Yuan Yeh, Hsi-Wen Chen, Ming-Syan Chen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06345"" target=""_blank"">2405.06345</a>",,2024-12-11
Certified $\ell_2$ Attribution Robustness via Uniformly Smoothed Attributions,"Fan Wang, Adams Wai-Kin Kong",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06361"" target=""_blank"">2405.06361</a>",,2024-12-11
Relational DNN Verification With Cross Executional Bound Refinement,"Debangshu Banerjee, Gagandeep Singh",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10143"" target=""_blank"">2405.10143</a>",,2024-12-11
Manifold Integrated Gradients: Riemannian Geometry for Feature Attribution,"Eslam Zaher, Maciej Trzaskowski, Quan Nguyen, Fred Roosta",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09800"" target=""_blank"">2405.09800</a>",,2024-12-11
DispaRisk: Auditing Fairness Through Usable Information,"Jonathan Vasquez, Carlotta Domeniconi, Huzefa Rangwala",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12372"" target=""_blank"">2405.12372</a>","<a href=""https://github.com/jovasque156/disparisk"" target=""_blank"">jovasque156</a>",2024-12-11
Box-Free Model Watermarks Are Prone to Black-Box Removal Attacks,"Haonan An, Guang Hua, Zhiping Lin, Yuguang Fang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09863"" target=""_blank"">2405.09863</a>",,2024-12-11
Towards Robust Policy: Enhancing Offline Reinforcement Learning with Adversarial Attacks and Defenses,"Thanh Nguyen, Tung M. Luu, Tri Ton, Chang D. Yoo",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11206"" target=""_blank"">2405.11206</a>",,2024-12-11
Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models,"Vyas Raina, Rao Ma, Charles McGhee, Kate Knill, Mark Gales",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06134"" target=""_blank"">2405.06134</a>",,2024-12-11
Robust Deep Reinforcement Learning with Adaptive Adversarial Perturbations in Action Space,"Qianmei Liu, Yufei Kuang, Jie Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11982"" target=""_blank"">2405.11982</a>","<a href=""https://github.com/Lqm00/A2P-SAC"" target=""_blank"">Lqm00</a>",2024-12-11
EGAN: Evolutional GAN for Ransomware Evasion,"Daniel Commey, Benjamin Appiah, Bill K. Frimpong, Isaac Osei, Ebenezer N. A. Hammond, Garth V. Crosby",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12266"" target=""_blank"">2405.12266</a>",,2024-12-11
Rethinking Robustness Assessment: Adversarial Attacks on Learning-based Quadrupedal Locomotion Controllers,"Fan Shi, Chong Zhang, Takahiro Miki, Joonho Lee, Marco Hutter, Stelian Coros",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12424"" target=""_blank"">2405.12424</a>",,2024-12-11
Adversarially Diversified Rehearsal Memory (ADRM): Mitigating Memory Overfitting Challenge in Continual Learning,"Hikmat Khan, Ghulam Rasool, Nidhal Carla Bouaynaya",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11829"" target=""_blank"">2405.11829</a>","<a href=""https://github.com/hikmatkhan/ADRM"" target=""_blank"">hikmatkhan</a>",2024-12-11
Efficient Model-Stealing Attacks Against Inductive Graph Neural Networks,"Marcin Podhajski, Jan DubiÅski, Franziska Boenisch, Adam Dziedzic, Agnieszka Pregowska, Tomasz Michalak",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12295"" target=""_blank"">2405.12295</a>",,2024-12-11
Adaptive Batch Normalization Networks for Adversarial Robustness,"Shao-Yuan Lo, Vishal M. Patel",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11708"" target=""_blank"">2405.11708</a>",,2024-12-11
An Invisible Backdoor Attack Based On Semantic Feature,Yangming Chen,arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11551"" target=""_blank"">2405.11551</a>",,2024-12-11
Certified Robust Accuracy of Neural Networks Are Bounded due to Bayes Errors,"Ruihan Zhang, Jun Sun",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11547"" target=""_blank"">2405.11547</a>",,2024-12-11
A GAN-Based Data Poisoning Attack Against Federated Learning Systems and Its Countermeasure,"Wei Sun, Bo Gao, Ke Xiong, Yuwei Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11440"" target=""_blank"">2405.11440</a>","<a href=""https://github.com/SSssWEIssSS/VagueGAN-Data-Poisoning-Attack-and-Its-Countermeasure"" target=""_blank"">SSssWEIssSS</a>",2024-12-11
SEEP: Training Dynamics Grounds Latent Representation Search for Mitigating Backdoor Poisoning Attacks,"Xuanli He, Qiongkai Xu, Jun Wang, Benjamin I. P. Rubinstein, Trevor Cohn",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11575"" target=""_blank"">2405.11575</a>",,2024-12-11
Fed-Credit: Robust Federated Learning with Credibility Management,"Jiayan Chen, Zhirong Qian, Tianhui Meng, Xitong Gao, Tian Wang, Weijia Jia",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11758"" target=""_blank"">2405.11758</a>",,2024-12-11
BOSC: A Backdoor-based Framework for Open Set Synthetic Image Attribution,"Jun Wang, Benedetta Tondi, Mauro Barni",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11491"" target=""_blank"">2405.11491</a>",,2024-12-11
Trustworthy Actionable Perturbations,"Jesse Friedbaum, Sudarshan Adiga, Ravi Tandon",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11195"" target=""_blank"">2405.11195</a>",,2024-12-11
Adversarial Robustness Guarantees for Quantum Classifiers,"Neil Dowling, Maxwell T. West, Angus Southwell, Azar C. Nakhl, Martin Sevior, Muhammad Usman, Kavan Modi",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10360"" target=""_blank"">2405.10360</a>",,2024-12-11
A Constraint-Enforcing Reward for Adversarial Attacks on Text Classifiers,"Tom Roth, Inigo Jauregi Unanue, Alsharif Abuadbba, Massimo Piccardi",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11904"" target=""_blank"">2405.11904</a>",,2024-12-11
UPAM: Unified Prompt Attack in Text-to-Image Generation Models Against Both Textual Filters and Visual Checkers,"Duo Peng, Qiuhong Ke, Jun Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11336"" target=""_blank"">2405.11336</a>",,2024-12-11
BadActs: A Universal Backdoor Defense in the Activation Space,"Biao Yi, Sishuo Chen, Yiming Li, Tong Li, Baolei Zhang, Zheli Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11227"" target=""_blank"">2405.11227</a>",,2024-12-11
On Robust Reinforcement Learning with Lipschitz-Bounded Policy Networks,"Nicholas H. Barbara, Ruigang Wang, Ian R. Manchester",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11432"" target=""_blank"">2405.11432</a>",,2024-12-11
Diffusion Model Driven Test-Time Image Adaptation for Robust Skin Lesion Classification,"Ming Hu, Siyuan Yan, Peng Xia, Feilong Tang, Wenxue Li, Peibo Duan, Lin Zhang, Zongyuan Ge",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11289"" target=""_blank"">2405.11289</a>","<a href=""https://github.com/minghu0830/Skin-TTA_Diffusion"" target=""_blank"">minghu0830</a>",2024-12-11
Revisiting the Robust Generalization of Adversarial Prompt Tuning,"Fan Yang, Mingxuan Xia, Sangzhou Xia, Chicheng Ma, Hui Hui",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11154"" target=""_blank"">2405.11154</a>",,2024-12-11
Safeguarding Vision-Language Models Against Patched Visual Prompt Injectors,"Jiachen Sun, Changsheng Wang, Jiongxiao Wang, Yiwei Zhang, Chaowei Xiao",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10529"" target=""_blank"">2405.10529</a>",,2024-12-11
Rethinking Graph Backdoor Attacks: A Distribution-Preserving Perspective,"Zhiwei Zhang, Minhua Lin, Enyan Dai, Suhang Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10757"" target=""_blank"">2405.10757</a>",,2024-12-11
Not All Prompts Are Secure: A Switchable Backdoor Attack Against Pre-trained Vision Transformers,"Sheng Yang, Jiawang Bai, Kuofeng Gao, Yong Yang, Yiming Li, Shu-tao Xia",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10612"" target=""_blank"">2405.10612</a>","<a href=""https://github.com/20000yshust/SWARM"" target=""_blank"">20000yshust</a>",2024-12-11
Boosting Few-Pixel Robustness Verification via Covering Verification Designs,"Yuval Shapira, Naor Wiesel, Shahar Shabelman, Dana Drachsler-Cohen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10924"" target=""_blank"">2405.10924</a>",,2024-12-11
DiffAM: Diffusion-based Adversarial Makeup Transfer for Facial Privacy Protection,"Yuhao Sun, Lingyun Yu, Hongtao Xie, Jiaming Li, Yongdong Zhang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09882"" target=""_blank"">2405.09882</a>","<a href=""https://github.com/HansSunY/DiffAM"" target=""_blank"">HansSunY</a>",2024-12-11
Infrared Adversarial Car Stickers,"Xiaopei Zhu, Yuqiu Liu, Zhanhao Hu, Jianmin Li, Xiaolin Hu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09924"" target=""_blank"">2405.09924</a>",,2024-12-11
Adversarial Robustness for Visual Grounding of Multimodal Large Language Models,"Kuofeng Gao, Yang Bai, Jiawang Bai, Yong Yang, Shu-Tao Xia",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09981"" target=""_blank"">2405.09981</a>",,2024-12-11
BB-Patch: BlackBox Adversarial Patch-Attack using Zeroth-Order Optimization,"Satyadwyoom Kumar, Saurabh Gupta, Arun Balaji Buduru",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06049"" target=""_blank"">2405.06049</a>",,2024-12-11
Adversarial Attacks and Defense for Conversation Entailment Task,"Zhenning Yang, Ryan Krawec, Liang-Yuan Wu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00289"" target=""_blank"">2405.00289</a>",,2024-12-11
Poisoning-based Backdoor Attacks for Arbitrary Target Label with Positive Triggers,"Binxiao Huang, Jason Chun Lok, Chang Liu, Ngai Wong",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05573"" target=""_blank"">2405.05573</a>",,2024-12-11
Adversarial Attacks on Reinforcement Learning Agents for Command and Control,"Ahaan Dabholkar, James Z. Hare, Mark Mittrick, John Richardson, Nicholas Waytowich, Priya Narayanan, Saurabh Bagchi",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01693"" target=""_blank"">2405.01693</a>",,2024-12-11
Updating Windows Malware Detectors: Balancing Robustness and Regression against Adversarial EXEmples,"Matous Kozak, Luca Demetrio, Dmitrijs Trizna, Fabio Roli",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.02646"" target=""_blank"">2405.02646</a>",,2024-12-11
Assessing Adversarial Robustness of Large Language Models: An Empirical Study,"Zeyu Yang, Zhao Meng, Xiaochen Zheng, Roger Wattenhofer",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.02764"" target=""_blank"">2405.02764</a>",,2024-12-11
A Novel Approach to Guard from Adversarial Attacks using Stable Diffusion,"Trinath Sai Subhash Reddy Pittala, Uma Maheswara Rao Meleti, Geethakrishna Puligundla",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01838"" target=""_blank"">2405.01838</a>",,2024-12-11
From Attack to Defense: Insights into Deep Learning Security Measures in Black-Box Settings,"Firuz Juraev, Mohammed Abuhamad, Eric Chan-Tin, George K. Thiruvathukal, Tamer Abuhmed",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01963"" target=""_blank"">2405.01963</a>",,2024-12-11
ProFLingo: A Fingerprinting-based Copyright Protection Scheme for Large Language Models,"Heng Jin, Chaoyu Zhang, Shanghao Shi, Wenjing Lou, Y. Thomas Hou",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.02466"" target=""_blank"">2405.02466</a>","<a href=""https://github.com/hengvt/ProFLingo_arXiv"" target=""_blank"">hengvt</a>",2024-12-11
Impact of Architectural Modifications on Deep Learning Adversarial Robustness,"Firuz Juraev, Mohammed Abuhamad, Simon S. Woo, George K Thiruvathukal, Tamer Abuhmed",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01934"" target=""_blank"">2405.01934</a>",,2024-12-11
Adaptive and robust watermark against model extraction attack,"Kaiyi Pang, Tao Qi, Chuhan Wu, Minhao Bai",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.02365"" target=""_blank"">2405.02365</a>",,2024-12-11
Robust Explainable Recommendation,"Sairamvinay Vijayaraghavan, Prasant Mohapatra",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01855"" target=""_blank"">2405.01855</a>",,2024-12-11
Adversarial Botometer: Adversarial Analysis for Social Bot Detection,"Shaghayegh Najari, Davood Rafiee, Mostafa Salehi, Reza Farahbakhsh",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.02016"" target=""_blank"">2405.02016</a>",,2024-12-11
Position Paper: Beyond Robustness Against Single Attack Types,"Sihui Dai, Chong Xiang, Tong Wu, Prateek Mittal",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01349"" target=""_blank"">2405.01349</a>",,2024-12-11
Explainability Guided Adversarial Evasion Attacks on Malware Detectors,"Kshitiz Aryal, Maanak Gupta, Mahmoud Abdelsalam, Moustafa Saleh",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01728"" target=""_blank"">2405.01728</a>",,2024-12-11
Purify Unlearnable Examples via Rate-Constrained Variational Autoencoders,"Yi Yu, Yufei Wang, Song Xia, Wenhan Yang, Shijian Lu, Yap-Peng Tan, Alex C. Kot",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01460"" target=""_blank"">2405.01460</a>","<a href=""https://github.com/yuyi-sd/D-VAE"" target=""_blank"">yuyi-sd</a>",2024-12-11
Poisoning Attacks on Federated Learning for Autonomous Driving,"Sonakshi Garg, Hugo JÃ¶nsson, Gustav Kalander, Axel Nilsson, Bhhaanu Pirange, Viktor Valadi, Johan Ãstman",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01073"" target=""_blank"">2405.01073</a>",,2024-12-11
Boosting Jailbreak Attack with Momentum,"Yihao Zhang, Zeming Wei",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01229"" target=""_blank"">2405.01229</a>","<a href=""https://github.com/weizeming/momentum-attack-llm"" target=""_blank"">weizeming</a>",2024-12-11
Explainable Malware Detection with Tailored Logic Explained Networks,"Peter Anthony, Francesco Giannini, Michelangelo Diligenti, Martin Homola, Marco Gori, Stefan Balogh, Jan Mojzis",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03009"" target=""_blank"">2405.03009</a>",,2024-12-11
Uniformly Stable Algorithms for Adversarial Training and Beyond,"Jiancong Xiao, Jiawei Zhang, Zhi-Quan Luo, Asuman Ozdaglar",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01817"" target=""_blank"">2405.01817</a>",,2024-12-11
ATTAXONOMY: Unpacking Differential Privacy Guarantees Against Practical Adversaries,"Rachel Cummings, Shlomi Hod, Jayshree Sarathy, Marika Swanberg",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01716"" target=""_blank"">2405.01716</a>",,2024-12-11
Certified Adversarial Robustness of Machine Learning-based Malware Detectors via (De)Randomized Smoothing,"Daniel Gibert, Luca Demetrio, Giulio Zizzo, Quan Le, Jordi Planes, Battista Biggio",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00392"" target=""_blank"">2405.00392</a>",,2024-12-11
JNI Global References Are Still Vulnerable: Attacks and Defenses,"Yi He, Yuan Zhou, Yacong Gu, Purui Su, Qi Li, Yajin Zhou, Yong Jiang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00526"" target=""_blank"">2405.00526</a>",,2024-12-11
Robustness of graph embedding methods for community detection,"Zhi-Feng Wei, Pablo Moriano, Ramakrishnan Kannan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00636"" target=""_blank"">2405.00636</a>",,2024-12-11
Exploiting Positional Bias for Query-Agnostic Generative Content in Search,"Andrew Parry, Sean MacAvaney, Debasis Ganguly",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00469"" target=""_blank"">2405.00469</a>",,2024-12-11
ASAM: Boosting Segment Anything Model with Adversarial Tuning,"Bo Li, Haoke Xiao, Lv Tang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00256"" target=""_blank"">2405.00256</a>","<a href=""https://asam2024.github.io/"" target=""_blank"">asam2024.github.io</a>",2024-12-11
VeriFence: Lightweight and Precise Spectre Defenses for Untrusted Linux Kernel Extensions,"Luis Gerhorst, Henriette Herzog, Peter WÃ¤gemann, Maximilian Ott, RÃ¼diger Kapitza, Timo HÃ¶nig",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00078"" target=""_blank"">2405.00078</a>",,2024-12-11
Learnable Linguistic Watermarks for Tracing Model Extraction Attacks on Large Language Models,"Minhao Bai, Kaiyi Pang, Yongfeng Huang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01509"" target=""_blank"">2405.01509</a>",,2024-12-11
CodeFort: Robust Training for Code Generation Models,"Yuhao Zhang, Shiqi Wang, Haifeng Qian, Zijian Wang, Mingyue Shang, Linbo Liu, Sanjay Krishna Gouda, Baishakhi Ray, Murali Krishna Ramanathan, Xiaofei Ma, Anoop Deoras",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01567"" target=""_blank"">2405.01567</a>",,2024-12-11
DiffuseMix: Label-Preserving Data Augmentation with Diffusion Models,"Khawar Islam, Muhammad Zaigham Zaheer, Arif Mahmood, Karthik Nandakumar",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14881"" target=""_blank"">2405.14881</a>","<a href=""https://diffusemix.github.io/"" target=""_blank"">diffusemix.github.io</a>",2024-12-11
Mask-based Invisible Backdoor Attacks on Object Detection,Shin Jeong Jin,arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09550"" target=""_blank"">2405.09550</a>",,2024-12-11
Exploring mechanisms of Neural Robustness: probing the bridge between geometry and spectrum,"Konstantin Holzhausen, Mia Merlid, HÃ¥kon Olav Torvik, Anders Malthe-SÃ¸renssen, Mikkel Elle LepperÃ¸d",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00679"" target=""_blank"">2405.00679</a>",,2024-12-11
Leveraging the Human Ventral Visual Stream to Improve Neural Network Robustness,"Zhenan Shao, Linjian Ma, Bo Li, Diane M. Beck",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.02564"" target=""_blank"">2405.02564</a>",,2024-12-11
To Each (Textual Sequence) Its Own: Improving Memorized-Data Unlearning in Large Language Models,"George-Octavian Barbulescu, Peter Triantafillou",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03097"" target=""_blank"">2405.03097</a>",,2024-12-11
Link Stealing Attacks Against Inductive Graph Neural Networks,"Yixin Wu, Xinlei He, Pascal Berrang, Mathias Humbert, Michael Backes, Neil Zhenqiang Gong, Yang Zhang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05784"" target=""_blank"">2405.05784</a>",,2024-12-11
Explainability-Informed Targeted Malware Misclassification,"Quincy Card, Kshitiz Aryal, Maanak Gupta",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.04010"" target=""_blank"">2405.04010</a>",,2024-12-11
Hard Work Does Not Always Pay Off: Poisoning Attacks on Neural Architecture Search,"Zachary Coalson, Huazheng Wang, Qingyun Wu, Sanghyun Hong",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06073"" target=""_blank"">2405.06073</a>",,2024-12-11
Concealing Backdoor Model Updates in Federated Learning by Trigger-Optimized Data Poisoning,"Yujie Zhang, Neil Gong, Michael K. Reiter",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06206"" target=""_blank"">2405.06206</a>",,2024-12-11
Towards Robust Physical-world Backdoor Attacks on Lane Detection,"Xinwei Zhang, Aishan Liu, Tianyuan Zhang, Siyuan Liang, Xianglong Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05553"" target=""_blank"">2405.05553</a>",,2024-12-11
Model Inversion Robustness: Can Transfer Learning Help? (45%),"Sy-Tuyen Ho, Koh Jun Hao, Keshigeyan Chandrasegaran, Ngoc-Bao Nguyen, Ngai-Man Cheung",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05588"" target=""_blank"">2405.05588</a>","<a href=""https://hosytuyen.github.io/projects/TL-DMI"" target=""_blank"">projects</a>",2024-12-11
Chain of Attack: a Semantic-Driven Contextual Multi-Turn attacker for LLM,"Xikang Yang, Xuehai Tang, Songlin Hu, Jizhong Han",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05610"" target=""_blank"">2405.05610</a>",,2024-12-11
Demystifying Behavior-Based Malware Detection at Endpoints,"Yigitcan Kaya, Yizheng Chen, Shoumik Saha, Fabio Pierazzi, Lorenzo Cavallaro, David Wagner, Tudor Dumitras",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06124"" target=""_blank"">2405.06124</a>",,2024-12-11
Universal Adversarial Perturbations for Vision-Language Pre-trained Models,"Peng-Fei Zhang, Zi Huang, Guangdong Bai",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05524"" target=""_blank"">2405.05524</a>",,2024-12-11
Adversarial Threats to Automatic Modulation Open Set Recognition in Wireless Networks,"Yandie Yang, Sicheng Zhang, Kuixian Li, Qiao Tian, Yun Lin",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05022"" target=""_blank"">2405.05022</a>",,2024-12-11
Untargeted Adversarial Attack on Knowledge Graph Embeddings,"Tianzhe Zhao, Jiaoyan Chen, Yanchi Ru, Qika Lin, Yuxia Geng, Jun Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10970"" target=""_blank"">2405.10970</a>",,2024-12-11
Towards Efficient Training and Evaluation of Robust Models against $l_0$ Bounded Adversarial Perturbations,"Xuyang Zhong, Yixiao Huang, Chen Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05075"" target=""_blank"">2405.05075</a>","<a href=""https://github.com/CityU-MLO/sPGD"" target=""_blank"">CityU-MLO</a>",2024-12-11
Towards Accurate and Robust Architectures via Neural Architecture Search,"Yuwei Ou, Yuqi Feng, Yanan Sun",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05502"" target=""_blank"">2405.05502</a>",,2024-12-11
Explanation as a Watermark: Towards Harmless and Multi-bit Model Ownership Verification via Watermarking Feature Attribution,"Shuo Shao, Yiming Li, Hongwei Yao, Yiling He, Zhan Qin, Kui Ren",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.04825"" target=""_blank"">2405.04825</a>",,2024-12-11
Revisiting character-level adversarial attacks,"Elias Abad Rocamora, Yongtao Wu, Fanghui Liu, Grigorios G. Chrysos, Volkan Cevher",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.04346"" target=""_blank"">2405.04346</a>","<a href=""https://github.com/LIONS-EPFL/Charmer"" target=""_blank"">LIONS-EPFL</a>",2024-12-11
Effective and Robust Adversarial Training against Data and Label Corruptions,"Peng-Fei Zhang, Zi Huang, Xin-Shun Xu, Guangdong Bai",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.04191"" target=""_blank"">2405.04191</a>",,2024-12-11
Defense against Joint Poison and Evasion Attacks: A Case Study of DERMS,"Zain ul Abdeen, Padmaksha Roy, Ahmad Al-Tawaha, Rouxi Jia, Laura Freeman, Peter Beling, Chen-Ching Liu, Alberto Sangiovanni-Vincentelli, Ming Jin",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.02989"" target=""_blank"">2405.02989</a>",,2024-12-11
Going Proactive and Explanatory Against Malware Concept Drift,"Yiling He, Junchi Lei, Zhan Qin, Kui Ren",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.04095"" target=""_blank"">2405.04095</a>",,2024-12-11
Verified Neural Compressed Sensing,"Rudy Bunel, Krishnamurthy Dvijotham, M. Pawan Kumar, Palma Alessandro De, Robert Stanforth",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.04260"" target=""_blank"">2405.04260</a>",,2024-12-11
Exploring Frequencies via Feature Mixing and Meta-Learning for Improving Adversarial Transferability,"Juanjuan Weng, Zhiming Luo, Shaozi Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03193"" target=""_blank"">2405.03193</a>","<a href=""https://github.com/WJJLL/MetaSSA"" target=""_blank"">WJJLL</a>",2024-12-11
Cutting through buggy adversarial example defenses: fixing 1 line of code breaks Sabre,Nicholas Carlini,arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03672"" target=""_blank"">2405.03672</a>",,2024-12-11
On Adversarial Examples for Text Classification by Perturbing Latent Representations,"Korn Sooksatra, Bikram Khanal, Pablo Rivas",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03789"" target=""_blank"">2405.03789</a>",,2024-12-11
Is ReLU Adversarially Robust? (98%),"Korn Sooksatra, Greg Hamerly, Pablo Rivas",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03777"" target=""_blank"">2405.03777</a>",,2024-12-11
Enhancing O-RAN Security: Evasion Attacks and Robust Defenses for Graph Reinforcement Learning-based Connection Management,"Ravikumar Balakrishnan, Marius Arvinte, Nageen Himayat, Hosein Nikopour, Hassnaa Moustafa",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03891"" target=""_blank"">2405.03891</a>",,2024-12-11
BadFusion: 2D-Oriented Backdoor Attacks against 3D Object Detection,"Saket S. Chaturvedi, Lan Zhang, Wenbin Zhang, Pan He, Xiaoyong Yuan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03884"" target=""_blank"">2405.03884</a>",,2024-12-11
Provably Unlearnable Examples,"Derui Wang, Minhui Xue, Bo Li, Seyit Camtepe, Liming Zhu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03316"" target=""_blank"">2405.03316</a>",,2024-12-11
DarkFed: A Data-Free Backdoor Attack in Federated Learning,"Minghui Li, Wei Wan, Yuxuan Ning, Shengshan Hu, Lulu Xue, Leo Yu Zhang, Yichen Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03299"" target=""_blank"">2405.03299</a>",,2024-12-11
Why is SAM Robust to Label Noise? (1%),"Christina Baek, Zico Kolter, Aditi Raghunathan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03676"" target=""_blank"">2405.03676</a>",,2024-12-11
Detecting Android Malware: From Neural Embeddings to Hands-On Validation with BERTroid,"Meryam Chaieb, Mostafa Anouar Ghorab, Mohamed Aymen Saied",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03620"" target=""_blank"">2405.03620</a>",,2024-12-11
LaserEscape: Detecting and Mitigating Optical Probing Attacks,"Saleh Khalaj Monfared, Kyle Mitard, Andrew Cannon, Domenic Forte, Shahin Tajik",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03632"" target=""_blank"">2405.03632</a>",,2024-12-11
GAN-GRID: A Novel Generative Attack on Smart Grid Stability Prediction,"Emad Efatinasab, Alessandro Brighente, Mirco Rampazzo, Nahal Azadi, Mauro Conti",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12076"" target=""_blank"">2405.12076</a>",,2024-12-11
UnsafeBench: Benchmarking Image Safety Classifiers on Real-World and AI-Generated Images,"Yiting Qu, Xinyue Shen, Yixin Wu, Michael Backes, Savvas Zannettou, Yang Zhang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03486"" target=""_blank"">2405.03486</a>",,2024-12-11
Tiny Refinements Elicit Resilience: Toward Efficient Prefix-Model Against LLM Red-Teaming,"Jiaxu Liu, Xiangyu Yin, Sihao Wu, Jianhong Wang, Meng Fang, Xinping Yi, Xiaowei Huang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12604"" target=""_blank"">2405.12604</a>",,2024-12-11
Can We Trust Embodied Agents? Exploring Backdoor Attacks against Embodied LLM-based Decision-Making Systems,"Ruochen Jiao, Shaoyuan Xie, Justin Yue, Takami Sato, Lixu Wang, Yixuan Wang, Qi Alfred Chen, Qi Zhu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20774"" target=""_blank"">2405.20774</a>",,2024-12-11
EntProp: High Entropy Propagation for Improving Accuracy and Robustness,Shohei Enomoto,arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18931"" target=""_blank"">2405.18931</a>",,2024-12-11
ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning,"Ruchika Chavhan, Da Li, Timothy Hospedales",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19237"" target=""_blank"">2405.19237</a>",,2024-12-11
Resurrecting Old Classes with New Data for Exemplar-Free Continual Learning,"Dipam Goswami, Albin Soutif--Cormerais, Yuyang Liu, Sandesh Kamath, BartÅomiej Twardowski, de Weijer Joost van",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19074"" target=""_blank"">2405.19074</a>","<a href=""https://github.com/dipamgoswami/ADC"" target=""_blank"">dipamgoswami</a>",2024-12-11
Node Injection Attack Based on Label Propagation Against Graph Neural Network,"Peican Zhu, Zechen Pan, Keke Tang, Xiaodong Cui, Jinhuan Wang, Qi Xuan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18824"" target=""_blank"">2405.18824</a>",,2024-12-11
Query Provenance Analysis: Efficient and Robust Defense against Query-based Black-box Attacks,"Shaofei Li, Ziqi Zhang, Haomin Jia, Ding Li, Yao Guo, Xiangqun Chen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20641"" target=""_blank"">2405.20641</a>",,2024-12-11
Genshin: General Shield for Natural Language Processing with Large Language Models,"Xiao Peng, Tao Liu, Ying Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18741"" target=""_blank"">2405.18741</a>",,2024-12-11
Confronting the Reproducibility Crisis: A Case Study of Challenges in Cybersecurity AI,"Richard H. Moulton, Gary A. McCully, John D. Hastings",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18753"" target=""_blank"">2405.18753</a>",,2024-12-11
Enhancing Security and Privacy in Federated Learning using Update Digests and Voting-Based Defense,"Wenjie Li, Kai Fan, Jingyuan Zhang, Hui Li, Wei Yang Bryan Lim, Qiang Yang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18802"" target=""_blank"">2405.18802</a>",,2024-12-11
Gone but Not Forgotten: Improved Benchmarks for Machine Unlearning,"Keltin Grimes, Collin Abidi, Cole Frank, Shannon Gallagher",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19211"" target=""_blank"">2405.19211</a>",,2024-12-11
MemControl: Mitigating Memorization in Diffusion Models via Automated Parameter Selection,"Raman Dutt, Ondrej Bohdal, Pedro Sanchez, Sotirios A. Tsaftaris, Timothy Hospedales",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19458"" target=""_blank"">2405.19458</a>","<a href=""https://github.com/Raman1121/Diffusion_Memorization_HPO"" target=""_blank"">Raman1121</a>",2024-12-11
Towards Unified Robustness Against Both Backdoor and Adversarial Attacks,"Zhenxing Niu, Yuyao Sun, Qiguang Miao, Rong Jin, Gang Hua",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17929"" target=""_blank"">2405.17929</a>",,2024-12-11
Improved Generation of Adversarial Examples Against Safety-aligned LLMs,"Qizhang Li, Yiwen Guo, Wangmeng Zuo, Hao Chen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20778"" target=""_blank"">2405.20778</a>","<a href=""https://github.com/qizhangli/Gradient-based-Jailbreak-Attacks"" target=""_blank"">qizhangli</a>",2024-12-11
PureGen: Universal Data Purification for Train-Time Poison Defense via Generative Model Dynamics,"Sunay Bhat, Jeffrey Jiang, Omead Pooladzandi, Alexander Branch, Gregory Pottie",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18627"" target=""_blank"">2405.18627</a>",,2024-12-11
PureEBM: Universal Poison Purification via Mid-Run Dynamics of Energy-Based Models,"Omead Pooladzandi, Jeffrey Jiang, Sunay Bhat, Gregory Pottie",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19376"" target=""_blank"">2405.19376</a>",,2024-12-11
White-box Multimodal Jailbreaks Against Large Vision-Language Models,"Ruofan Wang, Xingjun Ma, Hanxu Zhou, Chuanjun Ji, Guangnan Ye, Yu-Gang Jiang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17894"" target=""_blank"">2405.17894</a>",,2024-12-11
Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing,"Wei Zhao, Zhe Li, Yige Li, Ye Zhang, Jun Sun",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18166"" target=""_blank"">2405.18166</a>","<a href=""https://github.com/ledllm/ledllm"" target=""_blank"">ledllm</a>",2024-12-11
Wavelet-Based Image Tokenizer for Vision Transformers,"Zhenhai Zhu, Radu Soricut",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18616"" target=""_blank"">2405.18616</a>",,2024-12-11
Cross-Context Backdoor Attacks against Graph Prompt Learning,"Xiaoting Lyu, Yufei Han, Wei Wang, Hangwei Qian, Ivor Tsang, Xiangliang Zhang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17984"" target=""_blank"">2405.17984</a>",,2024-12-11
BlueSWAT: A Lightweight State-Aware Security Framework for Bluetooth Low Energy,"Xijia Che, Yi He, Xuewei Feng, Kun Sun, Ke Xu, Qi Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17987"" target=""_blank"">2405.17987</a>",,2024-12-11
Watermarking Counterfactual Explanations,"Hangzhi Guo, Firdaus Ahmed Choudhury, Tinghua Chen, Amulya Yadav",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18671"" target=""_blank"">2405.18671</a>",,2024-12-11
Black-Box Detection of Language Model Watermarks,"Thibaud Gloaguen, Nikola JovanoviÄ, Robin Staab, Martin Vechev",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20777"" target=""_blank"">2405.20777</a>",,2024-12-11
Adversarial Attacks on Both Face Recognition and Face Anti-spoofing Models,"Fengfan Zhou, Qianyu Zhou, Xiangtai Li, Xuequan Lu, Lizhuang Ma, Hefei Ling",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16940"" target=""_blank"">2405.16940</a>",,2024-12-11
The Uncanny Valley: Exploring Adversarial Robustness from a Flatness Perspective,"Nils Philipp Walter, Linara Adilova, Jilles Vreeken, Michael Kamp",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16918"" target=""_blank"">2405.16918</a>",,2024-12-11
Exploiting the Layered Intrinsic Dimensionality of Deep Models for Practical Adversarial Training,"Enes Altinisik, Safa Messaoud, Husrev Taha Sencar, Hassan Sajjad, Sanjay Chawla",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17130"" target=""_blank"">2405.17130</a>",,2024-12-11
Spectral regularization for adversarially-robust representation learning,"Sheng Yang, Jacob A. Zavatone-Veth, Cengiz Pehlevan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17181"" target=""_blank"">2405.17181</a>",,2024-12-11
TIMA: Text-Image Mutual Awareness for Balancing Zero-Shot Adversarial Robustness and Generalization Ability,"Fengji Ma, Li Liu, Hei Victor Cheng",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17678"" target=""_blank"">2405.17678</a>",,2024-12-11
OSLO: One-Shot Label-Only Membership Inference Attacks,"Yuefeng Peng, Jaechul Roh, Subhransu Maji, Amir Houmansadr",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16978"" target=""_blank"">2405.16978</a>",,2024-12-11
Verifying Properties of Binary Neural Networks Using Sparse Polynomial Optimization,"Jianting Yang, SreÄko ÃuraÅ¡inoviÄ, Jean-Bernard Lasserre, Victor Magron, Jun Zhao",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17049"" target=""_blank"">2405.17049</a>",,2024-12-11
Rethinking Pruning for Backdoor Mitigation: An Optimization Perspective,"Nan Li, Haiyang Yu, Ping Yi",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17746"" target=""_blank"">2405.17746</a>",,2024-12-11
AutoBreach: Universal and Adaptive Jailbreaking with Efficient Wordplay-Guided Optimization,"Jiawei Chen, Xiao Yang, Zhengwei Fang, Yu Tian, Yinpeng Dong, Zhaoxia Yin, Hang Su",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19668"" target=""_blank"">2405.19668</a>",,2024-12-11
AI Risk Management Should Incorporate Both Safety and Security,"Xiangyu Qi, Yangsibo Huang, Yi Zeng, Edoardo Debenedetti, Jonas Geiping, Luxi He, Kaixuan Huang, Udari Madhushani, Vikash Sehwag, Weijia Shi, Boyi Wei, Tinghao Xie, Danqi Chen, Pin-Yu Chen, Jeffrey Ding, Ruoxi Jia, Jiaqi Ma, Arvind Narayanan, Weijie J Su, Mengdi Wang, Chaowei Xiao, Bo Li, Dawn Song, Peter Henderson, Prateek Mittal",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19524"" target=""_blank"">2405.19524</a>",,2024-12-11
Verifiably Robust Conformal Prediction,"Linus Jeary, Tom Kuipers, Mehran Hosseini, Nicola Paoletti",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18942"" target=""_blank"">2405.18942</a>",,2024-12-11
Phantom: General Trigger Attacks on Retrieval Augmented Language Generation,"Harsh Chaudhari, Giorgio Severi, John Abascal, Matthew Jagielski, Christopher A. Choquette-Choo, Milad Nasr, Cristina Nita-Rotaru, Alina Oprea",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20485"" target=""_blank"">2405.20485</a>",,2024-12-11
ACE: A Model Poisoning Attack on Contribution Evaluation Methods in Federated Learning,"Zhangchen Xu, Fengqing Jiang, Luyao Niu, Jinyuan Jia, Bo Li, Radha Poovendran",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20975"" target=""_blank"">2405.20975</a>",,2024-12-11
Improved Techniques for Optimization-Based Jailbreaking on Large Language Models,"Xiaojun Jia, Tianyu Pang, Chao Du, Yihao Huang, Jindong Gu, Yang Liu, Xiaochun Cao, Min Lin",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.21018"" target=""_blank"">2405.21018</a>","<a href=""https://github.com/jiaxiaojunQAQ/I-GCG"" target=""_blank"">jiaxiaojunQAQ</a>",2024-12-11
Enhancing Jailbreak Attack Against Large Language Models through Silent Tokens,"Jiahao Yu, Haozheng Luo, Jerry Yao-Chieh Hu, Wenbo Guo, Han Liu, Xinyu Xing",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20653"" target=""_blank"">2405.20653</a>",,2024-12-11
Dullahan: Stealthy Backdoor Attack against Without-Label-Sharing Split Learning,"Yuwen Pu, Zhuoyuan Ding, Jiahao Chen, Chunyi Zhou, Qingming Li, Chunqiang Hu, Shouling Ji",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12751"" target=""_blank"">2405.12751</a>",,2024-12-11
GANcrop: A Contrastive Defense Against Backdoor Attacks in Federated Learning,"Xiaoyun Gan, Shanyu Gan, Taizhi Su, Peng Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20727"" target=""_blank"">2405.20727</a>",,2024-12-11
Investigating and unmasking feature-level vulnerabilities of CNNs to adversarial perturbations,"Davide Coppola, Hwee Kuan Lee",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20672"" target=""_blank"">2405.20672</a>",,2024-12-11
Neural Network Verification with Branch-and-Bound for General Nonlinearities,"Zhouxing Shi, Qirui Jin, Zico Kolter, Suman Jana, Cho-Jui Hsieh, Huan Zhang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.21063"" target=""_blank"">2405.21063</a>",,2024-12-11
GI-NAS: Boosting Gradient Inversion Attacks through Adaptive Neural Architecture Search,"Wenbo Yu, Hao Fang, Bin Chen, Xiaohang Sui, Chuan Chen, Hao Wu, Shu-Tao Xia, Ke Xu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20725"" target=""_blank"">2405.20725</a>",,2024-12-11
Robust Stable Spiking Neural Networks,"Jianhao Ding, Zhiyu Pan, Yujia Liu, Zhaofei Yu, Tiejun Huang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20694"" target=""_blank"">2405.20694</a>",,2024-12-11
Disrupting Diffusion: Token-Level Attention Erasure Attack against Diffusion-based Customization,"Yisu Liu, Jinyang An, Wanqian Zhang, Dayan Wu, Jingzi Gu, Zheng Lin, Weiping Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20584"" target=""_blank"">2405.20584</a>",,2024-12-11
HOLMES: to Detect Adversarial Examples with Multiple Detectors,Jing Wen,arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19956"" target=""_blank"">2405.19956</a>",,2024-12-11
Typography Leads Semantic Diversifying: Amplifying Adversarial Transferability across Multimodal Large Language Models,"Hao Cheng, Erjia Xiao, Jiayan Yang, Jiahang Cao, Qiang Zhang, Le Yang, Jize Zhang, Kaidi Xu, Jindong Gu, Renjing Xu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20090"" target=""_blank"">2405.20090</a>",,2024-12-11
Exploring the Robustness of Decision-Level Through Adversarial Attacks on LLM-Based Embodied Models,"Shuyuan Liu, Jiawei Chen, Shouwei Ruan, Hang Su, Zhaoxia Yin",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19802"" target=""_blank"">2405.19802</a>",,2024-12-11
SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents,"Ethan Rathbun, Christopher Amato, Alina Oprea",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20539"" target=""_blank"">2405.20539</a>",,2024-12-11
Evaluating the Effectiveness and Robustness of Visual Similarity-based Phishing Detection Models,"Fujiao Ji, Kiho Lee, Hyungjoon Koo, Wenhao You, Euijin Choo, Hyoungshick Kim, Doowon Kim",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19598"" target=""_blank"">2405.19598</a>",,2024-12-11
BAN: Detecting Backdoors Activated by Adversarial Neuron Noise,"Xiaoyun Xu, Zhuoran Liu, Stefanos Koffas, Shujian Yu, Stjepan Picek",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19928"" target=""_blank"">2405.19928</a>",,2024-12-11
Is My Data in Your Retrieval Database? Membership Inference Attacks Against Retrieval Augmented Generation,"Maya Anderson, Guy Amit, Abigail Goldsteen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20446"" target=""_blank"">2405.20446</a>",,2024-12-11
Defensive Prompt Patch: A Robust and Interpretable Defense of LLMs against Jailbreak Attacks,"Chen Xiong, Xiangyu Qi, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20099"" target=""_blank"">2405.20099</a>",,2024-12-11
Large Language Model Watermark Stealing With Mixed Integer Programming,"Zhaoxi Zhang, Xiaomei Zhang, Yanjun Zhang, Leo Yu Zhang, Chao Chen, Shengshan Hu, Asif Gill, Shirui Pan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19677"" target=""_blank"">2405.19677</a>",,2024-12-11
DiffPhysBA: Diffusion-based Physical Backdoor Attack against Person Re-Identification in Real-World,"Wenli Sun, Xinyang Jiang, Dongsheng Li, Cairong Zhao",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19990"" target=""_blank"">2405.19990</a>",,2024-12-11
Unveiling and Mitigating Backdoor Vulnerabilities based on Unlearning Weight Changes and Backdoor Activeness,"Weilin Lin, Li Liu, Shaokui Wei, Jianze Li, Hui Xiong",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20291"" target=""_blank"">2405.20291</a>",,2024-12-11
Certifying Global Robustness for Deep Neural Networks,"You Li, Guannan Zhao, Shuyu Kong, Yunqi He, Hai Zhou",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20556"" target=""_blank"">2405.20556</a>",,2024-12-11
Breaking Indistinguishability with Transfer Learning: A First Look at SPECK32/64 Lightweight Block Ciphers,"Jimmy Dani, Kalyan Nakka, Nitesh Saxena",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19683"" target=""_blank"">2405.19683</a>",,2024-12-11
Reconstruction Attacks on Machine Unlearning: Simple Models are Vulnerable,"Martin Bertran, Shuai Tang, Michael Kearns, Jamie Morgenstern, Aaron Roth, Zhiwei Steven Wu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20272"" target=""_blank"">2405.20272</a>",,2024-12-11
Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior,"Shuyu Cheng, Yibo Miao, Yinpeng Dong, Xiao Yang, Xiao-Shan Gao, Jun Zhu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19098"" target=""_blank"">2405.19098</a>","<a href=""https://github.com/yibo-miao/PBO-Attack"" target=""_blank"">yibo-miao</a>",2024-12-11
Leveraging Many-To-Many Relationships for Defending Against Visual-Language Adversarial Attacks,"Futa Waseda, Antonio Tejero-de-Pablos",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18770"" target=""_blank"">2405.18770</a>",,2024-12-11
Model Agnostic Defense against Adversarial Patch Attacks on Object Detection in Unmanned Aerial Vehicles,"Saurabh Pathak, Samridha Shrestha, Abdelrahman AlMahmoud",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19179"" target=""_blank"">2405.19179</a>",,2024-12-11
Diffusion Policy Attacker: Crafting Adversarial Attacks for Diffusion-based Policies,"Yipu Chen, Haotian Xue, Yongxin Chen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19424"" target=""_blank"">2405.19424</a>",,2024-12-11
Navigating the Safety Landscape: Measuring Risks in Finetuning Large Language Models,"ShengYun Peng, Pin-Yu Chen, Matthew Hull, Duen Horng Chau",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17374"" target=""_blank"">2405.17374</a>","<a href=""https://github.com/ShengYun-Peng/llm-landscape"" target=""_blank"">ShengYun-Peng</a>",2024-12-11
Enhancing Adversarial Robustness in SNNs with Sparse Gradients,"Yujia Liu, Tong Bu, Jianhao Ding, Zecheng Hao, Tiejun Huang, Zhaofei Yu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20355"" target=""_blank"">2405.20355</a>",,2024-12-11
LabObf: A Label Protection Scheme for Vertical Federated Learning Through Label Obfuscation,"Ying He, Mingyang Niu, Jingyu Hua, Yunlong Mao, Xu Huang, Chen Li, Sheng Zhong",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17042"" target=""_blank"">2405.17042</a>",,2024-12-11
"Revisit, Extend, and Enhance Hessian-Free Influence Functions","Ziao Yang, Han Yue, Jian Chen, Hongfu Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17490"" target=""_blank"">2405.17490</a>",,2024-12-11
Certified Robustness against Sparse Adversarial Perturbations via Data Localization,"Ambar Pal, RenÃ© Vidal, Jeremias Sulam",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14176"" target=""_blank"">2405.14176</a>",,2024-12-11
A New Formulation for Zeroth-Order Optimization of Adversarial EXEmples in Malware Detection,"Marco Rando, Luca Demetrio, Lorenzo Rosasco, Fabio Roli",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14519"" target=""_blank"">2405.14519</a>",,2024-12-11
Generating camera failures as a class of physics-based adversarial examples,"Manav Prabhakar, Jwalandhar Girnar, Arpan Kusari",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15033"" target=""_blank"">2405.15033</a>",,2024-12-11
TrojanForge: Generating Adversarial Hardware Trojan Examples with Reinforcement Learning,"Amin Sarihi, Peter Jamieson, Ahmad Patooghy, Abdel-Hameed A. Badawy",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15184"" target=""_blank"">2405.15184</a>",,2024-12-11
Towards Transferable Attacks Against Vision-LLMs in Autonomous Driving with Typography,"Nhat Chung, Sensen Gao, Tuan-Anh Vu, Jie Zhang, Aishan Liu, Yun Lin, Jin Song Dong, Qing Guo",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14169"" target=""_blank"">2405.14169</a>",,2024-12-11
SLIFER: Investigating Performance and Robustness of Malware Detection Pipelines,"Andrea Ponte, Dmitrijs Trizna, Luca Demetrio, Battista Biggio, Ivan Tesfai Ogbu, Fabio Roli",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14478"" target=""_blank"">2405.14478</a>",,2024-12-11
How Does Bayes Error Limit Probabilistic Robust Accuracy,"Ruihan Zhang, Jun Sun",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14923"" target=""_blank"">2405.14923</a>",,2024-12-11
Universal Robustness via Median Randomized Smoothing for Real-World Super-Resolution,"Zakariya Chaouai, Mohamed Tamaazousti",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14934"" target=""_blank"">2405.14934</a>",,2024-12-11
Towards Imperceptible Backdoor Attack in Self-supervised Learning,"Hanrong Zhang, Zhenting Wang, Tingxu Han, Mingyu Jin, Chenlu Zhan, Mengnan Du, Hongwei Wang, Shiqing Ma",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14672"" target=""_blank"">2405.14672</a>","<a href=""https://github.com/Zhang-Henry/IMPERATIVE"" target=""_blank"">Zhang-Henry</a>",2024-12-11
AdjointDEIS: Efficient Gradients for Diffusion Models,"Zander W. Blasingame, Chen Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15020"" target=""_blank"">2405.15020</a>","<a href=""https://zblasingame.github.io/AdjointDEIS/"" target=""_blank"">AdjointDEIS</a>",2024-12-11
What Variables Affect Out-of-Distribution Generalization in Pretrained Models? (9%),"Md Yousuf Harun, Kyungbok Lee, Jhair Gallardo, Giri Krishnan, Christopher Kanan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15018"" target=""_blank"">2405.15018</a>",,2024-12-11
Tighter Privacy Auditing of DP-SGD in the Hidden State Threat Model,"Tudor Cebere, AurÃ©lien Bellet, Nicolas Papernot",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14457"" target=""_blank"">2405.14457</a>",,2024-12-11
RFLPA: A Robust Federated Learning Framework against Poisoning Attacks with Secure Aggregation,"Peihua Mai, Ran Yan, Yan Pang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15182"" target=""_blank"">2405.15182</a>",,2024-12-11
Are You Copying My Prompt? Protecting the Copyright of Vision Prompt for VPaaS via Watermark,"Huali Ren, Anli Yan, Chong-zhi Gao, Hongyang Yan, Zhenxin Zhang, Jin Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15161"" target=""_blank"">2405.15161</a>",,2024-12-11
Learning to Transform Dynamically for Better Adversarial Transferability,"Rongyi Zhu, Zeliang Zhang, Susan Liang, Zhuo Liu, Chenliang Xu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14077"" target=""_blank"">2405.14077</a>","<a href=""https://github.com/RongyiZhu/L2T"" target=""_blank"">RongyiZhu</a>",2024-12-11
Adversarial Training of Two-Layer Polynomial and ReLU Activation Networks via Convex Optimization,"Daniel Kuelbs, Sanjay Lall, Mert Pilanci",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14033"" target=""_blank"">2405.14033</a>",,2024-12-11
Towards Certification of Uncertainty Calibration under Adversarial Attacks,"Cornelius Emde, Francesco Pinto, Thomas Lukasiewicz, Philip H. S. Torr, Adel Bibi",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.13922"" target=""_blank"">2405.13922</a>",,2024-12-11
LookHere: Vision Transformers with Directed Attention Generalize and Extrapolate,"Anthony Fuller, Daniel G. Kyrollos, Yousef Yassin, James R. Green",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.13985"" target=""_blank"">2405.13985</a>",,2024-12-11
Remote Keylogging Attacks in Multi-user VR Applications,"Zihao Su, Kunlin Cai, Reuben Beeler, Lukas Dresel, Allan Garcia, Ilya Grishchenko, Yuan Tian, Christopher Kruegel, Giovanni Vigna",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14036"" target=""_blank"">2405.14036</a>",,2024-12-11
A novel reliability attack of Physical Unclonable Functions,"Gaoxiang Li, Yu Zhuang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.13147"" target=""_blank"">2405.13147</a>",,2024-12-11
Nearly Tight Black-Box Auditing of Differentially Private Machine Learning,"Meenatchi Sundaram Muthu Selva Annamalai, Cristofaro Emiliano De",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14106"" target=""_blank"">2405.14106</a>","<a href=""https://github.com/spalabucr/bb-audit-dpsgd"" target=""_blank"">spalabucr</a>",2024-12-11
WordGame: Efficient & Effective LLM Jailbreak via Simultaneous Obfuscation in Query and Response,"Tianrong Zhang, Bochuan Cao, Yuanpu Cao, Lu Lin, Prasenjit Mitra, Jinghui Chen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14023"" target=""_blank"">2405.14023</a>",,2024-12-11
Mellivora Capensis: A Backdoor-Free Training Framework on the Poisoned Dataset without Auxiliary Data,"Yuwen Pu, Jiahao Chen, Chunyi Zhou, Zhou Feng, Qingming Li, Chunqiang Hu, Shouling Ji",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12719"" target=""_blank"">2405.12719</a>",,2024-12-11
Adversarial Training via Adaptive Knowledge Amalgamation of an Ensemble of Teachers,"Shayan Mohajer Hamidi, Linfeng Ye",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.13324"" target=""_blank"">2405.13324</a>",,2024-12-11
Rethinking the Vulnerabilities of Face Recognition Systems:From a Practical Perspective,"Jiahao Chen, Zhiqiang Shen, Yuwen Pu, Chunyi Zhou, Shouling Ji",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12786"" target=""_blank"">2405.12786</a>",,2024-12-11
EmInspector: Combating Backdoor Attacks in Federated Self-Supervised Learning Through Embedding Inspection,"Yuwen Qian, Shuchi Wu, Kang Wei, Ming Ding, Di Xiao, Tao Xiang, Chuan Ma, Song Guo",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.13080"" target=""_blank"">2405.13080</a>","<a href=""https://github.com/ShuchiWu/EmInspector"" target=""_blank"">ShuchiWu</a>",2024-12-11
Fully Randomized Pointers,"Gregory J. Duck, Sai Dhawal Phaye, Roland H. C. Yap, Trevor E. Carlson",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12513"" target=""_blank"">2405.12513</a>",,2024-12-11
Nearest is Not Dearest: Towards Practical Defense against Quantization-conditioned Backdoor Attacks,"Boheng Li, Yishuo Cai, Haowei Li, Feng Xue, Zhifeng Li, Yiming Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12725"" target=""_blank"">2405.12725</a>","<a href=""https://github.com/AntigoneRandy/QuantBackdoor_EFRAP"" target=""_blank"">AntigoneRandy</a>",2024-12-11
Magnitude-based Neuron Pruning for Backdoor Defens,"Nan Li, Haoyu Jiang, Ping Yi",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17750"" target=""_blank"">2405.17750</a>",,2024-12-11
"Eidos: Efficient, Imperceptible Adversarial 3D Point Clouds","Hanwei Zhang, Luo Cheng, Qisong He, Wei Huang, Renjue Li, Ronan Sicre, Xiaowei Huang, Holger Hermanns, Lijun Zhang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14210"" target=""_blank"">2405.14210</a>",,2024-12-11
Unveiling the Achilles' Heel of NLG Evaluators: A Unified Adversarial Framework Driven by Large Language Models,"Yiming Chen, Chen Zhang, Danqing Luo, Luis Fernando D'Haro, Robby T. Tan, Haizhou Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14646"" target=""_blank"">2405.14646</a>",,2024-12-11
AuthNet: Neural Network with Integrated Authentication Logic,"Yuling Cai, Fan Xiang, Guozhu Meng, Yinzhi Cao, Kai Chen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15426"" target=""_blank"">2405.15426</a>",,2024-12-11
No Two Devils Alike: Unveiling Distinct Mechanisms of Fine-tuning Attacks,"Chak Tou Leong, Yi Cheng, Kaishuai Xu, Jian Wang, Hanlin Wang, Wenjie Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16229"" target=""_blank"">2405.16229</a>",,2024-12-11
TrojFM: Resource-efficient Backdoor Attacks against Very Large Foundation Models,"Yuzhou. Nie, Yanting. Wang, Jinyuan. Jia, Lucia Michael J. De, Nathaniel D. Bastian, Wenbo. Guo, Dawn. Song",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16783"" target=""_blank"">2405.16783</a>",,2024-12-11
Pruning for Robust Concept Erasing in Diffusion Models,"Tianyun Yang, Juan Cao, Chang Xu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16534"" target=""_blank"">2405.16534</a>",,2024-12-11
"Partial train and isolate, mitigate backdoor attack","Yong Li, Han Gao",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16488"" target=""_blank"">2405.16488</a>",,2024-12-11
Automatic Jailbreaking of the Text-to-Image Generative AI Systems,"Minseon Kim, Hyomin Lee, Boqing Gong, Huishuai Zhang, Sung Ju Hwang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16567"" target=""_blank"">2405.16567</a>",,2024-12-11
Breaking the False Sense of Security in Backdoor Defense through Re-Activation Attack,"Mingli Zhu, Siyuan Liang, Baoyuan Wu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16134"" target=""_blank"">2405.16134</a>",,2024-12-11
BadGD: A unified data-centric framework to identify gradient descent vulnerabilities,"Chi-Hua Wang, Guang Cheng",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15979"" target=""_blank"">2405.15979</a>",,2024-12-11
Detecting Adversarial Data via Perturbation Forgery,"Qian Wang, Chen Li, Yuchen Luo, Hefei Ling, Ping Li, Jiazhong Chen, Shijuan Huang, Ning Yu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16226"" target=""_blank"">2405.16226</a>",,2024-12-11
Enhancing Adversarial Transferability Through Neighborhood Conditional Sampling,"Chunlin Qiu, Yiheng Duan, Lingchen Zhao, Qian Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16181"" target=""_blank"">2405.16181</a>",,2024-12-11
R,"Changhoon Kim, Kyle Min, Yezhou Yang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16341"" target=""_blank"">2405.16341</a>",,2024-12-11
Uncertainty Measurement of Deep Learning System based on the Convex Hull of Training Sets,"Hyekyoung Hwang, Jitae Shin",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16082"" target=""_blank"">2405.16082</a>",,2024-12-11
Layer-Aware Analysis of Catastrophic Overfitting: Revealing the Pseudo-Robust Shortcut Dependency,"Runqi Lin, Chaojian Yu, Bo Han, Hang Su, Tongliang Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16262"" target=""_blank"">2405.16262</a>",,2024-12-11
Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Image Character,"Siyuan Ma, Weidi Luo, Yu Wang, Xiaogeng Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20773"" target=""_blank"">2405.20773</a>",,2024-12-11
Medical MLLM is Vulnerable: Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models,"Xijie Huang, Xinyuan Wang, Hantao Zhang, Yinghao Zhu, Jiawen Xi, Jingkun An, Hao Wang, Hao Liang, Chengwei Pan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20775"" target=""_blank"">2405.20775</a>","<a href=""https://github.com/dirtycomputer/O2M_attack"" target=""_blank"">dirtycomputer</a>",2024-12-11
Intruding with Words: Towards Understanding Graph Injection Attacks at the Text Level,"Runlin Lei, Yuwei Hu, Yuchen Ren, Zhewei Wei",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16405"" target=""_blank"">2405.16405</a>",,2024-12-11
Mitigating Backdoor Attack by Injecting Proactive Defensive Backdoor,"Shaokui Wei, Hongyuan Zha, Baoyuan Wu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16112"" target=""_blank"">2405.16112</a>",,2024-12-11
Robust width: A lightweight and certifiable adversarial defense,"Jonathan Peck, Bart Goossens",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15971"" target=""_blank"">2405.15971</a>","<a href=""https://github.com/peck94/robust-width-defense"" target=""_blank"">peck94</a>",2024-12-11
Can Implicit Bias Imply Adversarial Robustness? (11%),"Hancheng Min, RenÃ© Vidal",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15942"" target=""_blank"">2405.15942</a>",,2024-12-11
Adversarial Attacks on Hidden Tasks in Multi-Task Learning,"Yu Zhe, Rei Nagaike, Daiki Nishiyama, Kazuto Fukuchi, Jun Sakuma",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15244"" target=""_blank"">2405.15244</a>",,2024-12-11
Certifiably Robust RAG against Retrieval Corruption,"Chong Xiang, Tong Wu, Zexuan Zhong, David Wagner, Danqi Chen, Prateek Mittal",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15556"" target=""_blank"">2405.15556</a>",,2024-12-11
Evaluating and Safeguarding the Adversarial Robustness of Retrieval-Based In-Context Learning,"Simon Yu, Jie He, Pasquale Minervini, Jeff Z. Pan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15984"" target=""_blank"">2405.15984</a>","<a href=""https://github.com/simonucl/adv-retreival-icl"" target=""_blank"">simonucl</a>",2024-12-11
Certifying Adapters: Enabling and Enhancing the Certification of Classifier Adversarial Robustness,"Jieren Deng, Hanbin Hong, Aaron Palmer, Xin Zhou, Jinbo Bi, Kaleel Mahmood, Yuan Hong, Derek Aguiar",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16036"" target=""_blank"">2405.16036</a>",,2024-12-11
Efficient Adversarial Training in LLMs with Continuous Attacks,"Sophie Xhonneux, Alessandro Sordoni, Stephan GÃ¼nnemann, Gauthier Gidel, Leo Schwinn",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15589"" target=""_blank"">2405.15589</a>",,2024-12-11
Rethinking Independent Cross-Entropy Loss For Graph-Structured Data,"Rui Miao, Kaixiong Zhou, Yili Wang, Ninghao Liu, Ying Wang, Xin Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15564"" target=""_blank"">2405.15564</a>",,2024-12-11
BDetCLIP: Multimodal Prompting Contrastive Test-Time Backdoor Detection,"Yuwei Niu, Shuo He, Qi Wei, Zongyu Wu, Feng Liu, Lei Feng",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15269"" target=""_blank"">2405.15269</a>",,2024-12-11
Large Language Model Sentinel: LLM Agent for Adversarial Purification,"Guang Lin, Qibin Zhao",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20770"" target=""_blank"">2405.20770</a>",,2024-12-11
Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models,"Yimeng Zhang, Xin Chen, Jinghan Jia, Yihua Zhang, Chongyu Fan, Jiancheng Liu, Mingyi Hong, Ke Ding, Sijia Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15234"" target=""_blank"">2405.15234</a>","<a href=""https://github.com/OPTML-Group/AdvUnlearn"" target=""_blank"">OPTML-Group</a>",2024-12-11
Robustifying Safety-Aligned Large Language Models through Clean Data Curation,"Xiaoqun Liu, Jiacheng Liang, Muchao Ye, Zhaohan Xi",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19358"" target=""_blank"">2405.19358</a>",,2024-12-11
HiddenSpeaker: Generate Imperceptible Unlearnable Audios for Speaker Verification System,"Zhisheng Zhang, Pengyang Huang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15655"" target=""_blank"">2405.15655</a>",,2024-12-11
Certified PEFTSmoothing: Parameter-Efficient Fine-Tuning with Randomized Smoothing,"Chengyan Fu, Wenjie Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05350"" target=""_blank"">2404.05350</a>",,2024-12-11
How to Craft Backdoors with Unlabeled Data Alone? (1%),"Yifei Wang, Wenhan Ma, Yisen Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06694"" target=""_blank"">2404.06694</a>","<a href=""https://github.com/PKU-ML/nlb"" target=""_blank"">PKU-ML</a>",2024-12-11
"Aggressive or Imperceptible, or Both: Network Pruning Assisted Hybrid Byzantines in Federated Learning","Emre Ozfatura, Kerem Ozfatura, Alptekin Kupcu, Deniz Gunduz",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06230"" target=""_blank"">2404.06230</a>",,2024-12-11
Towards Robust Domain Generation Algorithm Classification,"Arthur Drichel, Marc Meyer, Ulrike Meyer",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06236"" target=""_blank"">2404.06236</a>",,2024-12-11
Sandwich attack: Multi-language Mixture Adaptive Attack on LLMs,"Bibek Upadhayay, Vahid Behzadan",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.07242"" target=""_blank"">2404.07242</a>",,2024-12-11
SafeGen: Mitigating Unsafe Content Generation in Text-to-Image Models,"Xinfeng Li, Yuchen Yang, Jiangyi Deng, Chen Yan, Yanjiao Chen, Xiaoyu Ji, Wenyuan Xu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06666"" target=""_blank"">2404.06666</a>",,2024-12-11
LRR: Language-Driven Resamplable Continuous Representation against Adversarial Tracking Attacks,"Jianlang Chen, Xuhong Ren, Qing Guo, Felix Juefei-Xu, Di Lin, Wei Feng, Lei Ma, Jianjun Zhao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06247"" target=""_blank"">2404.06247</a>",,2024-12-11
On adversarial training and the 1 Nearest Neighbor classifier,"Amir Hagai, Yair Weiss",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06313"" target=""_blank"">2404.06313</a>","<a href=""https://github.com/amirhagai/On-Adversarial-Training-And-The-1-Nearest-Neighbor-Classifier"" target=""_blank"">amirhagai</a>",2024-12-11
BruSLeAttack: A Query-Efficient Score-Based Black-Box Sparse Adversarial Attack,"Viet Quoc Vo, Ehsan Abbasnejad, Damith C. Ranasinghe",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05311"" target=""_blank"">2404.05311</a>",,2024-12-11
David and Goliath: An Empirical Evaluation of Attacks and Defenses for QNNs at the Deep Edge,"Miguel Costa, Sandro Pinto",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05688"" target=""_blank"">2404.05688</a>",,2024-12-11
CANEDERLI: On The Impact of Adversarial Training and Transferability on CAN Intrusion Detection Systems,"Francesco Marchiori, Mauro Conti",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04648"" target=""_blank"">2404.04648</a>",,2024-12-11
Case Study: Neural Network Malware Detection Verification for Feature and Image Datasets,"Preston K. Robinette, Diego Manzanas Lopez, Serena Serbinowska, Kevin Leach, Taylor T. Johnson",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05703"" target=""_blank"">2404.05703</a>",,2024-12-11
Out-of-Distribution Data: An Acquaintance of Adversarial Examples -- A Survey,"Naveen Karunanayake, Ravin Gunawardena, Suranga Seneviratne, Sanjay Chawla",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05219"" target=""_blank"">2404.05219</a>",,2024-12-11
Quantum Adversarial Learning for Kernel Methods,"Giuseppe Montalbano, Leonardo Banchi",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05824"" target=""_blank"">2404.05824</a>",,2024-12-11
Investigating the Impact of Quantization on Adversarial Robustness,"Qun Li, Yuan Meng, Chen Tang, Jiacheng Jiang, Zhi Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05639"" target=""_blank"">2404.05639</a>",,2024-12-11
SphereHead: Stable 3D Full-head Synthesis with Spherical Tri-plane Representation,"Heyuan Li, Ce Chen, Tianhao Shi, Yuda Qiu, Sizhe An, Guanying Chen, Xiaoguang Han",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05680"" target=""_blank"">2404.05680</a>","<a href=""https://lhyfst.github.io/spherehead"" target=""_blank"">lhyfst.github.io</a>",2024-12-11
Semantic Stealth: Adversarial Text Attacks on NLP Using Several Methods,"Roopkatha Dey, Aivy Debnath, Sayak Kumar Dutta, Kaustav Ghosh, Arijit Mitra, Arghya Roy Chowdhury, Jaydip Sen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05159"" target=""_blank"">2404.05159</a>",,2024-12-11
Enabling Privacy-Preserving Cyber Threat Detection with Federated Learning,"Yu Bi, Yekai Li, Xuan Feng, Xianghang Mi",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05130"" target=""_blank"">2404.05130</a>",,2024-12-11
How much reliable is ChatGPT's prediction on Information Extraction under Input Perturbations? (5%),"Ishani Mondal, Abhilasha Sancheti",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05088"" target=""_blank"">2404.05088</a>",,2024-12-11
SemEval-2024 Task 2: Safe Biomedical Natural Language Inference for Clinical Trials,"Mael Jullien, Marco Valentino, AndrÃ© Freitas",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04963"" target=""_blank"">2404.04963</a>",,2024-12-11
Learning Minimal NAP Specifications for Neural Network Verification,"Chuqin Geng, Zhaoyue Wang, Haolin Ye, Saifei Liao, Xujie Si",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04662"" target=""_blank"">2404.04662</a>",,2024-12-11
Data Poisoning Attacks on Off-Policy Policy Evaluation Methods,"Elita Lobo, Harvineet Singh, Marek Petrik, Cynthia Rudin, Himabindu Lakkaraju",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04714"" target=""_blank"">2404.04714</a>",,2024-12-11
TrajPRed: Trajectory Prediction with Region-based Relation Learning,"Chen Zhou, Ghassan AlRegib, Armin Parchami, Kunjan Singh",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06971"" target=""_blank"">2404.06971</a>",,2024-12-11
Towards Building a Robust Toxicity Predictor,"Dmitriy Bespalov, Sourav Bhabesh, Yi Xiang, Liutong Zhou, Yanjun Qi",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08690"" target=""_blank"">2404.08690</a>",,2024-12-11
Stability and Generalization in Free Adversarial Training,"Xiwei Cheng, Kexin Fu, Farzan Farnia",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08980"" target=""_blank"">2404.08980</a>","<a href=""https://github.com/Xiwei-Cheng/Stability_FreeAT"" target=""_blank"">Xiwei-Cheng</a>",2024-12-11
Simpler becomes Harder: Do LLMs Exhibit a Coherent Behavior on Simplified Corpora? (2%),"Miriam AnschÃ¼tz, Edoardo Mosca, Georg Groh",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06838"" target=""_blank"">2404.06838</a>",,2024-12-11
Adversarial purification for no-reference image-quality metrics: applicability study and new methods,"Aleksandr Gushchin, Anna Chistyakova, Vladislav Minashkin, Anastasia Antsiferova, Dmitriy Vatolin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06957"" target=""_blank"">2404.06957</a>",,2024-12-11
Adversarial Robustness Limits via Scaling-Law and Human-Alignment Studies,"Brian R. Bartoldson, James Diffenderfer, Konstantinos Parasyris, Bhavya Kailkhura",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09349"" target=""_blank"">2404.09349</a>",,2024-12-11
FaceCat: Enhancing Face Recognition Security with a Unified Generative Model Framework,"Jiawei Chen, Xiao Yang, Yinpeng Dong, Hang Su, Jianteng Peng, Zhaoxia Yin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09193"" target=""_blank"">2404.09193</a>",,2024-12-11
Structured Gradient-based Interpretations via Norm-Regularized Adversarial Training,"Shizhan Gong, Qi Dou, Farzan Farnia",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04647"" target=""_blank"">2404.04647</a>",,2024-12-11
Proof-of-Learning with Incentive Security,"Zishuo Zhao, Zhixuan Fang, Xuechao Wang, Xi Chen, Yuan Zhou",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09005"" target=""_blank"">2404.09005</a>",,2024-12-11
PASA: Attack Agnostic Unsupervised Adversarial Detection using Prediction & Attribution Sensitivity Analysis,"Dipkamal Bhusal, Md Tanvirul Alam, Monish K. Veerabhadran, Michael Clifford, Sara Rampazzi, Nidhi Rastogi",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10789"" target=""_blank"">2404.10789</a>",,2024-12-11
Counterfactual Explanations for Face Forgery Detection via Adversarial Removal of Artifacts,"Yang Li, Songlin Yang, Wei Wang, Ziwen He, Bo Peng, Jing Dong",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08341"" target=""_blank"">2404.08341</a>",,2024-12-11
Struggle with Adversarial Defense? Try Diffusion,"Yujie Li, Yanbin Wang, Haitao Xu, Bin Liu, Jianguo Sun, Zhenhao Guo, Wenrui Ma",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08273"" target=""_blank"">2404.08273</a>",,2024-12-11
Multimodal Attack Detection for Action Recognition Models,"Furkan Mumcu, Yasin Yilmaz",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10790"" target=""_blank"">2404.10790</a>",,2024-12-11
A Survey of Neural Network Robustness Assessment in Image Recognition,"Jie Wang, Jun Ai, Minyan Lu, Haoran Su, Dan Yu, Yutao Zhang, Junda Zhu, Jingyu Liu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08285"" target=""_blank"">2404.08285</a>",,2024-12-11
Practical Region-level Attack against Segment Anything Models,"Yifan Shen, Zhengyuan Li, Gang Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08255"" target=""_blank"">2404.08255</a>",,2024-12-11
FCert: Certifiably Robust Few-Shot Classification in the Era of Foundation Models,"Yanting Wang, Wei Zou, Jinyuan Jia",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08631"" target=""_blank"">2404.08631</a>",,2024-12-11
Mitigating Cascading Effects in Large Adversarial Graph Environments,"James D. Cunningham, Conrad S. Tucker",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14418"" target=""_blank"">2404.14418</a>",,2024-12-11
On the Robustness of Language Guidance for Low-Level Vision Tasks: Findings from Depth Estimation,"Agneet Chatterjee, Tejas Gokhale, Chitta Baral, Yezhou Yang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08540"" target=""_blank"">2404.08540</a>",,2024-12-11
Empowering Malware Detection Efficiency within Processing-in-Memory Architecture,"Sreenitha Kasarapu, Sathwika Bavikadi, Sai Manoj Pudukotai Dinakarrao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08818"" target=""_blank"">2404.08818</a>",,2024-12-11
Persistent Classification: A New Approach to Stability of Data and Adversarial Examples,"Brian Bell, Michael Geyer, David Glickenstein, Keaton Hamm, Carlos Scheidegger, Amanda Fernandez, Juston Moore",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08069"" target=""_blank"">2404.08069</a>",,2024-12-11
Eliminating Catastrophic Overfitting Via Abnormal Adversarial Examples Regularization,"Runqi Lin, Chaojian Yu, Tongliang Liu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08154"" target=""_blank"">2404.08154</a>",,2024-12-11
Backdoor Contrastive Learning via Bi-level Trigger Optimization,"Weiyu Sun, Xinyu Zhang, Hao Lu, Yingcong Chen, Ting Wang, Jinghui Chen, Lu Lin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.07863"" target=""_blank"">2404.07863</a>","<a href=""https://github.com/SWY666/SSL-backdoor-BLTO"" target=""_blank"">SWY666</a>",2024-12-11
Adversarial Robustness of Distilled and Pruned Deep Learning-based Wireless Classifiers,"Nayan Moni Baishya, B. R. Manoj",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15344"" target=""_blank"">2404.15344</a>",,2024-12-11
AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs,"Zeyi Liao, Huan Sun",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.07921"" target=""_blank"">2404.07921</a>",,2024-12-11
LeapFrog: The Rowhammer Instruction Skip Attack,"Andrew Adiletta, Caner Tol, Berk Sunar",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.07878"" target=""_blank"">2404.07878</a>",,2024-12-11
"Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies","Zichao Li, Cihang Xie, Ekin Dogus Cubuk",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08197"" target=""_blank"">2404.08197</a>",,2024-12-11
Logit Calibration and Feature Contrast for Robust Federated Learning on Non-IID Data,"Yu Qiao, Chaoning Zhang, Apurba Adhikary, Choong Seon Hong",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06776"" target=""_blank"">2404.06776</a>",,2024-12-11
Lost in Translation: Modern Neural Networks Still Struggle With Small Realistic Image Transformations,"Ofir Shifman, Yair Weiss",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.07153"" target=""_blank"">2404.07153</a>",,2024-12-11
Goal-guided Generative Prompt Injection Attack on Large Language Models,"Chong Zhang, Mingyu Jin, Qinkai Yu, Chengzhi Liu, Haochen Xue, Xiaobo Jin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.07234"" target=""_blank"">2404.07234</a>",,2024-12-11
CAPE: CAM as a Probabilistic Ensemble for Enhanced DNN Interpretation,"Townim Faisal Chowdhury, Kewen Liao, Vu Minh Hieu Phan, Minh-Son To, Yutong Xie, Kevin Hung, David Ross, Anton van den Hengel, Johan W. Verjans, Zhibin Liao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02388"" target=""_blank"">2404.02388</a>","<a href=""https://github.com/AIML-MED/CAPE"" target=""_blank"">AIML-MED</a>",2024-12-11
Exploiting Sequence Number Leakage: TCP Hijacking in NAT-Enabled Wi-Fi Networks,"Yuxiang Yang, Xuewei Feng, Qi Li, Kun Sun, Ziqiang Wang, Ke Xu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04601"" target=""_blank"">2404.04601</a>",,2024-12-11
Designing a Photonic Physically Unclonable Function Having Resilience to Machine Learning Attacks,"Elena R. Henderson, Jessie M. Henderson, Hiva Shahoei, William V. Oxford, Eric C. Larson, Duncan L. MacFarlane, Mitchell A. Thornton",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02440"" target=""_blank"">2404.02440</a>",,2024-12-11
The Double-Edged Sword of Input Perturbations to Robust Accurate Fairness,"Xuran Li, Peng Wu, Yanting Chen, Xingjun Ma, Zhen Zhang, Kaixiang Dong",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01356"" target=""_blank"">2404.01356</a>",,2024-12-11
Multi-granular Adversarial Attacks against Black-box Neural Ranking Models,"Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Rijke Maarten de, Yixing Fan, Xueqi Cheng",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01574"" target=""_blank"">2404.01574</a>",,2024-12-11
BadPart: Unified Black-box Adversarial Patch Attacks against Pixel-wise Regression Tasks,"Zhiyuan Cheng, Zhaoyi Liu, Tengda Guo, Shiwei Feng, Dongfang Liu, Mingjie Tang, Xiangyu Zhang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00924"" target=""_blank"">2404.00924</a>",,2024-12-11
Poisoning Decentralized Collaborative Recommender System and Its Countermeasures,"Ruiqi Zheng, Liang Qu, Tong Chen, Kai Zheng, Yuhui Shi, Hongzhi Yin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01177"" target=""_blank"">2404.01177</a>",,2024-12-11
Can Biases in ImageNet Models Explain Generalization? (10%),"Paul Gavrikov, Janis Keuper",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01509"" target=""_blank"">2404.01509</a>","<a href=""https://github.com/paulgavrikov/biases_vs_generalization"" target=""_blank"">paulgavrikov</a>",2024-12-11
UFID: A Unified Framework for Input-level Backdoor Detection on Diffusion Models,"Zihan Guan, Mengxuan Hu, Sheng Li, Anil Vullikanti",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01101"" target=""_blank"">2404.01101</a>","<a href=""https://github.com/GuanZihan/official_UFID"" target=""_blank"">GuanZihan</a>",2024-12-11
Privacy Backdoors: Enhancing Membership Inference through Poisoning Pre-trained Models,"Yuxin Wen, Leo Marchyok, Sanghyun Hong, Jonas Geiping, Tom Goldstein, Nicholas Carlini",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01231"" target=""_blank"">2404.01231</a>",,2024-12-11
An incremental hybrid adaptive network-based IDS in Software Defined Networks to detect stealth attacks,Abdullah H Alqahtani,arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01109"" target=""_blank"">2404.01109</a>",,2024-12-11
PID Control-Based Self-Healing to Improve the Robustness of Large Language Models,"Zhuotong Chen, Zihu Wang, Yifan Yang, Qianxiao Li, Zheng Zhang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00828"" target=""_blank"">2404.00828</a>","<a href=""https://github.com/zhuotongchen/PID-Control-Based-Self-Healing-to-Improve-the-Robustness-of-Large-Language-Models"" target=""_blank"">zhuotongchen</a>",2024-12-11
Machine Learning Robustness: A Primer,"Houssem Ben Braiek, Foutse Khomh",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00897"" target=""_blank"">2404.00897</a>",,2024-12-11
STBA: Towards Evaluating the Robustness of DNNs for Query-Limited Black-box Scenario,"Renyang Liu, Kwok-Yan Lam, Wei Zhou, Sixing Wu, Jun Zhao, Dongting Hu, Mingming Gong",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00362"" target=""_blank"">2404.00362</a>",,2024-12-11
Embodied Active Defense: Leveraging Recurrent Feedback to Counter Adversarial Patches,"Lingxuan Wu, Xiao Yang, Yinpeng Dong, Liuwei Xie, Hang Su, Jun Zhu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00540"" target=""_blank"">2404.00540</a>",,2024-12-11
Shortcuts Arising from Contrast: Effective and Covert Clean-Label Attacks in Prompt-Based Learning,"Xiaopeng Xie, Ming Yan, Xiwen Zhou, Chenlong Zhao, Suli Wang, Yong Zhang, Joey Tianyi Zhou",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00461"" target=""_blank"">2404.00461</a>",,2024-12-11
On Inherent Adversarial Robustness of Active Vision Systems,"Amitangshu Mukherjee, Timur Ibrayev, Kaushik Roy",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00185"" target=""_blank"">2404.00185</a>",,2024-12-11
Deepfake Sentry: Harnessing Ensemble Intelligence for Resilient Detection and Generalisation,"Liviu-Daniel University ""Politehnica"" of Bucharest, Romania Åtefan, Dan-Cristian University ""Politehnica"" of Bucharest, Romania Stanciu, Mihai University ""Politehnica"" of Bucharest, Romania Dogariu, Mihai Gabriel University ""Politehnica"" of Bucharest, Romania Constantin, Andrei Cosmin University ""Politehnica"" of Bucharest, Romania Jitaru, Bogdan University ""Politehnica"" of Bucharest, Romania Ionescu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00114"" target=""_blank"">2404.00114</a>",,2024-12-11
GDA: Generalized Diffusion for Robust Test-time Adaptation,"Yun-Yun Tsai, Fu-Chen Chen, Albert Y. C. Chen, Junfeng Yang, Che-Chun Su, Min Sun, Cheng-Hao Kuo",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00095"" target=""_blank"">2404.00095</a>",,2024-12-11
Efficient Data-Free Model Stealing with Label Diversity,"Yiyong Liu, Rui Wen, Michael Backes, Yang Zhang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00108"" target=""_blank"">2404.00108</a>",,2024-12-11
State-of-the-Art Approaches to Enhancing Privacy Preservation of Machine Learning Datasets: A Survey,Chaoyu Zhang,arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16847"" target=""_blank"">2404.16847</a>",,2024-12-11
A Backdoor Approach with Inverted Labels Using Dirty Label-Flipping Attacks,Orson Mengara,arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00076"" target=""_blank"">2404.00076</a>",,2024-12-11
JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models,"Patrick Chao, Edoardo Debenedetti, Alexander Robey, Maksym Andriushchenko, Francesco Croce, Vikash Sehwag, Edgar Dobriban, Nicolas Flammarion, George J. Pappas, Florian Tramer, Hamed Hassani, Eric Wong",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01318"" target=""_blank"">2404.01318</a>","<a href=""https://github.com/JailbreakBench/jailbreakbench"" target=""_blank"">JailbreakBench</a>",2024-12-11
EdgeLeakage: Membership Information Leakage in Distributed Edge Intelligence Systems,"Kongyang Chen, Yi Lin, Hui Luo, Bing Mi, Yatie Xiao, Chao Ma, Jorge SÃ¡ Silva",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16851"" target=""_blank"">2404.16851</a>",,2024-12-11
A novel interface for adversarial trivia question-writing,Jason Liu,arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00011"" target=""_blank"">2404.00011</a>",,2024-12-11
Counteracting Concept Drift by Learning with Future Malware Predictions,"Branislav Bosansky, Lada Hospodkova, Michal Najman, Maria Rigaki, Elnaz Babayeva, Viliam Lisy",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09352"" target=""_blank"">2404.09352</a>",,2024-12-11
Exploring Backdoor Vulnerabilities of Chat Models,"Yunzhuo Hao, Wenkai Yang, Yankai Lin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02406"" target=""_blank"">2404.02406</a>",,2024-12-11
Towards Robust 3D Pose Transfer with Adversarial Learning,"Haoyu Chen, Hao Tang, Ehsan Adeli, Guoying Zhao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02242"" target=""_blank"">2404.02242</a>",,2024-12-11
"Evaluating Adversarial Robustness: A Comparison Of FGSM, Carlini-Wagner Attacks, And The Role of Distillation as Defense Mechanism","Trilokesh Ranjan Sarkar, Nilanjan Das, Pralay Sankar Maitra, Bijoy Some, Ritwik Saha, Orijita Adhikary, Bishal Bose, Jaydip Sen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04245"" target=""_blank"">2404.04245</a>",,2024-12-11
Red-Teaming Segment Anything Model,"Krzysztof Jankowski, Bartlomiej Sobieski, Mateusz Kwiatkowski, Jakub Szulc, Michal Janik, Hubert Baniecki, Przemyslaw Biecek",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02067"" target=""_blank"">2404.02067</a>",,2024-12-11
Reliable Feature Selection for Adversarially Robust Cyber-Attack Detection,"JoÃ£o Vitorino, Miguel Silva, Eva Maia, Isabel PraÃ§a",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04188"" target=""_blank"">2404.04188</a>",,2024-12-11
Compositional Estimation of Lipschitz Constants for Deep Neural Networks,"Yuezhu Xu, S. Sivaranjani",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04375"" target=""_blank"">2404.04375</a>",,2024-12-11
Precision Guided Approach to Mitigate Data Poisoning Attacks in Federated Learning,"K Naveen Kumar, C Krishna Mohan, Aravind Machiry",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04139"" target=""_blank"">2404.04139</a>",,2024-12-11
Meta Invariance Defense Towards Generalizable Robustness to Unknown Adversarial Attacks,"Lei Zhang, Yuhang Zhou, Yi Yang, Xinbo Gao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.03340"" target=""_blank"">2404.03340</a>",,2024-12-11
FACTUAL: A Novel Framework for Contrastive Learning Based Robust SAR Image Classification,"Xu Wang, Tian Ye, Rajgopal Kannan, Viktor Prasanna",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.03225"" target=""_blank"">2404.03225</a>",,2024-12-11
Learn What You Want to Unlearn: Unlearning Inversion Attacks against Machine Unlearning,"Hongsheng Hu, Shuo Wang, Tian Dong, Minhui Xue",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.03233"" target=""_blank"">2404.03233</a>",,2024-12-11
Knowledge Distillation-Based Model Extraction Attack using GAN-based Private Counterfactual Explanations,"Fatima Ezzeddine, Omran Ayoub, Silvia Giordano",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.03348"" target=""_blank"">2404.03348</a>",,2024-12-11
Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak Attacks? (2%),"Shuo Chen, Zhen Han, Bailan He, Zifeng Ding, Wenqian Yu, Philip Torr, Volker Tresp, Jindong Gu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.03411"" target=""_blank"">2404.03411</a>",,2024-12-11
Adversarial Attacks and Dimensionality in Text Classifiers,"Nandish Chattopadhyay, Atreya Goswami, Anupam Chattopadhyay",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02660"" target=""_blank"">2404.02660</a>",,2024-12-11
Unsegment Anything by Simulating Deformation,"Jiahao Lu, Xingyi Yang, Xinchao Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02585"" target=""_blank"">2404.02585</a>","<a href=""https://github.com/jiahaolu97/anything-unsegmentable"" target=""_blank"">jiahaolu97</a>",2024-12-11
"""Are Adversarial Phishing Webpages a Threat in Reality?"" Understanding the Users' Perception of Adversarial Webpages","Ying Yuan, Qingying Hao, Giovanni Apruzzese, Mauro Conti, Gang Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02832"" target=""_blank"">2404.02832</a>",,2024-12-11
JailBreakV-28K: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks,"Weidi Luo, Siyuan Ma, Xiaogeng Liu, Xiaoyu Guo, Chaowei Xiao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.03027"" target=""_blank"">2404.03027</a>",,2024-12-11
Learn to Disguise: Avoid Refusal Responses in LLM's Defense via a Multi-agent Attacker-Disguiser Game,"Qianqiao Xu, Zhiliang Tian, Hongyan Wu, Zhen Huang, Yiping Song, Feng Liu, Dongsheng Li",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02532"" target=""_blank"">2404.02532</a>",,2024-12-11
A Unified Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability,"Jie Zhu, Jirong Zha, Ding Li, Leye Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02462"" target=""_blank"">2404.02462</a>","<a href=""https://github.com/JiePKU/PartCrop"" target=""_blank"">JiePKU</a>",2024-12-11
Steganographic Passport: An Owner and User Verifiable Credential for Deep Model IP Protection Without Retraining,"Qi Cui, Ruohan Meng, Chaohui Xu, Chip-Hong Chang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02889"" target=""_blank"">2404.02889</a>",,2024-12-11
Humanizing Machine-Generated Content: Evading AI-Text Detection through Adversarial Attack,"Ying Zhou, Ben He, Le Sun",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01907"" target=""_blank"">2404.01907</a>",,2024-12-11
ADVREPAIR:Provable Repair of Adversarial Attack,"Zhiming Chi, Jianan Ma, Pengfei Yang, Cheng-Chao Huang, Renjue Li, Xiaowei Huang, Lijun Zhang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01642"" target=""_blank"">2404.01642</a>",,2024-12-11
Jailbreaking Prompt Attack: A Controllable Adversarial Attack against Diffusion Models,"Jiachen Ma, Anda Cao, Zhiqing Xiao, Yijiang Li, Jie Zhang, Chao Ye, Junbo Zhao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02928"" target=""_blank"">2404.02928</a>",,2024-12-11
One Noise to Rule Them All: Multi-View Adversarial Attacks with Universal Perturbation,"Mehmet Ergezer, Phat Duong, Christian Green, Tommy Nguyen, Abdurrahman Zeybey",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02287"" target=""_blank"">2404.02287</a>","<a href=""https://github.com/memoatwit/UniversalPerturbation"" target=""_blank"">memoatwit</a>",2024-12-11
Defense without Forgetting: Continual Adversarial Defense with Anisotropic & Isotropic Pseudo Replay,"Yuhang Zhou, Zhongyun Hua",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01828"" target=""_blank"">2404.01828</a>",,2024-12-11
Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks,"Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02151"" target=""_blank"">2404.02151</a>","<a href=""https://github.com/tml-epfl/llm-adaptive-attacks"" target=""_blank"">tml-epfl</a>",2024-12-11
READ: Improving Relation Extraction from an ADversarial Perspective,"Dawei Li, William Hogan, Jingbo Shang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02931"" target=""_blank"">2404.02931</a>","<a href=""https://github.com/David-Li0406/READ"" target=""_blank"">David-Li0406</a>",2024-12-11
Two Heads are Better than One: Nested PoE for Robust Defense Against Multi-Backdoors,"Victoria Graf, Qin Liu, Muhao Chen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02356"" target=""_blank"">2404.02356</a>",,2024-12-11
Watermark-embedded Adversarial Examples for Copyright Protection against Diffusion Models,"Peifei Zhu, Tsubasa Takahashi, Hirokatsu Kataoka",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09401"" target=""_blank"">2404.09401</a>",,2024-12-11
Detector Collapse: Backdooring Object Detection to Catastrophic Overload or Blindness,"Hangtao Zhang, Shengshan Hu, Yichen Wang, Leo Yu Zhang, Ziqi Zhou, Xianlong Wang, Yanjun Zhang, Chao Chen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.11357"" target=""_blank"">2404.11357</a>",,2024-12-11
Consistency and Uncertainty: Identifying Unreliable Responses From Black-Box Vision-Language Models for Selective Visual Question Answering,"Zaid Khan, Yun Fu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10193"" target=""_blank"">2404.10193</a>",,2024-12-11
An Empirical Study of Aegis,"Daniel Saragih, Paridhi Goel, Tejas Balaji, Alyssa Li",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15784"" target=""_blank"">2404.15784</a>",,2024-12-11
Adversarial Consistency and the Uniqueness of the Adversarial Bayes Classifier,Natalie S. Frank,arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17358"" target=""_blank"">2404.17358</a>",,2024-12-11
Generating Minimalist Adversarial Perturbations to Test Object-Detection Models: An Adaptive Multi-Metric Evolutionary Search Approach,"Cristopher McIntyre-Garcia, Adrien Heymans, Beril Borali, Won-Sook Lee, Shiva Nejati",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17020"" target=""_blank"">2404.17020</a>",,2024-12-11
PAD: Patch-Agnostic Defense against Adversarial Patch Attacks,"Lihua Jing, Rui Wang, Wenqi Ren, Xin Dong, Cong Zou",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16452"" target=""_blank"">2404.16452</a>","<a href=""https://github.com/Lihua-Jing/PAD"" target=""_blank"">Lihua-Jing</a>",2024-12-11
Defending Spiking Neural Networks against Adversarial Attacks through Image Purification,"Weiran Chen, Qi Sun, Qi Xu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17092"" target=""_blank"">2404.17092</a>",,2024-12-11
Don't Say No: Jailbreaking LLM by Suppressing Refusal,"Yukai Zhou, Zhijie Huang, Feiyang Lu, Zhan Qin, Wenjie Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16369"" target=""_blank"">2404.16369</a>",,2024-12-11
A Self-Organizing Clustering System for Unsupervised Distribution Shift Detection,"SebastiÃ¡n Basterrech, Line Clemmensen, Gerardo Rubino",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16656"" target=""_blank"">2404.16656</a>",,2024-12-11
Constructing Optimal Noise Channels for Enhanced Robustness in Quantum Machine Learning,"David Winderl, Nicola Franco, Jeanette Miriam Lorenz",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16417"" target=""_blank"">2404.16417</a>",,2024-12-11
Energy-Latency Manipulation of Multi-modal Large Language Models via Verbose Samples,"Kuofeng Gao, Jindong Gu, Yang Bai, Shu-Tao Xia, Philip Torr, Wei Liu, Zhifeng Li",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16557"" target=""_blank"">2404.16557</a>",,2024-12-11
Talking Nonsense: Probing Large Language Models' Understanding of Adversarial Gibberish Inputs,"Valeriia Cherepanova, James Zou",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17120"" target=""_blank"">2404.17120</a>",,2024-12-11
Steal Now and Attack Later: Evaluating Robustness of Object Detection against Black-box Adversarial Attacks,"Erh-Chung Chen, Pin-Yu Chen, I-Hsin Chung, Che-Rung Lee",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15881"" target=""_blank"">2404.15881</a>",,2024-12-11
An Analysis of Recent Advances in Deepfake Image Detection in an Evolving Threat Landscape,"Sifat Muhammad Abdullah, Aravind Cheruvu, Shravya Kanchi, Taejoong Chung, Peng Gao, Murtuza Jadliwala, Bimal Viswanath",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16212"" target=""_blank"">2404.16212</a>",,2024-12-11
A General Black-box Adversarial Attack on Graph-based Fake News Detectors,"Peican Zhu, Zechen Pan, Yang Liu, Jiwei Tian, Keke Tang, Zhen Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15744"" target=""_blank"">2404.15744</a>",,2024-12-11
Adversarial Reweighting with $\alpha$-Power Maximization for Domain Adaptation,"Xiang Gu, Xi Yu, Yan Yang, Jian Sun, Zongben Xu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17275"" target=""_blank"">2404.17275</a>",,2024-12-11
A Comparative Analysis of Adversarial Robustness for Quantum and Classical Machine Learning Models,"Maximilian Wendlinger, Kilian Tscharke, Pascal Debus",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16154"" target=""_blank"">2404.16154</a>",,2024-12-11
MISLEAD: Manipulating Importance of Selected features for Learning Epsilon in Evasion Attack Deception,"Vidit Khazanchi, Pavan Kulkarni, Yuvaraj Govindarajulu, Manojkumar Parmar",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15656"" target=""_blank"">2404.15656</a>",,2024-12-11
Investigating the prompt leakage effect and black-box defenses for multi-turn LLM interactions,"Divyansh Agarwal, Alexander R. Fabbri, Philippe Laban, Ben Risher, Shafiq Joty, Caiming Xiong, Chien-Sheng Wu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16251"" target=""_blank"">2404.16251</a>",,2024-12-11
Universal Adversarial Triggers Are Not Universal,"Nicholas Meade, Arkil Patel, Siva Reddy",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16020"" target=""_blank"">2404.16020</a>",,2024-12-11
CLAD: Robust Audio Deepfake Detection Against Manipulation Attacks with Contrastive Learning,"Haolin Wu, Jing Chen, Ruiying Du, Cong Wu, Kun He, Xingcan Shang, Hao Ren, Guowen Xu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15854"" target=""_blank"">2404.15854</a>","<a href=""https://github.com/CLAD23/CLAD"" target=""_blank"">CLAD23</a>",2024-12-11
Security Analysis of WiFi-based Sensing Systems: Threats from Perturbation Attacks,"Hangcheng Cao, Wenbin Huang, Guowen Xu, Xianhao Chen, Ziyang He, Jingyang Hu, Hongbo Jiang, Yuguang Fang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15587"" target=""_blank"">2404.15587</a>",,2024-12-11
Manipulating Recommender Systems: A Survey of Poisoning Attacks and Countermeasures,"Thanh Toan Nguyen, Quoc Viet Hung Nguyen, Thanh Tam Nguyen, Thanh Trung Huynh, Thanh Thi Nguyen, Matthias Weidlich, Hongzhi Yin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14942"" target=""_blank"">2404.14942</a>","<a href=""https://github.com/tamlhp/awesome-recsys-poisoning"" target=""_blank"">tamlhp</a>",2024-12-11
PoisonedFL: Model Poisoning Attacks to Federated Learning via Multi-Round Consistency,"Yueqi Xie, Minghong Fang, Neil Zhenqiang Gong",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15611"" target=""_blank"">2404.15611</a>",,2024-12-11
Perturbing Attention Gives You More Bang for the Buck: Subtle Imaging Perturbations That Efficiently Fool Customized Diffusion Models,"Jingyao Xu, Yuetong Lu, Yandong Li, Siyang Lu, Dongdong Wang, Xiang Wei",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15081"" target=""_blank"">2404.15081</a>",,2024-12-11
Talk Too Much: Poisoning Large Language Models under Token Limit,"Jiaming He, Wenbo Jiang, Guanyu Hou, Wenshu Fan, Rui Zhang, Hongwei Li",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14795"" target=""_blank"">2404.14795</a>",,2024-12-11
Leverage Variational Graph Representation For Model Poisoning on Federated Learning,"Kai Li, Xin Yuan, Jingjing Zheng, Wei Ni, Falko Dressler, Abbas Jamalipour",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15042"" target=""_blank"">2404.15042</a>",,2024-12-11
Changing the Training Data Distribution to Reduce Simplicity Bias Improves In-distribution Generalization,"Dang Nguyen, Paymon Haddad, Eric Gan, Baharan Mirzasoleiman",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17768"" target=""_blank"">2404.17768</a>",,2024-12-11
Enhancing Privacy and Security of Autonomous UAV Navigation,"Vatsal Aggarwal, Arjun Ramesh Kaushik, Charanjit Jutla, Nalini Ratha",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17225"" target=""_blank"">2404.17225</a>",,2024-12-11
Does It Make Sense to Explain a Black Box With Another Black Box? (1%),"Julien Delaunay, Luis GalÃ¡rraga, Christine LargouÃ«t",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14943"" target=""_blank"">2404.14943</a>",,2024-12-11
Espresso: Robust Concept Filtering in Text-to-Image Models,"Anudeep Das, Vasisht Duddu, Rui Zhang, N. Asokan",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19227"" target=""_blank"">2404.19227</a>",,2024-12-11
Probing Unlearned Diffusion Models: A Transferable Adversarial Attack Perspective,"Xiaoxuan Han, Songlin Yang, Wei Wang, Yang Li, Jing Dong",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19382"" target=""_blank"">2404.19382</a>",,2024-12-11
AttackBench: Evaluating Gradient-based Attacks for Adversarial Examples,"Antonio Emanuele CinÃ , JÃ©rÃ´me Rony, Maura Pintor, Luca Demetrio, Ambra Demontis, Battista Biggio, Ismail Ben Ayed, Fabio Roli",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19460"" target=""_blank"">2404.19460</a>",,2024-12-11
Provably Robust Conformal Prediction with Improved Efficiency,"Ge Yan, Yaniv Romano, Tsui-Wei Weng",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19651"" target=""_blank"">2404.19651</a>","<a href=""https://github.com/Trustworthy-ML-Lab/Provably-Robust-Conformal-Prediction"" target=""_blank"">Trustworthy-ML-Lab</a>",2024-12-11
Causal Perception Inspired Representation Learning for Trustworthy Image Quality Assessment,"Lei Wang, Desen Yuan",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19567"" target=""_blank"">2404.19567</a>",,2024-12-11
Revisiting the Adversarial Robustness of Vision Language Models: a Multimodal Perspective,"Wanqi Zhou, Shuanghao Bai, Qibin Zhao, Badong Chen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19287"" target=""_blank"">2404.19287</a>",,2024-12-11
Transferring Troubles: Cross-Lingual Transferability of Backdoor Attacks in LLMs with Instruction Tuning,"Xuanli He, Jun Wang, Qiongkai Xu, Pasquale Minervini, Pontus Stenetorp, Benjamin I. P. Rubinstein, Trevor Cohn",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19597"" target=""_blank"">2404.19597</a>",,2024-12-11
Enhancing Code Vulnerability Detection via Vulnerability-Preserving Data Augmentation,"Shangqing Liu, Wei Ma, Jian Wang, Xiaofei Xie, Ruitao Feng, Yang Liu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09599"" target=""_blank"">2404.09599</a>",,2024-12-11
Physical Backdoor: Towards Temperature-based Backdoor Attacks in the Physical World,"Wen Yin, Jian Lou, Pan Zhou, Yulai Xie, Dan Feng, Yuhua Sun, Tailai Zhang, Lichao Sun",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19417"" target=""_blank"">2404.19417</a>",,2024-12-11
Assessing Cybersecurity Vulnerabilities in Code Large Language Models,"Md Imran Hossen, Jianyi Zhang, Yinzhi Cao, Xiali Hei",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.18567"" target=""_blank"">2404.18567</a>",,2024-12-11
A Systematic Evaluation of Adversarial Attacks against Speech Emotion Recognition Models,"Nicolas Facchinetti, Federico Simonetta, Stavros Ntalampiras",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.18514"" target=""_blank"">2404.18514</a>",,2024-12-11
Certification of Speaker Recognition Models to Additive Perturbations,"Dmitrii Korzh, Elvir Karimov, Mikhail Pautov, Oleg Y. Rogov, Ivan Oseledets",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.18791"" target=""_blank"">2404.18791</a>",,2024-12-11
Why You Should Not Trust Interpretations in Machine Learning: Adversarial Attacks on Partial Dependence Plots,"Xi Xin, Giles Hooker, Fei Huang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.18702"" target=""_blank"">2404.18702</a>",,2024-12-11
Evaluations of Machine Learning Privacy Defenses are Misleading,"Michael Aerni, Jie Zhang, Florian TramÃ¨r",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17399"" target=""_blank"">2404.17399</a>",,2024-12-11
"Machine Learning for Windows Malware Detection and Classification: Methods, Challenges and Ongoing Research",Daniel Gibert,arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.18541"" target=""_blank"">2404.18541</a>",,2024-12-11
Towards Quantitative Evaluation of Explainable AI Methods for Deepfake Detection,"Konstantinos Tsigos, Evlampios Apostolidis, Spyridon Baxevanakis, Symeon Papadopoulos, Vasileios Mezaris",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.18649"" target=""_blank"">2404.18649</a>",,2024-12-11
Harmonic Machine Learning Models are Robust,"Nicholas S. Kersting, Yi Li, Aman Mohanty, Oyindamola Obisesan, Raphael Okochu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.18825"" target=""_blank"">2404.18825</a>",,2024-12-11
Enhancing IoT Security: A Novel Feature Engineering Approach for ML-Based Intrusion Detection Systems,"Afsaneh Mahanipour, Hana Khamfroush",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19114"" target=""_blank"">2404.19114</a>",,2024-12-11
Towards Robust Recommendation: A Review and an Adversarial Robustness Evaluation Library,"Lei Cheng, Xiaowen Huang, Jitao Sang, Jian Yu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17844"" target=""_blank"">2404.17844</a>","<a href=""https://github.com/chengleileilei/ShillingREC"" target=""_blank"">chengleileilei</a>",2024-12-11
Privacy-Preserving Aggregation for Decentralized Learning with Byzantine-Robustness,"Ali Reza Ghavamipour, Benjamin Zi Hao Zhao, Oguzhan Ersoy, Fatih Turkmen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17970"" target=""_blank"">2404.17970</a>",,2024-12-11
Bounding the Expected Robustness of Graph Neural Networks Subject to Node Feature Attacks,"Yassine Abbahaddou, Sofiane Ennadir, Johannes F. Lutzeyer, Michalis Vazirgiannis, Henrik BostrÃ¶m",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17947"" target=""_blank"">2404.17947</a>","<a href=""https://github.com/Sennadir/GCORN"" target=""_blank"">Sennadir</a>",2024-12-11
Are Watermarks Bugs for Deepfake Detectors? Rethinking Proactive Forensics,"Xiaoshuai Wu, Xin Liao, Bo Ou, Yuling Liu, Zheng Qin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17867"" target=""_blank"">2404.17867</a>",,2024-12-11
Attacking Bayes: On the Adversarial Robustness of Bayesian Neural Networks,"Yunzhen Feng, Tim G. J. Rudner, Nikolaos Tsilivis, Julia Kempe",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19640"" target=""_blank"">2404.19640</a>",,2024-12-11
Adversarial Examples: Generation Proposal in the Context of Facial Recognition Systems,"Marina Fuster, Ignacio Vidaurreta",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17760"" target=""_blank"">2404.17760</a>",,2024-12-11
Human-Imperceptible Retrieval Poisoning Attacks in LLM-Powered Applications,"Quan Zhang, Binqi Zeng, Chijin Zhou, Gwihwan Go, Heyuan Shi, Yu Jiang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17196"" target=""_blank"">2404.17196</a>",,2024-12-11
Formal Verification of Graph Convolutional Networks with Uncertain Node Features and Uncertain Graph Structure,"Tobias Ladner, Michael Eichelbeck, Matthias Althoff",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15065"" target=""_blank"">2404.15065</a>",,2024-12-11
Let's Focus: Focused Backdoor Attack against Federated Transfer Learning,"Marco Arazzi, Stefanos Koffas, Antonino Nocera, Stjepan Picek",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19420"" target=""_blank"">2404.19420</a>",,2024-12-11
Graph Machine Learning in the Era of Large Language Models (LLMs),"Wenqi Fan, Shijie Wang, Jiani Huang, Zhikai Chen, Yu Song, Wenzhuo Tang, Haitao Mao, Hui Liu, Xiaorui Liu, Dawei Yin, Qing Li",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14928"" target=""_blank"">2404.14928</a>",,2024-12-11
MLSD-GAN -- Generating Strong High Quality Face Morphing Attacks using Latent Semantic Disentanglement,"Aravinda Reddy PN, Raghavendra Ramachandra, Krothapalli Sreenivasa Rao, Pabitra Mitra",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12679"" target=""_blank"">2404.12679</a>",,2024-12-11
LSP Framework: A Compensatory Model for Defeating Trigger Reverse Engineering via Label Smoothing Poisoning,"Beichen Li, Yuanfang Guo, Heqi Peng, Yangxi Li, Yunhong Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12852"" target=""_blank"">2404.12852</a>",,2024-12-11
"Fortify the Guardian, Not the Treasure: Resilient Adversarial Detectors","Raz Lapid, Almog Dubin, Moshe Sipper",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12120"" target=""_blank"">2404.12120</a>",,2024-12-11
Advancing the Robustness of Large Language Models through Self-Denoised Smoothing,"Jiabao Ji, Bairu Hou, Zhen Zhang, Guanhua Zhang, Wenqi Fan, Qing Li, Yang Zhang, Gaowen Liu, Sijia Liu, Shiyu Chang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12274"" target=""_blank"">2404.12274</a>","<a href=""https://github.com/UCSB-NLP-Chang/SelfDenoise"" target=""_blank"">UCSB-NLP-Chang</a>",2024-12-11
SA-Attack: Speed-adaptive stealthy adversarial attack on trajectory prediction,"Huilin Yin, Jiaxiang Li, Pengju Zhen, Jun Yan",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12612"" target=""_blank"">2404.12612</a>","<a href=""https://github.com/eclipse-bot/SA-Attack"" target=""_blank"">eclipse-bot</a>",2024-12-11
Enhance Robustness of Language Models Against Variation Attack through Graph Integration,"Zi Xiong, Lizhi Qing, Yangyang Kang, Jiawei Liu, Hongsong Li, Changlong Sun, Xiaozhong Liu, Wei Lu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12014"" target=""_blank"">2404.12014</a>",,2024-12-11
Uncovering Safety Risks of Large Language Models through Concept Activation Vector,"Zhihao Xu, Ruixuan Huang, Changyu Chen, Shuai Wang, Xiting Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12038"" target=""_blank"">2404.12038</a>",,2024-12-11
Proteus: Preserving Model Confidentiality during Graph Optimizations,"Yubo Gao, Maryam Haghifam, Christina Giannoula, Renbo Tu, Gennady Pekhimenko, Nandita Vijaykumar",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12512"" target=""_blank"">2404.12512</a>",,2024-12-11
Omniview-Tuning: Boosting Viewpoint Invariance of Vision-Language Pre-training Models,"Shouwei Ruan, Yinpeng Dong, Hanqing Liu, Yao Huang, Hang Su, Xingxing Wei",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12139"" target=""_blank"">2404.12139</a>",,2024-12-11
"Is There No Such Thing as a Bad Question? H4R: HalluciBot For Ratiocination, Rewriting, Ranking, and Routing","William Watson, Nicole Cho, Nishan Srishankar",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12535"" target=""_blank"">2404.12535</a>",,2024-12-11
The Victim and The Beneficiary: Exploiting a Poisoned Model to Train a Clean Model on Poisoned Data,"Zixuan Zhu, Rui Wang, Cong Zou, Lihua Jing",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.11265"" target=""_blank"">2404.11265</a>","<a href=""https://github.com/Zixuan-Zhu/VaB"" target=""_blank"">Zixuan-Zhu</a>",2024-12-11
GenFighter: A Generative and Evolutive Textual Attack Removal,"Md Athikul Islam, Edoardo Serra, Sushil Jajodia",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.11538"" target=""_blank"">2404.11538</a>",,2024-12-11
Utilizing Adversarial Examples for Bias Mitigation and Accuracy Enhancement,"Pushkar Shukla, Dhruv Srikanth, Lee Cohen, Matthew Turk",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.11819"" target=""_blank"">2404.11819</a>",,2024-12-11
Exploring DNN Robustness Against Adversarial Attacks Using Approximate Multipliers,"Mohammad Javad Askarizadeh, Ebrahim Farahmand, Jorge Castro-Godinez, Ali Mahani, Laura Cabrera-Quiros, Carlos Salazar-Garcia",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.11665"" target=""_blank"">2404.11665</a>",,2024-12-11
Exploring the Transferability of Visual Prompting for Multimodal Large Language Models,"Yichi Zhang, Yinpeng Dong, Siyuan Zhang, Tianzan Min, Hang Su, Jun Zhu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.11207"" target=""_blank"">2404.11207</a>",,2024-12-11
Toward Understanding the Disagreement Problem in Neural Network Feature Attribution,"Niklas Koenen, Marvin N. Wright",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.11330"" target=""_blank"">2404.11330</a>",,2024-12-11
Towards Robust and Interpretable EMG-based Hand Gesture Recognition using Deep Metric Meta Learning,"Simon Tam, Shriram Tallam Puranam Raghu, Ãtienne Buteau, Erik Scheme, Mounir Boukadoum, Alexandre Campeau-Lecours, Benoit Gosselin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15360"" target=""_blank"">2404.15360</a>",,2024-12-11
Efficiently Adversarial Examples Generation for Visual-Language Models under Targeted Transfer Scenarios using Diffusion Models,"Qi Guo, Shanmin Pang, Xiaojun Jia, Qing Guo",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10335"" target=""_blank"">2404.10335</a>",,2024-12-11
Robust Noisy Label Learning via Two-Stream Sample Distillation,"Sihan Bai, Sanping Zhou, Zheng Qin, Le Wang, Nanning Zheng",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10499"" target=""_blank"">2404.10499</a>",,2024-12-11
Black-box Adversarial Transferability: An Empirical Study in Cybersecurity Perspective,"Khushnaseeb Roshan, Aasim Zafar",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10796"" target=""_blank"">2404.10796</a>",,2024-12-11
Towards Understanding the Robustness of Diffusion-Based Purification: A Stochastic Perspective,"Yiming Liu, Kezhao Liu, Yao Xiao, Ziyi Dong, Xiaogang Xu, Pengxu Wei, Liang Lin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14309"" target=""_blank"">2404.14309</a>",,2024-12-11
Improving Weakly-Supervised Object Localization Using Adversarial Erasing and Pseudo Label,"Byeongkeun Kang, Sinhae Cha, Yeejin Lee",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09475"" target=""_blank"">2404.09475</a>",,2024-12-11
Ti-Patch: Tiled Physical Adversarial Patch for no-reference video quality metrics,"Victoria Leonenkova, Ekaterina Shumitskaya, Anastasia Antsiferova, Dmitriy Vatolin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09961"" target=""_blank"">2404.09961</a>",,2024-12-11
Towards a Novel Perspective on Adversarial Examples Driven by Frequency,"Zhun Zhang, Yi Zeng, Qihe Liu, Shijie Zhou",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10202"" target=""_blank"">2404.10202</a>",,2024-12-11
Model-Based Counterfactual Explanations Incorporating Feature Space Attributes for Tabular Data,"Yuta Sumiya, Hayaru shouno",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13224"" target=""_blank"">2404.13224</a>","<a href=""https://github.com/sumugit/FastDCFlow"" target=""_blank"">sumugit</a>",2024-12-11
Adversarial Identity Injection for Semantic Face Image Synthesis,"Giuseppe Tarollo, Tomaso Fontanini, Claudio Ferrari, Guido Borghi, Andrea Prati",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10408"" target=""_blank"">2404.10408</a>",,2024-12-11
Physical Backdoor Attack can Jeopardize Driving with Vision-Large-Language Models,"Zhenyang Ni, Rui Ye, Yuxi Wei, Zhen Xiang, Yanfeng Wang, Siheng Chen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12916"" target=""_blank"">2404.12916</a>",,2024-12-11
Attack on Scene Flow using Point Clouds,"Haniyeh Ehsani Oskouie, Mohammad-Shahram Moin, Shohreh Kasaei",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13621"" target=""_blank"">2404.13621</a>","<a href=""https://github.com/aheldis/Attack-on-Scene-Flow-using-Point-Clouds"" target=""_blank"">aheldis</a>",2024-12-11
Explicit Lipschitz Value Estimation Enhances Policy Robustness Against Perturbation,"Xulin Chen, Ruipeng Liu, Garrett E. Katz",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13879"" target=""_blank"">2404.13879</a>",,2024-12-11
A Clean-graph Backdoor Attack against Graph Convolutional Networks with Poisoned Label Only,"Jiazhu Dai, Haoyu Sun",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12704"" target=""_blank"">2404.12704</a>",,2024-12-11
Protecting Your LLMs with Information Bottleneck,"Zichuan Liu, Zefan Wang, Linjie Xu, Jinyu Wang, Lei Song, Tianchun Wang, Chunlin Chen, Wei Cheng, Jiang Bian",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13968"" target=""_blank"">2404.13968</a>",,2024-12-11
CloudFort: Enhancing Robustness of 3D Point Cloud Classification Against Backdoor Attacks via Spatial Partitioning and Ensemble Prediction,"Wenhao Lan, Yijun Yang, Haihua Shen, Shan Li",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14042"" target=""_blank"">2404.14042</a>",,2024-12-11
Competition Report: Finding Universal Jailbreak Backdoors in Aligned LLMs,"Javier Rando, Francesco Croce, KryÅ¡tof Mitka, Stepan Shabalin, Maksym Andriushchenko, Nicolas Flammarion, Florian TramÃ¨r",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14461"" target=""_blank"">2404.14461</a>",,2024-12-11
Deep Learning as Ricci Flow,"Anthony Baptista, Alessandro Barp, Tapabrata Chakraborti, Chris Harbron, Ben D. MacArthur, Christopher R. S. Banerji",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14265"" target=""_blank"">2404.14265</a>",,2024-12-11
Double Privacy Guard: Robust Traceable Adversarial Watermarking against Face Recognition,"Yunming Zhang, Dengpan Ye, Sipeng Shen, Caiyun Xie, Ziyi Liu, Jiacheng Deng, Long Tang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14693"" target=""_blank"">2404.14693</a>",,2024-12-11
Hyp-OC: Hyperbolic One Class Classification for Face Anti-Spoofing,"Kartik Narayan, Vishal M. Patel",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14406"" target=""_blank"">2404.14406</a>",,2024-12-11
Poisoning Attacks on Federated Learning-based Wireless Traffic Prediction,"Zifan Zhang, Minghong Fang, Jiayuan Huang, Yuchen Liu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14389"" target=""_blank"">2404.14389</a>",,2024-12-11
Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations,"Sukmin Cho, Soyeong Jeong, Jeongyeon Seo, Taeho Hwang, Jong C. Park",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13948"" target=""_blank"">2404.13948</a>",,2024-12-11
Audio Anti-Spoofing Detection: A Survey,"Menglu Li, Yasaman Ahmadiadli, Xiao-Ping Zhang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13914"" target=""_blank"">2404.13914</a>",,2024-12-11
Fermi-Bose Machine,"Mingshan Xie, Yuchen Wang, Haiping Huang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13631"" target=""_blank"">2404.13631</a>",,2024-12-11
Reliable Model Watermarking: Defending Against Theft without Compromising on Evasion,"Hongyu Zhu, Sichu Liang, Wentao Hu, Fangqi Li, Ju Jia, Shilin Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13518"" target=""_blank"">2404.13518</a>",,2024-12-11
AED-PADA:Improving Generalizability of Adversarial Example Detection via Principal Adversarial Domain Adaptation,"Heqi Peng, Yunhong Wang, Ruijie Yang, Beichen Li, Rui Wang, Yuanfang Guo",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12635"" target=""_blank"">2404.12635</a>",,2024-12-11
How Real Is Real? A Human Evaluation Framework for Unrestricted Adversarial Examples,"Dren Fazlija, Arkadij Orlov, Johanna Schrader, Monty-Maximilian ZÃ¼hlke, Michael Rohs, Daniel Kudenko",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12653"" target=""_blank"">2404.12653</a>",,2024-12-11
Backdoor Attacks and Defenses on Semantic-Symbol Reconstruction in Semantic Communications,"Yuan Zhou, Rose Qingyang Hu, Yi Qian",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13279"" target=""_blank"">2404.13279</a>",,2024-12-11
Pixel is a Barrier: Diffusion Models Are More Adversarially Robust Than We Think,"Haotian Xue, Yongxin Chen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13320"" target=""_blank"">2404.13320</a>","<a href=""https://github.com/xavihart/PDM-Pure"" target=""_blank"">xavihart</a>",2024-12-11
Robust EEG-based Emotion Recognition Using an Inception and Two-sided Perturbation Model,"Shadi Sartipi, Mujdat Cetin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15373"" target=""_blank"">2404.15373</a>",,2024-12-11
Beyond Score Changes: Adversarial Attack on No-Reference Image Quality Assessment from Two Perspectives,"Chenxi Yang, Yujia Liu, Dingquan Li, Yan Zhong, Tingting Jiang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13277"" target=""_blank"">2404.13277</a>",,2024-12-11
Dual Model Replacement:invisible Multi-target Backdoor Attack based on Federal Learning,"Rong Wang, Guichen Zhou, Mingjun Gao, Yunpeng Xiao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13946"" target=""_blank"">2404.13946</a>",,2024-12-11
Trojan Detection in Large Language Models: Insights from The Trojan Detection Challenge,"Narek Maloyan, Ekansh Verma, Bulat Nutfullin, Bislan Ashinov",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13660"" target=""_blank"">2404.13660</a>",,2024-12-11
Swap It Like Its Hot: Segmentation-based spoof attacks on eye-tracking images,"Anish S. Narkar, Brendan David-John",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13827"" target=""_blank"">2404.13827</a>",,2024-12-11
AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs,"Anselm Paulus, Arman Zharmagambetov, Chuan Guo, Brandon Amos, Yuandong Tian",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16873"" target=""_blank"">2404.16873</a>",,2024-12-11
epsilon-Mesh Attack: A Surface-based Adversarial Point Cloud Attack for Facial Expression Recognition,"Batuhan Cengiz, Mert Gulsen, Yusuf H. Sahin, Gozde Unal",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06661"" target=""_blank"">2403.06661</a>","<a href=""https://github.com/batuceng/e-mesh-attack"" target=""_blank"">batuceng</a>",2024-12-11
Dynamic Perturbation-Adaptive Adversarial Training on Medical Image Classification,"Shuai Li, Xiaoguang Ma, Shancheng Jiang, Lu Meng",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06798"" target=""_blank"">2403.06798</a>",,2024-12-11
"Improving deep learning with prior knowledge and cognitive models: A survey on enhancing explainability, adversarial robustness and zero-shot learning","Fuseinin Mumuni, Alhassan Mumuni",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07078"" target=""_blank"">2403.07078</a>",,2024-12-11
Disentangling Policy from Offline Task Representation Learning via Adversarial Data Augmentation,"Chengxing Jia, Fuxiang Zhang, Yi-Chen Li, Chen-Xiao Gao, Xu-Hui Liu, Lei Yuan, Zongzhang Zhang, Yang Yu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07261"" target=""_blank"">2403.07261</a>",,2024-12-11
PCLD: Point Cloud Layerwise Diffusion for Adversarial Purification,"Mert Gulsen, Batuhan Cengiz, Yusuf H. Sahin, Gozde Unal",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06698"" target=""_blank"">2403.06698</a>","<a href=""https://github.com/batuceng/diffusion-layer-robustness-pc"" target=""_blank"">batuceng</a>",2024-12-11
Overcoming the Paradox of Certified Training with Gaussian Smoothing,"Stefan Balauca, Mark Niklas MÃ¼ller, Yuhao Mao, Maximilian Baader, Marc Fischer, Martin Vechev",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07095"" target=""_blank"">2403.07095</a>",,2024-12-11
Intra-Section Code Cave Injection for Adversarial Evasion Attacks on Windows PE Malware File,"Kshitiz Aryal, Maanak Gupta, Mahmoud Abdelsalam, Moustafa Saleh",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06428"" target=""_blank"">2403.06428</a>",,2024-12-11
Real is not True: Backdoor Attacks Against Deepfake Detection,"Hong Sun, Ziqiang Li, Lei Liu, Bin Li",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06610"" target=""_blank"">2403.06610</a>",,2024-12-11
PeerAiD: Improving Adversarial Distillation from a Specialized Peer Tutor,"Jaewon Jung, Hongsun Jang, Jaeyong Song, Jinho Lee",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06668"" target=""_blank"">2403.06668</a>","<a href=""https://github.com/jaewonalive/PeerAiD"" target=""_blank"">jaewonalive</a>",2024-12-11
IOI: Invisible One-Iteration Adversarial Attack on No-Reference Image- and Video-Quality Metrics,"Ekaterina Shumitskaya, Anastasia Antsiferova, Dmitriy Vatolin",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05955"" target=""_blank"">2403.05955</a>",,2024-12-11
Stealing Part of a Production Language Model,"Nicholas Carlini, Daniel Paleka, Krishnamurthy Dj Dvijotham, Thomas Steinke, Jonathan Hayase, A. Feder Cooper, Katherine Lee, Matthew Jagielski, Milad Nasr, Arthur Conmy, Eric Wallace, David Rolnick, Florian TramÃ¨r",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06634"" target=""_blank"">2403.06634</a>",,2024-12-11
AS-FIBA: Adaptive Selective Frequency-Injection for Backdoor Attack on Deep Face Restoration,"Zhenbo Song, Wenhao Gao, Kaihao Zhang, Wenhan Luo, Zhaoxin Fan, Jianfeng Lu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06430"" target=""_blank"">2403.06430</a>",,2024-12-11
Towards the Uncharted: Density-Descending Feature Perturbation for Semi-supervised Semantic Segmentation,"Xiaoyang Wang, Huihui Bai, Limin Yu, Yao Zhao, Jimin Xiao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06462"" target=""_blank"">2403.06462</a>","<a href=""https://github.com/Gavinwxy/DDFP"" target=""_blank"">Gavinwxy</a>",2024-12-11
Learning with Noisy Foundation Models,"Hao Chen, Jindong Wang, Zihan Wang, Ran Tao, Hongxin Wei, Xing Xie, Masashi Sugiyama, Bhiksha Raj",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06869"" target=""_blank"">2403.06869</a>",,2024-12-11
DNNShield: Embedding Identifiers for Deep Neural Network Ownership Verification,"Jasper Stang, Torsten KrauÃ, Alexandra Dmitrienko",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06581"" target=""_blank"">2403.06581</a>",,2024-12-11
A Zero Trust Framework for Realization and Defense Against Generative AI Attacks in Power Grid,"Md. Shirajum Munir, Sravanthi Proddatoori, Manjushree Muralidhara, Walid Saad, Zhu Han, Sachin Shetty",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06388"" target=""_blank"">2403.06388</a>",,2024-12-11
Hard-label based Small Query Black-box Adversarial Attack,"Jeonghwan Park, Paul Miller, Niall McLaughlin",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06014"" target=""_blank"">2403.06014</a>",,2024-12-11
Duwak: Dual Watermarks in Large Language Models,"Chaoyi Zhu, Jeroen Galjaard, Pin-Yu Chen, Lydia Y. Chen",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13000"" target=""_blank"">2403.13000</a>",,2024-12-11
iBA: Backdoor Attack on 3D Point Cloud via Reconstructing Itself,"Yuhao Bian, Shengjing Tian, Xiuping Liu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05847"" target=""_blank"">2403.05847</a>",,2024-12-11
Attacking Transformers with Feature Diversity Adversarial Perturbation,"Chenxing Gao, Hang Zhou, Junqing Yu, YuTeng Ye, Jiale Cai, Junle Wang, Wei Yang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07942"" target=""_blank"">2403.07942</a>",,2024-12-11
Hide in Thicket: Generating Imperceptible and Rational Adversarial Perturbations on 3D Point Clouds,"Tianrui Lou, Xiaojun Jia, Jindong Gu, Li Liu, Siyuan Liang, Bangyan He, Xiaochun Cao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05247"" target=""_blank"">2403.05247</a>","<a href=""https://github.com/TRLou/HiT-ADV"" target=""_blank"">TRLou</a>",2024-12-11
Visual Privacy Auditing with Diffusion Models,"Kristian Schwethelm, Johannes Kaiser, Moritz Knolle, Daniel Rueckert, Georgios Kaissis, Alexander Ziller",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07588"" target=""_blank"">2403.07588</a>",,2024-12-11
Attack Deterministic Conditional Image Generative Models for Diverse and Controllable Generation,"Tianyi Chu, Wei Xing, Jiafu Chen, Zhizhong Wang, Jiakai Sun, Lei Zhao, Haibo Chen, Huaizhong Lin",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.08294"" target=""_blank"">2403.08294</a>",,2024-12-11
Towards a Framework for Deep Learning Certification in Safety-Critical Applications Using Inherently Safe Design and Run-Time Error Detection,Romeo Valentin,arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14678"" target=""_blank"">2403.14678</a>",,2024-12-11
Backdoor Attack with Mode Mixture Latent Modification,"Hongwei Zhang, Xiaoyin Xu, Dongsheng An, Xianfeng Gu, Min Zhang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07463"" target=""_blank"">2403.07463</a>",,2024-12-11
Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency,"Soumyadeep Pal, Yuguang Yao, Ren Wang, Bingquan Shen, Sijia Liu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10717"" target=""_blank"">2403.10717</a>","<a href=""https://github.com/OPTML-Group/BackdoorMSPC"" target=""_blank"">OPTML-Group</a>",2024-12-11
Robust Influence-based Training Methods for Noisy Brain MRI,"Minh-Hao Van, Alycia N. Carey, Xintao Wu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10698"" target=""_blank"">2403.10698</a>",,2024-12-11
An Image Is Worth 1000 Lies: Adversarial Transferability across Prompts on Vision-Language Models,"Haochen Luo, Jindong Gu, Fengyuan Liu, Philip Torr",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09766"" target=""_blank"">2403.09766</a>","<a href=""https://github.com/Haochen-Luo/CroPA"" target=""_blank"">Haochen-Luo</a>",2024-12-11
Counter-Samples: A Stateless Strategy to Neutralize Black Box Adversarial Attacks,"Roey Bokobza, Yisroel Mirsky",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10562"" target=""_blank"">2403.10562</a>",,2024-12-11
Exploring the Adversarial Frontier: Quantifying Robustness via Adversarial Hypervolume,"Ping Guo, Cheng Gong, Xi Lin, Zhiyuan Yang, Qingfu Zhang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05100"" target=""_blank"">2403.05100</a>",,2024-12-11
Adversarial Fine-tuning of Compressed Neural Networks for Joint Improvement of Robustness and Efficiency,"Hallgrimur Thorsteinsson, Valdemar J Henriksen, Tong Chen, Raghavendra Selvan",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09441"" target=""_blank"">2403.09441</a>",,2024-12-11
Soften to Defend: Towards Adversarial Robustness via Self-Guided Label Refinement,"Daiwei Yu, Zhuorong Li, Lina Wei, Canghong Jin, Yun Zhang, Sixian Chan",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09101"" target=""_blank"">2403.09101</a>",,2024-12-11
Robust Subgraph Learning by Monitoring Early Training Representations,"Sepideh Neshatfar, Salimeh Yasaei Sekeh",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09901"" target=""_blank"">2403.09901</a>",,2024-12-11
LDPRecover: Recovering Frequencies from Poisoning Attacks against Local Differential Privacy,"Xinyue Sun, Qingqing Ye, Haibo Hu, Jiawei Duan, Tianyu Wo, Jie Xu, Renyu Yang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09351"" target=""_blank"">2403.09351</a>",,2024-12-11
AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting,"Yu Wang, Xiaogeng Liu, Yu Li, Muhao Chen, Chaowei Xiao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09513"" target=""_blank"">2403.09513</a>","<a href=""https://github.com/rain305f/AdaShield"" target=""_blank"">rain305f</a>",2024-12-11
Towards White Box Deep Learning,Maciej Satkiewicz,arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09863"" target=""_blank"">2403.09863</a>","<a href=""https://github.com/314-Foundation/white-box-nn"" target=""_blank"">314-Foundation</a>",2024-12-11
Symbiotic Game and Foundation Models for Cyber Deception Operations in Strategic Cyber Warfare,"Tao Li, Quanyan Zhu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10570"" target=""_blank"">2403.10570</a>",,2024-12-11
PreCurious: How Innocent Pre-Trained Language Models Turn into Privacy Traps,"Ruixuan Liu, Tianhao Wang, Yang Cao, Li Xiong",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09562"" target=""_blank"">2403.09562</a>",,2024-12-11
AVIBench: Towards Evaluating the Robustness of Large Vision-Language Model on Adversarial Visual-Instructions,"Hao Zhang, Wenqi Shao, Hong Liu, Yongqiang Ma, Ping Luo, Yu Qiao, Kaipeng Zhang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09346"" target=""_blank"">2403.09346</a>",,2024-12-11
Medical Unlearnable Examples: Securing Medical Data from Unauthorized Traning via Sparsity-Aware Local Masking,"Weixiang Sun, Yixin Liu, Zhiling Yan, Kaidi Xu, Lichao Sun",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10573"" target=""_blank"">2403.10573</a>",,2024-12-11
ADEdgeDrop: Adversarial Edge Dropping for Robust Graph Neural Networks,"Zhaoliang Chen, Zhihao Wu, Ylli Sadikaj, Claudia Plant, Hong-Ning Dai, Shiping Wang, Yiu-Ming Cheung, Wenzhong Guo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09171"" target=""_blank"">2403.09171</a>",,2024-12-11
Fast Inference of Removal-Based Node Influence,"Weikai Li, Zhiping Xiao, Xiao Luo, Yizhou Sun",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.08333"" target=""_blank"">2403.08333</a>","<a href=""https://github.com/weikai-li/NORA"" target=""_blank"">weikai-li</a>",2024-12-11
Tastle: Distract Large Language Models for Automatic Jailbreak Attack,"Zeguan Xiao, Yan Yang, Guanhua Chen, Yun Chen",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.08424"" target=""_blank"">2403.08424</a>",,2024-12-11
Adaptive Hybrid Masking Strategy for Privacy-Preserving Face Recognition Against Model Inversion Attack,"Yinggui Wang, Yuanqing Huang, Jianshu Li, Le Yang, Kai Song, Lei Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10558"" target=""_blank"">2403.10558</a>",,2024-12-11
"RAF-GI: Towards Robust, Accurate and Fast-Convergent Gradient Inversion Attack in Federated Learning","Can Liu, Jin Wang, Dongyang Yu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.08383"" target=""_blank"">2403.08383</a>",,2024-12-11
Verifix: Post-Training Correction to Improve Label Noise Robustness with Verified Samples,"Sangamesh Kodge, Deepak Ravikumar, Gobinda Saha, Kaushik Roy",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.08618"" target=""_blank"">2403.08618</a>",,2024-12-11
Versatile Defense Against Adversarial Attacks on Image Recognition,"Haibo Zhang, Zhihua Yao, Kouichi Sakurai",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.08170"" target=""_blank"">2403.08170</a>",,2024-12-11
Towards Model Extraction Attacks in GAN-Based Image Translation via Domain Shift Mitigation,"Di Mi, Yanjun Zhang, Leo Yu Zhang, Shengshan Hu, Qi Zhong, Haizhuan Yuan, Shirui Pan",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07673"" target=""_blank"">2403.07673</a>",,2024-12-11
Gemini 1,"Team Gemini, Petko Georgiev, Ving Ian Lei, Ryan Burnell, Libin Bai, Anmol Gulati, Garrett Tanzer, Damien Vincent, Zhufeng Pan, Shibo Wang, Soroosh Mariooryad, Yifan Ding, Xinyang Geng, Fred Alcober, Roy Frostig, Mark Omernick, Lexi Walker, Cosmin Paduraru, Christina Sorokin, Andrea Tacchetti, Colin Gaffney, Samira Daruki, Olcan Sercinoglu, Zach Gleicher, Juliette Love, Paul Voigtlaender, Rohan Jain, Gabriela Surita, Kareem Mohamed, Rory Blevins, Junwhan Ahn, Tao Zhu, Kornraphop Kawintiranon, Orhan Firat, Yiming Gu, Yujing Zhang, Matthew Rahtz, Manaal Faruqui, Natalie Clay, Justin Gilmer, JD Co-Reyes, Ivo Penchev, Rui Zhu, Nobuyuki Morioka, Kevin Hui, Krishna Haridasan, Victor Campos, Mahdis Mahdieh, Mandy Guo, Samer Hassan, Kevin Kilgour, Arpi Vezer, Heng-Tze Cheng, Liedekerke Raoul de, Siddharth Goyal, Paul Barham, DJ Strouse, Seb Noury, Jonas Adler, Mukund Sundararajan, Sharad Vikram, Dmitry Lepikhin, Michela Paganini, Xavier Garcia, Fan Yang, Dasha Valter, Maja Trebacz, Kiran Vodrahalli, Chulayuth Asawaroengchai, Roman Ring, Norbert Kalb, Livio Baldini Soares, Siddhartha Brahma, David Steiner, Tianhe Yu, Fabian Mentzer, Antoine He, Lucas Gonzalez, Bibo Xu, Raphael Lopez Kaufman, Laurent El Shafey, Junhyuk Oh, Tom Hennigan, George van den Driessche, Seth Odoom, Mario Lucic, Becca Roelofs, Sid Lall, Amit Marathe, Betty Chan, Santiago Ontanon, Luheng He, Denis Teplyashin, Jonathan Lai, Phil Crone, Bogdan Damoc, Lewis Ho, Sebastian Riedel, Karel Lenc, Chih-Kuan Yeh, Aakanksha Chowdhery, Yang Xu, Mehran Kazemi, Ehsan Amid, Anastasia Petrushkina, Kevin Swersky, Ali Khodaei, Gowoon Chen, Chris Larkin, Mario Pinto, Geng Yan, Adria Puigdomenech Badia, Piyush Patil, Steven Hansen, Dave Orr, Sebastien M. R. Arnold, Jordan Grimstad, Andrew Dai, Sholto Douglas, Rishika Sinha, Vikas Yadav, Xi Chen, Elena Gribovskaya, Jacob Austin, Jeffrey Zhao, Kaushal Patel, Paul Komarek, Sophia Austin, Sebastian Borgeaud, Linda Friso, Abhimanyu Goyal, Ben Caine, Kris Cao, Da-Woon Chung, Matthew Lamm, Gabe Barth-Maron, Thais Kagohara, Kate Olszewska, Mia Chen, Kaushik Shivakumar, Rishabh Agarwal, Harshal Godhia, Ravi Rajwar, Javier Snaider, Xerxes Dotiwalla, Yuan Liu, Aditya Barua, Victor Ungureanu, Yuan Zhang, Bat-Orgil Batsaikhan, Mateo Wirth, James Qin, Ivo Danihelka, Tulsee Doshi, Martin Chadwick, Jilin Chen, Sanil Jain, Quoc Le, Arjun Kar, Madhu Gurumurthy, Cheng Li, Ruoxin Sang, Fangyu Liu, Lampros Lamprou, Rich Munoz, Nathan Lintz, Harsh Mehta, Heidi Howard, Malcolm Reynolds, Lora Aroyo, Quan Wang, Lorenzo Blanco, Albin Cassirer, Jordan Griffith, Dipanjan Das, Stephan Lee, Jakub Sygnowski, Zach Fisher, James Besley, Richard Powell, Zafarali Ahmed, Dominik Paulus, David Reitter, Zalan Borsos, Rishabh Joshi, Aedan Pope, Steven Hand, Vittorio Selo, Vihan Jain, Nikhil Sethi, Megha Goel, Takaki Makino, Rhys May, Zhen Yang, Johan Schalkwyk, Christina Butterfield, Anja Hauth, Alex Goldin, Will Hawkins, Evan Senter, Sergey Brin, Oliver Woodman, Marvin Ritter, Eric Noland, Minh Giang, Vijay Bolina, Lisa Lee, Tim Blyth, Ian Mackinnon, Machel Reid, Obaid Sarvana, David Silver, Alexander Chen, Lily Wang, Loren Maggiore, Oscar Chang, Nithya Attaluri, Gregory Thornton, Chung-Cheng Chiu, Oskar Bunyan, Nir Levine, Timothy Chung, Evgenii Eltyshev, Xiance Si, Timothy Lillicrap, Demetra Brady, Vaibhav Aggarwal, Boxi Wu, Yuanzhong Xu, Ross McIlroy, Kartikeya Badola, Paramjit Sandhu, Erica Moreira, Wojciech Stokowiec, Ross Hemsley, Dong Li, Alex Tudor, Pranav Shyam, Elahe Rahimtoroghi, Salem Haykal, Pablo Sprechmann, Xiang Zhou, Diana Mincu, Yujia Li, Ravi Addanki, Kalpesh Krishna, Xiao Wu, Alexandre Frechette, Matan Eyal, Allan Dafoe, Dave Lacey, Jay Whang, Thi Avrahami, Ye Zhang, Emanuel Taropa, Hanzhao Lin, Daniel Toyama, Eliza Rutherford, Motoki Sano, HyunJeong Choe, Alex Tomala, Chalence Safranek-Shrader, Nora Kassner, Mantas Pajarskas, Matt Harvey, Sean Sechrist, Meire Fortunato, Christina Lyu, Gamaleldin Elsayed, Chenkai Kuang, James Lottes, Eric Chu, Chao Jia, Chih-Wei Chen, Peter Humphreys, Kate Baumli, Connie Tao, Rajkumar Samuel, Cicero Nogueira dos Santos, Anders Andreassen, Nemanja RakiÄeviÄ, Dominik Grewe, Aviral Kumar, Stephanie Winkler, Jonathan Caton, Andrew Brock, Sid Dalmia, Hannah Sheahan, Iain Barr, Yingjie Miao, Paul Natsev, Jacob Devlin, Feryal Behbahani, Flavien Prost, Yanhua Sun, Artiom Myaskovsky, Thanumalayan Sankaranarayana Pillai, Dan Hurt, Angeliki Lazaridou, Xi Xiong, Ce Zheng, Fabio Pardo, Xiaowei Li, Dan Horgan, Joe Stanton, Moran Ambar, Fei Xia, Alejandro Lince, Mingqiu Wang, Basil Mustafa, Albert Webson, Hyo Lee, Rohan Anil, Martin Wicke, Timothy Dozat, Abhishek Sinha, Enrique Piqueras, Elahe Dabir, Shyam Upadhyay, Anudhyan Boral, Lisa Anne Hendricks, Corey Fry, Josip Djolonga, Yi Su, Jake Walker, Jane Labanowski, Ronny Huang, Vedant Misra, Jeremy Chen, RJ Skerry-Ryan, Avi Singh, Shruti Rijhwani, Dian Yu, Alex Castro-Ros, Beer Changpinyo, Romina Datta, Sumit Bagri, Arnar Mar Hrafnkelsson, Marcello Maggioni, Daniel Zheng, Yury Sulsky, Shaobo Hou, Tom Le Paine, Antoine Yang, Jason Riesa, Dominika Rogozinska, Dror Marcus, Dalia El Badawy, Qiao Zhang, Luyu Wang, Helen Miller, Jeremy Greer, Lars Lowe Sjos, Azade Nova, Heiga Zen, Rahma Chaabouni, Mihaela Rosca, Jiepu Jiang, Charlie Chen, Ruibo Liu, Tara Sainath, Maxim Krikun, Alex Polozov, Jean-Baptiste Lespiau, Josh Newlan, Zeyncep Cankara, Soo Kwak, Yunhan Xu, Phil Chen, Andy Coenen, Clemens Meyer, Katerina Tsihlas, Ada Ma, Juraj Gottweis, Jinwei Xing, Chenjie Gu, Jin Miao, Christian Frank, Zeynep Cankara, Sanjay Ganapathy, Ishita Dasgupta, Steph Hughes-Fitt, Heng Chen, David Reid, Keran Rong, Hongmin Fan, Amersfoort Joost van, Vincent Zhuang, Aaron Cohen, Shixiang Shane Gu, Anhad Mohananey, Anastasija Ilic, Taylor Tobin, John Wieting, Anna Bortsova, Phoebe Thacker, Emma Wang, Emily Caveness, Justin Chiu, Eren Sezener, Alex Kaskasoli, Steven Baker, Katie Millican, Mohamed Elhawaty, Kostas Aisopos, Carl Lebsack, Nathan Byrd, Hanjun Dai, Wenhao Jia, Matthew Wiethoff, Elnaz Davoodi, Albert Weston, Lakshman Yagati, Arun Ahuja, Isabel Gao, Golan Pundak, Susan Zhang, Michael Azzam, Khe Chai Sim, Sergi Caelles, James Keeling, Abhanshu Sharma, Andy Swing, YaGuang Li, Chenxi Liu, Carrie Grimes Bostock, Yamini Bansal, Zachary Nado, Ankesh Anand, Josh Lipschultz, Abhijit Karmarkar, Lev Proleev, Abe Ittycheriah, Soheil Hassas Yeganeh, George Polovets, Aleksandra Faust, Jiao Sun, Alban Rrustemi, Pen Li, Rakesh Shivanna, Jeremiah Liu, Chris Welty, Federico Lebron, Anirudh Baddepudi, Sebastian Krause, Emilio Parisotto, Radu Soricut, Zheng Xu, Dawn Bloxwich, Melvin Johnson, Behnam Neyshabur, Justin Mao-Jones, Renshen Wang, Vinay Ramasesh, Zaheer Abbas, Arthur Guez, Constant Segal, Duc Dung Nguyen, James Svensson, Le Hou, Sarah York, Kieran Milan, Sophie Bridgers, Wiktor Gworek, Marco Tagliasacchi, James Lee-Thorp, Michael Chang, Alexey Guseynov, Ale Jakse Hartman, Michael Kwong, Ruizhe Zhao, Sheleem Kashem, Elizabeth Cole, Antoine Miech, Richard Tanburn, Mary Phuong, Filip Pavetic, Sebastien Cevey, Ramona Comanescu, Richard Ives, Sherry Yang, Cosmo Du, Bo Li, Zizhao Zhang, Mariko Iinuma, Clara Huiyi Hu, Aurko Roy, Shaan Bijwadia, Zhenkai Zhu, Danilo Martins, Rachel Saputro, Anita Gergely, Steven Zheng, Dawei Jia, Ioannis Antonoglou, Adam Sadovsky, Shane Gu, Yingying Bi, Alek Andreev, Sina Samangooei, Mina Khan, Tomas Kocisky, Angelos Filos, Chintu Kumar, Colton Bishop, Adams Yu, Sarah Hodkinson, Sid Mittal, Premal Shah, Alexandre Moufarek, Yong Cheng, Adam Bloniarz, Jaehoon Lee, Pedram Pejman, Paul Michel, Stephen Spencer, Vladimir Feinberg, Xuehan Xiong, Nikolay Savinov, Charlotte Smith, Siamak Shakeri, Dustin Tran, Mary Chesus, Bernd Bohnet, George Tucker, Glehn Tamara von, Carrie Muir, Yiran Mao, Hideto Kazawa, Ambrose Slone, Kedar Soparkar, Disha Shrivastava, James Cobon-Kerr, Michael Sharman, Jay Pavagadhi, Carlos Araya, Karolis Misiunas, Nimesh Ghelani, Michael Laskin, David Barker, Qiujia Li, Anton Briukhov, Neil Houlsby, Mia Glaese, Balaji Lakshminarayanan, Nathan Schucher, Yunhao Tang, Eli Collins, Hyeontaek Lim, Fangxiaoyu Feng, Adria Recasens, Guangda Lai, Alberto Magni, Cao Nicola De, Aditya Siddhant, Zoe Ashwood, Jordi Orbay, Mostafa Dehghani, Jenny Brennan, Yifan He, Kelvin Xu, Yang Gao, Carl Saroufim, James Molloy, Xinyi Wu, Seb Arnold, Solomon Chang, Julian Schrittwieser, Elena Buchatskaya, Soroush Radpour, Martin Polacek, Skye Giordano, Ankur Bapna, Simon Tokumine, Vincent Hellendoorn, Thibault Sottiaux, Sarah Cogan, Aliaksei Severyn, Mohammad Saleh, Shantanu Thakoor, Laurent Shefey, Siyuan Qiao, Meenu Gaba, Shuo-yiin Chang, Craig Swanson, Biao Zhang, Benjamin Lee, Paul Kishan Rubenstein, Gan Song, Tom Kwiatkowski, Anna Koop, Ajay Kannan, David Kao, Parker Schuh, Axel Stjerngren, Golnaz Ghiasi, Gena Gibson, Luke Vilnis, Ye Yuan, Felipe Tiengo Ferreira, Aishwarya Kamath, Ted Klimenko, Ken Franko, Kefan Xiao, Indro Bhattacharya, Miteyan Patel, Rui Wang, Alex Morris, Robin Strudel, Vivek Sharma, Peter Choy, Sayed Hadi Hashemi, Jessica Landon, Mara Finkelstein, Priya Jhakra, Justin Frye, Megan Barnes, Matthew Mauger, Dennis Daun, Khuslen Baatarsukh, Matthew Tung, Wael Farhan, Henryk Michalewski, Fabio Viola, Felix de Chaumont Quitry, Charline Le Lan, Tom Hudson, Qingze Wang, Felix Fischer, Ivy Zheng, Elspeth White, Anca Dragan, Jean-baptiste Alayrac, Eric Ni, Alexander Pritzel, Adam Iwanicki, Michael Isard, Anna Bulanova, Lukas Zilka, Ethan Dyer, Devendra Sachan, Srivatsan Srinivasan, Hannah Muckenhirn, Honglong Cai, Amol Mandhane, Mukarram Tariq, Jack W. Rae, Gary Wang, Kareem Ayoub, Nicholas FitzGerald, Yao Zhao, Woohyun Han, Chris Alberti, Dan Garrette, Kashyap Krishnakumar, Mai Gimenez, Anselm Levskaya, Daniel Sohn, Josip Matak, Inaki Iturrate, Michael B. Chang, Jackie Xiang, Yuan Cao, Nishant Ranka, Geoff Brown, Adrian Hutter, Vahab Mirrokni, Nanxin Chen, Kaisheng Yao, Zoltan Egyed, Francois Galilee, Tyler Liechty, Praveen Kallakuri, Evan Palmer, Sanjay Ghemawat, Jasmine Liu, David Tao, Chloe Thornton, Tim Green, Mimi Jasarevic, Sharon Lin, Victor Cotruta, Yi-Xuan Tan, Noah Fiedel, Hongkun Yu, Ed Chi, Alexander Neitz, Jens Heitkaemper, Anu Sinha, Denny Zhou, Yi Sun, Charbel Kaed, Brice Hulse, Swaroop Mishra, Maria Georgaki, Sneha Kudugunta, Clement Farabet, Izhak Shafran, Daniel Vlasic, Anton Tsitsulin, Rajagopal Ananthanarayanan, Alen Carin, Guolong Su, Pei Sun, Shashank V, Gabriel Carvajal, Josef Broder, Iulia Comsa, Alena Repina, William Wong, Warren Weilun Chen, Peter Hawkins, Egor Filonov, Lucia Loher, Christoph Hirnschall, Weiyi Wang, Jingchen Ye, Andrea Burns, Hardie Cate, Diana Gage Wright, Federico Piccinini, Lei Zhang, Chu-Cheng Lin, Ionel Gog, Yana Kulizhskaya, Ashwin Sreevatsa, Shuang Song, Luis C. Cobo, Anand Iyer, Chetan Tekur, Guillermo Garrido, Zhuyun Xiao, Rupert Kemp, Huaixiu Steven Zheng, Hui Li, Ananth Agarwal, Christel Ngani, Kati Goshvadi, Rebeca Santamaria-Fernandez, Wojciech Fica, Xinyun Chen, Chris Gorgolewski, Sean Sun, Roopal Garg, Xinyu Ye, S. M. Ali Eslami, Nan Hua, Jon Simon, Pratik Joshi, Yelin Kim, Ian Tenney, Sahitya Potluri, Lam Nguyen Thiet, Quan Yuan, Florian Luisier, Alexandra Chronopoulou, Salvatore Scellato, Praveen Srinivasan, Minmin Chen, Vinod Koverkathu, Valentin Dalibard, Yaming Xu, Brennan Saeta, Keith Anderson, Thibault Sellam, Nick Fernando, Fantine Huot, Junehyuk Jung, Mani Varadarajan, Michael Quinn, Amit Raul, Maigo Le, Ruslan Habalov, Jon Clark, Komal Jalan, Kalesha Bullard, Achintya Singhal, Thang Luong, Boyu Wang, Sujeevan Rajayogam, Julian Eisenschlos, Johnson Jia, Daniel Finchelstein, Alex Yakubovich, Daniel Balle, Michael Fink, Sameer Agarwal, Jing Li, Dj Dvijotham, Shalini Pal, Kai Kang, Jaclyn Konzelmann, Jennifer Beattie, Olivier Dousse, Diane Wu, Remi Crocker, Chen Elkind, Siddhartha Reddy Jonnalagadda, Jong Lee, Dan Holtmann-Rice, Krystal Kallarackal, Rosanne Liu, Denis Vnukov, Neera Vats, Luca Invernizzi, Mohsen Jafari, Huanjie Zhou, Lilly Taylor, Jennifer Prendki, Marcus Wu, Tom Eccles, Tianqi Liu, Kavya Kopparapu, Francoise Beaufays, Christof Angermueller, Andreea Marzoca, Shourya Sarcar, Hilal Dib, Jeff Stanway, Frank Perbet, Nejc Trdin, Rachel Sterneck, Andrey Khorlin, Dinghua Li, Xihui Wu, Sonam Goenka, David Madras, Sasha Goldshtein, Willi Gierke, Tong Zhou, Yaxin Liu, Yannie Liang, Anais White, Yunjie Li, Shreya Singh, Sanaz Bahargam, Mark Epstein, Sujoy Basu, Li Lao, Adnan Ozturel, Carl Crous, Alex Zhai, Han Lu, Zora Tung, Neeraj Gaur, Alanna Walton, Lucas Dixon, Ming Zhang, Amir Globerson, Grant Uy, Andrew Bolt, Olivia Wiles, Milad Nasr, Ilia Shumailov, Marco Selvi, Francesco Piccinno, Ricardo Aguilar, Sara McCarthy, Misha Khalman, Mrinal Shukla, Vlado Galic, John Carpenter, Kevin Villela, Haibin Zhang, Harry Richardson, James Martens, Matko Bosnjak, Shreyas Rammohan Belle, Jeff Seibert, Mahmoud Alnahlawi, Brian McWilliams, Sankalp Singh, Annie Louis, Wen Ding, Dan Popovici, Lenin Simicich, Laura Knight, Pulkit Mehta, Nishesh Gupta, Chongyang Shi, Saaber Fatehi, Jovana Mitrovic, Alex Grills, Joseph Pagadora, Dessie Petrova, Danielle Eisenbud, Zhishuai Zhang, Damion Yates, Bhavishya Mittal, Nilesh Tripuraneni, Yannis Assael, Thomas Brovelli, Prateek Jain, Mihajlo Velimirovic, Canfer Akbulut, Jiaqi Mu, Wolfgang Macherey, Ravin Kumar, Jun Xu, Haroon Qureshi, Gheorghe Comanici, Jeremy Wiesner, Zhitao Gong, Anton Ruddock, Matthias Bauer, Nick Felt, Anirudh GP, Anurag Arnab, Dustin Zelle, Jonas Rothfuss, Bill Rosgen, Ashish Shenoy, Bryan Seybold, Xinjian Li, Jayaram Mudigonda, Goker Erdogan, Jiawei Xia, Jiri Simsa, Andrea Michi, Yi Yao, Christopher Yew, Steven Kan, Isaac Caswell, Carey Radebaugh, Andre Elisseeff, Pedro Valenzuela, Kay McKinney, Kim Paterson, Albert Cui, Eri Latorre-Chimoto, Solomon Kim, William Zeng, Ken Durden, Priya Ponnapalli, Tiberiu Sosea, Christopher A. Choquette-Choo, James Manyika, Brona Robenek, Harsha Vashisht, Sebastien Pereira, Hoi Lam, Marko Velic, Denese Owusu-Afriyie, Katherine Lee, Tolga Bolukbasi, Alicia Parrish, Shawn Lu, Jane Park, Balaji Venkatraman, Alice Talbert, Lambert Rosique, Yuchung Cheng, Andrei Sozanschi, Adam Paszke, Praveen Kumar, Jessica Austin, Lu Li, Khalid Salama, Wooyeol Kim, Nandita Dukkipati, Anthony Baryshnikov, Christos Kaplanis, XiangHai Sheng, Yuri Chervonyi, Caglar Unlu, Diego de Las Casas, Harry Askham, Kathryn Tunyasuvunakool, Felix Gimeno, Siim Poder, Chester Kwak, Matt Miecnikowski, Vahab Mirrokni, Alek Dimitriev, Aaron Parisi, Dangyi Liu, Tomy Tsai, Toby Shevlane, Christina Kouridi, Drew Garmon, Adrian Goedeckemeyer, Adam R. Brown, Anitha Vijayakumar, Ali Elqursh, Sadegh Jazayeri, Jin Huang, Sara Mc Carthy, Jay Hoover, Lucy Kim, Sandeep Kumar, Wei Chen, Courtney Biles, Garrett Bingham, Evan Rosen, Lisa Wang, Qijun Tan, David Engel, Francesco Pongetti, Cesare Dario de, Dongseong Hwang, Lily Yu, Jennifer Pullman, Srini Narayanan, Kyle Levin, Siddharth Gopal, Megan Li, Asaf Aharoni, Trieu Trinh, Jessica Lo, Norman Casagrande, Roopali Vij, Loic Matthey, Bramandia Ramadhana, Austin Matthews, CJ Carey, Matthew Johnson, Kremena Goranova, Rohin Shah, Shereen Ashraf, Kingshuk Dasgupta, Rasmus Larsen, Yicheng Wang, Manish Reddy Vuyyuru, Chong Jiang, Joana Ijazi, Kazuki Osawa, Celine Smith, Ramya Sree Boppana, Taylan Bilal, Yuma Koizumi, Ying Xu, Yasemin Altun, Nir Shabat, Ben Bariach, Alex Korchemniy, Kiam Choo, Olaf Ronneberger, Chimezie Iwuanyanwu, Shubin Zhao, David Soergel, Cho-Jui Hsieh, Irene Cai, Shariq Iqbal, Martin Sundermeyer, Zhe Chen, Elie Bursztein, Chaitanya Malaviya, Fadi Biadsy, Prakash Shroff, Inderjit Dhillon, Tejasi Latkar, Chris Dyer, Hannah Forbes, Massimo Nicosia, Vitaly Nikolaev, Somer Greene, Marin Georgiev, Pidong Wang, Nina Martin, Hanie Sedghi, John Zhang, Praseem Banzal, Doug Fritz, Vikram Rao, Xuezhi Wang, Jiageng Zhang, Viorica Patraucean, Dayou Du, Igor Mordatch, Ivan Jurin, Lewis Liu, Ayush Dubey, Abhi Mohan, Janek Nowakowski, Vlad-Doru Ion, Nan Wei, Reiko Tojo, Maria Abi Raad, Drew A. Hudson, Vaishakh Keshava, Shubham Agrawal, Kevin Ramirez, Zhichun Wu, Hoang Nguyen, Ji Liu, Madhavi Sewak, Bryce Petrini, DongHyun Choi, Ivan Philips, Ziyue Wang, Ioana Bica, Ankush Garg, Jarek Wilkiewicz, Priyanka Agrawal, Xiaowei Li, Danhao Guo, Emily Xue, Naseer Shaik, Andrew Leach, Sadh MNM Khan, Julia Wiesinger, Sammy Jerome, Abhishek Chakladar, Alek Wenjiao Wang, Tina Ornduff, Folake Abu, Alireza Ghaffarkhah, Marcus Wainwright, Mario Cortes, Frederick Liu, Joshua Maynez, Slav Petrov, Yonghui Wu, Demis Hassabis, Koray Kavukcuoglu, Jeffrey Dean, Oriol Vinyals",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05530"" target=""_blank"">2403.05530</a>",,2024-12-11
Uplift Modeling for Target User Attacks on Recommender Systems,"Wenjie Wang, Changsheng Wang, Fuli Feng, Wentao Shi, Daizong Ding, Tat-Seng Chua",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02692"" target=""_blank"">2403.02692</a>",,2024-12-11
Prepared for the Worst: A Learning-Based Adversarial Attack for Resilience Analysis of the ICP Algorithm,"Ziyu Zhang, Johann Laconte, Daniil Lisus, Timothy D. Barfoot",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05666"" target=""_blank"">2403.05666</a>",,2024-12-11
Adversarial Sparse Teacher: Defense Against Distillation-Based Model Stealing Attacks Using Adversarial Examples,"Eda Yilmaz, Hacer Yalim Keles",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05181"" target=""_blank"">2403.05181</a>",,2024-12-11
Improving the Robustness of Object Detection and Classification AI models against Adversarial Patch Attacks,"Roie Kazoom, Raz Birman, Ofer Hadar",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12988"" target=""_blank"">2403.12988</a>",,2024-12-11
COMMIT: Certifying Robustness of Multi-Sensor Fusion Systems against Semantic Attacks,"Zijian Huang, Wenda Chu, Linyi Li, Chejian Xu, Bo Li",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02329"" target=""_blank"">2403.02329</a>",,2024-12-11
Inf2Guard: An Information-Theoretic Framework for Learning Privacy-Preserving Representations against Inference Attacks,"Sayedeh Leila Noorbakhsh, Binghui Zhang, Yuan Hong, Binghui Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02116"" target=""_blank"">2403.02116</a>",,2024-12-11
BSDP: Brain-inspired Streaming Dual-level Perturbations for Online Open World Object Detection,"Yu Chen, Liyan Ma, Liping Jing, Jian Yu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02637"" target=""_blank"">2403.02637</a>",,2024-12-11
Mirage: Defense against CrossPath Attacks in Software Defined Networks,"Shariq Murtuza, Krishna Asawa",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02172"" target=""_blank"">2403.02172</a>",,2024-12-11
Bayesian Uncertainty Estimation by Hamiltonian Monte Carlo: Applications to Cardiac MRI Segmentation,"Yidong Zhao, Joao Tourais, Iain Pierce, Christian Nitsche, Thomas A. Treibel, Sebastian WeingÃ¤rtner, Artur M. Schweidtmann, Qian Tao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02311"" target=""_blank"">2403.02311</a>",,2024-12-11
GuardT2I: Defending Text-to-Image Models from Adversarial Prompts,"Yijun Yang, Ruiyuan Gao, Xiao Yang, Jianyuan Zhong, Qiang Xu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01446"" target=""_blank"">2403.01446</a>","<a href=""https://github.com/cure-lab/GuardT2I"" target=""_blank"">cure-lab</a>",2024-12-11
SAR-AE-SFP: SAR Imagery Adversarial Example in Real Physics domain with Target Scattering Feature Parameters,"Jiahao Cui, Jiale Duan, Binyan Luo, Hang Cao, Wang Guo, Haifeng Li",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01210"" target=""_blank"">2403.01210</a>",,2024-12-11
Inexact Unlearning Needs More Careful Evaluations to Avoid a False Sense of Privacy,"Jamie Hayes, Ilia Shumailov, Eleni Triantafillou, Amr Khalifa, Nicolas Papernot",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01218"" target=""_blank"">2403.01218</a>",,2024-12-11
Breaking Down the Defenses: A Comparative Survey of Attacks on Large Language Models,"Arijit Ghosh Chowdhury, Md Mofijul Islam, Vaibhav Kumar, Faysal Hossain Shezan, Vaibhav Kumar, Vinija Jain, Aman Chadha",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04786"" target=""_blank"">2403.04786</a>",,2024-12-11
Adversarial Testing for Visual Grounding via Image-Aware Property Reduction,"Zhiyuan Chang, Mingyang Li, Junjie Wang, Cheng Li, Boyu Wu, Fanjiang Xu, Qing Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01118"" target=""_blank"">2403.01118</a>",,2024-12-11
Query Recovery from Easy to Hard: Jigsaw Attack against SSE,"Hao Nie, Wei Wang, Peng Xu, Xianglong Zhang, Laurence T. Yang, Kaitai Liang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01155"" target=""_blank"">2403.01155</a>",,2024-12-11
Accelerating Greedy Coordinate Gradient via Probe Sampling,"Yiran Zhao, Wenyue Zheng, Tianle Cai, Xuan Long Do, Kenji Kawaguchi, Anirudh Goyal, Michael Shieh",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01251"" target=""_blank"">2403.01251</a>",,2024-12-11
Robust Deep Reinforcement Learning Through Adversarial Attacks and Training : A Survey,"Lucas Schott, Josephine Delas, Hatem Hajri, Elies Gherbi, Reda Yaich, Nora Boulahia-Cuppens, Frederic Cuppens, Sylvain Lamprier",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.00420"" target=""_blank"">2403.00420</a>",,2024-12-11
Resilience of Entropy Model in Distributed Neural Networks,"Milin Zhang, Mohammad Abdi, Shahriar Rifat, Francesco Restuccia",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.00942"" target=""_blank"">2403.00942</a>",,2024-12-11
Attacking Delay-based PUFs with Minimal Adversary Model,"Hongming Fei, Owen Millwood, Prosanta Gope, Jack Miskelly, Biplab Sikdar",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.00464"" target=""_blank"">2403.00464</a>",,2024-12-11
On Robustness and Generalization of ML-Based Congestion Predictors to Valid and Imperceptible Perturbations,"Chester Holtz, Yucheng Wang, Chung-Kuan Cheng, Bill Lin",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.00103"" target=""_blank"">2403.00103</a>",,2024-12-11
Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes,"Xiaomeng Hu, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.00867"" target=""_blank"">2403.00867</a>",,2024-12-11
Evaluating Robustness of Generative Search Engine on Adversarial Factual Questions,"Xuming Hu, Xiaochuan Li, Junzhe Chen, Yinghui Li, Yangning Li, Xiaoguang Li, Yasheng Wang, Qun Liu, Lijie Wen, Philip S. Yu, Zhijiang Guo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12077"" target=""_blank"">2403.12077</a>",,2024-12-11
Adversarially Robust Deepfake Detection via Adversarial Feature Similarity Learning,Sarwar Khan,arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.08806"" target=""_blank"">2403.08806</a>",,2024-12-11
Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A Pilot Study,"Chenguang Wang, Ruoxi Jia, Xin Liu, Dawn Song",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10499"" target=""_blank"">2403.10499</a>",,2024-12-11
Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models,"Zachary Horvitz, Jingru Chen, Rahul Aditya, Harshvardhan Srivastava, Robert West, Zhou Yu, Kathleen McKeown",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.00794"" target=""_blank"">2403.00794</a>",,2024-12-11
Adversarial Nibbler: An Open Red-Teaming Method for Identifying Diverse Harms in Text-to-Image Generation,"Jessica Quaye, Alicia Parrish, Oana Inel, Charvi Rastogi, Hannah Rose Kirk, Minsuk Kahng, Liemt Erin van, Max Bartolo, Jess Tsang, Justin White, Nathan Clement, Rafael Mosquera, Juan Ciro, Vijay Janapa Reddi, Lora Aroyo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12075"" target=""_blank"">2403.12075</a>",,2024-12-11
One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models,"Lin Li, Haoyan Guan, Jianing Qiu, Michael Spratling",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01849"" target=""_blank"">2403.01849</a>","<a href=""https://github.com/TreeLLi/APT"" target=""_blank"">TreeLLi</a>",2024-12-11
Robustness Bounds on the Successful Adversarial Examples: Theory and Practice,"Hiroaki Maeshima, Akira Otsuka",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01896"" target=""_blank"">2403.01896</a>",,2024-12-11
XAI-Based Detection of Adversarial Attacks on Deepfake Detectors,"Ben Pinhasov, Raz Lapid, Rony Ohayon, Moshe Sipper, Yehudit Aperstein",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02955"" target=""_blank"">2403.02955</a>",,2024-12-11
Improving Adversarial Training using Vulnerability-Aware Perturbation Budget,"Olukorede Fakorede, Modeste Atsague, Jin Tian",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04070"" target=""_blank"">2403.04070</a>",,2024-12-11
EVD4UAV: An Altitude-Sensitive Benchmark to Evade Vehicle Detection in UAV,"Huiming Sun, Jiacheng Guo, Zibo Meng, Tianyun Zhang, Jianwu Fang, Yuewei Lin, Hongkai Yu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05422"" target=""_blank"">2403.05422</a>",,2024-12-11
The Impact of Quantization on the Robustness of Transformer-based Text Classifiers,"Seyed Parsa Neshaei, Yasaman Boreshban, Gholamreza Ghassem-Sani, Seyed Abolghasem Mirroshandel",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05365"" target=""_blank"">2403.05365</a>",,2024-12-11
Speech Robust Bench: A Robustness Benchmark For Speech Recognition,"Muhammad A. Shah, David Solans Noguero, Mikko A. Heikkila, Bhiksha Raj, Nicolas Kourtellis",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07937"" target=""_blank"">2403.07937</a>",,2024-12-11
Defending Against Unforeseen Failure Modes with Latent Adversarial Training,"Stephen Casper, Lennart Schulze, Oam Patel, Dylan Hadfield-Menell",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05030"" target=""_blank"">2403.05030</a>",,2024-12-11
Fooling Neural Networks for Motion Forecasting via Adversarial Attacks,"Edgar Medina, Leyong Loh",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04954"" target=""_blank"">2403.04954</a>",,2024-12-11
Automatic and Universal Prompt Injection Attacks against Large Language Models,"Xiaogeng Liu, Zhiyuan Yu, Yizhe Zhang, Ning Zhang, Chaowei Xiao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04957"" target=""_blank"">2403.04957</a>",,2024-12-11
ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes,"Hashmat Shadab Malik, Muhammad Huzaifa, Muzammal Naseer, Salman Khan, Fahad Shahbaz Khan",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04701"" target=""_blank"">2403.04701</a>","<a href=""https://github.com/Muhammad-Huzaifaa/ObjectCompose"" target=""_blank"">Muhammad-Huzaifaa</a>",2024-12-11
Cell reprogramming design by transfer learning of functional transcriptional networks,"Thomas P. Wytock, Adilson E. Motter",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04837"" target=""_blank"">2403.04837</a>",,2024-12-11
Towards Robustness Analysis of E-Commerce Ranking System,"Ningfei Wang, Yupin Huang, Han Cheng, Jiri Gesi, Xiaojie Wang, Vivek Mittal",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04257"" target=""_blank"">2403.04257</a>",,2024-12-11
Adversarial Infrared Geometry: Using Geometry to Perform Adversarial Attack against Infrared Pedestrian Detectors,Kalibinuer Tiliwalidi,arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.03674"" target=""_blank"">2403.03674</a>",,2024-12-11
Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability,"Rajdeep Haldar, Yue Xing, Qifan Song",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.03967"" target=""_blank"">2403.03967</a>",,2024-12-11
InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents,"Qiusi Zhan, Zhixiang Liang, Zifan Ying, Daniel Kang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02691"" target=""_blank"">2403.02691</a>","<a href=""https://github.com/uiuc-kang-lab/InjecAgent"" target=""_blank"">uiuc-kang-lab</a>",2024-12-11
Belief-Enriched Pessimistic Q-Learning against Adversarial State Perturbations,"Xiaolin Sun, Zizhan Zheng",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04050"" target=""_blank"">2403.04050</a>","<a href=""https://github.com/SliencerX/Belief-enriched-robust-Q-learning"" target=""_blank"">SliencerX</a>",2024-12-11
On the Effectiveness of Distillation in Mitigating Backdoors in Pre-trained Encoder,"Tingxu Han, Shenghan Huang, Ziqi Ding, Weisong Sun, Yebo Feng, Chunrong Fang, Jun Li, Hanwei Qian, Cong Wu, Quanjun Zhang, Yang Liu, Zhenyu Chen",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.03846"" target=""_blank"">2403.03846</a>",,2024-12-11
Verified Training for Counterfactual Explanation Robustness under Data Shift,"Anna P. Meyer, Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.03773"" target=""_blank"">2403.03773</a>",,2024-12-11
Towards Robust Federated Learning via Logits Calibration on Non-IID Data,"Yu Qiao, Apurba Adhikary, Chaoning Zhang, Choong Seon Hong",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02803"" target=""_blank"">2403.02803</a>",,2024-12-11
Mitigating Label Flipping Attacks in Malicious URL Detectors Using Ensemble Trees,"Ehsan Nowroozi, Nada Jadalla, Samaneh Ghelichkhani, Alireza Jolfaei",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02995"" target=""_blank"">2403.02995</a>",,2024-12-11
Minimum Topology Attacks for Graph Neural Networks,"Mengmei Zhang, Xiao Wang, Chuan Shi, Lingjuan Lyu, Tianchi Yang, Junping Du",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02723"" target=""_blank"">2403.02723</a>",,2024-12-11
Federated Learning Under Attack: Exposing Vulnerabilities through Data Poisoning Attacks in Computer Networks,"Ehsan Nowroozi, Imran Haider, Rahim Taheri, Mauro Conti",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02983"" target=""_blank"">2403.02983</a>",,2024-12-11
A general approach to enhance the survivability of backdoor attacks by decision path coupling,"Yufei Zhao, Dingji Wang, Bihuan Chen, Ziqian Chen, Xin Peng",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02950"" target=""_blank"">2403.02950</a>",,2024-12-11
Robust Federated Learning Mitigates Client-side Training Data Distribution Inference Attacks,"Yichang Xu, Ming Yin, Minghong Fang, Neil Zhenqiang Gong",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.03149"" target=""_blank"">2403.03149</a>",,2024-12-11
FLGuard: Byzantine-Robust Federated Learning via Ensemble of Contrastive Models,"Younghan Lee, Yungi Cho, Woorim Han, Ho Bae, Yunheung Paek",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02846"" target=""_blank"">2403.02846</a>","<a href=""https://github.com/201younghanlee/FLGuard"" target=""_blank"">201younghanlee</a>",2024-12-11
"Not Just Change the Labels, Learn the Features: Watermarking Deep Neural Networks with Multi-View Data","Yuxuan Li, Sarthak Kumar Maharana, Yunhui Guo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10663"" target=""_blank"">2403.10663</a>",,2024-12-11
Cross-Lingual Transfer Robustness to Lower-Resource Languages on Adversarial Datasets,"Shadi Manafi, Nikhil Krishnaswamy",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.20056"" target=""_blank"">2403.20056</a>",,2024-12-11
Securing Federated Learning with Control-Flow Attestation: A Novel Framework for Enhanced Integrity and Resilience against Adversarial Attacks,Zahir Alsulaimawi,arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10005"" target=""_blank"">2403.10005</a>",,2024-12-11
Targeted Visualization of the Backbone of Encoder LLMs,"Isaac Roberts, Alexander Schulz, Luca Hermes, Barbara Hammer",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18872"" target=""_blank"">2403.18872</a>",,2024-12-11
Exploring LLMs as a Source of Targeted Synthetic Textual Data to Minimize High Confidence Misclassifications,"Philip Lippmann, Matthijs Spaan, Jie Yang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.17860"" target=""_blank"">2403.17860</a>",,2024-12-11
$\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on Prompt-based Language Models,"Yue Xu, Wenjie Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16432"" target=""_blank"">2403.16432</a>","<a href=""https://github.com/SavannahXu79/LinkPrompt"" target=""_blank"">SavannahXu79</a>",2024-12-11
Physical 3D Adversarial Attacks against Monocular Depth Estimation in Autonomous Driving,"Junhao Zheng, Chenhao Lin, Jiahao Sun, Zhengyu Zhao, Qian Li, Chao Shen",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.17301"" target=""_blank"">2403.17301</a>",,2024-12-11
The Anatomy of Adversarial Attacks: Concept-based XAI Dissection,"Georgii Mikriukov, Gesina Schwalbe, Franz Motzkus, Korinna Bade",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16782"" target=""_blank"">2403.16782</a>",,2024-12-11
DeepKnowledge: Generalisation-Driven Deep Learning Testing,"Sondess Missaoui, Simos Gerasimou, Nikolaos Matragkas",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16768"" target=""_blank"">2403.16768</a>",,2024-12-11
Revealing Vulnerabilities of Neural Networks in Parameter Learning and Defense Against Explanation-Aware Backdoors,"Md Abdul Kadir, GowthamKrishna Addluri, Daniel Sonntag",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16569"" target=""_blank"">2403.16569</a>",,2024-12-11
LOTUS: Evasive and Resilient Backdoor Attacks through Sub-Partitioning,"Siyuan Cheng, Guanhong Tao, Yingqi Liu, Guangyu Shen, Shengwei An, Shiwei Feng, Xiangzhe Xu, Kaiyuan Zhang, Shiqing Ma, Xiangyu Zhang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.17188"" target=""_blank"">2403.17188</a>","<a href=""https://github.com/Megum1/LOTUS"" target=""_blank"">Megum1</a>",2024-12-11
Model-less Is the Best Model: Generating Pure Code Implementations to Replace On-Device DL Models,"Mingyi Zhou, Xiang Gao, Pei Liu, John Grundy, Chunyang Chen, Xiao Chen, Li Li",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16479"" target=""_blank"">2403.16479</a>",,2024-12-11
Subspace Defense: Discarding Adversarial Perturbations by Learning a Subspace for Clean Signals,"Rui Zheng, Yuhao Zhou, Zhiheng Xi, Tao Gui, Qi Zhang, Xuanjing Huang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16176"" target=""_blank"">2403.16176</a>",,2024-12-11
Ensemble Adversarial Defense via Integration of Multiple Dispersed Low Curvature Models,"Kaikang Zhao, Xi Chen, Wei Huang, Liuxin Ding, Xianglong Kong, Fan Zhang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16405"" target=""_blank"">2403.16405</a>",,2024-12-11
Robust Diffusion Models for Adversarial Purification,"Guang Lin, Zerui Tao, Jianhai Zhang, Toshihisa Tanaka, Qibin Zhao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16067"" target=""_blank"">2403.16067</a>",,2024-12-11
Unlearning Backdoor Threats: Enhancing Backdoor Defense in Multimodal Contrastive Learning via Local Token Unlearning,"Siyuan Liang, Kuanrong Liu, Jiajun Gong, Jiawei Liang, Yuan Xun, Ee-Chien Chang, Xiaochun Cao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16257"" target=""_blank"">2403.16257</a>",,2024-12-11
Rumor Detection with a novel graph neural network approach,"Tianrui Liu, Qi Cai, Changxin Xu, Bo Hong, Fanghao Ni, Yuxin Qiao, Tsungwei Yang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16206"" target=""_blank"">2403.16206</a>",,2024-12-11
Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion,"Hossein Souri, Arpit Bansal, Hamid Kazemi, Liam Fowl, Aniruddha Saha, Jonas Geiping, Andrew Gordon Wilson, Rama Chellappa, Tom Goldstein, Micah Goldblum",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16365"" target=""_blank"">2403.16365</a>","<a href=""https://github.com/hsouri/GDP"" target=""_blank"">hsouri</a>",2024-12-11
A General and Efficient Federated Split Learning with Pre-trained Image Transformers for Heterogeneous Data,"Yifan Shi, Yuhui Zhang, Ziyue Huang, Xiaofeng Yang, Li Shen, Wei Chen, Xueqian Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16050"" target=""_blank"">2403.16050</a>",,2024-12-11
Towards Adversarial Robustness And Backdoor Mitigation in SSL,"Aryan Satpathy, Nilaksh Singh, Dhruva Rajwade, Somesh Kumar",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15918"" target=""_blank"">2403.15918</a>",,2024-12-11
Adversarial Defense Teacher for Cross-Domain Object Detection under Poor Visibility Conditions,"Kaiwen Wang, Yinzhe Shen, Martin Lauer",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15786"" target=""_blank"">2403.15786</a>",,2024-12-11
Robust optimization for adversarial learning with finite sample complexity guarantees,"AndrÃ© Bertolace, Konstatinos Gatsis, Kostas Margellos",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15207"" target=""_blank"">2403.15207</a>",,2024-12-11
A Transfer Attack to Image Watermarks,"Yuepeng Hu, Zhengyuan Jiang, Moyang Guo, Neil Gong",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15365"" target=""_blank"">2403.15365</a>",,2024-12-11
From Hardware Fingerprint to Access Token: Enhancing the Authentication on IoT Devices,"Yue Xiao, Yi He, Xiaoli Zhang, Qian Wang, Renjie Xie, Kun Sun, Ke Xu, Qi Li",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15271"" target=""_blank"">2403.15271</a>",,2024-12-11
Clean-image Backdoor Attacks,"Dazhong Rong, Guoyao Yu, Shuheng Shen, Xinyi Fu, Peng Qian, Jianhai Chen, Qinming He, Xing Fu, Weiqiang Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15010"" target=""_blank"">2403.15010</a>",,2024-12-11
Forward Learning for Gradient-based Black-box Saliency Map Generation,"Zeliang Zhang, Mingqian Feng, Jinyang Jiang, Rongyi Zhu, Yijie Peng, Chenliang Xu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15603"" target=""_blank"">2403.15603</a>",,2024-12-11
Diffusion Attack: Leveraging Stable Diffusion for Naturalistic Image Attacking,"Qianyu Guo, Jiaming Fu, Yawen Lu, Dongming Gan",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14778"" target=""_blank"">2403.14778</a>",,2024-12-11
Leak and Learn: An Attacker's Cookbook to Train Using Leaked Data from Federated Learning,"Joshua C. Zhao, Ahaan Dabholkar, Atul Sharma, Saurabh Bagchi",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18144"" target=""_blank"">2403.18144</a>",,2024-12-11
Optimization-based Prompt Injection Attack to LLM-as-a-Judge,"Jiawen Shi, Zenghui Yuan, Yinuo Liu, Yue Huang, Pan Zhou, Lichao Sun, Neil Zhenqiang Gong",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.17710"" target=""_blank"">2403.17710</a>",,2024-12-11
Reversible Jump Attack to Textual Classifiers with Modification Reduction,"Mingze Ni, Zhensu Sun, Wei Liu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14731"" target=""_blank"">2403.14731</a>",,2024-12-11
Boosting Adversarial Training via Fisher-Rao Norm-based Regularization,"Xiangyu Yin, Wenjie Ruan",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.17520"" target=""_blank"">2403.17520</a>","<a href=""https://github.com/TrustAI/LOAT"" target=""_blank"">TrustAI</a>",2024-12-11
The Impact of Prompts on Zero-Shot Detection of AI-Generated Text,"Kaito Taguchi, Yujie Gu, Kouichi Sakurai",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.20127"" target=""_blank"">2403.20127</a>","<a href=""https://github.com/kaito25atugich/Detector"" target=""_blank"">kaito25atugich</a>",2024-12-11
Towards Understanding Dual BN In Hybrid Adversarial Training,"Chenshuang Zhang, Chaoning Zhang, Kang Zhang, Axi Niu, Junmo Kim, In So Kweon",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19150"" target=""_blank"">2403.19150</a>",,2024-12-11
"Improving Adversarial Data Collection by Supporting Annotators: Lessons from GAHD, a German Hate Speech Dataset","Janis Goldzycher, Paul RÃ¶ttger, Gerold Schneider",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19559"" target=""_blank"">2403.19559</a>","<a href=""https://github.com/jagol/gahd"" target=""_blank"">jagol</a>",2024-12-11
On the Robustness of LDP Protocols for Numerical Attributes under Data Poisoning Attacks,"Xiaoguang Li, Zitao Li, Ninghui Li, Wenhai Sun",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19510"" target=""_blank"">2403.19510</a>",,2024-12-11
MedBN: Robust Test-Time Adaptation against Malicious Test Samples,"Hyejin Park, Jeongyeon Hwang, Sunung Mun, Sangdon Park, Jungseul Ok",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19326"" target=""_blank"">2403.19326</a>",,2024-12-11
Interactive Trimming against Evasive Online Data Manipulation Attacks: A Game-Theoretic Approach,"Yue Fu, Qingqing Ye, Rong Du, Haibo Hu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10313"" target=""_blank"">2403.10313</a>",,2024-12-11
Imperceptible Protection against Style Imitation from Diffusion Models,"Namhyuk Ahn, Wonhyuk Ahn, KiYoon Yoo, Daesik Kim, Seung-Hun Nam",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19254"" target=""_blank"">2403.19254</a>",,2024-12-11
Benchmarking the Robustness of Temporal Action Detection Models Against Temporal Corruptions,"Runhao Zeng, Xiaoyong Chen, Jiaming Liang, Huisi Wu, Guangzhong Cao, Yong Guo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.20254"" target=""_blank"">2403.20254</a>","<a href=""https://github.com/Alvin-Zeng/temporal-robustness-benchmark"" target=""_blank"">Alvin-Zeng</a>",2024-12-11
Uncertainty-Aware SAR ATR: Defending Against Adversarial Attacks via Bayesian Neural Networks,"Tian Ye, Rajgopal Kannan, Viktor Prasanna, Carl Busart",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18318"" target=""_blank"">2403.18318</a>",,2024-12-11
CosalPure: Learning Concept from Group Images for Robust Co-Saliency Detection,"Jiayi Zhu, Qing Guo, Felix Juefei-Xu, Yihao Huang, Yang Liu, Geguang Pu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18554"" target=""_blank"">2403.18554</a>",,2024-12-11
MMCert: Provable Defense against Adversarial Attacks to Multi-modal Models,"Yanting Wang, Hongye Fu, Wei Zou, Jinyuan Jia",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19080"" target=""_blank"">2403.19080</a>",,2024-12-11
Bayesian Learned Models Can Detect Adversarial Malware For Free,"Bao Gia Doan, Dang Quang Nguyen, Paul Montague, Tamas Abraham, Vel Olivier De, Seyit Camtepe, Salil S. Kanhere, Ehsan Abbasnejad, Damith C. Ranasinghe",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18309"" target=""_blank"">2403.18309</a>",,2024-12-11
MisGUIDE : Defense Against Data-Free Deep Learning Model Extraction,"Mahendra Gurve, Sankar Behera, Satyadev Ahlawat, Yamuna Prasad",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18580"" target=""_blank"">2403.18580</a>",,2024-12-11
Towards Sustainable SecureML: Quantifying Carbon Footprint of Adversarial Machine Learning,"Syed Mhamudul Hasan, Abdur R. Shahid, Ahmed Imteaj",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19009"" target=""_blank"">2403.19009</a>",,2024-12-11
Deep Learning for Robust and Explainable Models in Computer Vision,Mohammadreza Amirian,arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18674"" target=""_blank"">2403.18674</a>",,2024-12-11
SemRoDe: Macro Adversarial Training to Learn Representations That are Robust to Word-Level Attacks,"Brian Formento, Wenjie Feng, Chuan Sheng Foo, Luu Anh Tuan, See-Kiong Ng",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18423"" target=""_blank"">2403.18423</a>",,2024-12-11
Vulnerability Detection with Code Language Models: How Far Are We? (26%),"Yangruibo Ding, Yanjun Fu, Omniyyah Ibrahim, Chawin Sitawarin, Xinyun Chen, Basel Alomair, David Wagner, Baishakhi Ray, Yizheng Chen",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18624"" target=""_blank"">2403.18624</a>",,2024-12-11
Spikewhisper: Temporal Spike Backdoor Attacks on Federated Neuromorphic Learning over Low-power Devices,"Hanqing Fu, Gaolei Li, Jun Wu, Jianhua Li, Xi Lin, Kai Zhou, Yuchen Liu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18607"" target=""_blank"">2403.18607</a>",,2024-12-11
"Robustness and Visual Explanation for Black Box Image, Video, and ECG Signal Classification with Reinforcement Learning","Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad Mousavi, Vineet Gundecha, Avisek Naug, Sahand Ghorbanpour",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18985"" target=""_blank"">2403.18985</a>",,2024-12-11
The Impact of Uniform Inputs on Activation Sparsity and Energy-Latency Attacks in Computer Vision,"Andreas MÃ¼ller, Erwin Quiring",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18587"" target=""_blank"">2403.18587</a>",,2024-12-11
Fact Checking Beyond Training Set,"Payam Karisani, Heng Ji",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18671"" target=""_blank"">2403.18671</a>",,2024-12-11
BAM: Box Abstraction Monitors for Real-time OoD Detection in Object Detection,"Changshun Wu, Weicheng He, Chih-Hong Cheng, Xiaowei Huang, Saddek Bensalem",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18373"" target=""_blank"">2403.18373</a>",,2024-12-11
FaultGuard: A Generative Approach to Resilient Fault Prediction in Smart Electrical Grids,"Emad Efatinasab, Francesco Marchiori, Alessandro Brighente, Mirco Rampazzo, Mauro Conti",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.17494"" target=""_blank"">2403.17494</a>",,2024-12-11
Few-Shot Adversarial Prompt Learning on Vision-Language Models,"Yiwei Zhou, Xiaobo Xia, Zhiwei Lin, Bo Han, Tongliang Liu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14774"" target=""_blank"">2403.14774</a>",,2024-12-11
DataCook: Crafting Anti-Adversarial Examples for Healthcare Data Copyright Protection,"Sihan Shang, Jiancheng Yang, Zhenglong Sun, Pascal Fua",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.17755"" target=""_blank"">2403.17755</a>","<a href=""https://github.com/MedMNIST/DataCook"" target=""_blank"">MedMNIST</a>",2024-12-11
Improving Robustness to Model Inversion Attacks via Sparse Coding Architectures,"Sayanton V. Dibbo, Adam Breuer, Juston Moore, Michael Teti",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14772"" target=""_blank"">2403.14772</a>",,2024-12-11
Problem space structural adversarial attacks for Network Intrusion Detection Systems based on Graph Neural Networks,"Andrea Venturi, Dario Stabili, Mirco Marchetti",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11830"" target=""_blank"">2403.11830</a>",,2024-12-11
SSAP: A Shape-Sensitive Adversarial Patch for Comprehensive Disruption of Monocular Depth Estimation in Autonomous Navigation Applications,"Amira Guesmi, Muhammad Abdullah Hanif, Ihsen Alouani, Bassem Ouni, Muhammad Shafique",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11515"" target=""_blank"">2403.11515</a>",,2024-12-11
Towards Adversarially Robust Dataset Distillation by Curvature Regularization,"Eric Xue, Yijiang Li, Haoyang Liu, Yifan Shen, Haohan Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10045"" target=""_blank"">2403.10045</a>",,2024-12-11
Electioneering the Network: Dynamic Multi-Step Adversarial Attacks for Community Canvassing,"Saurabh Sharma, Ambuj SIngh",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12399"" target=""_blank"">2403.12399</a>","<a href=""https://github.com/saurabhsharma1993/mac"" target=""_blank"">saurabhsharma1993</a>",2024-12-11
Advancing Time Series Classification with Multimodal Language Modeling,"Mingyue Cheng, Yiheng Chen, Qi Liu, Zhiding Liu, Yucong Luo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12371"" target=""_blank"">2403.12371</a>",,2024-12-11
Defense Against Adversarial Attacks on No-Reference Image Quality Models with Gradient Norm Regularization,"Yujia Liu, Chenxi Yang, Dingquan Li, Jianhao Ding, Tingting Jiang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11397"" target=""_blank"">2403.11397</a>",,2024-12-11
A Modified Word Saliency-Based Adversarial Attack on Text Classification Models,"Hetvi Waghela, Sneha Rakshit, Jaydip Sen",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11297"" target=""_blank"">2403.11297</a>",,2024-12-11
Robust Overfitting Does Matter: Test-Time Adversarial Purification With FGSM,"Linyu Tang, Lei Zhang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11448"" target=""_blank"">2403.11448</a>",,2024-12-11
Forging the Forger: An Attempt to Improve Authorship Verification via Data Augmentation,"Silvia Corbara, Alejandro Moreo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11265"" target=""_blank"">2403.11265</a>",,2024-12-11
RobustSentEmbed: Robust Sentence Embeddings Using Adversarial Self-Supervised Contrastive Learning,"Javad Rafiei Asl, Prajwal Panzade, Eduardo Blanco, Daniel Takabi, Zhipeng Cai",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11082"" target=""_blank"">2403.11082</a>",,2024-12-11
COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits,"Mintong Kang, Nezihe Merve GÃ¼rel, Linyi Li, Bo Li",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11348"" target=""_blank"">2403.11348</a>",,2024-12-11
A Dual-Tier Adaptive One-Class Classification IDS for Emerging Cyberthreats,"Md. Ashraf Uddin, Sunil Aryal, Mohamed Reda Bouadjenek, Muna Al-Hawawreh, Md. Alamin Talukder",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13010"" target=""_blank"">2403.13010</a>",,2024-12-11
CBR - Boosting Adaptive Classification By Retrieval of Encrypted Network Traffic with Out-of-distribution,"Amir Lukach, Ran Dubin, Amit Dvir, Chen Hajaj",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11206"" target=""_blank"">2403.11206</a>",,2024-12-11
Pencil: Private and Extensible Collaborative Learning without the Non-Colluding Assumption,"Xuanqi Liu, Zhuotao Liu, Qi Li, Ke Xu, Mingwei Xu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11166"" target=""_blank"">2403.11166</a>",,2024-12-11
Securely Fine-tuning Pre-trained Encoders Against Adversarial Examples,"Ziqi Zhou, Minghui Li, Wei Liu, Shengshan Hu, Yechao Zhang, Wei Wan, Lulu Xue, Leo Yu Zhang, Dezhong Yang, Hai Jin",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10801"" target=""_blank"">2403.10801</a>",,2024-12-11
Understanding Robustness of Visual State Space Models for Image Classification,"Chengbin Du, Yanxi Li, Chang Xu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10935"" target=""_blank"">2403.10935</a>",,2024-12-11
Revisiting Adversarial Training under Long-Tailed Distributions,"Xinli Yue, Ningping Mou, Qian Wang, Lingchen Zhao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10073"" target=""_blank"">2403.10073</a>","<a href=""https://github.com/NISPLab/AT-BSL"" target=""_blank"">NISPLab</a>",2024-12-11
Improving Adversarial Transferability of Visual-Language Pre-training Models through Collaborative Multimodal Interaction,"Jiyuan Fu, Zhaoyu Chen, Kaixun Jiang, Haijing Guo, Jiafeng Wang, Shuyong Gao, Wenqiang Zhang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10883"" target=""_blank"">2403.10883</a>",,2024-12-11
Edge Private Graph Neural Networks with Singular Value Perturbation,"Tingting Tang, Yue Niu, Salman Avestimehr, Murali Annavaram",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10995"" target=""_blank"">2403.10995</a>",,2024-12-11
Adversary-Robust Graph-Based Learning of WSIs,"Saba Heidari Gheshlaghi, Milan Aryal, Nasim Yahyasoltani, Masoud Ganji",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14489"" target=""_blank"">2403.14489</a>",,2024-12-11
Benchmarking Adversarial Robustness of Image Shadow Removal with Shadow-adaptive Attacks,"Chong Wang, Yi Yu, Lanqing Guo, Bihan Wen",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10076"" target=""_blank"">2403.10076</a>",,2024-12-11
Introducing Adaptive Continuous Adversarial Training (ACAT) to Enhance ML Robustness,"Mohamed elShehaby, Aditya Kotha, Ashraf Matrawy",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10461"" target=""_blank"">2403.10461</a>",,2024-12-11
Time-Frequency Jointed Imperceptible Adversarial Attack to Brainprint Recognition with Deep Learning Models,"Hangjie Yi, Yuhang Ming, Dongjun Liu, Wanzeng Kong",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10021"" target=""_blank"">2403.10021</a>",,2024-12-11
Towards Non-Adversarial Algorithmic Recourse,"Tobias Leemann, Martin Pawelczyk, Bardh Prenkaj, Gjergji Kasneci",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10330"" target=""_blank"">2403.10330</a>",,2024-12-11
Impart: An Imperceptible and Effective Label-Specific Backdoor Attack,"Jingke Zhao, Zan Wang, Yongwei Wang, Lanjun Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13017"" target=""_blank"">2403.13017</a>",,2024-12-11
Hierarchical Classification for Intrusion Detection System: Effective Design and Empirical Analysis,"Md. Ashraf Uddin, Sunil Aryal, Mohamed Reda Bouadjenek, Muna Al-Hawawreh, Md. Alamin Talukder",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13013"" target=""_blank"">2403.13013</a>",,2024-12-11
Invisible Backdoor Attack Through Singular Value Decomposition,"Wenmin Chen, Xiaowei Xu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13018"" target=""_blank"">2403.13018</a>",,2024-12-11
"Threats, Attacks, and Defenses in Machine Unlearning: A Survey","Ziyao Liu, Huanyi Ye, Chen Chen, Kwok-Yan Lam",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13682"" target=""_blank"">2403.13682</a>",,2024-12-11
DD-RobustBench: An Adversarial Robustness Benchmark for Dataset Distillation,"Yifan Wu, Jiawei Du, Ping Liu, Yuewei Lin, Wenqing Cheng, Wei Xu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13322"" target=""_blank"">2403.13322</a>",,2024-12-11
Adversarial Attacks and Defenses in Automated Control Systems: A Comprehensive Benchmark,"Vitaliy Pozdnyakov, Aleksandr Kovalenko, Ilya Makarov, Mikhail Drobyshevskiy, Kirill Lukyanov",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13502"" target=""_blank"">2403.13502</a>",,2024-12-11
FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based LLMs,"Jinmin Li, Kuofeng Gao, Yang Bai, Jingyun Zhang, Shu-tao Xia, Yisen Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13507"" target=""_blank"">2403.13507</a>","<a href=""https://github.com/THU-Kingmin/FMM-Attack"" target=""_blank"">THU-Kingmin</a>",2024-12-11
Safeguarding Medical Image Segmentation Datasets against Unauthorized Training via Contour- and Texture-Aware Perturbations,"Xun Lin, Yi Yu, Song Xia, Jue Jiang, Haoran Wang, Zitong Yu, Yizhong Liu, Ying Fu, Shuai Wang, Wenzhong Tang, Alex Kot",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14250"" target=""_blank"">2403.14250</a>",,2024-12-11
LocalStyleFool: Regional Video Style Transfer Attack Using Segment Anything Model,"Yuxin Cao, Jinghao Li, Xi Xiao, Derui Wang, Minhui Xue, Hao Ge, Wei Liu, Guangwu Hu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11656"" target=""_blank"">2403.11656</a>",,2024-12-11
Certified Human Trajectory Prediction,"Mohammadhossein Bahari, Saeed Saadatnejad, Amirhossein Asgari Farsangi, Seyed-Mohsen Moosavi-Dezfooli, Alexandre Alahi",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13778"" target=""_blank"">2403.13778</a>","<a href=""https://s-attack.github.io/"" target=""_blank"">s-attack.github.io</a>",2024-12-11
Have You Poisoned My Data? Defending Neural Networks against Data Poisoning,"Gaspari Fabio De, Dorjan Hitaj, Luigi V. Mancini",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13523"" target=""_blank"">2403.13523</a>",,2024-12-11
Defending Against Indirect Prompt Injection Attacks With Spotlighting,"Keegan Hines, Gary Lopez, Matthew Hall, Federico Zarfati, Yonatan Zunger, Emre Kiciman",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14720"" target=""_blank"">2403.14720</a>",,2024-12-11
Don't be a Fool: Pooling Strategies in Offensive Language Detection from User-Intended Adversarial Attacks,"Seunguk Yu, Juhwan Choi, Youngbin Kim",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15467"" target=""_blank"">2403.15467</a>",,2024-12-11
BadEdit: Backdooring large language models by model editing,"Yanzhou Li, Tianlin Li, Kangjie Chen, Jian Zhang, Shangqing Liu, Wenhan Wang, Tianwei Zhang, Yang Liu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13355"" target=""_blank"">2403.13355</a>",,2024-12-11
Teacher-Student Training for Debiasing: General Permutation Debiasing for Large Language Models,"Adian Liusie, Yassir Fathullah, Mark J. F. Gales",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13590"" target=""_blank"">2403.13590</a>",,2024-12-11
Capsule Neural Networks as Noise Stabilizer for Time Series Data,"Soyeon Kim, Jihyeon Seong, Hyunkyung Han, Jaesik Choi",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13867"" target=""_blank"">2403.13867</a>",,2024-12-11
Resilience in Online Federated Learning: Mitigating Model-Poisoning Attacks via Partial Sharing,"Ehsan Lari, Reza Arablouei, Vinay Chakravarthi Gogineni, Stefan Werner",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13108"" target=""_blank"">2403.13108</a>",,2024-12-11
Discover and Mitigate Multiple Biased Subgroups in Image Classifiers,"Zeliang Zhang, Mingqian Feng, Zhiheng Li, Chenliang Xu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12777"" target=""_blank"">2403.12777</a>","<a href=""https://github.com/ZhangAIPI/DIM"" target=""_blank"">ZhangAIPI</a>",2024-12-11
Boosting Transferability in Vision-Language Attacks via Diversification along the Intersection Region of Adversarial Trajectory,"Sensen Gao, Xiaojun Jia, Xuhong Ren, Ivor Tsang, Qing Guo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12445"" target=""_blank"">2403.12445</a>",,2024-12-11
ADAPT to Robustify Prompt Tuning Vision Transformers,"Masih Eskandar, Tooba Imtiaz, Zifeng Wang, Jennifer Dy",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13196"" target=""_blank"">2403.13196</a>",,2024-12-11
"SSCAE -- Semantic, Syntactic, and Context-aware natural language Adversarial Examples generator","Javad Rafiei Asl, Mohammad H. Rafiei, Manar Alohaly, Daniel Takabi",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11833"" target=""_blank"">2403.11833</a>",,2024-12-11
Marlin: Knowledge-Driven Analysis of Provenance Graphs for Efficient and Robust Detection of Cyber Attacks,"Zhenyuan Li, Yangyang Wei, Xiangmin Shen, Lingzhi Wang, Yan Chen, Haitao Xu, Shouling Ji, Fan Zhang, Liang Hou, Wenmao Liu, Xuhong Zhang, Jianwei Ying",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12541"" target=""_blank"">2403.12541</a>",,2024-12-11
Diffusion Denoising as a Certified Defense against Clean-label Poisoning,"Sanghyun Hong, Nicholas Carlini, Alexey Kurakin",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11981"" target=""_blank"">2403.11981</a>",,2024-12-11
As Firm As Their Foundations: Can open-sourced foundation models be used to create adversarial examples for downstream tasks? (99%),"Anjun Hu, Jindong Gu, Francesco Pinto, Konstantinos Kamnitsas, Philip Torr",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12693"" target=""_blank"">2403.12693</a>",,2024-12-11
RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content,"Zhuowen Yuan, Zidi Xiong, Yi Zeng, Ning Yu, Ruoxi Jia, Dawn Song, Bo Li",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13031"" target=""_blank"">2403.13031</a>",,2024-12-11
"Robust NAS under adversarial training: benchmark, theory, and beyond","Yongtao Wu, Fanghui Liu, Carl-Johann Simon-Gabriel, Grigorios G Chrysos, Volkan Cevher",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13134"" target=""_blank"">2403.13134</a>",,2024-12-11
The SkipSponge Attack: Sponge Weight Poisoning of Deep Neural Networks,"Jona te Lintelo, Stefanos Koffas, Stjepan Picek",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06357"" target=""_blank"">2402.06357</a>",,2024-12-11
System-level Analysis of Adversarial Attacks and Defenses on Intelligence in O-RAN based Cellular Networks,"Azuka Chiejina, Brian Kim, Kaushik Chowhdury, Vijay K. Shah",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06846"" target=""_blank"">2402.06846</a>",,2024-12-11
RAMP: Boosting Adversarial Robustness Against Multiple $l_p$ Perturbations,"Enyi Jiang, Gagandeep Singh",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06827"" target=""_blank"">2402.06827</a>",,2024-12-11
Pixel Sentence Representation Learning,"Chenghao Xiao, Zhuoxu Huang, Danlu Chen, G Thomas Hudson, Yizhi Li, Haoran Duan, Chenghua Lin, Jie Fu, Jungong Han, Noura Al Moubayed",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08183"" target=""_blank"">2402.08183</a>","<a href=""https://github.com/gowitheflow-1998/Pixel-Linguist"" target=""_blank"">gowitheflow-1998</a>",2024-12-11
Fight Back Against Jailbreaking via Prompt Adversarial Tuning,"Yichuan Mo, Yuji Wang, Zeming Wei, Yisen Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06255"" target=""_blank"">2402.06255</a>","<a href=""https://github.com/PKU-ML/PAT"" target=""_blank"">PKU-ML</a>",2024-12-11
Anomaly Unveiled: Securing Image Classification against Adversarial Patch Attacks,"Nandish Chattopadhyay, Amira Guesmi, Muhammad Shafique",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06249"" target=""_blank"">2402.06249</a>",,2024-12-11
Architectural Neural Backdoors from First Principles,"Harry Langford, Ilia Shumailov, Yiren Zhao, Robert Mullins, Nicolas Papernot",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06957"" target=""_blank"">2402.06957</a>",,2024-12-11
Whispers in the Machine: Confidentiality in LLM-integrated Systems,"Jonathan Evertz, Merlin Chlosta, Lea SchÃ¶nherr, Thorsten Eisenhofer",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06922"" target=""_blank"">2402.06922</a>",,2024-12-11
Corruption Robust Offline Reinforcement Learning with Human Feedback,"Debmalya Mandal, Andi Nika, Parameswaran Kamalaruban, Adish Singla, Goran RadanoviÄ",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06734"" target=""_blank"">2402.06734</a>",,2024-12-11
A Random Ensemble of Encrypted Vision Transformers for Adversarially Robust Defense,"Ryota Iijima, Sayaka Shiota, Hitoshi Kiya",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07183"" target=""_blank"">2402.07183</a>",,2024-12-11
Accuracy of TextFooler black box adversarial attacks on 01 loss sign activation neural network ensemble,"Yunzhe Xue, Usman Roshan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07347"" target=""_blank"">2402.07347</a>","<a href=""https://github.com/zero-one-loss/wordcnn01"" target=""_blank"">zero-one-loss</a>",2024-12-11
Linearizing Models for Efficient yet Robust Private Inference,"Sreetama Sarkar, Souvik Kundu, Peter A. Beerel",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05521"" target=""_blank"">2402.05521</a>",,2024-12-11
Quantifying and Enhancing Multi-modal Robustness with Modality Preference,"Zequn Yang, Yake Wei, Ce Liang, Di Hu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06244"" target=""_blank"">2402.06244</a>",,2024-12-11
StruQ: Defending Against Prompt Injection with Structured Queries,"Sizhe Chen, Julien Piet, Chawin Sitawarin, David Wagner",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06363"" target=""_blank"">2402.06363</a>","<a href=""https://github.com/Sizhe-Chen/PromptInjectionDefense"" target=""_blank"">Sizhe-Chen</a>",2024-12-11
Evaluating Membership Inference Attacks and Defenses in Federated Learning,"Gongxi Zhu, Donghao Li, Hanlin Gu, Yuxing Han, Yuan Yao, Lixin Fan, Qiang Yang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06289"" target=""_blank"">2402.06289</a>","<a href=""https://github.com/Liar-Mask/FedMIA"" target=""_blank"">Liar-Mask</a>",2024-12-11
Blockchain Bribing Attacks and the Efficacy of Counterincentives,"Dimitris Karakostas, Aggelos Kiayias, Thomas Zacharias",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06352"" target=""_blank"">2402.06352</a>",,2024-12-11
For Better or For Worse? Learning Minimum Variance Features With Label Augmentation,"Muthu Chidambaram, Rong Ge",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06855"" target=""_blank"">2402.06855</a>",,2024-12-11
Comprehensive Assessment of Jailbreak Attacks Against LLMs,"Junjie Chu, Yugeng Liu, Ziqing Yang, Xinyue Shen, Michael Backes, Yang Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05668"" target=""_blank"">2402.05668</a>",,2024-12-11
Investigating White-Box Attacks for On-Device Models,"Mingyi Zhou, Xiang Gao, Jing Wu, Kui Liu, Hailong Sun, Li Li",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05493"" target=""_blank"">2402.05493</a>",,2024-12-11
TETRIS: Towards Exploring the Robustness of Interactive Segmentation,"Andrey Moskalenko, Vlad Shakhuro, Anna Vorontsova, Anton Konushin, Anton Antonov, Alexander Krapukhin, Denis Shepelev, Konstantin Soshin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06132"" target=""_blank"">2402.06132</a>",,2024-12-11
A High Dimensional Statistical Model for Adversarial Training: Geometry and Trade-Offs,"Kasimir Tanner, Matteo Vilucchio, Bruno Loureiro, Florent Krzakala",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05674"" target=""_blank"">2402.05674</a>",,2024-12-11
Is Adversarial Training with Compressed Datasets Effective? (10%),"Tong Chen, Raghavendra Selvan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05675"" target=""_blank"">2402.05675</a>",,2024-12-11
Reinforcement Learning as a Catalyst for Robust and Fair Federated Learning: Deciphering the Dynamics of Client Contributions,"Jialuo He, Wei Chen, Xiaojin Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05541"" target=""_blank"">2402.05541</a>",,2024-12-11
Adversarial Robustness Through Artifact Design,"Tsufit Shua, Liron David, Mahmood Sharif",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.04660"" target=""_blank"">2402.04660</a>",,2024-12-11
Breaking Free: How to Hack Safety Guardrails in Black-Box Diffusion Models! (98%),"Shashank Kotyan, Po-Yuan Mao, Pin-Yu Chen, Danilo Vasconcellos Vargas",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.04699"" target=""_blank"">2402.04699</a>","<a href=""https://shashankkotyan.github.io/EvoSeed"" target=""_blank"">shashankkotyan.github.io</a>",2024-12-11
NeuralSentinel: Safeguarding Neural Network Reliability and Trustworthiness,"Xabier Echeberria-Barrio, Mikel Gorricho, Selene Valencia, Francesco Zola",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07506"" target=""_blank"">2402.07506</a>",,2024-12-11
Do Membership Inference Attacks Work on Large Language Models? (1%),"Michael Duan, Anshuman Suri, Niloofar Mireshghallah, Sewon Min, Weijia Shi, Luke Zettlemoyer, Yulia Tsvetkov, Yejin Choi, David Evans, Hannaneh Hajishirzi",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07841"" target=""_blank"">2402.07841</a>",,2024-12-11
Faster Repeated Evasion Attacks in Tree Ensembles,"Lorenzo Cascioli, Laurens Devos, OndÅej KuÅ¾elka, Jesse Davis",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08586"" target=""_blank"">2402.08586</a>",,2024-12-11
Local Centrality Minimization with Quality Guarantees,"Atsushi Miyauchi, Lorenzo Severini, Francesco Bonchi",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07718"" target=""_blank"">2402.07718</a>",,2024-12-11
COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability,"Xingang Guo, Fangxu Yu, Huan Zhang, Lianhui Qin, Bin Hu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08679"" target=""_blank"">2402.08679</a>","<a href=""https://github.com/Yu-Fangxu/COLD-Attack"" target=""_blank"">Yu-Fangxu</a>",2024-12-11
Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications,"Boyi Wei, Kaixuan Huang, Yangsibo Huang, Tinghao Xie, Xiangyu Qi, Mengzhou Xia, Prateek Mittal, Mengdi Wang, Peter Henderson",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05162"" target=""_blank"">2402.05162</a>",,2024-12-11
Attacking Large Language Models with Projected Gradient Descent,"Simon Geisler, Tom WollschlÃ¤ger, M. H. I. Abdalla, Johannes Gasteiger, Stephan GÃ¼nnemann",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09154"" target=""_blank"">2402.09154</a>",,2024-12-11
Detecting Adversarial Spectrum Attacks via Distance to Decision Boundary Statistics,"Wenwei Zhao, Xiaowen Li, Shangqing Zhao, Jie Xu, Yao Liu, Zhuo Lu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08986"" target=""_blank"">2402.08986</a>",,2024-12-11
SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding,"Zhangchen Xu, Fengqing Jiang, Luyao Niu, Jinyuan Jia, Bill Yuchen Lin, Radha Poovendran",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08983"" target=""_blank"">2402.08983</a>",,2024-12-11
Reward Poisoning Attack Against Offline Reinforcement Learning,"Yinglun Xu, Rohan Gumaste, Gagandeep Singh",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09695"" target=""_blank"">2402.09695</a>",,2024-12-11
"Rapid Adoption, Hidden Risks: The Dual Impact of Large Language Model Customization","Rui Zhang, Hongwei Li, Rui Wen, Wenbo Jiang, Yuan Zhang, Michael Backes, Yun Shen, Yang Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09179"" target=""_blank"">2402.09179</a>",,2024-12-11
Ten Words Only Still Help: Improving Black-Box AI-Generated Text Detection via Proxy-Guided Efficient Re-Sampling,"Yuhui Shi, Qiang Sheng, Juan Cao, Hao Mi, Beizhe Hu, Danding Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09199"" target=""_blank"">2402.09199</a>",,2024-12-11
Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks,"Yixin Cheng, Markos Georgopoulos, Volkan Cevher, Grigorios G. Chrysos",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09177"" target=""_blank"">2402.09177</a>",,2024-12-11
Towards Robust Model-Based Reinforcement Learning Against Adversarial Corruption,"Chenlu Ye, Jiafan He, Quanquan Gu, Tong Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08991"" target=""_blank"">2402.08991</a>",,2024-12-11
Immediate generalisation in humans but a generalisation lag in deep neural networks$\unicode{x2014}$evidence for representational divergence? (1%),"Lukas S. Huber, Fred W. Mast, Felix A. Wichmann",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09303"" target=""_blank"">2402.09303</a>",,2024-12-11
Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues,"Zhiyuan Chang, Mingyang Li, Yi Liu, Junjie Wang, Qing Wang, Yang Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09091"" target=""_blank"">2402.09091</a>",,2024-12-11
Generating Universal Adversarial Perturbations for Quantum Classifiers,"Gautham Anil, Vishnu Vinod, Apurva Narayan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08648"" target=""_blank"">2402.08648</a>",,2024-12-11
Enhancing Robustness of Indoor Robotic Navigation with Free-Space Segmentation Models Against Adversarial Attacks,"Qiyuan An, Christos Sevastopoulos, Fillia Makedon",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08763"" target=""_blank"">2402.08763</a>",,2024-12-11
Data Reconstruction Attacks and Defenses: A Systematic Evaluation,"Sheng Liu, Zihan Wang, Qi Lei",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09478"" target=""_blank"">2402.09478</a>",,2024-12-11
Test-Time Backdoor Attacks on Multimodal Large Language Models,"Dong Lu, Tianyu Pang, Chao Du, Qian Liu, Xianjun Yang, Min Lin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08577"" target=""_blank"">2402.08577</a>","<a href=""https://sail-sg.github.io/AnyDoor/"" target=""_blank"">AnyDoor</a>",2024-12-11
Game of Trojans: Adaptive Adversaries Against Output-based Trojaned-Model Detectors,"Dinuka Sahabandu, Xiaojun Xu, Arezoo Rajabi, Luyao Niu, Bhaskar Ramasubramanian, Bo Li, Radha Poovendran",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08695"" target=""_blank"">2402.08695</a>",,2024-12-11
Adversarially Robust Feature Learning for Breast Cancer Diagnosis,"Degan Hao, Dooman Arefan, Margarita Zuley, Wendie Berg, Shandong Wu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08768"" target=""_blank"">2402.08768</a>",,2024-12-11
Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast,"Xiangming Gu, Xiaosen Zheng, Tianyu Pang, Chao Du, Qian Liu, Ye Wang, Jing Jiang, Min Lin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08567"" target=""_blank"">2402.08567</a>","<a href=""https://sail-sg.github.io/Agent-Smith/"" target=""_blank"">Agent-Smith</a>",2024-12-11
Adaptive Hierarchical Certification for Segmentation using Randomized Smoothing,"Alaa Anani, Tobias Lorenz, Bernt Schiele, Mario Fritz",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08400"" target=""_blank"">2402.08400</a>","<a href=""https://github.com/AlaaAnani/adaptive-certify"" target=""_blank"">AlaaAnani</a>",2024-12-11
Feature Attribution with Necessity and Sufficiency via Dual-stage Perturbation Test for Causal Explanation,"Xuexin Chen, Ruichu Cai, Zhengting Huang, Yuxuan Zhu, Julien Horwood, Zhifeng Hao, Zijian Li, Jose Miguel Hernandez-Lobato",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08845"" target=""_blank"">2402.08845</a>",,2024-12-11
Understanding Deep Learning defenses Against Adversarial Examples Through Visualizations for Dynamic Risk Assessment,"Xabier Echeberria-Barrio, Amaia Gil-Lerchundi, Jon Egana-Zubia, Raul Orduna-Urrutia",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07496"" target=""_blank"">2402.07496</a>",,2024-12-11
Topological safeguard for evasion attack interpreting the neural networks' behavior,"Xabier Echeberria-Barrio, Amaia Gil-Lerchundi, IÃ±igo Mendialdua, Raul Orduna-Urrutia",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07480"" target=""_blank"">2402.07480</a>",,2024-12-11
PoisonedRAG: Knowledge Corruption Attacks to Retrieval-Augmented Generation of Large Language Models,"Wei Zou, Runpeng Geng, Binghui Wang, Jinyuan Jia",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07867"" target=""_blank"">2402.07867</a>",,2024-12-11
Privacy-Preserving Gaze Data Streaming in Immersive Interactive Virtual Reality: Robustness and User Experience,"Ethan Wilson, Azim Ibragimov, Michael J. Proulx, Sai Deep Tetali, Kevin Butler, Eakta Jain",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07687"" target=""_blank"">2402.07687</a>",,2024-12-11
OrderBkd: Textual backdoor attack through repositioning,"Irina Alekseevskaia, Konstantin Arkhipenko",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07689"" target=""_blank"">2402.07689</a>","<a href=""https://github.com/alekseevskaia/OrderBkd"" target=""_blank"">alekseevskaia</a>",2024-12-11
Tighter Bounds on the Information Bottleneck with Application to Deep Learning,"Nir Weingarten, Zohar Yakhini, Moshe Butman, Ran Gilad-Bachrach",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07639"" target=""_blank"">2402.07639</a>",,2024-12-11
Multi-Attribute Vision Transformers are Efficient and Robust Learners,"Hanan Gani, Nada Saadi, Noor Hussein, Karthik Nandakumar",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08070"" target=""_blank"">2402.08070</a>",,2024-12-11
Customizable Perturbation Synthesis for Robust SLAM Benchmarking,"Xiaohao Xu, Tianyi Zhang, Sibo Wang, Xiang Li, Yongqi Chen, Ye Li, Bhiksha Raj, Matthew Johnson-Roberson, Xiaonan Huang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08125"" target=""_blank"">2402.08125</a>","<a href=""https://github.com/Xiaohao-Xu/SLAM-under-Perturbation/"" target=""_blank"">SLAM-under-Perturbation</a>",2024-12-11
THE COLOSSEUM: A Benchmark for Evaluating Generalization for Robotic Manipulation,"Wilbert Pumacay, Ishika Singh, Jiafei Duan, Ranjay Krishna, Jesse Thomason, Dieter Fox",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08191"" target=""_blank"">2402.08191</a>","<a href=""https://robot-colosseum.github.io/"" target=""_blank"">robot-colosseum.github.io</a>",2024-12-11
Accelerated Smoothing: A Scalable Approach to Randomized Smoothing,"Devansh Bhardwaj, Kshitiz Kaushik, Sarthak Gupta",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07498"" target=""_blank"">2402.07498</a>",,2024-12-11
Analyzing Adversarial Inputs in Deep Reinforcement Learning,"Davide Corsi, Guy Amir, Guy Katz, Alessandro Farinelli",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05284"" target=""_blank"">2402.05284</a>",,2024-12-11
Fundamental Challenges in Cybersecurity and a Philosophy of Vulnerability-Guided Hardening,Marcel BÃ¶hme,arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01944"" target=""_blank"">2402.01944</a>",,2024-12-11
Boosting Adversarial Transferability across Model Genus by Deformation-Constrained Warping,"Qinliang Lin, Cheng Luo, Zenghao Niu, Xilin He, Weicheng Xie, Yuanbo Hou, Linlin Shen, Siyang Song",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03951"" target=""_blank"">2402.03951</a>","<a href=""https://github.com/LinQinLiang/DeCoWA"" target=""_blank"">LinQinLiang</a>",2024-12-11
Benchmarking Transferable Adversarial Attacks,"Zhibo Jin, Jiayu Zhang, Zhiyu Zhu, Huaming Chen",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00418"" target=""_blank"">2402.00418</a>","<a href=""https://github.com/KxPlaug/TAA-Bench"" target=""_blank"">KxPlaug</a>",2024-12-11
Safety Fine-Tuning at (Almost) No Cost: A Baseline for Vision Large Language Models,"Yongshuo Zong, Ondrej Bohdal, Tingyang Yu, Yongxin Yang, Timothy Hospedales",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02207"" target=""_blank"">2402.02207</a>","<a href=""https://github.com/ys-zong/VLGuard"" target=""_blank"">ys-zong</a>",2024-12-11
Data Poisoning for In-context Learning,"Pengfei He, Han Xu, Yue Xing, Hui Liu, Makoto Yamada, Jiliang Tang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02160"" target=""_blank"">2402.02160</a>",,2024-12-11
HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack on Text,"Han Liu, Zhi Xu, Xiaotong Zhang, Feng Zhang, Fenglong Ma, Hongyang Chen, Hong Yu, Xianchao Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01806"" target=""_blank"">2402.01806</a>",,2024-12-11
$\sigma$-zero: Gradient-based Optimization of $\ell_0$-norm Adversarial Examples,"Antonio Emanuele CinÃ , Francesco Villani, Maura Pintor, Lea SchÃ¶nherr, Battista Biggio, Marcello Pelillo",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01879"" target=""_blank"">2402.01879</a>",,2024-12-11
STAA-Net: A Sparse and Transferable Adversarial Attack for Speech Emotion Recognition,"Yi Chang, Zhao Ren, Zixing Zhang, Xin Jing, Kun Qian, Xi Shao, Bin Hu, Tanja Schultz, BjÃ¶rn W. Schuller",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01227"" target=""_blank"">2402.01227</a>",,2024-12-11
Delving into Decision-based Black-box Attacks on Semantic Segmentation,"Zhaoyu Chen, Zhengyang Shan, Jingwen Chang, Kaixun Jiang, Dingkang Yang, Yiting Cheng, Wenqiang Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01220"" target=""_blank"">2402.01220</a>",,2024-12-11
SignSGD with Federated Defense: Harnessing Adversarial Attacks through Gradient Sign Decoding,"Chanho Park, Namyoon Lee",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01340"" target=""_blank"">2402.01340</a>",,2024-12-11
Unlearnable Examples For Time Series,"Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, James Bailey",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02028"" target=""_blank"">2402.02028</a>",,2024-12-11
Preference Poisoning Attacks on Reward Model Learning,"Junlin Wu, Jiongxiao Wang, Chaowei Xiao, Chenguang Wang, Ning Zhang, Yevgeniy Vorobeychik",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01920"" target=""_blank"">2402.01920</a>",,2024-12-11
Privacy-Preserving Distributed Learning for Residential Short-Term Load Forecasting,"Yi Dong, Yingjie Wang, Mariana Gama, Mustafa A. Mustafa, Geert Deconinck, Xiaowei Huang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01546"" target=""_blank"">2402.01546</a>",,2024-12-11
S2malloc: Statistically Secure Allocator for Use-After-Free Protection And More,"Ruizhe Wang, Meng Xu, N. Asokan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01894"" target=""_blank"">2402.01894</a>",,2024-12-11
Cheating Suffix: Targeted Attack to Text-To-Image Diffusion Models with Multi-Modal Priors,"Dingcheng Yang, Yang Bai, Xiaojun Jia, Yang Liu, Xiaochun Cao, Wenjian Yu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01369"" target=""_blank"">2402.01369</a>","<a href=""https://github.com/ydc123/MMP-Attack"" target=""_blank"">ydc123</a>",2024-12-11
What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement,"Xisen Jin, Xiang Ren",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01865"" target=""_blank"">2402.01865</a>",,2024-12-11
Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated Student Essay Detection,"Xinlin Peng, Ying Zhou, Ben He, Le Sun, Yingfei Sun",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00412"" target=""_blank"">2402.00412</a>",,2024-12-11
Towards Optimal Adversarial Robust Q-learning with Bellman Infinity-error,"Haoran Li, Zicheng Zhang, Wang Luo, Congying Han, Yudong Hu, Tiande Guo, Shichen Liao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02165"" target=""_blank"">2402.02165</a>",,2024-12-11
Double-Dip: Thwarting Label-Only Membership Inference Attacks with Transfer Learning and Randomization,"Arezoo Rajabi, Reeya Pimple, Aiswarya Janardhanan, Surudhi Asokraj, Bhaskar Ramasubramanian, Radha Poovendran",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01114"" target=""_blank"">2402.01114</a>",,2024-12-11
Vision-LLMs Can Fool Themselves with Self-Generated Typographic Attacks,"Maan Qraitem, Nazia Tasnim, Piotr Teterwak, Kate Saenko, Bryan A. Plummer",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00626"" target=""_blank"">2402.00626</a>","<a href=""https://github.com/mqraitem/Self-Gen-Typo-Attack"" target=""_blank"">mqraitem</a>",2024-12-11
Approximating Optimal Morphing Attacks using Template Inversion,"Laurent Colbois, Hatef Otroshi Shahreza, SÃ©bastien Marcel",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00695"" target=""_blank"">2402.00695</a>",,2024-12-11
"Trustworthy Distributed AI Systems: Robustness, Privacy, and Governance","Wenqi Wei, Ling Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01096"" target=""_blank"">2402.01096</a>",,2024-12-11
Vaccine: Perturbation-aware Alignment for Large Language Models against Harmful Fine-tuning Attack,"Tiansheng Huang, Sihao Hu, Ling Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01109"" target=""_blank"">2402.01109</a>","<a href=""https://github.com/git-disl/Vaccine"" target=""_blank"">git-disl</a>",2024-12-11
algoXSSF: Detection and analysis of cross-site request forgery (XSRF) and cross-site scripting (XSS) attacks via Machine learning algorithms,"Naresh Kshetri, Dilip Kumar, James Hutson, Navneet Kaur, Omar Faruq Osama",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01012"" target=""_blank"">2402.01012</a>",,2024-12-11
Adversarial Quantum Machine Learning: An Information-Theoretic Generalization Analysis,"Petros Georgiou, Sharu Theresa Jose, Osvaldo Simeone",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00176"" target=""_blank"">2402.00176</a>",,2024-12-11
Invariance-powered Trustworthy Defense via Remove Then Restore,"Xiaowei Fu, Yuhang Zhou, Lina Ma, Lei Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00304"" target=""_blank"">2402.00304</a>",,2024-12-11
BrainLeaks: On the Privacy-Preserving Properties of Neuromorphic Architectures against Model Inversion Attacks,"Hamed Poursiami, Ihsen Alouani, Maryam Parsa",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00906"" target=""_blank"">2402.00906</a>",,2024-12-11
Security and Privacy Challenges of Large Language Models: A Survey,"Badhan Chandra Das, M. Hadi Amini, Yanzhao Wu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00888"" target=""_blank"">2402.00888</a>",,2024-12-11
Fluent dreaming for language models,"T. Ben Confirm Labs Thompson, Zygimantas Confirm Labs Straznickas, Michael Confirm Labs Sklar",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01702"" target=""_blank"">2402.01702</a>","<a href=""https://github.com/Confirm-Solutions/dreamy"" target=""_blank"">Confirm-Solutions</a>",2024-12-11
Robustness Assessment of a Runway Object Classifier for Safe Aircraft Taxiing,"Yizhak Elboher, Raya Elsaleh, Omri Isac, MÃ©lanie Ducoffe, Audrey Galametz, Guillaume PovÃ©da, Ryma Boumazouza, NoÃ©mie Cohen, Guy Katz",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00035"" target=""_blank"">2402.00035</a>",,2024-12-11
SpecFormer: Guarding Vision Transformer Robustness via Maximum Singular Value Penalization,"Xixu Hu, Runkai Zheng, Jindong Wang, Cheuk Hang Leung, Qi Wu, Xing Xie",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03317"" target=""_blank"">2402.03317</a>","<a href=""https://github.com/microsoft/robustlearn"" target=""_blank"">microsoft</a>",2024-12-11
Invisible Finger: Practical Electromagnetic Interference Attack on Touchscreen-based Electronic Devices,"Haoqi Shan, Boyi Zhang, Zihao Zhan, Dean Sullivan, Shuo Wang, Yier Jin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02227"" target=""_blank"">2402.02227</a>",,2024-12-11
Universal Post-Training Reverse-Engineering Defense Against Backdoors in Deep Neural Networks,"Xi Li, Hang Wang, David J. Miller, George Kesidis",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02034"" target=""_blank"">2402.02034</a>",,2024-12-11
How Secure Are Large Language Models (LLMs) for Navigation in Urban Environments? (80%),"Congcong Wen, Jiazhao Liang, Shuaihang Yuan, Hao Huang, Yi Fang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09546"" target=""_blank"">2402.09546</a>",,2024-12-11
Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language Models,"Yuancheng Xu, Jiarui Yao, Manli Shu, Yanchao Sun, Zichu Wu, Ning Yu, Tom Goldstein, Furong Huang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06659"" target=""_blank"">2402.06659</a>","<a href=""https://github.com/umd-huang-lab/VLM-Poisoning"" target=""_blank"">umd-huang-lab</a>",2024-12-11
SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent Reinforcement Learning Systems,"Oubo Ma, Yuwen Pu, Linkang Du, Yang Dai, Ruo Wang, Xiaolei Liu, Yingcai Wu, Shouling Ji",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03741"" target=""_blank"">2402.03741</a>",,2024-12-11
PAC-Bayesian Adversarially Robust Generalization Bounds for Graph Neural Network,"Tan Sun, Junhong Lin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.04038"" target=""_blank"">2402.04038</a>",,2024-12-11
BotSSCL: Social Bot Detection with Self-Supervised Contrastive Learning,"Mohammad Majid Akhtar, Navid Shadman Bhuiyan, Rahat Masood, Muhammad Ikram, Salil S. Kanhere",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03740"" target=""_blank"">2402.03740</a>",,2024-12-11
Privacy Leakage on DNNs: A Survey of Model Inversion Attacks and Defenses,"Hao Fang, Yixiang Qiu, Hongyao Yu, Wenbo Yu, Jiawei Kong, Baoli Chong, Bin Chen, Xuan Wang, Shu-Tao Xia, Ke Xu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.04013"" target=""_blank"">2402.04013</a>",,2024-12-11
Studying Vulnerable Code Entities in R,"Zixiao Zhao, Millon Madhur Das, Fatemeh H. Fard",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.04421"" target=""_blank"">2402.04421</a>",,2024-12-11
DeMarking: A Defense for Network Flow Watermarking in Real-Time,"Yali Yuan, Jian Ge, Guang Cheng",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03760"" target=""_blank"">2402.03760</a>",,2024-12-11
HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal,"Mantas Mazeika, Long Phan, Xuwang Yin, Andy Zou, Zifan Wang, Norman Mu, Elham Sakhaee, Nathaniel Li, Steven Basart, Bo Li, David Forsyth, Dan Hendrycks",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.04249"" target=""_blank"">2402.04249</a>","<a href=""https://github.com/centerforaisafety/HarmBench"" target=""_blank"">centerforaisafety</a>",2024-12-11
A Generative Approach to Surrogate-based Black-box Attacks,"Raha Moraffah, Huan Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02732"" target=""_blank"">2402.02732</a>",,2024-12-11
Transcending Adversarial Perturbations: Manifold-Aided Adversarial Examples with Legitimate Semantics,"Shuai Li, Xiaoyu Jiang, Xiaoguang Ma",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03095"" target=""_blank"">2402.03095</a>","<a href=""https://github.com/shuaili1027/MAELS"" target=""_blank"">shuaili1027</a>",2024-12-11
Arabic Synonym BERT-based Adversarial Examples for Text Classification,"Norah Alshahrani, Saied Alshahrani, Esma Wali, Jeanna Matthews",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03477"" target=""_blank"">2402.03477</a>",,2024-12-11
Generalization Properties of Adversarial Training for $\ell_0$-Bounded Adversarial Attacks,"Payam Delgosha, Hamed Hassani, Ramtin Pedarsani",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03576"" target=""_blank"">2402.03576</a>",,2024-12-11
FoolSDEdit: Deceptively Steering Your Edits Towards Targeted Attribute-aware Distribution,"Qi Zhou, Dongxia Wang, Tianlin Li, Zhihong Xu, Yang Liu, Kui Ren, Wenhai Wang, Qing Guo",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03705"" target=""_blank"">2402.03705</a>",,2024-12-11
Time-Distributed Backdoor Attacks on Federated Spiking Learning,"Gorka Abad, Stjepan Picek, Aitor Urbieta",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02886"" target=""_blank"">2402.02886</a>",,2024-12-11
Partially Recentralization Softmax Loss for Vision-Language Models Robustness,"Hao Wang, Xin Zhang, Jinzhe Jiang, Yaqian Zhao, Chen Li",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03627"" target=""_blank"">2402.03627</a>",,2024-12-11
Analyzing Sentiment Polarity Reduction in News Presentation through Contextual Perturbation and Large Language Models,"Alapan Kuila, Somnath Jena, Sudeshna Sarkar, Partha Pratim Chakrabarti",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02145"" target=""_blank"">2402.02145</a>",,2024-12-11
Organic or Diffused: Can We Distinguish Human Art from AI-generated Images? (31%),"Anna Yoo Jeong Ha, Josephine Passananti, Ronik Bhaskar, Shawn Shan, Reid Southen, Haitao Zheng, Ben Y. Zhao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03214"" target=""_blank"">2402.03214</a>",,2024-12-11
DisDet: Exploring Detectability of Backdoor Attack on Diffusion Models,"Yang Sui, Huy Phan, Jinqi Xiao, Tianfang Zhang, Zijie Tang, Cong Shi, Yan Wang, Yingying Chen, Bo Yuan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02739"" target=""_blank"">2402.02739</a>",,2024-12-11
FINEST: Stabilizing Recommendations by Rank-Preserving Fine-Tuning,"Sejoon Oh, Berk Ustun, Julian McAuley, Srijan Kumar",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03481"" target=""_blank"">2402.03481</a>",,2024-12-11
PROSAC: Provably Safe Certification for Machine Learning Models under Adversarial Attacks,"Ziquan Liu, Zhuo Zhi, Ilija Bogunovic, Carsten Gerner-Beuerle, Miguel Rodrigues",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02629"" target=""_blank"">2402.02629</a>",,2024-12-11
Adversarial Text Purification: A Large Language Model Approach for Defense,"Raha Moraffah, Shubh Khandelwal, Amrita Bhattacharjee, Huan Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06655"" target=""_blank"">2402.06655</a>",,2024-12-11
DeSparsify: Adversarial Attack Against Token Sparsification Mechanisms in Vision Transformers,"Oryan Yehezkel, Alon Zolfi, Amit Baras, Yuval Elovici, Asaf Shabtai",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02554"" target=""_blank"">2402.02554</a>",,2024-12-11
Exploiting Class Probabilities for Black-box Sentence-level Attacks,"Raha Moraffah, Huan Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02695"" target=""_blank"">2402.02695</a>",,2024-12-11
Evading Deep Learning-Based Malware Detectors via Obfuscation: A Deep Reinforcement Learning Approach,"Brian Etter, James Lee Hu, Mohammedreza Ebrahimi, Weifeng Li, Xin Li, Hsinchun Chen",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02600"" target=""_blank"">2402.02600</a>",,2024-12-11
Adversarial Data Augmentation for Robust Speaker Verification,"Zhenyu Zhou, Junhui Chen, Namin Wang, Lantian Li, Dong Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02699"" target=""_blank"">2402.02699</a>",,2024-12-11
Seeing is not always believing: The Space of Harmless Perturbations,"Lu Chen, Shaofeng Li, Benhao Huang, Fan Yang, Zheng Li, Jie Li, Yuan Luo",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02095"" target=""_blank"">2402.02095</a>",,2024-12-11
Evaluating the Robustness of Off-Road Autonomous Driving Segmentation against Adversarial Attacks: A Dataset-Centric analysis,"Pankaj Deoli, Rohit Kumar, Axel Vierling, Karsten Berns",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02154"" target=""_blank"">2402.02154</a>","<a href=""https://github.com/rohtkumar/adversarial_attacks_"" target=""_blank"">rohtkumar</a>",2024-12-11
Your Diffusion Model is Secretly a Certifiably Robust Classifier,"Huanran Chen, Yinpeng Dong, Shitong Shao, Zhongkai Hao, Xiao Yang, Hang Su, Jun Zhu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02316"" target=""_blank"">2402.02316</a>",,2024-12-11
MixedNUTS: Training-Free Accuracy-Robustness Balance via Nonlinearly Mixed Classifiers,"Yatong Bai, Mo Zhou, Vishal M. Patel, Somayeh Sojoudi",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02263"" target=""_blank"">2402.02263</a>",,2024-12-11
Review-Incorporated Model-Agnostic Profile Injection Attacks on Recommender Systems,"Shiyi Yang, Lina Yao, Chen Wang, Xiwei Xu, Liming Zhu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09023"" target=""_blank"">2402.09023</a>",,2024-12-11
Enhance DNN Adversarial Robustness and Efficiency via Injecting Noise to Non-Essential Neurons,"Zhenyu Liu, Garrett Gagnon, Swagath Venkataramani, Liu Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.04325"" target=""_blank"">2402.04325</a>",,2024-12-11
Only My Model On My Data: A Privacy Preserving Approach Protecting one Model and Deceiving Unauthorized Black-Box Models,"Weiheng Chai, Brian Testa, Huantao Ren, Asif Salekin, Senem Velipasalar",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09316"" target=""_blank"">2402.09316</a>",,2024-12-11
Investigating Deep Watermark Security: An Adversarial Transferability Perspective,"Biqing Qi, Junqi Gao, Yiang Luo, Jianxing Liu, Ligang Wu, Bowen Zhou",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16397"" target=""_blank"">2402.16397</a>",,2024-12-11
Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts,"Mikayel Samvelyan, Sharath Chandra Raparthy, Andrei Lupu, Eric Hambro, Aram H. Markosyan, Manish Bhatt, Yuning Mao, Minqi Jiang, Jack Parker-Holder, Jakob Foerster, Tim RocktÃ¤schel, Roberta Raileanu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16822"" target=""_blank"">2402.16822</a>",,2024-12-11
Pandora's White-Box: Precise Training Data Detection and Extraction in Large Language Models,"Jeffrey G. Wang, Jason Wang, Marvin Li, Seth Neel",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17012"" target=""_blank"">2402.17012</a>",,2024-12-11
WIPI: A New Web Threat for LLM-Driven Web Agents,"Fangzhou Wu, Shutong Wu, Yulong Cao, Chaowei Xiao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16965"" target=""_blank"">2402.16965</a>",,2024-12-11
RoCoIns: Enhancing Robustness of Large Language Models through Code-Style Instructions,"Yuansen Zhang, Xiao Wang, Zhiheng Xi, Han Xia, Tao Gui, Qi Zhang, Xuanjing Huang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16431"" target=""_blank"">2402.16431</a>",,2024-12-11
An Innovative Information Theory-based Approach to Tackle and Enhance The Transparency in Phishing Detection,"Van Nguyen, Tingmin Wu, Xingliang Yuan, Marthie Grobler, Surya Nepal, Carsten Rudolph",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17092"" target=""_blank"">2402.17092</a>",,2024-12-11
From Noise to Clarity: Unraveling the Adversarial Suffix of Large Language Model Attacks via Translation of Text Embeddings,"Hao Wang, Hao Li, Minlie Huang, Lei Sha",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16006"" target=""_blank"">2402.16006</a>",,2024-12-11
An Adversarial Robustness Benchmark for Enterprise Network Intrusion Detection,"JoÃ£o Vitorino, Miguel Silva, Eva Maia, Isabel PraÃ§a",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16912"" target=""_blank"">2402.16912</a>",,2024-12-11
Defending Large Language Models against Jailbreak Attacks via Semantic Smoothing,"Jiabao Ji, Bairu Hou, Alexander Robey, George J. Pappas, Hamed Hassani, Yang Zhang, Eric Wong, Shiyu Chang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16192"" target=""_blank"">2402.16192</a>","<a href=""https://github.com/UCSB-NLP-Chang/SemanticSmooth"" target=""_blank"">UCSB-NLP-Chang</a>",2024-12-11
Adversarial-Robust Transfer Learning for Medical Imaging via Domain Assimilation,"Xiaohui Chen, Tie Luo",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16005"" target=""_blank"">2402.16005</a>",,2024-12-11
DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM Jailbreakers,"Xirui Li, Ruochen Wang, Minhao Cheng, Tianyi Zhou, Cho-Jui Hsieh",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16914"" target=""_blank"">2402.16914</a>",,2024-12-11
m2mKD: Module-to-Module Knowledge Distillation for Modular Transformers,"Ka Man Lo, Yiming Liang, Wenyu Du, Yuantao Fan, Zili Wang, Wenhao Huang, Lei Ma, Jie Fu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16918"" target=""_blank"">2402.16918</a>","<a href=""https://github.com/kamanphoebe/m2mKD"" target=""_blank"">kamanphoebe</a>",2024-12-11
PRP: Propagating Universal Perturbations to Attack Large Language Model Guard-Rails,"Neal Mangaokar, Ashish Hooda, Jihye Choi, Shreyas Chandrashekaran, Kassem Fawaz, Somesh Jha, Atul Prakash",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15911"" target=""_blank"">2402.15911</a>",,2024-12-11
LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner: A Vision Paper,"Daoyuan Wu, Shuai Wang, Yang Liu, Ning Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15727"" target=""_blank"">2402.15727</a>",,2024-12-11
RAUCA: A Novel Physical Adversarial Attack on Vehicle Detectors via Robust and Accurate Camouflage Generation,"Jiawei Zhou, Linye Lyu, Daojing He, Yu Li",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15853"" target=""_blank"">2402.15853</a>",,2024-12-11
Towards Robust Image Stitching: An Adaptive Resistance Learning against Compatible Attacks,"Zhiying Jiang, Xingyuan Li, Jinyuan Liu, Xin Fan, Risheng Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15959"" target=""_blank"">2402.15959</a>","<a href=""https://github.com/Jzy2017/TRIS"" target=""_blank"">Jzy2017</a>",2024-12-11
Optimal Zero-Shot Detector for Multi-Armed Attacks,"Federica Granese, Marco Romanelli, Pablo Piantanida",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15808"" target=""_blank"">2402.15808</a>",,2024-12-11
Sparse MeZO: Less Parameters for Better Performance in Zeroth-Order LLM Fine-Tuning,"Yong Liu, Zirui Zhu, Chaoyu Gong, Minhao Cheng, Cho-Jui Hsieh, Yang You",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15751"" target=""_blank"">2402.15751</a>",,2024-12-11
Distilling Adversarial Robustness Using Heterogeneous Teachers,"Jieren Deng, Aaron Palmer, Rigel Mahmood, Ethan Rathbun, Jinbo Bi, Kaleel Mahmood, Derek Aguiar",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15586"" target=""_blank"">2402.15586</a>",,2024-12-11
Fast Adversarial Attacks on Language Models In One GPU Minute,"Vinu Sankar Sadasivan, Shoumik Saha, Gaurang Sriramanan, Priyatham Kattakinda, Atoosa Chegini, Soheil Feizi",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15570"" target=""_blank"">2402.15570</a>","<a href=""https://github.com/vinusankars/BEAST"" target=""_blank"">vinusankars</a>",2024-12-11
A Robust Defense against Adversarial Attacks on Deep Learning-based Malware Detectors via (De)Randomized Smoothing,"Daniel Gibert, Giulio Zizzo, Quan Le, Jordi Planes",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15267"" target=""_blank"">2402.15267</a>",,2024-12-11
ProTIP: Probabilistic Robustness Verification on Text-to-Image Diffusion Models against Stochastic Perturbation,"Yi Zhang, Yun Tang, Wenjie Ruan, Xiaowei Huang, Siddartha Khastgir, Paul Jennings, Xingyu Zhao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15429"" target=""_blank"">2402.15429</a>",,2024-12-11
On the Duality Between Sharpness-Aware Minimization and Adversarial Training,"Yihao Zhang, Hangzhou He, Jingyu Zhu, Huanran Chen, Yifei Wang, Zeming Wei",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15152"" target=""_blank"">2402.15152</a>","<a href=""https://github.com/weizeming/SAM_AT"" target=""_blank"">weizeming</a>",2024-12-11
Low-Frequency Black-Box Backdoor Attack via Evolutionary Algorithm,"Yanqi Qiao, Dazhuang Liu, Rui Wang, Kaitai Liang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15653"" target=""_blank"">2402.15653</a>",,2024-12-11
Deep Networks Always Grok and Here is Why,"Ahmed Imtiaz Humayun, Randall Balestriero, Richard Baraniuk",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15555"" target=""_blank"">2402.15555</a>",,2024-12-11
BSPA: Exploring Black-box Stealthy Prompt Attacks against Image Generators,"Yu Tian, Xiao Yang, Yinpeng Dong, Heming Yang, Hang Su, Jun Zhu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15218"" target=""_blank"">2402.15218</a>",,2024-12-11
Reinforcement Learning-Based Approaches for Enhancing Security and Resilience in Smart Control: A Survey on Attack and Defense Methods,Zheyu Zhang,arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15617"" target=""_blank"">2402.15617</a>",,2024-12-11
Break the Breakout: Reinventing LM Defense Against Jailbreak Attacks with Self-Refinement,"Heegyu Kim, Sehyun Yuk, Hyunsouk Cho",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15180"" target=""_blank"">2402.15180</a>",,2024-12-11
Prime+Retouch: When Cache is Locked and Leaked,"Jaehyuk Lee, Fan Sang, Taesoo Kim",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15425"" target=""_blank"">2402.15425</a>",,2024-12-11
TREC: APT Tactic / Technique Recognition via Few-Shot Provenance Subgraph Learning,"Mingqi Lv, HongZhe Gao, Xuebo Qiu, Tieming Chen, Tiantian Zhu, Jinyin Chen, Shouling Ji",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15147"" target=""_blank"">2402.15147</a>",,2024-12-11
Defending LLMs against Jailbreaking Attacks via Backtranslation,"Yihan Wang, Zhouxing Shi, Andrew Bai, Cho-Jui Hsieh",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16459"" target=""_blank"">2402.16459</a>",,2024-12-11
Edge Detectors Can Make Deep Convolutional Neural Networks More Robust,"Jin Ding, Jie-Chao Zhao, Yong-Zhi Sun, Ping Tan, Jia-Wei Wang, Ji-En Ma, You-Tong Fang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16479"" target=""_blank"">2402.16479</a>",,2024-12-11
Rethinking Invariance Regularization in Adversarial Training to Improve Robustness-Accuracy Trade-off,"Futa Waseda, Ching-Chun Chang, Isao Echizen",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14648"" target=""_blank"">2402.14648</a>",,2024-12-11
Unveiling Vulnerability of Self-Attention,"Khai Jiet Liong, Hongqiu Wu, Hai Zhao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16470"" target=""_blank"">2402.16470</a>",,2024-12-11
How to Train your Antivirus: RL-based Hardening through the Problem-Space,"Jacopo Cortellazzi, Ilias Tsingenopoulos, Branislav BoÅ¡anskÃ½, Simone Aonzo, Davy Preuveneers, Wouter Joosen, Fabio Pierazzi, Lorenzo Cavallaro",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19027"" target=""_blank"">2402.19027</a>",,2024-12-11
Pointing out the Shortcomings of Relation Extraction Models with Semantically Motivated Adversarials,"Gennaro Nolano, Moritz Blum, Basil Ell, Philipp Cimiano",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19076"" target=""_blank"">2402.19076</a>",,2024-12-11
Assessing Visually-Continuous Corruption Robustness of Neural Networks Relative to Human Performance,"Huakun Shen, Boyue Caroline Hu, Krzysztof Czarnecki, Lina Marsso, Marsha Chechik",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19401"" target=""_blank"">2402.19401</a>",,2024-12-11
Unraveling Adversarial Examples against Speaker Identification -- Techniques for Attack Detection and Victim Model Classification,"Sonal Joshi, Thomas Thebaud, JesÃºs Villalba, Najim Dehak",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19355"" target=""_blank"">2402.19355</a>",,2024-12-11
PAL: Proxy-Guided Black-Box Attack on Large Language Models,"Chawin Sitawarin, Norman Mu, David Wagner, Alexandre Araujo",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09674"" target=""_blank"">2402.09674</a>","<a href=""https://github.com/chawins/pal"" target=""_blank"">chawins</a>",2024-12-11
Verification of Neural Networks' Global Robustness,"Anan Kabaha, Dana Drachsler-Cohen",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19322"" target=""_blank"">2402.19322</a>",,2024-12-11
SynGhost: Imperceptible and Universal Task-agnostic Backdoor Attack in Pre-trained Language Models,"Pengzhou Cheng, Wei Du, Zongru Wu, Fengwei Zhang, Libo Chen, Gongshen Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18945"" target=""_blank"">2402.18945</a>",,2024-12-11
Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge,"Ansh Arora, Xuanli He, Maximilian Mozes, Srinibas Swain, Mark Dras, Qiongkai Xu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19334"" target=""_blank"">2402.19334</a>",,2024-12-11
Unveiling Typographic Deceptions: Insights of the Typographic Vulnerability in Large Vision-Language Model,"Hao Cheng, Erjia Xiao, Jindong Gu, Le Yang, Jinhao Duan, Jize Zhang, Jiahang Cao, Kaidi Xu, Renjing Xu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19150"" target=""_blank"">2402.19150</a>","<a href=""https://github.com/ChaduCheng/TypoDeceptions"" target=""_blank"">ChaduCheng</a>",2024-12-11
"Enhancing the ""Immunity"" of Mixture-of-Experts Networks for Adversarial Defense","Qiao Han, yong huang, xinling Guo, Yiteng Zhai, Yu Qin, Yao Yang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18787"" target=""_blank"">2402.18787</a>",,2024-12-11
MPAT: Building Robust Deep Neural Networks against Textual Adversarial Attacks,"Fangyuan Zhang, Huichi Zhou, Shuangjiao Li, Hongtao Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18792"" target=""_blank"">2402.18792</a>",,2024-12-11
Catastrophic Overfitting: A Potential Blessing in Disguise,"Mengnan Zhao, Lihe Zhang, Yuqiu Kong, Baocai Yin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18211"" target=""_blank"">2402.18211</a>",,2024-12-11
Living-off-The-Land Reverse-Shell Detection by Informed Data Augmentation,"Dmitrijs Trizna, Luca Demetrio, Battista Biggio, Fabio Roli",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18329"" target=""_blank"">2402.18329</a>",,2024-12-11
A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems,"Fangzhou Wu, Ning Zhang, Somesh Jha, Patrick McDaniel, Chaowei Xiao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18649"" target=""_blank"">2402.18649</a>","<a href=""https://fzwark.github.io/LLM-System-Attack-Demo/"" target=""_blank"">LLM-System-Attack-Demo</a>",2024-12-11
Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction,"Tong Liu, Yingjie Zhang, Zhe Zhao, Yinpeng Dong, Guozhu Meng, Kai Chen",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18104"" target=""_blank"">2402.18104</a>",,2024-12-11
Out-of-Distribution Detection using Neural Activation Prior,"Weilin Wan, Weizhong Zhang, Cheng Jin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18162"" target=""_blank"">2402.18162</a>",,2024-12-11
Robustness-Congruent Adversarial Training for Secure Machine Learning Model Updates,"Daniele Angioni, Luca Demetrio, Maura Pintor, Luca Oneto, Davide Anguita, Battista Biggio, Fabio Roli",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17390"" target=""_blank"">2402.17390</a>",,2024-12-11
Extreme Miscalibration and the Illusion of Adversarial Robustness,"Vyas Raina, Samson Tan, Volkan Cevher, Aditya Rawal, Sheng Zha, George Karypis",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17509"" target=""_blank"">2402.17509</a>",,2024-12-11
Black-box Adversarial Attacks Against Image Quality Assessment Models,"Yu Ran, Ao-Xiang Zhang, Mingjie Li, Weixuan Tang, Yuan-Gen Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17533"" target=""_blank"">2402.17533</a>",,2024-12-11
Enhancing Tracking Robustness with Auxiliary Adversarial Defense Networks,"Zhewei Wu, Ruilong Yu, Qihe Liu, Shuying Cheng, Shilin Qiu, Shijie Zhou",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17976"" target=""_blank"">2402.17976</a>",,2024-12-11
LLM-Resistant Math Word Problem Generation via Adversarial Attacks,"Roy Xie, Chengxuan Huang, Junlin Wang, Bhuwan Dhingra",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17916"" target=""_blank"">2402.17916</a>",,2024-12-11
Breaking the Black-Box: Confidence-Guided Model Inversion Attack for Distribution Shift,"Xinhao Liu, Yingzhao Jiang, Zetao Lin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18027"" target=""_blank"">2402.18027</a>",,2024-12-11
Towards Fairness-Aware Adversarial Learning,"Yanghao Zhang, Tianle Zhang, Ronghui Mu, Xiaowei Huang, Wenjie Ruan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17729"" target=""_blank"">2402.17729</a>",,2024-12-11
Time-Restricted Double-Spending Attack on PoW-based Blockchains,"Yiming Jiang, Jiangfan Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17223"" target=""_blank"">2402.17223</a>",,2024-12-11
Improving the JPEG-resistance of Adversarial Attacks on Face Recognition by Interpolation Smoothing,"Kefu Guo, Fengfan Zhou, Hefei Ling, Ping Li, Hui Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16586"" target=""_blank"">2402.16586</a>",,2024-12-11
Improving behavior based authentication against adversarial attack using XAI,"Dong Qin, George Amariucai, Daji Qiao, Yong Guan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16430"" target=""_blank"">2402.16430</a>",,2024-12-11
Adversarial example soups: averaging multiple adversarial examples improves transferability without increasing additional generation time,"Bo Yang, Hengwei Zhang, Chenwei Li, Jindong Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18370"" target=""_blank"">2402.18370</a>",,2024-12-11
A Curious Case of Remarkable Resilience to Gradient Attacks via Fully Convolutional and Differentiable Front End with a Skip Connection,"Leonid Boytsov, Ameya Joshi, Filipe Condessa",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17018"" target=""_blank"">2402.17018</a>",,2024-12-11
Adversarial Perturbations of Physical Signals,"Robert L. Bassett, Dellen Austin Van, Anthony P. Austin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17104"" target=""_blank"">2402.17104</a>",,2024-12-11
SoK: Analyzing Adversarial Examples: A Framework to Study Adversary Knowledge,"Lucas Fenaux, Florian Kerschbaum",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14937"" target=""_blank"">2402.14937</a>",,2024-12-11
Model X-ray:Detecting Backdoored Models via Decision Boundary,"Yanghao Su, Jie Zhang, Ting Xu, Tianwei Zhang, Weiming Zhang, Nenghai Yu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17465"" target=""_blank"">2402.17465</a>",,2024-12-11
Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning Meets Adversarial Images,"Zefeng Wang, Zhen Han, Shuo Chen, Fan Xue, Zifeng Ding, Xun Xiao, Volker Tresp, Philip Torr, Jindong Gu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14899"" target=""_blank"">2402.14899</a>",,2024-12-11
Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning,"Shuai Zhao, Leilei Gan, Luu Anh Tuan, Jie Fu, Lingjuan Lyu, Meihuizi Jia, Jinming Wen",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12168"" target=""_blank"">2402.12168</a>",,2024-12-11
Amplifying Training Data Exposure through Fine-Tuning with Pseudo-Labeled Memberships,"Myung Gyo Oh, Hong Eun Ahn, Leo Hyun Park, Taekyoung Kwon",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12189"" target=""_blank"">2402.12189</a>",,2024-12-11
Privacy-Preserving Low-Rank Adaptation for Latent Diffusion Models,"Zihao Luo, Xilie Xu, Feng Liu, Yun Sing Koh, Di Wang, Jingfeng Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11989"" target=""_blank"">2402.11989</a>","<a href=""https://github.com/WilliamLUO0/StablePrivateLoRA"" target=""_blank"">WilliamLUO0</a>",2024-12-11
A Curious Case of Searching for the Correlation between Training Data and Adversarial Robustness of Transformer Textual Models,"Cuong Dang, Dung D. Le, Thai Le",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11469"" target=""_blank"">2402.11469</a>","<a href=""https://github.com/CaptainCuong/RobustText_ACL2024"" target=""_blank"">CaptainCuong</a>",2024-12-11
Evaluating Adversarial Robustness of Low dose CT Recovery,"Kanchana Vaishnavi Gandikota, Paramanand Chandramouli, Hannah Droege, Michael Moeller",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11557"" target=""_blank"">2402.11557</a>",,2024-12-11
Evaluating Efficacy of Model Stealing Attacks and Defenses on Quantum Neural Networks,"Satwik Kundu, Debarshi Kundu, Swaroop Ghosh",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11687"" target=""_blank"">2402.11687</a>",,2024-12-11
The Effectiveness of Random Forgetting for Robust Generalization,"Vijaya Raghavan T Ramkumar, Bahram Zonooz, Elahe Arani",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11733"" target=""_blank"">2402.11733</a>",,2024-12-11
Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection,"Jiawei Liang, Siyuan Liang, Aishan Liu, Xiaojun Jia, Junhao Kuang, Xiaochun Cao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11473"" target=""_blank"">2402.11473</a>","<a href=""https://github.com/JWLiang007/PFF"" target=""_blank"">JWLiang007</a>",2024-12-11
Poisoning Federated Recommender Systems with Fake Users,"Ming Yin, Yichang Xu, Minghong Fang, Neil Zhenqiang Gong",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11637"" target=""_blank"">2402.11637</a>",,2024-12-11
SPML: A DSL for Defending Language Models Against Prompt Attacks,"Reshabh K Sharma, Vinayak Gupta, Dan Grossman",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11755"" target=""_blank"">2402.11755</a>","<a href=""https://prompt-compiler.github.io/SPML/"" target=""_blank"">SPML</a>",2024-12-11
Teacher as a Lenient Expert: Teacher-Agnostic Data-Free Knowledge Distillation,"Hyunjune Shin, Dong-Wan Choi",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12406"" target=""_blank"">2402.12406</a>",,2024-12-11
Maintaining Adversarial Robustness in Continuous Learning,"Xiaolei Ru, Xiaowei Cao, Zijia Liu, Jack Murdoch Moore, Xin-Ya Zhang, Xia Zhu, Wenjia Wei, Gang Yan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11196"" target=""_blank"">2402.11196</a>",,2024-12-11
Be Persistent: Towards a Unified Solution for Mitigating Shortcuts in Deep Learning,"Hadi M. Dolatabadi, Sarah M. Erfani, Christopher Leckie",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11237"" target=""_blank"">2402.11237</a>",,2024-12-11
Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents,"Wenkai Yang, Xiaohan Bi, Yankai Lin, Sishuo Chen, Jie Zhou, Xu Sun",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11208"" target=""_blank"">2402.11208</a>",,2024-12-11
VoltSchemer: Use Voltage Noise to Manipulate Your Wireless Charger,"Zihao Zhan, Yirui Yang, Haoqi Shan, Hanqiu Wang, Yier Jin, Shuo Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11423"" target=""_blank"">2402.11423</a>",,2024-12-11
DART: A Principled Approach to Adversarially Robust Unsupervised Domain Adaptation,"Yunjuan Wang, Hussein Hazimeh, Natalia Ponomareva, Alexey Kurakin, Ibrahim Hammoud, Raman Arora",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11120"" target=""_blank"">2402.11120</a>",,2024-12-11
Theoretical Understanding of Learning from Adversarial Perturbations,"Soichiro Kumano, Hiroshi Kera, Toshihiko Yamasaki",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10470"" target=""_blank"">2402.10470</a>","<a href=""https://github.com/s-kumano/learning-from-adversarial-perturbations"" target=""_blank"">s-kumano</a>",2024-12-11
Assessing biomedical knowledge robustness in large language models by query-efficient sampling attacks,"R. Patrick Xian, Alex J. Lee, Satvik Lolla, Vincent Wang, Qiming Cui, Russell Ro, Reza Abbasi-Asl",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10527"" target=""_blank"">2402.10527</a>",,2024-12-11
The AI Security Pyramid of Pain,"Chris M. Ward, Josh Harguess, Julia Tao, Daniel Christman, Paul Spicer, Mike Tan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11082"" target=""_blank"">2402.11082</a>",,2024-12-11
AIM: Automated Input Set Minimization for Metamorphic Security Testing,"Nazanin Bayati Chaleshtari, Yoann Marquer, Fabrizio Pastore, Lionel C. Briand",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10773"" target=""_blank"">2402.10773</a>",,2024-12-11
Universal Prompt Optimizer for Safe Text-to-Image Generation,"Zongyu Wu, Hongcheng Gao, Yueze Wang, Xiang Zhang, Suhang Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10882"" target=""_blank"">2402.10882</a>",,2024-12-11
ToBlend: Token-Level Blending With an Ensemble of LLMs to Attack AI-Generated Text Detection,"Fan Huang, Haewoon Kwak, Jisun An",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11167"" target=""_blank"">2402.11167</a>",,2024-12-11
Camouflage is all you need: Evaluating and Enhancing Language Model Robustness Against Camouflage Adversarial Attacks,"Ãlvaro Huertas-GarcÃ­a, Alejandro MartÃ­n, Javier Huertas-Tato, David Camacho",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09874"" target=""_blank"">2402.09874</a>",,2024-12-11
On the Safety Concerns of Deploying LLMs/VLMs in Robotics: Highlighting the Risks and Vulnerabilities,"Xiyang Wu, Ruiqi Xian, Tianrui Guan, Jing Liang, Souradip Chakraborty, Fuxiao Liu, Brian Sadler, Dinesh Manocha, Amrit Singh Bedi",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10340"" target=""_blank"">2402.10340</a>",,2024-12-11
Backdoor Attack against One-Class Sequential Anomaly Detection Models,"He Cheng, Shuhan Yuan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10283"" target=""_blank"">2402.10283</a>",,2024-12-11
Noise-BERT: A Unified Perturbation-Robust Framework with Noise Alignment Pre-training for Noisy Slot Filling Task,"Jinxu Zhao, Guanting Dong, Yueyan Qiu, Tingfeng Hui, Xiaoshuai Song, Daichi Guo, Weiran Xu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14494"" target=""_blank"">2402.14494</a>",,2024-12-11
A Trembling House of Cards? Mapping Adversarial Attacks against Language Agents,"Lingbo Mo, Zeyi Liao, Boyuan Zheng, Yu Su, Chaowei Xiao, Huan Sun",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10196"" target=""_blank"">2402.10196</a>",,2024-12-11
FedRDF: A Robust and Dynamic Aggregation Function against Poisoning Attacks in Federated Learning,"Enrique MÃ¡rmol Campos, Aurora GonzÃ¡lez Vidal, JosÃ© Luis HernÃ¡ndez Ramos, Antonio Skarmeta",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10082"" target=""_blank"">2402.10082</a>",,2024-12-11
Exploring the Adversarial Capabilities of Large Language Models,"Lukas Struppek, Minh Hieu Le, Dominik Hintersdorf, Kristian Kersting",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09132"" target=""_blank"">2402.09132</a>",,2024-12-11
Quantum-Inspired Analysis of Neural Network Vulnerabilities: The Role of Conjugate Variables in System Attacks,"Jun-Jie Zhang, Deyu Meng",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10983"" target=""_blank"">2402.10983</a>",,2024-12-11
Robustness and Exploration of Variational and Machine Learning Approaches to Inverse Problems: An Overview,"Alexander Auras, Kanchana Vaishnavi Gandikota, Hannah Droege, Michael Moeller",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12072"" target=""_blank"">2402.12072</a>",,2024-12-11
VQAttack: Transferable Adversarial Attacks on Visual Question Answering via Pre-trained Models,"Ziyi Yin, Muchao Ye, Tianrong Zhang, Jiaqi Wang, Han Liu, Jinghui Chen, Ting Wang, Fenglong Ma",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11083"" target=""_blank"">2402.11083</a>",,2024-12-11
Robust CLIP: Unsupervised Adversarial Fine-Tuning of Vision Embeddings for Robust Large Vision-Language Models,"Christian Schlarmann, Naman Deep Singh, Francesco Croce, Matthias Hein",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12336"" target=""_blank"">2402.12336</a>","<a href=""https://github.com/chs20/RobustVLM"" target=""_blank"">chs20</a>",2024-12-11
Investigating the Impact of Model Instability on Explanations and Uncertainty,"Sara Vera MarjanoviÄ, Isabelle Augenstein, Christina Lioma",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13006"" target=""_blank"">2402.13006</a>",,2024-12-11
A Simple and Yet Fairly Effective Defense for Graph Neural Networks,"Sofiane Ennadir, Yassine Abbahaddou, Johannes F. Lutzeyer, Michalis Vazirgiannis, Henrik BostrÃ¶m",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13987"" target=""_blank"">2402.13987</a>","<a href=""https://github.com/Sennadir/NoisyGNN"" target=""_blank"">Sennadir</a>",2024-12-11
Adversarial Purification and Fine-tuning for Robust UDC Image Restoration,"Zhenbo Song, Zhenyuan Zhang, Kaihao Zhang, Wenhan Luo, Zhaoxin Fan, Jianfeng Lu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13629"" target=""_blank"">2402.13629</a>",,2024-12-11
Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment,"Vyas Raina, Adian Liusie, Mark Gales",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14016"" target=""_blank"">2402.14016</a>",,2024-12-11
Self-Guided Robust Graph Structure Refinement,"Yeonjun In, Kanghoon Yoon, Kibum Kim, Kijung Shin, Chanyoung Park",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11837"" target=""_blank"">2402.11837</a>","<a href=""https://github.com/yeonjun-in/torch-SG-GSR"" target=""_blank"">yeonjun-in</a>",2024-12-11
AttackGNN: Red-Teaming GNNs in Hardware Security Using Reinforcement Learning,"Vasudev Gohil, Satwik Patnaik, Dileep Kalathil, Jeyavijayan Rajendran",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13946"" target=""_blank"">2402.13946</a>",,2024-12-11
Robustness of Deep Neural Networks for Micro-Doppler Radar Classification,"Mikolaj Czerkawski, Carmine Clemente, Craig MichieCraig Michie, Christos Tachtatzis",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13651"" target=""_blank"">2402.13651</a>",,2024-12-11
Flexible Physical Camouflage Generation Based on a Differential Approach,"Yang Li, Wenyi Tan, Chenxing Zhao, Shuangju Zhou, Xinkai Liang, Quan Pan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13575"" target=""_blank"">2402.13575</a>",,2024-12-11
Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs,"Xiaoxia Li, Siyuan Liang, Jiyi Zhang, Han Fang, Aishan Liu, Ee-Chien Chang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14872"" target=""_blank"">2402.14872</a>",,2024-12-11
Coercing LLMs to do and reveal (almost) anything,"Jonas Geiping, Alex Stein, Manli Shu, Khalid Saifullah, Yuxin Wen, Tom Goldstein",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14020"" target=""_blank"">2402.14020</a>",,2024-12-11
T-Stitch: Accelerating Sampling in Pre-Trained Diffusion Models with Trajectory Stitching,"Zizheng Pan, Bohan Zhuang, De-An Huang, Weili Nie, Zhiding Yu, Chaowei Xiao, Jianfei Cai, Anima Anandkumar",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14167"" target=""_blank"">2402.14167</a>","<a href=""https://github.com/NVlabs/T-Stitch"" target=""_blank"">NVlabs</a>",2024-12-11
QuanTest: Entanglement-Guided Testing of Quantum Neural Network Systems,"Jinjing Shi, Zimeng Xiao, Heyuan Shi, Yu Jiang, Xuelong Li",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12950"" target=""_blank"">2402.12950</a>",,2024-12-11
Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment,"Jiongxiao Wang, Jiazhao Li, Yiquan Li, Xiangyu Qi, Junjie Hu, Yixuan Li, Patrick McDaniel, Muhao Chen, Bo Li, Chaowei Xiao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14968"" target=""_blank"">2402.14968</a>",,2024-12-11
Defending Jailbreak Prompts via In-Context Adversarial Game,"Yujun Zhou, Yufei Han, Haomin Zhuang, Taicheng Guo, Kehan Guo, Zhenwen Liang, Hongyan Bao, Xiangliang Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13148"" target=""_blank"">2402.13148</a>",,2024-12-11
Round Trip Translation Defence against Large Language Model Jailbreaking Attacks,"Canaan Yung, Hadi Mohaghegh Dolatabadi, Sarah Erfani, Christopher Leckie",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13517"" target=""_blank"">2402.13517</a>","<a href=""https://github.com/Cancanxxx/Round_Trip_Translation_Defence"" target=""_blank"">Cancanxxx</a>",2024-12-11
VL-Trojan: Multimodal Instruction Backdoor Attacks against Autoregressive Visual Language Models,"Jiawei Liang, Siyuan Liang, Man Luo, Aishan Liu, Dongchen Han, Ee-Chien Chang, Xiaochun Cao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13851"" target=""_blank"">2402.13851</a>",,2024-12-11
A Comprehensive Study of Jailbreak Attack versus Defense for Large Language Models,"Zihao Xu, Yi Liu, Gelei Deng, Yuekang Li, Stjepan Picek",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13457"" target=""_blank"">2402.13457</a>",,2024-12-11
AICAttack: Adversarial Image Captioning Attack with Attention-Based Optimization,"Jiyao Li, Mingze Ni, Yifei Dong, Tianqing Zhu, Wei Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11940"" target=""_blank"">2402.11940</a>",,2024-12-11
Learning to Poison Large Language Models During Instruction Tuning,"Yao Qiang, Xiangyu Zhou, Saleh Zare Zade, Mohammad Amin Roshani, Douglas Zytko, Dongxiao Zhu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13459"" target=""_blank"">2402.13459</a>",,2024-12-11
Stealing the Invisible: Unveiling Pre-Trained CNN Models through Adversarial Examples and Timing Side-Channels,"Shubhi Shukla, Manaar Alam, Pabitra Mitra, Debdeep Mukhopadhyay",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11953"" target=""_blank"">2402.11953</a>",,2024-12-11
An Adversarial Approach to Evaluating the Robustness of Event Identification Models,"Obai Bahwal, Oliver Kosut, Lalitha Sankar",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12338"" target=""_blank"">2402.12338</a>",,2024-12-11
Attacks on Node Attributes in Graph Neural Networks,"Ying Xu, Michael Lanier, Anindya Sarkar, Yevgeniy Vorobeychik",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12426"" target=""_blank"">2402.12426</a>",,2024-12-11
Indiscriminate Data Poisoning Attacks on Pre-trained Feature Extractors,"Yiwei Lu, Matthew Y. R. Yang, Gautam Kamath, Yaoliang Yu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12626"" target=""_blank"">2402.12626</a>",,2024-12-11
Adversarial Feature Alignment: Balancing Robustness and Accuracy in Deep Learning via Adversarial Training,"Leo Hyun Park, Jaeuk Kim, Myung Gyo Oh, Jaewoo Park, Taekyoung Kwon",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12187"" target=""_blank"">2402.12187</a>",,2024-12-11
Query-Based Adversarial Prompt Generation,"Jonathan Hayase, Ema Borevkovic, Nicholas Carlini, Florian TramÃ¨r, Milad Nasr",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12329"" target=""_blank"">2402.12329</a>",,2024-12-11
RITFIS: Robust input testing framework for LLMs-based intelligent software,"Mingxuan Xiao, Yan Xiao, Hai Dong, Shunhui Ji, Pengcheng Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13518"" target=""_blank"">2402.13518</a>",,2024-12-11
The Wolf Within: Covert Injection of Malice into MLLM Societies via an MLLM Operative,"Zhen Tan, Chengshuai Zhao, Raha Moraffah, Yifan Li, Yu Kong, Tianlong Chen, Huan Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14859"" target=""_blank"">2402.14859</a>",,2024-12-11
Stealthy Adversarial Attacks on Stochastic Multi-Armed Bandits,"Zhiwei Wang, Huazheng Wang, Hongning Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13487"" target=""_blank"">2402.13487</a>",,2024-12-11
Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies,"Xiangyu Liu, Chenghao Deng, Yanchao Sun, Yongyuan Liang, Furong Huang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12673"" target=""_blank"">2402.12673</a>",,2024-12-11
Can We Trust the Unlabeled Target Data? Towards Backdoor Attack and Defense on Model Adaptation,"Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06030"" target=""_blank"">2401.06030</a>",,2024-12-11
Manipulating Feature Visualizations with Gradient Slingshots,"Dilyara Bareeva, Marina M. -C. HÃ¶hne, Alexander Warnecke, Lukas Pirch, Klaus-Robert MÃ¼ller, Konrad Rieck, Kirill Bykov",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06122"" target=""_blank"">2401.06122</a>",,2024-12-11
Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training,"Evan Hubinger, Carson Denison, Jesse Mu, Mike Lambert, Meg Tong, Monte MacDiarmid, Tamera Lanham, Daniel M. Ziegler, Tim Maxwell, Newton Cheng, Adam Jermyn, Amanda Askell, Ansh Radhakrishnan, Cem Anil, David Duvenaud, Deep Ganguli, Fazl Barez, Jack Clark, Kamal Ndousse, Kshitij Sachan, Michael Sellitto, Mrinank Sharma, Nova DasSarma, Roger Grosse, Shauna Kravec, Yuntao Bai, Zachary Witten, Marina Favaro, Jan Brauner, Holden Karnofsky, Paul Christiano, Samuel R. Bowman, Logan Graham, Jared Kaplan, SÃ¶ren Mindermann, Ryan Greenblatt, Buck Shlegeris, Nicholas Schiefer, Ethan Perez",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05566"" target=""_blank"">2401.05566</a>",,2024-12-11
Combating Adversarial Attacks with Multi-Agent Debate,"Steffi Chern, Zhen Fan, Andy Liu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05998"" target=""_blank"">2401.05998</a>",,2024-12-11
Exploring Vulnerabilities of No-Reference Image Quality Assessment Models: A Query-Based Black-Box Method,"Chenxi Yang, Yujia Liu, Dingquan Li, Tingting Jiang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05217"" target=""_blank"">2401.05217</a>",,2024-12-11
TrustLLM: Trustworthiness in Large Language Models,"Lichao Sun, Yue Huang, Haoran Wang, Siyuan Wu, Qihui Zhang, Chujie Gao, Yixin Huang, Wenhan Lyu, Yixuan Zhang, Xiner Li, Zhengliang Liu, Yixin Liu, Yijue Wang, Zhikun Zhang, Bhavya Kailkhura, Caiming Xiong, Chaowei Xiao, Chunyuan Li, Eric Xing, Furong Huang, Hao Liu, Heng Ji, Hongyi Wang, Huan Zhang, Huaxiu Yao, Manolis Kellis, Marinka Zitnik, Meng Jiang, Mohit Bansal, James Zou, Jian Pei, Jian Liu, Jianfeng Gao, Jiawei Han, Jieyu Zhao, Jiliang Tang, Jindong Wang, John Mitchell, Kai Shu, Kaidi Xu, Kai-Wei Chang, Lifang He, Lifu Huang, Michael Backes, Neil Zhenqiang Gong, Philip S. Yu, Pin-Yu Chen, Quanquan Gu, Ran Xu, Rex Ying, Shuiwang Ji, Suman Jana, Tianlong Chen, Tianming Liu, Tianyi Zhou, Willian Wang, Xiang Li, Xiangliang Zhang, Xiao Wang, Xing Xie, Xun Chen, Xuyu Wang, Yan Liu, Yanfang Ye, Yinzhi Cao, Yong Chen, Yue Zhao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05561"" target=""_blank"">2401.05561</a>",,2024-12-11
SENet: Visual Detection of Online Social Engineering Attack Campaigns,"Irfan Ozen, Karthika Subramani, Phani Vadrevu, Roberto Perdisci",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05569"" target=""_blank"">2401.05569</a>",,2024-12-11
Revisiting Adversarial Training at Scale,"Zeyu Wang, Xianhang Li, Hongru Zhu, Cihang Xie",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04727"" target=""_blank"">2401.04727</a>","<a href=""https://github.com/UCSC-VLAA/AdvXL"" target=""_blank"">UCSC-VLAA</a>",2024-12-11
CoLafier: Collaborative Noisy Label Purifier With Local Intrinsic Dimensionality Guidance,"Dongyu Zhang, Ruofan Hu, Elke Rundensteiner",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05458"" target=""_blank"">2401.05458</a>","<a href=""https://github.com/zdy93/CoLafier"" target=""_blank"">zdy93</a>",2024-12-11
Brave: Byzantine-Resilient and Privacy-Preserving Peer-to-Peer Federated Learning,"Zhangchen Xu, Fengqing Jiang, Luyao Niu, Jinyuan Jia, Radha Poovendran",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05562"" target=""_blank"">2401.05562</a>",,2024-12-11
FBSDetector: Fake Base Station and Multi Step Attack Detection in Cellular Networks using Machine Learning,"Kazi Samin Mubasshir, Imtiaz Karim, Elisa Bertino",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04958"" target=""_blank"">2401.04958</a>",,2024-12-11
SoK: Facial Deepfake Detectors,"Binh M. Le, Jiwon Kim, Shahroz Tariq, Kristen Moore, Alsharif Abuadbba, Simon S. Woo",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04364"" target=""_blank"">2401.04364</a>",,2024-12-11
Advancing Ante-Hoc Explainable Models through Generative Adversarial Networks,"Tanmay Garg, Deepika Vemuri, Vineeth N Balasubramanian",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04647"" target=""_blank"">2401.04647</a>",,2024-12-11
Pre-trained Model Guided Fine-Tuning for Zero-Shot Adversarial Robustness,"Sibo Wang, Jie Zhang, Zheng Yuan, Shiguang Shan",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04350"" target=""_blank"">2401.04350</a>","<a href=""https://github.com/serendipity1122/Pre-trained-Model-Guided-Fine-Tuning-for-Zero-Shot-Adversarial-Robustness"" target=""_blank"">serendipity1122</a>",2024-12-11
Coupling Graph Neural Networks with Fractional Order Continuous Dynamics: A Robustness Study,"Qiyu Kang, Kai Zhao, Yang Song, Yihang Xie, Yanan Zhao, Sijie Wang, Rui She, Wee Peng Tay",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04331"" target=""_blank"">2401.04331</a>",,2024-12-11
Logits Poisoning Attack in Federated Distillation,"Yuhan Tang, Zhiyuan Wu, Bo Gao, Tian Wen, Yuwei Wang, Sheng Sun",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.03685"" target=""_blank"">2401.03685</a>",,2024-12-11
Attack-Resilient Image Watermarking Using Stable Diffusion,"Lijun Zhang, Xiao Liu, Antoni Viros Martin, Cindy Xiong Bearfield, Yuriy Brun, Hui Guan",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04247"" target=""_blank"">2401.04247</a>","<a href=""https://github.com/zhanglijun95/ZoDiac"" target=""_blank"">zhanglijun95</a>",2024-12-11
Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks,"Shuai Zhao, Meihuizi Jia, Luu Anh Tuan, Jinming Wen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05949"" target=""_blank"">2401.05949</a>",,2024-12-11
Open the Pandora's Box of LLMs: Jailbreaking LLMs through Representation Engineering,"Tianlong Li, Shihan Dou, Wenhao Liu, Muling Wu, Changze Lv, Xiaoqing Zheng, Xuanjing Huang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06824"" target=""_blank"">2401.06824</a>",,2024-12-11
Authorship Obfuscation in Multilingual Machine-Generated Text Detection,"Dominik Macko, Robert Moro, Adaku Uchendu, Ivan Srba, Jason Samuel Lucas, Michiharu Yamashita, Nafis Irtiza Tripto, Dongwon Lee, Jakub Simko, Maria Bielikova",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.07867"" target=""_blank"">2401.07867</a>",,2024-12-11
GE-AdvGAN: Improving the transferability of adversarial samples by gradient editing-based adversarial generative model,"Zhiyu Zhu, Huaming Chen, Xinyi Wang, Jiayu Zhang, Zhibo Jin, Kim-Kwang Raymond Choo, Jun Shen, Dong Yuan",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06031"" target=""_blank"">2401.06031</a>","<a href=""https://github.com/LMBTough/GE-advGAN"" target=""_blank"">LMBTough</a>",2024-12-11
Intention Analysis Makes LLMs A Good Jailbreak Defender,"Yuqi Zhang, Liang Ding, Lefei Zhang, Dacheng Tao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06561"" target=""_blank"">2401.06561</a>","<a href=""https://github.com/alphadl/SafeLLM_with_IntentionAnalysis"" target=""_blank"">alphadl</a>",2024-12-11
Bag of Tricks to Boost Adversarial Transferability,"Zeliang Zhang, Rongyi Zhu, Wei Yao, Xiaosen Wang, Chenliang Xu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08734"" target=""_blank"">2401.08734</a>",,2024-12-11
Invisible Reflections: Leveraging Infrared Laser Reflections to Target Traffic Sign Perception,"Takami Sato, Sri Hrushikesh Varma Bhupathiraju, Michael Clifford, Takeshi Sugawara, Qi Alfred Chen, Sara Rampazzi",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.03582"" target=""_blank"">2401.03582</a>",,2024-12-11
A Generative Adversarial Attack for Multilingual Text Classifiers,"Tom Roth, Inigo Jauregi Unanue, Alsharif Abuadbba, Massimo Piccardi",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08255"" target=""_blank"">2401.08255</a>",,2024-12-11
PPR: Enhancing Dodging Attacks while Maintaining Impersonation Attacks on Face Recognition Systems,"Fengfan Zhou, Heifei Ling",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08903"" target=""_blank"">2401.08903</a>",,2024-12-11
Robust Localization of Key Fob Using Channel Impulse Response of Ultra Wide Band Sensors for Keyless Entry Systems,"Abhiram Kolli, Filippo Casamassima, Horst Possegger, Horst Bischof",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08863"" target=""_blank"">2401.08863</a>",,2024-12-11
The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images,"Nicholas Konz, Maciej A. Mazurowski",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08865"" target=""_blank"">2401.08865</a>","<a href=""https://github.com/mazurowski-lab/intrinsic-properties"" target=""_blank"">mazurowski-lab</a>",2024-12-11
RandOhm: Mitigating Impedance Side-channel Attacks using Randomized Circuit Configurations,"Saleh Khalaj Monfared, Domenic Forte, Shahin Tajik",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08925"" target=""_blank"">2401.08925</a>",,2024-12-11
Towards Efficient and Certified Recovery from Poisoning Attacks in Federated Learning,"Yu Jiang, Jiyuan Shen, Ziyao Liu, Chee Wei Tan, Kwok-Yan Lam",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08216"" target=""_blank"">2401.08216</a>",,2024-12-11
IPR-NeRF: Ownership Verification meets Neural Radiance Field,"Win Kent Ong, Kam Woh Ng, Chee Seng Chan, Yi Zhe Song, Tao Xiang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09495"" target=""_blank"">2401.09495</a>",,2024-12-11
IoTWarden: A Deep Reinforcement Learning Based Real-time Defense System to Mitigate Trigger-action IoT Attacks,"Md Morshed Department of Software and Information Systems, University of North Carolina at Charlotte, Charlotte, USA Alam, Israt Department of Computer Science, University of Memphis, Memphis, USA Jahan, Weichao Department of Software and Information Systems, University of North Carolina at Charlotte, Charlotte, USA Wang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08141"" target=""_blank"">2401.08141</a>",,2024-12-11
Robustness Against Adversarial Attacks via Learning Confined Adversarial Polytopes,"Shayan Mohajer Hamidi, Linfeng Ye",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.07991"" target=""_blank"">2401.07991</a>",,2024-12-11
LookAhead: Preventing DeFi Attacks via Unveiling Adversarial Contracts,"Shoupeng Ren, Lipeng He, Tianyu Tu, Di Wu, Jian Liu, Kui Ren, Chun Chen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.07261"" target=""_blank"">2401.07261</a>",,2024-12-11
Crafter: Facial Feature Crafting against Inversion-based Identity Theft on Deep Models,"Shiming Wang, Zhe Ji, Liyao Xiang, Hao Zhang, Xinbing Wang, Chenghu Zhou, Bo Li",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.07205"" target=""_blank"">2401.07205</a>",,2024-12-11
Exploring Adversarial Attacks against Latent Diffusion Model from the Perspective of Adversarial Transferability,"Junxi Chen, Junhao Dong, Xiaohua Xie",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.07087"" target=""_blank"">2401.07087</a>",,2024-12-11
Left-right Discrepancy for Adversarial Attack on Stereo Networks,"Pengfei Wang, Xiaofei Hui, Beijia Lu, Nimrod Lilith, Jun Liu, Sameer Alam",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.07188"" target=""_blank"">2401.07188</a>",,2024-12-11
Adversarial Examples are Misaligned in Diffusion Model Manifolds,"Peter Lorenz, Ricard Durall, Janis Keuper",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06637"" target=""_blank"">2401.06637</a>",,2024-12-11
How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs,"Yi Zeng, Hongpeng Lin, Jingwen Zhang, Diyi Yang, Ruoxi Jia, Weiyan Shi",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06373"" target=""_blank"">2401.06373</a>",,2024-12-11
Enhancing Consistency and Mitigating Bias: A Data Replay Approach for Incremental Learning,"Chenyang Wang, Junjun Jiang, Xingyu Hu, Xianming Liu, Xiangyang Ji",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06548"" target=""_blank"">2401.06548</a>",,2024-12-11
An Analytical Framework for Modeling and Synthesizing Malicious Attacks on ACC Vehicles,Shian Wang,arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06916"" target=""_blank"">2401.06916</a>",,2024-12-11
Dense Hopfield Networks in the Teacher-Student Setting,"Robin ThÃ©riault, Daniele Tantari",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04191"" target=""_blank"">2401.04191</a>",,2024-12-11
Will 6G be Semantic Communications? Opportunities and Challenges from Task Oriented and Secure Communications to Integrated Sensing,"Yalin E. Sagduyu, Tugba Erpek, Aylin Yener, Sennur Ulukus",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01531"" target=""_blank"">2401.01531</a>",,2024-12-11
Data-Driven Subsampling in the Presence of an Adversarial Actor,"Abu Shafin Mohammad Mahdee Jameel, Ahmed P. Mohamed, Jinho Yi, Aly El Gamal, Akshay Malhotra",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.03488"" target=""_blank"">2401.03488</a>",,2024-12-11
Is It Possible to Backdoor Face Forgery Detection with Natural Triggers? (68%),"Xiaoxuan Han, Songlin Yang, Wei Wang, Ziwen He, Jing Dong",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00414"" target=""_blank"">2401.00414</a>",,2024-12-11
Dual Teacher Knowledge Distillation with Domain Alignment for Face Anti-spoofing,"Zhe Kong, Wentian Zhang, Tao Wang, Kaihao Zhang, Yuexiang Li, Xiaoying Tang, Wenhan Luo",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01102"" target=""_blank"">2401.01102</a>",,2024-12-11
Unveiling the Stealthy Threat: Analyzing Slow Drift GPS Spoofing Attacks for Autonomous Vehicles in Urban Environments and Enabling the Resilience,"Sagar Dasgupta, Abdullah Ahmed, Mizanur Rahman, Thejesh N. Bandi",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01394"" target=""_blank"">2401.01394</a>",,2024-12-11
Imperio: Language-Guided Backdoor Attacks for Arbitrary Model Control,"Ka-Ho Chow, Wenqi Wei, Lei Yu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01085"" target=""_blank"">2401.01085</a>",,2024-12-11
"Safety and Performance, Why Not Both? Bi-Objective Optimized Model Compression against Heterogeneous Attacks Toward AI Software Deployment","Jie Zhu, Leye Wang, Xiao Han, Anmin Liu, Tao Xie",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00996"" target=""_blank"">2401.00996</a>",,2024-12-11
Detection and Defense Against Prominent Attacks on Preconditioned LLM-Integrated Virtual Assistants,"Chun Fai Chan, Daniel Wankit Yip, Aysan Esmradi",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00994"" target=""_blank"">2401.00994</a>",,2024-12-11
A Novel Evaluation Framework for Assessing Resilience Against Prompt Injection Attacks in Large Language Models,"Daniel Wankit Yip, Aysan Esmradi, Chun Fai Chan",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00991"" target=""_blank"">2401.00991</a>",,2024-12-11
AR-GAN: Generative Adversarial Network-Based Defense Method Against Adversarial Attacks on the Traffic Sign Classification System of Autonomous Vehicles,"M Sabbir Salek, Abdullah Al Mamun, Mashrur Chowdhury",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14232"" target=""_blank"">2401.14232</a>",,2024-12-11
Does Few-shot Learning Suffer from Backdoor Attacks? (98%),"Xinwei Liu, Xiaojun Jia, Jindong Gu, Yuan Xun, Siyuan Liang, Xiaochun Cao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01377"" target=""_blank"">2401.01377</a>",,2024-12-11
Explainability-Driven Leaf Disease Classification using Adversarial Training and Knowledge Distillation,"Sebastian-Vasile Echim, Iulian-Marius TÄiatu, Dumitru-Clementin Cercel, Florin Pop",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00334"" target=""_blank"">2401.00334</a>",,2024-12-11
Enhancing Generalization of Invisible Facial Privacy Cloak via Gradient Accumulation,"Xuannan Liu, Yaoyao Zhong, Weihong Deng, Hongzhi Shi, Xingchen Cui, Yunfeng Yin, Dongchao Wen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01575"" target=""_blank"">2401.01575</a>",,2024-12-11
CamPro: Camera-based Anti-Facial Recognition,"Wenjun Zhu, Yuan Sun, Jiani Liu, Yushi Cheng, Xiaoyu Ji, Wenyuan Xu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00151"" target=""_blank"">2401.00151</a>",,2024-12-11
TPatch: A Triggered Physical Adversarial Patch,"Wenjun Zhu, Xiaoyu Ji, Yushi Cheng, Shibo Zhang, Wenyuan Xu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00148"" target=""_blank"">2401.00148</a>",,2024-12-11
A clean-label graph backdoor attack method in node classification task,"Xiaogang Xing, Ming Xu, Yujing Bai, Dongdong Yang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00163"" target=""_blank"">2401.00163</a>",,2024-12-11
Reputation-Based Federated Learning Defense to Mitigate Threats in EEG Signal Classification,"Zhibo Zhang, Pengfei Li, Ahmed Y. Al Hammadi, Fusen Guo, Ernesto Damiani, Chan Yeob Yeun",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01896"" target=""_blank"">2401.01896</a>",,2024-12-11
SSL-OTA: Unveiling Backdoor Threats in Self-Supervised Learning for Object Detection,"Qiannan Wang, Changchun Yin, Lu Zhou, Liming Fang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00137"" target=""_blank"">2401.00137</a>",,2024-12-11
STR-Cert: Robustness Certification for Deep Text Recognition on Deep Learning Pipelines and Vision Transformers,"Daqian Shao, Lukas Fesser, Marta Kwiatkowska",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05338"" target=""_blank"">2401.05338</a>",,2024-12-11
Resilient Path Planning for UAVs in Data Collection under Adversarial Attacks,"Xueyuan Wang, M. Cenk Gursoy",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08634"" target=""_blank"">2401.08634</a>",,2024-12-11
"Caught in the Quicksand of Reasoning, Far from AGI Summit: Evaluating LLMs' Mathematical and Coding Competency through Ontology-guided Interventions","Pengfei Hong, Deepanway Ghosal, Navonil Majumder, Somak Aditya, Rada Mihalcea, Soujanya Poria",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09395"" target=""_blank"">2401.09395</a>","<a href=""https://github.com/declare-lab/llm_robustness"" target=""_blank"">declare-lab</a>",2024-12-11
JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example,"Benedetta Tondi, Wei Guo, Mauro Barni",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01199"" target=""_blank"">2401.01199</a>",,2024-12-11
Integrated Cyber-Physical Resiliency for Power Grids under IoT-Enabled Dynamic Botnet Attacks,"Yuhan Zhao, Juntao Chen, Quanyan Zhu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01963"" target=""_blank"">2401.01963</a>",,2024-12-11
ROIC-DM: Robust Text Inference and Classification via Diffusion Model,"Shilong Yuan, Wei Yuan, Hongzhi Yin, Tieke He",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.03514"" target=""_blank"">2401.03514</a>",,2024-12-11
Vulnerabilities Unveiled: Adversarially Attacking a Multimodal Vision Langauge Model for Pathology Imaging,"Jai Prakash Veerla, Poojitha Thota, Partha Sai Guttikonda, Shirin Nilizadeh, Jacob M. Luber",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02565"" target=""_blank"">2401.02565</a>",,2024-12-11
Data-Dependent Stability Analysis of Adversarial Training,"Yihan Wang, Shuang Liu, Xiao-Shan Gao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.03156"" target=""_blank"">2401.03156</a>",,2024-12-11
End-to-End Anti-Backdoor Learning on Images and Time Series,"Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, Yige Li, James Bailey",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.03215"" target=""_blank"">2401.03215</a>",,2024-12-11
Transferable Learned Image Compression-Resistant Adversarial Perturbations,"Yang Sui, Zhuohang Li, Ding Ding, Xiang Pan, Xiaozhong Xu, Shan Liu, Zhenzhong Chen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.03115"" target=""_blank"">2401.03115</a>",,2024-12-11
Enhancing targeted transferability via feature space fine-tuning,"Hui Zeng, Biwei Chen, Anjie Peng",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02727"" target=""_blank"">2401.02727</a>",,2024-12-11
Calibration Attack: A Framework For Adversarial Attacks Targeting Calibration,"Stephen Obadinma, Xiaodan Zhu, Hongyu Guo",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02718"" target=""_blank"">2401.02718</a>",,2024-12-11
A backdoor attack against link prediction tasks with graph neural networks,"Jiazhu Dai, Haoyu Sun",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02663"" target=""_blank"">2401.02663</a>",,2024-12-11
TEN-GUARD: Tensor Decomposition for Backdoor Attack Detection in Deep Neural Networks,"Khondoker Murad Hossain, Tim Oates",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05432"" target=""_blank"">2401.05432</a>",,2024-12-11
MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance,"Renjie Pi, Tianyang Han, Yueqi Xie, Rui Pan, Qing Lian, Hanze Dong, Jipeng Zhang, Tong Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02906"" target=""_blank"">2401.02906</a>",,2024-12-11
A Random Ensemble of Encrypted models for Enhancing Robustness against Adversarial Examples,"Ryota Iijima, Sayaka Shiota, Hitoshi Kiya",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02633"" target=""_blank"">2401.02633</a>",,2024-12-11
FullLoRA-AT: Efficiently Boosting the Robustness of Pretrained Vision Transformers,"Zheng Yuan, Jie Zhang, Shiguang Shan",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01752"" target=""_blank"">2401.01752</a>",,2024-12-11
AdvSQLi: Generating Adversarial SQL Injections against Real-world WAF-as-a-service,"Zhenqing Qu, Xiang Ling, Ting Wang, Xiang Chen, Shouling Ji, Chunming Wu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02615"" target=""_blank"">2401.02615</a>",,2024-12-11
Evasive Hardware Trojan through Adversarial Power Trace,"Behnam Omidi, Khaled N. Khasawneh, Ihsen Alouani",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02342"" target=""_blank"">2401.02342</a>",,2024-12-11
Object-oriented backdoor attack against image captioning,"Meiling Li, Nan Zhong, Xinpeng Zhang, Zhenxing Qian, Sheng Li",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02600"" target=""_blank"">2401.02600</a>",,2024-12-11
DEM: A Method for Certifying Deep Neural Network Classifier Outputs in Aerospace,"Guy Katz, Natan Levy, Idan Refaeli, Raz Yerushalmi",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02283"" target=""_blank"">2401.02283</a>",,2024-12-11
Secure Control of Connected and Automated Vehicles Using Trust-Aware Robust Event-Triggered Control Barrier Functions,"H M Sabbir Ahmad, Ehsan Sabouni, Akua Dickson, Wei Xiao, Christos G. Cassandras, Wenchao Li",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02306"" target=""_blank"">2401.02306</a>",,2024-12-11
A Survey Analyzing Generalization in Deep Reinforcement Learning,Ezgi Korkmaz,arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02349"" target=""_blank"">2401.02349</a>",,2024-12-11
Towards Robust Semantic Segmentation against Patch-based Attack via Attention Refinement,"Zheng Yuan, Jie Zhang, Yude Wang, Shiguang Shan, Xilin Chen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01750"" target=""_blank"">2401.01750</a>",,2024-12-11
Spy-Watermark: Robust Invisible Watermarking for Backdoor Attack,"Ruofei Wang, Renjie Wan, Zongyu Guo, Qing Guo, Rui Huang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02031"" target=""_blank"">2401.02031</a>",,2024-12-11
Revealing Vulnerabilities in Stable Diffusion via Targeted Attacks,"Chenyu Zhang, Lanjun Wang, Anan Liu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08725"" target=""_blank"">2401.08725</a>","<a href=""https://github.com/datar001/Revealing-Vulnerabilities-in-Stable-Diffusion-via-Targeted-Attacks"" target=""_blank"">datar001</a>",2024-12-11
Adapters Mixup: Mixing Parameter-Efficient Adapters to Enhance the Adversarial Robustness of Fine-tuned Pre-trained Text Classifiers,"Tuc Nguyen, Thai Le",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10111"" target=""_blank"">2401.10111</a>",,2024-12-11
Attack and Reset for Unlearning: Exploiting Adversarial Noise toward Machine Unlearning through Parameter Re-initialization,"Yoonhwa Jung, Ikhyun Cho, Shun-Hsiang Hsu, Julia Hockenmaier",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08998"" target=""_blank"">2401.08998</a>",,2024-12-11
Boosting the Transferability of Adversarial Examples via Local Mixup and Adaptive Step Size,"Junlin Liu, Xinchen Lyu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.13205"" target=""_blank"">2401.13205</a>",,2024-12-11
L-AutoDA: Leveraging Large Language Models for Automated Decision-based Adversarial Attacks,"Ping Guo, Fei Liu, Xi Lin, Qingchuan Zhao, Qingfu Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15335"" target=""_blank"">2401.15335</a>",,2024-12-11
Set-Based Training for Neural Network Verification,"Lukas Koller, Tobias Ladner, Matthias Althoff",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14961"" target=""_blank"">2401.14961</a>",,2024-12-11
Mitigating Feature Gap for Adversarial Robustness by Feature Disentanglement,"Nuoyan Zhou, Dawei Zhou, Decheng Liu, Xinbo Gao, Nannan Wang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14707"" target=""_blank"">2401.14707</a>",,2024-12-11
"Multi-Trigger Backdoor Attacks: More Triggers, More Threats","Yige Li, Xingjun Ma, Jiabo He, Hanxun Huang, Yu-Gang Jiang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15295"" target=""_blank"">2401.15295</a>",,2024-12-11
Adversarial Attacks and Defenses in 6G Network-Assisted IoT Systems,"Bui Duc Son, Nguyen Tien Hoa, Chien Trinh Van, Waqas Khalid, Mohamed Amine Ferrag, Wan Choi, Merouane Debbah",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14780"" target=""_blank"">2401.14780</a>",,2024-12-11
Conserve-Update-Revise to Cure Generalization and Robustness Trade-off in Adversarial Training,"Shruthi Gowda, Bahram Zonooz, Elahe Arani",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14948"" target=""_blank"">2401.14948</a>",,2024-12-11
Asymptotic Behavior of Adversarial Training Estimator under $\ell_\infty$-Perturbation,"Yiling Xie, Xiaoming Huo",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15262"" target=""_blank"">2401.15262</a>",,2024-12-11
Better Representations via Adversarial Training in Pre-Training: A Theoretical Perspective,"Yue Xing, Xiaofeng Lin, Qifan Song, Yi Xu, Belinda Zeng, Guang Cheng",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15248"" target=""_blank"">2401.15248</a>",,2024-12-11
MEA-Defender: A Robust Watermark against Model Extraction Attack,"Peizhuo Lv, Hualong Ma, Kai Chen, Jiachen Zhou, Shengzhi Zhang, Ruigang Liang, Shenchen Zhu, Pan Li, Yingjun Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15239"" target=""_blank"">2401.15239</a>",,2024-12-11
BackdoorBench: A Comprehensive Benchmark and Analysis of Backdoor Learning,"Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Mingli Zhu, Ruotong Wang, Li Liu, Chao Shen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15002"" target=""_blank"">2401.15002</a>",,2024-12-11
Sparse and Transferable Universal Singular Vectors Attack,"Kseniia Kuvshinova, Olga Tsymboi, Ivan Oseledets",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14031"" target=""_blank"">2401.14031</a>",,2024-12-11
Friendly Attacks to Improve Channel Coding Reliability,"Anastasiia Kurmukova, Deniz Gunduz",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14184"" target=""_blank"">2401.14184</a>",,2024-12-11
Semantic Sensitivities and Inconsistent Predictions: Measuring the Fragility of NLI Models,"Erik Arakelyan, Zhaoqi Liu, Isabelle Augenstein",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14440"" target=""_blank"">2401.14440</a>",,2024-12-11
The Risk of Federated Learning to Skew Fine-Tuning Features and Underperform Out-of-Distribution Robustness,"Mengyao Du, Miao Zhang, Yuwen Pu, Kai Xu, Shouling Ji, Quanjun Yin",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14027"" target=""_blank"">2401.14027</a>",,2024-12-11
Novel Quadratic Constraints for Extending LipSDP beyond Slope-Restricted Activations,"Patricia Pauli, Aaron Havens, Alexandre Araujo, Siddharth Garg, Farshad Khorrami, Frank AllgÃ¶wer, Bin Hu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14033"" target=""_blank"">2401.14033</a>",,2024-12-11
Physical Trajectory Inference Attack and Defense in Decentralized POI Recommendation,"Jing Long, Tong Chen, Guanhua Ye, Kai Zheng, Nguyen Quoc Viet Hung, Hongzhi Yin",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14583"" target=""_blank"">2401.14583</a>",,2024-12-11
A Training Rate and Survival Heuristic for Inference and Robustness Evaluation (TRASHFIRE),"Charles Meyers, Mohammad Reza Saleh Sedghpour, Tommy LÃ¶fstedt, Erik Elmroth",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.13751"" target=""_blank"">2401.13751</a>",,2024-12-11
Can overfitted deep neural networks in adversarial training generalize? -- An approximation viewpoint,"Zhongjie Shi, Fanghui Liu, Yuan Cao, Johan A. K. Suykens",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.13624"" target=""_blank"">2401.13624</a>",,2024-12-11
WPDA: Frequency-based Backdoor Attack with Wavelet Packet Decomposition,"Zhengyao Song, Yongqiang Li, Danni Yuan, Li Liu, Shaokui Wei, Baoyuan Wu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.13578"" target=""_blank"">2401.13578</a>",,2024-12-11
Model Supply Chain Poisoning: Backdooring Pre-trained Models via Embedding Indistinguishability,"Hao Wang, Shangwei Guo, Jialing He, Hangcheng Liu, Tianwei Zhang, Tao Xiang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15883"" target=""_blank"">2401.15883</a>","<a href=""https://github.com/haowang-cqu/TransTroj"" target=""_blank"">haowang-cqu</a>",2024-12-11
Addressing Noise and Efficiency Issues in Graph-Based Machine Learning Models From the Perspective of Adversarial Attack,Yongyu Wang,arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15615"" target=""_blank"">2401.15615</a>",,2024-12-11
GPS: Graph Contrastive Learning via Multi-scale Augmented Views from Adversarial Pooling,"Wei Ju, Yiyang Gu, Zhengyang Mao, Ziyue Qiao, Yifang Qin, Xiao Luo, Hui Xiong, Ming Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.16011"" target=""_blank"">2401.16011</a>",,2024-12-11
AdvGPS: Adversarial GPS for Multi-Agent Perception Attack,"Jinlong Li, Baolu Li, Xinyu Liu, Jianwu Fang, Felix Juefei-Xu, Qing Guo, Hongkai Yu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17499"" target=""_blank"">2401.17499</a>",,2024-12-11
Logit Poisoning Attack in Distillation-based Federated Learning and its Countermeasures,"Yonghao Yu, Shunan Zhu, Jinglu Hu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17746"" target=""_blank"">2401.17746</a>",,2024-12-11
An Optimal Transport Approach for Computing Adversarial Training Lower Bounds in Multiclass Classification,"Nicolas Garcia Trillos, Matt Jacobs, Jakwang Kim, Matthew Werenski",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09191"" target=""_blank"">2401.09191</a>",,2024-12-11
Manipulating Predictions over Discrete Inputs in Machine Teaching,"Xiaodong Wu, Yufei Han, Hayssam Dahrouj, Jianbing Ni, Zhenwen Liang, Xiangliang Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17865"" target=""_blank"">2401.17865</a>",,2024-12-11
LoRec: Large Language Model for Robust Sequential Recommendation against Poisoning Attacks,"Kaike Zhang, Qi Cao, Yunfan Wu, Fei Sun, Huawei Shen, Xueqi Cheng",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17723"" target=""_blank"">2401.17723</a>",,2024-12-11
Ambush from All Sides: Understanding Security Threats in Open-Source Software CI/CD Pipelines,"Ziyue Pan, Wenbo Shen, Xingkai Wang, Yutian Yang, Rui Chang, Yao Liu, Chengwei Liu, Yang Liu, Kui Ren",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17606"" target=""_blank"">2401.17606</a>",,2024-12-11
Single Word Change is All You Need: Designing Attacks and Defenses for Text Classifiers,"Lei Xu, Sarah Alnegheimish, Laure Berti-Equille, Alfredo Cuesta-Infante, Kalyan Veeramachaneni",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17196"" target=""_blank"">2401.17196</a>",,2024-12-11
Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks,"Andy Zhou, Bo Li, Haohan Wang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17263"" target=""_blank"">2401.17263</a>",,2024-12-11
Towards Assessing the Synthetic-to-Measured Adversarial Vulnerability of SAR ATR,"Bowen Peng, Bo Peng, Jingyuan Xia, Tianpeng Liu, Yongxiang Liu, Li Liu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17038"" target=""_blank"">2401.17038</a>","<a href=""https://github.com/scenarri/S2M-TEA"" target=""_blank"">scenarri</a>",2024-12-11
Game-Theoretic Unlearnable Example Generator,"Shuang Liu, Yihan Wang, Xiao-Shan Gao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17523"" target=""_blank"">2401.17523</a>","<a href=""https://github.com/hong-xian/gue"" target=""_blank"">hong-xian</a>",2024-12-11
Revisiting Gradient Pruning: A Dual Realization for Defending against Gradient Attacks,"Lulu Xue, Shengshan Hu, Ruizhi Zhao, Leo Yu Zhang, Shengqing Hu, Lichao Sun, Dezhong Yao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.16687"" target=""_blank"">2401.16687</a>",,2024-12-11
Camouflage Adversarial Attacks on Multiple Agent Systems,"Ziqing Lu, Guanlin Liu, Lifeng Lai, Weiyu Xu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17405"" target=""_blank"">2401.17405</a>",,2024-12-11
Weak-to-Strong Jailbreaking on Large Language Models,"Xuandong Zhao, Xianjun Yang, Tianyu Pang, Chao Du, Lei Li, Yu-Xiang Wang, William Yang Wang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17256"" target=""_blank"">2401.17256</a>","<a href=""https://github.com/XuandongZhao/weak-to-strong"" target=""_blank"">XuandongZhao</a>",2024-12-11
A Proactive and Dual Prevention Mechanism against Illegal Song Covers empowered by Singing Voice Conversion,"Guangke Chen, Yedi Zhang, Fu Song, Ting Wang, Xiaoning Du, Yang Liu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17133"" target=""_blank"">2401.17133</a>",,2024-12-11
Improving QA Model Performance with Cartographic Inoculation,"Allen UT Austin Chen, Okan UT Austin Tanrikulu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17498"" target=""_blank"">2401.17498</a>",,2024-12-11
Towards Visual Syntactical Understanding,"Sayeed Shafayet Chowdhury, Soumyadeep Chandra, Kaushik Roy",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17497"" target=""_blank"">2401.17497</a>",,2024-12-11
Provably Robust Multi-bit Watermarking for AI-generated Text via Error Correction Code,"Wenjie Qu, Dong Yin, Zixin He, Wei Zou, Tianyang Tao, Jinyuan Jia, Jiaheng Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.16820"" target=""_blank"">2401.16820</a>",,2024-12-11
LESSON: Multi-Label Adversarial False Data Injection Attack for Deep Learning Locational Detection,"Jiwei Tian, Chao Shen, Buhong Wang, Xiaofang Xia, Meng Zhang, Chenhao Lin, Qian Li",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.16001"" target=""_blank"">2401.16001</a>",,2024-12-11
Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization,"Guang Lin, Chao Li, Jianhai Zhang, Toshihisa Tanaka, Qibin Zhao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.16352"" target=""_blank"">2401.16352</a>",,2024-12-11
Exploring Adversarial Threat Models in Cyber Physical Battery Systems,"Shanthan Kumar Padisala, Shashank Dhananjay Vyas, Satadru Dey",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.13801"" target=""_blank"">2401.13801</a>",,2024-12-11
Transparency Attacks: How Imperceptible Image Layers Can Fool AI Perception,"Forrest McKee, David Noever",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15817"" target=""_blank"">2401.15817</a>",,2024-12-11
Securing Recommender System via Cooperative Training,"Qingyang Wang, Chenwang Wu, Defu Lian, Enhong Chen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12700"" target=""_blank"">2401.12700</a>",,2024-12-11
Differentially Private and Adversarially Robust Machine Learning: An Empirical Evaluation,"Janvi Thakkar, Giulio Zizzo, Sergio Maffeis",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10405"" target=""_blank"">2401.10405</a>",,2024-12-11
The Surprising Harmfulness of Benign Overfitting for Adversarial Robustness,"Yifan Hao, Tong Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12236"" target=""_blank"">2401.12236</a>",,2024-12-11
Adversarially Robust Signed Graph Contrastive Learning from Balance Augmentation,"Jialong Zhou, Xing Ai, Yuni Lai, Kai Zhou",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10590"" target=""_blank"">2401.10590</a>",,2024-12-11
BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models,"Zhen Xiang, Fengqing Jiang, Zidi Xiong, Bhaskar Ramasubramanian, Radha Poovendran, Bo Li",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12242"" target=""_blank"">2401.12242</a>",,2024-12-11
Image Safeguarding: Reasoning with Conditional Vision Language Model and Obfuscating Unsafe Content Counterfactually,"Mazal Bethany, Brandon Wherry, Nishant Vishwamitra, Peyman Najafirad",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11035"" target=""_blank"">2401.11035</a>","<a href=""https://github.com/SecureAIAutonomyLab/ConditionalVLM"" target=""_blank"">SecureAIAutonomyLab</a>",2024-12-11
HGAttack: Transferable Heterogeneous Graph Adversarial Attack,"He Zhao, Zhiwei Zeng, Yongwei Wang, Deheng Ye, Chunyan Miao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09945"" target=""_blank"">2401.09945</a>",,2024-12-11
Hijacking Attacks against Neural Networks by Analyzing Training Data,"Yunjie Ge, Qian Wang, Huayang Huang, Qi Li, Cong Wang, Chao Shen, Lingchen Zhao, Peipei Jiang, Zheng Fang, Shenyi Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09740"" target=""_blank"">2401.09740</a>",,2024-12-11
A GAN-based data poisoning framework against anomaly detection in vertical federated learning,"Xiaolin Chen, Daoguang Zan, Wei Li, Bei Guan, Yongji Wang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08984"" target=""_blank"">2401.08984</a>",,2024-12-11
Hacking Predictors Means Hacking Cars: Using Sensitivity Analysis to Identify Trajectory Prediction Vulnerabilities for Autonomous Driving Security,"Marsalis Gibson, David Babazadeh, Claire Tomlin, Shankar Sastry",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10313"" target=""_blank"">2401.10313</a>",,2024-12-11
Investigating Training Strategies and Model Robustness of Low-Rank Adaptation for Language Modeling in Speech Recognition,"Yu Yu, Chao-Han Huck Yang, Tuan Dinh, Sungho Ryu, Jari Kolehmainen, Roger Ren, Denis Filimonov, Prashanth G. Shivakumar, Ankur Gandhe, Ariya Rastow, Jia Xu, Ivan Bulyko, Andreas Stolcke",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10447"" target=""_blank"">2401.10447</a>",,2024-12-11
PuriDefense: Randomized Local Implicit Adversarial Purification for Defending Black-box Query-based Attacks,"Ping Guo, Zhiyuan Yang, Xi Lin, Qingchuan Zhao, Qingfu Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10586"" target=""_blank"">2401.10586</a>",,2024-12-11
Power in Numbers: Robust reading comprehension by finetuning with four adversarial sentences per example,Ariel Marcus,arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10091"" target=""_blank"">2401.10091</a>",,2024-12-11
Cross-Modality Perturbation Synergy Attack for Person Re-identification,"Yunpeng Gong, Zhun Zhong, Yansong Qu, Zhiming Luo, Rongrong Ji, Min Jiang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10090"" target=""_blank"">2401.10090</a>",,2024-12-11
Vulnerabilities of Foundation Model Integrated Federated Learning Under Adversarial Threats,"Chen Wu, Xi Li, Jiaqi Wang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10375"" target=""_blank"">2401.10375</a>",,2024-12-11
Large Language Models are Efficient Learners of Noise-Robust Speech Recognition,"Yuchen Hu, Chen Chen, Chao-Han Huck Yang, Ruizhe Li, Chao Zhang, Pin-Yu Chen, EnSiong Chng",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10446"" target=""_blank"">2401.10446</a>",,2024-12-11
Towards Scalable and Robust Model Versioning,"Wenxin Ding, Arjun Nitin Bhagoji, Ben Y. Zhao, Haitao Zheng",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09574"" target=""_blank"">2401.09574</a>",,2024-12-11
Artwork Protection Against Neural Style Transfer Using Locally Adaptive Adversarial Color Attack,"Zhongliang Guo, Junhao Dong, Yifei Qian, Kaixuan Wang, Weiye Li, Ziheng Guo, Yuheng Wang, Yanli Li, Ognjen ArandjeloviÄ, Lei Fang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09673"" target=""_blank"">2401.09673</a>",,2024-12-11
Compositional Generative Inverse Design,"Tailin Wu, Takashi Maruyama, Long Wei, Tao Zhang, Yilun Du, Gianluca Iaccarino, Jure Leskovec",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.13171"" target=""_blank"">2401.13171</a>","<a href=""https://github.com/AI4Science-WestlakeU/cindm"" target=""_blank"">AI4Science-WestlakeU</a>",2024-12-11
MITS-GAN: Safeguarding Medical Imaging from Tampering with Generative Adversarial Networks,"Giovanni Pasqualino, Luca Guarnera, Alessandro Ortis, Sebastiano Battiato",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09624"" target=""_blank"">2401.09624</a>",,2024-12-11
Explainable and Transferable Adversarial Attack for ML-Based Network Intrusion Detectors,"Hangsheng Zhang, Dongqi Han, Yinlong Liu, Zhiliang Wang, Jiyan Sun, Shangyuan Zhuang, Jiqiang Liu, Jinsong Dong",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10691"" target=""_blank"">2401.10691</a>",,2024-12-11
FIMBA: Evaluating the Robustness of AI in Genomics via Feature Importance Adversarial Attacks,"Heorhii Skovorodnikov, Hoda Alkhzaimi",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10657"" target=""_blank"">2401.10657</a>",,2024-12-11
Adversarial speech for voice privacy protection from Personalized Speech generation,"Shihao Chen, Liping Chen, Jie Zhang, KongAik Lee, Zhenhua Ling, Lirong Dai",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11857"" target=""_blank"">2401.11857</a>","<a href=""https://voiceprivacy.github.io/Adeversarial-Speech-with-YourTTS"" target=""_blank"">voiceprivacy.github.io</a>",2024-12-11
Text Embedding Inversion Security for Multilingual Language Models,"Yiyi Chen, Heather Lent, Johannes Bjerva",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12192"" target=""_blank"">2401.12192</a>",,2024-12-11
AdCorDA: Classifier Refinement via Adversarial Correction and Domain Adaptation,"Lulan Shen, Ali Edalati, Brett Meyer, Warren Gross, James J. Clark",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.13212"" target=""_blank"">2401.13212</a>",,2024-12-11
DAFA: Distance-Aware Fair Adversarial Training,"Hyungyu Lee, Saehyung Lee, Hyemi Jang, Junsung Park, Ho Bae, Sungroh Yoon",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12532"" target=""_blank"">2401.12532</a>",,2024-12-11
The twin peaks of learning neural networks,"Elizaveta Demyanenko, Christoph Feinauer, Enrico M. Malatesta, Luca Saglietti",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12610"" target=""_blank"">2401.12610</a>",,2024-12-11
Fast Adversarial Training against Textual Adversarial Attacks,"Yichen Yang, Xin Liu, Kun He",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12461"" target=""_blank"">2401.12461</a>",,2024-12-11
A Training-Free Defense Framework for Robust Learned Image Compression,"Myungseo Song, Jinyoung Choi, Bohyung Han",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11902"" target=""_blank"">2401.11902</a>",,2024-12-11
Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images,"Kuofeng Gao, Yang Bai, Jindong Gu, Shu-Tao Xia, Philip Torr, Zhifeng Li, Wei Liu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11170"" target=""_blank"">2401.11170</a>","<a href=""https://github.com/KuofengGao/Verbose_Images"" target=""_blank"">KuofengGao</a>",2024-12-11
NEUROSEC: FPGA-Based Neuromorphic Audio Security,"Murat Isik, Hiruna Vishwamith, Yusuf Sur, Kayode Inadagbo, I. Can Dikmen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12055"" target=""_blank"">2401.12055</a>",,2024-12-11
Unraveling Attacks in Machine Learning-based IoT Ecosystems: A Survey and the Open Libraries Behind Them,"Chao Liu, Boxi Chen, Wei Shao, Chris Zhang, Kelvin Wong, Yi Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11723"" target=""_blank"">2401.11723</a>",,2024-12-11
Robustness to distribution shifts of compressed networks for edge devices,"Lulan Shen, Ali Edalati, Brett Meyer, Warren Gross, James J. Clark",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12014"" target=""_blank"">2401.12014</a>",,2024-12-11
Out-of-Distribution Detection & Applications With Ablated Learned Temperature Energy,"Will LeVine, Benjamin Pikus, Jacob Phillips, Berk Norman, Fernando Amat Gil, Sean Hendryx",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12129"" target=""_blank"">2401.12129</a>",,2024-12-11
How Robust Are Energy-Based Models Trained With Equilibrium Propagation? (99%),"Siddharth Mansingh, Michal Kucer, Garrett Kenyon, Juston Moore, Michael Teti",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11543"" target=""_blank"">2401.11543</a>",,2024-12-11
Analyzing the Quality Attributes of AI Vision Models in Open Repositories Under Adversarial Attacks,"Zerui Wang, Yan Liu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12261"" target=""_blank"">2401.12261</a>",,2024-12-11
Adversarial Augmentation Training Makes Action Recognition Models More Robust to Realistic Video Distribution Shifts,"Kiyoon Kim, Shreyank N Gowda, Panagiotis Eustratiadis, Antreas Antoniou, Robert B Fisher",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11406"" target=""_blank"">2401.11406</a>",,2024-12-11
Efficient local linearity regularization to overcome catastrophic overfitting,"Elias Abad Rocamora, Fanghui Liu, Grigorios G. Chrysos, Pablo M. Olmos, Volkan Cevher",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11618"" target=""_blank"">2401.11618</a>","<a href=""https://github.com/LIONS-EPFL/ELLE"" target=""_blank"">LIONS-EPFL</a>",2024-12-11
Susceptibility of Adversarial Attack on Medical Image Segmentation Models,"Zhongxuan Wang, Leo Xu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11224"" target=""_blank"">2401.11224</a>","<a href=""https://github.com/ZhongxuanWang/adv_attk"" target=""_blank"">ZhongxuanWang</a>",2024-12-11
Finding a Needle in the Adversarial Haystack: A Targeted Paraphrasing Approach For Uncovering Edge Cases with Minimal Distribution Distortion,"Aly M. Kassem, Sherif Saad",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11373"" target=""_blank"">2401.11373</a>",,2024-12-11
CARE: Ensemble Adversarial Robustness Evaluation Against Adaptive Attackers for Security Applications,"Hangsheng Zhang, Jiqiang Liu, Jinsong Dong",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11126"" target=""_blank"">2401.11126</a>",,2024-12-11
ToDA: Target-oriented Diffusion Attacker against Recommendation System,"Xiaohao Liu, Zhulin Tao, Ting Jiang, He Chang, Yunshan Ma, Xianglin Huang, Xiang Wang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12578"" target=""_blank"">2401.12578</a>",,2024-12-11
Poisoning $\times$ Evasion: Symbiotic Adversarial Robustness for Graph Neural Networks,"Ege Erdogan, Simon Geisler, Stephan GÃ¼nnemann",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.05502"" target=""_blank"">2312.05502</a>",,2024-12-11
Initialization Matters for Adversarial Transfer Learning,"Andong Hua, Jindong Gu, Zhiyu Xue, Nicholas Carlini, Eric Wong, Yao Qin",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.05716"" target=""_blank"">2312.05716</a>","<a href=""https://github.com/DongXzz/RoLI"" target=""_blank"">DongXzz</a>",2024-12-11
Dynamic Adversarial Attacks on Autonomous Driving Systems,"Amirhosein Chahe, Chenan Wang, Abhishek Jeyapratap, Kaidi Xu, Lifeng Zhou",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06701"" target=""_blank"">2312.06701</a>",,2024-12-11
Improving Adversarial Robust Fairness via Anti-Bias Soft Label Distillation,"Shiji Zhao, Ranjie Duan, Xizhe Wang, Xingxing Wei",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.05508"" target=""_blank"">2312.05508</a>",,2024-12-11
Robust Graph Neural Network based on Graph Denoising,"Victor M. Tenorio, Samuel Rey, Antonio G. Marques",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06557"" target=""_blank"">2312.06557</a>",,2024-12-11
METAL: Metamorphic Testing Framework for Analyzing Large-Language Model Qualities,"Sangwon Hyun, Mingyu Guo, M. Ali Babar",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06056"" target=""_blank"">2312.06056</a>",,2024-12-11
An Ambiguity Measure for Recognizing the Unknowns in Deep Learning,Roozbeh Yousefzadeh,arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06077"" target=""_blank"">2312.06077</a>",,2024-12-11
A Practical Survey on Emerging Threats from AI-driven Voice Attacks: How Vulnerable are Commercial Voice Control Systems? (76%),"Yuanda Wang, Qiben Yan, Nikolay Ivanov, Xun Chen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06010"" target=""_blank"">2312.06010</a>",,2024-12-11
Data-Free Hard-Label Robustness Stealing Attack,"Xiaojian Yuan, Kejiang Chen, Wen Huang, Jie Zhang, Weiming Zhang, Nenghai Yu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.05924"" target=""_blank"">2312.05924</a>","<a href=""https://github.com/LetheSec/DFHL-RS-Attack"" target=""_blank"">LetheSec</a>",2024-12-11
SA-Attack: Improving Adversarial Transferability of Vision-Language Pre-training Models via Self-Augmentation,"Bangyan He, Xiaojun Jia, Siyuan Liang, Tianrui Lou, Yang Liu, Xiaochun Cao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04913"" target=""_blank"">2312.04913</a>",,2024-12-11
HC-Ref: Hierarchical Constrained Refinement for Robust Adversarial Training of GNNs,"Xiaobing Pei, Haoran Yang, Gang Shen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04879"" target=""_blank"">2312.04879</a>",,2024-12-11
FreqFed: A Frequency Analysis-Based Approach for Mitigating Poisoning Attacks in Federated Learning,"Hossein Fereidooni, Alessandro Pegoraro, Phillip Rieger, Alexandra Dmitrienko, Ahmad-Reza Sadeghi",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04432"" target=""_blank"">2312.04432</a>",,2024-12-11
MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness,"Xiaoyun Xu, Shujian Yu, Jingzheng Wu, Stjepan Picek",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04960"" target=""_blank"">2312.04960</a>","<a href=""https://github.com/xiaoyunxxy/MIMIR"" target=""_blank"">xiaoyunxxy</a>",2024-12-11
BELT: Old-School Backdoor Attacks can Evade the State-of-the-Art Defense with Backdoor Exclusivity Lifting,"Huming Qiu, Junjie Sun, Mi Zhang, Xudong Pan, Min Yang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04902"" target=""_blank"">2312.04902</a>",,2024-12-11
An adversarial attack approach for eXplainable AI evaluation on deepfake detection models,"Balachandar Gowrisankar, Vrizlynn L. L. Thing",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06627"" target=""_blank"">2312.06627</a>",,2024-12-11
A Red Teaming Framework for Securing AI in Maritime Autonomous Systems,"Mathew J. Walter, Aaron Barrett, Kimberly Tam",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11500"" target=""_blank"">2312.11500</a>",,2024-12-11
Annotation-Free Group Robustness via Loss-Based Resampling,"Mahdi Ghaznavi, Hesam Asadollahzadeh, HamidReza Yaghoubi Araghi, Fahimeh Hosseini Noohdani, Mohammad Hossein Rohban, Mahdieh Soleymani Baghshah",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04893"" target=""_blank"">2312.04893</a>",,2024-12-11
HuRef: HUman-REadable Fingerprint for Large Language Models,"Boyi Zeng, Lizheng Wang, Yuncong Hu, Yi Xu, Chenghu Zhou, Xinbing Wang, Yu Yu, Zhouhan Lin",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04828"" target=""_blank"">2312.04828</a>","<a href=""https://github.com/LUMIA-Group/HuRef"" target=""_blank"">LUMIA-Group</a>",2024-12-11
MimicDiffusion: Purifying Adversarial Perturbation via Mimicking Clean Diffusion Model,"Kaiyu Song, Hanjiang Lai",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04802"" target=""_blank"">2312.04802</a>",,2024-12-11
OT-Attack: Enhancing Adversarial Transferability of Vision-Language Models via Optimal Transport Optimization,"Dongchen Han, Xiaojun Jia, Yang Bai, Jindong Gu, Yang Liu, Xiaochun Cao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04403"" target=""_blank"">2312.04403</a>",,2024-12-11
Diffence: Fencing Membership Privacy With Diffusion Models,"Yuefeng Peng, Ali Naseh, Amir Houmansadr",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04692"" target=""_blank"">2312.04692</a>",,2024-12-11
Forcing Generative Models to Degenerate Ones: The Power of Data Poisoning Attacks,"Shuli Jiang, Swanand Ravindra Kadhe, Yi Zhou, Ling Cai, Nathalie Baracaldo",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04748"" target=""_blank"">2312.04748</a>",,2024-12-11
Adversarial Camera Patch: An Effective and Robust Physical-World Attack on Object Detectors,Kalibinuer Tiliwalidi,arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06163"" target=""_blank"">2312.06163</a>",,2024-12-11
Attacking the Loop: Adversarial Attacks on Graph-based Loop Closure Detection,"Jonathan J. Y. Kim, Martin Urschler, Patricia J. Riddle, Jorg S. Wicker",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06991"" target=""_blank"">2312.06991</a>",,2024-12-11
Promoting Counterfactual Robustness through Diversity,"Francesco Leofante, Nico Potyka",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06564"" target=""_blank"">2312.06564</a>",,2024-12-11
Poisoned ChatGPT Finds Work for Idle Hands: Exploring Developers' Coding Practices with Insecure Suggestions from Poisoned AI Models,"Sanghak Oh, Kiho Lee, Seonhye Park, Doowon Kim, Hyoungshick Kim",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06227"" target=""_blank"">2312.06227</a>",,2024-12-11
Defense against ML-based Power Side-channel Attacks on DNN Accelerators with Adversarial Attacks,"Xiaobei Yan, Chip Hong Chang, Tianwei Zhang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04035"" target=""_blank"">2312.04035</a>",,2024-12-11
DTA: Distribution Transform-based Attack for Query-Limited Scenario,"Renyang Liu, Wei Zhou, Xin Jin, Song Gao, Yuanyu Wang, Ruxin Wang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07245"" target=""_blank"">2312.07245</a>",,2024-12-11
Collapse-Oriented Adversarial Training with Triplet Decoupling for Robust Image Retrieval,"Qiwei Tian, Chenhao Lin, Qian Li, Zhengyu Zhao, Chao Shen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07364"" target=""_blank"">2312.07364</a>",,2024-12-11
Focus on Hiders: Exploring Hidden Threats for Enhancing Adversarial Training,"Qian Li, Yuxiao Hu, Yinpeng Dong, Dongxiao Zhang, Yuntian Chen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07067"" target=""_blank"">2312.07067</a>",,2024-12-11
QuadAttack: A Quadratic Programming Approach to Ordered Top-K Attacks,"Thomas Paniagua, Ryan Grainger, Tianfu Wu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11510"" target=""_blank"">2312.11510</a>",,2024-12-11
ReRoGCRL: Representation-based Robustness in Goal-Conditioned Reinforcement Learning,"Xiangyu Yin, Sihao Wu, Jiaxu Liu, Meng Fang, Xingyu Zhao, Xiaowei Huang, Wenjie Ruan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07392"" target=""_blank"">2312.07392</a>","<a href=""https://github.com/TrustAI/ReRoGCRL"" target=""_blank"">TrustAI</a>",2024-12-11
Robust MRI Reconstruction by Smoothed Unrolling (SMUG),"Shijun Liang, Van Hoang Minh Nguyen, Jinghan Jia, Ismail Alkhouri, Sijia Liu, Saiprasad Ravishankar",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07784"" target=""_blank"">2312.07784</a>",,2024-12-11
"Cost Aware Untargeted Poisoning Attack against Graph Neural Networks,","Yuwei Han, Yuni Lai, Yulin Zhu, Kai Zhou",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07158"" target=""_blank"">2312.07158</a>",,2024-12-11
EdgePruner: Poisoned Edge Pruning in Graph Contrastive Learning,"Hiroya Kato, Kento Hasegawa, Seira Hidano, Kazuhide Fukushima",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07022"" target=""_blank"">2312.07022</a>",,2024-12-11
Causality Analysis for Evaluating the Security of Large Language Models,"Wei Zhao, Zhe Li, Jun Sun",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07876"" target=""_blank"">2312.07876</a>",,2024-12-11
SimAC: A Simple Anti-Customization Method for Protecting Face Privacy against Text-to-Image Synthesis of Diffusion Models,"Feifei Wang, Zhentao Tan, Tianyi Wei, Yue Wu, Qidong Huang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07865"" target=""_blank"">2312.07865</a>","<a href=""https://github.com/somuchtome/SimAC"" target=""_blank"">somuchtome</a>",2024-12-11
Divide-and-Conquer Attack: Harnessing the Power of LLM to Bypass Safety Filters of Text-to-Image Models,"Yimo Deng, Huangxun Chen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07130"" target=""_blank"">2312.07130</a>","<a href=""https://github.com/researchcode001/Divide-and-Conquer-Attack"" target=""_blank"">researchcode001</a>",2024-12-11
Eroding Trust In Aerial Imagery: Comprehensive Analysis and Evaluation Of Adversarial Attacks In Geospatial Systems,"Michael Lanier, Aayush Dhakal, Zhexiao Xiong, Arthur Li, Nathan Jacobs, Yevgeniy Vorobeychik",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07389"" target=""_blank"">2312.07389</a>",,2024-12-11
Securing Graph Neural Networks in MLaaS: A Comprehensive Realization of Query-based Integrity Verification,"Bang Wu, Xingliang Yuan, Shuo Wang, Qi Li, Minhui Xue, Shirui Pan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07870"" target=""_blank"">2312.07870</a>",,2024-12-11
Majority is Not Required: A Rational Analysis of the Private Double-Spend Attack from a Sub-Majority Adversary,"Yanni Georghiades, Rajesh Mishra, Karl Kreder, Sriram Vishwanath",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07709"" target=""_blank"">2312.07709</a>",,2024-12-11
Rethinking Model Inversion Attacks With Patch-Wise Reconstruction,"Jonggyu Jang, Hyeonsu Lyu, Hyun Jong Yang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07040"" target=""_blank"">2312.07040</a>",,2024-12-11
Towards Transferable Adversarial Attacks with Centralized Perturbation,"Shangbo Wu, Yu-an Tan, Yajie Wang, Ruinan Ma, Wencong Ma, Yuanzhang Li",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06199"" target=""_blank"">2312.06199</a>",,2024-12-11
MalPurifier: Enhancing Android Malware Detection with Adversarial Purification against Evasion Attacks,"Yuyang Zhou, Guang Cheng, Zongyao Chen, Shui Yu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06423"" target=""_blank"">2312.06423</a>",,2024-12-11
Sparse but Strong: Crafting Adversarially Robust Graph Lottery Tickets,"Subhajit Dutta Chowdhury, Zhiyu Ni, Qingyuan Peng, Souvik Kundu, Pierluigi Nuzzo",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06568"" target=""_blank"">2312.06568</a>",,2024-12-11
Reward Certification for Policy Smoothed Reinforcement Learning,"Ronghui Mu, Leandro Soriano Marcolino, Tianle Zhang, Yanghao Zhang, Xiaowei Huang, Wenjie Ruan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06436"" target=""_blank"">2312.06436</a>",,2024-12-11
Activation Gradient based Poisoned Sample Detection Against Backdoor Attacks,"Danni Yuan, Shaokui Wei, Mingda Zhang, Li Liu, Baoyuan Wu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06230"" target=""_blank"">2312.06230</a>","<a href=""https://github.com/SCLBD/bdzoo2/blob/dev/detection_pretrain/agpd.py"" target=""_blank"">detection_pretrain</a>",2024-12-11
DeceptPrompt: Exploiting LLM-driven Code Generation via Adversarial Natural Language Instructions,"Fangzhou Wu, Xiaogeng Liu, Chaowei Xiao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04730"" target=""_blank"">2312.04730</a>",,2024-12-11
Universal Backdoor Attacks,"Benjamin Schneider, Nils Lukas, Florian Kerschbaum",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00157"" target=""_blank"">2312.00157</a>",,2024-12-11
Defense Against Adversarial Attacks using Convolutional Auto-Encoders,Shreyasi Mandal,arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03520"" target=""_blank"">2312.03520</a>",,2024-12-11
The Philosopher's Stone: Trojaning Plugins of Large Language Models,"Tian Dong, Minhui Xue, Guoxing Chen, Rayne Holland, Yan Meng, Shaofeng Li, Zhen Liu, Haojin Zhu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00374"" target=""_blank"">2312.00374</a>",,2024-12-11
Evaluating the Security of Satellite Systems,"Roy Peled, Eran Aizikovich, Edan Habler, Yuval Elovici, Asaf Shabtai",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01330"" target=""_blank"">2312.01330</a>",,2024-12-11
Exploring Adversarial Robustness of LiDAR-Camera Fusion Model in Autonomous Driving,"Bo Yang, Xiaoyu Ji, Xiaoyu Ji, Xiaoyu Ji, Xiaoyu Ji",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01468"" target=""_blank"">2312.01468</a>",,2024-12-11
Towards Sample-specific Backdoor Attack with Clean Labels via Attribute Trigger,"Yiming Li, Mingyan Zhu, Junfeng Guo, Tao Wei, Shu-Tao Xia, Zhan Qin",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04584"" target=""_blank"">2312.04584</a>",,2024-12-11
TranSegPGD: Improving Transferability of Adversarial Examples on Semantic Segmentation,"Xiaojun Jia, Jindong Gu, Yihao Huang, Simeng Qin, Qing Guo, Yang Liu, Xiaochun Cao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02207"" target=""_blank"">2312.02207</a>",,2024-12-11
Rethinking PGD Attack: Is Sign Function Necessary? (98%),"Junjie Yang, Tianlong Chen, Xuxi Chen, Zhangyang Wang, Yingbin Liang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01260"" target=""_blank"">2312.01260</a>","<a href=""https://github.com/JunjieYang97/RGD"" target=""_blank"">JunjieYang97</a>",2024-12-11
PROFL: A Privacy-Preserving Federated Learning Method with Stringent Defense Against Poisoning Attacks,"Yisheng Zhong, Li-Ping Wang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01045"" target=""_blank"">2312.01045</a>",,2024-12-11
Mendata: A Framework to Purify Manipulated Training Data,"Zonghao Huang, Neil Gong, Michael K. Reiter",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01281"" target=""_blank"">2312.01281</a>",,2024-12-11
PyraTrans: Learning Attention-Enriched Multi-Scale Pyramid Network from Pre-Trained Transformers for Effective Malicious URL Detection,"Ruitong Liu, Yanbin Wang, Zhenhao Guo, Haitao Xu, Zhan Qin, Wenrui Ma, Fan Zhang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00508"" target=""_blank"">2312.00508</a>","<a href=""https://github.com/Alixyvtte/PyraTrans"" target=""_blank"">Alixyvtte</a>",2024-12-11
Survey of Security Issues in Memristor-based Machine Learning Accelerators for RF Analysis,"William Lillis, Max Cohen Hoffing, Wayne Burleson",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00942"" target=""_blank"">2312.00942</a>",,2024-12-11
Deep Generative Attacks and Countermeasures for Data-Driven Offline Signature Verification,"An Ngo, MinhPhuong Cao, Rajesh Kumar",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00987"" target=""_blank"">2312.00987</a>",,2024-12-11
"Temperature Balancing, Layer-wise Weight Analysis, and Neural Network Training","Yefan Zhou, Tianyu Pang, Keqin Liu, Charles H. Martin, Michael W. Mahoney, Yaoqing Yang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00359"" target=""_blank"">2312.00359</a>",,2024-12-11
QuantAttack: Exploiting Dynamic Quantization to Attack Vision Transformers,"Amit Baras, Alon Zolfi, Yuval Elovici, Asaf Shabtai",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02220"" target=""_blank"">2312.02220</a>",,2024-12-11
Crystal: Enhancing Blockchain Mining Transparency with Quorum Certificate,"Jianyu Niu, Fangyu Gai, Runchao Han, Ren Zhang, Yinqian Zhang, Chen Feng",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00741"" target=""_blank"">2312.00741</a>",,2024-12-11
Improving the Robustness of Quantized Deep Neural Networks to White-Box Attacks using Stochastic Quantization and Information-Theoretic Ensemble Training,"Saurabh Farkya, Aswin Raghavan, Avi Ziskind",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00105"" target=""_blank"">2312.00105</a>",,2024-12-11
Fool the Hydra: Adversarial Attacks against Multi-view Object Detection Systems,"Bilel Tarchoun, Quazi Mishkatul Alam, Nael Abu-Ghazaleh, Ihsen Alouani",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00173"" target=""_blank"">2312.00173</a>",,2024-12-11
Optimal Attack and Defense for Reinforcement Learning,"Jeremy McMahan, Young Wu, Xiaojin Zhu, Qiaomin Xie",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00198"" target=""_blank"">2312.00198</a>",,2024-12-11
Can Protective Perturbation Safeguard Personal Data from Being Exploited by Stable Diffusion? (74%),"Zhengyue Zhao, Jinhao Duan, Kaidi Xu, Chenan Wang, Rui Zhangp Zidong Dup Qi Guo, Xing Hu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00084"" target=""_blank"">2312.00084</a>",,2024-12-11
Mark My Words: Analyzing and Evaluating Language Model Watermarks,"Julien Piet, Chawin Sitawarin, Vivian Fang, Norman Mu, David Wagner",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00273"" target=""_blank"">2312.00273</a>","<a href=""https://github.com/wagner-group/MarkMyWords"" target=""_blank"">wagner-group</a>",2024-12-11
Elijah: Eliminating Backdoors Injected in Diffusion Models via Distribution Shift,"Shengwei An, Sheng-Yen Chou, Kaiyuan Zhang, Qiuling Xu, Guanhong Tao, Guangyu Shen, Siyuan Cheng, Shiqing Ma, Pin-Yu Chen, Tsung-Yi Ho, Xiangyu Zhang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00050"" target=""_blank"">2312.00050</a>",,2024-12-11
Presentation Attack Detection using Convolutional Neural Networks and Local Binary Patterns,"Justin Spencer, Deborah Lawrence, Prosenjit Chatterjee, Kaushik Roy, Albert Esterline, Jung-Hee Kim",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00041"" target=""_blank"">2312.00041</a>",,2024-12-11
Bergeron: Combating Adversarial Attacks through a Conscience-Based Alignment Framework,"Matthew Pisano, Peter Ly, Abraham Sanders, Bingsheng Yao, Dakuo Wang, Tomek Strzalkowski, Mei Si",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00029"" target=""_blank"">2312.00029</a>",,2024-12-11
Radio Signal Classification by Adversarially Robust Quantum Machine Learning,"Yanqiu Wu, Eromanga Adermann, Chandra Thapa, Seyit Camtepe, Hajime Suzuki, Muhammad Usman",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07821"" target=""_blank"">2312.07821</a>",,2024-12-11
OCGEC: One-class Graph Embedding Classification for DNN Backdoor Detection,"Haoyu Jiang, Haiyang Yu, Nan Li, Ping Yi",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01585"" target=""_blank"">2312.01585</a>","<a href=""https://github.com/jhy549/OCGEC"" target=""_blank"">jhy549</a>",2024-12-11
Rejuvenating image-GPT as Strong Visual Representation Learners,"Sucheng Ren, Zeyu Wang, Hongru Zhu, Junfei Xiao, Alan Yuille, Cihang Xie",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02147"" target=""_blank"">2312.02147</a>","<a href=""https://github.com/OliverRensu/D-iGPT"" target=""_blank"">OliverRensu</a>",2024-12-11
Node-aware Bi-smoothing: Certified Robustness against Graph Injection Attacks,"Yuni Lai, Yulin Zhu, Bailin Pan, Kai Zhou",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03979"" target=""_blank"">2312.03979</a>",,2024-12-11
"Provable Adversarial Robustness for Group Equivariant Tasks: Graphs, Point Clouds, Molecules, and More","Jan Schuchardt, Yan Scholten, Stephan GÃ¼nnemann",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02708"" target=""_blank"">2312.02708</a>",,2024-12-11
RoAST: Robustifying Language Models via Adversarial Perturbation with Selective Training,"Jaehyung Kim, Yuning Mao, Rui Hou, Hanchao Yu, Davis Liang, Pascale Fung, Qifan Wang, Fuli Feng, Lifu Huang, Madian Khabsa",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04032"" target=""_blank"">2312.04032</a>",,2024-12-11
Detecting Voice Cloning Attacks via Timbre Watermarking,"Chang Liu, Jie Zhang, Tianwei Zhang, Xi Yang, Weiming Zhang, Nenghai Yu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03410"" target=""_blank"">2312.03410</a>","<a href=""https://timbrewatermarking.github.io/samples"" target=""_blank"">timbrewatermarking.github.io</a>",2024-12-11
Synthesizing Physical Backdoor Datasets: An Automated Framework Leveraging Deep Generative Models,"Sze Jue Yang, Chinh D. La, Quang H. Nguyen, Eugene Bagdasaryan, Kok-Seng Wong, Anh Tuan Tran, Chee Seng Chan, Khoa D. Doan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03419"" target=""_blank"">2312.03419</a>",,2024-12-11
Dr,"Matteo Gioele Collu, Tom Janssen-Groesbeek, Stefanos Koffas, Mauro Conti, Stjepan Picek",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03853"" target=""_blank"">2312.03853</a>",,2024-12-11
MICRO: Model-Based Offline Reinforcement Learning with a Conservative Bellman Operator,"Xiao-Yin Liu, Xiao-Hu Zhou, Guo-Tao Li, Hao Li, Mei-Jiang Gui, Tian-Yu Xiang, De-Xing Huang, Zeng-Guang Hou",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03991"" target=""_blank"">2312.03991</a>",,2024-12-11
Generating Visually Realistic Adversarial Patch,"Xiaosen Wang, Kunyu Wang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03030"" target=""_blank"">2312.03030</a>",,2024-12-11
A Simple Framework to Enhance the Adversarial Robustness of Deep Learning-based Intrusion Detection System,"Xinwei Yuan, Shu Han, Wei Huang, Hongliang Ye, Xianglong Kong, Fan Zhang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03245"" target=""_blank"">2312.03245</a>",,2024-12-11
Realistic Scatterer Based Adversarial Attacks on SAR Image Classifiers,"Tian Ye, Rajgopal Kannan, Viktor Prasanna, Carl Busart, Lance Kaplan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02912"" target=""_blank"">2312.02912</a>",,2024-12-11
ScAR: Scaling Adversarial Robustness for LiDAR Object Detection,"Xiaohu Lu, Hayder Radha",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03085"" target=""_blank"">2312.03085</a>","<a href=""https://github.com/xiaohulugo/ScAR-IROS2023"" target=""_blank"">xiaohulugo</a>",2024-12-11
Class Incremental Learning for Adversarial Robustness,"Seungju Cho, Hongsin Lee, Changick Kim",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03289"" target=""_blank"">2312.03289</a>",,2024-12-11
On the Robustness of Large Multimodal Models Against Image Adversarial Attacks,"Xuanimng Cui, Alejandro Aparcedo, Young Kyun Jang, Ser-Nam Lim",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03777"" target=""_blank"">2312.03777</a>",,2024-12-11
Auto DP-SGD: Dual Improvements of Privacy and Accuracy via Automatic Clipping Threshold and Noise Multiplier Estimation,"Sai Venkatesh Chilukoti, Md Imran Hossen, Liqun Shan, Vijay Srinivas Tida, Xiai Hei",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02400"" target=""_blank"">2312.02400</a>",,2024-12-11
Scaling Laws for Adversarial Attacks on Language Model Activations,Stanislav Fort,arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02780"" target=""_blank"">2312.02780</a>",,2024-12-11
Indirect Gradient Matching for Adversarial Robust Distillation,"Hongsin Lee, Seungju Cho, Changick Kim",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03286"" target=""_blank"">2312.03286</a>",,2024-12-11
Robust Backdoor Detection for Deep Learning via Topological Evolution Dynamics,"Xiaoxing Mo, Yechao Zhang, Leo Yu Zhang, Wei Luo, Nan Sun, Shengshan Hu, Shang Gao, Yang Xiang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02673"" target=""_blank"">2312.02673</a>",,2024-12-11
Prompt Optimization via Adversarial In-Context Learning,"Xuan Long Do, Yiran Zhao, Hannah Brown, Yuxi Xie, James Xu Zhao, Nancy F. Chen, Kenji Kawaguchi, Michael Qizhe Xie, Junxian He",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02614"" target=""_blank"">2312.02614</a>",,2024-12-11
Privacy-Preserving Task-Oriented Semantic Communications Against Model Inversion Attacks,"Yanhu Wang, Shuaishuai Guo, Yiqin Deng, Haixia Zhang, Yuguang Fang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03252"" target=""_blank"">2312.03252</a>",,2024-12-11
Machine Vision Therapy: Multimodal Large Language Models Can Enhance Visual Robustness via Denoising In-Context Learning,"Zhuo Huang, Chang Liu, Yinpeng Dong, Hang Su, Shibao Zheng, Tongliang Liu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02546"" target=""_blank"">2312.02546</a>","<a href=""https://github.com/tmllab/Machine_Vision_Therapy"" target=""_blank"">tmllab</a>",2024-12-11
Adversarial Medical Image with Hierarchical Feature Hiding,"Qingsong Yao, Zecheng He, Yuexiang Li, Yi Lin, Kai Ma, Yefeng Zheng, S. Kevin Zhou",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01679"" target=""_blank"">2312.01679</a>",,2024-12-11
InstructTA: Instruction-Tuned Targeted Attack for Large Vision-Language Models,"Xunguang Wang, Zhenlan Ji, Pingchuan Ma, Zongjie Li, Shuai Wang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01886"" target=""_blank"">2312.01886</a>","<a href=""https://github.com/xunguangwang/InstructTA"" target=""_blank"">xunguangwang</a>",2024-12-11
Singular Regularization with Information Bottleneck Improves Model's Adversarial Robustness,"Guanlin Li, Naishan Zheng, Man Zhou, Jie Zhang, Tianwei Zhang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02237"" target=""_blank"">2312.02237</a>",,2024-12-11
Two-stage optimized unified adversarial patch for attacking visible-infrared cross-modal detectors in the physical world,"Chengyin Hu, Weiwen Shi",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01789"" target=""_blank"">2312.01789</a>",,2024-12-11
SSTA: Salient Spatially Transformed Attack,"Renyang Liu, Wei Zhou, Sixin Wu, Jun Zhao, Kwok-Yan Lam",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07258"" target=""_blank"">2312.07258</a>",,2024-12-11
May the Noise be with you: Adversarial Training without Adversarial Examples,"Ayoub Arous, Andres F Lopez-Lopera, Nael Abu-Ghazaleh, Ihsen Alouani",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08877"" target=""_blank"">2312.08877</a>",,2024-12-11
Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models,"Jiang Zhang, Qiong Wu, Yiming Xu, Cheng Cao, Zheng Du, Konstantinos Psounis",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08303"" target=""_blank"">2312.08303</a>",,2024-12-11
I-CEE: Tailoring Explanations of Image Classifications Models to User Expertise,"Yao Rong, Peizhu Qian, Vaibhav Unhelkar, Enkelejda Kasneci",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12102"" target=""_blank"">2312.12102</a>",,2024-12-11
Attacking Byzantine Robust Aggregation in High Dimensions,"Sarthak Choudhary, Aashish Kolluri, Prateek Saxena",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14461"" target=""_blank"">2312.14461</a>",,2024-12-11
SODA: Protecting Proprietary Information in On-Device Machine Learning Models,"Akanksha Atrey, Ritwik Sinha, Saayan Mitra, Prashant Shenoy",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15036"" target=""_blank"">2312.15036</a>",,2024-12-11
Energy-based learning algorithms for analog computing: a comparative study,"Benjamin Scellier, Maxence Ernoult, Jack Kendall, Suhas Kumar",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15103"" target=""_blank"">2312.15103</a>",,2024-12-11
Adaptive Domain Inference Attack,"Yuechun Gu, Keke Chen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15088"" target=""_blank"">2312.15088</a>",,2024-12-11
AutoAugment Input Transformation for Highly Transferable Targeted Attacks,"Haobo Lu, Xin Liu, Kun He",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14218"" target=""_blank"">2312.14218</a>",,2024-12-11
Where and How to Attack? A Causality-Inspired Recipe for Generating Counterfactual Adversarial Examples,"Ruichu Cai, Yuxuan Zhu, Jie Qiao, Zefeng Liang, Furui Liu, Zhifeng Hao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.13628"" target=""_blank"">2312.13628</a>",,2024-12-11
Elevating Defenses: Bridging Adversarial Training and Watermarking for Model Resilience,"Janvi Thakkar, Giulio Zizzo, Sergio Maffeis",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14260"" target=""_blank"">2312.14260</a>",,2024-12-11
Adversarial Infrared Curves: An Attack on Infrared Pedestrian Detectors in the Physical World,"Chengyin Hu, Weiwen Shi",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14217"" target=""_blank"">2312.14217</a>",,2024-12-11
Exploiting Novel GPT-4 APIs,"Kellin Pelrine, Mohammad Taufeeque, MichaÅ ZajÄc, Euan McLean, Adam Gleave",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14302"" target=""_blank"">2312.14302</a>",,2024-12-11
Mutual-modality Adversarial Attack with Semantic Perturbation,"Jingwen Ye, Ruonan Yu, Songhua Liu, Xinchao Wang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12768"" target=""_blank"">2312.12768</a>",,2024-12-11
LRS: Enhancing Adversarial Transferability through Lipschitz Regularized Surrogate,"Tao Wu, Tie Luo, Donald C. Wunsch",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.13118"" target=""_blank"">2312.13118</a>","<a href=""https://github.com/TrustAIoT/LRS"" target=""_blank"">TrustAIoT</a>",2024-12-11
Adversarial Markov Games: On Adaptive Decision-Based Attacks and Defenses,"Ilias Tsingenopoulos, Vera Rimmer, Davy Preuveneers, Fabio Pierazzi, Lorenzo Cavallaro, Wouter Joosen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.13435"" target=""_blank"">2312.13435</a>",,2024-12-11
Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models,"Jingwei Yi, Yueqi Xie, Bin Zhu, Emre Kiciman, Guangzhong Sun, Xing Xie, Fangzhao Wu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14197"" target=""_blank"">2312.14197</a>",,2024-12-11
PGN: A perturbation generation network against deep reinforcement learning,"Xiangjuan Li, Feifan Li, Yang Li, Quan Pan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12904"" target=""_blank"">2312.12904</a>",,2024-12-11
ARBiBench: Benchmarking Adversarial Robustness of Binarized Neural Networks,"Peng Zhao, Jiehua Zhang, Bowen Peng, Longguang Wang, YingMei Wei, Yu Liu, Li Liu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.13575"" target=""_blank"">2312.13575</a>",,2024-12-11
Scaling Compute Is Not All You Need for Adversarial Robustness,"Edoardo Debenedetti, Zishen Wan, Maksym Andriushchenko, Vikash Sehwag, Kshitij Bhardwaj, Bhavya Kailkhura",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.13131"" target=""_blank"">2312.13131</a>",,2024-12-11
Doubly Perturbed Task Free Continual Learning,"Byung Hyun Lee, Min-hwan Oh, Se Young Chun",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.13027"" target=""_blank"">2312.13027</a>",,2024-12-11
Interactive Visualization of Time-Varying Flow Fields Using Particle Tracing Neural Networks,"Mengjiao Han, Jixian Li, Sudhanshu Sane, Shubham Gupta, Bei Wang, Steve Petruzza, Chris R. Johnson",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14973"" target=""_blank"">2312.14973</a>",,2024-12-11
Tensor Train Decomposition for Adversarial Attacks on Computer Vision Models,"Andrei Chertkov, Ivan Oseledets",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12556"" target=""_blank"">2312.12556</a>",,2024-12-11
Rethinking Randomized Smoothing from the Perspective of Scalability,"Anupriya Kumari, Devansh Bhardwaj, Sukrit Jindal",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12608"" target=""_blank"">2312.12608</a>",,2024-12-11
SkyMask: Attack-agnostic Robust Federated Learning with Fine-grained Learnable Masks,"Peishen Yan, Hao Wang, Tao Song, Yang Hua, Ruhui Ma, Ningxin Hu, Mohammad R. Haghighat, Haibing Guan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12484"" target=""_blank"">2312.12484</a>","<a href=""https://github.com/KoalaYan/SkyMask"" target=""_blank"">KoalaYan</a>",2024-12-11
Progressive Poisoned Data Isolation for Training-time Backdoor Defense,"Yiming Chen, Haiwei Wu, Jiantao Zhou",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12724"" target=""_blank"">2312.12724</a>",,2024-12-11
Adversarial AutoMixup,"Huafeng Qin, Xin Jin, Yun Jiang, Mounim A. El-Yacoubi, Xinbo Gao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11954"" target=""_blank"">2312.11954</a>",,2024-12-11
Understanding the Regularity of Self-Attention with Optimal Transport,"ValÃ©rie Castin, Pierre Ablin, Gabriel PeyrÃ©",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14820"" target=""_blank"">2312.14820</a>",,2024-12-11
Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks,"Haz Sameen Shahgir, Xianghao Kong, Greg Ver Steeg, Yue Dong",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14440"" target=""_blank"">2312.14440</a>",,2024-12-11
MEAOD: Model Extraction Attack against Object Detectors,"Zeyu Li, Chenghui Shi, Yuwen Pu, Xuhong Zhang, Yu Li, Jinbao Li, Shouling Ji",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14677"" target=""_blank"">2312.14677</a>",,2024-12-11
Timeliness: A New Design Metric and a New Attack Surface,"Priyanka Kaswan, Sennur Ulukus",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.17220"" target=""_blank"">2312.17220</a>",,2024-12-11
Towards Faithful Explanations for Text Classification with Robustness Improvement and Explanation Guided Training,"Dongfang Li, Baotian Hu, Qingcai Chen, Shan He",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.17591"" target=""_blank"">2312.17591</a>",,2024-12-11
Efficient Representation of the Activation Space in Deep Neural Networks,"Tanya Akumu, Celia Cintas, Girmaw Abebe Tadesse, Adebayo Oshingbesan, Skyler Speakman, Edward III McFowland",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08143"" target=""_blank"">2312.08143</a>",,2024-12-11
Adversarial Attacks on Image Classification Models: Analysis and Defense,"Jaydip Sen, Abhiraj Sen, Ananda Chatterjee",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16880"" target=""_blank"">2312.16880</a>",,2024-12-11
BlackboxBench: A Comprehensive Benchmark of Black-box Adversarial Attacks,"Meixi Zheng, Xuanchen Yan, Zihao Zhu, Hongrui Chen, Baoyuan Wu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16979"" target=""_blank"">2312.16979</a>","<a href=""https://blackboxbench.github.io/"" target=""_blank"">blackboxbench.github.io</a>",2024-12-11
Attack Tree Analysis for Adversarial Evasion Attacks,"Yuki Yamaguchi, Toshiaki Aoki",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16957"" target=""_blank"">2312.16957</a>",,2024-12-11
Can you See me? On the Visibility of NOPs against Android Malware Detectors,"Diego Soi, Davide Maiorca, Giorgio Giacinto, Harel Berger",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.17356"" target=""_blank"">2312.17356</a>",,2024-12-11
MVPatch: More Vivid Patch for Adversarial Camouflaged Attacks on Object Detectors in the Physical World,"Zheng Zhou, Hongbo Zhao, Ju Liu, Qiaosheng Zhang, Liwei Geng, Shuchang Lyu, Wenquan Feng",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.17431"" target=""_blank"">2312.17431</a>",,2024-12-11
Explainability-Based Adversarial Attack on Graphs Through Edge Perturbation,"Dibaloke Chanda, Saba Heidari Gheshlaghi, Nasim Yahya Soltani",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.17301"" target=""_blank"">2312.17301</a>",,2024-12-11
DOEPatch: Dynamically Optimized Ensemble Model for Adversarial Patches Generation,"Wenyi Tan, Yang Li, Chenxing Zhao, Zhunga Liu, Quan Pan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16907"" target=""_blank"">2312.16907</a>",,2024-12-11
Securing NextG Systems against Poisoning Attacks on Federated Learning: A Game-Theoretic Solution,"Yalin E. Sagduyu, Tugba Erpek, Yi Shi",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.17164"" target=""_blank"">2312.17164</a>",,2024-12-11
Adversarial Attacks on LoRa Device Identification and Rogue Signal Detection with Deep Learning,"Yalin E. Sagduyu, Tugba Erpek",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16715"" target=""_blank"">2312.16715</a>",,2024-12-11
TVE: Learning Meta-attribution for Transferable Vision Explainer,"Guanchu Wang, Yu-Neng Chuang, Fan Yang, Mengnan Du, Chia-Yuan Chang, Shaochen Zhong, Zirui Liu, Zhaozhuo Xu, Kaixiong Zhou, Xuanting Cai, Xia Hu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15359"" target=""_blank"">2312.15359</a>",,2024-12-11
Domain Generalization with Vital Phase Augmentation,"Ingyun Lee, Wooju Lee, Hyun Myung",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16451"" target=""_blank"">2312.16451</a>","<a href=""https://github.com/excitedkid/vipaug"" target=""_blank"">excitedkid</a>",2024-12-11
From text to multimodal: a survey of adversarial example generation in question answering systems,"Gulsum Yigit, Mehmet Fatih Amasyali",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16156"" target=""_blank"">2312.16156</a>",,2024-12-11
Natural Adversarial Patch Generation Method Based on Latent Diffusion Model,"Xianyi Chen, Fazhan Liu, Dong Jiang, Kai Yan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16401"" target=""_blank"">2312.16401</a>",,2024-12-11
Robust Survival Analysis with Adversarial Regularization,"Michael Potter, Stefano Maxenti, Michael Everett",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16019"" target=""_blank"">2312.16019</a>","<a href=""https://github.com/mlpotter/SAWAR"" target=""_blank"">mlpotter</a>",2024-12-11
Universal Pyramid Adversarial Training for Improved ViT Performance,"Ping-yeh Chiang, Yipin Zhou, Omid Poursaeed, Satya Narayan Shukla, Ashish Shah, Tom Goldstein, Ser-Nam Lim",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16339"" target=""_blank"">2312.16339</a>",,2024-12-11
GanFinger: GAN-Based Fingerprint Generation for Deep Neural Network Ownership Verification,"Huali Ren, Anli Yan, Xiaojun Ren, Pei-Gen Ye, Chong-zhi Gao, Zhili Zhou, Jin Li",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15617"" target=""_blank"">2312.15617</a>",,2024-12-11
Adversarial Item Promotion on Visually-Aware Recommender Systems by Guided Diffusion,"Lijian Chen, Wei Yuan, Tong Chen, Guanhua Ye, Quoc Viet Hung Nguyen, Hongzhi Yin",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15826"" target=""_blank"">2312.15826</a>",,2024-12-11
Punctuation Matters! Stealthy Backdoor Attack for Language Models,"Xuan Sheng, Zhicheng Li, Zhaoyang Han, Xiangmao Chang, Piji Li",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15867"" target=""_blank"">2312.15867</a>",,2024-12-11
Adversarial Data Poisoning for Fake News Detection: How to Make a Model Misclassify a Target News without Modifying It,"Federico Siciliano, Luca Maiano, Lorenzo Papa, Federica Baccin, Irene Amerini, Fabrizio Silvestri",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15228"" target=""_blank"">2312.15228</a>",,2024-12-11
Pre-trained Trojan Attacks for Visual Recognition,"Aishan Liu, Xinwei Zhang, Yisong Xiao, Yuguang Zhou, Siyuan Liang, Jiakai Wang, Xianglong Liu, Xiaochun Cao, Dacheng Tao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15172"" target=""_blank"">2312.15172</a>",,2024-12-11
Shaping Up SHAP: Enhancing Stability through Layer-Wise Neighbor Selection,"Gwladys Kelodjou, Laurence RozÃ©, VÃ©ronique Masson, Luis GalÃ¡rraga, Romaric Gaudel, Maurice Tchuente, Alexandre Termier",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12115"" target=""_blank"">2312.12115</a>",,2024-12-11
Jatmo: Prompt Injection Defense by Task-Specific Finetuning,"Julien Piet, Maha Alrashed, Chawin Sitawarin, Sizhe Chen, Zeming Wei, Elizabeth Sun, Basel Alomair, David Wagner",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.17673"" target=""_blank"">2312.17673</a>","<a href=""https://github.com/wagner-group/prompt-injection-defense"" target=""_blank"">wagner-group</a>",2024-12-11
Gemini: A Family of Highly Capable Multimodal Models,"Team Gemini, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M. Dai, Anja Hauth, Katie Millican, David Silver, Slav Petrov, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser, Amelia Glaese, Jilin Chen, Emily Pitler, Timothy Lillicrap, Angeliki Lazaridou, Orhan Firat, James Molloy, Michael Isard, Paul R. Barham, Tom Hennigan, Benjamin Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, Ryan Doherty, Eli Collins, Clemens Meyer, Eliza Rutherford, Erica Moreira, Kareem Ayoub, Megha Goel, George Tucker, Enrique Piqueras, Maxim Krikun, Iain Barr, Nikolay Savinov, Ivo Danihelka, Becca Roelofs, AnaÃ¯s White, Anders Andreassen, Glehn Tamara von, Lakshman Yagati, Mehran Kazemi, Lucas Gonzalez, Misha Khalman, Jakub Sygnowski, Alexandre Frechette, Charlotte Smith, Laura Culp, Lev Proleev, Yi Luan, Xi Chen, James Lottes, Nathan Schucher, Federico Lebron, Alban Rrustemi, Natalie Clay, Phil Crone, Tomas Kocisky, Jeffrey Zhao, Bartek Perz, Dian Yu, Heidi Howard, Adam Bloniarz, Jack W. Rae, Han Lu, Laurent Sifre, Marcello Maggioni, Fred Alcober, Dan Garrette, Megan Barnes, Shantanu Thakoor, Jacob Austin, Gabriel Barth-Maron, William Wong, Rishabh Joshi, Rahma Chaabouni, Deeni Fatiha, Arun Ahuja, Ruibo Liu, Yunxuan Li, Sarah Cogan, Jeremy Chen, Chao Jia, Chenjie Gu, Qiao Zhang, Jordan Grimstad, Ale Jakse Hartman, Martin Chadwick, Gaurav Singh Tomar, Xavier Garcia, Evan Senter, Emanuel Taropa, Thanumalayan Sankaranarayana Pillai, Jacob Devlin, Michael Laskin, Diego de Las Casas, Dasha Valter, Connie Tao, Lorenzo Blanco, AdriÃ  PuigdomÃ¨nech Badia, David Reitter, Mianna Chen, Jenny Brennan, Clara Rivera, Sergey Brin, Shariq Iqbal, Gabriela Surita, Jane Labanowski, Abhi Rao, Stephanie Winkler, Emilio Parisotto, Yiming Gu, Kate Olszewska, Yujing Zhang, Ravi Addanki, Antoine Miech, Annie Louis, Laurent El Shafey, Denis Teplyashin, Geoff Brown, Elliot Catt, Nithya Attaluri, Jan Balaguer, Jackie Xiang, Pidong Wang, Zoe Ashwood, Anton Briukhov, Albert Webson, Sanjay Ganapathy, Smit Sanghavi, Ajay Kannan, Ming-Wei Chang, Axel Stjerngren, Josip Djolonga, Yuting Sun, Ankur Bapna, Matthew Aitchison, Pedram Pejman, Henryk Michalewski, Tianhe Yu, Cindy Wang, Juliette Love, Junwhan Ahn, Dawn Bloxwich, Kehang Han, Peter Humphreys, Thibault Sellam, James Bradbury, Varun Godbole, Sina Samangooei, Bogdan Damoc, Alex Kaskasoli, SÃ©bastien M. R. Arnold, Vijay Vasudevan, Shubham Agrawal, Jason Riesa, Dmitry Lepikhin, Richard Tanburn, Srivatsan Srinivasan, Hyeontaek Lim, Sarah Hodkinson, Pranav Shyam, Johan Ferret, Steven Hand, Ankush Garg, Tom Le Paine, Jian Li, Yujia Li, Minh Giang, Alexander Neitz, Zaheer Abbas, Sarah York, Machel Reid, Elizabeth Cole, Aakanksha Chowdhery, Dipanjan Das, Dominika RogoziÅska, Vitaly Nikolaev, Pablo Sprechmann, Zachary Nado, Lukas Zilka, Flavien Prost, Luheng He, Marianne Monteiro, Gaurav Mishra, Chris Welty, Josh Newlan, Dawei Jia, Miltiadis Allamanis, Clara Huiyi Hu, Liedekerke Raoul de, Justin Gilmer, Carl Saroufim, Shruti Rijhwani, Shaobo Hou, Disha Shrivastava, Anirudh Baddepudi, Alex Goldin, Adnan Ozturel, Albin Cassirer, Yunhan Xu, Daniel Sohn, Devendra Sachan, Reinald Kim Amplayo, Craig Swanson, Dessie Petrova, Shashi Narayan, Arthur Guez, Siddhartha Brahma, Jessica Landon, Miteyan Patel, Ruizhe Zhao, Kevin Villela, Luyu Wang, Wenhao Jia, Matthew Rahtz, Mai GimÃ©nez, Legg Yeung, Hanzhao Lin, James Keeling, Petko Georgiev, Diana Mincu, Boxi Wu, Salem Haykal, Rachel Saputro, Kiran Vodrahalli, James Qin, Zeynep Cankara, Abhanshu Sharma, Nick Fernando, Will Hawkins, Behnam Neyshabur, Solomon Kim, Adrian Hutter, Priyanka Agrawal, Alex Castro-Ros, George van den Driessche, Tao Wang, Fan Yang, Shuo-yiin Chang, Paul Komarek, Ross McIlroy, Mario LuÄiÄ, Guodong Zhang, Wael Farhan, Michael Sharman, Paul Natsev, Paul Michel, Yong Cheng, Yamini Bansal, Siyuan Qiao, Kris Cao, Siamak Shakeri, Christina Butterfield, Justin Chung, Paul Kishan Rubenstein, Shivani Agrawal, Arthur Mensch, Kedar Soparkar, Karel Lenc, Timothy Chung, Aedan Pope, Loren Maggiore, Jackie Kay, Priya Jhakra, Shibo Wang, Joshua Maynez, Mary Phuong, Taylor Tobin, Andrea Tacchetti, Maja Trebacz, Kevin Robinson, Yash Katariya, Sebastian Riedel, Paige Bailey, Kefan Xiao, Nimesh Ghelani, Lora Aroyo, Ambrose Slone, Neil Houlsby, Xuehan Xiong, Zhen Yang, Elena Gribovskaya, Jonas Adler, Mateo Wirth, Lisa Lee, Music Li, Thais Kagohara, Jay Pavagadhi, Sophie Bridgers, Anna Bortsova, Sanjay Ghemawat, Zafarali Ahmed, Tianqi Liu, Richard Powell, Vijay Bolina, Mariko Iinuma, Polina Zablotskaia, James Besley, Da-Woon Chung, Timothy Dozat, Ramona Comanescu, Xiance Si, Jeremy Greer, Guolong Su, Martin Polacek, RaphaÃ«l Lopez Kaufman, Simon Tokumine, Hexiang Hu, Elena Buchatskaya, Yingjie Miao, Mohamed Elhawaty, Aditya Siddhant, Nenad Tomasev, Jinwei Xing, Christina Greer, Helen Miller, Shereen Ashraf, Aurko Roy, Zizhao Zhang, Ada Ma, Angelos Filos, Milos Besta, Rory Blevins, Ted Klimenko, Chih-Kuan Yeh, Soravit Changpinyo, Jiaqi Mu, Oscar Chang, Mantas Pajarskas, Carrie Muir, Vered Cohen, Charline Le Lan, Krishna Haridasan, Amit Marathe, Steven Hansen, Sholto Douglas, Rajkumar Samuel, Mingqiu Wang, Sophia Austin, Chang Lan, Jiepu Jiang, Justin Chiu, Jaime Alonso Lorenzo, Lars Lowe SjÃ¶sund, SÃ©bastien Cevey, Zach Gleicher, Thi Avrahami, Anudhyan Boral, Hansa Srinivasan, Vittorio Selo, Rhys May, Konstantinos Aisopos, LÃ©onard Hussenot, Livio Baldini Soares, Kate Baumli, Michael B. Chang, AdriÃ  Recasens, Ben Caine, Alexander Pritzel, Filip Pavetic, Fabio Pardo, Anita Gergely, Justin Frye, Vinay Ramasesh, Dan Horgan, Kartikeya Badola, Nora Kassner, Subhrajit Roy, Ethan Dyer, VÃ­ctor Campos, Alex Tomala, Yunhao Tang, Dalia El Badawy, Elspeth White, Basil Mustafa, Oran Lang, Abhishek Jindal, Sharad Vikram, Zhitao Gong, Sergi Caelles, Ross Hemsley, Gregory Thornton, Fangxiaoyu Feng, Wojciech Stokowiec, Ce Zheng, Phoebe Thacker, ÃaÄlar ÃnlÃ¼, Zhishuai Zhang, Mohammad Saleh, James Svensson, Max Bileschi, Piyush Patil, Ankesh Anand, Roman Ring, Katerina Tsihlas, Arpi Vezer, Marco Selvi, Toby Shevlane, Mikel Rodriguez, Tom Kwiatkowski, Samira Daruki, Keran Rong, Allan Dafoe, Nicholas FitzGerald, Keren Gu-Lemberg, Mina Khan, Lisa Anne Hendricks, Marie Pellat, Vladimir Feinberg, James Cobon-Kerr, Tara Sainath, Maribeth Rauh, Sayed Hadi Hashemi, Richard Ives, Yana Hasson, YaGuang Li, Eric Noland, Yuan Cao, Nathan Byrd, Le Hou, Qingze Wang, Thibault Sottiaux, Michela Paganini, Jean-Baptiste Lespiau, Alexandre Moufarek, Samer Hassan, Kaushik Shivakumar, Amersfoort Joost van, Amol Mandhane, Pratik Joshi, Anirudh Goyal, Matthew Tung, Andrew Brock, Hannah Sheahan, Vedant Misra, Cheng Li, Nemanja RakiÄeviÄ, Mostafa Dehghani, Fangyu Liu, Sid Mittal, Junhyuk Oh, Seb Noury, Eren Sezener, Fantine Huot, Matthew Lamm, Cao Nicola De, Charlie Chen, Gamaleldin Elsayed, Ed Chi, Mahdis Mahdieh, Ian Tenney, Nan Hua, Ivan Petrychenko, Patrick Kane, Dylan Scandinaro, Rishub Jain, Jonathan Uesato, Romina Datta, Adam Sadovsky, Oskar Bunyan, Dominik Rabiej, Shimu Wu, John Zhang, Gautam Vasudevan, Edouard Leurent, Mahmoud Alnahlawi, Ionut Georgescu, Nan Wei, Ivy Zheng, Betty Chan, Pam G Rabinovitch, Piotr Stanczyk, Ye Zhang, David Steiner, Subhajit Naskar, Michael Azzam, Matthew Johnson, Adam Paszke, Chung-Cheng Chiu, Jaume Sanchez Elias, Afroz Mohiuddin, Faizan Muhammad, Jin Miao, Andrew Lee, Nino Vieillard, Sahitya Potluri, Jane Park, Elnaz Davoodi, Jiageng Zhang, Jeff Stanway, Drew Garmon, Abhijit Karmarkar, Zhe Dong, Jong Lee, Aviral Kumar, Luowei Zhou, Jonathan Evens, William Isaac, Zhe Chen, Johnson Jia, Anselm Levskaya, Zhenkai Zhu, Chris Gorgolewski, Peter Grabowski, Yu Mao, Alberto Magni, Kaisheng Yao, Javier Snaider, Norman Casagrande, Paul Suganthan, Evan Palmer, Geoffrey Irving, Edward Loper, Manaal Faruqui, Isha Arkatkar, Nanxin Chen, Izhak Shafran, Michael Fink, Alfonso CastaÃ±o, Irene Giannoumis, Wooyeol Kim, MikoÅaj RybiÅski, Ashwin Sreevatsa, Jennifer Prendki, David Soergel, Adrian Goedeckemeyer, Willi Gierke, Mohsen Jafari, Meenu Gaba, Jeremy Wiesner, Diana Gage Wright, Yawen Wei, Harsha Vashisht, Yana Kulizhskaya, Jay Hoover, Maigo Le, Lu Li, Chimezie Iwuanyanwu, Lu Liu, Kevin Ramirez, Andrey Khorlin, Albert Cui, Tian LIN, Marin Georgiev, Marcus Wu, Ricardo Aguilar, Keith Pallo, Abhishek Chakladar, Alena Repina, Xihui Wu, der Weide Tom van, Priya Ponnapalli, Caroline Kaplan, Jiri Simsa, Shuangfeng Li, Olivier Dousse, Fan Yang, Jeff Piper, Nathan Ie, Minnie Lui, Rama Pasumarthi, Nathan Lintz, Anitha Vijayakumar, Lam Nguyen Thiet, Daniel Andor, Pedro Valenzuela, Cosmin Paduraru, Daiyi Peng, Katherine Lee, Shuyuan Zhang, Somer Greene, Duc Dung Nguyen, Paula Kurylowicz, Sarmishta Velury, Sebastian Krause, Cassidy Hardin, Lucas Dixon, Lili Janzer, Kiam Choo, Ziqiang Feng, Biao Zhang, Achintya Singhal, Tejasi Latkar, Mingyang Zhang, Quoc Le, Elena Allica Abellan, Dayou Du, Dan McKinnon, Natasha Antropova, Tolga Bolukbasi, Orgad Keller, David Reid, Daniel Finchelstein, Maria Abi Raad, Remi Crocker, Peter Hawkins, Robert Dadashi, Colin Gaffney, Sid Lall, Ken Franko, Egor Filonov, Anna Bulanova, RÃ©mi Leblond, Vikas Yadav, Shirley Chung, Harry Askham, Luis C. Cobo, Kelvin Xu, Felix Fischer, Jun Xu, Christina Sorokin, Chris Alberti, Chu-Cheng Lin, Colin Evans, Hao Zhou, Alek Dimitriev, Hannah Forbes, Dylan Banarse, Zora Tung, Jeremiah Liu, Mark Omernick, Colton Bishop, Chintu Kumar, Rachel Sterneck, Ryan Foley, Rohan Jain, Swaroop Mishra, Jiawei Xia, Taylor Bos, Geoffrey Cideron, Ehsan Amid, Francesco Piccinno, Xingyu Wang, Praseem Banzal, Petru Gurita, Hila Noga, Premal Shah, Daniel J. Mankowitz, Alex Polozov, Nate Kushman, Victoria Krakovna, Sasha Brown, MohammadHossein Bateni, Dennis Duan, Vlad Firoiu, Meghana Thotakuri, Tom Natan, Anhad Mohananey, Matthieu Geist, Sidharth Mudgal, Sertan Girgin, Hui Li, Jiayu Ye, Ofir Roval, Reiko Tojo, Michael Kwong, James Lee-Thorp, Christopher Yew, Quan Yuan, Sumit Bagri, Danila Sinopalnikov, Sabela Ramos, John Mellor, Abhishek Sharma, Aliaksei Severyn, Jonathan Lai, Kathy Wu, Heng-Tze Cheng, David Miller, Nicolas Sonnerat, Denis Vnukov, Rory Greig, Jennifer Beattie, Emily Caveness, Libin Bai, Julian Eisenschlos, Alex Korchemniy, Tomy Tsai, Mimi Jasarevic, Weize Kong, Phuong Dao, Zeyu Zheng, Frederick Liu, Fan Yang, Rui Zhu, Mark Geller, Tian Huey Teh, Jason Sanmiya, Evgeny Gladchenko, Nejc Trdin, Andrei Sozanschi, Daniel Toyama, Evan Rosen, Sasan Tavakkol, Linting Xue, Chen Elkind, Oliver Woodman, John Carpenter, George Papamakarios, Rupert Kemp, Sushant Kafle, Tanya Grunina, Rishika Sinha, Alice Talbert, Abhimanyu Goyal, Diane Wu, Denese Owusu-Afriyie, Cosmo Du, Chloe Thornton, Jordi Pont-Tuset, Pradyumna Narayana, Jing Li, Sabaer Fatehi, John Wieting, Omar Ajmeri, Benigno Uria, Tao Zhu, Yeongil Ko, Laura Knight, AmÃ©lie HÃ©liou, Ning Niu, Shane Gu, Chenxi Pang, Dustin Tran, Yeqing Li, Nir Levine, Ariel Stolovich, Norbert Kalb, Rebeca Santamaria-Fernandez, Sonam Goenka, Wenny Yustalim, Robin Strudel, Ali Elqursh, Balaji Lakshminarayanan, Charlie Deck, Shyam Upadhyay, Hyo Lee, Mike Dusenberry, Zonglin Li, Xuezhi Wang, Kyle Levin, Raphael Hoffmann, Dan Holtmann-Rice, Olivier Bachem, Summer Yue, Sho Arora, Eric Malmi, Daniil Mirylenka, Qijun Tan, Christy Koh, Soheil Hassas Yeganeh, Siim PÃµder, Steven Zheng, Francesco Pongetti, Mukarram Tariq, Yanhua Sun, Lucian Ionita, Mojtaba Seyedhosseini, Pouya Tafti, Ragha Kotikalapudi, Zhiyu Liu, Anmol Gulati, Jasmine Liu, Xinyu Ye, Bart Chrzaszcz, Lily Wang, Nikhil Sethi, Tianrun Li, Ben Brown, Shreya Singh, Wei Fan, Aaron Parisi, Joe Stanton, Chenkai Kuang, Vinod Koverkathu, Christopher A. Choquette-Choo, Yunjie Li, TJ Lu, Abe Ittycheriah, Prakash Shroff, Pei Sun, Mani Varadarajan, Sanaz Bahargam, Rob Willoughby, David Gaddy, Ishita Dasgupta, Guillaume Desjardins, Marco Cornero, Brona Robenek, Bhavishya Mittal, Ben Albrecht, Ashish Shenoy, Fedor Moiseev, Henrik Jacobsson, Alireza Ghaffarkhah, Morgane RiviÃ¨re, Alanna Walton, ClÃ©ment Crepy, Alicia Parrish, Yuan Liu, Zongwei Zhou, Clement Farabet, Carey Radebaugh, Praveen Srinivasan, der Salm Claudia van, Andreas Fidjeland, Salvatore Scellato, Eri Latorre-Chimoto, Hanna Klimczak-PluciÅska, David Bridson, Cesare Dario de, Tom Hudson, Piermaria Mendolicchio, Lexi Walker, Alex Morris, Ivo Penchev, Matthew Mauger, Alexey Guseynov, Alison Reid, Seth Odoom, Lucia Loher, Victor Cotruta, Madhavi Yenugula, Dominik Grewe, Anastasia Petrushkina, Tom Duerig, Antonio Sanchez, Steve Yadlowsky, Amy Shen, Amir Globerson, Adam Kurzrok, Lynette Webb, Sahil Dua, Dong Li, Preethi Lahoti, Surya Bhupatiraju, Dan Hurt, Haroon Qureshi, Ananth Agarwal, Tomer Shani, Matan Eyal, Anuj Khare, Shreyas Rammohan Belle, Lei Wang, Chetan Tekur, Mihir Sanjay Kale, Jinliang Wei, Ruoxin Sang, Brennan Saeta, Tyler Liechty, Yi Sun, Yao Zhao, Stephan Lee, Pandu Nayak, Doug Fritz, Manish Reddy Vuyyuru, John Aslanides, Nidhi Vyas, Martin Wicke, Xiao Ma, Taylan Bilal, Evgenii Eltyshev, Daniel Balle, Nina Martin, Hardie Cate, James Manyika, Keyvan Amiri, Yelin Kim, Xi Xiong, Kai Kang, Florian Luisier, Nilesh Tripuraneni, David Madras, Mandy Guo, Austin Waters, Oliver Wang, Joshua Ainslie, Jason Baldridge, Han Zhang, Garima Pruthi, Jakob Bauer, Feng Yang, Riham Mansour, Jason Gelman, Yang Xu, George Polovets, Ji Liu, Honglong Cai, Warren Chen, XiangHai Sheng, Emily Xue, Sherjil Ozair, Adams Yu, Christof Angermueller, Xiaowei Li, Weiren Wang, Julia Wiesinger, Emmanouil Koukoumidis, Yuan Tian, Anand Iyer, Madhu Gurumurthy, Mark Goldenson, Parashar Shah, MK Blake, Hongkun Yu, Anthony Urbanowicz, Jennimaria Palomaki, Chrisantha Fernando, Kevin Brooks, Ken Durden, Harsh Mehta, Nikola Momchev, Elahe Rahimtoroghi, Maria Georgaki, Amit Raul, Sebastian Ruder, Morgan Redshaw, Jinhyuk Lee, Komal Jalan, Dinghua Li, Ginger Perng, Blake Hechtman, Parker Schuh, Milad Nasr, Mia Chen, Kieran Milan, Vladimir Mikulik, Trevor Strohman, Juliana Franco, Tim Green, Demis Hassabis, Koray Kavukcuoglu, Jeffrey Dean, Oriol Vinyals",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11805"" target=""_blank"">2312.11805</a>",,2024-12-11
DRAM-Locker: A General-Purpose DRAM Protection Mechanism against Adversarial DNN Weight Attacks,"Ranyang Zhou, Sabbir Ahmed, Arman Roohi, Adnan Siraj Rakin, Shaahin Angizi",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09027"" target=""_blank"">2312.09027</a>",,2024-12-11
VNN: Verification-Friendly Neural Networks with Hard Robustness Guarantees,"Anahita Baninajjar, Ahmed Rezine, Amir Aminifar",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09748"" target=""_blank"">2312.09748</a>",,2024-12-11
Silent Guardian: Protecting Text from Malicious Exploitation by Large Language Models,"Jiawei Zhao, Kejiang Chen, Xiaojian Yuan, Yuang Qi, Weiming Zhang, Nenghai Yu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09669"" target=""_blank"">2312.09669</a>",,2024-12-11
AVA: Inconspicuous Attribute Variation-based Adversarial Attack bypassing DeepFake Detection,"Xiangtao Meng, Li Wang, Shanqing Guo, Lei Ju, Qingchuan Zhao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08675"" target=""_blank"">2312.08675</a>",,2024-12-11
Continual Adversarial Defense,"Qian Wang, Yaoyao Liu, Hefei Ling, Yingwei Li, Qihao Liu, Ping Li, Jiazhong Chen, Alan Yuille, Ning Yu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09481"" target=""_blank"">2312.09481</a>",,2024-12-11
SlowTrack: Increasing the Latency of Camera-based Perception in Autonomous Driving Using Adversarial Examples,"Chen Ma, Ningfei Wang, Qi Alfred Chen, Chao Shen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09520"" target=""_blank"">2312.09520</a>",,2024-12-11
On the Difficulty of Defending Contrastive Learning against Backdoor Attacks,"Changjiang Li, Ren Pang, Bochuan Cao, Zhaohan Xi, Jinghui Chen, Shouling Ji, Ting Wang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09057"" target=""_blank"">2312.09057</a>",,2024-12-11
Detection and Defense of Unlearnable Examples,"Yifan Zhu, Lijia Yu, Xiao-Shan Gao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08898"" target=""_blank"">2312.08898</a>",,2024-12-11
Adv-Diffusion: Imperceptible Adversarial Face Identity Attack via Latent Diffusion Model,"Decheng Liu, Xijun Wang, Chunlei Peng, Nannan Wang, Ruiming Hu, Xinbo Gao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11285"" target=""_blank"">2312.11285</a>","<a href=""https://github.com/kopper-xdu/Adv-Diffusion"" target=""_blank"">kopper-xdu</a>",2024-12-11
Adversarial Robustness on Image Classification with $k$-means,"Rollin Omari, Junae Kim, Paul Montague",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09533"" target=""_blank"">2312.09533</a>",,2024-12-11
"Data and Model Poisoning Backdoor Attacks on Wireless Federated Learning, and the Defense Mechanisms: A Comprehensive Survey","Yichen Wan, Youyang Qu, Wei Ni, Yong Xiang, Longxiang Gao, Ekram Hossain",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08667"" target=""_blank"">2312.08667</a>",,2024-12-11
No-Skim: Towards Efficiency Robustness Evaluation on Skimming-based Language Models,"Shengyao Zhang, Mi Zhang, Xudong Pan, Min Yang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09494"" target=""_blank"">2312.09494</a>",,2024-12-11
Closing the Gap: Achieving Better Accuracy-Robustness Tradeoffs Against Query-Based Attacks,"Pascal Zimmer, SÃ©bastien Andreina, Giorgia Azzurra Marson, Ghassan Karame",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10132"" target=""_blank"">2312.10132</a>",,2024-12-11
Forbidden Facts: An Investigation of Competing Objectives in Llama-2,"Tony T. Wang, Miles Wang, Kaivalya Hariharan, Nir Shavit",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08793"" target=""_blank"">2312.08793</a>","<a href=""https://forbiddenfacts.github.io"" target=""_blank""></a>",2024-12-11
Coevolutionary Algorithm for Building Robust Decision Trees under Minimax Regret,"Adam Å»ychowski, Andrew Perrault, Jacek MaÅdziuk",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09078"" target=""_blank"">2312.09078</a>",,2024-12-11
Exploring Transferability for Randomized Smoothing,"Kai Qiu, Huishuai Zhang, Zhirong Wu, Stephen Lin",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09020"" target=""_blank"">2312.09020</a>",,2024-12-11
Erasing Self-Supervised Learning Backdoor by Cluster Activation Masking,"Shengsheng Qian, Dizhan Xue, Yifei Wang, Shengjie Zhang, Huaiwen Zhang, Changsheng Xu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07955"" target=""_blank"">2312.07955</a>",,2024-12-11
Split-Ensemble: Efficient OOD-aware Ensemble via Task and Model Splitting,"Anthony Chen, Huanrui Yang, Yulu Gan, Denis A Gudovskiy, Zhen Dong, Haofan Wang, Tomoyuki Okuno, Yohei Nakata, Shanghang Zhang, Kurt Keutzer",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09148"" target=""_blank"">2312.09148</a>","<a href=""https://antonioo-c.github.io/projects/split-ensemble"" target=""_blank"">projects</a>",2024-12-11
Defenses in Adversarial Machine Learning: A Survey,"Baoyuan Wu, Shaokui Wei, Mingli Zhu, Meixi Zheng, Zihao Zhu, Mingda Zhang, Hongrui Chen, Danni Yuan, Li Liu, Qingshan Liu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08890"" target=""_blank"">2312.08890</a>",,2024-12-11
Robust Few-Shot Named Entity Recognition with Boundary Discrimination and Correlation Purification,"Xiaojun Xue, Chunxia Zhang, Tianxiang Xu, Zhendong Niu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07961"" target=""_blank"">2312.07961</a>",,2024-12-11
Scalable Ensemble-based Detection Method against Adversarial Attacks for speaker verification,"Haibin Wu, Heng-Cheng Kuo, Yu Tsao, Hung-yi Lee",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08622"" target=""_blank"">2312.08622</a>",,2024-12-11
Accelerating the Global Aggregation of Local Explanations,"Alon Mor, Yonatan Belinkov, Benny Kimelfeld",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07991"" target=""_blank"">2312.07991</a>",,2024-12-11
Towards Inductive Robustness: Distilling and Fostering Wave-induced Resonance in Transductive GCNs Against Graph Adversarial Attacks,"Ao Liu, Wenshan Li, Tao Li, Beibei Li, Hanyuan Huang, Pan Zhou",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08651"" target=""_blank"">2312.08651</a>",,2024-12-11
"Fragility, Robustness and Antifragility in Deep Learning","Chandresh Pravin, Ivan Martino, Giuseppe Nicosia, Varun Ojha",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09821"" target=""_blank"">2312.09821</a>",,2024-12-11
Improve Robustness of Reinforcement Learning against Observation Perturbations via $l_\infty$ Lipschitz Policy Networks,"Buqing Nie, Jingtian Ji, Yangqing Fu, Yue Gao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08751"" target=""_blank"">2312.08751</a>",,2024-12-11
FlowMur: A Stealthy and Practical Audio Backdoor Attack with Limited Knowledge,"Jiahe Lan, Jie Wang, Baochen Yan, Zheng Yan, Elisa Bertino",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09665"" target=""_blank"">2312.09665</a>",,2024-12-11
A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection,"Xiaoyu Zhang, Cen Zhang, Tianlin Li, Yihao Huang, Xiaojun Jia, Xiaofei Xie, Yang Liu, Chao Shen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10766"" target=""_blank"">2312.10766</a>",,2024-12-11
The Ultimate Combo: Boosting Adversarial Example Transferability by Composing Data Augmentations,"Zebin Yun, Achi-Or Weingarten, Eyal Ronen, Mahmood Sharif",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11309"" target=""_blank"">2312.11309</a>",,2024-12-11
DataElixir: Purifying Poisoned Dataset to Mitigate Backdoor Attacks via Diffusion Models,"Jiachen Zhou, Peizhuo Lv, Yibing Lan, Guozhu Meng, Kai Chen, Hualong Ma",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11057"" target=""_blank"">2312.11057</a>",,2024-12-11
"A Comprehensive Survey of Attack Techniques, Implementation, and Mitigation Strategies in Large Language Models","Aysan Esmradi, Daniel Wankit Yip, Chun Fai Chan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10982"" target=""_blank"">2312.10982</a>",,2024-12-11
Model Stealing Attack against Recommender System,"Zhihao Zhu, Rui Fan, Chenwang Wu, Yi Yang, Defu Lian, Enhong Chen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11571"" target=""_blank"">2312.11571</a>",,2024-12-11
A Malware Classification Survey on Adversarial Attacks and Defences,"Mahesh Datta Sai Ponnuru, Likhitha Amasala, Tanu Sree Bhimavarapu, Guna Chaitanya Garikipati",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09636"" target=""_blank"">2312.09636</a>",,2024-12-11
"Model Stealing Attack against Graph Classification with Authenticity, Uncertainty and Diversity","Zhihao Zhu, Chenwang Wu, Rui Fan, Yi Yang, Defu Lian, Enhong Chen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10943"" target=""_blank"">2312.10943</a>",,2024-12-11
MISA: Unveiling the Vulnerabilities in Split Federated Learning,"Wei Wan, Yuxuan Ning, Shengshan Hu, Lulu Xue, Minghui Li, Leo Yu Zhang, Hai Jin",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11026"" target=""_blank"">2312.11026</a>",,2024-12-11
"A Survey of Side-Channel Attacks in Context of Cache -- Taxonomies, Analysis and Mitigation","Ankit Pulkit, Smita Naval, Vijay Laxmi",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11094"" target=""_blank"">2312.11094</a>",,2024-12-11
UltraClean: A Simple Framework to Train Robust Neural Networks against Backdoor Attacks,"Bingyin Zhao, Yingjie Lao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10657"" target=""_blank"">2312.10657</a>","<a href=""https://github.com/bxz9200/UltraClean"" target=""_blank"">bxz9200</a>",2024-12-11
The Pros and Cons of Adversarial Robustness,"Yacine Izza, Joao Marques-Silva",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10911"" target=""_blank"">2312.10911</a>",,2024-12-11
Universal Adversarial Framework to Improve Adversarial Robustness for Diabetic Retinopathy Detection,"Samrat Mukherjee, Dibyanayan Bandyopadhyay, Baban Gain, Asif Ekbal",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08193"" target=""_blank"">2312.08193</a>",,2024-12-11
Robust Node Representation Learning via Graph Variational Diffusion Networks,"Jun Zhuang, Mohammad Al Hasan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10903"" target=""_blank"">2312.10903</a>",,2024-12-11
TrojFair: Trojan Fairness Attacks,"Mengxin Zheng, Jiaqi Xue, Yi Sheng, Lei Yang, Qian Lou, Lei Jiang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10508"" target=""_blank"">2312.10508</a>",,2024-12-11
Towards Transferable Targeted 3D Adversarial Attack in the Physical World,"Yao Huang, Yinpeng Dong, Shouwei Ruan, Xiao Yang, Hang Su, Xingxing Wei",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09558"" target=""_blank"">2312.09558</a>",,2024-12-11
LogoStyleFool: Vitiating Video Recognition Systems via Logo Style Transfer,"Yuxin Cao, Ziyu Zhao, Xi Xiao, Derui Wang, Minhui Xue, Jin Lu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09935"" target=""_blank"">2312.09935</a>",,2024-12-11
TrojFSP: Trojan Insertion in Few-shot Prompt Tuning,"Mengxin Zheng, Jiaqi Xue, Xun Chen, YanShan Wang, Qian Lou, Lei Jiang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10467"" target=""_blank"">2312.10467</a>",,2024-12-11
Transformers in Unsupervised Structure-from-Motion,"Hemang Chawla, Arnav Varma, Elahe Arani, Bahram Zonooz",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10529"" target=""_blank"">2312.10529</a>",,2024-12-11
Embodied Adversarial Attack: A Dynamic Robust Physical Attack in Autonomous Driving,"Yitong Sun, Yao Huang, Xingxing Wei",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09554"" target=""_blank"">2312.09554</a>",,2024-12-11
Rethinking Robustness of Model Attributions,"Sandesh Kamath, Sankalp Mittal, Amit Deshpande, Vineeth N Balasubramanian",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10534"" target=""_blank"">2312.10534</a>","<a href=""https://github.com/ksandeshk/LENS"" target=""_blank"">ksandeshk</a>",2024-12-11
Perturbation-Invariant Adversarial Training for Neural Ranking Models: Improving the Effectiveness-Robustness Trade-Off,"Yu-An Liu, Ruqing Zhang, Mingkun Zhang, Wei Chen, Rijke Maarten de, Jiafeng Guo, Xueqi Cheng",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10329"" target=""_blank"">2312.10329</a>",,2024-12-11
A Study on Transferability of Deep Learning Models for Network Intrusion Detection,"Shreya Ghosh, Abu Shafin Mohammad Mahdee Jameel, Aly El Gamal",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11550"" target=""_blank"">2312.11550</a>","<a href=""https://github.com/ghosh64/transferability"" target=""_blank"">ghosh64</a>",2024-12-11
SAME: Sample Reconstruction Against Model Extraction Attacks,"Yi Xie, Jie Zhang, Shiqian Zhao, Tianwei Zhang, Xiaofeng Chen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10578"" target=""_blank"">2312.10578</a>","<a href=""https://github.com/xythink/SAME"" target=""_blank"">xythink</a>",2024-12-11
FigStep: Jailbreaking Large Vision-language Models via Typographic Visual Prompts,"Yichen Gong, Delong Ran, Jinyuan Liu, Conglei Wang, Tianshuo Cong, Anyu Wang, Sisi Duan, Xiaoyun Wang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05608"" target=""_blank"">2311.05608</a>",,2024-12-11
Robust Text Classification: Analyzing Prototype-Based Networks,"Zhivar Sourati, Darshan Deshpande, Filip Ilievski, Kiril Gashteovski, Sascha Saralajew",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06647"" target=""_blank"">2311.06647</a>",,2024-12-11
Multi-agent Attacks for Black-box Social Recommendations,"Wenqi Fan, Shijie Wang, Xiao-yong Wei, Xiaowei Mei, Shanru Lin, Qing Li",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07127"" target=""_blank"">2311.07127</a>",,2024-12-11
On the Robustness of Neural Collapse and the Neural Collapse of Robustness,"Jingtong Su, Ya Shi Zhang, Nikolaos Tsilivis, Julia Kempe",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07444"" target=""_blank"">2311.07444</a>",,2024-12-11
Tabdoor: Backdoor Vulnerabilities in Transformer-based Neural Networks for Tabular Data,"Bart Pleiter, Behrad Tajalli, Stefanos Koffas, Gorka Abad, Jing Xu, Martha Larson, Stjepan Picek",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07550"" target=""_blank"">2311.07550</a>",,2024-12-11
Learning Globally Optimized Language Structure via Adversarial Training,Xuwang Yin,arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06771"" target=""_blank"">2311.06771</a>",,2024-12-11
Resilient Graph Neural Networks: A Coupled Dynamical Systems Approach,"Moshe Eliasof, Davide Murari, Ferdia Sherry, Carola-Bibiane SchÃ¶nlieb",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06942"" target=""_blank"">2311.06942</a>",,2024-12-11
Analytical Verification of Deep Neural Network Performance for Time-Synchronized Distribution System State Estimation,"Behrouz Azimian, Shiva Moshtagh, Anamitra Pal, Shanshan Ma",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06973"" target=""_blank"">2311.06973</a>",,2024-12-11
DialMAT: Dialogue-Enabled Transformer with Moment-Based Adversarial Training,"Kanta Kaneda, Ryosuke Korekata, Yuiga Wada, Shunya Nagashima, Motonari Kambara, Yui Iioka, Haruka Matsuo, Yuto Imai, Takayuki Nishimura, Komei Sugiura",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06855"" target=""_blank"">2311.06855</a>",,2024-12-11
Fight Fire with Fire: Combating Adversarial Patch Attacks using Pattern-randomized Defensive Patches,"Jianan Feng, Jiachun Li, Changqing Miao, Jianjun Huang, Wei You, Wenchang Shi, Bin Liang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06122"" target=""_blank"">2311.06122</a>",,2024-12-11
Robust Adversarial Attacks Detection for Deep Learning based Relative Pose Estimation for Space Rendezvous,"Ziwei Wang, Nabil Aouf, Jose Pizarro, Christophe Honvault",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05992"" target=""_blank"">2311.05992</a>",,2024-12-11
Transferability Bound Theory: Exploring Relationship between Adversarial Transferability and Flatness,"Mingyuan Fan, Xiaodan Li, Cen Chen, Wenmeng Zhou, Yaliang Li",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06423"" target=""_blank"">2311.06423</a>","<a href=""https://github.com/fmy266/TPA>"" target=""_blank"">fmy266</a>",2024-12-11
Resilient and constrained consensus against adversarial attacks: A distributed MPC framework,"Henglai Wei, Kunwu Zhang, Hui Zhang, Yang Shi",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05935"" target=""_blank"">2311.05935</a>",,2024-12-11
FireMatch: A Semi-Supervised Video Fire Detection Network Based on Consistency and Distribution Alignment,"Qinghua Lin, Zuoyong Li, Kun Zeng, Haoyi Fan, Wei Li, Xiaoguang Zhou",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05168"" target=""_blank"">2311.05168</a>",,2024-12-11
CALLOC: Curriculum Adversarial Learning for Secure and Robust Indoor Localization,"Danish Gufran, Sudeep Pasricha",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06361"" target=""_blank"">2311.06361</a>",,2024-12-11
Practical Membership Inference Attacks against Fine-tuned Large Language Models via Self-prompt Calibration,"Wenjie Fu, Huandong Wang, Chen Gao, Guanghua Liu, Yong Li, Tao Jiang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06062"" target=""_blank"">2311.06062</a>",,2024-12-11
ABIGX: A Unified Framework for eXplainable Fault Detection and Classification,"Yue Zhuo, Jinchuan Qian, Zhihuan Song, Zhiqiang Ge",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05316"" target=""_blank"">2311.05316</a>",,2024-12-11
Honest Score Client Selection Scheme: Preventing Federated Learning Label Flipping Attacks in Non-IID Scenarios,"Yanli Li, Huaming Chen, Wei Bao, Zhengmeng Xu, Dong Yuan",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05826"" target=""_blank"">2311.05826</a>",,2024-12-11
Scale-MIA: A Scalable Model Inversion Attack against Secure Federated Learning via Latent Space Reconstruction,"Shanghao Shi, Ning Wang, Yang Xiao, Chaoyu Zhang, Yi Shi, Y. Thomas Hou, Wenjing Lou",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05808"" target=""_blank"">2311.05808</a>",,2024-12-11
Towards more Practical Threat Models in Artificial Intelligence Security,"Kathrin Grosse, Lukas Bieringer, Tarek Richard Besold, Alexandre Alahi",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09994"" target=""_blank"">2311.09994</a>",,2024-12-11
An Extensive Study on Adversarial Attack against Pre-trained Models of Code,"Xiaohu Du, Ming Wen, Zichao Wei, Shangwen Wang, Hai Jin",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07553"" target=""_blank"">2311.07553</a>",,2024-12-11
MirrorNet: A TEE-Friendly Framework for Secure On-device DNN Inference,"Ziyu Liu, Yukui Luo, Shijin Duan, Tong Zhou, Xiaolin Xu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09489"" target=""_blank"">2311.09489</a>",,2024-12-11
Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities,"Avishree Khare, Saikat Dutta, Ziyang Li, Alaia Solko-Breslin, Rajeev Alur, Mayur Naik",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16169"" target=""_blank"">2311.16169</a>",,2024-12-11
Army of Thieves: Enhancing Black-Box Model Extraction via Ensemble based sample selection,"Akshit Jindal, Vikram Goyal, Saket Anand, Chetan Arora",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.04588"" target=""_blank"">2311.04588</a>",,2024-12-11
You Cannot Escape Me: Detecting Evasions of SIEM Rules in Enterprise Networks,"Rafael Uetz, Marco Herzog, Louis HacklÃ¤nder, Simon Schwarz, Martin Henze",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.10197"" target=""_blank"">2311.10197</a>",,2024-12-11
Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts,"Yuanwei Wu, Xiang Li, Yixin Liu, Pan Zhou, Lichao Sun",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09127"" target=""_blank"">2311.09127</a>",,2024-12-11
Backdoor Activation Attack: Attack Large Language Models using Activation Steering for Safety-Alignment,"Haoran Wang, Kai Shu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09433"" target=""_blank"">2311.09433</a>","<a href=""https://github.com/wang2226/Backdoor-Activation-Attack"" target=""_blank"">wang2226</a>",2024-12-11
Fast Certification of Vision-Language Models Using Incremental Randomized Smoothing,"A K Iowa State University Nirala, A New York University Joshi, C New York University Hegde, S Iowa State University Sarkar",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09024"" target=""_blank"">2311.09024</a>",,2024-12-11
Adversarially Robust Spiking Neural Networks Through Conversion,"Ozan Ãzdenizci, Robert Legenstein",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09266"" target=""_blank"">2311.09266</a>",,2024-12-11
How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities,"Lingbo Mo, Boshi Wang, Muhao Chen, Huan Sun",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09447"" target=""_blank"">2311.09447</a>",,2024-12-11
Privacy Threats in Stable Diffusion Models,"Thomas Cilloni, Charles Fleming, Charles Walter",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09355"" target=""_blank"">2311.09355</a>",,2024-12-11
JAB: Joint Adversarial Prompting and Belief Augmentation,"Ninareh Mehrabi, Palash Goyal, Anil Ramakrishna, Jwala Dhamala, Shalini Ghosh, Richard Zemel, Kai-Wei Chang, Aram Galstyan, Rahul Gupta",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09473"" target=""_blank"">2311.09473</a>",,2024-12-11
Parrot-Trained Adversarial Examples: Pushing the Practicality of Black-Box Audio Attacks against Speaker Recognition Models,"Rui Duan, Zhe Qu, Leah Ding, Yao Liu, Zhuo Lu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07780"" target=""_blank"">2311.07780</a>",,2024-12-11
Beyond Detection: Unveiling Fairness Vulnerabilities in Abusive Language Models,"Yueqing Liang, Lu Cheng, Ali Payani, Kai Shu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09428"" target=""_blank"">2311.09428</a>",,2024-12-11
Towards Improving Robustness Against Common Corruptions in Object Detectors Using Adversarial Contrastive Learning,"Shashank Kotyan, Danilo Vasconcellos Vargas",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07928"" target=""_blank"">2311.07928</a>",,2024-12-11
Physical Adversarial Examples for Multi-Camera Systems,"Ana RÄduÅ£oiu, Jan-Philipp Schulze, Philip Sperl, Konstantin BÃ¶ttinger",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.08539"" target=""_blank"">2311.08539</a>",,2024-12-11
DALA: A Distribution-Aware LoRA-Based Adversarial Attack against Language Models,"Yibo Wang, Xiangjue Dong, James Caverlee, Philip S. Yu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.08598"" target=""_blank"">2311.08598</a>",,2024-12-11
On The Relationship Between Universal Adversarial Attacks And Sparse Representations,"Dana Weitzner, Raja Giryes",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.08265"" target=""_blank"">2311.08265</a>","<a href=""https://github.com/danawr/adversarial_attacks_and_sparse_representations"" target=""_blank"">danawr</a>",2024-12-11
A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily,"Peng Ding, Jun Kuang, Dan Ma, Xuezhi Cao, Yunsen Xian, Jiajun Chen, Shujian Huang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.08268"" target=""_blank"">2311.08268</a>","<a href=""https://github.com/NJUNLP/ReNeLLM"" target=""_blank"">NJUNLP</a>",2024-12-11
Evaluating Concurrent Robustness of Language Models Across Diverse Challenge Sets,"Vatsal Gupta, Pranshu Pandya, Tushar Kataria, Vivek Gupta, Dan Roth",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.08662"" target=""_blank"">2311.08662</a>",,2024-12-11
The Perception-Robustness Tradeoff in Deterministic Image Restoration,"Guy Ohayon, Tomer Michaeli, Michael Elad",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09253"" target=""_blank"">2311.09253</a>",,2024-12-11
Adversarial Purification for Data-Driven Power System Event Classifiers with Diffusion Models,"Yuanbin Cheng, Koji Yamashita, Jim Follum, Nanpeng Yu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07110"" target=""_blank"">2311.07110</a>",,2024-12-11
Constrained Adaptive Attacks: Realistic Evaluation of Adversarial Examples and Robust Training of Deep Neural Networks for Tabular Data,"Thibault Simonetto, Salah Ghamizi, Antoine Desjardins, Maxime Cordy, Yves Le Traon",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.04503"" target=""_blank"">2311.04503</a>",,2024-12-11
Universal Perturbation-based Secret Key-Controlled Data Hiding,"Donghua Wang, Wen Yao, Tingsong Jiang, Xiaoqian Chen",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01696"" target=""_blank"">2311.01696</a>",,2024-12-11
"Frontier Language Models are not Robust to Adversarial Arithmetic, or ""What do I need to say so you agree 2+2=5? (61%)","C. Daniel Freeman, Laura Culp, Aaron Parisi, Maxwell L Bileschi, Gamaleldin F Elsayed, Alex Rizkowsky, Isabelle Simpson, Alex Alemi, Azade Nova, Ben Adlam, Bernd Bohnet, Gaurav Mishra, Hanie Sedghi, Igor Mordatch, Izzeddin Gur, Jaehoon Lee, JD Co-Reyes, Jeffrey Pennington, Kelvin Xu, Kevin Swersky, Kshiteej Mahajan, Lechao Xiao, Rosanne Liu, Simon Kornblith, Noah Constant, Peter J. Liu, Roman Novak, Yundi Qian, Noah Fiedel, Jascha Sohl-Dickstein",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07587"" target=""_blank"">2311.07587</a>",,2024-12-11
Robust Safety Classifier for Large Language Models: Adversarial Prompt Shield,"Jinhwa Kim, Ali Derakhshan, Ian G. Harris",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00172"" target=""_blank"">2311.00172</a>",,2024-12-11
E(2) Equivariant Neural Networks for Robust Galaxy Morphology Classification,"Sneh Pandya, Purvik Patel, Franc O, Jonathan Blazek",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01500"" target=""_blank"">2311.01500</a>","<a href=""https://github.com/snehjp2/GCNNMorphology"" target=""_blank"">snehjp2</a>",2024-12-11
Robust Identity Perceptual Watermark Against Deepfake Face Swapping,"Tianyi Wang, Mengxiao Huang, Harry Cheng, Bin Ma, Yinglong Wang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01357"" target=""_blank"">2311.01357</a>",,2024-12-11
NEO-KD: Knowledge-Distillation-Based Adversarial Training for Robust Multi-Exit Neural Networks,"Seokil Ham, Jungwuk Park, Dong-Jun Han, Jaekyun Moon",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00428"" target=""_blank"">2311.00428</a>",,2024-12-11
Adversarial Examples in the Physical World: A Survey,"Jiakai Wang, Donghua Wang, Jin Hu, Siyang Wu, Tingsong Jiang, Wen Yao, Aishan Liu, Xianglong Liu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01473"" target=""_blank"">2311.01473</a>",,2024-12-11
Optimal Cost Constrained Adversarial Attacks For Multiple Agent Systems,"Ziqing Lu, Guanlin Liu, Lifeng Cai, Weiyu Xu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00859"" target=""_blank"">2311.00859</a>",,2024-12-11
Improving Robustness for Vision Transformer with a Simple Dynamic Scanning Augmentation,"Shashank Kotyan, Danilo Vasconcellos Vargas",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00441"" target=""_blank"">2311.00441</a>",,2024-12-11
MIST: Defending Against Membership Inference Attacks Through Membership-Invariant Subspace Training,"Jiacheng Li, Ninghui Li, Bruno Ribeiro",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00919"" target=""_blank"">2311.00919</a>",,2024-12-11
Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks,"Yichen Huang, Timothy Baldwin",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00508"" target=""_blank"">2311.00508</a>",,2024-12-11
Open-Set Face Recognition with Maximal Entropy and Objectosphere Loss,"Rafael Henrique Vareto, Yu Linghu, Terrance E. Boult, William Robson Schwartz, Manuel GÃ¼nther",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00400"" target=""_blank"">2311.00400</a>",,2024-12-11
Magmaw: Modality-Agnostic Adversarial Attacks on Machine Learning-Based Wireless Communication Systems,"Jung-Woo Chang, Ke Sun, Nasimeh Heydaribeni, Seira Hidano, Xinyu Zhang, Farinaz Koushanfar",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00207"" target=""_blank"">2311.00207</a>",,2024-12-11
SCAAT: Improving Neural Network Interpretability via Saliency Constrained Adaptive Adversarial Training,"Rui Xu, Wenkang Qin, Peixiang Huang, Haowang, Lin Luo",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05143"" target=""_blank"">2311.05143</a>",,2024-12-11
BAGEL: Backdoor Attacks against Federated Contrastive Learning,"Yao Huang, Kongyang Chen, Jiannong Cao, Jiaxing Shen, Shaowei Wang, Yun Peng, Weilong Peng, Kechao Cai",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16113"" target=""_blank"">2311.16113</a>",,2024-12-11
DiffAttack: Evasion Attacks Against Diffusion-Based Adversarial Purification,"Mintong Kang, Dawn Song, Bo Li",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16124"" target=""_blank"">2311.16124</a>",,2024-12-11
Unscrambling the Rectification of Adversarial Attacks Transferability across Computer Networks,"Ehsan Nowroozi, Samaneh Ghelichkhani, Imran Haider, Ali Dehghantanha",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.03373"" target=""_blank"">2311.03373</a>",,2024-12-11
Toward effective protection against diffusion based mimicry through score distillation,"Haotian Xue, Chumeng Liang, Xiaoyu Wu, Yongxin Chen",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12832"" target=""_blank"">2311.12832</a>","<a href=""https://github.com/xavihart/Diff-Protect"" target=""_blank"">xavihart</a>",2024-12-11
Adversarial sample generation and training using geometric masks for accurate and resilient license plate character recognition,"Bishal Shrestha, Griwan Khakurel, Kritika Simkhada, Badri Adhikari",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12857"" target=""_blank"">2311.12857</a>",,2024-12-11
RAEDiff: Denoising Diffusion Probabilistic Models Based Reversible Adversarial Examples Self-Generation and Self-Recovery,"Fan Xing, Xiaoyi Zhou, Xuefeng Fan, Zhuo Tian, Yan Zhao",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12858"" target=""_blank"">2311.12858</a>",,2024-12-11
Imperceptible CMOS camera dazzle for adversarial attacks on deep neural networks,"Zvi Stein, Adrian Stern",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16118"" target=""_blank"">2311.16118</a>",,2024-12-11
RLHFPoison: Reward Poisoning Attack for Reinforcement Learning with Human Feedback in Large Language Models,"Jiongxiao Wang, Junlin Wu, Muhao Chen, Yevgeniy Vorobeychik, Chaowei Xiao",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09641"" target=""_blank"">2311.09641</a>",,2024-12-11
Can We Trust the Similarity Measurement in Federated Learning? (15%),"Zhilin Wang, Qin Hu, Xukai Zou",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.03369"" target=""_blank"">2311.03369</a>",,2024-12-11
Sequential Subset Matching for Dataset Distillation,"Jiawei Du, Qin Shi, Joey Tianyi Zhou",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01570"" target=""_blank"">2311.01570</a>","<a href=""https://github.com/shqii1j/seqmatch"" target=""_blank"">shqii1j</a>",2024-12-11
Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula,"Aryaman Reddi, Maximilian TÃ¶lle, Jan Peters, Georgia Chalvatzaki, Carlo D'Eramo",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01642"" target=""_blank"">2311.01642</a>",,2024-12-11
Assist Is Just as Important as the Goal: Image Resurfacing to Aid Model's Robust Prediction,"Abhijith Sharma, Phil Munz, Apurva Narayan",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01563"" target=""_blank"">2311.01563</a>",,2024-12-11
Distilling Out-of-Distribution Robustness from Vision-Language Foundation Models,"Andy Zhou, Jindong Wang, Yu-Xiong Wang, Haohan Wang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01441"" target=""_blank"">2311.01441</a>",,2024-12-11
Domain Adaptive Object Detection via Balancing Between Self-Training and Adversarial Learning,"Muhammad Akhtar Munir, Muhammad Haris Khan, M. Saquib Sarfraz, Mohsen Ali",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.04815"" target=""_blank"">2311.04815</a>",,2024-12-11
Counter-Empirical Attacking based on Adversarial Reinforcement Learning for Time-Relevant Scoring System,"Xiangguo Sun, Hong Cheng, Hang Dong, Bo Qiao, Si Qin, Qingwei Lin",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05144"" target=""_blank"">2311.05144</a>",,2024-12-11
Unveiling Safety Vulnerabilities of Large Language Models,"George Kour, Marcel Zalmanovici, Naama Zwerdling, Esther Goldbraich, Ora Nova Fandina, Ateret Anaby-Tavor, Orna Raz, Eitan Farchi",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.04124"" target=""_blank"">2311.04124</a>",,2024-12-11
When Fairness Meets Privacy: Exploring Privacy Threats in Fair Binary Classifiers through Membership Inference Attacks,"Huan Tian, Guangsheng Zhang, Bo Liu, Tianqing Zhu, Ming Ding, Wanlei Zhou",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.03865"" target=""_blank"">2311.03865</a>",,2024-12-11
Identifying and Mitigating Vulnerabilities in LLM-Integrated Applications,"Fengqing Jiang, Zhangchen Xu, Luyao Niu, Boxin Wang, Jinyuan Jia, Bo Li, Radha Poovendran",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16153"" target=""_blank"">2311.16153</a>",,2024-12-11
SoK: Security Below the OS -- A Security Analysis of UEFI,"Priyanka Prakash Surve, Oleg Brodt, Mark Yampolskiy, Yuval Elovici, Asaf Shabtai",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.03809"" target=""_blank"">2311.03809</a>",,2024-12-11
Do LLMs exhibit human-like response biases? A case study in survey design,"Lindia Tjuatja, Valerie Chen, Sherry Tongshuang Wu, Ameet Talwalkar, Graham Neubig",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.04076"" target=""_blank"">2311.04076</a>","<a href=""https://github.com/lindiatjuatja/BiasMonkey"" target=""_blank"">lindiatjuatja</a>",2024-12-11
Measuring Adversarial Datasets,"Yuanchen Bai, Raoyi Huang, Vijay Viswanathan, Tzu-Sheng Kuo, Tongshuang Wu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.03566"" target=""_blank"">2311.03566</a>",,2024-12-11
Can LLMs Follow Simple Rules? (68%),"Norman Mu, Sarah Chen, Zifan Wang, Sizhe Chen, David Karamardian, Lulwa Aljeraisy, Basel Alomair, Dan Hendrycks, David Wagner",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.04235"" target=""_blank"">2311.04235</a>",,2024-12-11
Preserving Privacy in GANs Against Membership Inference Attack,"Mohammadhadi Shateri, Francisco Messina, Fabrice Labeau, Pablo Piantanida",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.03172"" target=""_blank"">2311.03172</a>",,2024-12-11
Cal-DETR: Calibrated Detection Transformer,"Muhammad Akhtar Munir, Salman Khan, Muhammad Haris Khan, Mohsen Ali, Fahad Shahbaz Khan",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.03570"" target=""_blank"">2311.03570</a>","<a href=""https://github.com/akhtarvision/cal-detr"" target=""_blank"">akhtarvision</a>",2024-12-11
ELEGANT: Certified Defense on the Fairness of Graph Neural Networks,"Yushun Dong, Binchi Zhang, Hanghang Tong, Jundong Li",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.02757"" target=""_blank"">2311.02757</a>","<a href=""https://github.com/yushundong/ELEGANT"" target=""_blank"">yushundong</a>",2024-12-11
From Trojan Horses to Castle Walls: Unveiling Bilateral Data Poisoning Effects in Diffusion Models,"Zhuoshi Pan, Yuguang Yao, Gaowen Liu, Bingquan Shen, H. Vicky Zhao, Ramana Rao Kompella, Sijia Liu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.02373"" target=""_blank"">2311.02373</a>",,2024-12-11
Efficient Black-Box Adversarial Attacks on Neural Text Detectors,"Vitalii Fishchuk, Daniel Braun",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01873"" target=""_blank"">2311.01873</a>",,2024-12-11
The Alignment Problem in Context,RaphaÃ«l MilliÃ¨re,arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.02147"" target=""_blank"">2311.02147</a>",,2024-12-11
Adversary ML Resilience in Autonomous Driving Through Human Centered Perception Mechanisms,Aakriti Shah,arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01478"" target=""_blank"">2311.01478</a>",,2024-12-11
"Towards Evaluating Transfer-based Attacks Systematically, Practically, and Fairly","Qizhang Li, Yiwen Guo, Wangmeng Zuo, Hao Chen",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01323"" target=""_blank"">2311.01323</a>","<a href=""https://github.com/qizhangli/TA-Bench"" target=""_blank"">qizhangli</a>",2024-12-11
Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game,"Sam Toyer, Olivia Watkins, Ethan Adrian Mendes, Justin Svegliato, Luke Bailey, Tiffany Wang, Isaac Ong, Karim Elmaaroufi, Pieter Abbeel, Trevor Darrell, Alan Ritter, Stuart Russell",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01011"" target=""_blank"">2311.01011</a>",,2024-12-11
On the Lipschitz constant of random neural networks,"Paul Geuchen, Thomas Heindl, Dominik StÃ¶ger, Felix Voigtlaender",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01356"" target=""_blank"">2311.01356</a>",,2024-12-11
Towards Improving Robustness Against Common Corruptions using Mixture of Class Specific Experts,"Shashank Kotyan, Danilo Vasconcellos Vargas",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.10177"" target=""_blank"">2311.10177</a>",,2024-12-11
Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization,"Zhexin Zhang, Junxiao Yang, Pei Ke, Fei Mi, Hongning Wang, Minlie Huang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09096"" target=""_blank"">2311.09096</a>","<a href=""https://github.com/thu-coai/JailbreakDefense_GoalPriority"" target=""_blank"">thu-coai</a>",2024-12-11
Test-time Backdoor Mitigation for Black-Box Large Language Models with Defensive Demonstrations,"Wenjie Mo, Jiashu Xu, Qin Liu, Jiongxiao Wang, Jun Yan, Chaowei Xiao, Muhao Chen",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09763"" target=""_blank"">2311.09763</a>",,2024-12-11
Rethinking Mixup for Improving the Adversarial Transferability,"Xiaosen Wang, Zeyuan Yin",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17087"" target=""_blank"">2311.17087</a>",,2024-12-11
"1-Lipschitz Layers Compared: Memory, Speed, and Certifiable Robustness","Bernd Prach, Fabio Brau, Giorgio Buttazzo, Christoph H. Lampert",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16833"" target=""_blank"">2311.16833</a>","<a href=""https://github.com/berndprach/1LipschitzLayersCompared"" target=""_blank"">berndprach</a>",2024-12-11
Scalable Extraction of Training Data from (Production) Language Models,"Milad Nasr, Nicholas Carlini, Jonathan Hayase, Matthew Jagielski, A. Feder Cooper, Daphne Ippolito, Christopher A. Choquette-Choo, Eric Wallace, Florian TramÃ¨r, Katherine Lee",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17035"" target=""_blank"">2311.17035</a>",,2024-12-11
Cooperative Abnormal Node Detection with Adversary Resistance,"Yingying Huangfu, Tian Bai",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16661"" target=""_blank"">2311.16661</a>",,2024-12-11
On robust overfitting: adversarial training induced distribution matters,"Runzhi Tian, Yongyi Mao",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16526"" target=""_blank"">2311.16526</a>",,2024-12-11
Understanding the (Extra-)Ordinary: Validating Deep Model Decisions with Prototypical Concept-based Explanations,"Maximilian Dreyer, Reduan Achtibat, Wojciech Samek, Sebastian Lapuschkin",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16681"" target=""_blank"">2311.16681</a>","<a href=""https://github.com/maxdreyer/pcx"" target=""_blank"">maxdreyer</a>",2024-12-11
Shadows Don't Lie and Lines Can't Bend! Generative Models don't know Projective Geometry,"Ayush Sarkar, Hanlin Mai, Amitabh Mahapatra, Svetlana Lazebnik, D. A. Forsyth, Anand Bhattad",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17138"" target=""_blank"">2311.17138</a>",,2024-12-11
Enhancing Cyber-Resilience in Integrated Energy System Scheduling with Demand Response Using Deep Reinforcement Learning,"Yang Li, Wenjie Ma, Yuanzheng Li, Sen Li, Zhe Chen, Mohammad Shahidehpor",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17941"" target=""_blank"">2311.17941</a>",,2024-12-11
RetouchUAA: Unconstrained Adversarial Attack via Image Retouching,"Mengda Xie, Yiling He, Meie Fang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16478"" target=""_blank"">2311.16478</a>",,2024-12-11
Adversaral Doodles: Interpretable and Human-drawable Attacks Provide Describable Insights,"Ryoya Nara, Yusuke Matsui",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15994"" target=""_blank"">2311.15994</a>",,2024-12-11
Instruct2Attack: Language-Guided Semantic Adversarial Attacks,"Jiang Liu, Chen Wei, Yuxiang Guo, Heng Yu, Alan Yuille, Soheil Feizi, Chun Pong Lau, Rama Chellappa",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15551"" target=""_blank"">2311.15551</a>",,2024-12-11
Confidence Is All You Need for MI Attacks,"Abhishek Sinha, Himanshi Tibrewal, Mansi Gupta, Nikhar Waghela, Shivank Garg",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15373"" target=""_blank"">2311.15373</a>",,2024-12-11
CLAP: Contrastive Learning with Augmented Prompts for Robustness on Pretrained Vision-Language Models,"Yichao Cai, Yuhang Liu, Zhen Zhang, Javen Qinfeng Shi",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16445"" target=""_blank"">2311.16445</a>",,2024-12-11
A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective,"Xianghua Xie, Chen Hu, Hanchi Ren, Jingjing Deng",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16065"" target=""_blank"">2311.16065</a>",,2024-12-11
Threshold Breaker: Can Counter-Based RowHammer Prevention Mechanisms Truly Safeguard DRAM? (31%),"Ranyang Zhou, Jacqueline Liu, Sabbir Ahmed, Nakul Kochar, Adnan Siraj Rakin, Shaahin Angizi",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16460"" target=""_blank"">2311.16460</a>",,2024-12-11
Distributed Attacks over Federated Reinforcement Learning-enabled Cell Sleep Control,"Han Zhang, Hao Zhou, Medhat Elsayed, Majid Bavand, Raimundas Gaigalas, Yigit Ozcan, Melike Erol-Kantarci",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15894"" target=""_blank"">2311.15894</a>",,2024-12-11
"""Do Users fall for Real Adversarial Phishing?"" Investigating the Human response to Evasive Webpages","Ajka Draganovic, Savino Dambra, Javier Aldana Iuit, Kevin Roundy, Giovanni Apruzzese",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16383"" target=""_blank"">2311.16383</a>",,2024-12-11
How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for Vision LLMs,"Haoqin Tu, Chenhang Cui, Zijun Wang, Yiyang Zhou, Bingchen Zhao, Junlin Han, Wangchunshu Zhou, Huaxiu Yao, Cihang Xie",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16101"" target=""_blank"">2311.16101</a>","<a href=""https://github.com/UCSC-VLAA/vllm-safety-benchmark"" target=""_blank"">UCSC-VLAA</a>",2024-12-11
Microarchitectural Security of AWS Firecracker VMM for Serverless Cloud Platforms,"Zane Worcester Polytechnic Institute Weissman, Thore University of LÃ¼beck Tiemann, Thomas University of LÃ¼beck Eisenbarth, Berk Worcester Polytechnic Institute Sunar",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15999"" target=""_blank"">2311.15999</a>",,2024-12-11
Adversarial Purification of Information Masking,"Sitong Liu, Zhichao Lian, Shuangquan Zhang, Liang Xiao",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15339"" target=""_blank"">2311.15339</a>","<a href=""https://github.com/NoWindButRain/IMPure"" target=""_blank"">NoWindButRain</a>",2024-12-11
Having Second Thoughts? Let's hear it,"Jung H. Lee, Sujith Vijayan",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15356"" target=""_blank"">2311.15356</a>",,2024-12-11
RADAP: A Robust and Adaptive Defense Against Diverse Adversarial Patches on Face Recognition,"Xiaoliang Liu, Furao Shen, Jian Zhao, Changhai Nie",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17339"" target=""_blank"">2311.17339</a>",,2024-12-11
Efficient Key-Based Adversarial Defense for ImageNet by Using Pre-trained Model,"AprilPyone MaungMaung, Isao Echizen, Hitoshi Kiya",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16577"" target=""_blank"">2311.16577</a>",,2024-12-11
NeRFTAP: Enhancing Transferability of Adversarial Patches on Face Recognition using Neural Radiance Fields,"Xiaoliang Liu, Furao Shen, Feng Han, Jian Zhao, Changhai Nie",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17332"" target=""_blank"">2311.17332</a>",,2024-12-11
Vulnerability Analysis of Transformer-based Optical Character Recognition to Adversarial Attacks,"Lucas Beerens, Desmond J. Higham",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17128"" target=""_blank"">2311.17128</a>",,2024-12-11
Improving Adversarial Transferability via Model Alignment,"Avery Ma, Amir-massoud Farahmand, Yangchen Pan, Philip Torr, Jindong Gu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.18495"" target=""_blank"">2311.18495</a>",,2024-12-11
Corrupting Convolution-based Unlearnable Datasets with Pixel-based Image Transformations,"Xianlong Wang, Shengshan Hu, Minghui Li, Zhifei Yu, Ziqi Zhou, Leo Yu Zhang, Hai Jin",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.18403"" target=""_blank"">2311.18403</a>",,2024-12-11
Data-Agnostic Model Poisoning against Federated Learning: A Graph Autoencoder Approach,"Kai Li, Jingjing Zheng, Xin Yuan, Wei Ni, Ozgur B. Akan, H. Vincent Poor",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.18498"" target=""_blank"">2311.18498</a>",,2024-12-11
Improving the Robustness of Transformer-based Large Language Models with Dynamic Attention,"Lujia Shen, Yuwen Pu, Shouling Ji, Changjiang Li, Xuhong Zhang, Chunpeng Ge, Ting Wang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17400"" target=""_blank"">2311.17400</a>",,2024-12-11
Adversarial Attacks and Defenses for Wireless Signal Classifiers using CDI-aware GANs,"Sujata Sinha, Alkan Soysal",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.18820"" target=""_blank"">2311.18820</a>",,2024-12-11
Group-wise Sparse and Explainable Adversarial Attacks,"Shpresim Sadiku, Moritz Wagner, Sebastian Pokutta",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17434"" target=""_blank"">2311.17434</a>",,2024-12-11
Quantum Neural Networks under Depolarization Noise: Exploring White-Box Attacks and Defenses,"David Winderl, Nicola Franco, Jeanette Miriam Lorenz",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17458"" target=""_blank"">2311.17458</a>",,2024-12-11
On the Adversarial Robustness of Graph Contrastive Learning Methods,"Filippo Guerranti, Zinuo Yi, Anna Starovoit, Rafiq Kamel, Simon Geisler, Stephan GÃ¼nnemann",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17853"" target=""_blank"">2311.17853</a>",,2024-12-11
Cognitive Overload: Jailbreaking Large Language Models with Overloaded Logical Thinking,"Nan Xu, Fei Wang, Ben Zhou, Bang Zheng Li, Chaowei Xiao, Muhao Chen",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09827"" target=""_blank"">2311.09827</a>",,2024-12-11
Adversarial Robust Memory-Based Continual Learner,"Xiaoyue Mi, Fan Tang, Zonghan Yang, Danding Wang, Juan Cao, Peng Li, Yang Liu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17608"" target=""_blank"">2311.17608</a>",,2024-12-11
Improving Faithfulness for Vision Transformers,"Lijie Hu, Yixin Liu, Ninghao Liu, Mengdi Huai, Lichao Sun, Di Wang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17983"" target=""_blank"">2311.17983</a>",,2024-12-11
TARGET: Template-Transferable Backdoor Attack Against Prompt-based NLP Models via GPT4,"Zihao Tan, Qingliang Chen, Yongjian Huang, Chen Liang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17429"" target=""_blank"">2311.17429</a>",,2024-12-11
Topology-Preserving Adversarial Training,"Xiaoyue Mi, Fan Tang, Yepeng Weng, Danding Wang, Juan Cao, Sheng Tang, Peng Li, Yang Liu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17607"" target=""_blank"">2311.17607</a>",,2024-12-11
Query-Relevant Images Jailbreak Large Multi-Modal Models,"Xin Liu, Yichen Zhu, Yunshi Lan, Chao Yang, Yu Qiao",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17600"" target=""_blank"">2311.17600</a>","<a href=""https://github.com/isXinLiu/MM-SafetyBench"" target=""_blank"">isXinLiu</a>",2024-12-11
Analyzing and Explaining Image Classifiers via Diffusion Guidance,"Maximilian Augustin, Yannic Neuhaus, Matthias Hein",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17833"" target=""_blank"">2311.17833</a>",,2024-12-11
Poisoning Attacks Against Contrastive Recommender Systems,"Zongwei Wang, Junliang Yu, Min Gao, Hongzhi Yin, Bin Cui, Shazia Sadiq",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.18244"" target=""_blank"">2311.18244</a>",,2024-12-11
SenTest: Evaluating Robustness of Sentence Encoders,"Tanmay Chavan, Shantanu Patankar, Aditya Kane, Omkar Gokhale, Geetanjali Kale, Raviraj Joshi",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17722"" target=""_blank"">2311.17722</a>",,2024-12-11
CLIPC8: Face liveness detection algorithm based on image-text pairs and contrastive learning,"Xu Liu, Shu Zhou, Yurong Song, Wenzhe Luo, Xin Zhang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17583"" target=""_blank"">2311.17583</a>",,2024-12-11
Unveiling the Implicit Toxicity in Large Language Models,"Jiaxin Wen, Pei Ke, Hao Sun, Zhexin Zhang, Chengfei Li, Jinfeng Bai, Minlie Huang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17391"" target=""_blank"">2311.17391</a>","<a href=""https://github.com/thu-coai/Implicit-Toxicity"" target=""_blank"">thu-coai</a>",2024-12-11
BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP,"Jiawang Bai, Kuofeng Gao, Shaobo Min, Shu-Tao Xia, Zhifeng Li, Wei Liu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16194"" target=""_blank"">2311.16194</a>",,2024-12-11
Critical Influence of Overparameterization on Sharpness-aware Minimization,"Sungbin Shin, Dongyeop Lee, Maksym Andriushchenko, Namhoon Lee",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17539"" target=""_blank"">2311.17539</a>",,2024-12-11
Mixing Classifiers to Alleviate the Accuracy-Robustness Trade-Off,"Yatong Bai, Brendon G. Anderson, Somayeh Sojoudi",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15165"" target=""_blank"">2311.15165</a>",,2024-12-11
ODDR: Outlier Detection & Dimension Reduction Based Defense Against Adversarial Patches,"Nandish Chattopadhyay, Amira Guesmi, Muhammad Abdullah Hanif, Bassem Ouni, Muhammad Shafique",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12084"" target=""_blank"">2311.12084</a>",,2024-12-11
Generating Valid and Natural Adversarial Examples with Large Language Models,"Zimu Wang, Wei Wang, Qi Chen, Qiufeng Wang, Anh Nguyen",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11861"" target=""_blank"">2311.11861</a>",,2024-12-11
AdvGen: Physical Adversarial Attack on Face Presentation Attack Detection Systems,"Sai Amrit Patnaik, Shivali Chansoriya, Anil K. Jain, Anoop M. Namboodiri",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11753"" target=""_blank"">2311.11753</a>",,2024-12-11
Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI Systems,"Guangjing Wang, Ce Zhou, Yuanda Wang, Bocheng Chen, Hanqing Guo, Qiben Yan",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11796"" target=""_blank"">2311.11796</a>",,2024-12-11
Understanding Variation in Subpopulation Susceptibility to Poisoning Attacks,"Evan Rose, Fnu Suya, David Evans",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11544"" target=""_blank"">2311.11544</a>","<a href=""https://uvasrg.github.io/visualizing-poisoning"" target=""_blank"">uvasrg.github.io</a>",2024-12-11
Training robust and generalizable quantum models,"Julian Berberich, Daniel Fink, Daniel PranjiÄ, Christian Tutschku, Christian Holm",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11871"" target=""_blank"">2311.11871</a>",,2024-12-11
BrainWash: A Poisoning Attack to Forget in Continual Learning,"Ali Abbasi, Parsa Nooralinejad, Hamed Pirsiavash, Soheil Kolouri",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11995"" target=""_blank"">2311.11995</a>",,2024-12-11
Adversarial Prompt Tuning for Vision-Language Models,"Jiaming Zhang, Xingjun Ma, Xin Wang, Lingyu Qiu, Jiaqi Wang, Yu-Gang Jiang, Jitao Sang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11261"" target=""_blank"">2311.11261</a>",,2024-12-11
Token-Level Adversarial Prompt Detection Based on Perplexity Measures and Contextual Information,"Zhengmian Hu, Gang Wu, Saayan Mitra, Ruiyi Zhang, Tong Sun, Heng Huang, Viswanathan Swaminathan",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11509"" target=""_blank"">2311.11509</a>",,2024-12-11
EditShield: Protecting Unauthorized Image Editing by Instruction-guided Diffusion Models,"Ruoxi Chen, Haibo Jin, Jinyin Chen, Lichao Sun",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12066"" target=""_blank"">2311.12066</a>",,2024-12-11
Hijacking Large Language Models via Adversarial In-Context Learning,"Yao Qiang, Xiangyu Zhou, Dongxiao Zhu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09948"" target=""_blank"">2311.09948</a>",,2024-12-11
Breaking Boundaries: Balancing Performance and Robustness in Deep Wireless Traffic Forecasting,"Romain Ilbert, Thai V. Hoang, Zonghua Zhang, Themis Palpanas",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09790"" target=""_blank"">2311.09790</a>",,2024-12-11
Boost Adversarial Transferability by Uniform Scale and Mix Mask Method,"Tao Wang, Zijian Ying, Qianmu Li, zhichao Lian",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12051"" target=""_blank"">2311.12051</a>",,2024-12-11
Two-Factor Authentication Approach Based on Behavior Patterns for Defeating Puppet Attacks,"Wenhao Wang, Guyue Li, Zhiming Chu, Haobo Li, Daniele Faccio",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.10389"" target=""_blank"">2311.10389</a>",,2024-12-11
Robust Graph Neural Networks via Unbiased Aggregation,"Ruiqi Feng, Zhichao Hou, Tyler Derr, Xiaorui Liu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.14934"" target=""_blank"">2311.14934</a>",,2024-12-11
PACOL: Poisoning Attacks Against Continual Learners,"Huayu Li, Gregory Ditzler",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.10919"" target=""_blank"">2311.10919</a>",,2024-12-11
Breaking Temporal Consistency: Generating Video Universal Adversarial Perturbations Using Image Models,"Hee-Seon Kim, Minji Son, Minbeom Kim, Myung-Joon Kwon, Changick Kim",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.10366"" target=""_blank"">2311.10366</a>",,2024-12-11
Improving Adversarial Transferability by Stable Diffusion,"Jiayang Liu, Siyu Zhu, Siyuan Liang, Jie Zhang, Han Fang, Weiming Zhang, Ee-Chien Chang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11017"" target=""_blank"">2311.11017</a>",,2024-12-11
Attention-Based Real-Time Defenses for Physical Adversarial Attacks in Vision Applications,"Giulio Rossolini, Alessandro Biondi, Giorgio Buttazzo",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11191"" target=""_blank"">2311.11191</a>",,2024-12-11
TextGuard: Provable Defense against Backdoor Attacks on Text Classification,"Hengzhi Pei, Jinyuan Jia, Wenbo Guo, Bo Li, Dawn Song",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11225"" target=""_blank"">2311.11225</a>","<a href=""https://github.com/AI-secure/TextGuard"" target=""_blank"">AI-secure</a>",2024-12-11
DefensiveDR: Defending against Adversarial Patches using Dimensionality Reduction,"Nandish Chattopadhyay, Amira Guesmi, Muhammad Abdullah Hanif, Bassem Ouni, Muhammad Shafique",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12211"" target=""_blank"">2311.12211</a>",,2024-12-11
BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning,"Siyuan Liang, Mingli Zhu, Aishan Liu, Baoyuan Wu, Xiaochun Cao, Ee-Chien Chang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12075"" target=""_blank"">2311.12075</a>",,2024-12-11
Iris Presentation Attack: Assessing the Impact of Combining Vanadium Dioxide Films with Artificial Eyes,"Darshika Jauhari, Renu Sharma, Cunjian Chen, Nelson Sepulveda, Arun Ross",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12773"" target=""_blank"">2311.12773</a>",,2024-12-11
Hard Label Black Box Node Injection Attack on Graph Neural Networks,"Yu Zhou, Zihao Dong, Guofeng Zhang, Jingchen Tang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13244"" target=""_blank"">2311.13244</a>",,2024-12-11
Effective Backdoor Mitigation Depends on the Pre-training Objective,"Sahil Verma, Gantavya Bhatt, Avi Schwarzschild, Soumye Singhal, Arnav Mohanty Das, Chirag Shah, John P Dickerson, Jeff Bilmes",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.14948"" target=""_blank"">2311.14948</a>",,2024-12-11
Trainwreck: A damaging adversarial attack on image classifiers,Jan ZahÃ¡lka,arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.14772"" target=""_blank"">2311.14772</a>","<a href=""https://github.com/JanZahalka/trainwreck"" target=""_blank"">JanZahalka</a>",2024-12-11
Segment (Almost) Nothing: Prompt-Agnostic Adversarial Attacks on Segmentation Models,"Francesco Croce, Matthias Hein",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.14450"" target=""_blank"">2311.14450</a>",,2024-12-11
Universal Jailbreak Backdoors from Poisoned Human Feedback,"Javier Rando, Florian TramÃ¨r",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.14455"" target=""_blank"">2311.14455</a>",,2024-12-11
When Side-Channel Attacks Break the Black-Box Property of Embedded Artificial Intelligence,"Benoit Coqueret, Mathieu Carbone, Olivier Sentieys, Gabriel Zaid",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.14005"" target=""_blank"">2311.14005</a>",,2024-12-11
Adversarial defense based on distribution transfer,"Jiahao Chen, Diqun Yan, Li Dong",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13841"" target=""_blank"">2311.13841</a>",,2024-12-11
Robust and Interpretable COVID-19 Diagnosis on Chest X-ray Images using Adversarial Training,"Karina Yang, Alexis Bennett, Dominique Duncan",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.14227"" target=""_blank"">2311.14227</a>",,2024-12-11
Toward Robust Imperceptible Perturbation against Unauthorized Text-to-image Diffusion-based Synthesis,"Yixin Liu, Chenrui Fan, Yutong Dai, Xun Chen, Pan Zhou, Lichao Sun",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13127"" target=""_blank"">2311.13127</a>","<a href=""https://github.com/liuyixin-louis/MetaCloak"" target=""_blank"">liuyixin-louis</a>",2024-12-11
"A Survey of Adversarial CAPTCHAs on its History, Classification and Generation","Zisheng Xu, Qiao Yan, F. Richard Yu, Victor C. M. Leung",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13233"" target=""_blank"">2311.13233</a>",,2024-12-11
Transfer Attacks and Defenses for Large Language Models on Coding Tasks,"Chi Zhang, Zifan Wang, Ravi Mangal, Matt Fredrikson, Limin Jia, Corina Pasareanu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13445"" target=""_blank"">2311.13445</a>",,2024-12-11
Panda or not Panda? Understanding Adversarial Attacks with Interactive Visualization,"Yuzhe You, Jarvis Tse, Jian Zhao",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13656"" target=""_blank"">2311.13656</a>",,2024-12-11
"Robust Network Slicing: Multi-Agent Policies, Adversarial Attacks, and Defensive Strategies","Feng Wang, M. Cenk Gursoy, Senem Velipasalar",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11206"" target=""_blank"">2311.11206</a>",,2024-12-11
Attacking Motion Planners Using Adversarial Perception Errors,"Jonathan Sadeghi, Nicholas A. Lord, John Redford, Romain Mueller",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12722"" target=""_blank"">2311.12722</a>",,2024-12-11
SD-NAE: Generating Natural Adversarial Examples with Stable Diffusion,"Yueqian Lin, Jingyang Zhang, Yiran Chen, Hai Li",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12981"" target=""_blank"">2311.12981</a>","<a href=""https://github.com/linyueqian/SD-NAE"" target=""_blank"">linyueqian</a>",2024-12-11
Unified Classification and Rejection: A One-versus-All Framework,"Zhen Cheng, Xu-Yao Zhang, Cheng-Lin Liu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13355"" target=""_blank"">2311.13355</a>",,2024-12-11
Security and Privacy Challenges in Deep Learning Models,Gopichandh Golla,arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13744"" target=""_blank"">2311.13744</a>",,2024-12-11
OASIS: Offsetting Active Reconstruction Attacks in Federated Learning,"Tre' R. Jeter, Truc Nguyen, Raed Alharbi, My T. Thai",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13739"" target=""_blank"">2311.13739</a>",,2024-12-11
Attention Deficit is Ordered! Fooling Deformable Vision Transformers with Collaborative Adversarial Patches,"Quazi Mishkatul Alam, Bilel Tarchoun, Ihsen Alouani, Nael Abu-Ghazaleh",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12914"" target=""_blank"">2311.12914</a>",,2024-12-11
Stable Unlearnable Example: Enhancing the Robustness of Unlearnable Examples via Stable Error-Minimizing Noise,"Yixin Liu, Kaidi Xu, Xun Chen, Lichao Sun",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13091"" target=""_blank"">2311.13091</a>","<a href=""https://github.com/liuyixin-louis/Stable-Unlearnable-Example"" target=""_blank"">liuyixin-louis</a>",2024-12-11
A Somewhat Robust Image Watermark against Diffusion-based Editing Models,"Mingtian Tan, Tianhao Wang, Somesh Jha",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13713"" target=""_blank"">2311.13713</a>","<a href=""https://github.com/BennyTMT/RIW"" target=""_blank"">BennyTMT</a>",2024-12-11
IPMix: Label-Preserving Data Augmentation Method for Training Robust Classifiers,"Zhenglin Huang, Xiaoan Bao, Na Zhang, Qingqi Zhang, Xiaomei Tu, Biao Wu, Xi Yang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04780"" target=""_blank"">2310.04780</a>",,2024-12-11
GraphCloak: Safeguarding Task-specific Knowledge within Graph-structured Data from Unauthorized Exploitation,"Yixin Liu, Chenrui Fan, Xun Chen, Pan Zhou, Lichao Sun",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07100"" target=""_blank"">2310.07100</a>",,2024-12-11
Latent Diffusion Counterfactual Explanations,"Karim Farid, Simon Schrodi, Max Argus, Thomas Brox",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06668"" target=""_blank"">2310.06668</a>",,2024-12-11
No Privacy Left Outside: On the (In-)Security of TEE-Shielded DNN Partition for On-Device ML,"Ziqi Zhang, Chen Gong, Yifeng Cai, Yuanyuan Yuan, Bingyan Liu, Ding Li, Yao Guo, Xiangqun Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07152"" target=""_blank"">2310.07152</a>",,2024-12-11
Comparing the Robustness of Modern No-Reference Image- and Video-Quality Metrics to Adversarial Attacks,"Anastasia Antsiferova, Khaled Abud, Aleksandr Gushchin, Ekaterina Shumitskaya, Sergey Lavrushkin, Dmitriy Vatolin",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06958"" target=""_blank"">2310.06958</a>",,2024-12-11
Investigating the Adversarial Robustness of Density Estimation Using the Probability Flow ODE,"Marius Arvinte, Cory Cornelius, Jason Martin, Nageen Himayat",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07084"" target=""_blank"">2310.07084</a>",,2024-12-11
"Adversarial optimization leads to over-optimistic security-constrained dispatch, but sampling can help","Charles Dawson, Chuchu Fan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06956"" target=""_blank"">2310.06956</a>",,2024-12-11
Adversarial Robustness in Graph Neural Networks: A Hamiltonian Approach,"Kai Zhao, Qiyu Kang, Yang Song, Rui She, Sijie Wang, Wee Peng Tay",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06396"" target=""_blank"">2310.06396</a>","<a href=""https://github.com/zknus/NeurIPS-2023-HANG-Robustness"" target=""_blank"">zknus</a>",2024-12-11
My Brother Helps Me: Node Injection Based Adversarial Attack on Social Bot Detection,"Lanjun Wang, Xinran Qiao, Yanwei Xie, Weizhi Nie, Yongdong Zhang, Anan Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07159"" target=""_blank"">2310.07159</a>",,2024-12-11
A Geometrical Approach to Evaluate the Adversarial Robustness of Deep Neural Networks,"Yang Wang, Bo Dong, Ke Xu, Haiyin Piao, Yufei Ding, Baocai Yin, Xin Yang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06468"" target=""_blank"">2310.06468</a>",,2024-12-11
FTFT: efficient and robust Fine-Tuning by transFerring Training dynamics,"Yupei Du, Albert Gatt, Dong Nguyen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06588"" target=""_blank"">2310.06588</a>",,2024-12-11
PAC-Bayesian Spectrally-Normalized Bounds for Adversarially Robust Generalization,"Jiancong Xiao, Ruoyu Sun, Zhi- Quan Luo",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06182"" target=""_blank"">2310.06182</a>",,2024-12-11
Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations,"Zeming Wei, Yifei Wang, Yisen Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06387"" target=""_blank"">2310.06387</a>",,2024-12-11
Generating Less Certain Adversarial Examples Improves Robust Generalization,"Minxing Zhang, Michael Backes, Xiao Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04539"" target=""_blank"">2310.04539</a>",,2024-12-11
Deep Reinforcement Learning for Autonomous Cyber Defence: A Survey,"Gregory Palmer, Chris Parry, Daniel J. B. Harrold, Chris Willis",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07745"" target=""_blank"">2310.07745</a>",,2024-12-11
Domain Watermark: Effective and Harmless Dataset Copyright Protection is Closed at Hand,"Junfeng Guo, Yiming Li, Lixu Wang, Shu-Tao Xia, Heng Huang, Cong Liu, Bo Li",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14942"" target=""_blank"">2310.14942</a>","<a href=""https://github.com/JunfengGo/Domain-Watermark"" target=""_blank"">JunfengGo</a>",2024-12-11
Theoretical Analysis of Robust Overfitting for Wide DNNs: An NTK Approach,"Shaopeng Fu, Di Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06112"" target=""_blank"">2310.06112</a>","<a href=""https://github.com/fshp971/adv-ntk"" target=""_blank"">fshp971</a>",2024-12-11
Exploring adversarial attacks in federated learning for medical imaging,"Erfan Darzi, Florian Dubost, N. M. Sijtsema, Ooijen P. M. A van",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06227"" target=""_blank"">2310.06227</a>",,2024-12-11
An Initial Investigation of Neural Replay Simulator for Over-the-Air Adversarial Perturbations to Automatic Speaker Verification,"Jiaqi Li, Li Wang, Liumeng Xue, Lei Wang, Zhizheng Wu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05354"" target=""_blank"">2310.05354</a>",,2024-12-11
AdvSV: An Over-the-Air Adversarial Attack Dataset for Speaker Verification,"Li Wang, Jiaqi Li, Yuhao Luo, Jiahao Zheng, Lei Wang, Hao Li, Ke Xu, Chengfang Fang, Jie Shi, Zhizheng Wu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05369"" target=""_blank"">2310.05369</a>",,2024-12-11
Transferable Availability Poisoning Attacks,"Yiyong Liu, Michael Backes, Xiao Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05141"" target=""_blank"">2310.05141</a>",,2024-12-11
VLATTACK: Multimodal Adversarial Attacks on Vision-Language Tasks via Pre-trained Models,"Ziyi Yin, Muchao Ye, Tianrong Zhang, Tianyu Du, Jinguo Zhu, Han Liu, Jinghui Chen, Ting Wang, Fenglong Ma",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04655"" target=""_blank"">2310.04655</a>","<a href=""https://github.com/ericyinyzy/VLAttack"" target=""_blank"">ericyinyzy</a>",2024-12-11
BRAINTEASER: Lateral Thinking Puzzles for Large Language Models,"Yifan Jiang, Filip Ilievski, Kaixin Ma, Zhivar Sourati",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05057"" target=""_blank"">2310.05057</a>",,2024-12-11
Adversarial Attacks on Combinatorial Multi-Armed Bandits,"Rishab Balasubramanian, Jiawei Li, Prasad Tadepalli, Huazheng Wang, Qingyun Wu, Haoyu Zhao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05308"" target=""_blank"">2310.05308</a>",,2024-12-11
Improving Adversarial Attacks on Latent Diffusion Model,"Boyang Zheng, Chumeng Liang, Xiaoyu Wu, Yan Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04687"" target=""_blank"">2310.04687</a>",,2024-12-11
GReAT: A Graph Regularized Adversarial Training Method,"Samet Bayram, Kenneth Barner",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05336"" target=""_blank"">2310.05336</a>",,2024-12-11
Fed-Safe: Securing Federated Learning in Healthcare Against Adversarial Attacks,"Erfan Darzi, Nanna M. Sijtsema, Ooijen P. M. A van",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08681"" target=""_blank"">2310.08681</a>",,2024-12-11
Towards Causal Deep Learning for Vulnerability Detection,"Md Mahbubur Rahman, Ira Ceka, Chengzhi Mao, Saikat Chakraborty, Baishakhi Ray, Wei Le",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07958"" target=""_blank"">2310.07958</a>",,2024-12-11
Why Train More? Effective and Efficient Membership Inference via Memorization,"Jihye Choi, Shruti Tople, Varun Chandrasekaran, Somesh Jha",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08015"" target=""_blank"">2310.08015</a>",,2024-12-11
OMG-ATTACK: Self-Supervised On-Manifold Generation of Transferable Evasion Attacks,"Ofir Bar Tal, Adi Haviv, Amit H. Bermano",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03707"" target=""_blank"">2310.03707</a>",,2024-12-11
AFLOW: Developing Adversarial Examples under Extremely Noise-limited Settings,"Renyang Liu, Jinhong Zhang, Haoran Li, Jin Zhang, Yuanyu Wang, Wei Zhou",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09795"" target=""_blank"">2310.09795</a>",,2024-12-11
Black-box Targeted Adversarial Attack on Segment Anything (SAM),"Sheng Zheng, Chaoning Zhang, Xinhong Hao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10010"" target=""_blank"">2310.10010</a>",,2024-12-11
Evading Detection Actively: Toward Anti-Forensics against Forgery Localization,"Long Zhuo, Shenghai Luo, Shunquan Tan, Han Chen, Bin Li, Jiwu Huang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10036"" target=""_blank"">2310.10036</a>",,2024-12-11
Explore the Effect of Data Selection on Poison Efficiency in Backdoor Attacks,"Ziqiang Li, Pengfei Xia, Hong Sun, Yueqi Zeng, Wei Zhang, Bin Li",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09744"" target=""_blank"">2310.09744</a>",,2024-12-11
Ring-A-Bell! How Reliable are Concept Removal Methods for Diffusion Models? (9%),"Yu-Lin Tsai, Chia-Yi Hsu, Chulin Xie, Chih-Hsun Lin, Jia-You Chen, Bo Li, Pin-Yu Chen, Chia-Mu Yu, Chun-Ying Huang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10012"" target=""_blank"">2310.10012</a>","<a href=""https://github.com/chiayi-hsu/Ring-A-Bell"" target=""_blank"">chiayi-hsu</a>",2024-12-11
VFLAIR: A Research Library and Benchmark for Vertical Federated Learning,"Tianyuan Zou, Zixuan Gu, Yu He, Hideaki Takahashi, Yang Liu, Ya-Qin Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09827"" target=""_blank"">2310.09827</a>","<a href=""https://github.com/FLAIR-THU/VFLAIR"" target=""_blank"">FLAIR-THU</a>",2024-12-11
BufferSearch: Generating Black-Box Adversarial Texts With Lower Queries,"Wenjie Lv, Zhen Wang, Yitao Zheng, Zhehua Zhong, Qi Xuan, Tianyi Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09652"" target=""_blank"">2310.09652</a>",,2024-12-11
Is Certifying $\ell_p$ Robustness Still Worthwhile? (99%),"Ravi Mangal, Klas Leino, Zifan Wang, Kai Hu, Weicheng Yu, Corina Pasareanu, Anupam Datta, Matt Fredrikson",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09361"" target=""_blank"">2310.09361</a>",,2024-12-11
User Inference Attacks on Large Language Models,"Nikhil Kandpal, Krishna Pillutla, Alina Oprea, Peter Kairouz, Christopher A. Choquette-Choo, Zheng Xu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09266"" target=""_blank"">2310.09266</a>",,2024-12-11
"On the Over-Memorization During Natural, Robust and Catastrophic Overfitting","Runqi Lin, Chaojian Yu, Bo Han, Tongliang Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08847"" target=""_blank"">2310.08847</a>",,2024-12-11
Samples on Thin Ice: Re-Evaluating Adversarial Pruning of Neural Networks,"Giorgio Piras, Maura Pintor, Ambra Demontis, Battista Biggio",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08073"" target=""_blank"">2310.08073</a>",,2024-12-11
Concealed Electronic Countermeasures of Radar Signal with Adversarial Examples,"Ruinan Ma, Canjie Zhu, Mingfeng Lu, Yunjie Li, Yu-an Tan, Ruibin Zhang, Ran Tao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08292"" target=""_blank"">2310.08292</a>",,2024-12-11
Attacks Meet Interpretability (AmI) Evaluation and Findings,"Qian Ma, Ziping Ye, Shagufta Mehnaz",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08808"" target=""_blank"">2310.08808</a>",,2024-12-11
Provably Robust Cost-Sensitive Learning via Randomized Smoothing,"Yuan Xin, Michael Backes, Xiao Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08732"" target=""_blank"">2310.08732</a>","<a href=""https://github.com/TrustMLRG/CS-RS"" target=""_blank"">TrustMLRG</a>",2024-12-11
Improving Fast Minimum-Norm Attacks with Hyperparameter Optimization,"Giuseppe Floris, Raffaele Mura, Luca Scionis, Giorgio Piras, Maura Pintor, Ambra Demontis, Battista Biggio",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08177"" target=""_blank"">2310.08177</a>","<a href=""https://github.com/pralab/HO-FMN"" target=""_blank"">pralab</a>",2024-12-11
Bucks for Buckets (B4B): Active Defenses Against Stealing Encoders,"Jan DubiÅski, StanisÅaw Pawlak, Franziska Boenisch, Tomasz TrzciÅski, Adam Dziedzic",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08571"" target=""_blank"">2310.08571</a>",,2024-12-11
Sentinel: An Aggregation Function to Secure Decentralized Federated Learning,"Chao Feng, Alberto Huertas Celdran, Janosch Baltensperger, Enrique Tomas MatÄ±nez Bertran, Gerome Bovet, Burkhard Stiller",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08097"" target=""_blank"">2310.08097</a>",,2024-12-11
Defending Our Privacy With Backdoors,"Dominik Hintersdorf, Lukas Struppek, Daniel Neider, Kristian Kersting",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08320"" target=""_blank"">2310.08320</a>",,2024-12-11
Investigating the Robustness and Properties of Detection Transformers (DETR) Toward Difficult Images,"Zhao Ning Zou, Yuhang Zhang, Robert Wijaya",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08772"" target=""_blank"">2310.08772</a>",,2024-12-11
Polynomial Time Cryptanalytic Extraction of Neural Network Models,"Adi Shamir, Isaac Canales-Martinez, Anna Hambitzer, Jorge Chavez-Saab, Francisco Rodrigez-Henriquez, Nitin Satpute",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08708"" target=""_blank"">2310.08708</a>",,2024-12-11
SEE-OoD: Supervised Exploration For Enhanced Out-of-Distribution Detection,"Xiaoyang Song, Wenbo Sun, Maher Nouiehed, Raed Al Kontar, Judy Jin",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08040"" target=""_blank"">2310.08040</a>",,2024-12-11
XAI Benchmark for Visual Explanation,"Yifei Zhang, Siyi Gu, James Song, Bo Pan, Liang Zhao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08537"" target=""_blank"">2310.08537</a>","<a href=""https://xaidataset.github.io"" target=""_blank""></a>",2024-12-11
Jailbreaking Black Box Large Language Models in Twenty Queries,"Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani, George J. Pappas, Eric Wong",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08419"" target=""_blank"">2310.08419</a>",,2024-12-11
Voyager: MTD-Based Aggregation Protocol for Mitigating Poisoning Attacks on DFL,"Chao Feng, Alberto Huertas Celdran, Michael Vuong, Gerome Bovet, Burkhard Stiller",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08739"" target=""_blank"">2310.08739</a>",,2024-12-11
Boosting Black-box Attack to Deep Neural Networks with Conditional Diffusion Models,"Renyang Liu, Wei Zhou, Tianwei Zhang, Kangjie Chen, Jun Zhao, Kwok-Yan Lam",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07492"" target=""_blank"">2310.07492</a>",,2024-12-11
Promoting Robustness of Randomized Smoothing: Two Cost-Effective Approaches,"Linbo Liu, Trong Nghia Hoang, Lam M. Nguyen, Tsui-Wei Weng",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07780"" target=""_blank"">2310.07780</a>",,2024-12-11
An Adversarial Example for Direct Logit Attribution: Memory Management in gelu-4l,"James Dao, Yeu-Tong Lao, Can Rager, Jett Janiak",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07325"" target=""_blank"">2310.07325</a>",,2024-12-11
Prompt Backdoors in Visual Prompt Learning,"Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07632"" target=""_blank"">2310.07632</a>",,2024-12-11
Kick Bad Guys Out! Conditionally Activated Anomaly Detection in Federated Learning with Zero-Knowledge Proof Verification,"Shanshan Han, Wenxuan Wu, Baturalp Buyukates, Weizhao Jin, Qifan Zhang, Yuhang Yao, Salman Avestimehr, Chaoyang He",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04055"" target=""_blank"">2310.04055</a>",,2024-12-11
Can Pre-trained Networks Detect Familiar Out-of-Distribution Data? (1%),"Atsuyuki Miyai, Qing Yu, Go Irie, Kiyoharu Aizawa",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00847"" target=""_blank"">2310.00847</a>","<a href=""https://github.com/AtsuMiyai/PT-OOD"" target=""_blank"">AtsuMiyai</a>",2024-12-11
Untargeted White-box Adversarial Attack with Heuristic Defence Methods in Real-time Deep Learning based Network Intrusion Detection System,"Khushnaseeb Roshan, Aasim Zafar, Sheikh Burhan Ul Haque",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03334"" target=""_blank"">2310.03334</a>",,2024-12-11
Adversarial Explainability: Utilizing Explainable Machine Learning in Bypassing IoT Botnet Detection Systems,"Mohammed M. Alani, Atefeh Mashatan, Ali Miri",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00070"" target=""_blank"">2310.00070</a>",,2024-12-11
Counterfactual Image Generation for adversarially robust and interpretable Classifiers,"Rafael Bischof, Florian Scheidegger, Michael A. Kraus, A. Cristiano I. Malossi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00761"" target=""_blank"">2310.00761</a>",,2024-12-11
On the Onset of Robust Overfitting in Adversarial Training,"Chaojian Yu, Xiaolong Shi, Jun Yu, Bo Han, Tongliang Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00607"" target=""_blank"">2310.00607</a>",,2024-12-11
Understanding Adversarial Transferability in Federated Learning,"Yijiang Li, Ying Gao, Haohan Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00616"" target=""_blank"">2310.00616</a>",,2024-12-11
GhostEncoder: Stealthy Backdoor Attacks with Dynamic Triggers to Pre-trained Encoders in Self-supervised Learning,"Qiannan Wang, Changchun Yin, Zhe Liu, Liming Fang, Run Wang, Chenhao Lin",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00626"" target=""_blank"">2310.00626</a>",,2024-12-11
Fewer is More: Trojan Attacks on Parameter-Efficient Fine-Tuning,"Lauren Hong, Ting Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00648"" target=""_blank"">2310.00648</a>",,2024-12-11
How well does LLM generate security tests? (1%),"Ying Daphne Zhang, Wenjia Daphne Song, Zhengjie Daphne Ji, Daphne Danfeng, Yao, Na Meng",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00710"" target=""_blank"">2310.00710</a>",,2024-12-11
Understanding the Robustness of Randomized Feature Defense Against Query-Based Adversarial Attacks,"Quang H. Nguyen, Yingjie Lao, Tung Pham, Kok-Seng Wong, Khoa D. Doan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00567"" target=""_blank"">2310.00567</a>",,2024-12-11
Human-Producible Adversarial Examples,"David Khachaturov, Yue Gao, Ilia Shumailov, Robert Mullins, Ross Anderson, Kassem Fawaz",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00438"" target=""_blank"">2310.00438</a>",,2024-12-11
Black-box Attacks on Image Activity Prediction and its Natural Language Explanations,"Alina Elena Baia, Valentina Poggioni, Andrea Cavallaro",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00503"" target=""_blank"">2310.00503</a>",,2024-12-11
Horizontal Class Backdoor to Deep Learning,"Hua Ma, Shang Wang, Yansong Gao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00542"" target=""_blank"">2310.00542</a>",,2024-12-11
Refutation of Shapley Values for XAI -- Additional Evidence,"Xuanxiang Huang, Joao Marques-Silva",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00416"" target=""_blank"">2310.00416</a>",,2024-12-11
Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks,"Mehrdad Saberi, Vinu Sankar Sadasivan, Keivan Rezaei, Aounon Kumar, Atoosa Chegini, Wenxiao Wang, Soheil Feizi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00076"" target=""_blank"">2310.00076</a>",,2024-12-11
Certified Robustness via Dynamic Margin Maximization and Improved Lipschitz Regularization,"Mahyar Fazlyab, Taha Entesari, Aniket Roy, Rama Chellappa",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00116"" target=""_blank"">2310.00116</a>",,2024-12-11
Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models: A Pilot Study,"Myeongseob Ko, Ming Jin, Chenguang Wang, Ruoxi Jia",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00108"" target=""_blank"">2310.00108</a>","<a href=""https://github.com/ruoxi-jia-group/CLIP-MIA"" target=""_blank"">ruoxi-jia-group</a>",2024-12-11
Enhancing Robust Representation in Adversarial Training: Alignment and Exclusion Criteria,"Nuoyan Zhou, Nannan Wang, Decheng Liu, Dawei Zhou, Xinbo Gao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03358"" target=""_blank"">2310.03358</a>",,2024-12-11
Source Inference Attacks: Beyond Membership Inference Attacks in Federated Learning,"Hongsheng Hu, Xuyun Zhang, Zoran Salcic, Lichao Sun, Kim-Kwang Raymond Choo, Gillian Dobbie",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00222"" target=""_blank"">2310.00222</a>",,2024-12-11
Warfare:Breaking the Watermark Protection of AI-Generated Content,"Guanlin Li, Yifei Chen, Jie Zhang, Jiwei Li, Shangwei Guo, Tianwei Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07726"" target=""_blank"">2310.07726</a>",,2024-12-11
Genetic Algorithm-Based Dynamic Backdoor Attack on Federated Learning-Based Network Traffic Classification,"Mahmoud Nazzal, Nura Aljaafari, Ahmed Sawalmeh, Abdallah Khreishah, Muhammad Anan, Abdulelah Algosaibi, Mohammed Alnaeem, Adel Aldalbahi, Abdulaziz Alhumam, Conrado P. Vizcarra, Shadan Alhamed",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06855"" target=""_blank"">2310.06855</a>",,2024-12-11
Benchmarking Local Robustness of High-Accuracy Binary Neural Networks for Enhanced Traffic Sign Recognition,"Andreea Postovan, MÄdÄlina EraÅcu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03033"" target=""_blank"">2310.03033</a>","<a href=""https://github.com/ChristopherBrix/vnncomp2023_benchmarks/tree/main/benchmarks/traffic_signs_recognition"" target=""_blank"">benchmarks</a>",2024-12-11
Nebula: Self-Attention for Dynamic Malware Analysis,"Dmitrijs Trizna, Luca Demetrio, Battista Biggio, Fabio Roli",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10664"" target=""_blank"">2310.10664</a>",,2024-12-11
Extreme Image Transformations Facilitate Robust Latent Object Representations,"Girik Malik, Dakarai Crowder, Ennio Mingolla",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07725"" target=""_blank"">2310.07725</a>",,2024-12-11
Exploiting Machine Unlearning for Backdoor Attacks in Deep Learning System,"Peixin Zhang, Jun Sun, Mingtian Tan, Xinyu Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10659"" target=""_blank"">2310.10659</a>",,2024-12-11
VeriDIP: Verifying Ownership of Deep Neural Networks through Privacy Leakage Fingerprints,"Aoting Hu, Zhigang Lu, Renjie Xie, Minhui Xue",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10656"" target=""_blank"">2310.10656</a>",,2024-12-11
RobustEdge: Low Power Adversarial Detection for Cloud-Edge Systems,"Abhishek Moitra, Abhiroop Bhattacharjee, Youngeun Kim, Priyadarshini Panda",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06845"" target=""_blank"">2310.06845</a>",,2024-12-11
Robust and Efficient Interference Neural Networks for Defending Against Adversarial Attacks in ImageNet,"Yunuo Xiong, Shujuan Liu, Hongwei Xiong",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05947"" target=""_blank"">2310.05947</a>",,2024-12-11
Graph Unlearning: A Review,"Anwar Said, Tyler Derr, Mudassir Shabbir, Waseem Abbas, Xenofon Koutsoukos",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02164"" target=""_blank"">2310.02164</a>",,2024-12-11
State Machine Frameworks for Website Fingerprinting Defenses: Maybe Not,Ethan Witwer,arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10789"" target=""_blank"">2310.10789</a>",,2024-12-11
Towards Deep Learning Models Resistant to Transfer-based Adversarial Attacks via Data-centric Robust Learning,"Yulong Yang, Chenhao Lin, Xiang Ji, Qiwei Tian, Qian Li, Hongshan Yang, Zhibo Wang, Chao Shen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09891"" target=""_blank"">2310.09891</a>",,2024-12-11
A Survey of Robustness and Safety of 2D and 3D Deep Learning Models Against Adversarial Attacks,"Yanjie Li, Bin Xie, Songtao Guo, Yuanyuan Yang, Bin Xiao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00633"" target=""_blank"">2310.00633</a>",,2024-12-11
Fool Your (Vision and) Language Model With Embarrassingly Simple Permutations,"Yongshuo Zong, Tingyang Yu, Bingchen Zhao, Ruchika Chavhan, Timothy Hospedales",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01651"" target=""_blank"">2310.01651</a>","<a href=""https://github.com/ys-zong/FoolyourVLLMs"" target=""_blank"">ys-zong</a>",2024-12-11
Gotcha! This Model Uses My Code! Evaluating Membership Leakage Risks in Code Models,"Zhou Yang, Zhipeng Zhao, Chenyu Wang, Jieke Shi, Dongsum Kim, Donggyun Han, David Lo",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01166"" target=""_blank"">2310.01166</a>",,2024-12-11
LoFT: Local Proxy Fine-tuning For Improving Transferability Of Adversarial Attacks Against Large Language Model,"Muhammad Ahmed Shah, Roshan Sharma, Hira Dhamyal, Raphael Olivier, Ankit Shah, Joseph Konan, Dareen Alharthi, Hazim T Bukhari, Massa Baali, Soham Deshmukh, Michael Kuhlmann, Bhiksha Raj, Rita Singh",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04445"" target=""_blank"">2310.04445</a>",,2024-12-11
An Integrated Algorithm for Robust and Imperceptible Audio Adversarial Examples,"Armin Ettenhofer, Jan-Philipp Schulze, Karla Pizzi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03349"" target=""_blank"">2310.03349</a>",,2024-12-11
Adversarial Machine Learning for Social Good: Reframing the Adversary as an Ally,"Shawqi Al-Maliki, Adnan Qayyum, Hassan Ali, Mohamed Abdallah, Junaid Qadir, Dinh Thai Hoang, Dusit Niyato, Ala Al-Fuqaha",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03614"" target=""_blank"">2310.03614</a>",,2024-12-11
SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks,"Alexander Robey, Eric Wong, Hamed Hassani, George J. Pappas",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03684"" target=""_blank"">2310.03684</a>","<a href=""https://github.com/arobey1/smooth-llm"" target=""_blank"">arobey1</a>",2024-12-11
Better Safe than Sorry: Pre-training CLIP against Targeted Data Poisoning and Backdoor Attacks,"Wenhan Yang, Jingdong Gao, Baharan Mirzasoleiman",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05862"" target=""_blank"">2310.05862</a>",,2024-12-11
Targeted Adversarial Attacks on Generalizable Neural Radiance Fields,"Andras Horvath, Csaba M. Jozsa",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03578"" target=""_blank"">2310.03578</a>",,2024-12-11
Certification of Deep Learning Models for Medical Image Segmentation,"Othmane Laousy, Alexandre Araujo, Guillaume Chassagnon, Nikos Paragios, Marie-Pierre Revel, Maria Vakalopoulou",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03664"" target=""_blank"">2310.03664</a>",,2024-12-11
Certifiably Robust Graph Contrastive Learning,"Minhua Lin, Teng Xiao, Enyan Dai, Xiang Zhang, Suhang Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03312"" target=""_blank"">2310.03312</a>","<a href=""https://github.com/ventr1c/RES-GCL"" target=""_blank"">ventr1c</a>",2024-12-11
Towards Robust and Generalizable Training: An Empirical Study of Noisy Slot Filling for Input Perturbations,"Jiachi Liu, Liwen Wang, Guanting Dong, Xiaoshuai Song, Zechen Wang, Zhengyang Wang, Shanglin Lei, Jinzheng Zhao, Keqing He, Bo Xiao, Weiran Xu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03518"" target=""_blank"">2310.03518</a>","<a href=""https://github.com/dongguanting/Noise-SF"" target=""_blank"">dongguanting</a>",2024-12-11
Optimizing Key-Selection for Face-based One-Time Biometrics via Morphing,"Daile Osorio-Roig, Mahdi Ghafourian, Christian Rathgeb, Ruben Vera-Rodriguez, Christoph Busch, Julian Fierrez",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02997"" target=""_blank"">2310.02997</a>",,2024-12-11
Misusing Tools in Large Language Models With Visual Adversarial Examples,"Xiaohan Fu, Zihan Wang, Shuheng Li, Rajesh K. Gupta, Niloofar Mireshghallah, Taylor Berg-Kirkpatrick, Earlence Fernandes",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03185"" target=""_blank"">2310.03185</a>",,2024-12-11
Burning the Adversarial Bridges: Robust Windows Malware Detection Against Binary-level Mutations,"Ahmed Abusnaina, Yizhen Wang, Sunpreet Arora, Ke Wang, Mihai Christodorescu, David Mohaisen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03285"" target=""_blank"">2310.03285</a>",,2024-12-11
Raze to the Ground: Query-Efficient Adversarial HTML Attacks on Machine-Learning Phishing Webpage Detectors,"Biagio Montaruli, Luca Demetrio, Maura Pintor, Luca Compagna, Davide Balzarotti, Battista Biggio",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03166"" target=""_blank"">2310.03166</a>",,2024-12-11
Shielding the Unseen: Privacy Protection through Poisoning NeRF with Spatial Deformation,"Yihan Wu, Brandon Y. Feng, Heng Huang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03125"" target=""_blank"">2310.03125</a>",,2024-12-11
Splitting the Difference on Adversarial Training,"Matan Levi, Aryeh Kontorovich",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02480"" target=""_blank"">2310.02480</a>",,2024-12-11
DeepZero: Scaling up Zeroth-Order Optimization for Deep Model Training,"Aochuan Chen, Yimeng Zhang, Jinghan Jia, James Diffenderfer, Jiancheng Liu, Konstantinos Parasyris, Yihua Zhang, Zheng Zhang, Bhavya Kailkhura, Sijia Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02025"" target=""_blank"">2310.02025</a>",,2024-12-11
SlowFormer: Universal Adversarial Patch for Attack on Compute and Energy Efficiency of Inference Efficient Vision Transformers,"KL Navaneet, Soroush Abbasi Koohpayegani, Essam Sleiman, Hamed Pirsiavash",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02544"" target=""_blank"">2310.02544</a>",,2024-12-11
Towards Stable Backdoor Purification through Feature Shift Tuning,"Rui Min, Zeyu Qin, Li Shen, Minhao Cheng",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01875"" target=""_blank"">2310.01875</a>","<a href=""https://github.com/AISafety-HKUST/stable_backdoor_purification"" target=""_blank"">AISafety-HKUST</a>",2024-12-11
Jailbreaker in Jail: Moving Target Defense for Large Language Models,"Bocheng Chen, Advait Paliwal, Qiben Yan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02417"" target=""_blank"">2310.02417</a>",,2024-12-11
AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models,"Xiaogeng Liu, Nan Xu, Muhao Chen, Chaowei Xiao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04451"" target=""_blank"">2310.04451</a>",,2024-12-11
Beyond Labeling Oracles: What does it mean to steal ML models? (47%),"Avital Shafran, Ilia Shumailov, Murat A. Erdogdu, Nicolas Papernot",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01959"" target=""_blank"">2310.01959</a>",,2024-12-11
A Recipe for Improved Certifiable Robustness,"Kai Hu, Klas Leino, Zifan Wang, Matt Fredrikson",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02513"" target=""_blank"">2310.02513</a>","<a href=""https://github.com/hukkai/liresnet"" target=""_blank"">hukkai</a>",2024-12-11
Exploring Model Learning Heterogeneity for Boosting Ensemble Robustness,"Yanzhao Wu, Ka-Ho Chow, Wenqi Wei, Ling Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02237"" target=""_blank"">2310.02237</a>",,2024-12-11
FLEDGE: Ledger-based Federated Learning Resilient to Inference and Backdoor Attacks,"Jorge Castillo, Phillip Rieger, Hossein Fereidooni, Qian Chen, Ahmad Sadeghi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02113"" target=""_blank"">2310.02113</a>",,2024-12-11
AutoLoRa: A Parameter-Free Automated Robust Fine-Tuning Framework,"Xilie Xu, Jingfeng Zhang, Mohan Kankanhalli",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01818"" target=""_blank"">2310.01818</a>",,2024-12-11
Fooling the Textual Fooler via Randomizing Latent Representations,"Duy C. Hoang, Quang H. Nguyen, Saurav Manchanda, MinLong Peng, Kok-Seng Wong, Khoa D. Doan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01452"" target=""_blank"">2310.01452</a>",,2024-12-11
"LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples","Jia-Yu Yao, Kun-Peng Ning, Zhen-Hui Liu, Mu-Nan Ning, Li Yuan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01469"" target=""_blank"">2310.01469</a>",,2024-12-11
Adversarial Client Detection via Non-parametric Subspace Monitoring in the Internet of Federated Things,"Xianjian Xie, Xiaochen Xian, Dan Li, Andi Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01537"" target=""_blank"">2310.01537</a>",,2024-12-11
SCME: A Self-Contrastive Method for Data-free and Query-Limited Model Extraction Attack,"Renyang Liu, Jinhong Zhang, Kwok-Yan Lam, Jun Zhao, Wei Zhou",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09792"" target=""_blank"">2310.09792</a>",,2024-12-11
"Trust, but Verify: Robust Image Segmentation using Deep Learning","Fahim Ahmed Zaman, Xiaodong Wu, Weiyu Xu, Milan Sonka, Raghuraman Mudumbai",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16999"" target=""_blank"">2310.16999</a>",,2024-12-11
Will the Prince Get True Love's Kiss? On the Model Sensitivity to Gender Perturbation over Fairytale Texts,"Christina Chance, Da Yin, Dakuo Wang, Kai-Wei Chang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10865"" target=""_blank"">2310.10865</a>",,2024-12-11
Wide Flat Minimum Watermarking for Robust Ownership Verification of GANs,"Jianwei Fei, Zhihua Xia, Benedetta Tondi, Mauro Barni",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16919"" target=""_blank"">2310.16919</a>",,2024-12-11
A Survey on Transferability of Adversarial Examples across Deep Neural Networks,"Jindong Gu, Xiaojun Jia, Jorge Pau de, Wenqain Yu, Xinwei Liu, Avery Ma, Yuan Xun, Anjun Hu, Ashkan Khakzar, Zhijiang Li, Xiaochun Cao, Philip Torr",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17626"" target=""_blank"">2310.17626</a>",,2024-12-11
Defending Against Transfer Attacks From Public Models,"Chawin Sitawarin, Jaewon Chang, David Huang, Wesson Altoyan, David Wagner",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17645"" target=""_blank"">2310.17645</a>","<a href=""https://github.com/wagner-group/pubdef"" target=""_blank"">wagner-group</a>",2024-12-11
Uncertainty-weighted Loss Functions for Improved Adversarial Attacks on Semantic Segmentation,"Kira Maag, Asja Fischer",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17436"" target=""_blank"">2310.17436</a>",,2024-12-11
Detection Defenses: An Empty Promise against Adversarial Patch Attacks on Optical Flow,"Erik Scheurer, Jenny Schmalfuss, Alexander Lis, AndrÃ©s Bruhn",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17403"" target=""_blank"">2310.17403</a>","<a href=""https://github.com/cv-stuttgart/DetectionDefenses"" target=""_blank"">cv-stuttgart</a>",2024-12-11
CBD: A Certified Backdoor Detector Based on Local Dominant Probability,"Zhen Xiang, Zidi Xiong, Bo Li",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17498"" target=""_blank"">2310.17498</a>",,2024-12-11
SoK: Pitfalls in Evaluating Black-Box Attacks,"Fnu Suya, Anshuman Suri, Tingwei Zhang, Jingtao Hong, Yuan Tian, David Evans",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17534"" target=""_blank"">2310.17534</a>",,2024-12-11
Instability of computer vision models is a necessary result of the task itself,"Oliver Turnbull, George Cevora",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17559"" target=""_blank"">2310.17559</a>",,2024-12-11
PAC-tuning:Fine-tuning Pretrained Language Models with PAC-driven Perturbed Gradient Descent,"Guangliang Liu, Zhiyu Xue, Xitong Zhang, Kristen Marie Johnson, Rongrong Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17588"" target=""_blank"">2310.17588</a>",,2024-12-11
A minimax optimal control approach for robust neural ODEs,"Cristina Cipriani, Alessandro Scagliotti, Tobias WÃ¶hrer",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17584"" target=""_blank"">2310.17584</a>",,2024-12-11
"Break it, Imitate it, Fix it: Robustness by Generating Human-Like Attacks","Aradhana Sinha, Ananth Balashankar, Ahmad Beirami, Thi Avrahami, Jilin Chen, Alex Beutel",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16955"" target=""_blank"">2310.16955</a>",,2024-12-11
Amoeba: Circumventing ML-supported Network Censorship via Adversarial Reinforcement Learning,"Haoyu Liu, Alec F. Diallo, Paul Patras",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.20469"" target=""_blank"">2310.20469</a>",,2024-12-11
"Dual Defense: Adversarial, Traceable, and Invisible Robust Watermarking against Face Swapping","Yunming Zhang, Dengpan Ye, Caiyun Xie, Long Tang, Chuanxi Chen, Ziyi Liu, Jiacheng Deng",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16540"" target=""_blank"">2310.16540</a>",,2024-12-11
On the Proactive Generation of Unsafe Images From Text-To-Image Models Using Benign Prompts,"Yixin Wu, Ning Yu, Michael Backes, Yun Shen, Yang Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16613"" target=""_blank"">2310.16613</a>",,2024-12-11
Multi-scale Diffusion Denoised Smoothing,"Jongheon Jeong, Jinwoo Shin",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16779"" target=""_blank"">2310.16779</a>",,2024-12-11
Fast Propagation is Better: Accelerating Single-Step Adversarial Training via Sampling Subnetworks,"Xiaojun Jia, Jianshu Li, Jindong Gu, Yang Bai, Xiaochun Cao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15444"" target=""_blank"">2310.15444</a>","<a href=""https://github.com/jiaxiaojunQAQ/FP-Better"" target=""_blank"">jiaxiaojunQAQ</a>",2024-12-11
SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous Manipulation,"Qianxu Wang, Haotong Zhang, Congyue Deng, Yang You, Hao Dong, Yixin Zhu, Leonidas Guibas",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16838"" target=""_blank"">2310.16838</a>",,2024-12-11
Defense Against Model Extraction Attacks on Recommender Systems,"Sixiao Zhang, Hongzhi Yin, Hongxu Chen, Cheng Long",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16335"" target=""_blank"">2310.16335</a>",,2024-12-11
Segue: Side-information Guided Generative Unlearnable Examples for Facial Privacy Protection in Real World,"Zhiling Zhang, Jie Zhang, Kui Zhang, Wenbo Zhou, Weiming Zhang, Nenghai Yu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16061"" target=""_blank"">2310.16061</a>",,2024-12-11
Hierarchical Randomized Smoothing,"Yan Scholten, Jan Schuchardt, Aleksandar Bojchevski, Stephan GÃ¼nnemann",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16221"" target=""_blank"">2310.16221</a>",,2024-12-11
Momentum Gradient-based Untargeted Attack on Hypergraph Neural Networks,"Yang Chen, Stjepan Picek, Zhonglin Ye, Zhaoyang Wang, Haixing Zhao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15656"" target=""_blank"">2310.15656</a>",,2024-12-11
Corrupting Neuron Explanations of Deep Visual Features,"Divyansh Srivastava, Tuomas Oikarinen, Tsui-Wei Weng",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16332"" target=""_blank"">2310.16332</a>",,2024-12-11
Improving Robustness and Reliability in Medical Image Classification with Latent-Guided Diffusion and Nested-Ensembles,"Xing Shen, Hengguan Huang, Brennan Nichyporuk, Tal Arbel",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15952"" target=""_blank"">2310.15952</a>",,2024-12-11
Guiding LLM to Fool Itself: Automatically Manipulating Machine Reading Comprehension Shortcut Triggers,"Mosh Levy, Shauli Ravfogel, Yoav Goldberg",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18360"" target=""_blank"">2310.18360</a>",,2024-12-11
A Survey on Detection of LLMs-Generated Content,"Xianjun Yang, Liangming Pan, Xuandong Zhao, Haifeng Chen, Linda Petzold, William Yang Wang, Wei Cheng",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15654"" target=""_blank"">2310.15654</a>","<a href=""https://github.com/Xianjun-Yang/Awesome_papers_on_LLMs_detection"" target=""_blank"">Xianjun-Yang</a>",2024-12-11
White-box Compiler Fuzzing Empowered by Large Language Models,"Chenyuan Yang, Yinlin Deng, Runyu Lu, Jiayi Yao, Jiawei Liu, Reyhaneh Jabbarvand, Lingming Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15991"" target=""_blank"">2310.15991</a>",,2024-12-11
Enhancing Large Language Models for Secure Code Generation: A Dataset-driven Study on Vulnerability Mitigation,"Jiexin Wang, Liuwen Cao, Xitong Luo, Zhiping Zhou, Jiayuan Xie, Adam Jatowt, Yi Cai",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16263"" target=""_blank"">2310.16263</a>",,2024-12-11
Semantic-Aware Adversarial Training for Reliable Deep Hashing Retrieval,"Xu Yuan, Zheng Zhang, Xunguang Wang, Lin Wu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14637"" target=""_blank"">2310.14637</a>","<a href=""https://github.com/xandery-geek/SAAT"" target=""_blank"">xandery-geek</a>",2024-12-11
F$^2$AT: Feature-Focusing Adversarial Training via Disentanglement of Natural and Perturbed Patterns,"Yaguan Qian, Chenyu Zhao, Zhaoquan Gu, Bin Wang, Shouling Ji, Wei Wang, Boyang Zhou, Pan Zhou",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14561"" target=""_blank"">2310.14561</a>",,2024-12-11
Understanding Parameter Saliency via Extreme Value Theory,"Shuo Wang, Issei Sato",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17951"" target=""_blank"">2310.17951</a>",,2024-12-11
Elevating Code-mixed Text Handling through Auditory Information of Words,"Mamta, Zishan Ahmad, Asif Ekbal",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18155"" target=""_blank"">2310.18155</a>","<a href=""https://github.com/20118/DefenseWithPhonetics"" target=""_blank"">20118</a>",2024-12-11
LipSim: A Provably Robust Perceptual Similarity Metric,"Sara Ghazanfari, Alexandre Araujo, Prashanth Krishnamurthy, Farshad Khorrami, Siddharth Garg",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18274"" target=""_blank"">2310.18274</a>","<a href=""https://github.com/SaraGhazanfari/LipSim"" target=""_blank"">SaraGhazanfari</a>",2024-12-11
Understanding and Improving Ensemble Adversarial Defense,"Yian Deng, Tingting Mu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18477"" target=""_blank"">2310.18477</a>",,2024-12-11
LFAA: Crafting Transferable Targeted Adversarial Examples with Low-Frequency Perturbations,"Kunyu Wang, Juluan Shi, Wenxuan Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.20175"" target=""_blank"">2310.20175</a>",,2024-12-11
Is Robustness Transferable across Languages in Multilingual Neural Machine Translation? (26%),"Leiyu Pan, Supryadi, Deyi Xiong",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.20162"" target=""_blank"">2310.20162</a>",,2024-12-11
Dynamic Batch Norm Statistics Update for Natural Robustness,"Shahbaz Rezaei, Mohammad Sadegh Norouzzadeh",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.20649"" target=""_blank"">2310.20649</a>",,2024-12-11
In Search of Lost Online Test-time Adaptation: A Survey,"Zixin Wang, Yadan Luo, Liang Zheng, Zhuoxiao Chen, Sen Wang, Zi Huang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.20199"" target=""_blank"">2310.20199</a>","<a href=""https://github.com/Jo-wang/OTTA_ViT_survey"" target=""_blank"">Jo-wang</a>",2024-12-11
Label-Only Model Inversion Attacks via Knowledge Transfer,"Ngoc-Bao Nguyen, Keshigeyan Chandrasegaran, Milad Abdollahzadeh, Ngai-Man Cheung",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19342"" target=""_blank"">2310.19342</a>","<a href=""https://ngoc-nguyen-0.github.io/lokt/"" target=""_blank"">lokt</a>",2024-12-11
Exploring Geometry of Blind Spots in Vision Models,"Sriram Balasubramanian, Gaurang Sriramanan, Vinu Sankar Sadasivan, Soheil Feizi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19889"" target=""_blank"">2310.19889</a>","<a href=""https://github.com/SriramB-98/blindspots-neurips-sub"" target=""_blank"">SriramB-98</a>",2024-12-11
Adversarial Attacks and Defenses in Large Language Models: Old and New Threats,"Leo Schwinn, David Dobre, Stephan GÃ¼nnemann, Gauthier Gidel",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19737"" target=""_blank"">2310.19737</a>",,2024-12-11
Generated Distributions Are All You Need for Membership Inference Attacks Against Generative Models,"Minxing Zhang, Ning Yu, Rui Wen, Michael Backes, Yang Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19410"" target=""_blank"">2310.19410</a>",,2024-12-11
"Causal Fair Metric: Bridging Causality, Individual Fairness, and Adversarial Robustness","Ahmad-Reza Ehyaei, Golnoosh Farnadi, Samira Samadi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19391"" target=""_blank"">2310.19391</a>",,2024-12-11
Differentially Private Reward Estimation with Preference Feedback,"Sayak Ray Chowdhury, Xingyu Zhou, Nagarajan Natarajan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19733"" target=""_blank"">2310.19733</a>",,2024-12-11
Asymmetric Diffusion Based Channel-Adaptive Secure Wireless Semantic Communications,"Xintian Ren, Jun Wu, Hansong Xu, Qianqian Pan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19439"" target=""_blank"">2310.19439</a>",,2024-12-11
Privacy-Preserving Federated Learning over Vertically and Horizontally Partitioned Data for Financial Anomaly Detection,"Swanand Ravindra Kadhe, Heiko Ludwig, Nathalie Baracaldo, Alan King, Yi Zhou, Keith Houck, Ambrish Rawat, Mark Purcell, Naoise Holohan, Mikio Takeuchi, Ryo Kawahara, Nir Drucker, Hayim Shaul, Eyal Kushnir, Omri Soceanu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19304"" target=""_blank"">2310.19304</a>",,2024-12-11
Blacksmith: Fast Adversarial Training of Vision Transformers via a Mixture of Single-step and Multi-step Methods,"Mahdi Salmani, Alireza Dehghanpour Farashah, Mohammad Azizmalayeri, Mahdi Amiri, Navid Eslami, Mohammad Taghi Manzuri, Mohammad Hossein Rohban",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18975"" target=""_blank"">2310.18975</a>",,2024-12-11
Boosting Decision-Based Black-Box Adversarial Attack with Gradient Priors,"Han Liu, Xingshuo Huang, Xiaotong Zhang, Qimai Li, Fenglong Ma, Wei Wang, Hongyang Chen, Hong Yu, Xianchao Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19038"" target=""_blank"">2310.19038</a>",,2024-12-11
BERT Lost Patience Won't Be Robust to Adversarial Slowdown,"Zachary Coalson, Gabriel Ritter, Rakesh Bobba, Sanghyun Hong",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19152"" target=""_blank"">2310.19152</a>","<a href=""https://github.com/ztcoalson/WAFFLE"" target=""_blank"">ztcoalson</a>",2024-12-11
Adversarial Examples Are Not Real Features,"Ang Li, Yifei Wang, Yiwen Guo, Yisen Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18936"" target=""_blank"">2310.18936</a>","<a href=""https://github.com/PKU-ML/AdvNotRealFeatures"" target=""_blank"">PKU-ML</a>",2024-12-11
IMPRESS: Evaluating the Resilience of Imperceptible Perturbations Against Unauthorized Data Usage in Diffusion-Based Generative AI,"Bochuan Cao, Changjiang Li, Ting Wang, Jinyuan Jia, Bo Li, Jinghui Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19248"" target=""_blank"">2310.19248</a>",,2024-12-11
Poisoning Retrieval Corpora by Injecting Adversarial Passages,"Zexuan Zhong, Ziqing Huang, Alexander Wettig, Danqi Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19156"" target=""_blank"">2310.19156</a>",,2024-12-11
Label Poisoning is All You Need,"Rishi D. Jha, Jonathan Hayase, Sewoong Oh",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18933"" target=""_blank"">2310.18933</a>",,2024-12-11
Robustifying Language Models with Test-Time Adaptation,"Noah Thomas McDermott, Junfeng Yang, Chengzhi Mao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19177"" target=""_blank"">2310.19177</a>",,2024-12-11
Path Analysis for Effective Fault Localization in Deep Neural Networks,"Soroush Hashemifar, Saeed Parsa, Akram Kalaee",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18987"" target=""_blank"">2310.18987</a>",,2024-12-11
"From Chatbots to PhishBots? -- Preventing Phishing scams created using ChatGPT, Google Bard and Claude","Sayak Saha Roy, Poojitha Thota, Krishna Vamsi Naragam, Shirin Nilizadeh",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19181"" target=""_blank"">2310.19181</a>",,2024-12-11
Assessing and Improving Syntactic Adversarial Robustness of Pre-trained Models for Code Translation,"Guang Yang, Yu Zhou, Xiangyu Zhang, Xiang Chen, Tingting Han, Taolue Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18587"" target=""_blank"">2310.18587</a>",,2024-12-11
Benchmark Generation Framework with Customizable Distortions for Image Classifier Robustness,"Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad Mousavi, Zachariah Carmichael, Vineet Gundecha, Sahand Ghorbanpour, Ricardo Luna, Gutierrez Antonio Guillen, Avisek Naug",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18626"" target=""_blank"">2310.18626</a>",,2024-12-11
Purify++: Improving Diffusion-Purification with Advanced Diffusion Models and Control of Randomness,"Boya Zhang, Weijian Luo, Zhihua Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18762"" target=""_blank"">2310.18762</a>",,2024-12-11
Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers,"Wencong You, Zayd Hammoudeh, Daniel Lowd",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18603"" target=""_blank"">2310.18603</a>",,2024-12-11
Where have you been? A Study of Privacy Risk for Point-of-Interest Recommendation,"Kunlin Cai, Jinghuai Zhang, Will Shand, Zhiqing Hong, Guang Wang, Desheng Zhang, Jianfeng Chi, Yuan Tian",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18606"" target=""_blank"">2310.18606</a>",,2024-12-11
AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models,"Sicheng Zhu, Ruiyi Zhang, Bang An, Gang Wu, Joe Barrow, Zichao Wang, Furong Huang, Ani Nenkova, Tong Sun",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15140"" target=""_blank"">2310.15140</a>",,2024-12-11
Orthogonal Uncertainty Representation of Data Manifold for Robust Long-Tailed Learning,"Yanbiao Ma, Licheng Jiao, Fang Liu, Shuyuan Yang, Xu Liu, Lingling Li",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10090"" target=""_blank"">2310.10090</a>",,2024-12-11
On the Detection of Image-Scaling Attacks in Machine Learning,"Erwin Quiring, Andreas MÃ¼ller, Konrad Rieck",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15085"" target=""_blank"">2310.15085</a>",,2024-12-11
Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning,"Taejin Kim, Jiarui Li, Shubhranshu Singh, Nikhil Madaan, Carlee Joe-Wong",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11594"" target=""_blank"">2310.11594</a>",,2024-12-11
Segment Anything Meets Universal Adversarial Perturbation,"Dongshen Han, Sheng Zheng, Chaoning Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12431"" target=""_blank"">2310.12431</a>",,2024-12-11
IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks,"Yue Cao, Tianlin Li, Xiaofeng Cao, Ivor Tsang, Yang Liu, Qing Guo",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11890"" target=""_blank"">2310.11890</a>",,2024-12-11
"Revisiting Transferable Adversarial Image Examples: Attack Categorization, Evaluation Guidelines, and New Insights","Zhengyu Zhao, Hanwei Zhang, Renjue Li, Ronan Sicre, Laurent Amsaleg, Michael Backes, Qi Li, Chao Shen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11850"" target=""_blank"">2310.11850</a>",,2024-12-11
Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class Manipulation Using DeepFool Algorithm,"S. M. Fazle Rabby Labib, Joyanta Jyoti Mondal, Meem Arafat Manab, Sarfaraz Newaz, Xi Xiao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13019"" target=""_blank"">2310.13019</a>",,2024-12-11
Malicious Agent Detection for Robust Multi-Agent Collaborative Perception,"Yangheng Zhao, Zhen Xiang, Sheng Yin, Xianghe Pang, Siheng Chen, Yanfeng Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11901"" target=""_blank"">2310.11901</a>",,2024-12-11
Black-Box Training Data Identification in GANs via Detector Networks,"Lukman Olagoke, Salil Vadhan, Seth Neel",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12063"" target=""_blank"">2310.12063</a>",,2024-12-11
Adversarial Training for Physics-Informed Neural Networks,"Yao Li, Shengzhu Shi, Zhichang Guo, Boying Wu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11789"" target=""_blank"">2310.11789</a>",,2024-12-11
REVAMP: Automated Simulations of Adversarial Attacks on Arbitrary Objects in Realistic Scenes,"Matthew Hull, Zijie J. Wang, Duen Horng Chau",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12243"" target=""_blank"">2310.12243</a>","<a href=""https://github.com/poloclub/revamp"" target=""_blank"">poloclub</a>",2024-12-11
Quantifying Privacy Risks of Prompts in Visual Prompt Learning,"Yixin Wu, Rui Wen, Michael Backes, Pascal Berrang, Mathias Humbert, Yun Shen, Yang Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11970"" target=""_blank"">2310.11970</a>",,2024-12-11
To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images ,"Yimeng Zhang, Jinghan Jia, Xin Chen, Aochuan Chen, Yihua Zhang, Jiancheng Liu, Ke Ding, Sijia Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11868"" target=""_blank"">2310.11868</a>","<a href=""https://github.com/OPTML-Group/Diffusion-MU-Attack"" target=""_blank"">OPTML-Group</a>",2024-12-11
CAT: Closed-loop Adversarial Training for Safe End-to-End Driving,"Linrui Zhang, Zhenghao Peng, Quanyi Li, Bolei Zhou",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12432"" target=""_blank"">2310.12432</a>","<a href=""https://metadriverse.github.io/cat"" target=""_blank"">metadriverse.github.io</a>",2024-12-11
PrivInfer: Privacy-Preserving Inference for Black-box Large Language Model,"Meng Tong, Kejiang Chen, Yuang Qi, Jie Zhang, Weiming Zhang, Nenghai Yu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12214"" target=""_blank"">2310.12214</a>",,2024-12-11
The Efficacy of Transformer-based Adversarial Attacks in Security Domains,"Kunyang Li, Kyle Domico, Jean-Charles Noirot Ferrand, Patrick McDaniel",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11597"" target=""_blank"">2310.11597</a>",,2024-12-11
WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks,"Jun Xia, Zhihao Yue, Yingbo Zhou, Zhiwei Ling, Xian Wei, Mingsong Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11595"" target=""_blank"">2310.11595</a>",,2024-12-11
Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models,"Jianwei Li, Qi Lei, Wei Cheng, Dongkuan Xu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13191"" target=""_blank"">2310.13191</a>",,2024-12-11
Generalizability of CNN Architectures for Face Morph Presentation Attack,"Sherko R. HmaSalah, Aras Asaad",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11105"" target=""_blank"">2310.11105</a>",,2024-12-11
Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks,"Erfan Shayegani, Md Abdullah Al Mamun, Yu Fu, Pedram Zaree, Yue Dong, Nael Abu-Ghazaleh",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10844"" target=""_blank"">2310.10844</a>",,2024-12-11
Regularization properties of adversarially-trained linear regression,"AntÃ´nio H. Ribeiro, Dave Zachariah, Francis Bach, Thomas B. SchÃ¶n",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10807"" target=""_blank"">2310.10807</a>",,2024-12-11
Fast Adversarial Label-Flipping Attack on Tabular Data,"Xinglong Chang, Gillian Dobbie, JÃ¶rg Wicker",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10744"" target=""_blank"">2310.10744</a>",,2024-12-11
A Non-monotonic Smooth Activation Function,"Koushik Biswas, Meghana Karri, UlaÅ BaÄcÄ±",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10126"" target=""_blank"">2310.10126</a>",,2024-12-11
Quantifying Assistive Robustness Via the Natural-Adversarial Frontier,"Jerry Zhi-Yang He, Zackory Erickson, Daniel S. Brown, Anca D. Dragan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10610"" target=""_blank"">2310.10610</a>","<a href=""https://ood-human.github.io"" target=""_blank""></a>",2024-12-11
A Comprehensive Study of Privacy Risks in Curriculum Learning,"Joann Qiongna Chen, Xinlei He, Zheng Li, Yang Zhang, Zhou Li",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10124"" target=""_blank"">2310.10124</a>",,2024-12-11
DANAA: Towards transferable attacks with double adversarial neuron attribution,"Zhibo Jin, Zhiyu Zhu, Xinyi Wang, Jiayu Zhang, Jun Shen, Huaming Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10427"" target=""_blank"">2310.10427</a>","<a href=""https://github.com/Davidjinzb/DANAA"" target=""_blank"">Davidjinzb</a>",2024-12-11
Demystifying Poisoning Backdoor Attacks from a Statistical Perspective,"Ganghua Wang, Xun Xian, Jayanth Srinivasa, Ashish Kundu, Xuan Bi, Mingyi Hong, Jie Ding",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10780"" target=""_blank"">2310.10780</a>",,2024-12-11
Prompt Packer: Deceiving LLMs through Compositional Instruction with Hidden Attacks,"Shuyu Jiang, Xingshu Chen, Rui Tang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10077"" target=""_blank"">2310.10077</a>",,2024-12-11
Robust Multi-Agent Reinforcement Learning via Adversarial Regularization: Theoretical Foundation and Stable Algorithms,"Alexander Bukharin, Yan Li, Yue Yu, Qingru Zhang, Zhehui Chen, Simiao Zuo, Chao Zhang, Songan Zhang, Tuo Zhao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10810"" target=""_blank"">2310.10810</a>","<a href=""https://github.com/abukharin3/ERNIE"" target=""_blank"">abukharin3</a>",2024-12-11
Passive Inference Attacks on Split Learning via Adversarial Regularization,"Xiaochen Zhu, Xinjian Luo, Yuncheng Wu, Yangfan Jiang, Xiaokui Xiao, Beng Chin Ooi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10483"" target=""_blank"">2310.10483</a>",,2024-12-11
Unleashing the potential of prompt engineering: a comprehensive review,"Banghao Chen, Zhaofeng Zhang, Nicolas LangrenÃ©, Shengxin Zhu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14735"" target=""_blank"">2310.14735</a>",,2024-12-11
Exploring Decision-based Black-box Attacks on Face Forgery Detection,"Zhaoyu Chen, Bo Li, Kaixun Jiang, Shuang Wu, Shouhong Ding, Wenqiang Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12017"" target=""_blank"">2310.12017</a>",,2024-12-11
On the Transferability of Learning Models for Semantic Segmentation for Remote Sensing Data,"Rongjun Qin, Guixiang Zhang, Yang Tang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10490"" target=""_blank"">2310.10490</a>","<a href=""https://github.com/GDAOSU/Transferability-Remote-Sensing"" target=""_blank"">GDAOSU</a>",2024-12-11
Detecting Shared Data Manipulation in Distributed Optimization Algorithms,"Mohannad Alkhraijah, Rachel Harris, Samuel Litchfield, David Huggins, Daniel K. Molzahn",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13252"" target=""_blank"">2310.13252</a>",,2024-12-11
Calibration of Time-Series Forecasting: Detecting and Adapting Context-Driven Distribution Shift,"Mouxiang Chen, Lefei Shen, Han Fu, Zhuo Li, Jianling Sun, Chenghao Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14838"" target=""_blank"">2310.14838</a>",,2024-12-11
ADoPT: LiDAR Spoofing Attack Detection Based on Point-Level Temporal Consistency,"Minkyoung Cho, Yulong Cao, Zixiang Zhou, Z. Morley Mao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14504"" target=""_blank"">2310.14504</a>",,2024-12-11
MoPe: Model Perturbation-based Privacy Attacks on Language Models,"Marvin Li, Jason Wang, Jeffrey Wang, Seth Neel",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14369"" target=""_blank"">2310.14369</a>",,2024-12-11
Adversarial Image Generation by Spatial Transformation in Perceptual Colorspaces,"Ayberk Aydin, Alptekin Temizel",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13950"" target=""_blank"">2310.13950</a>","<a href=""https://github.com/ayberkydn/stadv-torch"" target=""_blank"">ayberkydn</a>",2024-12-11
CT-GAT: Cross-Task Generative Adversarial Attack based on Transferability,"Minxuan Lv, Chengwei Dai, Kun Li, Wei Zhou, Songlin Hu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14265"" target=""_blank"">2310.14265</a>",,2024-12-11
Diffusion-Based Adversarial Purification for Speaker Verification,"Yibo Bai, Xiao-Lei Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14270"" target=""_blank"">2310.14270</a>",,2024-12-11
Training Image Derivatives: Increased Accuracy and Universal Robustness,Vsevolod I. Avrutskiy,arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14045"" target=""_blank"">2310.14045</a>",,2024-12-11
The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks,"Xiaoyi Chen, Siyuan Tang, Rui Zhu, Shijun Yan, Lei Jin, Zihao Wang, Liya Su, Zhikun Zhang, XiaoFeng Wang, Haixu Tang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15469"" target=""_blank"">2310.15469</a>",,2024-12-11
Beyond Hard Samples: Robust and Effective Grammatical Error Correction with Cycle Self-Augmenting,"Zecheng Tang, Kaifeng Qi, Juntao Li, Min Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13321"" target=""_blank"">2310.13321</a>","<a href=""https://github.com/ZetangForward/CSA-GEC"" target=""_blank"">ZetangForward</a>",2024-12-11
An LLM can Fool Itself: A Prompt-Based Adversarial Attack,"Xilie Xu, Keyi Kong, Ning Liu, Lizhen Cui, Di Wang, Jingfeng Zhang, Mohan Kankanhalli",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13345"" target=""_blank"">2310.13345</a>",,2024-12-11
RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions,"Lingdong Kong, Shaoyuan Xie, Hanjiang Hu, Lai Xing Ng, Benoit R. Cottereau, Wei Tsang Ooi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15171"" target=""_blank"">2310.15171</a>",,2024-12-11
Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models,"Shawn Shan, Wenxin Ding, Josephine Passananti, Haitao Zheng, Ben Y. Zhao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13828"" target=""_blank"">2310.13828</a>",,2024-12-11
The Hidden Adversarial Vulnerabilities of Medical Federated Learning,"Erfan Darzi, Florian Dubost, Nanna. M. Sijtsema, Ooijen P. M. A van",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13893"" target=""_blank"">2310.13893</a>",,2024-12-11
Adversarial Attacks on Fairness of Graph Neural Networks,"Binchi Zhang, Yushun Dong, Chen Chen, Yada Zhu, Minnan Luo, Jundong Li",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13822"" target=""_blank"">2310.13822</a>","<a href=""https://github.com/zhangbinchi/G-FairAttack"" target=""_blank"">zhangbinchi</a>",2024-12-11
FLTracer: Accurate Poisoning Attack Provenance in Federated Learning,"Xinyu Zhang, Qingyu Liu, Zhongjie Ba, Yuan Hong, Tianhang Zheng, Feng Lin, Li Lu, Kui Ren",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13424"" target=""_blank"">2310.13424</a>","<a href=""https://github.com/Eyr3/FLTracer"" target=""_blank"">Eyr3</a>",2024-12-11
Attention-Enhancing Backdoor Attacks Against BERT-based Models,"Weimin Lyu, Songzhu Zheng, Lu Pang, Haibin Ling, Chao Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14480"" target=""_blank"">2310.14480</a>",,2024-12-11
To grok or not to grok: Disentangling generalization and memorization on corrupted algorithmic datasets,"Darshil Doshi, Aritra Das, Tianyu He, Andrey Gromov",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13061"" target=""_blank"">2310.13061</a>",,2024-12-11
OODRobustBench: benchmarking and analyzing adversarial robustness under distribution shift,"Lin Li, Yifei Wang, Chawin Sitawarin, Michael Spratling",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12793"" target=""_blank"">2310.12793</a>",,2024-12-11
Prompt Injection Attacks and Defenses in LLM-Integrated Applications,"Yupei Liu, Yuqi Jia, Runpeng Geng, Jinyuan Jia, Neil Zhenqiang Gong",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12815"" target=""_blank"">2310.12815</a>","<a href=""https://github.com/liu00222/Open-Prompt-Injection"" target=""_blank"">liu00222</a>",2024-12-11
Recoverable Privacy-Preserving Image Classification through Noise-like Adversarial Examples,"Jun Liu, Jiantao Zhou, Jinyu Tian, Weiwei Sun",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12707"" target=""_blank"">2310.12707</a>","<a href=""https://github.com/csjunjun/RIC"" target=""_blank"">csjunjun</a>",2024-12-11
Generating Robust Adversarial Examples against Online Social Networks (OSNs),"Jun Liu, Jiantao Zhou, Haiwei Wu, Weiwei Sun, Jinyu Tian",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12708"" target=""_blank"">2310.12708</a>","<a href=""https://github.com/csjunjun/RobustOSNAttack"" target=""_blank"">csjunjun</a>",2024-12-11
Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks,"Xiaodong Yu, Hao Cheng, Xiaodong Liu, Dan Roth, Jianfeng Gao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12516"" target=""_blank"">2310.12516</a>",,2024-12-11
Learn from the Past: A Proxy based Adversarial Defense Framework to Boost Robustness,"Yaohua Liu, Jiaxin Gao, Zhu Liu, Xianghao Jiao, Xin Fan, Risheng Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12713"" target=""_blank"">2310.12713</a>",,2024-12-11
Attack Prompt Generation for Red Teaming and Defending Large Language Models,"Boyi Deng, Wenjie Wang, Fuli Feng, Yang Deng, Qifan Wang, Xiangnan He",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12505"" target=""_blank"">2310.12505</a>","<a href=""https://github.com/Aatrox103/SAP"" target=""_blank"">Aatrox103</a>",2024-12-11
SecurityNet: Assessing Machine Learning Vulnerabilities on Public Models,"Boyang Zhang, Zheng Li, Ziqing Yang, Xinlei He, Michael Backes, Mario Fritz, Yang Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12665"" target=""_blank"">2310.12665</a>",,2024-12-11
Data-Free Knowledge Distillation Using Adversarially Perturbed OpenGL Shader Images,"Logan Frank, Jim Davis",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13782"" target=""_blank"">2310.13782</a>",,2024-12-11
VOICE-ZEUS: Impersonating Zoom's E2EE-Protected Static Media and Textual Communications via Simple Voice Manipulations,"Mashari Alatawi, Nitesh Saxena",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13894"" target=""_blank"">2310.13894</a>",,2024-12-11
"PatchCURE: Improving Certifiable Robustness, Model Utility, and Computation Efficiency of Adversarial Patch Defenses","Chong Xiang, Tong Wu, Sihui Dai, Jonathan Petit, Suman Jana, Prateek Mittal",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13076"" target=""_blank"">2310.13076</a>",,2024-12-11
Counterfactual Explanations via Locally-guided Sequential Algorithmic Recourse,"Edward A. Small, Jeffrey N. Clark, Christopher J. McWilliams, Kacper Sokol, Jeffrey Chan, Flora D. Salim, Raul Santos-Rodriguez",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.04211"" target=""_blank"">2309.04211</a>",,2024-12-11
DiffDefense: Defending against Adversarial Attacks via Diffusion Models,"Hondamunige Prasanna Silva, Lorenzo Seidenari, Bimbo Alberto Del",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03702"" target=""_blank"">2309.03702</a>","<a href=""https://github.com/HondamunigePrasannaSilva/DiffDefence"" target=""_blank"">HondamunigePrasannaSilva</a>",2024-12-11
Divergences in Color Perception between Deep Neural Networks and Humans,"Ethan O. Nadler, Elise Darragh-Ford, Bhargav Srinivasa Desikan, Christian Conaway, Mark Chu, Tasker Hull, Douglas Guilbeault",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05809"" target=""_blank"">2309.05809</a>",,2024-12-11
Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences,"Jeremiah Birrell, Mohammadreza Ebrahimi",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03791"" target=""_blank"">2309.03791</a>",,2024-12-11
How adversarial attacks can disrupt seemingly stable accurate classifiers,"Oliver J. Sutton, Qinghua Zhou, Ivan Y. Tyukin, Alexander N. Gorban, Alexander Bastounis, Desmond J. Higham",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03665"" target=""_blank"">2309.03665</a>",,2024-12-11
Catch You Everything Everywhere: Guarding Textual Inversion via Concept Watermarking,"Weitao Feng, Jiyan He, Jie Zhang, Tianwei Zhang, Wenbo Zhou, Weiming Zhang, Nenghai Yu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05940"" target=""_blank"">2309.05940</a>",,2024-12-11
Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs,"Wenhua Cheng, Weiwei Zhang, Haihao Shen, Yiyang Cai, Xin He, Kaokao Lv",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05516"" target=""_blank"">2309.05516</a>","<a href=""https://github.com/intel/neural-compressor"" target=""_blank"">intel</a>",2024-12-11
Outlier Robust Adversarial Training,"Shu Hu, Zhenhuan Yang, Xin Wang, Yiming Ying, Siwei Lyu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05145"" target=""_blank"">2309.05145</a>","<a href=""https://github.com/discovershu/ORAT"" target=""_blank"">discovershu</a>",2024-12-11
Experimental Study of Adversarial Attacks on ML-based xApps in O-RAN,"Naveen Naik Sapavath, Brian Kim, Kaushik Chowdhury, Vijay K Shah",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03844"" target=""_blank"">2309.03844</a>",,2024-12-11
Adversarial attacks on hybrid classical-quantum Deep Learning models for Histopathological Cancer Detection,"Biswaraj Baral, Reek Majumdar, Bhavika Bhalgamiya, Taposh Dutta Roy",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06377"" target=""_blank"">2309.06377</a>",,2024-12-11
DAD++: Improved Data-free Test Time Adversarial Defense,"Gaurav Kumar Nayak, Inder Khatri, Shubham Randive, Ruchit Rawal, Anirban Chakraborty",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05132"" target=""_blank"">2309.05132</a>","<a href=""https://github.com/vcl-iisc/Improved-Data-free-Test-Time-Adversarial-Defense"" target=""_blank"">vcl-iisc</a>",2024-12-11
Machine Translation Models Stand Strong in the Face of Adversarial Attacks,"Pavel Burnyshev, Elizaveta Kostenok, Alexey Zaytsev",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06527"" target=""_blank"">2309.06527</a>",,2024-12-11
Secure Set-Based State Estimation for Linear Systems under Adversarial Attacks on Sensors,"M. Umar B. Niazi, Michelle S. Chong, Amr Alanwar, Karl H. Johansson",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05075"" target=""_blank"">2309.05075</a>",,2024-12-11
Exploring Robust Features for Improving Adversarial Robustness,"Hong Wang, Yuefan Deng, Shinjae Yoo, Yuewei Lin",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.04650"" target=""_blank"">2309.04650</a>",,2024-12-11
ARRTOC: Adversarially Robust Real-Time Optimization and Control,"Akhil Ahmed, Rio-Chanona Ehecatl Antonio del, Mehmet Mercangoz",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.04386"" target=""_blank"">2309.04386</a>",,2024-12-11
Towards Robust Model Watermark via Reducing Parametric Vulnerability,"Guanhao Gan, Yiming Li, Dongxian Wu, Shu-Tao Xia",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.04777"" target=""_blank"">2309.04777</a>","<a href=""https://github.com/GuanhaoGan/robust-model-watermarking"" target=""_blank"">GuanhaoGan</a>",2024-12-11
Generalized Attacks on Face Verification Systems,"Ehsan Nazari, Paula Branco, Guy-Vincent Jourdan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05879"" target=""_blank"">2309.05879</a>",,2024-12-11
Privacy Side Channels in Machine Learning Systems,"Edoardo Debenedetti, Giorgio Severi, Nicholas Carlini, Christopher A. Choquette-Choo, Matthew Jagielski, Milad Nasr, Eric Wallace, Florian TramÃ¨r",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05610"" target=""_blank"">2309.05610</a>",,2024-12-11
Adversarial Attacks Assessment of Salient Object Detection via Symbolic Learning,"Gustavo Olague, Roberto Pineda, Gerardo Ibarra-Vazquez, Matthieu Olague, Axel Martinez, Sambit Bakshi, Jonathan Vargas, Isnardo Reducindo",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05900"" target=""_blank"">2309.05900</a>",,2024-12-11
Semantic Adversarial Attacks via Diffusion Models,"Chenan Wang, Jinhao Duan, Chaowei Xiao, Edward Kim, Matthew Stamm, Kaidi Xu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07398"" target=""_blank"">2309.07398</a>","<a href=""https://github.com/steven202/semantic_adv_via_dm"" target=""_blank"">steven202</a>",2024-12-11
Hardening RGB-D Object Recognition Systems against Adversarial Patch Attacks,"Yang Zheng, Luca Demetrio, Antonio Emanuele CinÃ , Xiaoyi Feng, Zhaoqiang Xia, Xiaoyue Jiang, Ambra Demontis, Battista Biggio, Fabio Roli",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07106"" target=""_blank"">2309.07106</a>",,2024-12-11
Mitigating Adversarial Attacks in Federated Learning with Trusted Execution Environments,"Simon Queyrut, Valerio Schiavoni, Pascal Felber",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07197"" target=""_blank"">2309.07197</a>","<a href=""https://github.com/queyrusi/Pelta"" target=""_blank"">queyrusi</a>",2024-12-11
"PhantomSound: Black-Box, Query-Efficient Audio Adversarial Attack via Split-Second Phoneme Injection","Hanqing Guo, Guangjing Wang, Yuanda Wang, Bocheng Chen, Qiben Yan, Li Xiao",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06960"" target=""_blank"">2309.06960</a>",,2024-12-11
APICom: Automatic API Completion via Prompt Learning and Adversarial Training-based Data Augmentation,"Yafeng Gu, Yiheng Shen, Xiang Chen, Shaoyu Yang, Yiling Huang, Zhixiang Cao",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07026"" target=""_blank"">2309.07026</a>",,2024-12-11
RAIN: Your Language Models Can Align Themselves without Finetuning,"Yuhui Li, Fangyun Wei, Jinjing Zhao, Chao Zhang, Hongyang Zhang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07124"" target=""_blank"">2309.07124</a>",,2024-12-11
Differentiable JPEG: The Devil is in the Details,"Christoph Reich, Biplob Debnath, Deep Patel, Srimat Chakradhar",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06978"" target=""_blank"">2309.06978</a>","<a href=""https://github.com/necla-ml/Diff-JPEG"" target=""_blank"">necla-ml</a>",2024-12-11
"Deep Nonparametric Convexified Filtering for Computational Photography, Image Synthesis and Adversarial Defense",Jianqiao Wangni,arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06724"" target=""_blank"">2309.06724</a>",,2024-12-11
MASTERKEY: Practical Backdoor Attack Against Speaker Verification Systems,"Hanqing Guo, Xun Chen, Junfeng Guo, Li Xiao, Qiben Yan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06981"" target=""_blank"">2309.06981</a>",,2024-12-11
Client-side Gradient Inversion Against Federated Learning from Poisoning,"Jiaheng Wei, Yanjun Zhang, Leo Yu Zhang, Chao Chen, Shirui Pan, Kok-Leong Ong, Jun Zhang, Yang Xiang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07415"" target=""_blank"">2309.07415</a>",,2024-12-11
Safe Reinforcement Learning with Dual Robustness,"Zeyang Li, Chuxiong Hu, Yunan Wang, Yujie Yang, Shengbo Eben Li",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06835"" target=""_blank"">2309.06835</a>",,2024-12-11
Using Reed-Muller Codes for Classification with Rejection and Recovery,"Daniel University of Birmingham Fentham, David University of Oxford Parker, Mark University of Birmingham Ryan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06359"" target=""_blank"">2309.06359</a>",,2024-12-11
Certified Robust Models with Slack Control and Large Lipschitz Constants,"Max Losch, David Stutz, Bernt Schiele, Mario Fritz",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06166"" target=""_blank"">2309.06166</a>",,2024-12-11
Exploring Non-additive Randomness on ViT against Query-Based Black-Box Attacks,"Jindong Gu, Fangyun Wei, Philip Torr, Han Hu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06438"" target=""_blank"">2309.06438</a>",,2024-12-11
"Compiled Models, Built-In Exploits: Uncovering Pervasive Bit-Flip Attack Surfaces in DNN Executables","Yanzuo The Hong Kong University of Science and Technology Chen, Zhibo The Hong Kong University of Science and Technology Liu, Yuanyuan The Hong Kong University of Science and Technology Yuan, Sihang Huawei Technologies Hu, Tianxiang Huawei Technologies Li, Shuai The Hong Kong University of Science and Technology Wang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06223"" target=""_blank"">2309.06223</a>",,2024-12-11
Backdoor Attacks and Countermeasures in Natural Language Processing Models: A Comprehensive Security Review,"Pengzhou Cheng, Zongru Wu, Wei Du, Gongshen Liu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06055"" target=""_blank"">2309.06055</a>",,2024-12-11
CToMP: A Cycle-task-oriented Memory Protection Scheme for Unmanned Systems,"Chengyan Ma, Ning Xi, Di Lu, Yebo Feng, Jianfeng Ma",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05978"" target=""_blank"">2309.05978</a>",,2024-12-11
Language Models as Black-Box Optimizers for Vision-Language Models,"Shihong Liu, Zhiqiu Lin, Samuel Yu, Ryan Lee, Tiffany Ling, Deepak Pathak, Deva Ramanan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05950"" target=""_blank"">2309.05950</a>",,2024-12-11
Promoting Fairness in GNNs: A Characterization of Stability,"Yaning Jia, Chunhui Zhang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03648"" target=""_blank"">2309.03648</a>",,2024-12-11
One-to-Multiple Clean-Label Image Camouflage (OmClic) based Backdoor Attack on Deep Learning,"Guohong Wang, Hua Ma, Yansong Gao, Alsharif Abuadbba, Zhi Zhang, Wei Kang, Said F. Al-Sarawib, Gongxuan Zhang, Derek Abbott",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.04036"" target=""_blank"">2309.04036</a>",,2024-12-11
MIRA: Cracking Black-box Watermarking on Deep Neural Networks via Model Inversion-based Removal Attacks,"Yifan Lu, Wenxuan Li, Mi Zhang, Xudong Pan, Min Yang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03466"" target=""_blank"">2309.03466</a>",,2024-12-11
Certifying LLM Safety against Adversarial Prompting,"Aounon Kumar, Chirag Agarwal, Suraj Srinivas, Aaron Jiaxun Li, Soheil Feizi, Himabindu Lakkaraju",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02705"" target=""_blank"">2309.02705</a>","<a href=""https://github.com/aounon/certified-llm-safety"" target=""_blank"">aounon</a>",2024-12-11
Curating Naturally Adversarial Datasets for Trustworthy AI in Healthcare,"Sydney Pugh, Ivan Ruchkin, Insup Lee, James Weimer",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00543"" target=""_blank"">2309.00543</a>",,2024-12-11
Turn Fake into Real: Adversarial Head Turn Attacks Against Deepfake Detection,"Weijie Wang, Zhengyu Zhao, Nicu Sebe, Bruno Lepri",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01104"" target=""_blank"">2309.01104</a>","<a href=""https://github.com/twowwj/AdvHeaT"" target=""_blank"">twowwj</a>",2024-12-11
AdvMono3D: Advanced Monocular 3D Object Detection with Depth-Aware Robust Adversarial Training,"Xingyuan Li, Jinyuan Liu, Long Ma, Xin Fan, Risheng Liu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01106"" target=""_blank"">2309.01106</a>",,2024-12-11
Robust Adversarial Defense by Tensor Factorization,"Manish Bhattarai, Mehmet Cagri Kaymak, Ryan Barron, Ben Nebgen, Kim Rasmussen, Boian Alexandrov",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01077"" target=""_blank"">2309.01077</a>",,2024-12-11
Dual Adversarial Resilience for Collaborating Robust Underwater Image Enhancement and Perception,"Zengxi Zhang, Zhiying Jiang, Zeru Shi, Jinyuan Liu, Risheng Liu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01102"" target=""_blank"">2309.01102</a>",,2024-12-11
Towards Certified Probabilistic Robustness with High Accuracy,"Ruihan Zhang, Peixin Zhang, Jun Sun",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00879"" target=""_blank"">2309.00879</a>",,2024-12-11
Timbre-reserved Adversarial Attack in Speaker Identification,"Qing Wang, Jixun Yao, Li Zhang, Pengcheng Guo, Lei Xie",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00929"" target=""_blank"">2309.00929</a>",,2024-12-11
Regularly Truncated M-estimators for Learning with Noisy Labels,"Xiaobo Xia, Pengqian Lu, Chen Gong, Bo Han, Jun Yu, Jun Yu, Tongliang Liu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00894"" target=""_blank"">2309.00894</a>",,2024-12-11
Baseline Defenses for Adversarial Attacks Against Aligned Language Models,"Neel Jain, Avi Schwarzschild, Yuxin Wen, Gowthami Somepalli, John Kirchenbauer, Ping-yeh Chiang, Micah Goldblum, Aniruddha Saha, Jonas Geiping, Tom Goldstein",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00614"" target=""_blank"">2309.00614</a>",,2024-12-11
Non-Asymptotic Bounds for Adversarial Excess Risk under Misspecified Models,"Changyu Liu, Yuling Jiao, Junhui Wang, Jian Huang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00771"" target=""_blank"">2309.00771</a>",,2024-12-11
Dropout Attacks,"Andrew Yuan, Alina Oprea, Cheng Tan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01614"" target=""_blank"">2309.01614</a>",,2024-12-11
Why do universal adversarial attacks work on large language models?: Geometry might be the answer,"Varshini Subhash, Anna Bialas, Weiwei Pan, Finale Doshi-Velez",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00254"" target=""_blank"">2309.00254</a>",,2024-12-11
RenAIssance: A Survey into AI Text-to-Image Generation in the Era of Large Model,"Fengxiang Bie, Yibo Yang, Zhongzhu Zhou, Adam Ghanem, Minjia Zhang, Zhewei Yao, Xiaoxia Wu, Connor Holmes, Pareesa Golnari, David A. Clifton, Yuxiong He, Dacheng Tao, Shuaiwen Leon Song",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00810"" target=""_blank"">2309.00810</a>",,2024-12-11
Learned Visual Features to Textual Explanations,"Saeid Asgari Taghanaki, Aliasghar Khani, Amir Khasahmadi, Aditya Sanghi, Karl D. D. Willis, Ali Mahdavi-Amiri",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00733"" target=""_blank"">2309.00733</a>",,2024-12-11
Image Hijacking: Adversarial Images can Control Generative Models at Runtime,"Luke Bailey, Euan Ong, Stuart Russell, Scott Emmons",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00236"" target=""_blank"">2309.00236</a>",,2024-12-11
When Measures are Unreliable: Imperceptible Adversarial Perturbations toward Top-$k$ Multi-Label Learning,"Yuchen Sun, Qianqian Xu, Zitai Wang, Qingming Huang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00007"" target=""_blank"">2309.00007</a>",,2024-12-11
FTA: Stealthy and Robust Backdoor Attack with Flexible Trigger on Federated Learning,"Yanqi Qiao, Congwen Chen, Rui Wang, Kaitai Liang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00127"" target=""_blank"">2309.00127</a>",,2024-12-11
General Lipschitz: Certified Robustness Against Resolvable Semantic Transformations via Transformation-Dependent Randomized Smoothing,"Dmitrii Korzh, Mikhail Pautov, Olga Tsymboi, Ivan Oseledets",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16710"" target=""_blank"">2309.16710</a>",,2024-12-11
AIR: Threats of Adversarial Attacks on Deep Learning-Based Information Recovery,"Jinyin Chen, Jie Ge, Shilian Zheng, Linhui Ye, Haibin Zheng, Weiguo Shen, Keqiang Yue, Xiaoniu Yang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16706"" target=""_blank"">2309.16706</a>",,2024-12-11
Uncertainty in AI: Evaluating Deep Neural Networks on Out-of-Distribution Images,"Jamiu Idowu, Ahmed Almasoud",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01850"" target=""_blank"">2309.01850</a>",,2024-12-11
Safe and Robust Watermark Injection with a Single OoD Image,"Shuyang Yu, Junyuan Hong, Haobo Zhang, Haotao Wang, Zhangyang Wang, Jiayu Zhou",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01786"" target=""_blank"">2309.01786</a>",,2024-12-11
SWAP: Exploiting Second-Ranked Logits for Adversarial Attacks on Time Series,"Chang George Dong, Liangwei Nathan Zheng, Weitong Chen, Wei Emma Zhang, Lin Yue",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02752"" target=""_blank"">2309.02752</a>",,2024-12-11
M3Dsynth: A dataset of medical 3D images with AI-generated local manipulations,"Giada Zingarini, Davide Cozzolino, Riccardo Corvi, Giovanni Poggi, Luisa Verdoliva",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07973"" target=""_blank"">2309.07973</a>","<a href=""https://grip-unina.github.io/M3Dsynth/"" target=""_blank"">M3Dsynth</a>",2024-12-11
Byzantine-Robust Federated Learning with Variance Reduction and Differential Privacy,"Zikai Zhang, Rui Hu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03437"" target=""_blank"">2309.03437</a>",,2024-12-11
J-Guard: Journalism Guided Adversarially Robust Detection of AI-generated News,"Tharindu Kumarage, Amrita Bhattacharjee, Djordje Padejski, Kristy Roschke, Dan Gillmor, Scott Ruston, Huan Liu, Joshua Garland",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03164"" target=""_blank"">2309.03164</a>",,2024-12-11
Explainable and Trustworthy Traffic Sign Detection for Safe Autonomous Driving: An Inductive Logic Programming Approach,"Zahra University of Surrey Chaghazardi, Saber University of Surrey Fallah, Alireza University of Surrey Tamaddoni-Nezhad",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03215"" target=""_blank"">2309.03215</a>",,2024-12-11
My Art My Choice: Adversarial Protection Against Unruly AI,"Anthony Rhodes, Ram Bhagat, Umur Aybars Ciftci, Ilke Demir",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03198"" target=""_blank"">2309.03198</a>",,2024-12-11
A Theoretical Explanation of Activation Sparsity through Flat Minima and Adversarial Robustness,"Ze Peng, Lei Qi, Yinghuan Shi, Yang Gao",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03004"" target=""_blank"">2309.03004</a>",,2024-12-11
The Adversarial Implications of Variable-Time Inference,"Dudi Biton, Aditi Misra, Efrat Levy, Jaidip Kotak, Ron Bitton, Roei Schuster, Nicolas Papernot, Yuval Elovici, Ben Nassi",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02159"" target=""_blank"">2309.02159</a>",,2024-12-11
Adaptive Adversarial Training Does Not Increase Recourse Costs,"Ian Hardy, Jayanth Yetukuri, Yang Liu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02528"" target=""_blank"">2309.02528</a>",,2024-12-11
Black-Box Attacks against Signed Graph Analysis via Balance Poisoning,"Jialong Zhou, Yuni Lai, Jian Ren, Kai Zhou",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02396"" target=""_blank"">2309.02396</a>",,2024-12-11
Robust Recommender System: A Survey and Future Directions,"Kaike Zhang, Qi Cao, Fei Sun, Yunfan Wu, Shuchang Tao, Huawei Shen, Xueqi Cheng",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02057"" target=""_blank"">2309.02057</a>",,2024-12-11
EventTrojan: Manipulating Non-Intrusive Speech Quality Assessment via Imperceptible Events,"Ying Ren, Kailai Shen, Zhe Ye, Diqun Yan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01480"" target=""_blank"">2309.01480</a>",,2024-12-11
Dual Adversarial Alignment for Realistic Support-Query Shift Few-shot Learning,"Siyang Jiang, Rui Fang, Hsi-Wen Chen, Wei Ding, Ming-Syan Chen",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02088"" target=""_blank"">2309.02088</a>",,2024-12-11
Hindering Adversarial Attacks with Multiple Encrypted Patch Embeddings,"AprilPyone MaungMaung, Isao Echizen, Hitoshi Kiya",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01620"" target=""_blank"">2309.01620</a>",,2024-12-11
Improving Visual Quality and Transferability of Adversarial Attacks on Face Recognition Simultaneously with Adversarial Restoration,"Fengfan Zhou, Hefei Ling, Yuxuan Shi, Jiazhong Chen, Ping Li",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01582"" target=""_blank"">2309.01582</a>",,2024-12-11
Adv3D: Generating 3D Adversarial Examples in Driving Scenarios with NeRF,"Leheng Li, Qing Lian, Ying-Cong Chen",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01351"" target=""_blank"">2309.01351</a>","<a href=""https://len-li.github.io/adv3d-web"" target=""_blank"">len-li.github.io</a>",2024-12-11
Toward Defensive Letter Design,"Rentaro Kataoka, Akisato Kimura, Seiichi Uchida",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01452"" target=""_blank"">2309.01452</a>",,2024-12-11
MathAttack: Attacking Large Language Models Towards Math Solving Ability,"Zihao Zhou, Qiufeng Wang, Mingyu Jin, Jie Yao, Jianan Ye, Wei Liu, Wei Wang, Xiaowei Huang, Kaizhu Huang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01686"" target=""_blank"">2309.01686</a>",,2024-12-11
Efficient Defense Against Model Stealing Attacks on Convolutional Neural Networks,"Kacem Khaled, Mouna Dhaouadi, MagalhÃ£es Felipe Gohring de, Gabriela Nicolescu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01838"" target=""_blank"">2309.01838</a>",,2024-12-11
Efficient Query-Based Attack against ML-Based Android Malware Detection under Zero Knowledge Setting,"Ping He, Yifan Xia, Xuhong Zhang, Shouling Ji",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01866"" target=""_blank"">2309.01866</a>",,2024-12-11
Building a Winning Team: Selecting Source Model Ensembles using a Submodular Transferability Estimation Approach,"Vimal K B, Saketh Bachu, Tanmay Garg, Niveditha Lakshmi Narasimhan, Raghavan Konuru, Vineeth N Balasubramanian",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02429"" target=""_blank"">2309.02429</a>",,2024-12-11
RecAD: Towards A Unified Library for Recommender Attack and Defense,"Changsheng Wang, Jianbai Ye, Wenjie Wang, Chongming Gao, Fuli Feng, Xiangnan He",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.04884"" target=""_blank"">2309.04884</a>","<a href=""https://github.com/gusye1234/recad"" target=""_blank"">gusye1234</a>",2024-12-11
Physical Invisible Backdoor Based on Camera Imaging,"Yusheng Guo, Nan Zhong, Zhenxing Qian, Xinpeng Zhang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07428"" target=""_blank"">2309.07428</a>",,2024-12-11
Projected Randomized Smoothing for Certified Adversarial Robustness,"Samuel Pfrommer, Brendon G. Anderson, Somayeh Sojoudi",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13794"" target=""_blank"">2309.13794</a>",,2024-12-11
Privacy-preserving and Privacy-attacking Approaches for Speech and Audio -- A Survey,"Yuchen Liu, Apu Kapadia, Donald Williamson",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15087"" target=""_blank"">2309.15087</a>",,2024-12-11
Neural Stochastic Differential Equations for Robust and Explainable Analysis of Electromagnetic Unintended Radiated Emissions,"Sumit Kumar Jha, Susmit Jha, Rickard Ewetz, Alvaro Velasquez",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15386"" target=""_blank"">2309.15386</a>",,2024-12-11
Collaborative Watermarking for Adversarial Speech Synthesis,"Lauri Aalto University, Finland Juvela, Xin National Institute of Informatics, Japan Wang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15224"" target=""_blank"">2309.15224</a>",,2024-12-11
DifAttack: Query-Efficient Black-Box Attack via Disentangled Feature Space,"Liu Jun, Zhou Jiantao, Zeng Jiandian, Jinyu Tian",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.14585"" target=""_blank"">2309.14585</a>","<a href=""https://github.com/csjunjun/DifAttack"" target=""_blank"">csjunjun</a>",2024-12-11
Gray-box Adversarial Attack of Deep Reinforcement Learning-based Trading Agents,"Foozhan Ataiefard, Hadi Hemmati",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.14615"" target=""_blank"">2309.14615</a>",,2024-12-11
SurrogatePrompt: Bypassing the Safety Filter of Text-To-Image Models via Substitution,"Zhongjie Ba, Jieming Zhong, Jiachen Lei, Peng Cheng, Qinglong Wang, Zhan Qin, Zhibo Wang, Kui Ren",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.14122"" target=""_blank"">2309.14122</a>",,2024-12-11
Adversarial Attacks on Video Object Segmentation with Hard Region Discovery,"Ping Li, Yu Zhang, Li Yuan, Jian Zhao, Xianghua Xu, Xiaoqin Zhang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13857"" target=""_blank"">2309.13857</a>",,2024-12-11
Vulnerabilities in Video Quality Assessment Models: The Challenge of Adversarial Attacks,"Ao-Xiang Zhang, Yu Ran, Weixuan Tang, Yuan-Gen Wang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13609"" target=""_blank"">2309.13609</a>","<a href=""https://github.com/GZHU-DVL/AttackVQA"" target=""_blank"">GZHU-DVL</a>",2024-12-11
On the Effectiveness of Adversarial Samples against Ensemble Learning-based Windows PE Malware Detectors,"Trong-Nghia To, Danh Le Kim, Do Thi Thu Hien, Nghi Hoang Khoa, Hien Do Hoang, Phan The Duy, Van-Hau Pham",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13841"" target=""_blank"">2309.13841</a>",,2024-12-11
Combining Two Adversarial Attacks Against Person Re-Identification Systems,"Eduardo de O. Andrade, Igor Garcia Ballhausen Sampaio, Joris GuÃ©rin, JosÃ© Viterbo",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13763"" target=""_blank"">2309.13763</a>",,2024-12-11
Expressive variational quantum circuits provide inherent privacy in federated learning,"Niraj Kumar, Jamie Heredge, Changhao Li, Shaltiel Eloul, Shree Hari Sureshbabu, Marco Pistoia",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13002"" target=""_blank"">2309.13002</a>",,2024-12-11
Seeing Is Not Always Believing: Invisible Collision Attack and Defence on Pre-Trained Models,"Minghang Deng, Zhong Zhang, Junming Shao",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13579"" target=""_blank"">2309.13579</a>",,2024-12-11
Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks,"Zhaohan Xi, Tianyu Du, Changjiang Li, Ren Pang, Shouling Ji, Jinghui Chen, Fenglong Ma, Ting Wang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13256"" target=""_blank"">2309.13256</a>",,2024-12-11
Moving Target Defense based Secured Network Slicing System in the O-RAN Architecture,"Mojdeh Karbalaee Motalleb, Chafika BenzaÃ¯d, Tarik Taleb, Vahid Shah-Mansouri",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13444"" target=""_blank"">2309.13444</a>",,2024-12-11
Detecting and Mitigating System-Level Anomalies of Vision-Based Controllers,"Aryaman Gupta, Kaustav Chakraborty, Somil Bansal",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13475"" target=""_blank"">2309.13475</a>",,2024-12-11
RBFormer: Improve Adversarial Robustness of Transformer by Robust Bias,"Hao Cheng, Jinhao Duan, Hui Li, Lyutianyang Zhang, Jiahang Cao, Ping Wang, Jize Zhang, Kaidi Xu, Renjing Xu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13245"" target=""_blank"">2309.13245</a>",,2024-12-11
"Spatial-frequency channels, shape bias, and adversarial robustness","Ajay Subramanian, Elena Sizikova, Najib J. Majaj, Denis G. Pelli",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13190"" target=""_blank"">2309.13190</a>",,2024-12-11
VIC-KD: Variance-Invariance-Covariance Knowledge Distillation to Make Keyword Spotting More Robust Against Adversarial Attacks,"Heitor R. GuimarÃ£es, Arthur Pimentel, Anderson Avila, Tiago H. Falk",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.12914"" target=""_blank"">2309.12914</a>",,2024-12-11
Understanding Deep Gradient Leakage via Inversion Influence Functions,"Haobo Zhang, Junyuan Hong, Yuyang Deng, Mehrdad Mahdavi, Jiayu Zhou",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13016"" target=""_blank"">2309.13016</a>","<a href=""https://github.com/illidanlab/inversion-influence-function"" target=""_blank"">illidanlab</a>",2024-12-11
Pixel-wise Smoothing for Certified Robustness against Camera Motion Perturbations,"Hanjiang Hu, Zuxin Liu, Linyi Li, Jiacheng Zhu, Ding Zhao",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13150"" target=""_blank"">2309.13150</a>",,2024-12-11
Structure Invariant Transformation for better Adversarial Transferability,"Xiaosen Wang, Zeliang Zhang, Jianping Zhang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.14700"" target=""_blank"">2309.14700</a>","<a href=""https://github.com/xiaosen-wang/SIT"" target=""_blank"">xiaosen-wang</a>",2024-12-11
Breaking On-Chip Communication Anonymity using Flow Correlation Attacks,"Hansika Weerasena, Prabhat Mishra",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15687"" target=""_blank"">2309.15687</a>",,2024-12-11
Generating Transferable Adversarial Simulation Scenarios for Self-Driving via Neural Rendering,"Yasasa Abeysirigoonawardena, Kevin Xie, Chuhan Chen, Salar Hosseini, Ruiting Chen, Ruiqi Wang, Florian Shkurti",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15770"" target=""_blank"">2309.15770</a>",,2024-12-11
Automatic Feature Fairness in Recommendation via Adversaries,"Hengchang Hu, Yiming Cao, Zhankui He, Samson Tan, Min-Yen Kan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15418"" target=""_blank"">2309.15418</a>",,2024-12-11
Efficient Biologically Plausible Adversarial Training,"Matilde Tristany Farinha, Thomas Ortner, Giorgia Dellaferrera, Benjamin Grewe, Angeliki Pantazi",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.17348"" target=""_blank"">2309.17348</a>",,2024-12-11
Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks,"Vaidehi Patil, Peter Hase, Mohit Bansal",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.17410"" target=""_blank"">2309.17410</a>",,2024-12-11
On Continuity of Robust and Accurate Classifiers,"Ramin Barati, Reza Safabakhsh, Mohammad Rahmati",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.17048"" target=""_blank"">2309.17048</a>",,2024-12-11
Adversarial Machine Learning in Latent Representations of Neural Networks,"Milin Zhang, Mohammad Abdi, Francesco Restuccia",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.17401"" target=""_blank"">2309.17401</a>",,2024-12-11
What Matters to Enhance Traffic Rule Compliance of Imitation Learning for Automated Driving,"Hongkuan Zhou, Aifen Sui, Wei Cao, Zhenshan Bing",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07808"" target=""_blank"">2309.07808</a>","<a href=""https://hk-zh.github.io/p-csg-plus"" target=""_blank"">hk-zh.github.io</a>",2024-12-11
Distributed Resilient Control of DC Microgrids Under Generally Unbounded FDI Attacks,"Yichao Wang, Mohamadamin Rajabinezhad, Omar A. Beg, Shan Zuo",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.17301"" target=""_blank"">2309.17301</a>",,2024-12-11
Investigating Human-Identifiable Features Hidden in Adversarial Perturbations,"Dennis Y. Menn, Tzu-hsun Feng, Sriram Vishwanath, Hung-yi Lee",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16878"" target=""_blank"">2309.16878</a>",,2024-12-11
Parameter-Saving Adversarial Training: Reinforcing Multi-Perturbation Robustness via Hypernetworks,"Huihui Gong, Minjing Dong, Siqi Ma, Seyit Camtepe, Surya Nepal, Chang Xu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16207"" target=""_blank"">2309.16207</a>",,2024-12-11
Towards Poisoning Fair Representations,"Tianci Liu, Haoyu Wang, Feijie Wu, Hengtong Zhang, Pan Li, Lu Su, Jing Gao",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16487"" target=""_blank"">2309.16487</a>",,2024-12-11
On the Trade-offs between Adversarial Robustness and Actionable Explanations,"Satyapriya Krishna, Chirag Agarwal, Himabindu Lakkaraju",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16452"" target=""_blank"">2309.16452</a>",,2024-12-11
The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing,"Blaise Delattre, Alexandre Araujo, Quentin BarthÃ©lemy, Alexandre Allauzen",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16883"" target=""_blank"">2309.16883</a>",,2024-12-11
Post-Training Overfitting Mitigation in DNN Classifiers,"Hang Wang, David J. Miller, George Kesidis",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16827"" target=""_blank"">2309.16827</a>",,2024-12-11
Leveraging Optimization for Adaptive Attacks on Image Watermarks,"Nils Lukas, Abdulrahman Diaa, Lucas Fenaux, Florian Kerschbaum",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16952"" target=""_blank"">2309.16952</a>",,2024-12-11
Random and Safe Cache Architecture to Defeat Cache Timing Attacks,"Guangyuan Hu, Ruby B. Lee",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16172"" target=""_blank"">2309.16172</a>",,2024-12-11
Robust Offline Reinforcement Learning -- Certify the Confidence Interval,"Jiarui Yao, Simon Shaolei Du",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16631"" target=""_blank"">2309.16631</a>",,2024-12-11
A Primer on Bayesian Neural Networks: Review and Debates,"Julyan Arbel, Konstantinos Pitas, Mariia Vladimirova, Vincent Fortuin",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16314"" target=""_blank"">2309.16314</a>",,2024-12-11
On the Computational Entanglement of Distant Features in Adversarial Machine Learning,"YenLung Lai, Xingbo Dong, Zhe Jin",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15669"" target=""_blank"">2309.15669</a>",,2024-12-11
Adversarial Examples Might be Avoidable: The Role of Data Concentration in Adversarial Robustness,"Ambar Pal, Jeremias Sulam, RenÃ© Vidal",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16096"" target=""_blank"">2309.16096</a>",,2024-12-11
Defending Against Physical Adversarial Patch Attacks on Infrared Human Detection,"Lukas Strack, Futa Waseda, Huy H. Nguyen, Yinqiang Zheng, Isao Echizen",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15519"" target=""_blank"">2309.15519</a>",,2024-12-11
Privacy Assessment on Reconstructed Images: Are Existing Evaluation Metrics Faithful to Human Perception? (5%),"Xiaoxiao Sun, Nidham Gazagnadou, Vivek Sharma, Lingjuan Lyu, Hongdong Li, Liang Zheng",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13038"" target=""_blank"">2309.13038</a>",,2024-12-11
Toward Robust Recommendation via Real-time Vicinal Defense,"Yichang Xu, Chenwang Wu, Defu Lian",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.17278"" target=""_blank"">2309.17278</a>",,2024-12-11
On Data Fabrication in Collaborative Vehicular Perception: Attacks and Countermeasures,"Qingzhao Zhang, Shuowei Jin, Ruiyang Zhu, Jiachen Sun, Xumiao Zhang, Qi Alfred Chen, Z. Morley Mao",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.12955"" target=""_blank"">2309.12955</a>",,2024-12-11
Stealthy Physical Masked Face Recognition Attack via Adversarial Style Optimization,"Huihui Gong, Minjing Dong, Siqi Ma, Seyit Camtepe, Surya Nepal, Chang Xu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.09480"" target=""_blank"">2309.09480</a>",,2024-12-11
Efficient Low-Rank GNN Defense Against Structural Attacks,"Abdullah Alchihabi, Qing En, Yuhong Guo",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10136"" target=""_blank"">2309.10136</a>",,2024-12-11
Evaluating Adversarial Robustness with Expected Viable Performance,"Ryan McCoppin, Colin Dawson, Sean M. Kennedy, Leslie M. Blaha",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.09928"" target=""_blank"">2309.09928</a>",,2024-12-11
Dual Student Networks for Data-Free Model Stealing,"James Beetham, Navid Kardan, Ajmal Mian, Mubarak Shah",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10058"" target=""_blank"">2309.10058</a>",,2024-12-11
Securing Fixed Neural Network Steganography,"Zicong Luo, Sheng Li, Guobiao Li, Zhenxing Qian, Xinpeng Zhang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.09700"" target=""_blank"">2309.09700</a>",,2024-12-11
GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts,"Jiahao Yu, Xingwei Lin, Zheng Yu, Xinyu Xing",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10253"" target=""_blank"">2309.10253</a>",,2024-12-11
Spoofing attack augmentation: can differently-trained attack models improve generalisation? (3%),"Wanying Ge, Xin Wang, Junichi Yamagishi, Massimiliano Todisco, Nicholas Evans",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.09586"" target=""_blank"">2309.09586</a>",,2024-12-11
Reducing Adversarial Training Cost with Gradient Approximation,"Huihui Gong, Shuo Yang, Siqi Ma, Seyit Camtepe, Surya Nepal, Chang Xu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.09464"" target=""_blank"">2309.09464</a>",,2024-12-11
Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM,"Bochuan Cao, Yuanpu Cao, Lu Lin, Jinghui Chen",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.14348"" target=""_blank"">2309.14348</a>",,2024-12-11
Context-aware Adversarial Attack on Named Entity Recognition,"Shuguang Chen, Leonardo Neves, Thamar Solorio",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08999"" target=""_blank"">2309.08999</a>",,2024-12-11
Inverse classification with logistic and softmax classifiers: efficient optimization,"Miguel Ã. Carreira-PerpiÃ±Ã¡n, Suryabhan Singh Hada",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08945"" target=""_blank"">2309.08945</a>",,2024-12-11
Robust Backdoor Attacks on Object Detection in Real World,"Yaguan Qian, Boyuan Ji, Shuke He, Shenhui Huang, Xiang Ling, Bin Wang, Wei Wang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08953"" target=""_blank"">2309.08953</a>",,2024-12-11
Conditional Mutual Information Constrained Deep Learning for Classification,"En-Hui Yang, Shayan Mohajer Hamidi, Linfeng Ye, Renhao Tan, Beverly Yang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.09123"" target=""_blank"">2309.09123</a>",,2024-12-11
Adversarial Attacks on Tables with Entity Swap,"Aneta Koleva, Martin Ringsquandl, Volker Tresp",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08650"" target=""_blank"">2309.08650</a>",,2024-12-11
HINT: Healthy Influential-Noise based Training to Defend against Data Poisoning Attacks,"Minh-Hao Van, Alycia N. Carey, Xintao Wu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08549"" target=""_blank"">2309.08549</a>",,2024-12-11
"A Duty to Forget, a Right to be Assured? Exposing Vulnerabilities in Machine Unlearning Services","Hongsheng Hu, Shuo Wang, Jiamin Chang, Haonan Zhong, Ruoxi Sun, Shuang Hao, Haojin Zhu, Minhui Xue",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08230"" target=""_blank"">2309.08230</a>",,2024-12-11
SLMIA-SR: Speaker-Level Membership Inference Attacks against Speaker Recognition Systems,"Guangke Chen, Yedi Zhang, Fu Song",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07983"" target=""_blank"">2309.07983</a>",,2024-12-11
Distributionally Robust Post-hoc Classifiers under Prior Shifts,"Jiaheng Wei, Harikrishna Narasimhan, Ehsan Amid, Wen-Sheng Chu, Yang Liu, Abhishek Kumar",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08825"" target=""_blank"">2309.08825</a>","<a href=""https://github.com/weijiaheng/Drops"" target=""_blank"">weijiaheng</a>",2024-12-11
Unleashing the Adversarial Facet of Software Debloating,"Do-Men Su, Mohannad Alhanahnah",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08058"" target=""_blank"">2309.08058</a>",,2024-12-11
Improving Machine Learning Robustness via Adversarial Training,"Long Dang, Thushari Hapuarachchi, Kaiqi Xiong, Jing Lin",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.12593"" target=""_blank"">2309.12593</a>",,2024-12-11
Transferable Adversarial Attack on Image Tampering Localization,"Yuqi Wang, Gang Cao, Zijie Lou, Haochen Zhu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10243"" target=""_blank"">2309.10243</a>",,2024-12-11
Frame-to-Utterance Convergence: A Spectra-Temporal Approach for Unified Spoofing Detection,"Awais Khan, Khalid Mahmood Malik, Shah Nawaz",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.09837"" target=""_blank"">2309.09837</a>",,2024-12-11
It's Simplex! Disaggregating Measures to Improve Certified Robustness,"Andrew C. Cullen, Paul Montague, Shijie Liu, Sarah M. Erfani, Benjamin I. P. Rubinstein",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11005"" target=""_blank"">2309.11005</a>",,2024-12-11
Fed-LSAE: Thwarting Poisoning Attacks against Federated Cyber Threat Detection System via Autoencoder-based Latent Space Inspection,"Tran Duc Luong, Vuong Minh Tien, Nguyen Huu Quyen, Do Thi Thu Hien, Phan The Duy, Van-Hau Pham",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11053"" target=""_blank"">2309.11053</a>",,2024-12-11
Goal-Oriented Prompt Attack and Safety Evaluation for LLMs,"Chengyuan Liu, Fubang Zhao, Lizhi Qing, Yangyang Kang, Changlong Sun, Kun Kuang, Fei Wu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11830"" target=""_blank"">2309.11830</a>","<a href=""https://github.com/liuchengyuan123/CPAD"" target=""_blank"">liuchengyuan123</a>",2024-12-11
"HANS, are you clever? Clever Hans Effect Analysis of Neural Systems","Leonardo Ranaldi, Fabio Massimo Zanzotto",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.12481"" target=""_blank"">2309.12481</a>",,2024-12-11
On the Relationship between Skill Neurons and Robustness in Prompt Tuning,"Leon Ackermann, Xenia Ohmer",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.12263"" target=""_blank"">2309.12263</a>",,2024-12-11
DeepTheft: Stealing DNN Model Architectures through Power Side Channel,"Yansong Gao, Huming Qiu, Zhi Zhang, Binghui Wang, Hua Ma, Alsharif Abuadbba, Minhui Xue, Anmin Fu, Surya Nepal",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11894"" target=""_blank"">2309.11894</a>",,2024-12-11
SPFL: A Self-purified Federated Learning Method Against Poisoning Attacks,"Zizhen Liu, Weiyang He, Chip-Hong Chang, Jing Ye, Huawei Li, Xiaowei Li",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10607"" target=""_blank"">2309.10607</a>",,2024-12-11
PRAT: PRofiling Adversarial aTtacks,"Rahul Ambati, Naveed Akhtar, Ajmal Mian, Yogesh Singh Rawat",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11111"" target=""_blank"">2309.11111</a>",,2024-12-11
When to Trust AI: Advances and Challenges for Certification of Neural Networks,"Marta Kwiatkowska, Xiyue Zhang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11196"" target=""_blank"">2309.11196</a>",,2024-12-11
"AudioFool: Fast, Universal and synchronization-free Cross-Domain Attack on Speech Recognition","Mohamad Fakih, Rouwaida Kanj, Fadi Kurdahi, Mohammed E. Fouda",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11462"" target=""_blank"">2309.11462</a>",,2024-12-11
Understanding Pose and Appearance Disentanglement in 3D Human Pose Estimation,"Krishna Kanth Nakka, Mathieu Salzmann",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11667"" target=""_blank"">2309.11667</a>",,2024-12-11
How Robust is Google's Bard to Adversarial Image Attacks? (99%),"Yinpeng Dong, Huanran Chen, Jiawei Chen, Zhengwei Fang, Xiao Yang, Yichi Zhang, Yu Tian, Hang Su, Jun Zhu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11751"" target=""_blank"">2309.11751</a>","<a href=""https://github.com/thu-ml/Attack-Bard"" target=""_blank"">thu-ml</a>",2024-12-11
Compilation as a Defense: Enhancing DL Model Attack Robustness via Tensor Optimization,"Stefan Trawicki, William Hackett, Lewis Birch, Neeraj Suri, Peter Garraghan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16577"" target=""_blank"">2309.16577</a>",,2024-12-11
Robin: A Novel Method to Produce Robust Interpreters for Deep Learning-Based Code Classifiers,"Zhen Li, Ruqian Zhang, Deqing Zou, Ning Wang, Yating Li, Shouhuai Xu, Chen Chen, Hai Jin",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10644"" target=""_blank"">2309.10644</a>",,2024-12-11
Language Guided Adversarial Purification,"Himanshu Singh, A V Subramanyam",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10348"" target=""_blank"">2309.10348</a>",,2024-12-11
What Learned Representations and Influence Functions Can Tell Us About Adversarial Examples,"Shakila Mahjabin Tonni, Mark Dras",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10916"" target=""_blank"">2309.10916</a>",,2024-12-11
Adversarial Attacks Against Uncertainty Quantification,"Emanuele Ledda, Daniele Angioni, Giorgio Piras, Giorgio Fumera, Battista Biggio, Fabio Roli",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10586"" target=""_blank"">2309.10586</a>",,2024-12-11
Generalized Face Forgery Detection via Adaptive Learning for Pre-trained Vision Transformer,"Anwei Luo, Rizhao Cai, Chenqi Kong, Yakun Ju, Xiangui Kang, Jiwu Huang, Alex C. Kot",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11092"" target=""_blank"">2309.11092</a>","<a href=""https://github.com/LoveSiameseCat/FAViT"" target=""_blank"">LoveSiameseCat</a>",2024-12-11
Information Leakage from Data Updates in Machine Learning Models,"Tian Hui, Farhad Farokhi, Olga Ohrimenko",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11022"" target=""_blank"">2309.11022</a>",,2024-12-11
Model Leeching: An Extraction Attack Targeting LLMs,"Lewis Birch, William Hackett, Stefan Trawicki, Neeraj Suri, Peter Garraghan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10544"" target=""_blank"">2309.10544</a>",,2024-12-11
Adversarial Deep Reinforcement Learning for Cyber Security in Software Defined Networks,"Luke Borchjes, Clement Nyirenda, Louise Leenen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04909"" target=""_blank"">2308.04909</a>",,2024-12-11
Symmetry Defense Against XGBoost Adversarial Perturbation Attacks,Blerta Lindqvist,arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05575"" target=""_blank"">2308.05575</a>",,2024-12-11
Complex Network Effects on the Robustness of Graph Convolutional Networks,"Benjamin A. Miller, Kevin Chan, Tina Eliassi-Rad",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05498"" target=""_blank"">2308.05498</a>",,2024-12-11
"Critical Points ++: An Agile Point Cloud Importance Measure for Robust Classification, Adversarial Defense and Explainable AI","Meir Yossef Levi, Guy Gilboa",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05525"" target=""_blank"">2308.05525</a>",,2024-12-11
FLShield: A Validation Based Federated Learning Framework to Defend Against Poisoning Attacks,"Ehsanul Kabir, Zeyu Song, Md Rafi Ur Rashid, Shagufta Mehnaz",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05832"" target=""_blank"">2308.05832</a>",,2024-12-11
Comprehensive Analysis of Network Robustness Evaluation Based on Convolutional Neural Networks with Spatial Pyramid Pooling,"Wenjun Jiang, Tianlong Fan, Changhao Li, Chuanfu Zhang, Tao Zhang, Zong-fu Luo",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08012"" target=""_blank"">2308.08012</a>",,2024-12-11
Adv-Inpainting: Generating Natural and Transferable Adversarial Patch via Attention-guided Feature Fusion,"Yanjie Li, Mingxing Duan, Bin Xiao",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05320"" target=""_blank"">2308.05320</a>",,2024-12-11
Adversarial ModSecurity: Countering Adversarial SQL Injections with Robust Machine Learning,"Biagio Montaruli, Luca Demetrio, Andrea Valenza, Battista Biggio, Luca Compagna, Davide Balzarotti, Davide Ariu, Luca Piras",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04964"" target=""_blank"">2308.04964</a>",,2024-12-11
Pelta: Shielding Transformers to Mitigate Evasion Attacks in Federated Learning,"Simon Queyrut, YÃ©rom-David Bromberg, Valerio Schiavoni",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04373"" target=""_blank"">2308.04373</a>",,2024-12-11
Data-Free Model Extraction Attacks in the Context of Object Detection,"Harshit Shah, Aravindhan G, Pavan Kulkarni, Yuvaraj Govidarajulu, Manojkumar Parmar",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05127"" target=""_blank"">2308.05127</a>",,2024-12-11
Federated Zeroth-Order Optimization using Trajectory-Informed Surrogate Gradients,"Yao Shu, Xiaoqiang Lin, Zhongxiang Dai, Bryan Kian Hsiang Low",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04077"" target=""_blank"">2308.04077</a>",,2024-12-11
The Model Inversion Eavesdropping Attack in Semantic Communication Systems,"Yuhao Chen, Qianqian Yang, Zhiguo Shi, Jiming Chen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04304"" target=""_blank"">2308.04304</a>",,2024-12-11
Comprehensive Assessment of the Performance of Deep Learning Classifiers Reveals a Surprising Lack of Robustness,Michael W. Spratling,arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04137"" target=""_blank"">2308.04137</a>",,2024-12-11
XGBD: Explanation-Guided Graph Backdoor Detection,"Zihan Guan, Mengnan Du, Ninghao Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04406"" target=""_blank"">2308.04406</a>","<a href=""https://github.com/GuanZihan/GNN_backdoor_detection"" target=""_blank"">GuanZihan</a>",2024-12-11
Fast and Accurate Transferability Measurement by Evaluating Intra-class Feature Variance,"Huiwen Xu, U Kang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05986"" target=""_blank"">2308.05986</a>",,2024-12-11
Improved Activation Clipping for Universal Backdoor Mitigation and Test-Time Detection,"Hang Wang, Zhen Xiang, David J. Miller, George Kesidis",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04617"" target=""_blank"">2308.04617</a>",,2024-12-11
Evil Operation: Breaking Speaker Recognition with PaddingBack,"Zhe Ye, Diqun Yan, Li Dong, Kailai Shen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04179"" target=""_blank"">2308.04179</a>","<a href=""https://nbufabio25.github.io/paddingback/"" target=""_blank"">paddingback</a>",2024-12-11
Backdoor Federated Learning by Poisoning Backdoor-Critical Layers,"Haomin Zhuang, Mingxian Yu, Hao Wang, Yang Hua, Jian Li, Xu Yuan",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04466"" target=""_blank"">2308.04466</a>",,2024-12-11
Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient,"Zhengzhi Lu, He Wang, Ziyi Chang, Guoan Yang, Hubert P. H. Shum",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05681"" target=""_blank"">2308.05681</a>",,2024-12-11
Enhancing the Antidote: Improved Pointwise Certifications against Poisoning Attacks,"Shijie Liu, Andrew C. Cullen, Paul Montague, Sarah M. Erfani, Benjamin I. P. Rubinstein",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07553"" target=""_blank"">2308.07553</a>",,2024-12-11
Continual Face Forgery Detection via Historical Distribution Preserving,"Ke Sun, Shen Chen, Taiping Yao, Xiaoshuai Sun, Shouhong Ding, Rongrong Ji",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06217"" target=""_blank"">2308.06217</a>",,2024-12-11
Understanding the robustness difference between stochastic gradient descent and adaptive gradient methods,"Avery Ma, Yangchen Pan, Amir-massoud Farahmand",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06703"" target=""_blank"">2308.06703</a>",,2024-12-11
3DHacker: Spectrum-based Decision Boundary Generation for Hard-label 3D Point Cloud Attack,"Yunbo Tao, Daizong Liu, Pan Zhou, Yulai Xie, Wei Du, Wei Hu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07546"" target=""_blank"">2308.07546</a>",,2024-12-11
White-Box Adversarial Attacks on Deep Learning-Based Radio Frequency Fingerprint Identification,"Jie Ma, Junqing Zhang, Guanxiong Shen, Alan Marshall, Chip-Hong Chang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07433"" target=""_blank"">2308.07433</a>",,2024-12-11
AdvCLIP: Downstream-agnostic Adversarial Examples in Multimodal Contrastive Learning,"Ziqi Zhou, Shengshan Hu, Minghui Li, Hangtao Zhang, Yechao Zhang, Hai Jin",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07026"" target=""_blank"">2308.07026</a>",,2024-12-11
"LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked","Alec Helbling, Mansi Phute, Matthew Hull, Duen Horng Chau",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07308"" target=""_blank"">2308.07308</a>",,2024-12-11
DISBELIEVE: Distance Between Client Models is Very Essential for Effective Local Model Poisoning Attacks,"Indu Joshi, Priyank Upadhya, Gaurav Kumar Nayak, Peter SchÃ¼ffler, Nassir Navab",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07387"" target=""_blank"">2308.07387</a>",,2024-12-11
ACTIVE: Towards Highly Transferable 3D Physical Camouflage for Universal and Robust Vehicle Evasion,"Naufal Suryanto, Yongsu Kim, Harashta Tatimma Larasati, Hyoeun Kang, Thi-Thu-Huong Le, Yoonyoung Hong, Hunmin Yang, Se-Yoon Oh, Howon Kim",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07009"" target=""_blank"">2308.07009</a>",,2024-12-11
"SAM Meets Robotic Surgery: An Empirical Study on Generalization, Robustness and Adaptation","An Wang, Mobarakol Islam, Mengya Xu, Yang Zhang, Hongliang Ren",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07156"" target=""_blank"">2308.07156</a>",,2024-12-11
SoK: Realistic Adversarial Attacks and Defenses for Intelligent Network Intrusion Detection,"JoÃ£o Vitorino, Isabel PraÃ§a, Eva Maia",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06819"" target=""_blank"">2308.06819</a>",,2024-12-11
"A Survey on Deep Neural Network Pruning-Taxonomy, Comparison, Analysis, and Recommendations","Hongrong Cheng, Miao Zhang, Javen Qinfeng Shi",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06767"" target=""_blank"">2308.06767</a>","<a href=""https://github.com/hrcheng1066/awesome-pruning"" target=""_blank"">hrcheng1066</a>",2024-12-11
Test-Time Backdoor Defense via Detecting and Repairing,"Jiyang Guan, Jian Liang, Ran He",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06107"" target=""_blank"">2308.06107</a>",,2024-12-11
Robustified ANNs Reveal Wormholes Between Human Category Percepts,"Guy Gaziv, Michael J. Lee, James J. DiCarlo",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06887"" target=""_blank"">2308.06887</a>",,2024-12-11
Faithful to Whom? Questioning Interpretability Measures in NLP,"Evan Crothers, Herna Viktor, Nathalie Japkowicz",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06795"" target=""_blank"">2308.06795</a>",,2024-12-11
Not So Robust After All: Evaluating the Robustness of Deep Neural Networks to Unseen Adversarial Attacks,"Roman Garaev, Bader Rasheed, Adil Khan",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06467"" target=""_blank"">2308.06467</a>",,2024-12-11
One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training,"Jianshuo Dong, Han Qiu, Yiming Li, Tianwei Zhang, Yuanjie Li, Zeqi Lai, Chao Zhang, Shu-Tao Xia",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07934"" target=""_blank"">2308.07934</a>","<a href=""https://github.com/jianshuod/TBA"" target=""_blank"">jianshuod</a>",2024-12-11
Enhancing Generalization of Universal Adversarial Perturbation through Gradient Aggregation,"Xuannan Liu, Yaoyao Zhong, Yuhang Zhang, Lixiong Qin, Weihong Deng",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06015"" target=""_blank"">2308.06015</a>","<a href=""https://github.com/liuxuannan/Stochastic-Gradient-Aggregation"" target=""_blank"">liuxuannan</a>",2024-12-11
"Physical Adversarial Attacks For Camera-based Smart Systems: Current Trends, Categorization, Applications, Research Challenges, and Future Outlook","Amira Guesmi, Muhammad Abdullah Hanif, Bassem Ouni, Muhammed Shafique",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06173"" target=""_blank"">2308.06173</a>",,2024-12-11
Face Encryption via Frequency-Restricted Identity-Agnostic Attacks,"Xin Dong, Rui Wang, Siyuan Liang, Aishan Liu, Lihua Jing",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05983"" target=""_blank"">2308.05983</a>","<a href=""https://github.com/XinDong10/FRIA"" target=""_blank"">XinDong10</a>",2024-12-11
White-box Membership Inference Attacks against Diffusion Models,"Yan Pang, Tianhao Wang, Xuhui Kang, Mengdi Huai, Yang Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06405"" target=""_blank"">2308.06405</a>",,2024-12-11
Fixed Inter-Neuron Covariability Induces Adversarial Robustness,"Muhammad Ahmed Shah, Bhiksha Raj",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03956"" target=""_blank"">2308.03956</a>",,2024-12-11
Universal Defensive Underpainting Patch: Making Your Text Invisible to Optical Character Recognition,"JiaCheng Deng, Li Dong, Jiahao Chen, Diqun Yan, Rangding Wang, Dengpan Ye, Lingchen Zhao, Jinyu Tian",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02369"" target=""_blank"">2308.02369</a>","<a href=""https://github.com/QRICKDD/UDUP"" target=""_blank"">QRICKDD</a>",2024-12-11
PAIF: Perception-Aware Infrared-Visible Image Fusion for Attack-Tolerant Semantic Segmentation,"Zhu Liu, Jinyuan Liu, Benzhuang Zhang, Long Ma, Xin Fan, Risheng Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03979"" target=""_blank"">2308.03979</a>","<a href=""https://github.com/LiuZhu-CV/PAIF"" target=""_blank"">LiuZhu-CV</a>",2024-12-11
A reading survey on adversarial machine learning: Adversarial attacks and their understanding,Shashank Kotyan,arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03363"" target=""_blank"">2308.03363</a>",,2024-12-11
From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application? (4%),"Rodrigo Pedro, Daniel Castro, Paulo Carreira, Nuno Santos",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01990"" target=""_blank"">2308.01990</a>",,2024-12-11
Inaudible Adversarial Perturbation: Manipulating the Recognition of User Speech in Real Time,"Xinfeng Li, Chen Yan, Xuancun Lu, Zihan Zeng, Xiaoyu Ji, Wenyuan Xu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01040"" target=""_blank"">2308.01040</a>",,2024-12-11
Isolation and Induction: Training Robust Deep Neural Networks against Model Stealing Attacks,"Jun Guo, Aishan Liu, Xingyu Zheng, Siyuan Liang, Yisong Xiao, Yichao Wu, Xianglong Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00958"" target=""_blank"">2308.00958</a>","<a href=""https://github.com/DIG-Beihang/InI-Model-Stealing-Defense"" target=""_blank"">DIG-Beihang</a>",2024-12-11
Mercury: An Automated Remote Side-channel Attack to Nvidia Deep Learning Accelerator,"Xiaobei Yan, Xiaoxuan Lou, Guowen Xu, Han Qiu, Shangwei Guo, Chip Hong Chang, Tianwei Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01193"" target=""_blank"">2308.01193</a>",,2024-12-11
TEASMA: A Practical Approach for the Test Assessment of Deep Neural Networks using Mutation Analysis,"Amin Abbasishahkoo, Mahboubeh Dadkhah, Lionel Briand, Dayi Lin",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01311"" target=""_blank"">2308.01311</a>",,2024-12-11
LSF-IDM: Automotive Intrusion Detection Model with Lightweight Attribution and Semantic Fusion,"Pengzhou Cheng, Lei Hua, Haobin Jiang, Mohammad Samie, Gongshen Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01237"" target=""_blank"">2308.01237</a>",,2024-12-11
Dynamic ensemble selection based on Deep Neural Network Uncertainty Estimation for Adversarial Robustness,"Ruoxi Qin, Linyuan Wang, Xuehui Du, Xingyuan Chen, Bin Yan",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00346"" target=""_blank"">2308.00346</a>",,2024-12-11
Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning,"Kaijie Zhu, Jindong Wang, Xixu Hu, Xing Xie, Ge Yang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02533"" target=""_blank"">2308.02533</a>","<a href=""https://github.com/microsoft/robustlearn"" target=""_blank"">microsoft</a>",2024-12-11
LimeAttack: Local Explainable Method for Textual Hard-Label Adversarial Attack,"Hai Zhu, Zhaoqing Yang, Weiwei Shang, Yuren Wu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00319"" target=""_blank"">2308.00319</a>",,2024-12-11
Doubly Robust Instance-Reweighted Adversarial Training,"Daouda Sow, Sen Lin, Zhangyang Wang, Yingbin Liang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00311"" target=""_blank"">2308.00311</a>",,2024-12-11
Training on Foveated Images Improves Robustness to Adversarial Attacks,"Muhammad A. Shah, Bhiksha Raj",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00854"" target=""_blank"">2308.00854</a>",,2024-12-11
Kidnapping Deep Learning-based Multirotors using Optimized Flying Adversarial Patches,"Pia Hanfeld, Khaled Wahba, Marina M. -C. HÃ¶hne, Michael Bussmann, Wolfgang HÃ¶nig",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00344"" target=""_blank"">2308.00344</a>",,2024-12-11
Robust Linear Regression: Phase-Transitions and Precise Tradeoffs for General Norms,"Elvis Dohmatob, Meyer Scetbon",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00556"" target=""_blank"">2308.00556</a>",,2024-12-11
Learning to Generate Training Datasets for Robust Semantic Segmentation,"Marwane Hariat, Olivier Laurent, RÃ©mi Kazmierczak, Shihao Zhang, Andrei Bursuc, Angela Yao, Gianni Franchi",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02535"" target=""_blank"">2308.02535</a>","<a href=""https://github.com/ENSTA-U2IS-AI/robusta"" target=""_blank"">ENSTA-U2IS-AI</a>",2024-12-11
Zero-Shot Learning by Harnessing Adversarial Samples,"Zhi Chen, Pengfei Zhang, Jingjing Li, Sen Wang, Zi Huang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00313"" target=""_blank"">2308.00313</a>","<a href=""https://github.com/uqzhichen/HASZSL"" target=""_blank"">uqzhichen</a>",2024-12-11
A Novel Cross-Perturbation for Single Domain Generalization,"Dongjia Zhao, Lei Qi, Xiao Shi, Yinghuan Shi, Xin Geng",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00918"" target=""_blank"">2308.00918</a>",,2024-12-11
A Novel Deep Learning based Model to Defend Network Intrusion Detection System against Adversarial Attacks,"Khushnaseeb Roshan, Aasim Zafar, Shiekh Burhan Ul Haque",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00077"" target=""_blank"">2308.00077</a>",,2024-12-11
Adversarially Robust Neural Legal Judgement Systems,"Rohit Raj, V Susheela Devi",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00165"" target=""_blank"">2308.00165</a>",,2024-12-11
Robustness Over Time: Understanding Adversarial Examples' Effectiveness on Longitudinal Versions of Large Language Models,"Yugeng Liu, Tianshuo Cong, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07847"" target=""_blank"">2308.07847</a>",,2024-12-11
ParaFuzz: An Interpretability-Driven Technique for Detecting Poisoned Samples in NLP,"Lu Yan, Zhuo Zhang, Guanhong Tao, Kaiyuan Zhang, Xuan Chen, Guangyu Shen, Xiangyu Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02122"" target=""_blank"">2308.02122</a>",,2024-12-11
FROD: Robust Object Detection for Free,"Muhammad, Awais, Weiming, Zhuang, Lingjuan, Lyu, Sung-Ho, Bae",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01888"" target=""_blank"">2308.01888</a>",,2024-12-11
AdvFAS: A robust face anti-spoofing framework against adversarial examples,"Jiawei Chen, Xiao Yang, Heng Yin, Mingzhi Ma, Bihui Chen, Jianteng Peng, Yandong Guo, Zhaoxia Yin, Hang Su",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02116"" target=""_blank"">2308.02116</a>",,2024-12-11
An Adaptive Model Ensemble Adversarial Attack for Boosting Adversarial Transferability,"Bin Chen, Jia-Li Yin, Shukai Chen, Bo-Hao Chen, Ximeng Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02897"" target=""_blank"">2308.02897</a>",,2024-12-11
A Four-Pronged Defense Against Byzantine Attacks in Federated Learning,"Wei Wan, Shengshan Hu, Minghui Li, Jianrong Lu, Longling Zhang, Leo Yu Zhang, Hai Jin",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03331"" target=""_blank"">2308.03331</a>",,2024-12-11
Improving Performance of Semi-Supervised Learning by Adversarial Attacks,"Dongyoon Yang, Kunwoong Kim, Yongdai Kim",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04018"" target=""_blank"">2308.04018</a>",,2024-12-11
Mondrian: Prompt Abstraction Attack Against Large Language Models for Cheaper API Pricing,"Wai Man Si, Michael Backes, Yang Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03558"" target=""_blank"">2308.03558</a>",,2024-12-11
SAAM: Stealthy Adversarial Attack on Monoculor Depth Estimation,"Amira Guesmi, Muhammad Abdullah Hanif, Bassem Ouni, Muhammad Shafique",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03108"" target=""_blank"">2308.03108</a>",,2024-12-11
CGBA: Curvature-aware Geometric Black-box Attack,"Md Farhamdur Reza, Ali Rahmati, Tianfu Wu, Huaiyu Dai",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03163"" target=""_blank"">2308.03163</a>","<a href=""https://github.com/Farhamdur/CGBA"" target=""_blank"">Farhamdur</a>",2024-12-11
APBench: A Unified Benchmark for Availability Poisoning Attacks and Defenses,"Tianrui Qin, Xitong Gao, Juanjuan Zhao, Kejiang Ye, Cheng-Zhong Xu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03258"" target=""_blank"">2308.03258</a>","<a href=""https://github.com/lafeat/apbench"" target=""_blank"">lafeat</a>",2024-12-11
Unsupervised Adversarial Detection without Extra Model: Training Loss Should Change,"Chien Cheng Chyou, Hung-Ting Su, Winston H. Hsu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03243"" target=""_blank"">2308.03243</a>",,2024-12-11
Using Overlapping Methods to Counter Adversaries in Community Detection,"Benjamin A. Miller, Kevin Chan, Tina Eliassi-Rad",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03081"" target=""_blank"">2308.03081</a>",,2024-12-11
An AI-Enabled Framework to Defend Ingenious MDT-based Attacks on the Emerging Zero Touch Cellular Networks,"Aneeqa Ijaz, Waseem Raza, Hasan Farooq, Marvin Manalastas, Ali Imran",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02923"" target=""_blank"">2308.02923</a>",,2024-12-11
URET: Universal Robustness Evaluation Toolkit (for Evasion),"Kevin Eykholt, Taesung Lee, Douglas Schales, Jiyong Jang, Ian Molloy, Masha Zorin",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01840"" target=""_blank"">2308.01840</a>",,2024-12-11
A Security and Usability Analysis of Local Attacks Against FIDO2,"Tarun Kumar Yadav, Kent Seamons",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02973"" target=""_blank"">2308.02973</a>",,2024-12-11
Approximating Positive Homogeneous Functions with Scale Invariant Neural Networks,"Stefan Bamberger, Reinhard Heckel, Felix Krahmer",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02836"" target=""_blank"">2308.02836</a>",,2024-12-11
Multi-attacks: Many images $+$ the same adversarial attack $\to$ many target labels,Stanislav Fort,arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03792"" target=""_blank"">2308.03792</a>",,2024-12-11
RobustMQ: Benchmarking Robustness of Quantized Models,"Yisong Xiao, Aishan Liu, Tianyuan Zhang, Haotong Qin, Jinyang Guo, Xianglong Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02350"" target=""_blank"">2308.02350</a>",,2024-12-11
SureFED: Robust Federated Learning via Uncertainty-Aware Inward and Outward Inspection,"Nasimeh Heydaribeni, Ruisi Zhang, Tara Javidi, Cristina Nita-Rotaru, Farinaz Koushanfar",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02747"" target=""_blank"">2308.02747</a>",,2024-12-11
Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning Attacks,"Domenico Cotroneo, Cristina Improta, Pietro Liguori, Roberto Natella",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04451"" target=""_blank"">2308.04451</a>",,2024-12-11
BlindSage: Label Inference Attacks against Node-level Vertical Federated Graph Neural Networks,"Marco Arazzi, Mauro Conti, Stefanos Koffas, Marina Krcek, Antonino Nocera, Stjepan Picek, Jing Xu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02465"" target=""_blank"">2308.02465</a>",,2024-12-11
Hard Adversarial Example Mining for Improving Robust Fairness,"Chenhao Lin, Xiang Ji, Yulong Yang, Qian Li, Chao Shen, Run Wang, Liming Fang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01823"" target=""_blank"">2308.01823</a>",,2024-12-11
Simple and Efficient Partial Graph Adversarial Attack: A New Perspective,"Guanghui Zhu, Mengyu Chen, Chunfeng Yuan, Yihua Huang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07834"" target=""_blank"">2308.07834</a>",,2024-12-11
Exploring the Physical World Adversarial Robustness of Vehicle Detection,"Wei Jiang, Tianyuan Zhang, Shuangcheng Liu, Weiyu Ji, Zichao Zhang, Gang Xiao",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03476"" target=""_blank"">2308.03476</a>",,2024-12-11
A Review of Adversarial Attacks in Computer Vision,"Yutong Zhang, Yao Li, Yin Li, Zhichang Guo",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07673"" target=""_blank"">2308.07673</a>",,2024-12-11
Designing an attack-defense game: how to increase robustness of financial transaction models via a competition,"Alexey Zaytsev, Maria Kovaleva, Alex Natekin, Evgeni Vorsin, Valerii Smirnov, Georgii Smirnov, Oleg Sidorshin, Alexander Senin, Alexander Dudin, Dmitry Berestnev",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11406"" target=""_blank"">2308.11406</a>",,2024-12-11
FaceChain: A Playground for Human-centric Artificial Intelligence Generated Content,"Yang Liu, Cheng Yu, Lei Shang, Yongyi He, Ziheng Wu, Xingjun Wang, Chao Xu, Haoyu Xie, Weida Wang, Yuze Zhao, Lin Zhu, Chen Cheng, Weitao Chen, Yuan Yao, Wenmeng Zhou, Jiaqi Xu, Qiang Wang, Yingda Chen, Xuansong Xie, Baigui Sun",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14256"" target=""_blank"">2308.14256</a>","<a href=""https://github.com/modelscope/facechain"" target=""_blank"">modelscope</a>",2024-12-11
Exploring Transferability of Multimodal Adversarial Samples for Vision-Language Pre-training Models with Contrastive Learning,"Youze Wang, Wenbo Hu, Yinpeng Dong, Richang Hong",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12636"" target=""_blank"">2308.12636</a>",,2024-12-11
Don't Look into the Sun: Adversarial Solarization Attacks on Image Classifiers,"Paul Gavrikov, Janis Keuper",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12661"" target=""_blank"">2308.12661</a>","<a href=""https://github.com/paulgavrikov/adversarial_solarization"" target=""_blank"">paulgavrikov</a>",2024-12-11
Evaluating the Vulnerabilities in ML systems in terms of adversarial attacks,"John Harshith, Mantej Singh Gill, Madhan Jothimani",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12918"" target=""_blank"">2308.12918</a>",,2024-12-11
Fast Adversarial Training with Smooth Convergence,"Mengnan Zhao, Lihe Zhang, Yuqiu Kong, Baocai Yin",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12857"" target=""_blank"">2308.12857</a>","<a href=""https://github.com/FAT-CS/ConvergeSmooth"" target=""_blank"">FAT-CS</a>",2024-12-11
WavMark: Watermarking for Audio Generation,"Guangyu Chen, Yu Wu, Shujie Liu, Tao Liu, Xiaoyong Du, Furu Wei",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12770"" target=""_blank"">2308.12770</a>",,2024-12-11
Prediction without Preclusion: Recourse Verification with Reachable Sets,"Avni Kothari, Bogdan Kulynych, Tsui-Wei Weng, Berk Ustun",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12820"" target=""_blank"">2308.12820</a>",,2024-12-11
On-Manifold Projected Gradient Descent,"Aaron Mahler, Tyrus Berry, Tom Stephens, Harbir Antil, Michael Merritt, Jeanie Schreiber, Ioannis Kevrekidis",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12279"" target=""_blank"">2308.12279</a>",,2024-12-11
Sample Complexity of Robust Learning against Evasion Attacks,Pascale Gourdeau,arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12054"" target=""_blank"">2308.12054</a>",,2024-12-11
LCANets++: Robust Audio Classification using Multi-layer Neural Networks with Lateral Competition,"Sayanton V. Dibbo, Juston S. Moore, Garrett T. Kenyon, Michael A. Teti",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12882"" target=""_blank"">2308.12882</a>",,2024-12-11
BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection,"Tinghao Xie, Xiangyu Qi, Ping He, Yiming Li, Jiachen T. Wang, Prateek Mittal",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12439"" target=""_blank"">2308.12439</a>",,2024-12-11
RemovalNet: DNN Fingerprint Removal Attacks,"Hongwei Yao, Zheng Li, Kunzhe Huang, Jian Lou, Zhan Qin, Kui Ren",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12319"" target=""_blank"">2308.12319</a>","<a href=""https://github.com/grasses/RemovalNet"" target=""_blank"">grasses</a>",2024-12-11
Ensembling Uncertainty Measures to Improve Safety of Black-Box Classifiers,"Tommaso Zoppi, Andrea Ceccarelli, Andrea Bondavalli",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12065"" target=""_blank"">2308.12065</a>",,2024-12-11
Aparecium: Revealing Secrets from Physical Photographs,"Zhe Lei, Jie Zhang, Jingtao Li, Weiming Zhang, Nenghai Yu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12141"" target=""_blank"">2308.12141</a>",,2024-12-11
SEA: Shareable and Explainable Attribution for Query-based Black-box Attacks,"Yue Gao, Ilia Shumailov, Kassem Fawaz",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11845"" target=""_blank"">2308.11845</a>",,2024-12-11
Multi-Instance Adversarial Attack on GNN-Based Malicious Domain Detection,"Mahmoud Nazzal, Issa Khalil, Abdallah Khreishah, NhatHai Phan, Yao Ma",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11754"" target=""_blank"">2308.11754</a>",,2024-12-11
Does Physical Adversarial Example Really Matter to Autonomous Driving? Towards System-Level Effect of Adversarial Object Evasion Attack,"Ningfei Wang, Yunpeng Luo, Takami Sato, Kaidi Xu, Qi Alfred Chen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11894"" target=""_blank"">2308.11894</a>",,2024-12-11
Protect Federated Learning Against Backdoor Attacks via Data-Free Trigger Generation,"Yanxin Yang, Ming Hu, Yue Cao, Jun Xia, Yihao Huang, Yang Liu, Mingsong Chen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11333"" target=""_blank"">2308.11333</a>",,2024-12-11
Revisiting and Exploring Efficient Fast Adversarial Training via LAW: Lipschitz Regularization and Auto Weight Averaging,"Xiaojun Jia, Yuefeng Chen, Xiaofeng Mao, Ranjie Duan, Jindong Gu, Rong Zhang, Hui Xue, Xiaochun Cao",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11443"" target=""_blank"">2308.11443</a>",,2024-12-11
Are Existing Out-Of-Distribution Techniques Suitable for Network Intrusion Detection? (1%),"Andrea Corsini, Shanchieh Jay Yang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14376"" target=""_blank"">2308.14376</a>",,2024-12-11
Rep2wav: Noise Robust text-to-speech Using self-supervised representations,"Qiushi Zhu, Yu Gu, Rilin Chen, Chao Weng, Yuchen Hu, Lirong Dai, Jie Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14553"" target=""_blank"">2308.14553</a>","<a href=""https://zqs01.github.io/rep2wav"" target=""_blank"">zqs01.github.io</a>",2024-12-11
ReMAV: Reward Modeling of Autonomous Vehicles for Finding Likely Failure Events,"Aizaz Sharif, Dusica Marijan",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14550"" target=""_blank"">2308.14550</a>",,2024-12-11
A Classification-Guided Approach for Adversarial Attacks against Neural Machine Translation,"Sahar Sadrizadeh, Ljiljana Dolamic, Pascal Frossard",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15246"" target=""_blank"">2308.15246</a>",,2024-12-11
The Power of MEME: Adversarial Malware Creation with Model-Based Reinforcement Learning,"Maria Rigaki, Sebastian Garcia",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.16562"" target=""_blank"">2308.16562</a>",,2024-12-11
Backpropagation Path Search On Adversarial Transferability,"Zhuoer Xu, Zhangxuan Gu, Jianping Zhang, Shiwen Cui, Changhua Meng, Weiqiang Wang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07625"" target=""_blank"">2308.07625</a>",,2024-12-11
Fault Injection and Safe-Error Attack for Extraction of Embedded Neural Network Models,"Kevin Hector, Pierre-Alain Moellic, Mathieu Dumont, Jean-Max Dutertre",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.16703"" target=""_blank"">2308.16703</a>",,2024-12-11
Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack,"Sze Jue Yang, Quang Nguyen, Chee Seng Chan, Khoa D. Doan",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.16684"" target=""_blank"">2308.16684</a>",,2024-12-11
Robust Principles: Architectural Design Principles for Adversarially Robust CNNs,"ShengYun Peng, Weilin Xu, Cory Cornelius, Matthew Hull, Kevin Li, Rahul Duggal, Mansi Phute, Jason Martin, Duen Horng Chau",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.16258"" target=""_blank"">2308.16258</a>","<a href=""https://github.com/poloclub/robust-principles"" target=""_blank"">poloclub</a>",2024-12-11
Adaptive Attack Detection in Text Classification: Leveraging Space Exploration Features for Text Sentiment Classification,"Atefeh Mahdavi, Neda Keivandarian, Marco Carvalho",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15663"" target=""_blank"">2308.15663</a>",,2024-12-11
Advancing Adversarial Robustness Through Adversarial Logit Update,"Hao Xuan, Peican Zhu, Xingyu Li",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15072"" target=""_blank"">2308.15072</a>",,2024-12-11
Imperceptible Adversarial Attack on Deep Neural Networks from Image Boundary,"Fahad Alrasheedi, Xin Zhong",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15344"" target=""_blank"">2308.15344</a>",,2024-12-11
MDTD: A Multi Domain Trojan Detector for Deep Neural Networks,"Arezoo Rajabi, Surudhi Asokraj, Fengqing Jiang, Luyao Niu, Bhaskar Ramasubramanian, Jim Ritcey, Radha Poovendran",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15673"" target=""_blank"">2308.15673</a>",,2024-12-11
Identifying and Mitigating the Security Risks of Generative AI,"Clark Barrett, Brad Boyd, Elie Burzstein, Nicholas Carlini, Brad Chen, Jihye Choi, Amrita Roy Chowdhury, Mihai Christodorescu, Anupam Datta, Soheil Feizi, Kathleen Fisher, Tatsunori Hashimoto, Dan Hendrycks, Somesh Jha, Daniel Kang, Florian Kerschbaum, Eric Mitchell, John Mitchell, Zulfikar Ramzan, Khawaja Shams, Dawn Song, Ankur Taly, Diyi Yang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14840"" target=""_blank"">2308.14840</a>",,2024-12-11
3D Adversarial Augmentations for Robust Out-of-Domain Predictions,"Alexander Lehner, Stefano Gasperini, Alvaro Marcos-Ramiro, Michael Schmidt, Nassir Navab, Benjamin Busam, Federico Tombari",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15479"" target=""_blank"">2308.15479</a>",,2024-12-11
Everything Perturbed All at Once: Enabling Differentiable Graph Attacks,"Haoran Liu, Bokun Wang, Jianling Wang, Xiangjue Dong, Tianbao Yang, James Caverlee",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15614"" target=""_blank"">2308.15614</a>",,2024-12-11
Intriguing Properties of Diffusion Models: An Empirical Study of the Natural Attack Capability in Text-to-Image Generative Models,"Takami Sato, Justin Yue, Nanze Chen, Ningfei Wang, Qi Alfred Chen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15692"" target=""_blank"">2308.15692</a>",,2024-12-11
Vulnerability of Machine Learning Approaches Applied in IoT-based Smart Grid: A Review,"Zhenyong Zhang, Mengxiang Liu, Mingyang Sun, Ruilong Deng, Peng Cheng, Dusit Niyato, Mo-Yuen Chow, Jiming Chen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15736"" target=""_blank"">2308.15736</a>",,2024-12-11
Can We Rely on AI? (50%),Desmond J. Higham,arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15092"" target=""_blank"">2308.15092</a>",,2024-12-11
Uncertainty Aware Training to Improve Deep Learning Model Calibration for Classification of Cardiac MR Images,"Tareen Dawood, Chen Chen, Baldeep S. Sidhua, Bram Ruijsink, Justin Goulda, Bradley Porter, Mark K. Elliott, Vishal Mehta, Christopher A. Rinaldi, Esther Puyol-Anton, Reza Razavi, Andrew P. King",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15141"" target=""_blank"">2308.15141</a>",,2024-12-11
Adversarial Attacks on Foundational Vision Models,"Nathan Inkawhich, Gwendolyn McDonald, Ryan Luley",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14597"" target=""_blank"">2308.14597</a>",,2024-12-11
DiffSmooth: Certifiably Robust Learning via Diffusion Models and Local Smoothing,"Jiawei Zhang, Zhongzhu Chen, Huan Zhang, Chaowei Xiao, Bo Li",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14333"" target=""_blank"">2308.14333</a>","<a href=""https://github.com/javyduck/DiffSmooth]"" target=""_blank"">javyduck</a>",2024-12-11
Adversarial Illusions in Multi-Modal Embeddings,"Tingwei Zhang, Rishi Jha, Eugene Bagdasaryan, Vitaly Shmatikov",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11804"" target=""_blank"">2308.11804</a>",,2024-12-11
Detecting Language Model Attacks with Perplexity,"Gabriel Alon, Michael Kamfonas",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14132"" target=""_blank"">2308.14132</a>",,2024-12-11
Adversarial Training Using Feedback Loops,"Ali Haisam Muhammad Rafid, Adrian Sandu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11881"" target=""_blank"">2308.11881</a>",,2024-12-11
Black-box Adversarial Attacks against Dense Retrieval Models: A Multi-view Contrastive Learning Method,"Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Rijke Maarten de, Wei Chen, Yixing Fan, Xueqi Cheng",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09861"" target=""_blank"">2308.09861</a>",,2024-12-11
Compensating Removed Frequency Components: Thwarting Voice Spectrum Reduction Attacks,"Shu Wang, Kun Sun, Qi Li",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09546"" target=""_blank"">2308.09546</a>",,2024-12-11
"DFB: A Data-Free, Low-Budget, and High-Efficacy Clean-Label Backdoor Attack","Binhao Ma, Jiahui Wang, Dejun Wang, Bo Meng",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09487"" target=""_blank"">2308.09487</a>",,2024-12-11
Backdoor Mitigation by Correcting the Distribution of Neural Activations,"Xi Li, Zhen Xiang, David J. Miller, George Kesidis",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09850"" target=""_blank"">2308.09850</a>",,2024-12-11
Towards Attack-tolerant Federated Learning via Critical Parameter Analysis,"Sungwon Han, Sungwon Park, Fangzhao Wu, Sundong Kim, Bin Zhu, Xing Xie, Meeyoung Cha",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09318"" target=""_blank"">2308.09318</a>",,2024-12-11
On Gradient-like Explanation under a Black-box Setting: When Black-box Explanations Become as Good as White-box,"Yi Cai, Gerhard Wunder",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09381"" target=""_blank"">2308.09381</a>",,2024-12-11
Defending Label Inference Attacks in Split Learning under Regression Setting,"Haoze Qiu, Fei Zheng, Chaochao Chen, Xiaolin Zheng",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09448"" target=""_blank"">2308.09448</a>",,2024-12-11
An Image is Worth a Thousand Toxic Words: A Metamorphic Testing Framework for Content Moderation Software,"Wenxuan Wang, Jingyuan Huang, Jen-tse Huang, Chang Chen, Jiazhen Gu, Pinjia He, Michael R. Lyu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09810"" target=""_blank"">2308.09810</a>",,2024-12-11
Towards a Practical Defense against Adversarial Attacks on Deep Learning-based Malware Detectors via Randomized Smoothing,"Daniel Gibert, Giulio Zizzo, Quan Le",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08906"" target=""_blank"">2308.08906</a>",,2024-12-11
A White-Box False Positive Adversarial Attack Method on Contrastive Loss Based Offline Handwritten Signature Verification Models,"Zhongliang Guo, Weiye Li, Yifei Qian, Ognjen ArandjeloviÄ, Lei Fang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08925"" target=""_blank"">2308.08925</a>",,2024-12-11
Causal Adversarial Perturbations for Individual Fairness and Robustness in Heterogeneous Data Spaces,"Ahmad-Reza Ehyaei, Kiarash Mohammadi, Amir-Hossein Karimi, Samira Samadi, Golnoosh Farnadi",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08938"" target=""_blank"">2308.08938</a>",,2024-12-11
That Doesn't Go There: Attacks on Shared State in Multi-User Augmented Reality Applications,"Carter Slocum, Yicheng Zhang, Erfan Shayegani, Pedram Zaree, Nael Abu-Ghazaleh, Jiasi Chen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09146"" target=""_blank"">2308.09146</a>",,2024-12-11
Evaluating the Instruction-Following Robustness of Large Language Models to Prompt Injection,"Zekun Li, Baolin Peng, Pengcheng He, Xifeng Yan",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10819"" target=""_blank"">2308.10819</a>","<a href=""https://github.com/Leezekun/Adv-Instruct-Eval"" target=""_blank"">Leezekun</a>",2024-12-11
Benchmarking Adversarial Robustness of Compressed Deep Learning Models,"Brijesh Vora, Kartik Patwari, Syed Mahbub Hafiz, Zubair Shafiq, Chen-Nee Chuah",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08160"" target=""_blank"">2308.08160</a>",,2024-12-11
Test-Time Poisoning Attacks Against Test-Time Adaptation Models,"Tianshuo Cong, Xinlei He, Yun Shen, Yang Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08505"" target=""_blank"">2308.08505</a>",,2024-12-11
Self-Deception: Reverse Penetrating the Semantic Firewall of Large Language Models,"Zhenhua Wang, Wei Xie, Kai Chen, Baosheng Wang, Zhiwen Gui, Enze Wang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11521"" target=""_blank"">2308.11521</a>",,2024-12-11
LEAP: Efficient and Automated Test Method for NLP Software,"Mingxuan Xiao, Yan Xiao, Hai Dong, Shunhui Ji, Pengcheng Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11284"" target=""_blank"">2308.11284</a>",,2024-12-11
Dynamic Neural Network is All You Need: Understanding the Robustness of Dynamic Mechanisms in Neural Networks,"Mirazul Haque, Wei Yang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08709"" target=""_blank"">2308.08709</a>",,2024-12-11
Expressivity of Graph Neural Networks Through the Lens of Adversarial Robustness,"Francesco Campi, Lukas Gosch, Tom WollschlÃ¤ger, Yan Scholten, Stephan GÃ¼nnemann",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08173"" target=""_blank"">2308.08173</a>",,2024-12-11
SEDA: Self-Ensembling ViT with Defensive Distillation and Adversarial Training for robust Chest X-rays Classification,"Raza Imam, Ibrahim Almakky, Salma Alrashdi, Baketah Alrashdi, Mohammad Yaqub",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07874"" target=""_blank"">2308.07874</a>",,2024-12-11
Attacking logo-based phishing website detectors with adversarial perturbations,"Jehyun Lee, Zhe Xin, Melanie Ng Pei See, Kanav Sabharwal, Giovanni Apruzzese, Dinil Mon Divakaran",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09392"" target=""_blank"">2308.09392</a>",,2024-12-11
Proceedings of the 2nd International Workshop on Adaptive Cyber Defense,"Marco Carvalho, Damian Marriott, Mark Bilinski, Ahmad Ridley",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09520"" target=""_blank"">2308.09520</a>",,2024-12-11
Robust Mixture-of-Expert Training for Convolutional Neural Networks,"Yihua Zhang, Ruisi Cai, Tianlong Chen, Guanhua Zhang, Huan Zhang, Pin-Yu Chen, Shiyu Chang, Zhangyang Wang, Sijia Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10110"" target=""_blank"">2308.10110</a>","<a href=""https://github.com/OPTML-Group/Robust-MoE-CNN"" target=""_blank"">OPTML-Group</a>",2024-12-11
Unlocking Accuracy and Fairness in Differentially Private Image Classification,"Leonard Berrada, Soham De, Judy Hanwen Shen, Jamie Hayes, Robert Stanforth, David Stutz, Pushmeet Kohli, Samuel L. Smith, Borja Balle",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10888"" target=""_blank"">2308.10888</a>",,2024-12-11
PatchBackdoor: Backdoor Attack against Deep Neural Networks without Model Modification,"Yizhen Institute for AI Industry Research Yuan, Rui Shanghai Jiao Tong University, Shanghai, China Kong, Shenghao Wuhan University, Wuhan, China Xie, Yuanchun Institute for AI Industry Research Shanghai AI Laboratory, Shanghai, China Li, Yunxin Institute for AI Industry Research Shanghai AI Laboratory, Shanghai, China Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11822"" target=""_blank"">2308.11822</a>",,2024-12-11
Improving the Transferability of Adversarial Examples with Arbitrary Style Transfer,"Zhijin Ge, Fanhua Shang, Hongying Liu, Yuanyuan Liu, Liang Wan, Wei Feng, Xiaosen Wang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10601"" target=""_blank"">2308.10601</a>","<a href=""https://github.com/Zhijin-Ge/STM"" target=""_blank"">Zhijin-Ge</a>",2024-12-11
Spear and Shield: Adversarial Attacks and Defense Methods for Model-Based Link Prediction on Continuous-Time Dynamic Graphs,"Dongjin Lee, Juho Lee, Kijung Shin",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10779"" target=""_blank"">2308.10779</a>",,2024-12-11
A Comparison of Adversarial Learning Techniques for Malware Detection,"Pavla LouthÃ¡novÃ¡, MatouÅ¡ KozÃ¡k, Martin JureÄek, Mark Stamp",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09958"" target=""_blank"">2308.09958</a>",,2024-12-11
Adversarial Attacks on Code Models with Discriminative Graph Patterns,"Thanh-Dat Nguyen, Yang Zhou, Xuan Bach D. Le, Patanamon Thongtanunam, David Lo",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11161"" target=""_blank"">2308.11161</a>",,2024-12-11
Temporal-Distributed Backdoor Attack Against Video Based Action Recognition,"Xi Li, Songhe Wang, Ruiquan Huang, Mahanth Gowda, George Kesidis",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11070"" target=""_blank"">2308.11070</a>",,2024-12-11
Measuring the Effect of Causal Disentanglement on the Adversarial Robustness of Neural Network Models,"Preben M. Ness, Dusica Marijan, Sunanda Bose",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10708"" target=""_blank"">2308.10708</a>",,2024-12-11
Single-User Injection for Invisible Shilling Attack against Recommender Systems,"Chengzhi Huang, Hui Li",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10467"" target=""_blank"">2308.10467</a>","<a href=""https://github.com/KDEGroup/SUI-Attack"" target=""_blank"">KDEGroup</a>",2024-12-11
On the Adversarial Robustness of Multi-Modal Foundation Models,"Christian Schlarmann, Matthias Hein",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10741"" target=""_blank"">2308.10741</a>",,2024-12-11
Enhancing Adversarial Attacks: The Similar Target Method,"Shuo Zhang, Ziruo Wang, Zikai Zhou, Huanran Chen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10743"" target=""_blank"">2308.10743</a>",,2024-12-11
Boosting Adversarial Transferability by Block Shuffle and Rotation,"Kunyu Wang, Xuanran He, Wenxuan Wang, Xiaosen Wang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10299"" target=""_blank"">2308.10299</a>","<a href=""https://github.com/Trustworthy-AI-Group/BSR"" target=""_blank"">Trustworthy-AI-Group</a>",2024-12-11
Efficient Joint Optimization of Layer-Adaptive Weight Pruning in Deep Neural Networks,"Kaixin Xu, Zhe Wang, Xue Geng, Jie Lin, Min Wu, Xiaoli Li, Weisi Lin",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10438"" target=""_blank"">2308.10438</a>","<a href=""https://github.com/Akimoto-Cris/RD_VIT_PRUNE"" target=""_blank"">Akimoto-Cris</a>",2024-12-11
HoSNN: Adversarially-Robust Homeostatic Spiking Neural Networks with Adaptive Firing Thresholds,"Hejia Geng, Peng Li",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10373"" target=""_blank"">2308.10373</a>",,2024-12-11
Hiding Backdoors within Event Sequence Data via Poisoning Attacks,"Elizaveta Kovtun, Alina Ermilova, Dmitry Berestnev, Alexey Zaytsev",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10201"" target=""_blank"">2308.10201</a>",,2024-12-11
Adversarial Collaborative Filtering for Free,"Huiyuan Chen, Xiaoting Li, Vivian Lai, Chin-Chia Michael Yeh, Yujie Fan, Yan Zheng, Mahashweta Das, Hao Yang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.13541"" target=""_blank"">2308.13541</a>",,2024-12-11
A Study on Robustness and Reliability of Large Language Model Code Generation,"Li Zhong, Zilong Wang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10335"" target=""_blank"">2308.10335</a>",,2024-12-11
Improving Adversarial Robustness of Masked Autoencoders via Test-time Frequency-domain Prompting,"Qidong Huang, Xiaoyi Dong, Dongdong Chen, Yinpeng Chen, Lu Yuan, Gang Hua, Weiming Zhang, Nenghai Yu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10315"" target=""_blank"">2308.10315</a>","<a href=""https://github.com/shikiw/RobustMAE"" target=""_blank"">shikiw</a>",2024-12-11
Adversarial Finetuning with Latent Representation Constraint to Mitigate Accuracy-Robustness Tradeoff,"Satoshi Suzuki, Shin'ya Yamaguchi, Shoichiro Takeda, Sekitoshi Kanai, Naoki Makishima, Atsushi Ando, Ryo Masumura",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.16454"" target=""_blank"">2308.16454</a>",,2024-12-11
On the Vulnerability of DeepFake Detectors to Attacks Generated by Denoising Diffusion Models,"Marija Ivanovska, Vitomir Å truc",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05397"" target=""_blank"">2307.05397</a>",,2024-12-11
Random-Set Convolutional Neural Network (RS-CNN) for Epistemic Deep Learning,"Shireen Kudukkil Manchingal, Muhammad Mubashar, Kaizheng Wang, Keivan Shariatmadar, Fabio Cuzzolin",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05772"" target=""_blank"">2307.05772</a>",,2024-12-11
Membership Inference Attacks on DNNs using Adversarial Perturbations,"Hassan Ali, Adnan Qayyum, Ala Al-Fuqaha, Junaid Qadir",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05193"" target=""_blank"">2307.05193</a>",,2024-12-11
A Bayesian approach to quantifying uncertainties and improving generalizability in traffic prediction models,"Agnimitra Sengupta, Sudeepta Mondal, Adway Das, S. Ilgin Guler",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05946"" target=""_blank"">2307.05946</a>",,2024-12-11
ATWM: Defense against adversarial malware based on adversarial training,"Kun Li, Fan Zhang, Wei Guo",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05095"" target=""_blank"">2307.05095</a>",,2024-12-11
Scale Alone Does not Improve Mechanistic Interpretability in Vision Models,"Roland S. Zimmermann, Thomas Klein, Wieland Brendel",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05471"" target=""_blank"">2307.05471</a>",,2024-12-11
Misclassification in Automated Content Analysis Causes Bias in Regression,"Nathan TeBlunthuis, Valerie Hase, Chung-Hong Chan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06483"" target=""_blank"">2307.06483</a>",,2024-12-11
Rational Neural Network Controllers,"Matthew Newton, Antonis Papachristodoulou",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06287"" target=""_blank"">2307.06287</a>",,2024-12-11
A Theoretical Perspective on Subnetwork Contributions to Adversarial Robustness,"Jovon Craig, Josh Andle, Theodore S. Nowak, Salimeh Yasaei Sekeh",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03803"" target=""_blank"">2307.03803</a>",,2024-12-11
Differential Analysis of Triggers and Benign Features for Black-Box DNN Backdoor Detection,"Hao Fu, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05422"" target=""_blank"">2307.05422</a>",,2024-12-11
Practical Trustworthiness Model for DNN in Dedicated 6G Application,"Anouar Nechi, Ahmed Mahmoudi, Christoph Herold, Daniel Widmer, Thomas KÃ¼rner, Mladen Berekovic, Saleh Mulhem",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.04677"" target=""_blank"">2307.04677</a>",,2024-12-11
Memorization Through the Lens of Curvature of Loss Function Around Samples,"Isha Garg, Deepak Ravikumar, Kaushik Roy",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05831"" target=""_blank"">2307.05831</a>",,2024-12-11
The Butterfly Effect in Artificial Intelligence Systems: Implications for AI Bias and Fairness,Emilio Ferrara,arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05842"" target=""_blank"">2307.05842</a>",,2024-12-11
Distill-SODA: Distilling Self-Supervised Vision Transformer for Source-Free Open-Set Domain Adaptation in Computational Pathology,"Guillaume Vray, Devavrat Tomar, Jean-Philippe Thiran, Behzad Bozorgtabar",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.04596"" target=""_blank"">2307.04596</a>",,2024-12-11
GNP Attack: Transferable Adversarial Examples via Gradient Norm Penalty,"Tao Wu, Tie Luo, Donald C. Wunsch",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.04099"" target=""_blank"">2307.04099</a>",,2024-12-11
Enhancing Adversarial Robustness via Score-Based Optimization,"Boya Zhang, Weijian Luo, Zhihua Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.04333"" target=""_blank"">2307.04333</a>",,2024-12-11
Adversarial Self-Attack Defense and Spatial-Temporal Relation Mining for Visible-Infrared Video Person Re-Identification,"Huafeng Li, Le Xu, Yafei Zhang, Dapeng Tao, Zhengtao Yu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03903"" target=""_blank"">2307.03903</a>","<a href=""https://github.com/lhf12278/xxx"" target=""_blank"">lhf12278</a>",2024-12-11
Random Position Adversarial Patch for Vision Transformers,Mingzhen Shao,arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.04066"" target=""_blank"">2307.04066</a>",,2024-12-11
Robust Ranking Explanations,"Chao Chen, Chenghua Guo, Guixiang Ma, Ming Zeng, Xi Zhang, Sihong Xie",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.04024"" target=""_blank"">2307.04024</a>",,2024-12-11
Single-Class Target-Specific Attack against Interpretable Deep Learning Systems,"Eldor Abdukhamidov, Mohammed Abuhamad, George K. Thiruvathukal, Hyoungshick Kim, Tamer Abuhmed",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06484"" target=""_blank"">2307.06484</a>",,2024-12-11
Microbial Genetic Algorithm-based Black-box Attack against Interpretable Deep Learning Systems,"Eldor Abdukhamidov, Mohammed Abuhamad, Simon S. Woo, Eric Chan-Tin, Tamer Abuhmed",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06496"" target=""_blank"">2307.06496</a>",,2024-12-11
Unified Adversarial Patch for Cross-modal Attacks in the Physical World,"Xingxing Wei, Yao Huang, Yitong Sun, Jie Yu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07859"" target=""_blank"">2307.07859</a>",,2024-12-11
Towards Traitor Tracing in Black-and-White-Box DNN Watermarking with Tardos-based Codes,"Elena Rodriguez-Lois, Fernando Perez-Gonzalez",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06695"" target=""_blank"">2307.06695</a>",,2024-12-11
Alleviating the Effect of Data Imbalance on Adversarial Training,"Guanlin Li, Guowen Xu, Tianwei Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10205"" target=""_blank"">2307.10205</a>","<a href=""https://github.com/GuanlinLee/REAT"" target=""_blank"">GuanlinLee</a>",2024-12-11
Scalable Membership Inference Attacks via Quantile Regression,"Martin Bertran, Shuai Tang, Michael Kearns, Jamie Morgenstern, Aaron Roth, Zhiwei Steven Wu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03694"" target=""_blank"">2307.03694</a>",,2024-12-11
On the Robustness of Split Learning against Adversarial Attacks,"Mingyuan Fan, Cen Chen, Chengyu Wang, Wenmeng Zhou, Jun Huang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07916"" target=""_blank"">2307.07916</a>",,2024-12-11
Why Does Little Robustness Help? Understanding and Improving Adversarial Transferability from Surrogate Training,"Yechao Zhang, Shengshan Hu, Leo Yu Zhang, Junyu Shi, Minghui Li, Xiaogeng Liu, Wei Wan, Hai Jin",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07873"" target=""_blank"">2307.07873</a>",,2024-12-11
MasterKey: Automated Jailbreak Across Multiple Large Language Model Chatbots,"Gelei Deng, Yi Liu, Yuekang Li, Kailong Wang, Ying Zhang, Zefeng Li, Haoyu Wang, Tianwei Zhang, Yang Liu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08715"" target=""_blank"">2307.08715</a>",,2024-12-11
Vulnerability-Aware Instance Reweighting For Adversarial Training,"Olukorede Fakorede, Ashutosh Kumar Nirala, Modeste Atsague, Jin Tian",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07167"" target=""_blank"">2307.07167</a>",,2024-12-11
Mitigating Adversarial Vulnerability through Causal Parameter Estimation by Adversarial Double Machine Learning,"Byung-Kwan Lee, Junho Kim, Yong Man Ro",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07250"" target=""_blank"">2307.07250</a>",,2024-12-11
On the Sensitivity of Deep Load Disaggregation to Adversarial Attacks,"Hafsa Bousbiat, Yassine Himeur, Abbes Amira, Wathiq Mansoor",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10209"" target=""_blank"">2307.10209</a>",,2024-12-11
RFLA: A Stealthy Reflected Light Adversarial Attack in the Physical World,"Donghua Wang, Wen Yao, Tingsong Jiang, Chao Li, Xiaoqian Chen",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07653"" target=""_blank"">2307.07653</a>",,2024-12-11
Structured Pruning of Neural Networks for Constraints Learning,"Matteo Cacciola, Antonio Frangioni, Andrea Lodi",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07457"" target=""_blank"">2307.07457</a>",,2024-12-11
Defeating Proactive Jammers Using Deep Reinforcement Learning for Resource-Constrained IoT Networks,"Abubakar Sani Ali, Shimaa Naser, Sami Muhaidat",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06796"" target=""_blank"">2307.06796</a>",,2024-12-11
Boosting Backdoor Attack with A Learnable Poisoning Sample Selection Strategy,"Zihao Zhu, Mingda Zhang, Shaokui Wei, Li Shen, Yanbo Fan, Baoyuan Wu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07328"" target=""_blank"">2307.07328</a>",,2024-12-11
"Erasing, Transforming, and Noising Defense Network for Occluded Person Re-Identification","Neng Dong, Liyan Zhang, Shuanglin Yan, Hao Tang, Jinhui Tang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07187"" target=""_blank"">2307.07187</a>","<a href=""https://github.com/nengdong96/ETNDNet"" target=""_blank"">nengdong96</a>",2024-12-11
Omnipotent Adversarial Training in the Wild,"Guanlin Li, Kangjie Chen, Yuan Xu, Han Qiu, Tianwei Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08596"" target=""_blank"">2307.08596</a>","<a href=""https://github.com/GuanlinLee/OAT"" target=""_blank"">GuanlinLee</a>",2024-12-11
Certified Robustness for Large Language Models with Self-Denoising,"Zhen Zhang, Guanhua Zhang, Bairu Hou, Wenqi Fan, Qing Li, Sijia Liu, Yang Zhang, Shiyu Chang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07171"" target=""_blank"">2307.07171</a>","<a href=""https://github.com/UCSB-NLP-Chang/SelfDenoise"" target=""_blank"">UCSB-NLP-Chang</a>",2024-12-11
Multi-objective Evolutionary Search of Variable-length Composite Semantic Perturbations,"Jialiang Suna, Wen Yao, Tingsong Jianga, Xiaoqian Chena",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06548"" target=""_blank"">2307.06548</a>",,2024-12-11
Introducing Foundation Models as Surrogate Models: Advancing Towards More Practical Adversarial Attacks,"Jiaming Zhang, Jitao Sang, Qi Yi, Changsheng Xu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06608"" target=""_blank"">2307.06608</a>",,2024-12-11
Effective Prompt Extraction from Language Models,"Yiming Zhang, Nicholas Carlini, Daphne Ippolito",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06865"" target=""_blank"">2307.06865</a>",,2024-12-11
Layer-wise Linear Mode Connectivity,"Linara Adilova, Maksym Andriushchenko, Michael Kamp, Asja Fischer, Martin Jaggi",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06966"" target=""_blank"">2307.06966</a>",,2024-12-11
Fooling Contrastive Language-Image Pre-trained Models with CLIPMasterPrints,"Matthias Freiberger, Peter Kun, Christian Igel, Anders Sundnes LÃ¸vlie, Sebastian Risi",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03798"" target=""_blank"">2307.03798</a>","<a href=""https://github.com/matfrei/CLIPMasterPrints"" target=""_blank"">matfrei</a>",2024-12-11
CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data Synthesis,"Abdallah Alshantti, Damiano Varagnolo, Adil Rasheed, Aria Rahmati, Frank Westad",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00384"" target=""_blank"">2307.00384</a>",,2024-12-11
RADAR: Robust AI-Text Detection via Adversarial Learning,"Xiaomeng Hu, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03838"" target=""_blank"">2307.03838</a>",,2024-12-11
A Dual Stealthy Backdoor: From Both Spatial and Frequency Perspectives,"Yudong Gao, Honglong Chen, Peng Sun, Junjian Li, Anqing Zhang, Zhibo Wang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10184"" target=""_blank"">2307.10184</a>",,2024-12-11
What Distributions are Robust to Indiscriminate Poisoning Attacks for Linear Learners? (62%),"Fnu Suya, Xiao Zhang, Yuan Tian, David Evans",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01073"" target=""_blank"">2307.01073</a>",,2024-12-11
Adversarial Learning in Real-World Fraud Detection: Challenges and Perspectives,"Danele Lunghi, Alkis Simitsis, Olivier Caelen, Gianluca Bontempi",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01390"" target=""_blank"">2307.01390</a>",,2024-12-11
Understanding the Transferability of Representations via Task-Relatedness,"Akshay Mehra, Yunbei Zhang, Jihun Hamm",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00823"" target=""_blank"">2307.00823</a>",,2024-12-11
Enhancing the Robustness of QMIX against State-adversarial Attacks,"Weiran Guo, Guanjun Liu, Ziyuan Zhou, Ling Wang, Jiacun Wang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00907"" target=""_blank"">2307.00907</a>",,2024-12-11
Towards Building Self-Aware Object Detectors via Reliable Uncertainty Quantification and Calibration,"Kemal Oksuz, Tom Joy, Puneet K. Dokania",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00934"" target=""_blank"">2307.00934</a>","<a href=""https://github.com/fiveai/saod"" target=""_blank"">fiveai</a>",2024-12-11
Query-Efficient Decision-based Black-Box Patch Attack,"Zhaoyu Chen, Bo Li, Shuang Wu, Shouhong Ding, Wenqiang Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00477"" target=""_blank"">2307.00477</a>",,2024-12-11
Interpretability and Transparency-Driven Detection and Transformation of Textual Adversarial Examples (IT-DT),"Bushra Sabir, M. Ali Babar, Sharif Abuadbba",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01225"" target=""_blank"">2307.01225</a>",,2024-12-11
From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy,"Maanak Gupta, CharanKumar Akiri, Kshitiz Aryal, Eli Parker, Lopamudra Praharaj",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00691"" target=""_blank"">2307.00691</a>",,2024-12-11
CLIMAX: An exploration of Classifier-Based Contrastive Explanations,"Praharsh Nanavati, Ranjitha Prasad",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00680"" target=""_blank"">2307.00680</a>",,2024-12-11
Common Knowledge Learning for Generating Transferable Adversarial Examples,"Ruijie Yang, Yuanfang Guo, Junfu Wang, Jiantao Zhou, Yunhong Wang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00274"" target=""_blank"">2307.00274</a>",,2024-12-11
Adversarial Attacks and Defenses on 3D Point Cloud Classification: A Survey,"Hanieh Naderi, Ivan V. BajiÄ",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00309"" target=""_blank"">2307.00309</a>",,2024-12-11
Brightness-Restricted Adversarial Attack Patch,Mingzhen Shao,arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00421"" target=""_blank"">2307.00421</a>",,2024-12-11
Fedward: Flexible Federated Backdoor Defense Framework with Non-IID Data,"Zekai Chen, Fuyi Wang, Zhiwei Zheng, Ximeng Liu, Yujie Lin",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00356"" target=""_blank"">2307.00356</a>",,2024-12-11
Minimizing Energy Consumption of Deep Learning Models by Energy-Aware Training,"Dario Lazzaro, Antonio Emanuele CinÃ , Maura Pintor, Ambra Demontis, Battista Biggio, Fabio Roli, Marcello Pelillo",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00368"" target=""_blank"">2307.00368</a>",,2024-12-11
SysNoise: Exploring and Benchmarking Training-Deployment System Inconsistency,"Yan Wang, Yuhang Li, Ruihao Gong, Aishan Liu, Yanfei Wang, Jian Hu, Yongqiang Yao, Yunchen Zhang, Tianzi Xiao, Fengwei Yu, Xianglong Liu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00280"" target=""_blank"">2307.00280</a>","<a href=""https://modeltc.github.io/systemnoise_web"" target=""_blank"">modeltc.github.io</a>",2024-12-11
Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD,"Anvith Thudi, Hengrui Jia, Casey Meehan, Ilia Shumailov, Nicolas Papernot",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00310"" target=""_blank"">2307.00310</a>",,2024-12-11
Diffusion to Confusion: Naturalistic Adversarial Patch Generation Based on Diffusion Model for Object Detector,"Shuo-Yen Lin, Ernie Chu, Che-Hsien Lin, Jun-Cheng Chen, Jia-Ching Wang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08076"" target=""_blank"">2307.08076</a>",,2024-12-11
FedDefender: Backdoor Attack Defense in Federated Learning,"Waris Virginia Tech Gill, Ali University of Minnesota Twin Cities Anwar, Muhammad Ali Virginia Tech Gulzar",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08672"" target=""_blank"">2307.08672</a>",,2024-12-11
Hiding in Plain Sight: Differential Privacy Noise Exploitation for Evasion-resilient Localized Poisoning Attacks in Multiagent Reinforcement Learning,"Md Tamjid Hossain, Hung La",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00268"" target=""_blank"">2307.00268</a>",,2024-12-11
Analyzing the vulnerabilities in SplitFed Learning: Assessing the robustness against Data Poisoning Attacks,"Aysha Thahsin Zahir Ismail, Raj Mani Shukla",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03197"" target=""_blank"">2307.03197</a>",,2024-12-11
Pareto-Secure Machine Learning (PSML): Fingerprinting and Securing Inference Serving Systems,"Debopam Georgia Institute of Technology Sanyal, Jui-Tse Georgia Institute of Technology Hung, Manav Georgia Institute of Technology Agrawal, Prahlad Georgia Institute of Technology Jasti, Shahab University of California, Riverside Nikkhoo, Somesh University of Wisconsin-Madison Jha, Tianhao University of Virginia Wang, Sibin George Washington University Mohan, Alexey Georgia Institute of Technology Tumanov",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01292"" target=""_blank"">2307.01292</a>",,2024-12-11
Generation of Time-Varying Impedance Attacks Against Haptic Shared Control Steering Systems,"Alireza Mohammadi, Hafiz Malik",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12399"" target=""_blank"">2307.12399</a>",,2024-12-11
Synthetic is all you need: removing the auxiliary data assumption for membership inference attacks against synthetic data,"Florent GuÃ©pin, Matthieu Meeus, Ana-Maria Cretu, Montjoye Yves-Alexandre de",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01701"" target=""_blank"">2307.01701</a>",,2024-12-11
Sampling-based Fast Gradient Rescaling Method for Highly Transferable Adversarial Attacks,"Xu Han, Anmin Liu, Chenxuan Yao, Yanbo Fan, Kun He",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02828"" target=""_blank"">2307.02828</a>",,2024-12-11
NatLogAttack: A Framework for Attacking Natural Language Inference Models with Natural Logic,"Zi'ou Zheng, Xiaodan Zhu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02849"" target=""_blank"">2307.02849</a>",,2024-12-11
Quantification of Uncertainty with Adversarial Models,"Kajetan Schweighofer, Lukas Aichberger, Mykyta Ielanskyi, GÃ¼nter Klambauer, Sepp Hochreiter",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03217"" target=""_blank"">2307.03217</a>",,2024-12-11
A Vulnerability of Attribution Methods Using Pre-Softmax Scores,"Miguel Lerma, Mirtha Lucas",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03305"" target=""_blank"">2307.03305</a>",,2024-12-11
Probabilistic and Semantic Descriptions of Image Manifolds and Their Applications,"Peter Tu, Zhaoyuan Yang, Richard Hartley, Zhiwei Xu, Jing Zhang, Yiwei Fu, Dylan Campbell, Jaskirat Singh, Tianyu Wang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02881"" target=""_blank"">2307.02881</a>",,2024-12-11
T-MARS: Improving Visual Representations by Circumventing Text Feature Learning,"Pratyush Maini, Sachin Goyal, Zachary C. Lipton, J. Zico Kolter, Aditi Raghunathan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03132"" target=""_blank"">2307.03132</a>","<a href=""https://github.com/locuslab/T-MARS"" target=""_blank"">locuslab</a>",2024-12-11
Adversarial Attacks on Image Classification Models: FGSM and Patch Attacks and their Impact,"Jaydip Sen, Subhasis Dasgupta",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02055"" target=""_blank"">2307.02055</a>",,2024-12-11
DARE: Towards Robust Text Explanations in Biomedical and Healthcare Applications,"Adam Ivankay, Mattia Rigotti, Pascal Frossard",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02094"" target=""_blank"">2307.02094</a>",,2024-12-11
Detecting Images Generated by Deep Diffusion Models using their Local Intrinsic Dimensionality,"Peter Lorenz, Ricard Durall, Janis Keuper",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02347"" target=""_blank"">2307.02347</a>",,2024-12-11
"GIT: Detecting Uncertainty, Out-Of-Distribution and Adversarial Samples using Gradients and Invariance Transformations","Julia Lust, Alexandru P. Condurache",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02672"" target=""_blank"">2307.02672</a>",,2024-12-11
Securing Cloud FPGAs Against Power Side-Channel Attacks: A Case Study on Iterative AES,"Nithyashankari Gummidipoondi JV Jayasankaran, Hao JV Guo, Satwik JV Patnaik, JV Jeyavijayan, Rajendran, Jiang Hu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02569"" target=""_blank"">2307.02569</a>",,2024-12-11
On the Adversarial Robustness of Generative Autoencoders in the Latent Space,"Mingfei Lu, Badong Chen",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02202"" target=""_blank"">2307.02202</a>",,2024-12-11
SCAT: Robust Self-supervised Contrastive Learning via Adversarial Training for Text Classification,"Junjie Wu, Dit-Yan Yeung",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01488"" target=""_blank"">2307.01488</a>",,2024-12-11
LEAT: Towards Robust Deepfake Disruption in Real-World Scenarios via Latent Ensemble Attack,"Joonkyo Shim, Hyunsoo Yoon",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01520"" target=""_blank"">2307.01520</a>",,2024-12-11
Interpretable Computer Vision Models through Adversarial Training: Unveiling the Robustness-Interpretability Connection,Delyan Boychev,arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02500"" target=""_blank"">2307.02500</a>",,2024-12-11
Overconfidence is a Dangerous Thing: Mitigating Membership Inference Attacks by Enforcing Less Confident Prediction,"Zitao Chen, Karthik Pattabiraman",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01610"" target=""_blank"">2307.01610</a>",,2024-12-11
Physically Realizable Natural-Looking Clothing Textures Evade Person Detectors via 3D Modeling,"Zhanhao Hu, Wenda Chu, Xiaopei Zhu, Hui Zhang, Bo Zhang, Xiaolin Hu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01778"" target=""_blank"">2307.01778</a>",,2024-12-11
An Analysis of Untargeted Poisoning Attack and Defense Methods for Federated Online Learning to Rank Systems,"Shuyi Wang, Guido Zuccon",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01565"" target=""_blank"">2307.01565</a>",,2024-12-11
Machine Learning-Based Intrusion Detection: Feature Selection versus Feature Extraction,"Vu-Duc Ngo, Tuan-Cuong Vuong, Luong Thien Van, Hung Tran",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01570"" target=""_blank"">2307.01570</a>",,2024-12-11
Lipschitz Continuous Algorithms for Covering Problems,"Soh Kumabe, Yuichi Yoshida",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08213"" target=""_blank"">2307.08213</a>",,2024-12-11
Frequency Domain Adversarial Training for Robust Volumetric Medical Segmentation,"Asif Hanif, Muzammal Naseer, Salman Khan, Mubarak Shah, Fahad Shahbaz Khan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07269"" target=""_blank"">2307.07269</a>","<a href=""https://github.com/asif-hanif/vafa"" target=""_blank"">asif-hanif</a>",2024-12-11
Towards Stealthy Backdoor Attacks against Speech Recognition via Elements of Sound,"Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao, Stefanos Koffas, Yiming Li",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08208"" target=""_blank"">2307.08208</a>","<a href=""https://github.com/HanboCai/BadSpeech_SoE"" target=""_blank"">HanboCai</a>",2024-12-11
FLARE: Fingerprinting Deep Reinforcement Learning Agents using Universal Adversarial Masks,"Buse G. A. Tekgul, N. Asokan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14751"" target=""_blank"">2307.14751</a>",,2024-12-11
NSA: Naturalistic Support Artifact to Boost Network Confidence,"Abhijith Sharma, Phil Munz, Apurva Narayan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14917"" target=""_blank"">2307.14917</a>",,2024-12-11
SEV-Step: A Single-Stepping Framework for AMD-SEV,"Luca Wilke, Jan Wichelmann, Anja Rabich, Thomas Eisenbarth",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14757"" target=""_blank"">2307.14757</a>",,2024-12-11
"Decoding the Secrets of Machine Learning in Malware Classification: A Deep Dive into Datasets, Feature Extraction, and Model Performance","Savino Dambra, Yufei Han, Simone Aonzo, Platon Kotzias, Antonino Vitale, Juan Caballero, Davide Balzarotti, Leyla Bilge",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14657"" target=""_blank"">2307.14657</a>",,2024-12-11
AC-Norm: Effective Tuning for Medical Image Analysis via Affine Collaborative Normalization,"Chuyan Zhang, Yuncheng Yang, Hao Zheng, Yun Gu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15282"" target=""_blank"">2307.15282</a>","<a href=""https://github.com/EndoluminalSurgicalVision-IMR/ACNorm"" target=""_blank"">EndoluminalSurgicalVision-IMR</a>",2024-12-11
Enhanced Security against Adversarial Examples Using a Random Ensemble of Encrypted Vision Transformer Models,"Ryota Iijima, Miki Tanaka, Sayaka Shiota, Hitoshi Kiya",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13985"" target=""_blank"">2307.13985</a>",,2024-12-11
Set-level Guidance Attack: Boosting Adversarial Transferability of Vision-Language Pre-training Models,"Dong Lu, Zhiqiang Wang, Teng Wang, Weili Guan, Hongchang Gao, Feng Zheng",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14061"" target=""_blank"">2307.14061</a>",,2024-12-11
Defending Adversarial Patches via Joint Region Localizing and Inpainting,"Junwen Chen, Xingxing Wei",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14242"" target=""_blank"">2307.14242</a>",,2024-12-11
Lateral-Direction Localization Attack in High-Level Autonomous Driving: Domain-Specific Defense Opportunity via Lane Detection,"Junjie Shen, Yunpeng Luo, Ziwen Wan, Qi Alfred Chen",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14540"" target=""_blank"">2307.14540</a>",,2024-12-11
Plug and Pray: Exploiting off-the-shelf components of Multi-Modal Models,"Erfan Shayegani, Yue Dong, Nael Abu-Ghazaleh",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14539"" target=""_blank"">2307.14539</a>",,2024-12-11
Coupled-Space Attacks against Random-Walk-based Anomaly Detection,"Yuni Lai, Marcin Waniek, Liying Li, Jingwen Wu, Yulin Zhu, Tomasz P. Michalak, Talal Rahwan, Kai Zhou",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14387"" target=""_blank"">2307.14387</a>",,2024-12-11
FakeTracer: Proactively Defending Against Face-swap DeepFakes via Implanting Traces in Training,"Pu Sun, Honggang Qi, Yuezun Li, Siwei Lyu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14593"" target=""_blank"">2307.14593</a>",,2024-12-11
Open Image Content Disarm And Reconstruction,"Eli Belkind, Ran Dubin, Amit Dvir",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14057"" target=""_blank"">2307.14057</a>",,2024-12-11
On the unreasonable vulnerability of transformers for image restoration -- and an easy fix,"Shashank Agnihotri, Kanchana Vaishnavi Gandikota, Julia Grabinski, Paramanand Chandramouli, Margret Keuper",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13856"" target=""_blank"">2307.13856</a>",,2024-12-11
Imperceptible Physical Attack against Face Recognition Systems via LED Illumination Modulation,"Junbin Fang, Canjian Jiang, You Jiang, Puxi Lin, Zhaojie Chen, Yujing Sun, Siu-Ming Yiu, Zoe L. Jiang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13294"" target=""_blank"">2307.13294</a>",,2024-12-11
Efficient Estimation of Average-Case Robustness for Multi-Class Classification,"Tessa Han, Suraj Srinivas, Himabindu Lakkaraju",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13885"" target=""_blank"">2307.13885</a>",,2024-12-11
Foundational Models Defining a New Era in Vision: A Survey and Outlook,"Muhammad Awais, Muzammal Naseer, Salman Khan, Rao Muhammad Anwer, Hisham Cholakkal, Mubarak Shah, Ming-Hsuan Yang, Fahad Shahbaz Khan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13721"" target=""_blank"">2307.13721</a>","<a href=""https://github.com/awaisrauf/Awesome-CV-Foundational-Models"" target=""_blank"">awaisrauf</a>",2024-12-11
Why Don't You Clean Your Glasses? Perception Attacks with Dynamic Optical Perturbations,"Yi Han, Matthew Chan, Eric Wengrowski, Zhuohuan Li, Nils Ole Tippenhauer, Mani Srivastava, Saman Zonouz, Luis Garcia",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13131"" target=""_blank"">2307.13131</a>",,2024-12-11
Lost In Translation: Generating Adversarial Examples Robust to Round-Trip Translation,"Neel Bhandari, Pin-Yu Chen",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12520"" target=""_blank"">2307.12520</a>",,2024-12-11
Data-free Black-box Attack based on Diffusion Model,"Mingwen Shao, Lingzhuang Meng, Yuanjian Qiao, Lixu Zhang, Wangmeng Zuo",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12872"" target=""_blank"">2307.12872</a>",,2024-12-11
Unified Adversarial Patch for Visible-Infrared Cross-modal Attacks in the Physical World,"Xingxing Wei, Yao Huang, Yitong Sun, Jie Yu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14682"" target=""_blank"">2307.14682</a>",,2024-12-11
Backdoor Attacks for In-Context Learning with Language Models,"Nikhil Kandpal, Matthew Jagielski, Florian TramÃ¨r, Nicholas Carlini",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14692"" target=""_blank"">2307.14692</a>",,2024-12-11
An Estimator for the Sensitivity to Perturbations of Deep Neural Networks,"Naman Maheshwari, Nicholas Malaya, Scott Moe, Jaydeep P. Kulkarni, Sudhanva Gurumurthi",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12679"" target=""_blank"">2307.12679</a>",,2024-12-11
Universal and Transferable Adversarial Attacks on Aligned Language Models,"Andy Zou, Zifan Wang, Nicholas Carlini, Milad Nasr, J. Zico Kolter, Matt Fredrikson",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15043"" target=""_blank"">2307.15043</a>",,2024-12-11
Towards Viewpoint-Invariant Visual Recognition via Adversarial Training,"Shouwei Ruan, Yinpeng Dong, Hang Su, Jianteng Peng, Ning Chen, Xingxing Wei",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10235"" target=""_blank"">2307.10235</a>",,2024-12-11
Transferable Attack for Semantic Segmentation,"Mengqi He, Jing Zhang, Zhaoyuan Yang, Mingyi He, Nick Barnes, Yuchao Dai",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16572"" target=""_blank"">2307.16572</a>","<a href=""https://github.com/anucvers/TASS"" target=""_blank"">anucvers</a>",2024-12-11
Universal Adversarial Defense in Remote Sensing Based on Pre-trained Denoising Diffusion Models,"Weikang Yu, Yonghao Xu, Pedram Ghamisi",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16865"" target=""_blank"">2307.16865</a>",,2024-12-11
Defense of Adversarial Ranking Attack in Text Retrieval: Benchmark and Baseline via Detection,"Xuanang Chen, Ben He, Le Sun, Yingfei Sun",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16816"" target=""_blank"">2307.16816</a>",,2024-12-11
Text-CRS: A Generalized Certified Robustness Framework against Textual Adversarial Attacks,"Xinyu Zhang, Hanbin Hong, Yuan Hong, Peng Huang, Binghui Wang, Zhongjie Ba, Kui Ren",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16630"" target=""_blank"">2307.16630</a>",,2024-12-11
BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models,"Jordan Vice, Naveed Akhtar, Richard Hartley, Ajmal Mian",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16489"" target=""_blank"">2307.16489</a>","<a href=""https://github.com/JJ-Vice/BAGM"" target=""_blank"">JJ-Vice</a>",2024-12-11
Virtual Prompt Injection for Instruction-Tuned Large Language Models,"Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai Wang, Vijay Srinivasan, Xiang Ren, Hongxia Jin",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16888"" target=""_blank"">2307.16888</a>","<a href=""https://poison-llm.github.io"" target=""_blank""></a>",2024-12-11
Noisy Self-Training with Data Augmentations for Offensive and Hate Speech Detection Tasks,"JoÃ£o A. Leite, Carolina Scarton, Diego F. Silva",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16609"" target=""_blank"">2307.16609</a>",,2024-12-11
Theoretically Principled Trade-off for Stateful Defenses against Query-Based Black-Box Attacks,"Ashish Hooda, Neal Mangaokar, Ryan Feng, Kassem Fawaz, Somesh Jha, Atul Prakash",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16331"" target=""_blank"">2307.16331</a>",,2024-12-11
Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples,"Qiufan Ji, Lin Wang, Cong Shi, Shengshan Hu, Yingying Chen, Lichao Sun",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16361"" target=""_blank"">2307.16361</a>","<a href=""https://github.com/qiufan319/benchmark_pc_attack"" target=""_blank"">qiufan319</a>",2024-12-11
Probabilistically robust conformal prediction,"Subhankar Ghosh, Yuanjie Shi, Taha Belkhouja, Yan Yan, Jana Doppa, Brian Jones",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16360"" target=""_blank"">2307.16360</a>",,2024-12-11
On Updating Static Output Feedback Controllers Under State-Space Perturbation,"MirSaleh Bahavarnia, Ahmad F. Taha",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16178"" target=""_blank"">2307.16178</a>",,2024-12-11
You Can Backdoor Personalized Federated Learning,"Tiandi Ye, Cen Chen, Yinggui Wang, Xiang Li, Ming Gao",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15971"" target=""_blank"">2307.15971</a>",,2024-12-11
On Neural Network approximation of ideal adversarial attack and convergence of adversarial training,"Rajdeep Haldar, Qifan Song",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16099"" target=""_blank"">2307.16099</a>",,2024-12-11
Exposing Hidden Attackers in Industrial Control Systems using Micro-distortions,"Suman Sourav, Binbin Chen",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15926"" target=""_blank"">2307.15926</a>",,2024-12-11
Beating Backdoor Attack at Its Own Game,"Min Liu, Alberto Sangiovanni-Vincentelli, Xiangyu Yue",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15539"" target=""_blank"">2307.15539</a>","<a href=""https://github.com/damianliumin/non-adversarial_backdoor"" target=""_blank"">damianliumin</a>",2024-12-11
Adversarial training for tabular data with attack propagation,"Tiago Leon Melo, JoÃ£o Bravo, Marco O. P. Sampaio, Paolo Romano, Hugo Ferreira, JoÃ£o Tiago AscensÃ£o, Pedro Bizarro",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15677"" target=""_blank"">2307.15677</a>",,2024-12-11
Improving Realistic Worst-Case Performance of NVCiM DNN Accelerators through Training with Right-Censored Gaussian Noise,"Zheyu Yan, Yifan Qin, Wujie Wen, Xiaobo Sharon Hu, Yiyu Shi",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15853"" target=""_blank"">2307.15853</a>",,2024-12-11
R-LPIPS: An Adversarially Robust Perceptual Similarity Metric,"Sara Ghazanfari, Siddharth Garg, Prashanth Krishnamurthy, Farshad Khorrami, Alexandre Araujo",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15157"" target=""_blank"">2307.15157</a>","<a href=""https://github.com/SaraGhazanfari/R-LPIPS"" target=""_blank"">SaraGhazanfari</a>",2024-12-11
Adaptive Certified Training: Towards Better Accuracy-Robustness Tradeoffs,"Zhakshylyk Nurlanov, Frank R. Schmidt, Florian Bernard",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13078"" target=""_blank"">2307.13078</a>",,2024-12-11
What can Discriminator do? Towards Box-free Ownership Verification of Generative Adversarial Network,"Ziheng Huang, Boheng Li, Yan Cai, Run Wang, Shangwei Guo, Liming Fang, Jing Chen, Lina Wang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15860"" target=""_blank"">2307.15860</a>","<a href=""https://github.com/AbstractTeen/gan_ownership_verification"" target=""_blank"">AbstractTeen</a>",2024-12-11
Cyber Deception against Zero-day Attacks: A Game Theoretic Approach,"Md Abu University of Texas at El Paso Sayed, Ahmed H. US Army Research Laboratory Anwar, Christopher University of Texas at El Paso Kiekintveld, Branislav Czech Technical University in Prague Bosansky, Charles US Army Research Laboratory Kamhoua",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13107"" target=""_blank"">2307.13107</a>",,2024-12-11
Adversarial attacks for mixtures of classifiers,"Lucas Gnecco Heredia, Benjamin Negrevergne, Yann Chevaleyre",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10788"" target=""_blank"">2307.10788</a>",,2024-12-11
A Holistic Assessment of the Reliability of Machine Learning Systems,"Anthony Corso, David Karamadian, Romeo Valentin, Mary Cooper, Mykel J. Kochenderfer",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10586"" target=""_blank"">2307.10586</a>",,2024-12-11
Making Pre-trained Language Models both Task-solvers and Self-calibrators,"Yangyi Chen, Xingyao Wang, Heng Ji",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11316"" target=""_blank"">2307.11316</a>","<a href=""https://github.com/Yangyi-Chen/LM-TOAST"" target=""_blank"">Yangyi-Chen</a>",2024-12-11
Boundary State Generation for Testing and Improvement of Autonomous Driving Systems,"Matteo Biagiola, Paolo Tonella",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10590"" target=""_blank"">2307.10590</a>",,2024-12-11
"A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency","Jiawei Shao, Zijian Li, Wenqiang Sun, Tailin Zhou, Yuchang Sun, Lumin Liu, Zehong Lin, Yuyi Mao, Jun Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10655"" target=""_blank"">2307.10655</a>",,2024-12-11
Backdoor Attack against Object Detection with Clean Annotation,"Yize Cheng, Wenbin Hu, Minhao Cheng",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10487"" target=""_blank"">2307.10487</a>",,2024-12-11
Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples,"Shaokui Wei, Mingda Zhang, Hongyuan Zha, Baoyuan Wu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10562"" target=""_blank"">2307.10562</a>",,2024-12-11
Rethinking Backdoor Attacks,"Alaa Khaddaj, Guillaume Leclerc, Aleksandar Makelov, Kristian Georgiev, Hadi Salman, Andrew Ilyas, Aleksander Madry",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10163"" target=""_blank"">2307.10163</a>",,2024-12-11
Towards Building More Robust Models with Frequency Bias,"Qingwen Bu, Dong Huang, Heming Cui",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.09763"" target=""_blank"">2307.09763</a>",,2024-12-11
Reinforcing POD based model reduction techniques in reaction-diffusion complex networks using stochastic filtering and pattern recognition,"Abhishek Ajayakumar, Soumyendu Raha",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.09762"" target=""_blank"">2307.09762</a>",,2024-12-11
FedDefender: Client-Side Attack-Tolerant Federated Learning,"Sungwon Park, Sungwon Han, Fangzhao Wu, Sundong Kim, Bin Zhu, Xing Xie, Meeyoung Cha",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.09048"" target=""_blank"">2307.09048</a>",,2024-12-11
Can Neural Network Memorization Be Localized? (4%),"Pratyush Maini, Michael C. Mozer, Hanie Sedghi, Zachary C. Lipton, J. Zico Kolter, Chiyuan Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.09542"" target=""_blank"">2307.09542</a>",,2024-12-11
Analyzing the Impact of Adversarial Examples on Explainable Machine Learning,"Prathyusha Devabhakthini, Sasmita Parida, Raj Mani Shukla, Suvendu Chandan Nayak",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08327"" target=""_blank"">2307.08327</a>",,2024-12-11
Adversarial Attacks on Traffic Sign Recognition: A Survey,"Svetlana Pavlitska, Nico Lambing, J. Marius ZÃ¶llner",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08278"" target=""_blank"">2307.08278</a>",,2024-12-11
Discretization-based ensemble model for robust learning in IoT,"Anahita Namvar, Chandra Thapa, Salil S. Kanhere",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08955"" target=""_blank"">2307.08955</a>",,2024-12-11
Unstoppable Attack: Label-Only Model Inversion via Conditional Diffusion Model,"Rongke Liu, Dong Wang, Yizhi Ren, Zhen Wang, Kaitian Guo, Qianqian Qin, Xiaolei Liu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08424"" target=""_blank"">2307.08424</a>",,2024-12-11
Runtime Stealthy Perception Attacks against DNN-based Adaptive Cruise Control Systems,"Xugui Zhou, Anqi Chen, Maxfield Kouzel, Haotian Ren, Morgan McCarty, Cristina Nita-Rotaru, Homa Alemzadeh",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08939"" target=""_blank"">2307.08939</a>",,2024-12-11
On the Fly Neural Style Smoothing for Risk-Averse Domain Generalization,"Akshay Mehra, Yunbei Zhang, Bhavya Kailkhura, Jihun Hamm",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08551"" target=""_blank"">2307.08551</a>",,2024-12-11
Malware Resistant Data Protection in Hyper-connected Networks: A survey,"Jannatul Ferdous, Rafiqul Islam, Maumita Bhattacharya, Md Zahidul Islam",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13164"" target=""_blank"">2307.13164</a>",,2024-12-11
A Machine Learning based Empirical Evaluation of Cyber Threat Actors High Level Attack Patterns over Low level Attack Patterns in Attributing Attacks,"Umara Noor, Sawera Shahid, Rimsha Kanwal, Zahid Rashid",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10252"" target=""_blank"">2307.10252</a>",,2024-12-11
PATROL: Privacy-Oriented Pruning for Collaborative Inference Against Model Inversion Attacks,"Shiwei Ding, Lan Zhang, Miao Pan, Xiaoyong Yuan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10981"" target=""_blank"">2307.10981</a>",,2024-12-11
CertPri: Certifiable Prioritization for Deep Neural Networks via Movement Cost in Feature Space,"Haibin Zheng, Jinyin Chen, Haibo Jin",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.09375"" target=""_blank"">2307.09375</a>",,2024-12-11
Improving Transferability of Adversarial Examples via Bayesian Attacks,"Qizhang Li, Yiwen Guo, Xiaochen Yang, Wangmeng Zuo, Hao Chen",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11334"" target=""_blank"">2307.11334</a>",,2024-12-11
Robust Automatic Speech Recognition via WavAugment Guided Phoneme Adversarial Training,"Gege Qi, Yuefeng Chen, Xiaofeng Mao, Xiaojun Jia, Ranjie Duan, Rong Zhang, Hui Xue",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12498"" target=""_blank"">2307.12498</a>",,2024-12-11
Investigating the Robustness of Sequential Recommender Systems Against Training Data Perturbations,"Filippo Betello, Federico Siciliano, Pushkar Mishra, Fabrizio Silvestri",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13165"" target=""_blank"">2307.13165</a>",,2024-12-11
Digital Twins for Moving Target Defense Validation in AC Microgrids,"Suman Rath, Subham Sahoo, Shamik Sengupta",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13152"" target=""_blank"">2307.13152</a>",,2024-12-11
A LLM Assisted Exploitation of AI-Guardian,Nicholas Carlini,arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15008"" target=""_blank"">2307.15008</a>",,2024-12-11
Towards Bridging the FL Performance-Explainability Trade-Off: A Trustworthy 6G RAN Slicing Use-Case,"Swastika Roy, Hatim Chergui, Christos Verikoukis",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12903"" target=""_blank"">2307.12903</a>",,2024-12-11
Learning Provably Robust Estimators for Inverse Problems via Jittering,"Anselm Krainovic, Mahdi Soltanolkotabi, Reinhard Heckel",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12822"" target=""_blank"">2307.12822</a>",,2024-12-11
Towards Generic and Controllable Attacks Against Object Detection,"Guopeng Li, Yue Xu, Jian Ding, Gui-Song Xia",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12342"" target=""_blank"">2307.12342</a>","<a href=""https://github.com/liguopeng0923/LGP"" target=""_blank"">liguopeng0923</a>",2024-12-11
Downstream-agnostic Adversarial Examples,"Ziqi Zhou, Shengshan Hu, Ruizhi Zhao, Qian Wang, Leo Yu Zhang, Junhui Hou, Hai Jin",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12280"" target=""_blank"">2307.12280</a>",,2024-12-11
Gradient-Based Word Substitution for Obstinate Adversarial Examples Generation in Language Models,"Yimu Wang, Peng Shi, Hongyang Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12507"" target=""_blank"">2307.12507</a>",,2024-12-11
A First Look at On-device Models in iOS Apps,"Han Hu, Yujin Huang, Qiuyuan Chen, Terry Tue Zhuo, Chunyang Chen",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12328"" target=""_blank"">2307.12328</a>",,2024-12-11
AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion Models,"Xuelong Dai, Kaisheng Liang, Bin Xiao",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12499"" target=""_blank"">2307.12499</a>",,2024-12-11
Backdoor Attacks against Voice Recognition Systems: A Survey,"Baochen Yan, Jiahe Lan, Zheng Yan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13643"" target=""_blank"">2307.13643</a>",,2024-12-11
Fast Adaptive Test-Time Defense with Robust Features,"Anurag Singh, Mahalakshmi Sabanayagam, Krikamol Muandet, Debarghya Ghoshdastidar",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11672"" target=""_blank"">2307.11672</a>",,2024-12-11
Unveiling Vulnerabilities in Interpretable Deep Learning Systems with Query-Efficient Black-box Attacks,"Eldor Abdukhamidov, Mohammed Abuhamad, Simon S. Woo, Eric Chan-Tin, Tamer Abuhmed",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11906"" target=""_blank"">2307.11906</a>",,2024-12-11
FMT: Removing Backdoor Feature Maps via Feature Map Testing in Deep Neural Networks,"Dong Huang, Qingwen Bu, Yahao Qing, Yichao Fu, Heming Cui",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11565"" target=""_blank"">2307.11565</a>",,2024-12-11
Improving Viewpoint Robustness for Visual Recognition via Adversarial Training,"Shouwei Ruan, Yinpeng Dong, Hang Su, Jianteng Peng, Ning Chen, Xingxing Wei",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11528"" target=""_blank"">2307.11528</a>",,2024-12-11
OUTFOX: LLM-generated Essay Detection through In-context Learning with Adversarially Generated Examples,"Ryuto Koike, Masahiro Kaneko, Naoaki Okazaki",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11729"" target=""_blank"">2307.11729</a>",,2024-12-11
Mitigating Communications Threats in Decentralized Federated Learning through Moving Target Defense,"Enrique TomÃ¡s MartÃ­nez BeltrÃ¡n, Pedro Miguel SÃ¡nchez SÃ¡nchez, Sergio LÃ³pez Bernal, GÃ©rÃ´me Bovet, Manuel Gil PÃ©rez, Gregorio MartÃ­nez PÃ©rez, Alberto Huertas CeldrÃ¡n",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11730"" target=""_blank"">2307.11730</a>",,2024-12-11
Cross Contrastive Feature Perturbation for Domain Generalization,"Chenming Li, Daoan Zhang, Wenjian Huang, Jianguo Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12502"" target=""_blank"">2307.12502</a>",,2024-12-11
HybridAugment++: Unified Frequency Spectra Perturbations for Model Robustness,"Mehmet Kerim Yucel, Ramazan Gokberk Cinbis, Pinar Duygulu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11823"" target=""_blank"">2307.11823</a>",,2024-12-11
PriSampler: Mitigating Property Inference of Diffusion Models,"Hailong Hu, Jun Pang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05208"" target=""_blank"">2306.05208</a>",,2024-12-11
Robust Framework for Explanation Evaluation in Time Series Classification,"Thu Trang Nguyen, Thach Le Nguyen, Georgiana Ifrim",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05501"" target=""_blank"">2306.05501</a>",,2024-12-11
Expanding Scope: Adapting English Adversarial Attacks to Chinese,"Hanyu Liu, Chengyuan Cai, Yanjun Qi",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04874"" target=""_blank"">2306.04874</a>",,2024-12-11
Extracting Cloud-based Model with Prior Knowledge,"Shiqian Zhao, Kangjie Chen, Meng Hao, Jian Zhang, Guowen Xu, Hongwei Li, Tianwei Zhang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04192"" target=""_blank"">2306.04192</a>",,2024-12-11
Open Set Relation Extraction via Unknown-Aware Training,"Jun Zhao, Xin Zhao, Wenyu Zhan, Qi Zhang, Tao Gui, Zhongyu Wei, Yunwen Chen, Xiang Gao, Xuanjing Huang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04950"" target=""_blank"">2306.04950</a>",,2024-12-11
Robustness Testing for Multi-Agent Reinforcement Learning: State Perturbations on Critical Agents,"Ziyuan Zhou, Guanjun Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06136"" target=""_blank"">2306.06136</a>",,2024-12-11
FedMLSecurity: A Benchmark for Attacks and Defenses in Federated Learning and LLMs,"Shanshan Han, Baturalp Buyukates, Zijian Hu, Han Jin, Weizhao Jin, Lichao Sun, Xiaoyang Wang, Chulin Xie, Kai Zhang, Qifan Zhang, Yuhui Zhang, Chaoyang He, Salman Avestimehr",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04959"" target=""_blank"">2306.04959</a>",,2024-12-11
Conservative Prediction via Data-Driven Confidence Minimization,"Caroline Choi, Fahim Tajwar, Yoonho Lee, Huaxiu Yao, Ananya Kumar, Chelsea Finn",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04974"" target=""_blank"">2306.04974</a>",,2024-12-11
Enhancing Robustness of AI Offensive Code Generators via Data Augmentation,"Cristina Improta, Pietro Liguori, Roberto Natella, Bojan Cukic, Domenico Cotroneo",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05079"" target=""_blank"">2306.05079</a>",,2024-12-11
Investigating the Effect of Misalignment on Membership Privacy in the White-box Setting,"Ana-Maria Cretu, Daniel Jones, Montjoye Yves-Alexandre de, Shruti Tople",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05093"" target=""_blank"">2306.05093</a>",,2024-12-11
Optimal Transport Model Distributional Robustness,"Van-Anh Nguyen, Trung Le, Anh Tuan Bui, Thanh-Toan Do, Dinh Phung",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04178"" target=""_blank"">2306.04178</a>",,2024-12-11
PromptAttack: Probing Dialogue State Trackers with Adversarial Prompts,"Xiangjue Dong, Yun He, Ziwei Zhu, James Caverlee",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04535"" target=""_blank"">2306.04535</a>",,2024-12-11
Transferable Adversarial Robustness for Categorical Data via Universal Robust Embeddings,"Klim Kireev, Maksym Andriushchenko, Carmela Troncoso, Nicolas Flammarion",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04064"" target=""_blank"">2306.04064</a>",,2024-12-11
PromptRobust: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts,"Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei Ye, Yue Zhang, Neil Zhenqiang Gong, Xing Xie",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04528"" target=""_blank"">2306.04528</a>",,2024-12-11
A Linearly Convergent GAN Inversion-based Algorithm for Reverse Engineering of Deceptions,"Darshan Thaker, Paris Giampouras, RenÃ© Vidal",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04756"" target=""_blank"">2306.04756</a>",,2024-12-11
Faithful Knowledge Distillation,"Tom A. Lamb, Rudy Brunel, Krishnamurthy DJ Dvijotham, M. Pawan Kumar, Philip H. S. Torr, Francisco Eiras",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04431"" target=""_blank"">2306.04431</a>",,2024-12-11
Divide and Repair: Using Options to Improve Performance of Imitation Learning Against Adversarial Demonstrations,Prithviraj Dasgupta,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04581"" target=""_blank"">2306.04581</a>",,2024-12-11
Can current NLI systems handle German word order? Investigating language model performance on a new German challenge set of minimal pairs,"Ines Reinig, Katja Markert",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04523"" target=""_blank"">2306.04523</a>","<a href=""https://github.com/ireinig/wogli"" target=""_blank"">ireinig</a>",2024-12-11
Adversarial Sample Detection Through Neural Network Transport Dynamics,"Skander Karkar, Patrick Gallinari, Alain Rakotomamonjy",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04252"" target=""_blank"">2306.04252</a>",,2024-12-11
Revisiting the Trade-off between Accuracy and Robustness via Weight Distribution of Filters,"Xingxing Wei, Shiji Zhao",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03430"" target=""_blank"">2306.03430</a>",,2024-12-11
Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations,"Torsten University of WÃ¼rzburg KrauÃ, Alexandra University of WÃ¼rzburg Dmitrienko",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03600"" target=""_blank"">2306.03600</a>",,2024-12-11
Adversarial attacks and defenses in explainable artificial intelligence: A survey,"Hubert Baniecki, Przemyslaw Biecek",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06123"" target=""_blank"">2306.06123</a>",,2024-12-11
Exploring Model Dynamics for Accumulative Poisoning Discovery,"Jianing Zhu, Xiawei Guo, Jiangchao Yao, Chao Du, Li He, Shuo Yuan, Tongliang Liu, Liang Wang, Bo Han",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03726"" target=""_blank"">2306.03726</a>","<a href=""https://github.com/tmlr-group/Memorization-Discrepancy"" target=""_blank"">tmlr-group</a>",2024-12-11
G$^2$uardFL: Safeguarding Federated Learning Against Backdoor Attacks through Attributed Client Graph Clustering,"Hao Yu, Chuan Ma, Meng Liu, Xinwang Liu, Zhe Liu, Ming Ding",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04984"" target=""_blank"">2306.04984</a>",,2024-12-11
Membership inference attack with relative decision boundary distance,"JiaCheng Xu, ChengXiang Tan",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04109"" target=""_blank"">2306.04109</a>",,2024-12-11
A Melting Pot of Evolution and Learning,"Moshe Sipper, Achiya Elyasaf, Tomer Halperin, Zvika Haramaty, Raz Lapid, Eyal Segal, Itai Tzruia, Snir Vitrack Tamam",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04971"" target=""_blank"">2306.04971</a>",,2024-12-11
Few-shot Multi-domain Knowledge Rearming for Context-aware Defence against Advanced Persistent Threats,"Gaolei Li, Yuanyuan Zhao, Wenqi Wei, Yuchen Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07685"" target=""_blank"">2306.07685</a>",,2024-12-11
Generalizable Lightweight Proxy for Robust NAS against Diverse Perturbations,"Hyeonjeong Ha, Minseon Kim, Sung Ju Hwang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05031"" target=""_blank"">2306.05031</a>",,2024-12-11
On the Robustness of Removal-Based Feature Attributions,"Chris Lin, Ian Covert, Su-In Lee",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07462"" target=""_blank"">2306.07462</a>",,2024-12-11
Adversarial Attacks and Defenses for Semantic Communication in Vehicular Metaverses,"Jiawen Kang, Jiayi He, Hongyang Du, Zehui Xiong, Zhaohui Yang, Xumin Huang, Shengli Xie",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03528"" target=""_blank"">2306.03528</a>",,2024-12-11
Revisiting and Advancing Adversarial Training Through A Simple Baseline,Hong Liu,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07613"" target=""_blank"">2306.07613</a>",,2024-12-11
Generative Watermarking Against Unauthorized Subject-Driven Image Synthesis,"Yihan Ma, Zhengyu Zhao, Xinlei He, Zheng Li, Michael Backes, Yang Zhang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07754"" target=""_blank"">2306.07754</a>",,2024-12-11
Privacy Inference-Empowered Stealthy Backdoor Attack on Federated Learning under Non-IID Scenarios,"Haochen Mei, Gaolei Li, Jun Wu, Longfei Zheng",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08011"" target=""_blank"">2306.08011</a>",,2024-12-11
DHBE: Data-free Holistic Backdoor Erasing in Deep Neural Networks via Restricted Adversarial Distillation,"Zhicong Yan, Shenghong Li, Ruijie Zhao, Yuan Tian, Yuanyuan Zhao",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08009"" target=""_blank"">2306.08009</a>","<a href=""https://github.com/yanzhicong/DHBE"" target=""_blank"">yanzhicong</a>",2024-12-11
Temporal Gradient Inversion Attacks with Robust Optimization,"Bowen Li, Hanlin Gu, Ruoxin Chen, Jie Li, Chentao Wu, Na Ruan, Xueming Si, Lixin Fan",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07883"" target=""_blank"">2306.07883</a>",,2024-12-11
When Vision Fails: Text Attacks Against ViT and OCR,"Nicholas Boucher, Jenny Blessing, Ilia Shumailov, Ross Anderson, Nicolas Papernot",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07033"" target=""_blank"">2306.07033</a>",,2024-12-11
AROID: Improving Adversarial Robustness Through Online Instance-Wise Data Augmentation,"Lin Li, Jianing Qiu, Michael Spratling",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07197"" target=""_blank"">2306.07197</a>","<a href=""https://github.com/TreeLLi/AROID"" target=""_blank"">TreeLLi</a>",2024-12-11
How robust accuracy suffers from certified training with convex relaxations,"Bartolomeis Piersilvio De, Jacob Clarysse, Amartya Sanyal, Fanny Yang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06995"" target=""_blank"">2306.06995</a>",,2024-12-11
Graph Agent Network: Empowering Nodes with Decentralized Communications Capabilities for Adversarial Resilience,"Ao Liu, Wenshan Li, Tao Li, Beibei Li, Guangquan Xu, Pan Zhou, Wengang Ma, Hanyuan Huang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06909"" target=""_blank"">2306.06909</a>",,2024-12-11
Frequency-Based Vulnerability Analysis of Deep Learning Models against Image Corruptions,"Harshitha Machiraju, Michael H. Herzog, Pascal Frossard",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07178"" target=""_blank"">2306.07178</a>",,2024-12-11
VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion Models,"Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06874"" target=""_blank"">2306.06874</a>",,2024-12-11
COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in Language Models,"Zihao Tan, Qingliang Chen, Wenbin Zhu, Yongjian Huang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05659"" target=""_blank"">2306.05659</a>",,2024-12-11
Securing Visually-Aware Recommender Systems: An Adversarial Image Reconstruction and Detection Framework,"Minglei Yin, Bin Liu, Neil Zhenqiang Gong, Xin Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07992"" target=""_blank"">2306.07992</a>",,2024-12-11
Neural Architecture Design and Robustness: A Dataset,"Steffen Jung, Jovita Lukasik, Margret Keuper",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06712"" target=""_blank"">2306.06712</a>",,2024-12-11
TrojLLM: A Black-box Trojan Prompt Attack on Large Language Models,"Jiaqi Xue, Mengxin Zheng, Ting Hua, Yilin Shen, Yepeng Liu, Ladislau Boloni, Qian Lou",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06815"" target=""_blank"">2306.06815</a>","<a href=""https://github.com/UCF-ML-Research/TrojLLM"" target=""_blank"">UCF-ML-Research</a>",2024-12-11
Boosting Adversarial Robustness using Feature Level Stochastic Smoothing,"Sravanti Addepalli, Samyak Jain, Gaurang Sriramanan, R. Venkatesh Babu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06462"" target=""_blank"">2306.06462</a>",,2024-12-11
NeRFool: Uncovering the Vulnerability of Generalizable Neural Radiance Fields against Adversarial Perturbations,"Yonggan Fu, Ye Yuan, Souvik Kundu, Shang Wu, Shunyao Zhang, Yingyan Lin",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06359"" target=""_blank"">2306.06359</a>","<a href=""https://github.com/GATECH-EIC/NeRFool"" target=""_blank"">GATECH-EIC</a>",2024-12-11
The Defense of Networked Targets in General Lotto games,"Adel Aghajan, Keith Paarporn, Jason R. Marden",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06485"" target=""_blank"">2306.06485</a>",,2024-12-11
Detecting Adversarial Directions in Deep Reinforcement Learning to Make Robust Decisions,"Ezgi Korkmaz, Jonah Brown-Cohen",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05873"" target=""_blank"">2306.05873</a>",,2024-12-11
When Authentication Is Not Enough: On the Security of Behavioral-Based Driver Authentication Systems,"Emad Efatinasab, Francesco Marchiori, Denis Donadel, Alessandro Brighente, Mauro Conti",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05923"" target=""_blank"">2306.05923</a>",,2024-12-11
Overcoming Adversarial Attacks for Human-in-the-Loop Applications,"Ryan McCoppin, Marla Kennedy, Platon Lukyanenko, Sean Kennedy",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05952"" target=""_blank"">2306.05952</a>",,2024-12-11
Adversarial Evasion Attacks Practicality in Networks: Testing the Impact of Dynamic Learning,"Mohamed el Shehaby, Ashraf Matrawy",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05494"" target=""_blank"">2306.05494</a>",,2024-12-11
Boosting Adversarial Transferability by Achieving Flat Local Maxima,"Zhijin Ge, Hongying Liu, Xiaosen Wang, Fanhua Shang, Yuanyuan Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05225"" target=""_blank"">2306.05225</a>","<a href=""https://github.com/Trustworthy-AI-Group/PGN"" target=""_blank"">Trustworthy-AI-Group</a>",2024-12-11
Performance-optimized deep neural networks are evolving into worse models of inferotemporal visual cortex,"Drew Linsley, Ivan F. Rodriguez, Thomas Fel, Michael Arcaro, Saloni Sharma, Margaret Livingstone, Thomas Serre",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03779"" target=""_blank"">2306.03779</a>",,2024-12-11
Graph-based methods coupled with specific distributional distances for adversarial attack detection,"Dwight Nwaigwe, Lucrezia Carboni, Martial Mermillod, Sophie Achard, Michel Dojat",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00042"" target=""_blank"">2306.00042</a>",,2024-12-11
Adversarial alignment: Breaking the trade-off between the strength of an attack and its relevance to human perception,"Drew Linsley, Pinyuan Feng, Thibaut Boissin, Alekh Karkada Ashok, Thomas Fel, Stephanie Olaiya, Thomas Serre",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03229"" target=""_blank"">2306.03229</a>",,2024-12-11
Adversarial Robustness in Unsupervised Machine Learning: A Systematic Review,"Mathias Lundteigen Mohus, Jinyue Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00687"" target=""_blank"">2306.00687</a>",,2024-12-11
VoteTRANS: Detecting Adversarial Text without Training by Voting on Hard Labels of Transformations,"Hoang-Quoc Nguyen-Son, Seira Hidano, Kazuhide Fukushima, Shinsaku Kiyomoto, Isao Echizen",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01273"" target=""_blank"">2306.01273</a>",,2024-12-11
Unlearnable Examples for Diffusion Models: Protect Data from Unauthorized Exploitation,"Zhengyue Zhao, Jinhao Duan, Xing Hu, Kaidi Xu, Chenan Wang, Rui Zhang, Zidong Du, Qi Guo, Yunji Chen",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01902"" target=""_blank"">2306.01902</a>",,2024-12-11
MutateNN: Mutation Testing of Image Recognition Models Deployed on Hardware Accelerators,"Nikolaos Louloudakis, Perry Gibson, JosÃ© Cano, Ajitha Rajan",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01697"" target=""_blank"">2306.01697</a>",,2024-12-11
Towards Robust GAN-generated Image Detection: a Multi-view Completion Representation,"Chi Liu, Tianqing Zhu, Sheng Shen, Wanlei Zhou",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01364"" target=""_blank"">2306.01364</a>",,2024-12-11
Improving the generalizability and robustness of large-scale traffic signal control,"Tianyu Shi, Francois-Xavier Devailly, Denis Larocque, Laurent Charlin",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01925"" target=""_blank"">2306.01925</a>",,2024-12-11
Adversarial Attack Based on Prediction-Correction,"Chen Wan, Fangjun Huang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01809"" target=""_blank"">2306.01809</a>",,2024-12-11
Constructing Semantics-Aware Adversarial Examples with Probabilistic Perspective,"Andi Zhang, Damon Wischik",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00353"" target=""_blank"">2306.00353</a>",,2024-12-11
Reconstruction Distortion of Learned Image Compression with Imperceptible Perturbations,"Yang Sui, Zhuohang Li, Ding Ding, Xiang Pan, Xiaozhong Xu, Shan Liu, Zhenzhong Chen",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01125"" target=""_blank"">2306.01125</a>",,2024-12-11
Intriguing Properties of Text-guided Diffusion Models,"Qihao Liu, Adam Kortylewski, Yutong Bai, Song Bai, Alan Yuille",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00974"" target=""_blank"">2306.00974</a>",,2024-12-11
"Versatile Backdoor Attack with Visible, Semantic, Sample-Specific, and Compatible Triggers","Ruotong Wang, Hongrui Chen, Zihao Zhu, Li Liu, Baoyuan Wu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00816"" target=""_blank"">2306.00816</a>",,2024-12-11
Improving the Robustness of Summarization Systems with Dual Augmentation,"Xiuying Chen, Guodong Long, Chongyang Tao, Mingzhe Li, Xin Gao, Chengqi Zhang, Xiangliang Zhang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01090"" target=""_blank"">2306.01090</a>",,2024-12-11
Does Black-box Attribute Inference Attacks on Graph Neural Networks Constitute Privacy Risk? (13%),"Iyiola E. Olatunji, Anmar Hizber, Oliver Sihlovec, Megha Khosla",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00578"" target=""_blank"">2306.00578</a>",,2024-12-11
Evading Black-box Classifiers Without Breaking Eggs,"Edoardo Debenedetti, Nicholas Carlini, Florian TramÃ¨r",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02895"" target=""_blank"">2306.02895</a>",,2024-12-11
CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV Perception,"Jiachen Sun, Haizhong Zheng, Qingzhao Zhang, Atul Prakash, Z. Morley Mao, Chaowei Xiao",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00349"" target=""_blank"">2306.00349</a>",,2024-12-11
ModelObfuscator: Obfuscating Model Information to Protect Deployed ML-based Systems,"Mingyi Zhou, Xiang Gao, Jing Wu, John Grundy, Xiao Chen, Chunyang Chen, Li Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06112"" target=""_blank"">2306.06112</a>","<a href=""https://github.com/zhoumingyi/ModelObfuscator"" target=""_blank"">zhoumingyi</a>",2024-12-11
Adversarial-Aware Deep Learning System based on a Secondary Classical Machine Learning Verification Approach,"Mohammed Alkhowaiter, Hisham Kholidy, Mnassar Alyami, Abdulmajeed Alghamdi, Cliff Zou",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00314"" target=""_blank"">2306.00314</a>",,2024-12-11
Trustworthy Sensor Fusion against Inaudible Command Attacks in Advanced Driver-Assistance System,"Jiwei Guan, Lei Pan, Chen Wang, Shui Yu, Longxiang Gao, Xi Zheng",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05358"" target=""_blank"">2306.05358</a>",,2024-12-11
Trainable and Explainable Simplicial Map Neural Networks,"Eduardo Paluzo-Hidalgo, Miguel A. GutiÃ©rrez-Naranjo, Rocio Gonzalez-Diaz",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00010"" target=""_blank"">2306.00010</a>",,2024-12-11
Adversarial Attack On Yolov5 For Traffic And Road Sign Detection,Sanyam Jain,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06071"" target=""_blank"">2306.06071</a>",,2024-12-11
Rapid Plug-in Defenders,"Kai Wu, Yujian Betterest Li, Jian Lou, Xiaoyu Zhang, Handing Wang, Jing Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01762"" target=""_blank"">2306.01762</a>",,2024-12-11
DeepSeaNet: Improving Underwater Object Detection using EfficientDet,Sanyam Jain,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06075"" target=""_blank"">2306.06075</a>",,2024-12-11
CARSO: Counter-Adversarial Recall of Synthetic Observations,"Emanuele Ballarin, Alessio Ansuini, Luca Bortolussi",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06081"" target=""_blank"">2306.06081</a>","<a href=""https://github.com/emaballarin/CARSO"" target=""_blank"">emaballarin</a>",2024-12-11
Adversarial Attacks on Leakage Detectors in Water Distribution Networks,"Paul Stahlhofen, AndrÃ© Artelt, Luca Hermes, Barbara Hammer",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06107"" target=""_blank"">2306.06107</a>",,2024-12-11
Backdoor Attack with Sparse and Invisible Trigger,"Yinghua Gao, Yiming Li, Xueluan Gong, Shu-Tao Xia, Qian Wang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06209"" target=""_blank"">2306.06209</a>","<a href=""https://github.com/YinghuaGao/SIBA"" target=""_blank"">YinghuaGao</a>",2024-12-11
Covert Communication Based on the Poisoning Attack in Federated Learning,"Junchuan Liang, Rong Wang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01342"" target=""_blank"">2306.01342</a>",,2024-12-11
Improving Adversarial Robustness of DEQs with Explicit Regulations Along the Neural Dynamics,"Zonghan Yang, Peng Li, Tianyu Pang, Yang Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01435"" target=""_blank"">2306.01435</a>",,2024-12-11
Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations,"Dou Hu, Yinan Bao, Lingwei Wei, Wei Zhou, Songlin Hu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01505"" target=""_blank"">2306.01505</a>",,2024-12-11
Robust low-rank training via approximate orthonormal constraints,"Dayana Savostianova, Emanuele Zangrando, Gianluca Ceruti, Francesco Tudisco",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01485"" target=""_blank"">2306.01485</a>",,2024-12-11
Evaluating robustness of support vector machines with the Lagrangian dual approach,"Yuting Liu, Hong Gu, Pan Qin",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02639"" target=""_blank"">2306.02639</a>",,2024-12-11
A Robust Likelihood Model for Novelty Detection,"Ranya Almohsen, Shivang Patel, Donald A. Adjeroh, Gianfranco Doretto",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03331"" target=""_blank"">2306.03331</a>",,2024-12-11
Adversarial Ink: Componentwise Backward Error Attacks on Deep Learning,"Lucas Beerens, Desmond J. Higham",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02918"" target=""_blank"">2306.02918</a>",,2024-12-11
Enhance Diffusion to Improve Robust Generalization,"Jianhui Sun, Sanchit Sinha, Aidong Zhang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02618"" target=""_blank"">2306.02618</a>",,2024-12-11
KNOW How to Make Up Your Mind! Adversarially Detecting and Alleviating Inconsistencies in Natural Language Explanations,"Myeongjun Jang, Bodhisattwa Prasad Majumder, Julian McAuley, Thomas Lukasiewicz, Oana-Maria Camburu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02980"" target=""_blank"">2306.02980</a>",,2024-12-11
Stable Diffusion is Unstable,"Chengbin Du, Yanxi Li, Zhongwei Qiu, Chang Xu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02583"" target=""_blank"">2306.02583</a>",,2024-12-11
Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization,"Yibing Liu, Chris Xing Tian, Haoliang Li, Lei Ma, Shiqi Wang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02879"" target=""_blank"">2306.02879</a>",,2024-12-11
Security Knowledge-Guided Fuzzing of Deep Learning Libraries,"Nima Shiri Harzevili, Hung Viet Pham, Song Wang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03269"" target=""_blank"">2306.03269</a>",,2024-12-11
Input-gradient space particle inference for neural network ensembles,"Trung Trinh, Markus Heinonen, Luigi Acerbi, Samuel Kaski",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02775"" target=""_blank"">2306.02775</a>",,2024-12-11
Adversary for Social Good: Leveraging Adversarial Attacks to Protect Personal Attribute Privacy,"Xiaoting Li, Lingwei Chen, Dinghao Wu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02488"" target=""_blank"">2306.02488</a>",,2024-12-11
Aerial Swarm Defense using Interception and Herding Strategies,"Vishnu S. Chipade, Dimitra Panagou",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02482"" target=""_blank"">2306.02482</a>",,2024-12-11
Towards Black-box Adversarial Example Detection: A Data Reconstruction-based Method,"Yifei Gao, Zhiyu Lin, Yunfan Yang, Jitao Sang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02021"" target=""_blank"">2306.02021</a>",,2024-12-11
Learning to Defend by Attacking (and Vice-Versa): Transfer of Learning in Cybersecurity Games,"Tyler Malloy, Cleotilde Gonzalez",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02165"" target=""_blank"">2306.02165</a>",,2024-12-11
Can Directed Graph Neural Networks be Adversarially Robust? (56%),"Zhichao Hou, Xitong Zhang, Wei Wang, Charu C. Aggarwal, Xiaorui Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02002"" target=""_blank"">2306.02002</a>",,2024-12-11
Flew Over Learning Trap: Learn Unlearnable Samples by Progressive Staged Training,"Pucheng Dang, Xing Hu, Kaidi Xu, Jinhao Duan, Di Huang, Husheng Han, Rui Zhang, Zidong Du, Qi Guo, Yunji Chen",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02064"" target=""_blank"">2306.02064</a>",,2024-12-11
Benchmarking Robustness of Adaptation Methods on Pre-trained Vision-Language Models,"Shuo Chen, Jindong Gu, Zhen Han, Yunpu Ma, Philip Torr, Volker Tresp",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02080"" target=""_blank"">2306.02080</a>","<a href=""https://adarobustness.github.io"" target=""_blank""></a>",2024-12-11
Towards Understanding Clean Generalization and Robust Overfitting in Adversarial Training,"Binghui Li, Yuanzhi Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01271"" target=""_blank"">2306.01271</a>",,2024-12-11
A Closer Look at the Adversarial Robustness of Deep Equilibrium Models,"Zonghan Yang, Tianyu Pang, Yang Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01429"" target=""_blank"">2306.01429</a>",,2024-12-11
Area is all you need: repeatable elements make stronger adversarial attacks,Dillon Niederhut,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07768"" target=""_blank"">2306.07768</a>",,2024-12-11
Adaptive Attractors: A Defense Strategy against ML Adversarial Collusion Attacks,"Jiyi Zhang, Han Fang, Ee-Chien Chang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01400"" target=""_blank"">2306.01400</a>",,2024-12-11
Poisoning Network Flow Classifiers,"Giorgio Severi, Simona Boboila, Alina Oprea, John Holodnak, Kendra Kratkiewicz, Jason Matterer",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01655"" target=""_blank"">2306.01655</a>",,2024-12-11
Hyperparameter Learning under Data Poisoning: Analysis of the Influence of Regularization via Multiobjective Bilevel Optimization,"Javier Carnerero-Cano, Luis MuÃ±oz-GonzÃ¡lez, Phillippa Spencer, Emil C. Lupu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01613"" target=""_blank"">2306.01613</a>",,2024-12-11
Invisible Image Watermarks Are Provably Removable Using Generative AI,"Xuandong Zhao, Kexun Zhang, Zihao Su, Saastha Vasan, Ilya Grishchenko, Christopher Kruegel, Giovanni Vigna, Yu-Xiang Wang, Lei Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01953"" target=""_blank"">2306.01953</a>","<a href=""https://github.com/XuandongZhao/WatermarkAttacker"" target=""_blank"">XuandongZhao</a>",2024-12-11
Malafide: a novel adversarial convolutive noise attack against deepfake and spoofing detection systems,"Michele Panariello, Wanying Ge, Hemlata Tak, Massimiliano Todisco, Nicholas Evans",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07655"" target=""_blank"">2306.07655</a>",,2024-12-11
A Spectral Perspective towards Understanding and Improving Adversarial Robustness,"Binxiao Huang, Rui Lin, Chaofan Tao, Ngai Wong",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14262"" target=""_blank"">2306.14262</a>",,2024-12-11
Robustness of SAM: Segment Anything Under Corruptions and Beyond,"Yu Qiao, Chaoning Zhang, Taegoo Kang, Donghun Kim, Chenshuang Zhang, Choong Seon Hong",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07713"" target=""_blank"">2306.07713</a>",,2024-12-11
Boosting Model Inversion Attacks with Adversarial Examples,"Shuai Zhou, Tianqing Zhu, Dayong Ye, Xin Yu, Wanlei Zhou",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13965"" target=""_blank"">2306.13965</a>",,2024-12-11
The race to robustness: exploiting fragile models for urban camouflage and the imperative for machine learning security,"Harriet Farlow, Matthew Garratt, Gavin Mount, Tim Lynar",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14609"" target=""_blank"">2306.14609</a>",,2024-12-11
3D-Aware Adversarial Makeup Generation for Facial Privacy Protection,"Yueming Lyu, Yue Jiang, Ziwen He, Bo Peng, Yunfan Liu, Jing Dong",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14640"" target=""_blank"">2306.14640</a>",,2024-12-11
Towards Sybil Resilience in Decentralized Learning,"Thomas Werthenbach, Johan Pouwelse",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15044"" target=""_blank"">2306.15044</a>",,2024-12-11
On the Resilience of Machine Learning-Based IDS for Automotive Networks,"Ivo Zenden, Han Wang, Alfonso Iacovazzi, Arash Vahidi, Rolf Blom, Shahid Raza",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14782"" target=""_blank"">2306.14782</a>",,2024-12-11
DSRM: Boost Textual Adversarial Training with Distribution Shift Risk Minimization,"Songyang Gao, Shihan Dou, Yan Liu, Xiao Wang, Qi Zhang, Zhongyu Wei, Jin Ma, Ying Shan",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15164"" target=""_blank"">2306.15164</a>",,2024-12-11
PWSHAP: A Path-Wise Explanation Model for Targeted Variables,"Lucile Ter-Minassian, Oscar Clivio, Karla Diaz-Ordaz, Robin J. Evans, Chris Holmes",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14672"" target=""_blank"">2306.14672</a>",,2024-12-11
On Evaluating the Adversarial Robustness of Semantic Segmentation Models,"Levente Halmosi, Mark Jelasity",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14217"" target=""_blank"">2306.14217</a>",,2024-12-11
Robust Spatiotemporal Traffic Forecasting with Reinforced Dynamic Adversarial Training,"Fan Liu, Weijia Zhang, Hao Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14126"" target=""_blank"">2306.14126</a>","<a href=""https://github.com/usail-hkust/RDAT"" target=""_blank"">usail-hkust</a>",2024-12-11
Enhancing Adversarial Training via Reweighting Optimization Trajectory,"Tianjin Huang, Shiwei Liu, Tianlong Chen, Meng Fang, Li Shen, Vlaod Menkovski, Lu Yin, Yulong Pei, Mykola Pechenizkiy",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14275"" target=""_blank"">2306.14275</a>",,2024-12-11
RobuT: A Systematic Study of Table QA Robustness Against Human-Annotated Adversarial Perturbations,"Yilun Zhao, Chen Zhao, Linyong Nan, Zhenting Qi, Wenlin Zhang, Xiangru Tang, Boyu Mi, Dragomir Radev",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14321"" target=""_blank"">2306.14321</a>","<a href=""https://github.com/yilunzhao/RobuT"" target=""_blank"">yilunzhao</a>",2024-12-11
Computational Asymmetries in Robust Classification,"Samuele Marro, Michele Lombardi",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14326"" target=""_blank"">2306.14326</a>",,2024-12-11
Machine Learning needs Better Randomness Standards: Randomised Smoothing and PRNG-based attacks,"Pranav Dahiya, Ilia Shumailov, Ross Anderson",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14043"" target=""_blank"">2306.14043</a>",,2024-12-11
Towards Reliable Evaluation and Fast Training of Robust Semantic Segmentation Models,"Francesco Croce, Naman D Singh, Matthias Hein",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12941"" target=""_blank"">2306.12941</a>","<a href=""https://github.com/nmndeep/robust-segmentation"" target=""_blank"">nmndeep</a>",2024-12-11
Similarity Preserving Adversarial Graph Contrastive Learning,"Yeonjun In, Kanghoon Yoon, Chanyoung Park",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13854"" target=""_blank"">2306.13854</a>","<a href=""https://github.com/yeonjun-in/torch-SP-AGCL"" target=""_blank"">yeonjun-in</a>",2024-12-11
Weighted Automata Extraction and Explanation of Recurrent Neural Networks for Natural Language Tasks,"Zeming Wei, Xiyue Zhang, Yihao Zhang, Meng Sun",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14040"" target=""_blank"">2306.14040</a>",,2024-12-11
Creating Valid Adversarial Examples of Malware,"MatouÅ¡ KozÃ¡k, Martin JureÄek, Mark Stamp, Troia Fabio Di",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13587"" target=""_blank"">2306.13587</a>",,2024-12-11
Adversarial Robustness Certification for Bayesian Neural Networks,"Matthew Wicker, Andrea Patane, Luca Laurenti, Marta Kwiatkowska",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13614"" target=""_blank"">2306.13614</a>",,2024-12-11
A First Order Meta Stackelberg Method for Robust Federated Learning,"Yunian Pan, Tao Li, Henger Li, Tianyi Xu, Zizhan Zheng, Quanyan Zhu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13800"" target=""_blank"">2306.13800</a>",,2024-12-11
Visual Adversarial Examples Jailbreak Large Language Models,"Xiangyu Qi, Kaixuan Huang, Ashwinee Panda, Mengdi Wang, Prateek Mittal",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13213"" target=""_blank"">2306.13213</a>",,2024-12-11
Towards quantum enhanced adversarial robustness in machine learning,"Maxwell T. West, Shu-Lok Tsang, Jia S. Low, Charles D. Hill, Christopher Leckie, Lloyd C. L. Hollenberg, Sarah M. Erfani, Muhammad Usman",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12688"" target=""_blank"">2306.12688</a>",,2024-12-11
Rethinking the Backward Propagation for Adversarial Transferability,"Xiaosen Wang, Kangheng Tong, Kun He",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12685"" target=""_blank"">2306.12685</a>","<a href=""https://github.com/Trustworthy-AI-Group/RPA"" target=""_blank"">Trustworthy-AI-Group</a>",2024-12-11
Evading Forensic Classifiers with Attribute-Conditioned Adversarial Faces,"Fahad Shamshad, Koushik Srivatsan, Karthik Nandakumar",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13091"" target=""_blank"">2306.13091</a>","<a href=""https://github.com/koushiksrivats/face_attribute_attack"" target=""_blank"">koushiksrivats</a>",2024-12-11
Adversarial Resilience in Sequential Prediction via Abstention,"Surbhi Goel, Steve Hanneke, Shay Moran, Abhishek Shetty",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13119"" target=""_blank"">2306.13119</a>",,2024-12-11
Document Image Cleaning using Budget-Aware Black-Box Approximation,"Ganesh Tata, Katyani Singh, Oeveren Eric Van, Nilanjan Ray",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13236"" target=""_blank"">2306.13236</a>",,2024-12-11
Are aligned neural networks adversarially aligned? (99%),"Nicholas Carlini, Milad Nasr, Christopher A. Choquette-Choo, Matthew Jagielski, Irena Gao, Anas Awadalla, Pang Wei Koh, Daphne Ippolito, Katherine Lee, Florian Tramer, Ludwig Schmidt",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15447"" target=""_blank"">2306.15447</a>",,2024-12-11
On the Universal Adversarial Perturbations for Efficient Data-free Adversarial Detection,"Songyang Gao, Shihan Dou, Qi Zhang, Xuanjing Huang, Jin Ma, Ying Shan",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15705"" target=""_blank"">2306.15705</a>",,2024-12-11
Shilling Black-box Review-based Recommender Systems through Fake Review Generation,"Hung-Yun Chiang, Yi-Syuan Chen, Yun-Zhu Song, Hong-Han Shuai, Jason S. Chang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16526"" target=""_blank"">2306.16526</a>",,2024-12-11
Catch Me If You Can: A New Low-Rate DDoS Attack Strategy Disguised by Feint,"Tianyang Cai, Yuqi Li, Tao Jia, Leo Yu Zhang, Zheng Yang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15248"" target=""_blank"">2306.15248</a>",,2024-12-11
I See Dead People: Gray-Box Adversarial Attack on Image-To-Text Models,"Raz Lapid, Moshe Sipper",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07591"" target=""_blank"">2306.07591</a>",,2024-12-11
Defense against Adversarial Cloud Attack on Remote Sensing Salient Object Detection,"Huiming Sun, Lan Fu, Jinlong Li, Qing Guo, Zibo Meng, Tianyun Zhang, Yuewei Lin, Hongkai Yu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.17431"" target=""_blank"">2306.17431</a>",,2024-12-11
Efficient Backdoor Removal Through Natural Gradient Fine-tuning,"Nazmul Karim, Abdullah Al Arafat, Umar Khalid, Zhishan Guo, Naznin Rahnavard",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.17441"" target=""_blank"">2306.17441</a>",,2024-12-11
Post-train Black-box Defense via Bayesian Boundary Correction,"He Wang, Yunfeng Diao",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16979"" target=""_blank"">2306.16979</a>",,2024-12-11
Towards Optimal Randomized Strategies in Adversarial Example Game,"Jiahao Xie, Chao Zhang, Weijie Liu, Wensong Bai, Hui Qian",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16738"" target=""_blank"">2306.16738</a>",,2024-12-11
Neural Polarizer: A Lightweight and Effective Backdoor Defense via Purifying Poisoned Features,"Mingli Zhu, Shaokui Wei, Hongyuan Zha, Baoyuan Wu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16697"" target=""_blank"">2306.16697</a>",,2024-12-11
NeuralFuse: Learning to Recover the Accuracy of Access-Limited Neural Network Inference in Low-Voltage Regimes,"Hao-Lun Sun, Lei Hsiung, Nandhini Chandramoorthy, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16869"" target=""_blank"">2306.16869</a>","<a href=""https://github.com/IBM/NeuralFuse"" target=""_blank"">IBM</a>",2024-12-11
Boosting Adversarial Transferability with Learnable Patch-wise Masks,"Xingxing Wei, Shiji Zhao",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15931"" target=""_blank"">2306.15931</a>",,2024-12-11
Evaluating Similitude and Robustness of Deep Image Denoising Models via Adversarial Attack,"Jie Ning, Yao Li, Zhichang Guo",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16050"" target=""_blank"">2306.16050</a>",,2024-12-11
Mitigating Accuracy-Robustness Trade-off via Balanced Multi-Teacher Adversarial Distillation,"Shiji Zhao, Xizhe Wang, Xingxing Wei",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16170"" target=""_blank"">2306.16170</a>",,2024-12-11
Group-based Robustness: A General Framework for Customized Robustness in the Real World,"Weiran Lin, Keane Lucas, Neo Eyal, Lujo Bauer, Michael K. Reiter, Mahmood Sharif",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16614"" target=""_blank"">2306.16614</a>",,2024-12-11
Distributional Modeling for Location-Aware Adversarial Patches,"Xingxing Wei, Shouwei Ruan, Yinpeng Dong, Hang Su",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16131"" target=""_blank"">2306.16131</a>",,2024-12-11
Enrollment-stage Backdoor Attacks on Speaker Recognition Systems via Adversarial Ultrasound,"Xinfeng Li, Junning Ze, Chen Yan, Yushi Cheng, Xiaoyu Ji, Wenyuan Xu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16022"" target=""_blank"">2306.16022</a>",,2024-12-11
Does Saliency-Based Training bring Robustness for Deep Neural Networks in Image Classification? (93%),Ali Karkehabadi,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16581"" target=""_blank"">2306.16581</a>",,2024-12-11
On Practical Aspects of Aggregation Defenses against Data Poisoning Attacks,"Wenxiao Wang, Soheil Feizi",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16415"" target=""_blank"">2306.16415</a>",,2024-12-11
On the Exploitability of Instruction Tuning,"Manli Shu, Jiongxiao Wang, Chen Zhu, Jonas Geiping, Chaowei Xiao, Tom Goldstein",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.17194"" target=""_blank"">2306.17194</a>","<a href=""https://github.com/azshue/AutoPoison"" target=""_blank"">azshue</a>",2024-12-11
Advancing Adversarial Training by Injecting Booster Signal,"Hong Joo Lee, Youngjoon Yu, Yong Man Ro",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15451"" target=""_blank"">2306.15451</a>",,2024-12-11
IMPOSITION: Implicit Backdoor Attack through Scenario Injection,"Mozhgan Pourkeshavarz, Mohammad Sabokrou, Amir Rasouli",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15755"" target=""_blank"">2306.15755</a>",,2024-12-11
"Adversarial Training for Graph Neural Networks: Pitfalls, Solutions, and New Directions","Lukas Gosch, Simon Geisler, Daniel Sturm, Bertrand Charpentier, Daniel ZÃ¼gner, Stephan GÃ¼nnemann",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15427"" target=""_blank"">2306.15427</a>",,2024-12-11
Robust Proxy: Improving Adversarial Robustness by Robust Proxy Learning,"Hong Joo Lee, Yong Man Ro",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15457"" target=""_blank"">2306.15457</a>",,2024-12-11
Your Attack Is Too DUMB: Formalizing Attacker Scenarios for Adversarial Transferability,"Marco Alecci, Mauro Conti, Francesco Marchiori, Luca Martinelli, Luca Pajola",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15363"" target=""_blank"">2306.15363</a>",,2024-12-11
[Re] Double Sampling Randomized Smoothing,"Aryan Gupta, Sarthak Gupta, Abhay Kumar, Harsh Dugar",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15221"" target=""_blank"">2306.15221</a>",,2024-12-11
Cooperation or Competition: Avoiding Player Domination for Multi-Target Robustness via Adaptive Budgets,"Yimu Wang, Dinghuai Zhang, Yihan Wu, Heng Huang, Hongyang Zhang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15482"" target=""_blank"">2306.15482</a>",,2024-12-11
Anticipatory Thinking Challenges in Open Worlds: Risk Management,"Adam Amos-Binks, Dustin Dannenhauer, Leilani H. Gilpin",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13157"" target=""_blank"">2306.13157</a>",,2024-12-11
Minimum-norm Sparse Perturbations for Opacity in Linear Systems,"Varkey M John, Vaibhav Katewa",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.17606"" target=""_blank"">2306.17606</a>",,2024-12-11
"Cross-lingual Cross-temporal Summarization: Dataset, Models, Evaluation","Ran Zhang, Jihed Ouni, Steffen Eger",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12916"" target=""_blank"">2306.12916</a>",,2024-12-11
Community Detection Attack against Collaborative Learning-based Recommender Systems,"Yacine Belal, Sonia Ben Mokhtar, Mohamed Maouche, Anthony Simonet-Boulogne",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08929"" target=""_blank"">2306.08929</a>",,2024-12-11
You Don't Need Robust Machine Learning to Manage Adversarial Attack Risks,"Edward Raff, Michel Benaroch, Andrew L. Farris",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09951"" target=""_blank"">2306.09951</a>",,2024-12-11
Towards Better Certified Segmentation via Diffusion Models,"Othmane Laousy, Alexandre Araujo, Guillaume Chassagnon, Marie-Pierre Revel, Siddharth Garg, Farshad Khorrami, Maria Vakalopoulou",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09949"" target=""_blank"">2306.09949</a>",,2024-12-11
Adversarially robust clustering with optimality guarantees,"Soham Jana, Kun Yang, Sanjeev Kulkarni",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09977"" target=""_blank"">2306.09977</a>",,2024-12-11
CLIP2Protect: Protecting Facial Privacy using Text-Guided Makeup via Adversarial Latent Search,"Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10008"" target=""_blank"">2306.10008</a>","<a href=""https://github.com/fahadshamshad/Clip2Protect"" target=""_blank"">fahadshamshad</a>",2024-12-11
DIFFender: Diffusion-Based Adversarial Defense against Patch Attacks in the Physical World,"Caixin Kang, Yinpeng Dong, Zhengyi Wang, Shouwei Ruan, Hang Su, Xingxing Wei",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09124"" target=""_blank"">2306.09124</a>",,2024-12-11
OVLA: Neural Network Ownership Verification using Latent Watermarks,"Feisi Fu, Wenchao Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13215"" target=""_blank"">2306.13215</a>",,2024-12-11
Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks,"Hongcheng Gao, Hao Zhang, Yinpeng Dong, Zhijie Deng",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13103"" target=""_blank"">2306.13103</a>",,2024-12-11
On Strengthening and Defending Graph Reconstruction Attack with Markov Chain Approximation,"Zhanke Zhou, Chenyu Zhou, Xuan Li, Jiangchao Yao, Quanming Yao, Bo Han",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09104"" target=""_blank"">2306.09104</a>","<a href=""https://github.com/tmlr-group/MC-GRA"" target=""_blank"">tmlr-group</a>",2024-12-11
Robustness Analysis on Foundational Segmentation Models,"Madeline Chantry Schiappa, Sachidanand VS, Yunhao Ge, Ondrej Miksik, Yogesh S. Rawat, Vibhav Vineet",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09278"" target=""_blank"">2306.09278</a>",,2024-12-11
DiffAug: A Diffuse-and-Denoise Augmentation for Training Robust Classifiers,"Chandramouli Sastry, Sri Harsha Dumpala, Sageev Oore",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09192"" target=""_blank"">2306.09192</a>",,2024-12-11
"Explore, Establish, Exploit: Red Teaming Language Models from Scratch","Stephen Casper, Jason Lin, Joe Kwon, Gatlen Culp, Dylan Hadfield-Menell",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09442"" target=""_blank"">2306.09442</a>",,2024-12-11
Concealing CAN Message Sequences to Prevent Schedule-based Bus-off Attacks,"Sunandan Adhikary, Ipsita Koley, Arkaprava Sain, Soumyadeep das, Shuvam Saha, Soumyajit Dey",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09206"" target=""_blank"">2306.09206</a>",,2024-12-11
Wasserstein distributional robustness of neural networks,"Xingjian Bai, Guangyi He, Yifan Jiang, Jan Obloj",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09844"" target=""_blank"">2306.09844</a>","<a href=""https://github.com/JanObloj/W-DRO-Adversarial-Methods"" target=""_blank"">JanObloj</a>",2024-12-11
Reliable Evaluation of Adversarial Transferability,"Wenqian Yu, Jindong Gu, Zhijiang Li, Philip Torr",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08565"" target=""_blank"">2306.08565</a>","<a href=""https://adv-trans-eval.github.io"" target=""_blank""></a>",2024-12-11
A Relaxed Optimization Approach for Adversarial Attacks against Neural Machine Translation Models,"Sahar Sadrizadeh, ClÃ©ment Barbier, Ljiljana Dolamic, Pascal Frossard",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08492"" target=""_blank"">2306.08492</a>",,2024-12-11
X-Detect: Explainable Adversarial Patch Detection for Object Detectors in Retail,"Omer Hofman, Amit Giloni, Yarin Hayun, Ikuya Morikawa, Toshiya Shimizu, Yuval Elovici, Asaf Shabtai",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08422"" target=""_blank"">2306.08422</a>",,2024-12-11
A First Order Meta Stackelberg Method for Robust Federated Learning (Technical Report),"Henger Li, Tianyi Xu, Tao Li, Yunian Pan, Quanyan Zhu, Zizhan Zheng",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13273"" target=""_blank"">2306.13273</a>",,2024-12-11
Augment then Smooth: Reconciling Differential Privacy with Certified Robustness,"Jiapeng Wu, Atiyeh Ashari Ghomi, David Glukhov, Jesse C. Cresswell, Franziska Boenisch, Nicolas Papernot",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08656"" target=""_blank"">2306.08656</a>",,2024-12-11
Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios,"Ziqiang Li, Hong Sun, Pengfei Xia, Heng Li, Beihao Xia, Yi Wu, Bin Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08386"" target=""_blank"">2306.08386</a>","<a href=""https://github.com/sunh1113/Efficient-backdoor-attacks-for-deep-neural-networks-in-real-world-scenarios"" target=""_blank"">sunh1113</a>",2024-12-11
A Unified Framework of Graph Information Bottleneck for Robustness and Membership Privacy,"Enyan Dai, Limeng Cui, Zhengyang Wang, Xianfeng Tang, Yinghan Wang, Monica Cheng, Bing Yin, Suhang Wang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08604"" target=""_blank"">2306.08604</a>",,2024-12-11
"Finite Gaussian Neurons: Defending against adversarial attacks by making neural networks say ""I don't know""",Felix Grezes,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07796"" target=""_blank"">2306.07796</a>",,2024-12-11
A Proxy Attack-Free Strategy for Practically Improving the Poisoning Efficiency in Backdoor Attacks,"Ziqiang Li, Hong Sun, Pengfei Xia, Beihao Xia, Xue Rui, Wei Zhang, Qinglang Guo, Bin Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08313"" target=""_blank"">2306.08313</a>",,2024-12-11
Improving Selective Visual Question Answering by Learning from Your Peers,"Corentin Dancette, Spencer Whitehead, Rishabh Maheshwary, Ramakrishna Vedantam, Stefan Scherer, Xinlei Chen, Matthieu Cord, Marcus Rohrbach",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08751"" target=""_blank"">2306.08751</a>",,2024-12-11
Theoretical Foundations of Adversarially Robust Learning,Omar Montasser,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07723"" target=""_blank"">2306.07723</a>",,2024-12-11
Query-Free Evasion Attacks Against Machine Learning-Based Malware Detectors with Generative Adversarial Networks,"Daniel Gibert, Jordi Planes, Quan Le, Giulio Zizzo",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09925"" target=""_blank"">2306.09925</a>",,2024-12-11
On the Robustness of Latent Diffusion Models,"Jianping Zhang, Zhuoer Xu, Shiwen Cui, Changhua Meng, Weibin Wu, Michael R. Lyu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08257"" target=""_blank"">2306.08257</a>","<a href=""https://github.com/jpzhang1810/LDM-Robustness"" target=""_blank"">jpzhang1810</a>",2024-12-11
Bkd-FedGNN: A Benchmark for Classification Backdoor Attacks on Federated Graph Neural Network,"Fan Liu, Siqi Lai, Yansong Ning, Hao Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10351"" target=""_blank"">2306.10351</a>","<a href=""https://github.com/usail-hkust/BkdFedGCN"" target=""_blank"">usail-hkust</a>",2024-12-11
DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models,"Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang, Chenhui Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, Sang T. Truong, Simran Arora, Mantas Mazeika, Dan Hendrycks, Zinan Lin, Yu Cheng, Sanmi Koyejo, Dawn Song, Bo Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11698"" target=""_blank"">2306.11698</a>","<a href=""https://decodingtrust.github.io/"" target=""_blank"">decodingtrust.github.io</a>",2024-12-11
Adversarial Attacks Neutralization via Data Set Randomization,"Mouna Rabhi, Pietro Roberto Di",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12161"" target=""_blank"">2306.12161</a>",,2024-12-11
Impacts and Risk of Generative AI Technology on Cyber Defense,"Subash Neupane, Ivan A. Fernandez, Sudip Mittal, Shahram Rahimi",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13033"" target=""_blank"">2306.13033</a>",,2024-12-11
GlyphNet: Homoglyph domains dataset and detection using attention-based Convolutional Neural Networks,"Akshat Gupta, Laxman Singh Tomar, Ridhima Garg",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10392"" target=""_blank"">2306.10392</a>",,2024-12-11
A Comprehensive Study on the Robustness of Image Classification and Object Detection in Remote Sensing: Surveying and Benchmarking,"Shaohui Mei, Jiawei Lian, Xiaofei Wang, Yuru Su, Mingyang Ma, Lap-Pui Chau",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12111"" target=""_blank"">2306.12111</a>",,2024-12-11
Sample Attackability in Natural Language Adversarial Attacks,"Vyas Raina, Mark Gales",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12043"" target=""_blank"">2306.12043</a>",,2024-12-11
Revisiting Image Classifier Training for Improved Certified Robust Defense against Adversarial Patches,"Aniruddha Saha, Shuhua Yu, Arash Norouzzadeh, Wan-Yi Lin, Chaithanya Kumar Mummadi",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12610"" target=""_blank"">2306.12610</a>",,2024-12-11
DP-BREM: Differentially-Private and Byzantine-Robust Federated Learning with Client Momentum,"Xiaolan Gu, Ming Li, Li Xiong",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12608"" target=""_blank"">2306.12608</a>",,2024-12-11
Reversible Adversarial Examples with Beam Search Attack and Grayscale Invariance,"Haodong Zhang, Chi Man Pun, Xia Du",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11322"" target=""_blank"">2306.11322</a>",,2024-12-11
Universal adversarial perturbations for multiple classification tasks with quantum classifiers,Yun-Zhong Qiu,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11974"" target=""_blank"">2306.11974</a>",,2024-12-11
Physics-constrained Attack against Convolution-based Human Motion Prediction,"Chengxu Duan, Zhicheng Zhang, Xiaoli Liu, Yonghao Dang, Jianqin Yin",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11990"" target=""_blank"">2306.11990</a>",,2024-12-11
FDINet: Protecting against DNN Model Extraction via Feature Distortion Index,"Hongwei Yao, Zheng Li, Haiqin Weng, Feng Xue, Zhan Qin, Kui Ren",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11338"" target=""_blank"">2306.11338</a>",,2024-12-11
FFCV: Accelerating Training by Removing Data Bottlenecks,"Guillaume Leclerc, Andrew Ilyas, Logan Engstrom, Sung Min Park, Hadi Salman, Aleksander Madry",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12517"" target=""_blank"">2306.12517</a>",,2024-12-11
Towards a robust and reliable deep learning approach for detection of compact binary mergers in gravitational wave data,"Shreejit Jadhav, Mihir Shrivastava, Sanjit Mitra",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11797"" target=""_blank"">2306.11797</a>",,2024-12-11
Understanding Certified Training with Interval Bound Propagation,"Yuhao Mao, Mark Niklas MÃ¼ller, Marc Fischer, Martin Vechev",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10426"" target=""_blank"">2306.10426</a>",,2024-12-11
Adversarial Robustness of Prompt-based Few-Shot Learning for Natural Language Understanding,"Venkata Prabhakara Sarath Nookala, Gaurav Verma, Subhabrata Mukherjee, Srijan Kumar",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11066"" target=""_blank"">2306.11066</a>",,2024-12-11
Eigenpatches -- Adversarial Patches from Principal Components,"Jens Bayer, Stefan Becker, David MÃ¼nch, Michael Arens",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10963"" target=""_blank"">2306.10963</a>",,2024-12-11
Practical and General Backdoor Attacks against Vertical Federated Learning,"Yuexin Xuan, Xiaojun Chen, Zhendong Zhao, Bisheng Tang, Ye Dong",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10746"" target=""_blank"">2306.10746</a>",,2024-12-11
BNN-DP: Robustness Certification of Bayesian Neural Networks via Dynamic Programming,"Steven Adams, Andrea Patane, Morteza Lahijanian, Luca Laurenti",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10742"" target=""_blank"">2306.10742</a>",,2024-12-11
"Edge Learning for 6G-enabled Internet of Things: A Comprehensive Survey of Vulnerabilities, Datasets, and Defenses","Mohamed Amine Ferrag, Othmane Friha, Burak Kantarci, Norbert Tihanyi, Lucas Cordeiro, Merouane Debbah, Djallel Hamouda, Muna Al-Hawawreh, Kim-Kwang Raymond Choo",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10309"" target=""_blank"">2306.10309</a>",,2024-12-11
Comparative Evaluation of Recent Universal Adversarial Perturbations in Image Classification,"Juanjuan Weng, Zhiming Luo, Dazhen Lin, Shaozi Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11261"" target=""_blank"">2306.11261</a>",,2024-12-11
Adversarial Training Should Be Cast as a Non-Zero-Sum Game,"Alexander Robey, Fabian Latorre, George J. Pappas, Hamed Hassani, Volkan Cevher",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11035"" target=""_blank"">2306.11035</a>",,2024-12-11
Mitigating Speculation-based Attacks through Configurable Hardware/Software Co-design,"Ali Hajiabadi, Archit Agarwal, Andreas Diavastos, Trevor E. Carlson",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11291"" target=""_blank"">2306.11291</a>",,2024-12-11
LVM-Med: Learning Large-Scale Self-Supervised Vision Models for Medical Imaging via Second-order Graph Matching,"Duy M. H. Nguyen, Hoang Nguyen, Nghiem T. Diep, Tan N. Pham, Tri Cao, Binh T. Nguyen, Paul Swoboda, Nhat Ho, Shadi Albarqouni, Pengtao Xie, Daniel Sonntag, Mathias Niepert",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11925"" target=""_blank"">2306.11925</a>",,2024-12-11
A Black-Box Attack on Code Models via Representation Nearest Neighbor Search,"Jie Zhang, Wei Ma, Qiang Hu, Shangqing Liu, Xiaofei Xie, Yves Le Traon, Yang Liu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.05896"" target=""_blank"">2305.05896</a>",,2024-12-11
On enhancing the robustness of Vision Transformers: Defensive Diffusion,"Raza Imam, Muhammad Huzaifa, Mohammed El-Amine Azz",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08031"" target=""_blank"">2305.08031</a>",,2024-12-11
Training Neural Networks without Backpropagation: A Deeper Dive into the Likelihood Ratio Method,"Jinyang Jiang, Zeliang Zhang, Chenliang Xu, Zhaofei Yu, Yijie Peng",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08960"" target=""_blank"">2305.08960</a>",,2024-12-11
"Assessing Hidden Risks of LLMs: An Empirical Study on Robustness, Consistency, and Credibility","Wentao Ye, Mingfeng Ou, Tianyi Li, Yipeng chen, Xuetao Ma, Yifan Yanggong, Sai Wu, Jie Fu, Gang Chen, Haobo Wang, Junbo Zhao",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10235"" target=""_blank"">2305.10235</a>",,2024-12-11
Diffusion Models for Imperceptible and Transferable Adversarial Attack,"Jianqi Chen, Hao Chen, Keyan Chen, Yilan Zhang, Zhengxia Zou, Zhenwei Shi",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08192"" target=""_blank"">2305.08192</a>",,2024-12-11
Improving Defensive Distillation using Teacher Assistant,"Maniratnam Mandal, Suna Gao",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08076"" target=""_blank"">2305.08076</a>",,2024-12-11
Manipulating Visually-aware Federated Recommender Systems and Its Countermeasures,"Wei Yuan, Shilong Yuan, Chaoqun Yang, Quoc Viet Hung Nguyen, Hongzhi Yin",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08183"" target=""_blank"">2305.08183</a>",,2024-12-11
Watermarking Text Generated by Black-Box Language Models,"Xi Yang, Kejiang Chen, Weiming Zhang, Chang Liu, Yuang Qi, Jie Zhang, Han Fang, Nenghai Yu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08883"" target=""_blank"">2305.08883</a>",,2024-12-11
DNN-Defender: A Victim-Focused In-DRAM Defense Mechanism for Taming Adversarial Weight Attack on DNNs,"Ranyang Zhou, Sabbir Ahmed, Adnan Siraj Rakin, Shaahin Angizi",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08034"" target=""_blank"">2305.08034</a>",,2024-12-11
Decision-based iterative fragile watermarking for model integrity verification,"Zhaoxia Yin, Heng Yin, Hang Su, Xinpeng Zhang, Zhenzhe Gao",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09684"" target=""_blank"">2305.09684</a>",,2024-12-11
Watch This Space: Securing Satellite Communication through Resilient Transmitter Fingerprinting,"Joshua Smailes, Sebastian Kohler, Simon Birnbach, Martin Strohmeier, Ivan Martinovic",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.06947"" target=""_blank"">2305.06947</a>",,2024-12-11
Efficient Search of Comprehensively Robust Neural Architectures via Multi-fidelity Evaluation,"Jialiang Sun, Wen Yao, Tingsong Jiang, Xiaoqian Chen",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.07308"" target=""_blank"">2305.07308</a>",,2024-12-11
Towards Invisible Backdoor Attacks in the Frequency Domain against Deep Neural Networks,"Xinrui Liu, Yajie Wang, Yu-an Tan, Kefan Qiu, Yuanzhang Li",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10596"" target=""_blank"">2305.10596</a>",,2024-12-11
Adversarial Security and Differential Privacy in mmWave Beam Prediction in 6G networks,"Ghanta Sai Krishna, Kundrapu Supriya, Sanskar Singh, Sabur Baidya",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09679"" target=""_blank"">2305.09679</a>",,2024-12-11
Exploiting Frequency Spectrum of Adversarial Images for General Robustness,"Chun Yang Tan, Kazuhiko Kawamoto, Hiroshi Kera",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08439"" target=""_blank"">2305.08439</a>",,2024-12-11
Stealthy Low-frequency Backdoor Attack against Deep Neural Networks,"Xinrui Liu, Yu-an Tan, Yajie Wang, Kefan Qiu, Yuanzhang Li",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09677"" target=""_blank"">2305.09677</a>",,2024-12-11
Distracting Downpour: Adversarial Weather Attacks for Motion Estimation,"Jenny Schmalfuss, Lukas Mehl, AndrÃ©s Bruhn",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.06716"" target=""_blank"">2305.06716</a>",,2024-12-11
Randomized Smoothing with Masked Inference for Adversarially Robust Text Classifications,"Han Cheol Moon, Shafiq Joty, Ruochen Zhao, Megh Thakkar, Xu Chi",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.06522"" target=""_blank"">2305.06522</a>","<a href=""https://github.com/Han8931/rsmi_nlp"" target=""_blank"">Han8931</a>",2024-12-11
Inter-frame Accelerate Attack against Video Interpolation Models,"Junpei Liao, Zhikai Chen, Liang Yi, Wenyuan Yang, Baoyuan Wu, Xiaochun Cao",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.06540"" target=""_blank"">2305.06540</a>",,2024-12-11
Mastering Percolation-like Games with Deep Learning,"Michael M. Danziger, Omkar R. Gojala, Sean P. Cornelius",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.07687"" target=""_blank"">2305.07687</a>",,2024-12-11
Ortho-ODE: Enhancing Robustness and of Neural ODEs against Adversarial Attacks,Vishal Purohit,arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09179"" target=""_blank"">2305.09179</a>",,2024-12-11
Attacking Perceptual Similarity Metrics,"Abhijay Ghildyal, Feng Liu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08840"" target=""_blank"">2305.08840</a>",,2024-12-11
Zero-Day Backdoor Attack against Text-to-Image Diffusion Models via Personalization,"Yihao Huang, Qing Guo, Felix Juefei-Xu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10701"" target=""_blank"">2305.10701</a>",,2024-12-11
Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning,"Mustafa Safa Ozdayi, Charith Peris, Jack FitzGerald, Christophe Dupuy, Jimit Majmudar, Haidar Khan, Rahil Parikh, Rahul Gupta",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11759"" target=""_blank"">2305.11759</a>",,2024-12-11
Deep PackGen: A Deep Reinforcement Learning Framework for Adversarial Network Packet Generation,"Soumyadeep Hore, Jalal Ghadermazi, Diwas Paudel, Ankit Shah, Tapas K. Das, Nathaniel D. Bastian",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11039"" target=""_blank"">2305.11039</a>",,2024-12-11
Adversarial Amendment is the Only Force Capable of Transforming an Enemy into a Friend,"Chong Yu, Tao Chen, Zhongxue Gan",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10766"" target=""_blank"">2305.10766</a>",,2024-12-11
Architecture-agnostic Iterative Black-box Certified Defense against Adversarial Patches,"Di Yang, Yihao Huang, Qing Guo, Felix Juefei-Xu, Ming Hu, Yang Liu, Geguang Pu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10929"" target=""_blank"">2305.10929</a>",,2024-12-11
Towards an Accurate and Secure Detector against Adversarial Perturbations,"Chao Wang, Shuren Qi, Zhiqiu Huang, Yushu Zhang, Xiaochun Cao",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10856"" target=""_blank"">2305.10856</a>",,2024-12-11
Quantifying the robustness of deep multispectral segmentation models against natural perturbations and data poisoning,"Elise Bishoff, Charles Godfrey, Myles McKay, Eleanor Byler",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11347"" target=""_blank"">2305.11347</a>",,2024-12-11
How Deep Learning Sees the World: A Survey on Adversarial Attacks & Defenses,"Joana C. Costa, Tiago Roxo, Hugo ProenÃ§a, Pedro R. M. InÃ¡cio",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10862"" target=""_blank"">2305.10862</a>",,2024-12-11
RobustFair: Adversarial Evaluation through Fairness Confusion Directed Gradient Search,"Xuran Li, Peng Wu, Kaixiang Dong, Zhen Zhang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10906"" target=""_blank"">2305.10906</a>",,2024-12-11
Attacks on Online Learners: a Teacher-Student Analysis,"Riccardo Giuseppe Margiotta, Sebastian Goldt, Guido Sanguinetti",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11132"" target=""_blank"">2305.11132</a>",,2024-12-11
Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture,"Galen Pogoncheff, Jacob Granley, Michael Beyeler",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11275"" target=""_blank"">2305.11275</a>",,2024-12-11
Large Language Models can be Guided to Evade AI-Generated Text Detection,"Ning Lu, Shengcai Liu, Rui He, Qi Wang, Yew-Soon Ong, Ke Tang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10847"" target=""_blank"">2305.10847</a>","<a href=""https://github.com/ColinLu50/Evade-GPT-Detector"" target=""_blank"">ColinLu50</a>",2024-12-11
Re-thinking Data Availablity Attacks Against Deep Neural Networks,"Bin Fang, Bo Li, Shuang Wu, Ran Yi, Shouhong Ding, Lizhuang Ma",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10691"" target=""_blank"">2305.10691</a>",,2024-12-11
Unlearnable Examples Give a False Sense of Security: Piercing through Unexploitable Data with Learnable Examples,"Wan Jiang, Yunfeng Diao, He Wang, Jianxin Sun, Meng Wang, Richang Hong",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09241"" target=""_blank"">2305.09241</a>","<a href=""https://github.com/jiangw-0/LE_JCDP"" target=""_blank"">jiangw-0</a>",2024-12-11
TrustSER: On the Trustworthiness of Fine-tuning Pre-trained Speech Embeddings For Speech Emotion Recognition,"Tiantian Feng, Rajat Hebbar, Shrikanth Narayanan",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11229"" target=""_blank"">2305.11229</a>","<a href=""https://github.com/usc-sail/trust-ser"" target=""_blank"">usc-sail</a>",2024-12-11
Content-based Unrestricted Adversarial Attack,"Zhaoyu Chen, Bo Li, Shuang Wu, Kaixun Jiang, Shouhong Ding, Wenqiang Zhang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10665"" target=""_blank"">2305.10665</a>",,2024-12-11
Raising the Bar for Certified Adversarial Robustness with Diffusion Models,"Thomas Altstidl, David Dobre, BjÃ¶rn Eskofier, Gauthier Gidel, Leo Schwinn",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10388"" target=""_blank"">2305.10388</a>",,2024-12-11
The Adversarial Consistency of Surrogate Risks for Binary Classification,"Natalie Frank, Jonathan Niles-Weed",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09956"" target=""_blank"">2305.09956</a>",,2024-12-11
An Empirical Study on the Robustness of the Segment Anything Model (SAM),"Yuqing Wang, Yun Zhao, Linda Petzold",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.06422"" target=""_blank"">2305.06422</a>",,2024-12-11
Variational Classification,"Shehzaad Dhuliawala, Mrinmaya Sachan, Carl Allen",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10406"" target=""_blank"">2305.10406</a>",,2024-12-11
"Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt","Zhaozhuo Xu, Zirui Liu, Beidi Chen, Yuxin Tang, Jue Wang, Kaixiong Zhou, Xia Hu, Anshumali Shrivastava",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11186"" target=""_blank"">2305.11186</a>",,2024-12-11
PaLM 2 Technical Report,"Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey, Yanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan Botha, James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng, Colin Cherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, ClÃ©ment Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark DÃ­az, Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, Guy Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey Hui, Jeremy Hurwitz, Michael Isard, Abe Ittycheriah, Matthew Jagielski, Wenhao Jia, Kathleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric Ni, Andrew Nystrom, Alicia Parrish, Marie Pellat, Martin Polacek, Alex Polozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel, Renee Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng, Ce Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, Yonghui Wu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10403"" target=""_blank"">2305.10403</a>",,2024-12-11
Iterative Adversarial Attack on Image-guided Story Ending Generation,"Youze Wang, Wenbo Hu, Richang Hong",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.13208"" target=""_blank"">2305.13208</a>",,2024-12-11
Releasing Inequality Phenomena in $L_{\infty}$-Adversarial Training via Input Gradient Distillation,"Junxi Chen, Junhao Dong, Xiaohua Xie",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09305"" target=""_blank"">2305.09305</a>",,2024-12-11
Latent Imitator: Generating Natural Individual Discriminatory Instances for Black-Box Fairness Testing,"Yisong Xiao, Aishan Liu, Tianlin Li, Xianglong Liu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11602"" target=""_blank"">2305.11602</a>",,2024-12-11
The Robustness of Computer Vision Models against Common Corruptions: a Survey,"Shunxin Wang, Raymond Veldhuis, Nicola Strisciuglio",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.06024"" target=""_blank"">2305.06024</a>",,2024-12-11
Toward Adversarial Training on Contextualized Language Representation,"Hongqiu Wu, Yongxiang Liu, Hanwen Shi, Hai Zhao, Min Zhang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.04557"" target=""_blank"">2305.04557</a>",,2024-12-11
Robust multi-agent coordination via evolutionary generation of auxiliary adversarial attackers,"Lei Yuan, Zi-Qian Zhang, Ke Xue, Hao Yin, Feng Chen, Cong Guan, Li-He Li, Chao Qian, Yang Yu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.05909"" target=""_blank"">2305.05909</a>",,2024-12-11
Towards Imperceptible Document Manipulations against Neural Ranking Models,"Xuanang Chen, Ben He, Zheng Ye, Le Sun, Yingfei Sun",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.01860"" target=""_blank"">2305.01860</a>",,2024-12-11
Faulting original McEliece's implementations is possible: How to mitigate this risk? (2%),"Vincent Giraud, Guillaume Bouffard",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02855"" target=""_blank"">2305.02855</a>",,2024-12-11
New Adversarial Image Detection Based on Sentiment Analysis,"Yulong Wang, Tianxiang Li, Shenghong Li, Xin Yuan, Wei Ni",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.03173"" target=""_blank"">2305.03173</a>",,2024-12-11
A Data-Driven Defense against Edge-case Model Poisoning Attacks on Federated Learning,"Kiran Purohit, Soumi Das, Sourangshu Bhattacharya, Santu Rana",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02022"" target=""_blank"">2305.02022</a>",,2024-12-11
Defending against Insertion-based Textual Backdoor Attacks via Attribution,"Jiazhao Li, Zhuofeng Wu, Wei Ping, Chaowei Xiao, V. G. Vinod Vydiswaran",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02394"" target=""_blank"">2305.02394</a>",,2024-12-11
On the Security Risks of Knowledge Graph Reasoning,"Zhaohan Xi, Tianyu Du, Changjiang Li, Ren Pang, Shouling Ji, Xiapu Luo, Xusheng Xiao, Fenglong Ma, Ting Wang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02383"" target=""_blank"">2305.02383</a>",,2024-12-11
Backdoor Learning on Sequence to Sequence Models,"Lichang Chen, Minhao Cheng, Heng Huang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02424"" target=""_blank"">2305.02424</a>",,2024-12-11
Rethinking Graph Lottery Tickets: Graph Sparsity Matters,"Bo Hui, Da Yan, Xiaolong Ma, Wei-Shinn Ku",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02190"" target=""_blank"">2305.02190</a>",,2024-12-11
PTP: Boosting Stability and Performance of Prompt Tuning with Perturbation-Based Regularizer,"Lichang Chen, Heng Huang, Minhao Cheng",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02423"" target=""_blank