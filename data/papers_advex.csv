title,author,venue_name,publish_date,url,code,crawl_timestamp
DRIFT: Divergent Response in Filtered Transformations for Robust Adversarial Defense,"Amira Guesmi, Muhammad Shafique",arXiv,2025-09,"<a href=""http://arxiv.org/abs/2509.24359"" target=""_blank"">2509.24359</a>","<a href=""https://github.com/choi403/DiffusionGuard"" target=""_blank"">choi403</a>",2025-12-03 22:39:25
Vision Transformer with Adversarial Indicator Token against Adversarial Attacks in Radio Signal Classifications,"Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Guisheng Liao, Xuekang Liu, Fabio Roli, Carsten Maple",arXiv,2025-07,"<a href=""http://arxiv.org/abs/2507.00015"" target=""_blank"">2507.00015</a>",,2025-12-03 22:39:25
AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models,"Aashray Reddy, Andrew Zagula, Nicholas Saban",arXiv,2025-07,"<a href=""http://arxiv.org/abs/2507.01020"" target=""_blank"">2507.01020</a>","<a href=""https://cuhk-arise.github.io/CodeCrash/"" target=""_blank"">CodeCrash</a>",2025-12-03 22:39:25
Poisoning Behavioral-based Worker Selection in Mobile Crowdsensing using Generative Adversarial Networks,"Ruba Nasser, Ahmed Alagha, Shakti Singh, Rabeb Mizouni, Hadi Otrok, Jamal Bentahar",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.05403"" target=""_blank"">2506.05403</a>",,2025-12-03 22:39:25
Invisible Backdoor Triggers in Image Editing Model via Deep Watermarking,"Yu-Feng Chen, Tzuhsuan Huang, Pin-Yen Chiu, Jun-Cheng Chen",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.04879"" target=""_blank"">2506.04879</a>","<a href=""https://github.com/aiiu-lab/BackdoorImageEditing"" target=""_blank"">aiiu-lab</a>",2025-12-03 22:39:25
Robustness Evaluation for Video Models with Reinforcement Learning,"Ashwin Ramesh Babu, Sajad Mousavi, Vineet Gundecha, Sahand Ghorbanpour, Avisek Naug, Antonio Guillen, Ricardo Luna Gutierrez, Soumyendu Sarkar",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.05431"" target=""_blank"">2506.05431</a>",,2025-12-03 22:39:25
Why LLM Safety Guardrails Collapse After Fine-tuning: A Similarity Analysis Between Alignment and Fine-tuning Datasets,"Lei Hsiung, Tianyu Pang, Yung-Chen Tang, Linyue Song, Tsung-Yi Ho, Pin-Yu Chen, Yaoqing Yang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.05346"" target=""_blank"">2506.05346</a>",,2025-12-03 22:39:25
Robust Few-Shot Vision-Language Model Adaptation,"Hanxin Wang, Tian Liu, Shu Kong",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.04713"" target=""_blank"">2506.04713</a>",,2025-12-03 22:39:25
Detection Method for Prompt Injection by Integrating Pre-trained Model and Heuristic Feature Engineering,"Yi Ji, Runzhi Li, Baolei Mao",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06384"" target=""_blank"">2506.06384</a>",,2025-12-03 22:39:25
Prediction Inconsistency Helps Achieve Generalizable Detection of Adversarial Examples,"Sicong Han, Chenhao Lin, Zhengyu Zhao, Xiyuan Wang, Xinlei He, Qian Li, Cong Wang, Qian Wang, Chao Shen",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.03765"" target=""_blank"">2506.03765</a>",,2025-12-03 22:39:25
RAID: A Dataset for Testing the Adversarial Robustness of AI-Generated Image Detectors,"Hicham Eddoubi, Jonas Ricker, Federico Cocchi, Lorenzo Baraldi, Angelo Sotgiu, Maura Pintor, Marcella Cornia, Lorenzo Baraldi, Asja Fischer, Rita Cucchiara, Battista Biggio",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.03988"" target=""_blank"">2506.03988</a>","<a href=""https://github.com/pralab/RAID"" target=""_blank"">pralab</a>",2025-12-03 22:39:25
Robustness of Prompting: Enhancing Robustness of Large Language Models Against Prompting Attacks,"Lin Mu, Guowei Chu, Li Ni, Lei Sang, Zhize Wu, Peiquan Jin, Yiwen Zhang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.03627"" target=""_blank"">2506.03627</a>",,2025-12-03 22:39:25
DiffCAP: Diffusion-based Cumulative Adversarial Purification for Vision Language Models,"Jia Fu, Yongtao Wu, Yihang Chen, Kunyu Peng, Xiao Zhang, Volkan Cevher, Sepideh Pashami, Anders Holst",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.03933"" target=""_blank"">2506.03933</a>",,2025-12-03 22:39:25
Coordinated Robustness Evaluation Framework for Vision-Language Models,"Ashwin Ramesh Babu, Sajad Mousavi, Vineet Gundecha, Sahand Ghorbanpour, Avisek Naug, Antonio Guillen, Ricardo Luna Gutierrez, Soumyendu Sarkar",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.05429"" target=""_blank"">2506.05429</a>",,2025-12-03 22:39:25
Through the Stealth Lens: Rethinking Attacks and Defenses in RAG,"Sarthak Choudhary, Nils Palumbo, Ashish Hooda, Krishnamurthy Dj Dvijotham, Somesh Jha",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.04390"" target=""_blank"">2506.04390</a>",,2025-12-03 22:39:25
Privacy and Security Threat for OpenAI GPTs,"Wei Wenying, Zhao Kaifa, Xue Lei, Fan Ming",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.04036"" target=""_blank"">2506.04036</a>",,2025-12-03 22:39:25
BESA: Boosting Encoder Stealing Attack with Perturbation Recovery,"Xuhao Ren, Haotian Liang, Yajie Wang, Chuan Zhang, Zehui Xiong, Liehuang Zhu",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.04556"" target=""_blank"">2506.04556</a>",,2025-12-03 22:39:25
PRJ: Perception-Retrieval-Judgement for Generated Images,"Qiang Fu, Zonglei Jing, Zonghao Ying, Xiaoqian Li",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.03683"" target=""_blank"">2506.03683</a>",,2025-12-03 22:39:25
Tournament Robustness via Redundancy,"Klim Efremenko, Hendrik Molter, Meirav Zehavi",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.03701"" target=""_blank"">2506.03701</a>",,2025-12-03 22:39:25
How stealthy is stealthy? Studying the Efficacy of Black-Box Adversarial Attacks in the Real World,"Francesco Panebianco, Mario D'Onghia, Stefano Zanero aand Michele Carminati",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.05382"" target=""_blank"">2506.05382</a>",,2025-12-03 22:39:25
Dynamic Epsilon Scheduling: A Multi-Factor Adaptive Perturbation Budget for Adversarial Training,"Alan Mitkiy, James Smith, Hana Satou, Hiroshi Tanaka, Emily Johnson, F Monkey",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.04263"" target=""_blank"">2506.04263</a>",,2025-12-03 22:39:25
Tarallo: Evading Behavioral Malware Detectors in the Problem Space,"Gabriele Digregorio, Salvatore Maccarrone, Mario D'Onghia, Luigi Gallo, Michele Carminati, Mario Polino, Stefano Zanero",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.02660"" target=""_blank"">2506.02660</a>",,2025-12-03 22:39:25
Privacy Leaks by Adversaries: Adversarial Iterations for Membership Inference Attack,"Jing Xue, Zhishen Sun, Haishan Ye, Luo Luo, Xiangyu Chang, Ivor Tsang, Guang Dai",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.02711"" target=""_blank"">2506.02711</a>",,2025-12-03 22:39:25
Fool the Stoplight: Realistic Adversarial Patch Attacks on Traffic Light Detectors,"Svetlana Pavlitska, Jamie Robb, Nikolai Polley, Melih Yazgan, J. Marius Zöllner",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.04823"" target=""_blank"">2506.04823</a>","<a href=""https://github.com/KASTEL-MobilityLab/attacks-on-traffic-light-detection"" target=""_blank"">KASTEL-MobilityLab</a>",2025-12-03 22:39:25
Identifying and Understanding Cross-Class Features in Adversarial Training,"Zeming Wei, Yiwen Guo, Yisen Wang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.05032"" target=""_blank"">2506.05032</a>","<a href=""https://github.com/PKU-ML/Cross-Class-Features-AT"" target=""_blank"">PKU-ML</a>",2025-12-03 22:39:25
Sylva: Tailoring Personalized Adversarial Defense in Pre-trained Models via Collaborative Fine-tuning,"Tianyu Qi, Lei Xue, Yufeng Zhan, Xiaobo Ma",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.05402"" target=""_blank"">2506.05402</a>",,2025-12-03 22:39:25
What Really is a Member? Discrediting Membership Inference via Poisoning,"Neal Mangaokar, Ashish Hooda, Zhuohang Li, Bradley A. Malin, Kassem Fawaz, Somesh Jha, Atul Prakash, Amrita Roy Chowdhury",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06003"" target=""_blank"">2506.06003</a>",,2025-12-03 22:39:25
Securing Traffic Sign Recognition Systems in Autonomous Vehicles,"Thushari Hapuarachchi, Long Dang, Kaiqi Xiong",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06563"" target=""_blank"">2506.06563</a>",,2025-12-03 22:39:25
Quantifying Adversarial Uncertainty in Evidential Deep Learning using Conflict Resolution,"Charmaine Barker, Daniel Bethell, Simos Gerasimou",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.05937"" target=""_blank"">2506.05937</a>",,2025-12-03 22:39:25
SDN-Based False Data Detection With Its Mitigation and Machine Learning Robustness for In-Vehicle Networks,"Long Dang, Thushari Hapuarachchi, Kaiqi Xiong, Yi Li",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06556"" target=""_blank"">2506.06556</a>",,2025-12-03 22:39:25
Joint-GCG: Unified Gradient-Based Poisoning Attacks on Retrieval-Augmented Generation Systems,"Haowei Wang, Rupeng Zhang, Junjie Wang, Mingyang Li, Yuekai Huang, Dandan Wang, Qing Wang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06151"" target=""_blank"">2506.06151</a>","<a href=""https://github.com/NicerWang/Joint-GCG"" target=""_blank"">NicerWang</a>",2025-12-03 22:39:25
To Protect the LLM Agent Against the Prompt Injection Attack with Polymorphic Prompt,"Zhilong Wang, Neha Nagaraja, Lan Zhang, Hayretdin Bahsi, Pawan Patil, Peng Liu",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.05739"" target=""_blank"">2506.05739</a>",,2025-12-03 22:39:25
SATversary: Adversarial Attacks on Satellite Fingerprinting,"Joshua Smailes, Sebastian Köhler, Simon Birnbach, Martin Strohmeier, Ivan Martinovic",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06119"" target=""_blank"">2506.06119</a>",,2025-12-03 22:39:25
Simple Yet Effective: Extracting Private Data Across Clients in Federated Fine-Tuning of Large Language Models,"Yingqi Hu, Zhuo Zhang, Jingyuan Zhang, Lizhen Qu, Zenglin Xu",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06060"" target=""_blank"">2506.06060</a>",,2025-12-03 22:39:25
Sample-Specific Noise Injection For Diffusion-Based Adversarial Purification,"Yuhao Sun, Jiacheng Zhang, Zesheng Ye, Chaowei Xiao, Feng Liu",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06027"" target=""_blank"">2506.06027</a>","<a href=""https://github.com/tmlr-group/SSNI"" target=""_blank"">tmlr-group</a>",2025-12-03 22:39:25
Stealix: Model Stealing via Prompt Evolution,"Zhixiong Zhuang, Hui-Po Wang, Maria-Irina Nicolae, Mario Fritz",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.05867"" target=""_blank"">2506.05867</a>",,2025-12-03 22:39:25
Robustness as Architecture: Designing IQA Models to Withstand Adversarial Perturbations,"Igor Meleshin, Anna Chistyakova, Anastasia Antsiferova, Dmitriy Vatolin",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.04951"" target=""_blank"">2506.04951</a>",,2025-12-03 22:39:25
A Systematic Review of Poisoning Attacks Against Large Language Models,"Neil Fendley, Edward W. Staley, Joshua Carney, William Redman, Marie Chau, Nathan Drenkow",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06518"" target=""_blank"">2506.06518</a>",,2025-12-03 22:39:25
Robust Learnability of Sample-Compressible Distributions under Noisy or Adversarial Perturbations,"Arefe Boushehrian, Amir Najafi",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06613"" target=""_blank"">2506.06613</a>",,2025-12-03 22:39:25
Adapting Under Fire: Multi-Agent Reinforcement Learning for Adversarial Drift in Network Security,"Emilia Rivas, Sabrina Saika, Ahtesham Bakht, Aritran Piplai, Nathaniel D. Bastian, Ankit Shah",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06565"" target=""_blank"">2506.06565</a>",,2025-12-03 22:39:25
Cyber Security of Sensor Systems for State Sequence Estimation: an AI Approach,"Xubin Fang, Rick S. Blum, Ramesh Bharadwaj, Brian M. Sadler",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06572"" target=""_blank"">2506.06572</a>",,2025-12-03 22:39:25
Explainer-guided Targeted Adversarial Attacks against Binary Code Similarity Detection Models,"Mingjie Zhejiang University Chen, Tiancheng Huazhong University of Science and Technology Zhu, Mingxue The State Key Laboratory of Blockchain and Data Security, Zhejiang University & Hangzhou High-Tech Zone Zhang, Yiling University College London He, Minghao University of Southern California Lin, Penghui Columbia University Li, Kui The State Key Laboratory of Blockchain and Data Security, Zhejiang University Ren",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.05430"" target=""_blank"">2506.05430</a>",,2025-12-03 22:39:25
Exploring Adversarial Watermarking in Transformer-Based Models: Transferability and Robustness Against Defense Mechanism for Medical Images,"Rifat Sadik, Tanvir Rahman, Arpan Bhattacharjee, Bikash Chandra Halder, Ismail Hossain",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06389"" target=""_blank"">2506.06389</a>",,2025-12-03 22:39:25
SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in VLMs,"Shuhan Xu, Siyuan Liang, Hongling Zheng, Yong Luo, Aishan Liu, Dacheng Tao",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.04743"" target=""_blank"">2506.04743</a>",,2025-12-03 22:39:25
Efficient Robust Conformal Prediction via Lipschitz-Bounded Networks,"Thomas IRIT, DTIPG - SNCF, UT3 Massena, Léo IMT, DTIPG - SNCF, UT3 andéol, Thibaut IRIT, UT3 Boissin, Franck IRIT, UT3 Mamalet, Corentin IRIT, UT3 Friedrich, Mathieu IRIT, UT3 Serrurier, Sébastien IMT Gerchinovitz",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.05434"" target=""_blank"">2506.05434</a>",,2025-12-03 22:39:25
On the Robustness of Tabular Foundation Models: Test-Time Attacks and In-Context Defenses,"Mohamed Djilani, Thibault Simonetto, Karim Tit, Florian Tambon, Paul Récamier, Salah Ghamizi, Maxime Cordy, Mike Papadakis",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.02978"" target=""_blank"">2506.02978</a>",,2025-12-03 22:39:25
Attacking Attention of Foundation Models Disrupts Downstream Tasks,"Hondamunige Prasanna Silva, Federico Becattini, Lorenzo Seidenari",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.05394"" target=""_blank"">2506.05394</a>","<a href=""https://github.com/HondamunigePrasannaSilva/attack-attention"" target=""_blank"">HondamunigePrasannaSilva</a>",2025-12-03 22:39:25
Fuse and Federate: Enhancing EV Charging Station Security with Multimodal Fusion and Federated Learning,"Rabah Rahal, Abdelaziz Amara Korba, Yacine Ghamri-Doudane",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06730"" target=""_blank"">2506.06730</a>",,2025-12-03 22:39:25
"Doppelg\""anger Method: Breaking Role Consistency in LLM Agent via Prompt-based Transferable Adversarial Attack","Daewon Kang, YeongHwan Shin, Doyeon Kim, Kyu-Hwan Jung, Meong Hi Son",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.14539"" target=""_blank"">2506.14539</a>",,2025-12-03 22:39:25
Con Instruction: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities,"Jiahui Geng, Thy Thy Tran, Preslav Nakov, Iryna Gurevych",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.00548"" target=""_blank"">2506.00548</a>",,2025-12-03 22:39:25
SafeGenes: Evaluating the Adversarial Robustness of Genomic Foundation Models,"Huixin Zhan, Jason H. Moore",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.00821"" target=""_blank"">2506.00821</a>",,2025-12-03 22:39:25
SafeTy Reasoning Elicitation Alignment for Multi-Turn Dialogues,"Martin Kuo, Jianyi Zhang, Aolin Ding, Louis DiValentin, Amin Hass, Benjamin F Morris, Isaac Jacobson, Randolph Linderman, James Kiessling, Nicolas Ramos, Bhavna Gopal, Maziyar Baran Pouyan, Changwei Liu, Hai Li, Yiran Chen",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.00668"" target=""_blank"">2506.00668</a>",,2025-12-03 22:39:25
Monitoring Robustness and Individual Fairness,"Ashutosh Gupta, Thomas A. Henzinger, Konstantin Kueffner, Kaushik Mallik, David Pape",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.00496"" target=""_blank"">2506.00496</a>",,2025-12-03 22:39:25
RARE: Retrieval-Aware Robustness Evaluation for Retrieval-Augmented Generation Systems,"Yixiao Zeng, Tianyu Cao, Danqing Wang, Xinran Zhao, Zimeng Qiu, Morteza Ziyadi, Tongshuang Wu, Lei Li",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.00789"" target=""_blank"">2506.00789</a>",,2025-12-03 22:39:25
The Amazon Nova Family of Models: Technical Report and Model Card,"Amazon JC AGI, Aaron JC Langford, Aayush JC Shah, Abhanshu JC Gupta, Abhimanyu JC Bhatter, Abhinav JC Goyal, Abhinav JC Mathur, Abhinav JC Mohanty, Abhishek JC Kumar, Abhishek JC Sethi, Abi JC Komma, Abner JC Pena, Achin JC Jain, Adam JC Kunysz, Adam JC Opyrchal, Adarsh JC Singh, Aditya JC Rawal, Adok Achar Budihal JC Prasad, Gispert Adrià JC de, Agnika JC Kumar, Aishwarya JC Aryamane, Ajay JC Nair, Akilan JC M, Akshaya JC Iyengar, Akshaya Vishnu Kudlu JC Shanbhogue, Alan JC He, Alessandra JC Cervone, Alex JC Loeb, Alex JC Zhang, Alexander JC Fu, Alexander JC Lisnichenko, Alexander JC Zhipa, Alexandros JC Potamianos, Ali JC Kebarighotbi, Aliakbar JC Daronkolaei, Alok JC Parmesh, Amanjot Kaur JC Samra, Ameen JC Khan, Amer JC Rez, Amir JC Saffari, Amit JC Agarwalla, Amit JC Jhindal, Amith JC Mamidala, Ammar JC Asmro, Amulya JC Ballakur, Anand JC Mishra, Anand JC Sridharan, Anastasiia JC Dubinina, Andre JC Lenz, Andreas JC Doerr, Andrew JC Keating, Andrew JC Leaver, Andrew JC Smith, Andrew JC Wirth, Andy JC Davey, Andy JC Rosenbaum, Andy JC Sohn, Angela JC Chan, Aniket JC Chakrabarti, Anil JC Ramakrishna, Anirban JC Roy, Anita JC Iyer, Anjali JC Narayan-Chen, Ankith JC Yennu, Anna JC Dabrowska, Anna JC Gawlowska, Anna JC Rumshisky, Anna JC Turek, Anoop JC Deoras, Anton JC Bezruchkin, Anup JC Prasad, Anupam JC Dewan, Anwith JC Kiran, Apoorv JC Gupta, Aram JC Galstyan, Aravind JC Manoharan, Arijit JC Biswas, Arindam JC Mandal, Arpit JC Gupta, Arsamkhan JC Pathan, Arun JC Nagarajan, Arushan JC Rajasekaram, Arvind JC Sundararajan, Ashwin JC Ganesan, Ashwin JC Swaminathan, Athanasios JC Mouchtaris, Audrey JC Champeau, Avik JC Ray, Ayush JC Jaiswal, Ayush JC Sharma, Bailey JC Keefer, Balamurugan JC Muthiah, Beatriz JC Leon-Millan, Ben JC Koopman, Ben JC Li, Benjamin JC Biggs, Benjamin JC Ott, Bhanu JC Vinzamuri, Bharath JC Venkatesh, Bhavana JC Ganesh, Bhoomit JC Vasani, Bill JC Byrne, Bill JC Hsu, Bincheng JC Wang, Blake JC King, Blazej JC Gorny, Bo JC Feng, Bo JC Zheng, Bodhisattwa JC Paul, Bofan JC Sun, Bofeng JC Luo, Bowen JC Chen, Bowen JC Xie, Boya JC Yu, Brendan JC Jugan, Brett JC Panosh, Brian JC Collins, Brian JC Thompson, Can JC Karakus, Can JC Liu, Carl JC Lambrecht, Carly JC Lin, Carolyn JC Wang, Carrie JC Yuan, Casey JC Loyda, Cezary JC Walczak, Chalapathi JC Choppa, Chandana Satya JC Prakash, Chankrisna Richy JC Meas, Charith JC Peris, Charles JC Recaido, Charlie JC Xu, Charul JC Sharma, Chase JC Kernan, Chayut JC Thanapirom, Chengwei JC Su, Chenhao JC Xu, Chenhao JC Yin, Chentao JC Ye, Chenyang JC Tao, Chethan JC Parameshwara, Ching-Yun JC Chang, Chong JC Li, Chris JC Hench, Chris JC Tran, Christophe JC Dupuy, Christopher JC Davis, Christopher JC DiPersio, Christos JC Christodoulopoulos, Christy JC Li, Chun JC Chen, Claudio Delli JC Bovi, Clement JC Chung, Cole JC Hawkins, Connor JC Harris, Corey JC Ropell, Cynthia JC He, DK JC Joo, Dae Yon JC Hwang, Dan JC Rosen, Daniel JC Elkind, Daniel JC Pressel, Daniel JC Zhang, Danielle JC Kimball, Daniil JC Sorokin, Dave JC Goodell, Davide JC Modolo, Dawei JC Zhu, Deepikaa JC Suresh, Deepti JC Ragha, Denis JC Filimonov, Denis Foo JC Kune, Denis Romasanta JC Rodriguez, Devamanyu JC Hazarika, Dhananjay JC Ram, Dhawal JC Parkar, Dhawal JC Patel, Dhwanil JC Desai, Dinesh Singh JC Rajput, Disha JC Sule, Diwakar JC Singh, Dmitriy JC Genzel, Dolly JC Goldenberg, Dongyi JC He, Dumitru JC Hanciu, Dushan JC Tharmal, Dzmitry JC Siankovich, Edi JC Cikovic, Edwin JC Abraham, Ekraam JC Sabir, Elliott JC Olson, Emmett JC Steven, Emre JC Barut, Eric JC Jackson, Ethan JC Wu, Evelyn JC Chen, Ezhilan JC Mahalingam, Fabian JC Triefenbach, Fan JC Yang, Fangyu JC Liu, Fanzi JC Wu, Faraz JC Tavakoli, Farhad JC Khozeimeh, Feiyang JC Niu, Felix JC Hieber, Feng JC Li, Firat JC Elbey, Florian JC Krebs, Florian JC Saupe, Florian JC Sprünken, Frank JC Fan, Furqan JC Khan, Vincenzo Gabriela JC De, Gagandeep JC Kang, George JC Ding, George JC He, George JC Yeung, Ghada JC Qaddoumi, Giannis JC Karamanolakis, Goeric JC Huybrechts, Gokul JC Maddali, Gonzalo JC Iglesias, Gordon JC McShane, Gozde JC Sahin, Guangtai JC Huang, Gukyeong JC Kwon, Gunnar A. JC Sigurdsson, Gurpreet JC Chadha, Gururaj JC Kosuru, Hagen JC Fuerstenau, Hah JC Hah, Haja JC Maideen, Hajime JC Hosokawa, Han JC Liu, Han-Kai JC Hsu, Hann JC Wang, Hao JC Li, Hao JC Yang, Haofeng JC Zhu, Haozheng JC Fan, Harman JC Singh, Harshavardhan JC Kaluvala, Hashim JC Saeed, He JC Xie, Helian JC Feng, Hendrix JC Luo, Hengzhi JC Pei, Henrik JC Nielsen, Hesam JC Ilati, Himanshu JC Patel, Hongshan JC Li, Hongzhou JC Lin, Hussain JC Raza, Ian JC Cullinan, Imre JC Kiss, Inbarasan JC Thangamani, Indrayani JC Fadnavis, Ionut Teodor JC Sorodoc, Irem JC Ertuerk, Iryna JC Yemialyanava, Ishan JC Soni, Ismail JC Jelal, Ivan JC Tse, Jack JC FitzGerald, Jack JC Zhao, Jackson JC Rothgeb, Jacky JC Lee, Jake JC Jung, Jakub JC Debski, Jakub JC Tomczak, James JC Jeun, James JC Sanders, Jason JC Crowley, Jay JC Lee, Jayakrishna Anvesh JC Paidy, Jayant JC Tiwari, Jean JC Farmer, Jeff JC Solinsky, Jenna JC Lau, Jeremy JC Savareese, Jerzy JC Zagorski, Ji JC Dai, JC Jiacheng, Skyler Gu, Jiahui Skyler Li, Skyler Jian, QZ Zheng, Jianhua QZ Lu, Jianhua QZ Wang, Jiawei QZ Dai, Jiawei QZ Mo, Jiaxi QZ Xu, Jie QZ Liang, Jie QZ Yang, Jim QZ Logan, Jimit QZ Majmudar, Jing QZ Liu, Jinghong QZ Miao, Jingru QZ Yi, Jingyang QZ Jin, Jiun-Yu QZ Kao, Jixuan QZ Wang, Jiyang QZ Wang, Joe QZ Pemberton, Joel QZ Carlson, Joey QZ Blundell, John QZ Chin-Jew, John QZ He, Jonathan QZ Ho, Jonathan QZ Hueser, Jonathan QZ Lunt, Jooyoung QZ Lee, Joshua QZ Tan, Joyjit QZ Chatterjee, Judith QZ Gaspers, Jue QZ Wang, Jun QZ Fang, Jun QZ Tang, Jun QZ Wan, Jun QZ Wu, Junlei QZ Wang, Junyi QZ Shi, Justin QZ Chiu, Justin QZ Satriano, Justin QZ Yee, Jwala QZ Dhamala, Jyoti QZ Bansal, Kai QZ Zhen, Kai-Wei QZ Chang, Kaixiang QZ Lin, Kalyan QZ Raman, Kanthashree Mysore QZ Sathyendra, Karabo QZ Moroe, Karan QZ Bhandarkar, Karan QZ Kothari, Karolina QZ Owczarzak, Karthick QZ Gopalswamy, Karthick QZ Ravi, Karthik QZ Ramakrishnan, Karthika QZ Arumugam, Kartik QZ Mehta, Katarzyna QZ Konczalska, Kavya QZ Ravikumar, Ke QZ Tran, Kechen QZ Qin, Kelin QZ Li, Kelvin QZ Li, Ketan QZ Kulkarni, Kevin Angelo QZ Rodrigues, Keyur QZ Patel, Khadige QZ Abboud, Kiana QZ Hajebi, Klaus QZ Reiter, Kris QZ Schultz, Krishna QZ Anisetty, Krishna QZ Kotnana, Kristen QZ Li, Kruthi QZ Channamallikarjuna, Krzysztof QZ Jakubczyk, Kuba QZ Pierewoj, Kunal QZ Pal, Kunwar QZ Srivastav, Kyle QZ Bannerman, Lahari QZ Poddar, Lakshmi QZ Prasad, Larry QZ Tseng, Laxmikant QZ Naik, Leena Chennuru QZ Vankadara, Lenon QZ Minorics, Leo QZ Liu, Leonard QZ Lausen, Leonardo F. R. QZ Ribeiro, Li QZ Zhang, Lili QZ Gehorsam, Ling QZ Qi, Lisa QZ Bauer, Lori QZ Knapp, Lu QZ Zeng, Lucas QZ Tong, Lulu QZ Wong, Luoxin QZ Chen, Maciej QZ Rudnicki, Mahdi QZ Namazifar, Mahesh QZ Jaliminche, Maira Ladeira QZ Tanke, Manasi QZ Gupta, Mandeep QZ Ahlawat, Mani QZ Khanuja, Mani QZ Sundaram, Marcin QZ Leyk, Mariusz QZ Momotko, Markus QZ Boese, Markus QZ Dreyer, Markus QZ Mueller, Mason QZ Fu, Mateusz QZ Górski, Mateusz QZ Mastalerczyk, Matias QZ Mora, Matt QZ Johnson, Matt QZ Scott, Matthew QZ Wen, Max QZ Barysau, Maya QZ Boumerdassi, Maya QZ Krishnan, Mayank QZ Gupta, Mayank QZ Hirani, Mayank QZ Kulkarni, Meganathan QZ Narayanasamy, Melanie QZ Bradford, Melanie QZ Gens, Melissa QZ Burke, Meng QZ Jin, Miao QZ Chen, Michael QZ Denkowski, Michael QZ Heymel, Michael QZ Krestyaninov, Michal QZ Obirek, Michalina QZ Wichorowska, Michał QZ Miotk, Milosz QZ Watroba, Mingyi QZ Hong, Mingzhi QZ Yu, Miranda QZ Liu, Mohamed QZ Gouda, Mohammad QZ El-Shabani, Mohammad QZ Ghavamzadeh, Mohit QZ Bansal, Morteza QZ Ziyadi, Nan QZ Xia, Nathan QZ Susanj, Nav QZ Bhasin, Neha QZ Goswami, Nehal QZ Belgamwar, Nicolas QZ Anastassacos, Nicolas QZ Bergeron, Nidhi QZ Jain, Nihal QZ Jain, Niharika QZ Chopparapu, Nik QZ Xu, Nikko QZ Strom, Nikolaos QZ Malandrakis, Nimisha QZ Mishra, Ninad QZ Parkhi, Ninareh QZ Mehrabi, Nishita QZ Sant, Nishtha QZ Gupta, Nitesh QZ Sekhar, Nithin QZ Rajeev, Nithish Raja QZ Chidambaram, Nitish QZ Dhar, Noor QZ Bhagwagar, Noy QZ Konforty, Omar QZ Babu, Omid QZ Razavi, Orchid QZ Majumder, Osama QZ Dar, Oscar QZ Hsu, Pablo QZ Kvitca, Pallavi QZ Pandey, Parker QZ Seegmiller, Patrick QZ Lange, Paul QZ Ferraro, Payal QZ Motwani, Pegah QZ Kharazmi, Pei QZ Wang, Pengfei QZ Liu, Peter QZ Bradtke, Peter QZ Götz, Peter QZ Zhou, Pichao QZ Wang, Piotr QZ Poskart, Pooja QZ Sonawane, Pradeep QZ Natarajan, Pradyun QZ Ramadorai, Pralam QZ Shah, Prasad QZ Nirantar, Prasanthi QZ Chavali, Prashan QZ Wanigasekara, Prashant QZ Saraf, Prashun QZ Dey, Pratyush QZ Pant, Prerak QZ Pradhan, Preyaa QZ Patel, Priyanka QZ Dadlani, Prudhvee Narasimha QZ Sadha, Qi QZ Dong, Qian QZ Hu, QZ Qiaozi, Sean Gao, Qing Sean Liu, Quinn Sean Lam, Quynh Sean Do, R. Sean Manmatha, Rachel Sean Willis, Rafael Sean Liu, Rafal Sean Ellert, Rafal Sean Kalinski, Rafi Al Sean Attrach, Ragha Sean Prasad, Ragini Sean Prasad, Raguvir Sean Kunani, Rahul Sean Gupta, Rahul Sean Sharma, Rahul Sean Tewari, Rajaganesh Sean Baskaran, Rajan Sean Singh, Rajiv Sean Gupta, Rajiv Sean Reddy, Rajshekhar Sean Das, Rakesh Sean Chada, Rakesh Vaideeswaran Sean Mahesh, Ram Sean Chandrasekaran, Ramesh Sean Nallapati, Ran Sean Xue, Rashmi Sean Gangadharaiah, Ravi Sean Rachakonda, Renxian Sean Zhang, Rexhina Sean Blloshmi, Rishabh Sean Agrawal, Robert Sean Enyedi, Robert Sean Lowe, Robik Sean Shrestha, Robinson Sean Piramuthu, Rohail Sean Asad, Rohan Sean Khanna, Rohan Sean Mukherjee, Rohit Sean Mittal, Rohit Sean Prasad, Rohith Mysore Vijaya Sean Kumar, Ron Sean Diamant, Ruchita Sean Gupta, Ruiwen Sean Li, Ruoying Sean Li, Rushabh Sean Fegade, Ruxu Sean Zhang, Ryan Sean Arbow, Ryan Sean Chen, Ryan Sean Gabbard, Ryan Sean Hoium, Ryan Sean King, Sabarishkumar Sean Iyer, Sachal Sean Malick, Sahar Sean Movaghati, Sai Sean Balakavi, Sai Sean Jakka, Sai Kashyap Sean Paruvelli, Sai Muralidhar Sean Jayanthi, Saicharan Shriram Sean Mujumdar, Sainyam Sean Kapoor, Sajjad Sean Beygi, Saket Sean Dingliwal, Saleh Sean Soltan, Sam Sean Ricklin, Sam Sean Tucker, Sameer Sean Sinha, Samridhi Sean Choudhary, Samson Sean Tan, Samuel Sean Broscheit, Samuel Sean Schulter, Sanchit Sean Agarwal, Sandeep Sean Atluri, Sander Sean Valstar, Sanjana Sean Shankar, Sanyukta Sean Sanyukta, Sarthak Sean Khanna, Sarvpriye Sean Khetrapal, Satish Sean Janakiraman, Saumil Sean Shah, Saurabh Sean Akolkar, Saurabh Sean Giri, Saurabh Sean Khandelwal, Saurabh Sean Pawar, Saurabh Sean Sahu, Sean Sean Huang, Sejun Sean Ra, Senthilkumar Sean Gopal, Sergei Sean Dobroshinsky, Shadi Sean Saba, Shamik Sean Roy, Shamit Sean Lal, Shankar Sean Ananthakrishnan, Sharon Sean Li, Shashwat Sean Srijan, Shekhar Sean Bhide, Sheng Long Sean Tang, Sheng Sean Zha, Shereen Sean Oraby, Sherif Sean Mostafa, Shiqi Sean Li, Shishir Sean Bharathi, Shivam Sean Prakash, Shiyuan Sean Huang, Shreya Sean Yembarwar, Shreyas Sean Pansare, Shreyas Sean Subramanian, Shrijeet Sean Joshi, Shuai Sean Liu, Shuai Sean Tang, Shubham Sean Chandak, Shubham Sean Garg, Shubham Sean Katiyar, Shubham Sean Mehta, Shubham Sean Srivastav, Shuo Sean Yang, Siddalingesha D Sean S, Siddharth Sean Choudhary, Siddharth Singh Sean Senger, Simon Sean Babb, Sina Sean Moeini, Siqi Sean Deng, Siva Sean Loganathan, Slawomir Sean Domagala, Sneha Sean Narkar, Sneha Sean Wadhwa, Songyang Sean Zhang, Songyao Sean Jiang, Sony Sean Trenous, Soumajyoti Sean Sarkar, Soumya Sean Saha, Sourabh Sean Reddy, Sourav Sean Dokania, Spurthideepika Sean Sandiri, Spyros Sean Matsoukas, Sravan Sean Bodapati, Sri Harsha Reddy Sean Wdaru, Sridevi Yagati Sean Venkateshdatta, Srikanth Sean Ronanki, Srinivasan R Sean Veeravanallur, Sriram Sean Venkatapathy, Sriramprabhu Sean Sankaraguru, Sruthi Sean Gorantla, Sruthi Sean Karuturi, Stefan Sean Schroedl, Subendhu Sean Rongali, Subhasis Sean Kundu, Suhaila Sean Shakiah, Sukriti Sean Tiwari, Sumit Sean Bharti, Sumita Sean Sami, Sumith Sean Mathew, Sunny Sean Yu, Sunwoo Sean Kim, Suraj Bajirao Sean Malode, Susana Cumplido Sean Riel, Swapnil Sean Palod, Swastik Sean Roy, Syed Sean Furqhan, Tagyoung Sean Chung, Takuma Sean Yoshitani, Taojiannan Sean Yang, Tejaswi Sean Chillakura, Tejwant Sean Bajwa, Temi Sean Lajumoke, Thanh Sean Tran, Thomas Sean Gueudre, Thomas Sean Jung, Tianhui Sean Li, Tim Sean Seemman, Timothy Sean Leffel, Tingting Sean Xiang, Tirth Sean Patel, Tobias Sean Domhan, Tobias Sean Falke, Toby Sean Guo, Tom Sean Li, Tomasz Sean Horszczaruk, Tomasz Sean Jedynak, Tushar Sean Kulkarni, Tyst Sean Marin, Tytus Sean Metrycki, Tzu-Yen Sean Wang, Umang Sean Jain, Upendra Sean Singh, Utkarsh Sean Chirimar, Vaibhav Sean Gupta, Vanshil Sean Shah, Varad Sean Deshpande, Varad Sean Gunjal, Varsha Sean Srikeshava, Varsha Sean Vivek, Varun Sean Bharadwaj, Varun Sean Gangal, Varun Sean Kumar, Venkatesh Sean Elango, Vicente Sean Ordonez, Victor Sean Soto, Vignesh Sean Radhakrishnan, Vihang Sean Patel, Vikram Sean Singh, Vinay Varma Sean Kolanuvada, Vinayshekhar Bannihatti Sean Kumar, Vincent Sean Auvray, Vincent Sean Cartillier, Vincent Sean Ponzo, Violet Sean Peng, Vishal Sean Khandelwal, Vishal Sean Naik, Vishvesh Sean Sahasrabudhe, Vitaliy Sean Korolev, Vivek Sean Gokuladas, Vivek Sean Madan, Vivek Sean Subramanian, Volkan Sean Cevher, Vrinda Sean Gupta, Wael Sean Hamza, Wei Sean Zhang, Weitong Sean Ruan, Weiwei Sean Cheng, Wen Sean Zhang, Wenbo Sean Zhao, Wenyan Sean Yao, Wenzhuo Sean Ouyang, Wesley Sean Dashner, William Sean Campbell, William Sean Lin, Willian Sean Martin, Wyatt Sean Pearson, Xiang Sean Jiang, Xiangxing Sean Lu, Xiangyang Sean Shi, Xianwen Sean Peng, Xiaofeng Sean Gao, Xiaoge Sean Jiang, Xiaohan Sean Fei, Xiaohui Sean Wang, Xiaozhou Joey Sean Zhou, Xin Sean Feng, Xinyan Sean Zhao, Xinyao Sean Wang, Xinyu Sean Li, Xu Sean Zhang, Xuan Sean Wang, Xuandi Sean Fu, Xueling Sean Yuan, Xuning Sean Wang, Yadunandana Sean Rao, Yair Sean Tavizon, Yan Sean Rossiytsev, Yanbei Sean Chen, Yang Sean Liu, Yang Sean Zou, Yangsook Sean Park, Yannick Sean Versley, Yanyan Sean Zhang, Yash Sean Patel, Yen-Cheng Sean Lu, Yi Sean Pan, Sean Yi-Hsiang, Rex Lai, Yichen Rex Hu, Yida Rex Wang, Yiheng Rex Zhou, Yilin Rex Xiang, Ying Rex Shi, Ying Rex Wang, Yishai Rex Galatzer, Yongxin Rex Wang, Yorick Rex Shen, Yuchen Rex Sun, Yudi Rex Purwatama, Rex Yue, Chris Wu, Yue Chris Gu, Yuechun Chris Wang, Yujun Chris Zeng, Yuncong Chris Chen, Yunke Chris Zhou, Yusheng Chris Xie, Yvon Chris Guy, Zbigniew Chris Ambrozinski, Zhaowei Chris Cai, Zhen Chris Zhang, Zheng Chris Wang, Zhenghui Chris Jin, Zhewei Chris Zhao, Zhiheng Chris Li, Zhiheng Chris Luo, Zhikang Chris Zhang, Zhilin Chris Fang, Zhiqi Chris Bu, Zhiyuan Chris Wang, Zhizhong Chris Li, Zijian Chris Wang, Chris Zimeng, Qiu, Zishi Li",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12103"" target=""_blank"">2506.12103</a>",,2025-12-03 22:39:25
3D Gaussian Splat Vulnerabilities,"Matthew Hull, Haoyang Yang, Pratham Mehta, Mansi Phute, Aeree Cho, Haoran Wang, Matthew Lau, Wenke Lee, Willian T. Lunardi, Martin Andreoni, Polo Chau",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.00280"" target=""_blank"">2506.00280</a>",,2025-12-03 22:39:25
Adversarial Machine Learning for Robust Password Strength Estimation,"Pappu Jha, Hanzla Hamid, Oluseyi Olukola, Ashim Dahal, Nick Rahimi",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.00373"" target=""_blank"">2506.00373</a>",,2025-12-03 22:39:25
Towards Effective and Efficient Adversarial Defense with Diffusion Models for Robust Visual Tracking,"Long Xu, Peng Gao, Wen-Jia Tang, Fei Wang, Ru-Yue Yuan",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.00325"" target=""_blank"">2506.00325</a>","<a href=""https://github.com/pgao-lab/DiffDf"" target=""_blank"">pgao-lab</a>",2025-12-03 22:39:25
No Soundness in the Real World: On the Challenges of the Verification of Deployed Neural Networks,"Attila Szász, Balázs Bánhelyi, Márk Jelasity",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.01054"" target=""_blank"">2506.01054</a>",,2025-12-03 22:39:25
Heterogeneous Graph Backdoor Attack,"Jiawei Chen, Lusi Li, Daniel Takabi, Masha Sosonkina, Rui Ning",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.00191"" target=""_blank"">2506.00191</a>",,2025-12-03 22:39:25
Shadow defense against gradient inversion attack in federated learning,"Le Jiang, Liyan Ma, Guang Yang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.15711"" target=""_blank"">2506.15711</a>",,2025-12-03 22:39:25
"Towards Secure MLOps: Surveying Attacks, Mitigation Strategies, and Research Challenges","Raj Patel, Himanshu Tripathi, Jasper Stone, Noorbakhsh Amiri Golilarz, Sudip Mittal, Shahram Rahimi, Vini Chaudhary",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.02032"" target=""_blank"">2506.02032</a>",,2025-12-03 22:39:25
Keeping an Eye on LLM Unlearning: The Hidden Risk and Remedy,"Jie Ren, Zhenwei Dai, Xianfeng Tang, Yue Xing, Shenglai Zeng, Hui Liu, Jingying Zeng, Qiankun Peng, Samarth Varshney, Suhang Wang, Qi He, Charu C. Aggarwal, Hui Liu",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.00359"" target=""_blank"">2506.00359</a>",,2025-12-03 22:39:25
Are classical deep neural networks weakly adversarially robust? (99%),"Nuolin Sun, Linyuan Wang, Dongyang Li, Bin Yan, Lei Li",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.02016"" target=""_blank"">2506.02016</a>",,2025-12-03 22:39:25
Distributionally Robust Wireless Semantic Communication with Large AI Models,"Long Tan Le, Senura Hansaja Wanasekara, Zerun Niu, Yansong Shi, Nguyen H. Tran, Phuong Vo, Walid Saad, Dusit Niyato, Zhu Han, Choong Seon Hong, H. Vincent Poor",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.03167"" target=""_blank"">2506.03167</a>",,2025-12-03 22:39:25
Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs,"Xiang Li, Chong Zhang, Jia Wang, Fangyu Wu, Yushi Li, Xiaobo Jin",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.17231"" target=""_blank"">2506.17231</a>",,2025-12-03 22:39:25
CellCLIP -- Learning Perturbation Effects in Cell Painting via Text-Guided Contrastive Learning,"Mingyu Lu, Ethan Weinberger, Chanwoo Kim, Su-In Lee",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06290"" target=""_blank"">2506.06290</a>",,2025-12-03 22:39:25
Poster: Adapting Pretrained Vision Transformers with LoRA Against Attack Vectors,"Richard E. Neddo, Sean Willis, Zander Blasingame, Chen Liu",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.00661"" target=""_blank"">2506.00661</a>",,2025-12-03 22:39:25
On the Stability of Graph Convolutional Neural Networks: A Probabilistic Perspective,"Ning Zhang, Henry Kenlay, Li Zhang, Mihai Cucuringu, Xiaowen Dong",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.01213"" target=""_blank"">2506.01213</a>",,2025-12-03 22:39:25
Poster: FedBlockParadox -- A Framework for Simulating and Securing Decentralized Federated Learning,"Gabriele Digregorio, Francesco Bleggi, Federico Caroli, Michele Carminati, Stefano Zanero, Stefano Longari",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.02679"" target=""_blank"">2506.02679</a>",,2025-12-03 22:39:25
Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation,"Yuan Gan, Jiaxu Miao, Yunze Wang, Yi Yang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.01591"" target=""_blank"">2506.01591</a>","<a href=""https://github.com/yuangan/Silencer"" target=""_blank"">yuangan</a>",2025-12-03 22:39:25
Robust Anti-Backdoor Instruction Tuning in LVLMs,"Yuan Xun, Siyuan Liang, Xiaojun Jia, Xinwei Liu, Xiaochun Cao",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.05401"" target=""_blank"">2506.05401</a>",,2025-12-03 22:39:25
BitBypass: A New Direction in Jailbreaking Aligned Large Language Models with Bitstream Camouflage,"Kalyan Nakka, Nitesh Saxena",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.02479"" target=""_blank"">2506.02479</a>",,2025-12-03 22:39:25
Adversarial Attacks on Robotic Vision Language Action Models,"Eliot Krzysztof Jones, Alexander Robey, Andy Zou, Zachary Ravichandran, George J. Pappas, Hamed Hassani, Matt Fredrikson, J. Zico Kolter",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.03350"" target=""_blank"">2506.03350</a>","<a href=""https://github.com/eliotjones1/robogcg"" target=""_blank"">eliotjones1</a>",2025-12-03 22:39:25
Robustness in Both Domains: CLIP Needs a Robust Text Encoder,"Elias Abad Rocamora, Christian Schlarmann, Naman Deep Singh, Yongtao Wu, Matthias Hein, Volkan Cevher",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.03355"" target=""_blank"">2506.03355</a>",,2025-12-03 22:39:25
Explicitly Modeling Subcortical Vision with a Neuro-Inspired Front-End Improves CNN Robustness,"Lucas Piper, Arlindo L. Oliveira, Tiago Marques",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.03089"" target=""_blank"">2506.03089</a>",,2025-12-03 22:39:25
BadReward: Clean-Label Poisoning of Reward Models in Text-to-Image RLHF,"Kaiwen Duan, Hongwei Yao, Yufei Chen, Ziyun Li, Tong Qiao, Zhan Qin, Cong Wang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.03234"" target=""_blank"">2506.03234</a>",,2025-12-03 22:39:25
Enhancing Diffusion-based Unrestricted Adversarial Attacks via Adversary Preferences Alignment,"Kaixun Jiang, Zhaoyu Chen, Haijing Guo, Jinglun Li, Jiyuan Fu, Pinxue Guo, Hao Tang, Bo Li, Wenqiang Zhang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.01511"" target=""_blank"">2506.01511</a>","<a href=""https://github.com/deep-kaixun/APA"" target=""_blank"">deep-kaixun</a>",2025-12-03 22:39:25
MISLEADER: Defending against Model Extraction with Ensembles of Distilled Models,"Xueqi Cheng, Minxing Zheng, Shixiang Zhu, Yushun Dong",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.02362"" target=""_blank"">2506.02362</a>","<a href=""https://github.com/LabRAI/MISLEADER"" target=""_blank"">LabRAI</a>",2025-12-03 22:39:25
Which Factors Make Code LLMs More Vulnerable to Backdoor Attacks? A Systematic Study,"Chenyu Wang, Zhou Yang, Yaniv Harel, David Lo",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.01825"" target=""_blank"">2506.01825</a>",,2025-12-03 22:39:25
Simple Prompt Injection Attacks Can Leak Personal Data Observed by LLM Agents During Task Execution,"Meysam Alizadeh, Zeynab Samei, Daria Stetsenko, Fabrizio Gilardi",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.01055"" target=""_blank"">2506.01055</a>",,2025-12-03 22:39:25
Mitigating Data Poisoning Attacks to Local Differential Privacy,"Xiaolin Li, Ninghui Li, Boyang Wang, Wenhai Sun",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.02156"" target=""_blank"">2506.02156</a>",,2025-12-03 22:39:25
Align is not Enough: Multimodal Universal Jailbreak Attack against Multimodal Large Language Models,"Youze Wang, Wenbo Hu, Yinpeng Dong, Jing Liu, Hanwang Zhang, Richang Hong",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.01307"" target=""_blank"">2506.01307</a>",,2025-12-03 22:39:25
Predictive-CSM: Lightweight Fragment Security for 6LoWPAN IoT Networks,Somayeh Sobati-M,arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.01767"" target=""_blank"">2506.01767</a>",,2025-12-03 22:39:25
Robust Satisficing Gaussian Process Bandits Under Adversarial Attacks,"Artun Saday, Yaşar Cahit Yıldırım, Cem Tekin",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.01625"" target=""_blank"">2506.01625</a>",,2025-12-03 22:39:25
CAPAA: Classifier-Agnostic Projector-Based Adversarial Attack,"Zhan Li, Mingyu Zhao, Xin Dong, Haibin Ling, Bingyao Huang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.00978"" target=""_blank"">2506.00978</a>","<a href=""https://github.com/ZhanLiQxQ/CAPAA"" target=""_blank"">ZhanLiQxQ</a>",2025-12-03 22:39:25
Fighting Fire with Fire (F3): A Training-free and Efficient Visual Adversarial Example Purification Method in LVLMs,"Yudong Zhang, Ruobing Xie, Yiqing Huang, Jiansheng Chen, Xingwu Sun, Zhanhui Kang, Di Wang, Yu Wang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.01064"" target=""_blank"">2506.01064</a>",,2025-12-03 22:39:25
Breaking Latent Prior Bias in Detectors for Generalizable AIGC Image Detection,"Yue Zhou, Xinan He, KaiQing Lin, Bin Fan, Feng Ding, Bin Li",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.00874"" target=""_blank"">2506.00874</a>",,2025-12-03 22:39:25
Adversarial learning for nonparametric regression: Minimax rate and adaptive estimation,"Jingfu Peng, Yuhong Yang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.01267"" target=""_blank"">2506.01267</a>",,2025-12-03 22:39:25
FREE: Fast and Robust Vision Language Models with Early Exits,"Divya Jyoti Bajpai, Manjesh Kumar Hanawal",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06884"" target=""_blank"">2506.06884</a>","<a href=""https://github.com/Div290/FREE"" target=""_blank"">Div290</a>",2025-12-03 22:39:25
SafeTuneBed: A Toolkit for Benchmarking LLM Safety Alignment in Fine-Tuning,"Saad Hossain, Samanvay Vajpayee, Sirisha Rambhatla",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.00676"" target=""_blank"">2506.00676</a>","<a href=""https://github.com/criticalml-uw/SafeTuneBed"" target=""_blank"">criticalml-uw</a>",2025-12-03 22:39:25
Can In-Context Reinforcement Learning Recover From Reward Poisoning Attacks? (8%),"Paulius Sasnauskas, Yiğit Yalın, Goran Radanović",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06891"" target=""_blank"">2506.06891</a>",,2025-12-03 22:39:25
A look at adversarial attacks on radio waveforms from discrete latent space,"Attanasia Garuso, Silvija Kokalj-Filipovic, Yagna Kaasaragadda",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.09896"" target=""_blank"">2506.09896</a>",,2025-12-03 22:39:25
Investigating Vulnerabilities and Defenses Against Audio-Visual Attacks: A Comprehensive Survey Emphasizing Multimodal Models,"Jinming Wen, Xinyi Wu, Shuai Zhao, Yanhao Jia, Yuwen Li",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.11521"" target=""_blank"">2506.11521</a>",,2025-12-03 22:39:25
Improving Large Language Model Safety with Contrastive Representation Learning,"Samuel Simko, Mrinmaya Sachan, Bernhard Schölkopf, Zhijing Jin",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.11938"" target=""_blank"">2506.11938</a>","<a href=""https://github.com/samuelsimko/crl-llm-defense"" target=""_blank"">samuelsimko</a>",2025-12-03 22:39:25
InfoFlood: Jailbreaking Large Language Models with Information Overload,"Advait Yadav, Haibo Jin, Man Luo, Jun Zhuang, Haohan Wang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12274"" target=""_blank"">2506.12274</a>",,2025-12-03 22:39:25
DRIFT: Dynamic Rule-Based Defense with Injection Isolation for Securing LLM Agents,"Hao Li, Xiaogeng Liu, Hung-Chun Chiu, Dianqi Li, Ning Zhang, Chaowei Xiao",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12104"" target=""_blank"">2506.12104</a>",,2025-12-03 22:39:25
Machine Unlearning for Robust DNNs: Attribution-Guided Partitioning and Neuron Pruning in Noisy Environments,"Deliang Jin, Gang Chen, Shuo Feng, Yufeng Ling, Haoran Zhu",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.11615"" target=""_blank"">2506.11615</a>",,2025-12-03 22:39:25
EgoPrivacy: What Your First-Person Camera Says About You? (1%),"Yijiang Li, Genpei Zhang, Jiacheng Cheng, Yi Li, Xiaojun Shan, Dashan Gao, Jiancheng Lyu, Yuan Li, Ning Bi, Nuno Vasconcelos",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12258"" target=""_blank"">2506.12258</a>","<a href=""https://github.com/williamium3000/ego-privacy"" target=""_blank"">williamium3000</a>",2025-12-03 22:39:25
Learning Causality for Modern Machine Learning,Yongqiang Chen,arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12226"" target=""_blank"">2506.12226</a>",,2025-12-03 22:39:25
Unsourced Adversarial CAPTCHA: A Bi-Phase Adversarial CAPTCHA Framework,"Xia Du, Xiaoyuan Liu, Jizhe Zhou, Zheng Lin, Chi-man Pun, Cong Wu, Tao Li, Zhe Chen, Wei Ni, Jun Luo",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.10685"" target=""_blank"">2506.10685</a>",,2025-12-03 22:39:25
TED-LaST: Towards Robust Backdoor Defense Against Adaptive Attacks,"Xiaoxing Mo, Yuxuan Cheng, Nan Sun, Leo Yu Zhang, Wei Luo, Shang Gao",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.10722"" target=""_blank"">2506.10722</a>",,2025-12-03 22:39:25
Assessing the Resilience of Automotive Intrusion Detection Systems to Adversarial Manipulation,"Stefano Longari, Paolo Cerracchio, Michele Carminati, Stefano Zanero",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.10620"" target=""_blank"">2506.10620</a>",,2025-12-03 22:39:25
ObfusBFA: A Holistic Approach to Safeguarding DNNs from Different Types of Bit-Flip Attacks,"Xiaobei Yan, Han Qiu, Tianwei Zhang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.10744"" target=""_blank"">2506.10744</a>",,2025-12-03 22:39:25
Monitoring Decomposition Attacks in LLMs with Lightweight Sequential Monitors,"Chen Yueh-Han, Nitish Joshi, Yulin Chen, Maksym Andriushchenko, Rico Angell, He He",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.10949"" target=""_blank"">2506.10949</a>",,2025-12-03 22:39:25
Lattice Climber Attack: Adversarial attacks for randomized mixtures of classifiers,"Lucas Gnecco-Heredia, Benjamin Negrevergne, Yann Chevaleyre",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.10888"" target=""_blank"">2506.10888</a>",,2025-12-03 22:39:25
Deception Against Data-Driven Linear-Quadratic Control,"Filippos Fotiadis, Aris Kanellopoulos, Kyriakos G. Vamvoudakis, Ufuk Topcu",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.11373"" target=""_blank"">2506.11373</a>",,2025-12-03 22:39:25
Efficiency Robustness of Dynamic Deep Learning Systems,"Ravishka Rathnasuriya, Tingxi Li, Zexin Xu, Zihe Song, Mirazul Haque, Simin Chen, Wei Yang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.10831"" target=""_blank"">2506.10831</a>",,2025-12-03 22:39:25
ME: Trigger Element Combination Backdoor Attack on Copyright Infringement,"Feiyu Yang, Siyuan Liang, Aishan Liu, Dacheng Tao",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.10776"" target=""_blank"">2506.10776</a>",,2025-12-03 22:39:25
Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization,"Stone Yun, Alexander Wong",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.10463"" target=""_blank"">2506.10463</a>",,2025-12-03 22:39:25
SOFT: Selective Data Obfuscation for Protecting LLM Fine-tuning against Membership Inference Attacks,"Kaiyuan Zhang, Siyuan Cheng, Hanxi Guo, Yuetian Chen, Zian Su, Shengwei An, Yuntao Du, Charles Fleming, Ashish Kundu, Xiangyu Zhang, Ninghui Li",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.10424"" target=""_blank"">2506.10424</a>",,2025-12-03 22:39:25
Bias Amplification in RAG: Poisoning Knowledge Retrieval to Steer LLMs,"Linlin Wang, Tianqing Zhu, Laiqiao Qin, Longxiang Gao, Wanlei Zhou",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.11415"" target=""_blank"">2506.11415</a>",,2025-12-03 22:39:25
On the Natural Robustness of Vision-Language Models Against Visual Perception Attacks in Autonomous Driving,"Pedram Clemson University, Clemson, SC, USA MohajerAnsari, Amir Clemson University, Clemson, SC, USA Salarpour, Michael Technical University of Munich, Munich, Germany Kühr, Siyu Clemson University, Clemson, SC, USA Huang, Mohammad Technical University of Munich, Munich, Germany Hamad, Sebastian Technical University of Munich, Munich, Germany Steinhorst, Habeeb University of Texas at Arlington, Arlington, TX, USA Olufowobi, Mert D. Clemson University, Clemson, SC, USA Pesé",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.11472"" target=""_blank"">2506.11472</a>",,2025-12-03 22:39:25
"TrustGLM: Evaluating the Robustness of GraphLLMs Against Prompt, Text, and Structure Attacks","Qihai Zhang, Xinyue Sheng, Yuanfu Sun, Qiaoyu Tan",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.11844"" target=""_blank"">2506.11844</a>",,2025-12-03 22:39:25
Attention-based Adversarial Robust Distillation in Radio Signal Classifications for Low-Power IoT Devices,"Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Guisheng Liao, Basil AsSadhan, Fabio Roli",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.11892"" target=""_blank"">2506.11892</a>",,2025-12-03 22:39:25
Position: Certified Robustness Does Not (Yet) Imply Model Security,"Andrew C. Cullen, Paul Montague, Sarah M. Erfani, Benjamin I. P. Rubinstein",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.13024"" target=""_blank"">2506.13024</a>",,2025-12-03 22:39:25
OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents,"Thomas Kuntz, Agatha Duzan, Hao Zhao, Francesco Croce, Zico Kolter, Nicolas Flammarion, Maksym Andriushchenko",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.14866"" target=""_blank"">2506.14866</a>","<a href=""https://github.com/tml-epfl/os-harm"" target=""_blank"">tml-epfl</a>",2025-12-03 22:39:25
Excessive Reasoning Attack on Reasoning LLMs,"Wai Man Si, Mingjie Li, Michael Backes, Yang Zhang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.14374"" target=""_blank"">2506.14374</a>",,2025-12-03 22:39:25
LADSG: Label-Anonymized Distillation and Similar Gradient Substitution for Label Privacy in Vertical Federated Learning,"Zeyu Yan, Yifei Yao, Xuanbing Wen, Juli Zhang, Kai Fan",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06742"" target=""_blank"">2506.06742</a>",,2025-12-03 22:39:25
CertDW: Towards Certified Dataset Ownership Verification via Conformal Prediction,"Ting Qiao, Yiming Li, Jianbin Li, Yingjia Wang, Leyi Qi, Junfeng Guo, Ruili Feng, Dacheng Tao",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.13160"" target=""_blank"">2506.13160</a>","<a href=""https://github.com/NcepuQiaoTing/CertDW"" target=""_blank"">NcepuQiaoTing</a>",2025-12-03 22:39:25
Unlearning-Enhanced Website Fingerprinting Attack: Against Backdoor Poisoning in Anonymous Networks,"Yali Yuan, Kai Xu, Ruolin Ma, Yuchen Zhang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.13563"" target=""_blank"">2506.13563</a>",,2025-12-03 22:39:25
Weakest Link in the Chain: Security Vulnerabilities in Advanced Reasoning Models,"Arjun Krishna, Aaditya Rastogi, Erick Galinkin",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.13726"" target=""_blank"">2506.13726</a>",,2025-12-03 22:39:25
Active Adversarial Noise Suppression for Image Forgery Localization,"Rongxuan Peng, Shunquan Tan, Xianbo Mo, Alex C. Kot, Jiwu Huang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12871"" target=""_blank"">2506.12871</a>",,2025-12-03 22:39:25
Intriguing Frequency Interpretation of Adversarial Robustness for CNNs and ViTs,"Lu Chen, Han Yang, Hu Wang, Yuxin Cao, Shaofeng Li, Yuan Luo",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12875"" target=""_blank"">2506.12875</a>",,2025-12-03 22:39:25
The Safety Reminder: A Soft Prompt to Reactivate Delayed Safety Awareness in Vision-Language Models,"Peiyuan Tang, Haojie Xin, Xiaodong Zhang, Jun Sun, Qin Xia, Zijiang Yang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.15734"" target=""_blank"">2506.15734</a>",,2025-12-03 22:39:25
Step-by-Step Reasoning Attack: Revealing 'Erased' Knowledge in Large Language Models,"Yash Sinha, Manit Baser, Murari Mandal, Dinil Mon Divakaran, Mohan Kankanhalli",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.17279"" target=""_blank"">2506.17279</a>",,2025-12-03 22:39:25
Alphabet Index Mapping: Jailbreaking LLMs through Semantic Dissimilarity,Bilal Saleh Husain,arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12685"" target=""_blank"">2506.12685</a>",,2025-12-03 22:39:25
On the existence of consistent adversarial attacks in high-dimensional linear classification,"Matteo Vilucchio, Lenka Zdeborová, Bruno Loureiro",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12454"" target=""_blank"">2506.12454</a>",,2025-12-03 22:39:25
Second Order State Hallucinations for Adversarial Attack Mitigation in Formation Control of Multi-Agent Systems,"Laksh Patel, Akhilesh Raj",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.17283"" target=""_blank"">2506.17283</a>",,2025-12-03 22:39:25
InverTune: Removing Backdoors from Multimodal Contrastive Learning Models via Trigger Inversion and Activation Tuning,"Mengyuan Sun, Yu Li, Yuchen Liu, Bo Du, Yunjie Ge",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12411"" target=""_blank"">2506.12411</a>",,2025-12-03 22:39:25
SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression,"Yucheng Li, Surin Ahn, Huiqiang Jiang, Amir H. Abdi, Yuqing Yang, Lili Qiu",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12707"" target=""_blank"">2506.12707</a>",,2025-12-03 22:39:25
Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025,"Zonghao Ying, Siyang Wu, Run Hao, Peng Ying, Shixuan Sun, Pengyu Chen, Junze Chen, Hao Du, Kaiwen Shen, Shangkun Wu, Jiwei Wei, Shiyuan He, Yang Yang, Xiaohai Xu, Ke Ma, Qianqian Xu, Qingming Huang, Shi Lin, Xun Wang, Changting Lin, Meng Han, Yilei Jiang, Siqi Lai, Yaozhi Zheng, Yifei Song, Xiangyu Yue, Zonglei Jing, Tianyuan Zhang, Zhilei Zhu, Aishan Liu, Jiakai Wang, Siyuan Liang, Xianglong Kong, Hainan Li, Junjie Mu, Haotong Qin, Yue Yu, Lei Chen, Felix Juefei-Xu, Qing Guo, Xinyun Chen, Yew Soon Ong, Xianglong Liu, Dawn Song, Alan Yuille, Philip Torr, Dacheng Tao",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12430"" target=""_blank"">2506.12430</a>","<a href=""https://github.com/NY1024/ATLAS_Challenge_2025"" target=""_blank"">NY1024</a>",2025-12-03 22:39:25
Existence of Adversarial Examples for Random Convolutional Networks via Isoperimetric Inequalities on $\mathbb{so}(d)$,Amit Daniely,arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12613"" target=""_blank"">2506.12613</a>",,2025-12-03 22:39:25
Image Corruption-Inspired Membership Inference Attacks against Large Vision-Language Models,"Zongyu Wu, Minhua Lin, Zhiwei Zhang, Fali Wang, Xianren Zhang, Xiang Zhang, Suhang Wang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12340"" target=""_blank"">2506.12340</a>",,2025-12-03 22:39:25
"Byzantine Outside, Curious Inside: Reconstructing Data Through Malicious Updates","Kai Yue, Richeng Jin, Chau-Wai Wong, Huaiyu Dai",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.11413"" target=""_blank"">2506.11413</a>",,2025-12-03 22:39:25
Constraint-Guided Prediction Refinement via Deterministic Diffusion Trajectories,"Pantelis Dogoulis, Fabien Bernier, Félix Fourreau, Karim Tit, Maxime Cordy",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.12911"" target=""_blank"">2506.12911</a>",,2025-12-03 22:39:25
LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge,"Songze Li, Chuokun Xu, Jiaying Wang, Xueluan Gong, Chen Chen, Jirui Zhang, Jun Wang, Kwok-Yan Lam, Shouling Ji",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.09443"" target=""_blank"">2506.09443</a>","<a href=""https://github.com/S3IC-Lab/RobustJudge"" target=""_blank"">S3IC-Lab</a>",2025-12-03 22:39:25
Statistical Hypothesis Testing for Auditing Robustness in Language Models,"Paulius Rauba, Qiyao Wei, der Schaar Mihaela van",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07947"" target=""_blank"">2506.07947</a>",,2025-12-03 22:39:25
Your Agent Can Defend Itself against Backdoor Attacks,"Li Changjiang, Liang Jiacheng, Cao Bochuan, Chen Jinghui, Wang Ting",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.08336"" target=""_blank"">2506.08336</a>",,2025-12-03 22:39:25
Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models,"Mickel Liu, Liwei Jiang, Yancheng Liang, Simon Shaolei Du, Yejin Choi, Tim Althoff, Natasha Jaques",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07468"" target=""_blank"">2506.07468</a>",,2025-12-03 22:39:25
Are Trees Really Green? A Detection Approach of IoT Malware Attacks,"Silvia Lucia Sanna, Diego Soi, Davide Maiorca, Giorgio Giacinto",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07836"" target=""_blank"">2506.07836</a>",,2025-12-03 22:39:25
GenBreak: Red Teaming Text-to-Image Generators Using Large Language Models,"Zilong Wang, Xiang Zheng, Xiaosen Wang, Bo Wang, Xingjun Ma, Yu-Gang Jiang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.10047"" target=""_blank"">2506.10047</a>",,2025-12-03 22:39:25
ProARD: progressive adversarial robustness distillation: provide wide range of robust students,"Seyedhamidreza Mousavi, Seyedali Mousavi, Masoud Daneshtalab",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07666"" target=""_blank"">2506.07666</a>",,2025-12-03 22:39:25
HeTa: Relation-wise Heterogeneous Graph Foundation Attack Model,"Yuling Wang, Zihui Chen, Pengfei Jiao, Xiao Wang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07428"" target=""_blank"">2506.07428</a>",,2025-12-03 22:39:25
SPBA: Utilizing Speech Large Language Model for Backdoor Attacks on Speech Classification Models,"Wenhan Yao, Fen Xiao, Xiarun Chen, Jia Liu, YongQiang He, Weiping Wen",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.08346"" target=""_blank"">2506.08346</a>",,2025-12-03 22:39:25
Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models,"Maciej Chrabąszcz, Katarzyna Lorenc, Karolina Seweryn",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07645"" target=""_blank"">2506.07645</a>",,2025-12-03 22:39:25
Single-Node Trigger Backdoor Attacks in Graph-Based Recommendation Systems,"Runze Li, Di Jin, Xiaobao Wang, Dongxiao He, Bingdao Feng, Zhen Wang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.08401"" target=""_blank"">2506.08401</a>",,2025-12-03 22:39:25
Explore the vulnerability of black-box models via diffusion models,"Jiacheng Shi, Yanfu Zhang, Huajie Shao, Ashley Gao",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07590"" target=""_blank"">2506.07590</a>",,2025-12-03 22:39:25
Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks,"Tzu-Ling Lin, Wei-Chih Chen, Teng-Fang Hsiao, Hou-I Liu, Ya-Hsin Yeh, Yu Kai Chan, Wen-Sheng Lien, Po-Yen Kuo, Philip S. Yu, Hong-Han Shuai",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.11113"" target=""_blank"">2506.11113</a>",,2025-12-03 22:39:25
Towards Interpretable Adversarial Examples via Sparse Adversarial Attack,"Fudong Lin, Jiadong Lou, Hao Wang, Brian Jalaian, Xu Yuan",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.17250"" target=""_blank"">2506.17250</a>","<a href=""https://github.com/fudong03/SparseAttack"" target=""_blank"">fudong03</a>",2025-12-03 22:39:25
Adversarial Paraphrasing: A Universal Attack for Humanizing AI-Generated Text,"Yize Cheng, Vinu Sankar Sadasivan, Mehrdad Saberi, Shoumik Saha, Soheil Feizi",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07001"" target=""_blank"">2506.07001</a>",,2025-12-03 22:39:25
Enhanced Consistency Bi-directional GAN(CBiGAN) for Malware Anomaly Detection,"Thesath Wijayasiri, Kar Wai Fok, Vrizlynn L. L. Thing",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07372"" target=""_blank"">2506.07372</a>",,2025-12-03 22:39:25
D2R: dual regularization loss with collaborative adversarial generation for model robustness,"Zhenyu Liu, Huizhi Liang, Rajiv Ranjan, Zhanxing Zhu, Vaclav Snasel, Varun Ojha",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07056"" target=""_blank"">2506.07056</a>",,2025-12-03 22:39:25
KNN-Defense: Defense against 3D Adversarial Point Clouds using Nearest-Neighbor Search,"Nima Jamali, Matina Mahdizadeh Sani, Hanieh Naderi, Shohreh Kasaei",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06906"" target=""_blank"">2506.06906</a>","<a href=""https://github.com/nimajam41/3d-knn-defense"" target=""_blank"">nimajam41</a>",2025-12-03 22:39:25
Backdoor Attack on Vision Language Models with Stealthy Semantic Manipulation,"Zhiyuan Zhong, Zhen Sun, Yepang Liu, Xinlei He, Guanhong Tao",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07214"" target=""_blank"">2506.07214</a>",,2025-12-03 22:39:25
From Static to Adaptive Defense: Federated Multi-Agent Deep Reinforcement Learning-Driven Moving Target Defense Against DoS Attacks in UAV Swarm Networks,"Yuyang Zhou, Guang Cheng, Kang Du, Zihan Chen, Tian Qin, Yuyu Zhao",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07392"" target=""_blank"">2506.07392</a>",,2025-12-03 22:39:25
Circumventing Backdoor Space via Weight Symmetry,"Jie Peng, Hongwei Yang, Jing Zhao, Hengji Dong, Hui He, Weizhe Zhang, Haoyu He",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07467"" target=""_blank"">2506.07467</a>","<a href=""https://github.com/JiePeng104/TSC"" target=""_blank"">JiePeng104</a>",2025-12-03 22:39:25
TokenBreak: Bypassing Text Classification Models Through Token Manipulation,"Kasimir Schulz, Kenneth Yeung, Kieran Evans",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07948"" target=""_blank"">2506.07948</a>",,2025-12-03 22:39:25
SHIELD: Secure Hypernetworks for Incremental Expansion Learning Defense,"Patryk Krukowski, Łukasz Gorczyca, Piotr Helm, Kamil Książek, Przemysław Spurek",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.08255"" target=""_blank"">2506.08255</a>",,2025-12-03 22:39:25
One Patch to Rule Them All: Transforming Static Patches into Dynamic Attacks in the Physical World,"Xingshuo Han, Chen Ling, Shiyi Yao, Haozhao Wang, Hangcheng Liu, Yutong Wu, Shengmin Xu, Changhai Ou, Xinyi Huang, Tianwei Zhang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.08482"" target=""_blank"">2506.08482</a>",,2025-12-03 22:39:25
Evasion Attacks Against Bayesian Predictive Models,"Pablo G. Arce, Roi Naveiro, David Ríos Insua",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.09640"" target=""_blank"">2506.09640</a>",,2025-12-03 22:39:25
AngleRoCL: Angle-Robust Concept Learning for Physically View-Invariant T2I Adversarial Patches,"Wenjun Ji, Yuxiang Fu, Luyang Ying, Deng-Ping Fan, Yuyi Wang, Ming-Ming Cheng, Ivor Tsang, Qing Guo",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.09538"" target=""_blank"">2506.09538</a>",,2025-12-03 22:39:25
Apollo: A Posteriori Label-Only Membership Inference Attack Towards Machine Unlearning,"Liou Tang, James Joshi, Ashish Kundu",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.09923"" target=""_blank"">2506.09923</a>",,2025-12-03 22:39:25
Token Constraint Decoding Improves Robustness on Question Answering for Large Language Models,"Jui-Ming Yao, Hao-Yuan Chen, Zi-Xian Tang, Bing-Jia Tan, Sheng-Wei Peng, Bing-Cheng Xie, Shun-Feng Su",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.09408"" target=""_blank"">2506.09408</a>",,2025-12-03 22:39:25
TooBadRL: Trigger Optimization to Boost Effectiveness of Backdoor Attacks on Deep Reinforcement Learning,"Songze Li, Mingxuan Zhang, Kang Wei, Shouling Ji",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.09562"" target=""_blank"">2506.09562</a>","<a href=""https://github.com/S3IC-Lab/TooBadRL"" target=""_blank"">S3IC-Lab</a>",2025-12-03 22:39:25
Adversarial Text Generation with Dynamic Contextual Perturbation,"Hetvi Waghela, Jaydip Sen, Sneha Rakshit, Subhasis Dasgupta",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.09148"" target=""_blank"">2506.09148</a>",,2025-12-03 22:39:25
Towards Robust Deep Reinforcement Learning against Environmental State Perturbation,"Chenxu Wang, Huaping Liu",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.08961"" target=""_blank"">2506.08961</a>",,2025-12-03 22:39:25
Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability,"Jie Bao, Chuangyin Dang, Rui Luo, Hanwei Zhang, Zhixin Zhou",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07804"" target=""_blank"">2506.07804</a>","<a href=""https://github.com/bjbbbb/Enhancing-Adversarial-Robustness-with-Conformal-Prediction"" target=""_blank"">bjbbbb</a>",2025-12-03 22:39:25
PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies,"Mojtaba Nafez, Amirhossein Koochakian, Arad Maleki, Jafar Habibi, Mohammad Hossein Rohban",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.09237"" target=""_blank"">2506.09237</a>","<a href=""https://github.com/rohban-lab/PatchGuard"" target=""_blank"">rohban-lab</a>",2025-12-03 22:39:25
AdversariaL attacK sAfety aLIgnment(ALKALI): Safeguarding LLMs through GRACE: Geometric Representation-Aware Contrastive Enhancement- Introducing Adversarial Vulnerability Quality Index (AVQI),"Danush Khanna, Krishna Kumar, Basab Ghosh, Vinija Jain, Vasu Sharma, Aman Chadha, Amitava Das",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.08885"" target=""_blank"">2506.08885</a>",,2025-12-03 22:39:25
Adversarial Surrogate Risk Bounds for Binary Classification,Natalie S. Frank,arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.09348"" target=""_blank"">2506.09348</a>",,2025-12-03 22:39:25
ASRJam: Human-Friendly AI Speech Jamming to Prevent Automated Phone Scams,"Freddie Grabovski, Gilad Gressel, Yisroel Mirsky",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.11125"" target=""_blank"">2506.11125</a>",,2025-12-03 22:39:25
Towards Class-wise Fair Adversarial Training via Anti-Bias Soft Label Distillation,"Shiji Zhao, Chi Chen, Ranjie Duan, Xizhe Wang, Xingxing Wei",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.08611"" target=""_blank"">2506.08611</a>",,2025-12-03 22:39:25
DiffGradCAM: A Universal Class Activation Map Resistant to Adversarial Training,"Jacob Piland, Chris Sweet, Adam Czakja",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.08514"" target=""_blank"">2506.08514</a>",,2025-12-03 22:39:25
Does Multimodal Large Language Model Truly Unlearn? Stealthy MLLM Unlearning Attack,"Xianren Zhang, Hui Liu, Delvin Ce Zhang, Xianfeng Tang, Qi He, Dongwon Lee, Suhang Wang",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.17265"" target=""_blank"">2506.17265</a>","<a href=""https://github.com/PKU-YuanGroup/AsFT"" target=""_blank"">PKU-YuanGroup</a>",2025-12-03 22:39:25
Design Patterns for Securing LLM Agents against Prompt Injections,"Luca Beurer-Kellner, Beat Buesser Ana-Maria Creţu, Edoardo Debenedetti, Daniel Dobos, Daniel Fabian, Marc Fischer, David Froelicher, Kathrin Grosse, Daniel Naeff, Ezinwanne Ozoani, Andrew Paverd, Florian Tramèr, Václav Volhejn",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.08837"" target=""_blank"">2506.08837</a>",,2025-12-03 22:39:25
WGLE:Backdoor-free and Multi-bit Black-box Watermarking for Graph Neural Networks,"Tingzhi Li, Xuefeng Liu",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.08602"" target=""_blank"">2506.08602</a>",,2025-12-03 22:39:25
Adversarial Attack Classification and Robustness Testing for Large Language Models for Code,"Yang Liu, Armstrong Foundjem, Foutse Khomh, Heng Li",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.07942"" target=""_blank"">2506.07942</a>",,2025-12-03 22:39:25
Rewriting the Budget: A General Framework for Black-Box Attacks Under Cost Asymmetry,"Mahdi Salmani, Alireza Abdollahpoorrostam, Seyed-Mohsen Moosavi-Dezfooli",arXiv,2025-06,"<a href=""http://arxiv.org/abs/2506.06933"" target=""_blank"">2506.06933</a>",,2025-12-03 22:39:25
Noise Injection Systemically Degrades Large Language Model Safety Guardrails,"Prithviraj Singh Shahani, Matthias Scheutz",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.13500"" target=""_blank"">2505.13500</a>",,2025-12-03 22:39:25
MorphGuard: Morph Specific Margin Loss for Enhancing Robustness to Face Morphing Attacks,"Iurii Medvedev, Nuno Goncalves",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.10497"" target=""_blank"">2505.10497</a>",,2025-12-03 22:39:25
A Unified and Scalable Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability,"Jie Zhu, Jirong Zha, Ding Li, Leye Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.10351"" target=""_blank"">2505.10351</a>","<a href=""https://github.com/JiePKU/PartCrop"" target=""_blank"">JiePKU</a>",2025-12-03 22:39:25
Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning,"Chibueze Peace Obioma, Youcheng Sun, Mustafa A. Mustafa",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.10297"" target=""_blank"">2505.10297</a>",,2025-12-03 22:39:25
One Shot Dominance: Knowledge Poisoning Attack on Retrieval-Augmented Generation Systems,"Zhiyuan Chang, Xiaojun Jia, Mingyang Li, Junjie Wang, Yuekai Huang, Qing Wang, Ziyou Jiang, Yang Liu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.11548"" target=""_blank"">2505.11548</a>",,2025-12-03 22:39:25
ProxyPrompt: Securing System Prompts against Prompt Extraction Attacks,"Zhixiong Zhuang, Maria-Irina Nicolae, Hui-Po Wang, Mario Fritz",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.11459"" target=""_blank"">2505.11459</a>",,2025-12-03 22:39:25
The Ephemeral Threat: Assessing the Security of Algorithmic Trading Systems powered by Deep Learning,"Advije Rizvani, Giovanni Apruzzese, Pavel Laskov",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.10430"" target=""_blank"">2505.10430</a>",,2025-12-03 22:39:25
Zero-Shot Visual Generalization in Robot Manipulation,"Sumeet Batra, Gaurav Sukhatme",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.11719"" target=""_blank"">2505.11719</a>",,2025-12-03 22:39:25
Co-Evolutionary Defence of Active Directory Attack Graphs via GNN-Approximated Dynamic Programming,"Diksha Goel, Hussain Ahmad, Kristen Moore, Mingyu Guo",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.11710"" target=""_blank"">2505.11710</a>",,2025-12-03 22:39:25
Anti-Sensing: Defense against Unauthorized Radar-based Human Vital Sign Sensing with Physically Realizable Wearable Oscillators,"Md Farhan Tasnim Oshim, Nigel Doering, Bashima Islam, Tsui-Wei Weng, Tauhidur Rahman",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.10864"" target=""_blank"">2505.10864</a>",,2025-12-03 22:39:25
EnvInjection: Environmental Prompt Injection Attack to Multi-modal Web Agents,"Xilong Wang, John Bloch, Zedian Shao, Yuepeng Hu, Shuyan Zhou, Neil Zhenqiang Gong",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.11717"" target=""_blank"">2505.11717</a>",,2025-12-03 22:39:25
Adversarially Robust Spiking Neural Networks with Sparse Connectivity,"Mathias Schmolli, Maximilian Baronig, Robert Legenstein, Ozan Özdenizci",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15833"" target=""_blank"">2505.15833</a>",,2025-12-03 22:39:25
CARES: Comprehensive Evaluation of Safety and Adversarial Robustness in Medical LLMs,"Sijia Chen, Xiaomin Li, Mengxue Zhang, Eric Hanchen Jiang, Qingcheng Zeng, Chen-Hsiang Yu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.11413"" target=""_blank"">2505.11413</a>",,2025-12-03 22:39:25
Sybil-based Virtual Data Poisoning Attacks in Federated Learning,"Changxun Zhu, Qilong Wu, Lingjuan Lyu, Shibei Xue",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.09983"" target=""_blank"">2505.09983</a>",,2025-12-03 22:39:25
SecReEvalBench: A Multi-turned Security Resilience Evaluation Benchmark for Large Language Models,"Huining Cui, Wei Liu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.07584"" target=""_blank"">2505.07584</a>",,2025-12-03 22:39:25
Dark LLMs: The Growing Threat of Unaligned AI Models,"Michael Fire, Yitzhak Elbazis, Adi Wasenstein, Lior Rokach",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.10066"" target=""_blank"">2505.10066</a>",,2025-12-03 22:39:25
Evaluating the Robustness of Adversarial Defenses in Malware Detection Systems,"Mostafa Jafari, Alireza Shameli-Sendi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.09342"" target=""_blank"">2505.09342</a>",,2025-12-03 22:39:25
IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method,"Mihyeon Kim, Juhyoung Park, Youngbin Kim",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06889"" target=""_blank"">2505.06889</a>",,2025-12-03 22:39:25
DP-TRAE: A Dual-Phase Merging Transferable Reversible Adversarial Example for Image Privacy Protection,"Xia Du, Jiajie Zhu, Jizhe Zhou, Chi-man Pun, Zheng Lin, Cong Wu, Zhe Chen, Jun Luo",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06860"" target=""_blank"">2505.06860</a>",,2025-12-03 22:39:25
Must Read: A Systematic Survey of Computational Persuasion,"Nimet Beyza Bozdag, Shuhaib Mehri, Xiaocheng Yang, Hyeonjeong Ha, Zirui Cheng, Esin Durmus, Jiaxuan You, Heng Ji, Gokhan Tur, Dilek Hakkani-Tür",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.07775"" target=""_blank"">2505.07775</a>",,2025-12-03 22:39:25
"Nosy Layers, Noisy Fixes: Tackling DRAs in Federated Learning Systems using Explainable AI","Meghali Nandi, Arash Shaghaghi, Nazatul Haque Sultan, Gustavo Batista, Raymond K. Zhao, Sanjay Jha",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.10942"" target=""_blank"">2505.10942</a>",,2025-12-03 22:39:25
GRADA: Graph-based Reranker against Adversarial Documents Attack,"Jingjie Zheng, Aryo Pradipta Gema, Giwon Hong, Xuanli He, Pasquale Minervini, Youcheng Sun, Qiongkai Xu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.07546"" target=""_blank"">2505.07546</a>",,2025-12-03 22:39:25
Dynamical Low-Rank Compression of Neural Networks with Robustness under Adversarial Attacks,"Steffen Schotthöfer, H. Lexie Yang, Stefan Schnake",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.08022"" target=""_blank"">2505.08022</a>",,2025-12-03 22:39:25
Strategy-Augmented Planning for Large Language Models via Opponent Exploitation,"Shuai Xu, Sijia Cui, Yanna Wang, Bo Xu, Qi Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.08459"" target=""_blank"">2505.08459</a>","<a href=""https://github.com/hsushuai/SAP"" target=""_blank"">hsushuai</a>",2025-12-03 22:39:25
On the Account Security Risks Posed by Password Strength Meters,"Ming Xu, Weili Han, Jitao Yu, Jing Liu, Xinyi Zhang, Yun Lin, Jin Song Dong",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.08292"" target=""_blank"">2505.08292</a>",,2025-12-03 22:39:25
Removing Watermarks with Partial Regeneration using Semantic Information,"Krti Tallam, John Kevin Cava, Caleb Geniesse, N. Benjamin Erichson, Michael W. Mahoney",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.08234"" target=""_blank"">2505.08234</a>",,2025-12-03 22:39:25
Revisiting Adversarial Perception Attacks and Defense Methods on Autonomous Driving Systems,"Cheng Chen, Yuhong Wang, Nafis S Munir, Xiangwei Zhou, Xugui Zhou",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.11532"" target=""_blank"">2505.11532</a>",,2025-12-03 22:39:25
Robustness Analysis against Adversarial Patch Attacks in Fully Unmanned Stores,"Hyunsik Na, Wonho Lee, Seungdeok Roh, Sohee Park, Daeseon Choi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.08835"" target=""_blank"">2505.08835</a>",,2025-12-03 22:39:25
Towards Adaptive Meta-Gradient Adversarial Examples for Visual Tracking,"Wei-Long Tian, Peng Gao, Xiao Liu, Long Xu, Hamido Fujita, Hanan Aljuai, Mao-Li Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.08999"" target=""_blank"">2505.08999</a>","<a href=""https://github.com/pgao-lab/AMGA"" target=""_blank"">pgao-lab</a>",2025-12-03 22:39:25
Guardian Positioning System (GPS) for Location Based Services,"Wenjie Liu, Panos Papadimitratos",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.09743"" target=""_blank"">2505.09743</a>",,2025-12-03 22:39:25
"RobustSpring: Benchmarking Robustness to Image Corruptions for Optical Flow, Scene Flow and Stereo","Jenny Schmalfuss, Victor Oei, Lukas Mehl, Madlen Bartsch, Shashank Agnihotri, Margret Keuper, Andrés Bruhn",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.09368"" target=""_blank"">2505.09368</a>",,2025-12-03 22:39:25
DataMIL: Selecting Data for Robot Imitation Learning with Datamodels,"Shivin Dass, Alaa Khaddaj, Logan Engstrom, Aleksander Madry, Andrew Ilyas, Roberto Martín-Martín",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.09603"" target=""_blank"">2505.09603</a>",,2025-12-03 22:39:25
Adversarial Attack on Large Language Models using Exponentiated Gradient Descent,"Sajib Biswas, Mao Nishino, Samuel Jacob Chacko, Xiuwen Liu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.09820"" target=""_blank"">2505.09820</a>","<a href=""https://github.com/sbamit/Exponentiated-Gradient-Descent-LLM-Attack"" target=""_blank"">sbamit</a>",2025-12-03 22:39:25
Adversarial Suffix Filtering: a Defense Pipeline for LLMs,"David Khachaturov, Robert Mullins",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.09602"" target=""_blank"">2505.09602</a>",,2025-12-03 22:39:25
On the Security Risks of ML-based Malware Detection Systems: A Survey,"Ping He, Yuhao Mao, Changjiang Li, Lorenzo Cavallaro, Ting Wang, Shouling Ji",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.10903"" target=""_blank"">2505.10903</a>",,2025-12-03 22:39:25
The Tower of Babel Revisited: Multilingual Jailbreak Prompts on Closed-Source Large Language Models,"Linghan Huang, Haolin Jin, Zhaoge Bi, Pengyue Yang, Peizhou Zhao, Taozhao Chen, Xiongfei Wu, Lei Ma, Huaming Chen",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12287"" target=""_blank"">2505.12287</a>",,2025-12-03 22:39:25
LLMs unlock new paths to monetizing exploits,"Nicholas Carlini, Milad Nasr, Edoardo Debenedetti, Barry Wang, Christopher A. Choquette-Choo, Daphne Ippolito, Florian Tramèr, Matthew Jagielski",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.11449"" target=""_blank"">2505.11449</a>",,2025-12-03 22:39:25
A Few Large Shifts: Layer-Inconsistency Based Minimal Overhead Adversarial Example Detection,"Sanggeon Yun, Ryozo Masukawa, Hyunwoo Oh, Nathaniel D. Bastian, Mohsen Imani",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12586"" target=""_blank"">2505.12586</a>","<a href=""https://github.com/c0510gy/AFLS-AED"" target=""_blank"">c0510gy</a>",2025-12-03 22:39:25
EPIC: Explanation of Pretrained Image Classification Networks via Prototype,"Piotr Borycki, Magdalena Trędowicz, Szymon Janusz, Jacek Tabor, Przemysław Spurek, Arkadiusz Lewicki, Łukasz Struski",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12897"" target=""_blank"">2505.12897</a>",,2025-12-03 22:39:25
Robust learning of halfspaces under log-concave marginals,"Jane Lange, Arsen Vasilyan",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.13708"" target=""_blank"">2505.13708</a>",,2025-12-03 22:39:25
Safety Alignment Can Be Not Superficial With Explicit Safety Signals,"Jianwei Li, Jung-Eun Kim",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17072"" target=""_blank"">2505.17072</a>",,2025-12-03 22:39:25
Does Low Rank Adaptation Lead to Lower Robustness against Training-Time Attacks? (8%),"Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, Ronghua Li",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12871"" target=""_blank"">2505.12871</a>",,2025-12-03 22:39:25
Fragments to Facts: Partial-Information Fragment Inference from LLMs,"Lucas Rosenblatt, Bin Han, Robert Wolfe, Bill Howe",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.13819"" target=""_blank"">2505.13819</a>",,2025-12-03 22:39:25
DynaNoise: Dynamic Probabilistic Noise Injection for Defending Against Membership Inference Attacks,"Javad Forough, Hamed Haddadi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.13362"" target=""_blank"">2505.13362</a>",,2025-12-03 22:39:25
Language Models That Walk the Talk: A Framework for Formal Fairness Certificates,"Danqing Chen, Tobias Ladner, Ahmed Rayen Mhadhbi, Matthias Althoff",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12767"" target=""_blank"">2505.12767</a>",,2025-12-03 22:39:25
PandaGuard: Systematic Evaluation of LLM Safety in the Era of Jailbreaking Attacks,"Guobin Shen, Dongcheng Zhao, Linghao Feng, Xiang He, Jihang Wang, Sicheng Shen, Haibo Tong, Yiting Dong, Jindong Li, Xiang Zheng, Yi Zeng",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.13862"" target=""_blank"">2505.13862</a>",,2025-12-03 22:39:25
RoVo: Robust Voice Protection Against Unauthorized Speech Synthesis with Embedding-Level Perturbations,"Seungmin Kim, Sohee Park, Donghyun Kim, Jisu Lee, Daeseon Choi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12686"" target=""_blank"">2505.12686</a>",,2025-12-03 22:39:25
Anti-Inpainting: A Proactive Defense against Malicious Diffusion-based Inpainters under Unknown Conditions,"Yimao Guo, Zuomin Qu, Wei Lu, Xiangyang Luo",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.13023"" target=""_blank"">2505.13023</a>",,2025-12-03 22:39:25
Investigating the Vulnerability of LLM-as-a-Judge Architectures to Prompt-Injection Attacks,"Narek Maloyan, Bislan Ashinov, Dmitry Namiot",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.13348"" target=""_blank"">2505.13348</a>",,2025-12-03 22:39:25
FlowPure: Continuous Normalizing Flows for Adversarial Purification,"Elias Collaert, Abel Rodríguez, Sander Joos, Lieven Desmet, Vera Rimmer",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.13280"" target=""_blank"">2505.13280</a>",,2025-12-03 22:39:25
Hidden Ghost Hand: Unveiling Backdoor Vulnerabilities in MLLM-Powered Mobile GUI Agents,"Pengzhou Cheng, Haowen Hu, Zheng Wu, Zongru Wu, Tianjie Ju, Zhuosheng Zhang, Gongshen Liu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14418"" target=""_blank"">2505.14418</a>",,2025-12-03 22:39:25
Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety,"Zihan Guan, Mengxuan Hu, Ronghang Zhu, Sheng Li, Anil Vullikanti",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06843"" target=""_blank"">2505.06843</a>","<a href=""https://github.com/GuanZihan/Benign-Samples-Matter"" target=""_blank"">GuanZihan</a>",2025-12-03 22:39:25
Covert Attacks on Machine Learning Training in Passively Secure MPC,"Matthew Jagielski, Daniel Escudero, Rahul Rachuri, Peter Scholl",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17092"" target=""_blank"">2505.17092</a>",,2025-12-03 22:39:25
Malware families discovery via Open-Set Recognition on Android manifest permissions,"Filippo Leveni, Matteo Mistura, Francesco Iubatti, Carmine Giangregorio, Nicolò Pastore, Cesare Alippi, Giacomo Boracchi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12750"" target=""_blank"">2505.12750</a>",,2025-12-03 22:39:25
On the Mechanisms of Adversarial Data Augmentation for Robust and Adaptive Transfer Learning,"Hana Satou, Alan Mitkiy",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12681"" target=""_blank"">2505.12681</a>",,2025-12-03 22:39:25
GenoArmory: A Unified Evaluation Framework for Adversarial Attacks on Genomic Foundation Models,"Haozheng Luo, Chenghao Qiu, Yimin Wang, Shang Wu, Jiahao Yu, Han Liu, Binghui Wang, Yan Chen",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.10983"" target=""_blank"">2505.10983</a>",,2025-12-03 22:39:25
PoisonArena: Uncovering Competing Poisoning Attacks in Retrieval-Augmented Generation,"Liuji Chen, Xiaofang Yang, Yuanzhuo Lu, Jinghao Zhang, Xin Sun, Qiang Liu, Shu Wu, Jing Dong, Liang Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12574"" target=""_blank"">2505.12574</a>","<a href=""https://github.com/yxf203/PoisonArena"" target=""_blank"">yxf203</a>",2025-12-03 22:39:25
FIGhost: Fluorescent Ink-based Stealthy and Flexible Backdoor Attacks on Physical Traffic Sign Recognition,"Shuai Yuan, Guowen Xu, Hongwei Li, Rui Zhang, Xinyuan Qian, Wenbo Jiang, Hangcheng Cao, Qingchuan Zhao",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12045"" target=""_blank"">2505.12045</a>",,2025-12-03 22:39:25
Video-SafetyBench: A Benchmark for Safety Evaluation of Video LVLMs,"Xuannan Liu, Zekun Li, Zheqi He, Peipei Li, Shuhan Xia, Xing Cui, Huaibo Huang, Xi Yang, Ran He",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.11842"" target=""_blank"">2505.11842</a>",,2025-12-03 22:39:25
FL-PLAS: Federated Learning with Partial Layer Aggregation for Backdoor Defense Against High-Ratio Malicious Clients,"Jianyi Zhang, Ziyin Zhou, Yilong Li, Qichao Jin",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12019"" target=""_blank"">2505.12019</a>",,2025-12-03 22:39:25
Self-Destructive Language Model,"Yuhui Wang, Rongyi Zhu, Ting Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12186"" target=""_blank"">2505.12186</a>",,2025-12-03 22:39:25
Black-box Adversaries from Latent Space: Unnoticeable Attacks on Human Pose and Shape Estimation,"Zhiying Li, Guanggang Geng, Yeying Jin, Zhizhi Guo, Bruce Gu, Jidong Huo, Zhaoxin Fan, Wenjun Wu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12009"" target=""_blank"">2505.12009</a>",,2025-12-03 22:39:25
Adversarial Robustness for Unified Multi-Modal Encoders via Efficient Calibration,"Chih-Ting Liao, Bin Ren, Guofeng Mei, Xu Zheng",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.11895"" target=""_blank"">2505.11895</a>",,2025-12-03 22:39:25
"FABLE: A Localized, Targeted Adversarial Attack on Weather Forecasting Models","Yue Deng, Asadullah Hill Galib, Xin Lan, Pang-Ning Tan, Lifeng Luo",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12167"" target=""_blank"">2505.12167</a>",,2025-12-03 22:39:25
CAPTURE: Context-Aware Prompt Injection Testing and Robustness Enhancement,"Gauri Kholkar, Ratinder Ahuja",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12368"" target=""_blank"">2505.12368</a>",,2025-12-03 22:39:25
Improving Out-of-Domain Robustness with Targeted Augmentation in Frequency and Pixel Spaces,"Ruoqi Wang, Haitao Wang, Shaojie Guo, Qiong Luo",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12317"" target=""_blank"">2505.12317</a>",,2025-12-03 22:39:25
Robust Planning for Autonomous Driving via Mixed Adversarial Diffusion Predictions,"Albert Zhao, Stefano Soatto",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12327"" target=""_blank"">2505.12327</a>",,2025-12-03 22:39:25
Few-Step Diffusion via Score identity Distillation,"Mingyuan Zhou, Yi Gu, Zhendong Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12674"" target=""_blank"">2505.12674</a>","<a href=""https://github.com/mingyuanzhou/SiD-LSG"" target=""_blank"">mingyuanzhou</a>",2025-12-03 22:39:25
IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems,"Liwen Wang, Wenxuan Wang, Shuai Wang, Zongjie Li, Zhenlan Ji, Zongyi Lyu, Daoyuan Wu, Shing-Chi Cheung",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12442"" target=""_blank"">2505.12442</a>",,2025-12-03 22:39:25
A Survey of Attacks on Large Language Models,"Wenrui Xu, Keshab K. Parhi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12567"" target=""_blank"">2505.12567</a>",,2025-12-03 22:39:25
Spiking Neural Network: a low power solution for physical layer authentication,"Jung Hoon Lee, Sujith Vijayan",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.12647"" target=""_blank"">2505.12647</a>",,2025-12-03 22:39:25
SPIRIT: Patching Speech Language Models against Jailbreak Attacks,"Amirbek Djanibekov, Nurdaulet Mukhituly, Kentaro Inui, Hanan Aldarmaki, Nils Lukas",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.13541"" target=""_blank"">2505.13541</a>",,2025-12-03 22:39:25
A Formally Verified Robustness Certifier for Neural Networks (Extended Version),"James Tobler, Hira Taqdees Syeda, Toby Murray",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06958"" target=""_blank"">2505.06958</a>",,2025-12-03 22:39:25
"Catastrophic Overfitting, Entropy Gap and Participation Ratio: A Noiseless $l^p$ Norm Solution for Fast Adversarial Training","Fares B. Mehouachi, Saif Eddin Jabari",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.02360"" target=""_blank"">2505.02360</a>",,2025-12-03 22:39:25
One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models,"Haoran Gu, Handing Wang, Yi Mei, Mengjie Zhang, Yaochu Jin",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.07167"" target=""_blank"">2505.07167</a>",,2025-12-03 22:39:25
Active Sybil Attack and Efficient Defense Strategy in IPFS DHT,"V. H. M. Netto, T. Cholez, C. L. Ignat",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01139"" target=""_blank"">2505.01139</a>",,2025-12-03 22:39:25
Helping Large Language Models Protect Themselves: An Enhanced Filtering and Summarization System,"Sheikh Samit Muhaimin, Spyridon Mastorakis",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01315"" target=""_blank"">2505.01315</a>",,2025-12-03 22:39:25
"Constrained Network Adversarial Attacks: Validity, Robustness, and Transferability","Anass Grini, Oumaima Taheri, Btissam El Khamlichi, Amal El Fallah-Seghrouchni",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01328"" target=""_blank"">2505.01328</a>",,2025-12-03 22:39:25
Harmonizing Intra-coherence and Inter-divergence in Ensemble Attacks for Adversarial Transferability,"Zhaoyang Ma, Zhihao Wu, Wang Lu, Xin Gao, Jinghang Yue, Taolin Zhang, Lipo Wang, Youfang Lin, Jing Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01168"" target=""_blank"">2505.01168</a>",,2025-12-03 22:39:25
Transferable Adversarial Attacks on Black-Box Vision-Language Models,"Kai Hu, Weichen Yu, Li Zhang, Alexander Robey, Andy Zou, Chengming Xu, Haoqi Hu, Matt Fredrikson",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01050"" target=""_blank"">2505.01050</a>",,2025-12-03 22:39:25
Adversarial Robustness of Deep Learning Models for Inland Water Body Segmentation from SAR Images,"Siddharth Kothari, Srinivasan Murali, Sankalp Kothari, Ujjwal Verma, Jaya Sreevalsan-Nair",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01884"" target=""_blank"">2505.01884</a>",,2025-12-03 22:39:25
Rogue Cell: Adversarial Attack and Defense in Untrusted O-RAN Setup Exploiting the Traffic Steering xApp,"Eran Aizikovich, Dudu Mimran, Edita Grolman, Yuval Elovici, Asaf Shabtai",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01816"" target=""_blank"">2505.01816</a>",,2025-12-03 22:39:25
CAMOUFLAGE: Exploiting Misinformation Detection Systems Through LLM-driven Adversarial Claim Transformation,"Mazal Bethany, Nishant Vishwamitra, Cho-Yu Jason Chiang, Peyman Najafirad",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01900"" target=""_blank"">2505.01900</a>",,2025-12-03 22:39:25
Lightweight Defense Against Adversarial Attacks in Time Series Classification,"Yi Independent Researcher, Australia Han",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.02073"" target=""_blank"">2505.02073</a>",,2025-12-03 22:39:25
SoK: Stealing Cars Since Remote Keyless Entry Introduction and How to Defend From It,"Tommaso Bianchi, Alessandro Brighente, Mauro Conti, Edoardo Pavan",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.02713"" target=""_blank"">2505.02713</a>",,2025-12-03 22:39:25
Bayesian Robust Aggregation for Federated Learning,"Aleksandr Uppsala University Karakulev, Usama Uppsala University Zafar, Salman Uppsala University Scaleout Systems Toor, Prashant Uppsala University Science for Life Laboratory, Sweden Singh",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.02490"" target=""_blank"">2505.02490</a>",,2025-12-03 22:39:25
Towards Dataset Copyright Evasion Attack against Personalized Text-to-Image Diffusion Models,"Kuofeng Gao, Yufei Zhu, Yiming Li, Jiawang Bai, Yong Yang, Zhifeng Li, Shu-Tao Xia",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.02824"" target=""_blank"">2505.02824</a>",,2025-12-03 22:39:25
Adversarial Attacks in Multimodal Systems: A Practitioner's Survey,"Shashank Kapoor, Sanjay Surendranath Girija, Lakshit Arora, Dipen Pradhan, Ankit Shetgaonkar, Aman Raj",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.03084"" target=""_blank"">2505.03084</a>",,2025-12-03 22:39:25
Robustness questions the interpretability of graph neural networks: what to do? (83%),"Kirill ISP RAS Research Center for Trusted Artificial Intelligence Ivannikov Institute for System Programming of the Russian Academy of Sciences Moscow Institute of Physics and Technology Lukyanov, Georgii Ivannikov Institute for System Programming of the Russian Academy of Sciences Lomonosov Moscow State University Sazonov, Serafim Yandex School of Data Analysis Boyarsky, Ilya 1 v 5 Makarov",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.02566"" target=""_blank"">2505.02566</a>",,2025-12-03 22:39:25
Adversarial Robustness Analysis of Vision-Language Models in Medical Image Segmentation,"Anjila Budathoki, Manish Dhakal",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.02971"" target=""_blank"">2505.02971</a>","<a href=""https://github.com/anjilab/secure-private-ai"" target=""_blank"">anjilab</a>",2025-12-03 22:39:25
Adversarial Sample Generation for Anomaly Detection in Industrial Control Systems,"Abdul Mustafa, Muhammad Talha Khan, Muhammad Azmi Umer, Zaki Masood, Chuadhry Mujeeb Ahmed",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.03120"" target=""_blank"">2505.03120</a>",,2025-12-03 22:39:25
Diffusion-based Adversarial Purification from the Perspective of the Frequency Domain,"Gaozheng Pei, Ke Ma, Yingfei Sun, Qianqian Xu, Qingming Huang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01267"" target=""_blank"">2505.01267</a>",,2025-12-03 22:39:25
Quantum Support Vector Regression for Robust Anomaly Detection,"Kilian Tscharke, Maximilian Wendlinger, Sebastian Issel, Pascal Debus",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01012"" target=""_blank"">2505.01012</a>",,2025-12-03 22:39:25
Interpretable Zero-shot Learning with Infinite Class Concepts,"Zihan Ye, Shreyank N Gowda, Shiming Chen, Yaochu Jin, Kaizhu Huang, Xiaobo Jin",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.03361"" target=""_blank"">2505.03361</a>",,2025-12-03 22:39:25
Secure Cluster-Based Hierarchical Federated Learning in Vehicular Networks,"M. Saeid HaghighiFard, Sinem Coleri",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01186"" target=""_blank"">2505.01186</a>",,2025-12-03 22:39:25
SifterNet: A Generalized and Model-Agnostic Trigger Purification Approach,"Shaoye Luo, Xinxin Fan, Quanliang Jing, Chi Lin, Mengfan Li, Yunfeng Lu, Yongjun Xu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14531"" target=""_blank"">2505.14531</a>",,2025-12-03 22:39:25
Stochastic Subspace Descent Accelerated via Bi-fidelity Line Search,"Nuojin Cheng, Alireza Doostan, Stephen Becker",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.00162"" target=""_blank"">2505.00162</a>",,2025-12-03 22:39:25
Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation,"Vaidehi Patil, Yi-Lin Sung, Peter Hase, Jie Peng, Tianlong Chen, Mohit Bansal",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01456"" target=""_blank"">2505.01456</a>",,2025-12-03 22:39:25
Enhancing Security and Strengthening Defenses in Automated Short-Answer Grading Systems,"Sahar Yarmohammadtoosky, Yiyun Zhou, Victoria Yaneva, Peter Baldwin, Saed Rezayi, Brian Clauser, Polina Harikeo",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.00061"" target=""_blank"">2505.00061</a>",,2025-12-03 22:39:25
Spill The Beans: Exploiting CPU Cache Side-Channels to Leak Tokens from Large Language Models,"Andrew Adiletta, Berk Sunar",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.00817"" target=""_blank"">2505.00817</a>",,2025-12-03 22:39:25
Attack and defense techniques in large language models: A survey and new perspectives,"Zhiyu Liao, Kang Chen, Yuanguo Lin, Kangkang Li, Yunxuan Liu, Hefeng Chen, Xingwang Huang, Yuanhui Yu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.00976"" target=""_blank"">2505.00976</a>",,2025-12-03 22:39:25
Protocol-agnostic and Data-free Backdoor Attacks on Pre-trained Models in RF Fingerprinting,"Tianya Zhao, Ningning Wang, Junqing Zhang, Xuyu Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.00881"" target=""_blank"">2505.00881</a>",,2025-12-03 22:39:25
GAN-based Generator of Adversarial Attack on Intelligent End-to-End Autoencoder-based Communication System,"Jianyuan Chen, Lin Zhang, Zuwei Chen, Yawen Chen, Hongcheng Zhuang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.00395"" target=""_blank"">2505.00395</a>",,2025-12-03 22:39:25
Analysis of the vulnerability of machine learning regression models to adversarial attacks using data from 5G wireless networks,"Leonid Legashev, Artur Zhigalov, Denis Parfenov",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.00487"" target=""_blank"">2505.00487</a>",,2025-12-03 22:39:25
Fast and Low-Cost Genomic Foundation Models via Outlier Removal,"Haozheng Luo, Chenghao Qiu, Maojiang Su, Zhihan Zhou, Zoe Mehta, Guo Ye, Jerry Yao-Chieh Hu, Han Liu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.00598"" target=""_blank"">2505.00598</a>",,2025-12-03 22:39:25
OET: Optimization-based prompt injection Evaluation Toolkit,"Jinsheng Pan, Xiaogeng Liu, Chaowei Xiao",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.00843"" target=""_blank"">2505.00843</a>",,2025-12-03 22:39:25
Explainable AI Based Diagnosis of Poisoning Attacks in Evolutionary Swarms,"Mehrdad Asadi, Roxana Rădulescu, Ann Nowé",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01181"" target=""_blank"">2505.01181</a>",,2025-12-03 22:39:25
"LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures","Francisco Aguilera-Martínez, Fernando Berzal",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01177"" target=""_blank"">2505.01177</a>",,2025-12-03 22:39:25
Fine-grained Manipulation Attacks to Local Differential Privacy Protocols for Data Streams,"Xinyu Li, Xuebin Ren, Shusen Yang, Liang Shi, Chia-Mu Yu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01292"" target=""_blank"">2505.01292</a>",,2025-12-03 22:39:25
Rubber Mallet: A Study of High Frequency Localized Bit Flips and Their Impact on Security,"Andrew Adiletta, Zane Weissman, Fatemeh Khojasteh Dana, Berk Sunar, Shahin Tajik",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.01518"" target=""_blank"">2505.01518</a>",,2025-12-03 22:39:25
"Event-Triggered GAT-LSTM Framework for Attack Detection in Heating, Ventilation, and Air Conditioning Systems","Zhenan Feng, Ehsan Nekouei",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.03559"" target=""_blank"">2505.03559</a>",,2025-12-03 22:39:25
SEVA: Leveraging Single-Step Ensemble of Vicinal Augmentations for Test-Time Adaptation,"Zixuan Hu, Yichun Hu, Ling-Yu Duan",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.04087"" target=""_blank"">2505.04087</a>",,2025-12-03 22:39:25
TokenProber: Jailbreaking Text-to-image Models via Fine-grained Word Impact Analysis,"Longtian Wang, Xiaofei Xie, Tianlin Li, Yuhan Zhi, Chao Shen",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.08804"" target=""_blank"">2505.08804</a>",,2025-12-03 22:39:25
Defending against Indirect Prompt Injection by Instruction Detection,"Tongyu Wen, Chenglong Wang, Xiyuan Yang, Haoyu Tang, Yueqi Xie, Lingjuan Lyu, Zhicheng Dou, Fangzhao Wu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06311"" target=""_blank"">2505.06311</a>",,2025-12-03 22:39:25
Advancing Neural Network Verification through Hierarchical Safety Abstract Interpretation,"Luca Marzari, Isabella Mastroeni, Alessandro Farinelli",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.05235"" target=""_blank"">2505.05235</a>",,2025-12-03 22:39:25
DispBench: Benchmarking Disparity Estimation to Synthetic Corruptions,"Shashank Agnihotri, Amaan Ansari, Annika Dackermann, Fabian Rösch, Margret Keuper",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.05091"" target=""_blank"">2505.05091</a>","<a href=""https://github.com/shashankskagnihotri/benchmarking_robustness/tree/disparity_estimation/final/disparity_estimation"" target=""_blank"">final</a>",2025-12-03 22:39:25
Adaptive Stress Testing Black-Box LLM Planners,"Neeloy Chakraborty, John Pohovey, Melkior Ornik, Katherine Driggs-Campbell",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.05665"" target=""_blank"">2505.05665</a>",,2025-12-03 22:39:25
X-Transfer Attacks: Towards Super Transferable Adversarial Attacks on CLIP,"Hanxun Huang, Sarah Erfani, Yige Li, Xingjun Ma, James Bailey",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.05528"" target=""_blank"">2505.05528</a>","<a href=""https://github.com/HanxunH/XTransferBench"" target=""_blank"">HanxunH</a>",2025-12-03 22:39:25
Unpacking Robustness in Inflectional Languages: Adversarial Evaluation and Mechanistic Insights,"Paweł Walkowiak, Marek Klonowski, Marcin Oleksy, Arkadiusz Janz",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.07856"" target=""_blank"">2505.07856</a>",,2025-12-03 22:39:25
Sponge Attacks on Sensing AI: Energy-Latency Vulnerabilities and Defense via Model Pruning,"Syed Mhamudul Hasan, Hussein Zangoti, Iraklis Anagnostopoulos, Abdur R. Shahid",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06454"" target=""_blank"">2505.06454</a>",,2025-12-03 22:39:25
Remote Rowhammer Attack using Adversarial Observations on Federated Learning Clients,"Jinsheng Yuan, Yuhang Hao, Weisi Guo, Yun Wu, Chongyan Gu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06335"" target=""_blank"">2505.06335</a>",,2025-12-03 22:39:25
LATENT: LLM-Augmented Trojan Insertion and Evaluation Framework for Analog Netlist Topologies,"Jayeeta Chaudhuri, Arjun Chaudhuri, Krishnendu Chakrabarty",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06364"" target=""_blank"">2505.06364</a>",,2025-12-03 22:39:25
AgentXploit: End-to-End Redteaming of Black-Box AI Agents,"Zhun Wang, Vincent Siu, Zhe Ye, Tianneng Shi, Yuzhou Nie, Xuandong Zhao, Chenguang Wang, Wenbo Guo, Dawn Song",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.05849"" target=""_blank"">2505.05849</a>",,2025-12-03 22:39:25
A Taxonomy of Attacks and Defenses in Split Learning,"Aqsa Shabbir, Halil İbrahim Kanpak, Alptekin Küpçü, Sinem Sav",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.05872"" target=""_blank"">2505.05872</a>",,2025-12-03 22:39:25
Realistic Adversarial Attacks for Robustness Evaluation of Trajectory Prediction Models via Future State Perturbation,"Julian F. Schumann, Jeroen Hagenus, Frederik Baymler Mathiesen, Arkady Zgonnikov",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06134"" target=""_blank"">2505.06134</a>",,2025-12-03 22:39:25
Learning from the Good Ones: Risk Profiling-Based Defenses Against Evasion Attacks on DNNs,"Mohammed Elnawawy, Gargi Mitra, Shahrear Iqbal, Karthik Pattabiraman",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06477"" target=""_blank"">2505.06477</a>",,2025-12-03 22:39:25
Practical Reasoning Interruption Attacks on Reasoning Large Language Models,"Yu Cui, Cong Zuo",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06643"" target=""_blank"">2505.06643</a>",,2025-12-03 22:39:25
T2V-OptJail: Discrete Prompt Optimization for Text-to-Video Jailbreak Attacks,"Jiayang Liu, Siyuan Liang, Shiqian Zhao, Rongcheng Tu, Wenbo Zhou, Aishan Liu, Dacheng Tao, Siew Kei Lam",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06679"" target=""_blank"">2505.06679</a>",,2025-12-03 22:39:25
POISONCRAFT: Practical Poisoning of Retrieval-Augmented Generation for Large Language Models,"Yangguang Shao, Xinjie Lin, Haozheng Luo, Chengshang Hou, Gang Xiong, Jiahao Yu, Junzheng Shi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06579"" target=""_blank"">2505.06579</a>","<a href=""https://github.com/AndyShaw01/PoisonCraft"" target=""_blank"">AndyShaw01</a>",2025-12-03 22:39:25
LiteLMGuard: Seamless and Lightweight On-Device Prompt Filtering for Safeguarding Small Language Models against Quantization-induced Risks and Vulnerabilities,"Kalyan Nakka, Jimmy Dani, Ausmit Mondal, Nitesh Saxena",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.05619"" target=""_blank"">2505.05619</a>",,2025-12-03 22:39:25
PaniCar: Securing the Perception of Advanced Driving Assistance Systems Against Emergency Vehicle Lighting,"Elad Feldman, Jacob Shams, Dudi Biton, Alfred Chen, Shaoyuan Xie, Satoru Koda, Yisroel Mirsky, Asaf Shabtai, Yuval Elovici, Ben Nassi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.05183"" target=""_blank"">2505.05183</a>",,2025-12-03 22:39:25
Mitigating Backdoor Triggered and Targeted Data Poisoning Attacks in Voice Authentication Systems,"Alireza Mohammadi, Keshav Sood, Dhananjay Thiruvady, Asef Nazari",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.03455"" target=""_blank"">2505.03455</a>",,2025-12-03 22:39:25
Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks,"Yixin Cheng, Hongcheng Guo, Yangming Li, Leonid Sigal",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.05190"" target=""_blank"">2505.05190</a>",,2025-12-03 22:39:25
A Chaos Driven Metric for Backdoor Attack Detection,"Hema Karnam School of Conflict and Security Studies, National Institute of Advanced Studies, Indian Institute of Science Campus, Bengaluru Surendrababu, Nithin Complex Systems Programme, National Institute of Advanced Studies, Indian Institute of Science Campus, Bengaluru Nagaraj",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.03208"" target=""_blank"">2505.03208</a>",,2025-12-03 22:39:25
BadLingual: A Novel Lingual-Backdoor Attack against Large Language Models,"Zihan Wang, Hongwei Li, Rui Zhang, Wenbo Jiang, Kangjie Chen, Tianwei Zhang, Qingchuan Zhao, Guowen Xu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.03501"" target=""_blank"">2505.03501</a>",,2025-12-03 22:39:25
Reliable Disentanglement Multi-view Learning Against View Adversarial Attacks,"Xuyang Wang, Siyuan Duan, Qizhi Li, Guiduo Duan, Yuan Sun, Dezhong Peng",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.04046"" target=""_blank"">2505.04046</a>",,2025-12-03 22:39:25
Framework GNN-AID: Graph Neural Network Analysis Interpretation and Defense,"Kirill Lukyanov, Mikhail Drobyshevskiy, Georgii Sazonov, Mikhail Soloviov, Ilya Makarov",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.03424"" target=""_blank"">2505.03424</a>","<a href=""https://github.com/ispras/GNN-AID"" target=""_blank"">ispras</a>",2025-12-03 22:39:25
Data-Driven Falsification of Cyber-Physical Systems,"Atanu Kundu, Sauvik Gon, Rajarshi Ray",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.03863"" target=""_blank"">2505.03863</a>",,2025-12-03 22:39:25
Uncovering the Limitations of Model Inversion Evaluation -- Benchmarks and Connection to Type-I Adversarial Attacks,"Sy-Tuyen Ho, Koh Jun Hao, Ngoc-Bao Nguyen, Alexander Binder, Ngai-Man Cheung",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.03519"" target=""_blank"">2505.03519</a>",,2025-12-03 22:39:25
Crafting Physical Adversarial Examples by Combining Differentiable and Physically Based Renders,"Yuqiu Liu, Huanqian Yan, Xiaopei Zhu, Xiaolin Hu, Liang Tang, Hang Su, Chen Lv",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.04662"" target=""_blank"">2505.04662</a>",,2025-12-03 22:39:25
Attention-aggregated Attack for Boosting the Transferability of Facial Adversarial Examples,"Jian-Wei Li, Wen-Ze Shao",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.03383"" target=""_blank"">2505.03383</a>",,2025-12-03 22:39:25
Robustness in AI-Generated Detection: Enhancing Resistance to Adversarial Attacks,"Sun Haoxuan, Hong Yan, Zhan Jiahui, Chen Haoxing, Lan Jun, Zhu Huijia, Wang Weiqiang, Zhang Liqing, Zhang Jianfu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.03435"" target=""_blank"">2505.03435</a>",,2025-12-03 22:39:25
Memory Under Siege: A Comprehensive Survey of Side-Channel Attacks on Memory,"MD Mahady Hassan, Shanto Roy, Reza Rahaeimehr",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.04896"" target=""_blank"">2505.04896</a>",,2025-12-03 22:39:25
DMRL: Data- and Model-aware Reward Learning for Data Extraction,"Zhiqiang Wang, Ruoxi Cheng",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06284"" target=""_blank"">2505.06284</a>",,2025-12-03 22:39:25
RFNNS: Robust Fixed Neural Network Steganography with Popular Deep Generative Models,"Yu Cheng, Jiuan Zhou, Jiawei Chen, Zhaoxia Yin, Xinpeng Zhang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.04116"" target=""_blank"">2505.04116</a>",,2025-12-03 22:39:25
Fight Fire with Fire: Defending Against Malicious RL Fine-Tuning via Reward Neutralization,Wenjun Cao,arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.04578"" target=""_blank"">2505.04578</a>",,2025-12-03 22:39:25
Input-Specific and Universal Adversarial Attack Generation for Spiking Neural Networks in the Spiking Domain,"Spyridon Raptis, Haralampos-G. Stratigopoulos",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.06299"" target=""_blank"">2505.06299</a>",,2025-12-03 22:39:25
Reasoning Models Don't Always Say What They Think,"Yanda Chen, Joe Benton, Ansh Radhakrishnan, Jonathan Uesato, Carson Denison, John Schulman, Arushi Somani, Peter Hase, Misha Wagner, Fabien Roger, Vlad Mikulik, Samuel R. Bowman, Jan Leike, Jared Kaplan, Ethan Perez",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.05410"" target=""_blank"">2505.05410</a>",,2025-12-03 22:39:25
ShortcutProbe: Probing Prediction Shortcuts for Learning Robust Models,"Guangtao Zheng, Wenqian Ye, Aidong Zhang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.13910"" target=""_blank"">2505.13910</a>",,2025-12-03 22:39:25
AugMixCloak: A Defense against Membership Inference Attacks via Image Transformation,"Heqing Ren, Chao Feng, Alberto Huertas, Burkhard Stiller",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.07149"" target=""_blank"">2505.07149</a>",,2025-12-03 22:39:25
Safety Subspaces are Not Distinct: A Fine-Tuning Case Study,"Kaustubh Ponkshe, Shaan Shah, Raghav Singhal, Praneeth Vepakomma",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14185"" target=""_blank"">2505.14185</a>","<a href=""https://github.com/CERT-Lab/safety-subspaces"" target=""_blank"">CERT-Lab</a>",2025-12-03 22:39:25
Practical Adversarial Attacks on Stochastic Bandits via Fake Data Injection,"Qirun Zeng, Eric He, Richard Hoffmann, Xuchuang Wang, Jinhang Zuo",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21938"" target=""_blank"">2505.21938</a>",,2025-12-03 22:39:25
Attention! You Vision Language Model Could Be Maliciously Manipulated,"Xiaosen Wang, Shaokang Wang, Zhijin Ge, Yuyang Luo, Shudong Zhang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.19911"" target=""_blank"">2505.19911</a>",,2025-12-03 22:39:25
RedTeamCUA: Realistic Adversarial Testing of Computer-Use Agents in Hybrid Web-OS Environments,"Zeyi Liao, Jaylen Jones, Linxi Jiang, Eric Fosler-Lussier, Yu Su, Zhiqiang Lin, Huan Sun",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21936"" target=""_blank"">2505.21936</a>",,2025-12-03 22:39:25
PHISH in MESH: Korean Adversarial Phonetic Substitution and Phonetic-Semantic Feature Integration Defense,"Byungjun Kim, Minju Kim, Hyeonchu Park, Bugeun Kim",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21380"" target=""_blank"">2505.21380</a>",,2025-12-03 22:39:25
Calibrating LLM Confidence by Probing Perturbed Representation Stability,"Reza Khanmohammadi, Erfan Miahi, Mehrsa Mardikoraem, Simerjot Kaur, Ivan Brugere, Charese H. Smiley, Kundan Thind, Mohammad M. Ghassemi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21772"" target=""_blank"">2505.21772</a>",,2025-12-03 22:39:25
Red-Teaming Text-to-Image Systems by Rule-based Preference Modeling,"Yichuan Cao, Yibo Miao, Xiao-Shan Gao, Yinpeng Dong",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21074"" target=""_blank"">2505.21074</a>",,2025-12-03 22:39:25
Tracing and Reversing Rank-One Model Edits,"Paul Youssef, Zhixue Zhao, Christin Seifert, Jörg Schlötterer",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.20819"" target=""_blank"">2505.20819</a>",,2025-12-03 22:39:25
System Prompt Extraction Attacks and Defenses in Large Language Models,"Badhan Chandra Das, M. Hadi Amini, Yanzhao Wu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.23817"" target=""_blank"">2505.23817</a>",,2025-12-03 22:39:25
What is Adversarial Training for Diffusion Models? (33%),"Briglia Maria Rosaria, Mujtaba Hussain Mirza, Giuseppe Lisanti, Iacopo Masi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21742"" target=""_blank"">2505.21742</a>",,2025-12-03 22:39:25
Audio Jailbreak Attacks: Exposing Vulnerabilities in SpeechGPT in a White-Box Framework,"Binhao Ma, Hanqing Guo, Zhengping Jay Luo, Rui Duan",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18864"" target=""_blank"">2505.18864</a>",,2025-12-03 22:39:25
Breaking the Ceiling: Exploring the Potential of Jailbreak Attacks through Expanding Strategy Space,"Yao Huang, Yitong Sun, Shouwei Ruan, Yichi Zhang, Yinpeng Dong, Xingxing Wei",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21277"" target=""_blank"">2505.21277</a>","<a href=""https://github.com/Aries-iai/CL-GSO"" target=""_blank"">Aries-iai</a>",2025-12-03 22:39:25
HeteroBA: A Structure-Manipulating Backdoor Attack on Heterogeneous Graphs,"Honglin Gao, Xiang Li, Lan Zhao, Gaoxi Xiao",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21140"" target=""_blank"">2505.21140</a>",,2025-12-03 22:39:25
VideoMarkBench: Benchmarking Robustness of Video Watermarking,"Zhengyuan Jiang, Moyang Guo, Kecen Li, Yuepeng Hu, Yupu Wang, Zhicong Huang, Cheng Hong, Neil Zhenqiang Gong",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21620"" target=""_blank"">2505.21620</a>","<a href=""https://github.com/zhengyuan-jiang/VideoMarkBench"" target=""_blank"">zhengyuan-jiang</a>",2025-12-03 22:39:25
AdInject: Real-World Black-Box Attacks on Web Agents via Advertising Delivery,"Haowei Wang, Junjie Wang, Xiaojun Jia, Rupeng Zhang, Mingyang Li, Zhe Liu, Yang Liu, Qing Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21499"" target=""_blank"">2505.21499</a>","<a href=""https://github.com/NicerWang/AdInject"" target=""_blank"">NicerWang</a>",2025-12-03 22:39:25
Preventing Adversarial AI Attacks Against Autonomous Situational Awareness: A Maritime Case Study,"Mathew J. Walter, Aaron Barrett, Kimberly Tam",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21609"" target=""_blank"">2505.21609</a>",,2025-12-03 22:39:25
NatADiff: Adversarial Boundary Guidance for Natural Adversarial Diffusion,"Max Collins, Jordan Vice, Tim French, Ajmal Mian",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.20934"" target=""_blank"">2505.20934</a>",,2025-12-03 22:39:25
A Framework for Adversarial Analysis of Decision Support Systems Prior to Deployment,"Brett Bissey, Kyle Gatesman, Walker Dimon, Mohammad Alam, Luis Robaina, Joseph Weissman",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21414"" target=""_blank"">2505.21414</a>",,2025-12-03 22:39:25
"One Surrogate to Fool Them All: Universal, Transferable, and Targeted Adversarial Attacks with CLIP","Binyan Xu, Xilin Dai, Di Tang, Kehuan Zhang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.19840"" target=""_blank"">2505.19840</a>",,2025-12-03 22:39:25
CPA-RAG:Covert Poisoning Attacks on Retrieval-Augmented Generation in Large Language Models,"Chunyang Li, Junwei Zhang, Anda Cheng, Zhuo Ma, Xinghua Li, Jianfeng Ma",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.19864"" target=""_blank"">2505.19864</a>",,2025-12-03 22:39:25
Multi-level Certified Defense Against Poisoning Attacks in Offline Reinforcement Learning,"Shijie Liu, Andrew C. Cullen, Paul Montague, Sarah Erfani, Benjamin I. P. Rubinstein",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.20621"" target=""_blank"">2505.20621</a>",,2025-12-03 22:39:25
JailBound: Jailbreaking Internal Safety Boundaries of Vision-Language Models,"Jiaxin Song, Yixu Wang, Jie Li, Rui Yu, Yan Teng, Xingjun Ma, Yingchun Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.19610"" target=""_blank"">2505.19610</a>",,2025-12-03 22:39:25
CloneShield: A Framework for Universal Perturbation Against Zero-Shot Voice Cloning,"Renyuan Li, Zhibo Liang, Haichuan Zhang, Tianyu Shi, Zhiyuan Cheng, Jia Shi, Carl Yang, Mingjie Tang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.19119"" target=""_blank"">2505.19119</a>",,2025-12-03 22:39:25
Co-evolutionary Dynamics of Attack and Defence in Cybersecurity,"Adeela Bashir, Zia Ush Shamszaman, Zhao Song, The Anh Han",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.19338"" target=""_blank"">2505.19338</a>",,2025-12-03 22:39:25
Evaluating Query Efficiency and Accuracy of Transfer Learning-based Model Extraction Attack in Federated Learning,"Sayyed Farid Ahamed, Sandip Roy, Soumya Banerjee, Marc Vucovich, Kevin Choi, Abdul Rahman, Alison Hu, Edward Bowen, Sachin Shetty",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.23791"" target=""_blank"">2505.23791</a>",,2025-12-03 22:39:25
Structure Disruption: Subverting Malicious Diffusion-Based Inpainting via Self-Attention Query Perturbation,"Yuhao He, Jinyu Tian, Haiwei Wu, Jianqing Li",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.19425"" target=""_blank"">2505.19425</a>",,2025-12-03 22:39:25
RADEP: A Resilient Adaptive Defense Framework Against Model Extraction Attacks,"Amit Chakraborty, Sayyed Farid Ahamed, Sandip Roy, Soumya Banerjee, Kevin Choi, Abdul Rahman, Alison Hu, Edward Bowen, Sachin Shetty",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.19364"" target=""_blank"">2505.19364</a>",,2025-12-03 22:39:25
Are Time-Series Foundation Models Deployment-Ready? A Systematic Study of Adversarial Robustness Across Domains,"Jiawen Zhang, Zhenwei Zhang, Shun Zheng, Xumeng Wen, Jia Li, Jiang Bian",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.19397"" target=""_blank"">2505.19397</a>",,2025-12-03 22:39:25
"Your Classifier Can Do More: Towards Bridging the Gaps in Classification, Robustness, and Generation","Kaichao Jiang, He Wang, Xiaoshuai Hao, Xiulong Yang, Ajian Liu, Qi Chu, Yunfeng Diao",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.19459"" target=""_blank"">2505.19459</a>",,2025-12-03 22:39:25
Curvature Dynamic Black-box Attack: revisiting adversarial robustness via dynamic curvature estimation,Peiran Sun,arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.19194"" target=""_blank"">2505.19194</a>",,2025-12-03 22:39:25
Fox in the Henhouse: Supply-Chain Backdoor Attacks Against Reinforcement Learning,"Shijie Liu, Andrew C. Cullen, Paul Montague, Sarah Erfani, Benjamin I. P. Rubinstein",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.19532"" target=""_blank"">2505.19532</a>",,2025-12-03 22:39:25
DOGe: Defensive Output Generation for LLM Protection Against Knowledge Distillation,"Pingzhi Li, Zhen Tan, Huaizhi Qu, Huan Liu, Tianlong Chen",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.19504"" target=""_blank"">2505.19504</a>",,2025-12-03 22:39:25
Capability-Based Scaling Laws for LLM Red-Teaming,"Alexander Panfilov, Paul Kassianik, Maksym Andriushchenko, Jonas Geiping",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.20162"" target=""_blank"">2505.20162</a>",,2025-12-03 22:39:25
Evaluating Software Plagiarism Detection in the Age of AI: Automated Obfuscation and Lessons for Academic Integrity,"Timur Sağlam, Larissa Schmid",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.20158"" target=""_blank"">2505.20158</a>",,2025-12-03 22:39:25
Comparing Neural Network Encodings for Logic-based Explainability,"Levi Cordeiro Carvalho, Saulo A. F. Oliveira, Thiago Alves Rocha",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.20269"" target=""_blank"">2505.20269</a>",,2025-12-03 22:39:25
Lifelong Safety Alignment for Language Models,"Haoyu Wang, Zeyu Qin, Yifei Zhao, Chao Du, Min Lin, Xueqian Wang, Tianyu Pang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.20259"" target=""_blank"">2505.20259</a>","<a href=""https://github.com/sail-sg/LifelongSafetyAlignment"" target=""_blank"">sail-sg</a>",2025-12-03 22:39:25
Novel Loss-Enhanced Universal Adversarial Patches for Sustainable Speaker Privacy,"Elvir Karimov, Alexander Varlamov, Danil Ivanov, Dmitrii Korzh, Oleg Y. Rogov",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.19951"" target=""_blank"">2505.19951</a>",,2025-12-03 22:39:25
Breaking Dataset Boundaries: Class-Agnostic Targeted Adversarial Attacks,"Taïga Gonçalves, Tomo Miyazaki, Shinichiro Omachi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.20782"" target=""_blank"">2505.20782</a>",,2025-12-03 22:39:25
Rethinking Gradient-based Adversarial Attacks on Point Cloud Classification,"Jun Chen, Xinke Li, Mingyue Xu, Tianrui Li, Chongshou Li",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21854"" target=""_blank"">2505.21854</a>",,2025-12-03 22:39:25
Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion,"Yayin Zheng, Chen Wan, Zihong Guo, Hailing Kuang, Xiaohai Lu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21181"" target=""_blank"">2505.21181</a>",,2025-12-03 22:39:25
SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents,"Kunlun Zhu, Jiaxun Zhang, Ziheng Qi, Nuoxing Shang, Zijia Liu, Peixuan Han, Yue Su, Haofei Yu, Jiaxuan You",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.23559"" target=""_blank"">2505.23559</a>","<a href=""https://github.com/ulab-uiuc/SafeScientist"" target=""_blank"">ulab-uiuc</a>",2025-12-03 22:39:25
TRAP: Targeted Redirecting of Agentic Preferences,"Hangoo Kang, Jehyeok Yeon, Gagandeep Singh",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.23518"" target=""_blank"">2505.23518</a>",,2025-12-03 22:39:25
The Butterfly Effect in Pathology: Exploring Security in Pathology Foundation Models,"Jiashuai Liu, Yingjia Shang, Yingkang Zhan, Di Zhang, Yi Niu, Dong Wei, Xian Wu, Zeyu Gao, Chen Li, Yefeng Zheng",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24141"" target=""_blank"">2505.24141</a>","<a href=""https://github.com/Jiashuai-Liu-hmos/Attack-WSI-pathology-foundation-models"" target=""_blank"">Jiashuai-Liu-hmos</a>",2025-12-03 22:39:25
Adversarial Semantic and Label Perturbation Attack for Pedestrian Attribute Recognition,"Weizhe Kong, Xiao Wang, Ruichong Gao, Chenglong Li, Yu Zhang, Xing Yang, Yaowei Wang, Jin Tang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.23313"" target=""_blank"">2505.23313</a>","<a href=""https://github.com/Event-AHU/OpenPAR"" target=""_blank"">Event-AHU</a>",2025-12-03 22:39:25
Robust Federated Learning against Model Perturbation in Edge Networks,"Dongzi Jin, Yong Xiao, Yingyu Li",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24728"" target=""_blank"">2505.24728</a>",,2025-12-03 22:39:25
"So, I climbed to the top of the pyramid of pain -- now what? (1%)","Vasilis Katos, Emily Rosenorn-Lanng, Jane Henriksen-Bulmer, Ala Yankouskaya",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24685"" target=""_blank"">2505.24685</a>",,2025-12-03 22:39:25
Model Unlearning via Sparse Autoencoder Subspace Guided Projections,"Xu Wang, Zihao Li, Benyou Wang, Yan Hu, Difan Zou",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24428"" target=""_blank"">2505.24428</a>",,2025-12-03 22:39:25
Breaking the Gold Standard: Extracting Forgotten Data under Exact Unlearning in Large Language Models,"Xiaoyu Wu, Yifei Pang, Terrance Liu, Zhiwei Steven Wu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24379"" target=""_blank"">2505.24379</a>",,2025-12-03 22:39:25
A Flat Minima Perspective on Understanding Augmentations and Model Robustness,"Weebum Yoo, Sung Whan Yoon",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24592"" target=""_blank"">2505.24592</a>",,2025-12-03 22:39:25
Light as Deception: GPT-driven Natural Relighting Against Vision-Language Pre-training Models,"Ying Yang, Jie Zhang, Xiao Lv, Di Lin, Tao Xiang, Qing Guo",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24227"" target=""_blank"">2505.24227</a>",,2025-12-03 22:39:25
Cascading Adversarial Bias from Injection to Distillation in Language Models,"Harsh Chaudhari, Jamie Hayes, Matthew Jagielski, Ilia Shumailov, Milad Nasr, Alina Oprea",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24842"" target=""_blank"">2505.24842</a>",,2025-12-03 22:39:25
Adversarial Preference Learning for Robust LLM Alignment,"Yuanfu Wang, Pengyu Wang, Chenyang Xi, Bo Tang, Junyi Zhu, Wenqiang Wei, Chen Chen, Chao Yang, Jingfeng Zhang, Chaochao Lu, Yijun Niu, Keming Mao, Zhiyu Li, Feiyu Xiong, Jie Hu, Mingchuan Yang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24369"" target=""_blank"">2505.24369</a>",,2025-12-03 22:39:25
Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors,"Andrea Pedrotti, Michele Papucci, Cristiano Ciaccio, Alessio Miaschi, Giovanni Puccetti, Felice Dell'Orletta, Andrea Esuli",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24523"" target=""_blank"">2505.24523</a>",,2025-12-03 22:39:25
Black-box Adversarial Attacks on CNN-based SLAM Algorithms,"Maria Rafaela Gkeka, Bowen Sun, Evgenia Smirni, Christos D. Antonopoulos, Spyros Lalis, Nikolaos Bellas",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24654"" target=""_blank"">2505.24654</a>",,2025-12-03 22:39:25
Learning Safety Constraints for Large Language Models,"Xin Chen, Yarden As, Andreas Krause",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24445"" target=""_blank"">2505.24445</a>",,2025-12-03 22:39:25
Is Your Prompt Safe? Investigating Prompt Injection Attacks Against Open-Source LLMs,"Jiawen Wang, Pritha Gupta, Ivan Habernal, Eyke Hüllermeier",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14368"" target=""_blank"">2505.14368</a>",,2025-12-03 22:39:25
Buffer-free Class-Incremental Learning with Out-of-Distribution Detection,"Srishti Gupta, Daniele Angioni, Maura Pintor, Ambra Demontis, Lea Schönherr, Battista Biggio, Fabio Roli",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.23412"" target=""_blank"">2505.23412</a>",,2025-12-03 22:39:25
Disrupting Vision-Language Model-Driven Navigation Services via Adversarial Object Fusion,"Chunlong Xie, Jialing He, Shangwei Guo, Jiacheng Wang, Shudong Zhang, Tianwei Zhang, Tao Xiang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.23266"" target=""_blank"">2505.23266</a>",,2025-12-03 22:39:25
Adversarial Attacks against Closed-Source MLLMs via Feature Optimal Alignment,"Xiaojun Jia, Sensen Gao, Simeng Qin, Tianyu Pang, Chao Du, Yihao Huang, Xinfeng Li, Yiming Li, Bo Li, Yang Liu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21494"" target=""_blank"">2505.21494</a>","<a href=""https://github.com/jiaxiaojunQAQ/FOA-Attack"" target=""_blank"">jiaxiaojunQAQ</a>",2025-12-03 22:39:25
LLM Agents Should Employ Security Principles,"Kaiyuan Zhang, Zian Su, Pin-Yu Chen, Elisa Bertino, Xiangyu Zhang, Ninghui Li",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24019"" target=""_blank"">2505.24019</a>",,2025-12-03 22:39:25
TabAttackBench: A Benchmark for Adversarial Attacks on Tabular Data,"Zhipeng He, Chun Ouyang, Lijie Wen, Cong Liu, Catarina Moreira",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21027"" target=""_blank"">2505.21027</a>",,2025-12-03 22:39:25
Pitfalls of Rule- and Model-based Verifiers -- A Case Study on Mathematical Reasoning,"Yuzhen Huang, Weihao Zeng, Xingshan Zeng, Qi Zhu, Junxian He",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.22203"" target=""_blank"">2505.22203</a>",,2025-12-03 22:39:25
How Do Diffusion Models Improve Adversarial Robustness? (2%),"Liu Yuezhang, Xue-Xin Wei",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.22839"" target=""_blank"">2505.22839</a>",,2025-12-03 22:39:25
Mitigating Overthinking in Large Reasoning Models via Manifold Steering,"Yao Huang, Huanran Chen, Shouwei Ruan, Yichi Zhang, Xingxing Wei, Yinpeng Dong",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.22411"" target=""_blank"">2505.22411</a>","<a href=""https://github.com/Aries-iai/Manifold_Steering"" target=""_blank"">Aries-iai</a>",2025-12-03 22:39:25
Efficient Preimage Approximation for Neural Network Certification,"Anton Björklund, Mykola Zaitsev, Marta Kwiatkowska",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.22798"" target=""_blank"">2505.22798</a>",,2025-12-03 22:39:25
FGS-Audio: Fixed-Decoder Framework for Audio Steganography with Adversarial Perturbation Generation,"Jialin Yan, Yu Cheng, Zhaoxia Yin, Xinpeng Zhang, Shilin Wang, Tanfeng Sun, Xinghao Jiang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.22266"" target=""_blank"">2505.22266</a>",,2025-12-03 22:39:25
Test-Time Immunization: A Universal Defense Framework Against Jailbreaks for (Multimodal) Large Language Models,"Yongcan Yu, Yanbo Wang, Ran He, Jian Liang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.22271"" target=""_blank"">2505.22271</a>",,2025-12-03 22:39:25
Spa-VLM: Stealthy Poisoning Attacks on RAG-based VLM,"Lei Yu, Yechao Zhang, Ziqi Zhou, Yang Wu, Wei Wan, Minghui Li, Shengshan Hu, Pei Xiaobing, Jing Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.23828"" target=""_blank"">2505.23828</a>",,2025-12-03 22:39:25
The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector,"Aixuan Li, Mochu Xiang, Jing Zhang, Yuchao Dai",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.22499"" target=""_blank"">2505.22499</a>",,2025-12-03 22:39:25
Adversarially Robust AI-Generated Image Detection for Free: An Information Theoretic Perspective,"Ruixuan Zhang, He Wang, Zhengyu Zhao, Zhiqing Guo, Xun Yang, Yunfeng Diao, Meng Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.22604"" target=""_blank"">2505.22604</a>",,2025-12-03 22:39:25
Seeing the Threat: Vulnerabilities in Vision-Language Models to Adversarial Attack,"Juan Ren, Mark Dras, Usman Naseem",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.21967"" target=""_blank"">2505.21967</a>",,2025-12-03 22:39:25
Understanding Adversarial Training with Energy-based Models,"Mujtaba Hussain Mirza, Maria Rosaria Briglia, Filippo Bartolucci, Senad Beadini, Giuseppe Lisanti, Iacopo Masi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.22486"" target=""_blank"">2505.22486</a>",,2025-12-03 22:39:25
The Rich and the Simple: On the Implicit Bias of Adam and SGD,"Bhavya Vasudeva, Jung Whan Lee, Vatsal Sharan, Mahdi Soltanolkotabi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24022"" target=""_blank"">2505.24022</a>",,2025-12-03 22:39:25
Distributed Federated Learning for Vehicular Network Security: Anomaly Detection Benefits and Multi-Domain Attack Threats,"Utku Demir, Yalin E. Sagduyu, Tugba Erpek, Hossein Jafari, Sastry Kompella, Mengran Xue",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.23706"" target=""_blank"">2505.23706</a>",,2025-12-03 22:39:25
Network Inversion for Uncertainty-Aware Out-of-Distribution Detection,"Pirzada Suhail, Rehna Afroz, Amit Sethi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.23448"" target=""_blank"">2505.23448</a>",,2025-12-03 22:39:25
The Silent Saboteur: Imperceptible Adversarial Attacks against Black-Box Retrieval-Augmented Generation Systems,"Hongru Song, Yu-an Liu, Ruqing Zhang, Jiafeng Guo, Jianming Lv, Rijke Maarten de, Xueqi Cheng",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18583"" target=""_blank"">2505.18583</a>",,2025-12-03 22:39:25
Confidential Guardian: Cryptographically Prohibiting the Abuse of Model Abstention,"Stephan Rabanser, Ali Shahin Shamsabadi, Olive Franzese, Xiao Wang, Adrian Weller, Nicolas Papernot",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.23968"" target=""_blank"">2505.23968</a>",,2025-12-03 22:39:25
PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches,"Dennis Jacob, Chong Xiang, Prateek Mittal",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.24703"" target=""_blank"">2505.24703</a>",,2025-12-03 22:39:25
Robustifying Vision-Language Models via Dynamic Token Reweighting,"Tanqiu Jiang, Jiacheng Liang, Rongyi Zhu, Jiawei Zhou, Fenglong Ma, Ting Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17132"" target=""_blank"">2505.17132</a>",,2025-12-03 22:39:25
Why Can Accurate Models Be Learned from Inaccurate Annotations? (1%),"Chongjie Si, Yidan Cui, Fuchao Yang, Xiaokang Yang, Wei Shen",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.16159"" target=""_blank"">2505.16159</a>",,2025-12-03 22:39:25
P3Net: Progressive and Periodic Perturbation for Semi-Supervised Medical Image Segmentation,"Zhenyan Yao, Miao Zhang, Lanhu Wu, Yongri Piao, Feng Tian, Weibing Sun, Huchuan Lu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15861"" target=""_blank"">2505.15861</a>",,2025-12-03 22:39:25
"My Face Is Mine, Not Yours: Facial Protection Against Diffusion Model Face Swapping","Hon Ming Yam, Zhongliang Guo, Chun Pong Lau",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15336"" target=""_blank"">2505.15336</a>",,2025-12-03 22:39:25
Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors,"Hao Fang, Jiawei Kong, Tianqu Zhuang, Yixiang Qiu, Kuofeng Gao, Bin Chen, Shu-Tao Xia, Yaowei Wang, Min Zhang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15337"" target=""_blank"">2505.15337</a>",,2025-12-03 22:39:25
Geometrically Regularized Transfer Learning with On-Manifold and Off-Manifold Perturbation,"Hana Satou, Alan Mitkiy, F Monkey",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15191"" target=""_blank"">2505.15191</a>",,2025-12-03 22:39:25
Ranking Free RAG: Replacing Re-ranking with Selection in RAG for Sensitive Domains,"Yash Saxena, Ankur Padia, Mandar S Chaudhary, Kalpa Gunaratna, Srinivasan Parthasarathy, Manas Gaur",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.16014"" target=""_blank"">2505.16014</a>",,2025-12-03 22:39:25
GAMA: Geometry-Aware Manifold Alignment via Structured Adversarial Perturbations for Robust Domain Adaptation,"Hana Satou, F Monkey",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15194"" target=""_blank"">2505.15194</a>",,2025-12-03 22:39:25
Silent Leaks: Implicit Knowledge Extraction Attack on RAG Systems through Benign Queries,"Yuhao Wang, Wenjie Qu, Yanze Jiang, Zichen Liu, Yue Liu, Shengfang Zhai, Yinpeng Dong, Jiaheng Zhang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15420"" target=""_blank"">2505.15420</a>",,2025-12-03 22:39:25
MTSA: Multi-turn Safety Alignment for LLMs through Multi-round Red-teaming,"Weiyang Guo, Jing Li, Wenya Wang, YU LI, Daojing He, Jun Yu, Min Zhang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17147"" target=""_blank"">2505.17147</a>",,2025-12-03 22:39:25
Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large Audio-Language Models,"Zirui Song, Qian Jiang, Mingxuan Cui, Mingzhe Li, Lang Gao, Zeyu Zhang, Zixiang Xu, Yanbo Wang, Chenxi Wang, Guangxian Ouyang, Zhenhao Chen, Xiuying Chen",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15406"" target=""_blank"">2505.15406</a>",,2025-12-03 22:39:25
Interpretability Illusions with Sparse Autoencoders: Evaluating Robustness of Concept Representations,"Aaron J. Li, Suraj Srinivas, Usha Bhalla, Himabindu Lakkaraju",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.16004"" target=""_blank"">2505.16004</a>",,2025-12-03 22:39:25
Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context Retrieval,"Taiye Chen, Zeming Wei, Ang Li, Yisen Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15753"" target=""_blank"">2505.15753</a>",,2025-12-03 22:39:25
TRAIL: Transferable Robust Adversarial Images via Latent diffusion,"Yuhao Xue, Zhifei Zhang, Xinyang Jiang, Yifei Shen, Junyao Gao, Wentao Gu, Jiale Zhao, Miaojing Shi, Cairong Zhao",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.16166"" target=""_blank"">2505.16166</a>",,2025-12-03 22:39:25
Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses,"Xiaoxue Yang, Bozhidar Stevanoski, Matthieu Meeus, Montjoye Yves-Alexandre de",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15738"" target=""_blank"">2505.15738</a>",,2025-12-03 22:39:25
Beyond Classification: Evaluating Diffusion Denoised Smoothing for Security-Utility Trade off,"Yury Belousov, Brian Pulfer, Vitaliy Kinakh, Slava Voloshynovskiy",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15594"" target=""_blank"">2505.15594</a>",,2025-12-03 22:39:25
Training on Plausible Counterfactuals Removes Spurious Correlations,"Shpresim Sadiku, Kartikeya Chitranshi, Hiroshi Kera, Sebastian Pokutta",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.16583"" target=""_blank"">2505.16583</a>",,2025-12-03 22:39:25
Hunyuan-TurboS: Advancing Large Language Models through Mamba-Transformer Synergy and Adaptive Chain-of-Thought,"Ao Liu, Botong Zhou, Can Xu, Chayse Zhou, ChenChen Zhang, Chengcheng Xu, Chenhao Wang, Decheng Wu, Dengpeng Wu, Dian Jiao, Dong Du, Dong Wang, Feng Zhang, Fengzong Lian, Guanghui Xu, Guanwei Zhang, Hai Wang, Haipeng Luo, Han Hu, Huilin Xu, Jiajia Wu, Jianchen Zhu, Jianfeng Yan, Jiaqi Zhu, Jihong Zhang, Jinbao Xue, Jun Xia, Junqiang Zheng, Kai Liu, Kai Zhang, Kai Zheng, Kejiao Li, Keyao Wang, Lan Jiang, Lixin Liu, Lulu Wu, Mengyuan Huang, Peijie Yu, Peiqi Wang, Qian Wang, Qianbiao Xiang, Qibin Liu, Qingfeng Sun, Richard Guo, Ruobing Xie, Saiyong Yang, Shaohua Chen, Shihui Hu, Shuai Li, Shuaipeng Li, Shuang Chen, Suncong Zheng, Tao Yang, Tian Zhang, Tinghao Yu, Weidong Han, Weijie Liu, Weijin Zhou, Weikang Wang, Wesleye Chen, Xiao Feng, Xiaoqin Ren, Xingwu Sun, Xiong Kuang, Xuemeng Huang, Xun Cao, Yanfeng Chen, Yang Du, Yang Zhen, Yangyu Tao, Yaping Deng, Yi Shen, Yigeng Hong, Yiqi Chen, Yiqing Huang, Yuchi Deng, Yue Mao, Yulong Wang, Yuyuan Zeng, Zenan Xu, Zhanhui Kang, Zhe Zhao, ZhenXiang Yan, Zheng Fang, Zhichao Hu, Zhongzhi Chen, Zhuoyu Li, Zongwei Li, Alex Yan, Ande Liang, Baitong Liu, Beiping Pan, Bin Xing, Binghong Wu, Bingxin Qu, Bolin Ni, Boyu Wu, Chen Li, Cheng Jiang, Cheng Zhang, Chengjun Liu, Chengxu Yang, Chiyu Wang, Chong Zha, Daisy Yi, Di Wang, Fanyang Lu, Fei Chen, Feifei Liu, Feng Zheng, Guanghua Yu, Guiyang Li, Guohua Wang, Haisheng Lin, Han Liu, Han Wang, Hao Fei, Hao Lu, Haoqing Jiang, Haoran Sun, Haotian Zhu, Huangjin Dai, Huankui Chen, Huawen Feng, Huihui Cai, Huxin Peng, Jackson Lv, Jiacheng Shi, Jiahao Bu, Jianbo Li, Jianglu Hu, Jiangtao Guan, Jianing Xu, Jianwei Cai, Jiarong Zhang, Jiawei Song, Jie Jiang, Jie Liu, Jieneng Yang, Jihong Zhang, Jin lv, Jing Zhao, Jinjian Li, Jinxing Liu, Jun Zhao, Juntao Guo, Kai Wang, Kan Wu, Lei Fu, Lei He, Lei Wang, Li Liu, Liang Dong, Liya Zhan, Long Cheng, Long Xu, Mao Zheng, Meng Liu, Mengkang Hu, Nanli Chen, Peirui Chen, Peng He, Pengju Pan, Pengzhi Wei, Qi Yang, Qi Yi, Roberts Wang, Rongpeng Chen, Rui Sun, Rui Yang, Ruibin Chen, Ruixu Zhou, Shaofeng Zhang, Sheng Zhang, Shihao Xu, Shuaishuai Chang, Shulin Liu, SiQi Wang, Songjia Feng, Songling Yuan, Tao Zhang, Tianjiao Lang, Tongkai Li, Wei Deng, Wei Li, Weichao Wang, Weigang Zhang, Weixuan Sun, Wen Ouyang, Wenxiang Jiao, Wenzhi Sun, Wenzhuo Jia, Xiang Zhang, Xiangyu He, Xianshun Ren, XiaoYing Zhu, Xiaolong Guo, Xiaoxue Li, Xiaoyu Ma, Xican Lu, Xinhua Feng, Xinting Huang, Xinyu Guan, Xirui Li, Xu Zhang, Xudong Gao, Xun Luo, Xuxiang Qi, Yangkun Chen, Yangyu Tao, Yanling Xiao, Yantao Mai, Yanze Chen, Yao Ding, Yeting Yang, YiFan Song, Yifan Yang, Yijiao Zhu, Yinhe Wu, Yixian Liu, Yong Yang, Yuanjun Cai, Yuanlin Tu, Yue Zhang, Yufei Huang, Yuhang Zhou, Yuhao Jiang, Yuhong Liu, Yuhui Hu, Yujin Lin, Yun Yang, Yunhao Wang, Yusong Zhang, Zekun Wu, Zelong Zhang, Zhan Yu, Zhaoliang Yang, Zhe Zhao, Zheng Li, Zhenyu Huang, Zhiguang Liu, Zhijiang Xu, Zhiqing Kui, Zhiyin Zeng, Zhiyuan Xiong, Zhuo Han, Zifan Wu, Zigang Geng, Zilong Zhao, Ziyan Tang, Ziyuan Zhu, Zonglei Zhu, Zhijiang Xu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15431"" target=""_blank"">2505.15431</a>",,2025-12-03 22:39:25
Enhancing Certified Robustness via Block Reflector Orthogonal Layers and Logit Annealing Loss,"Bo-Han Lai, Pin-Han Huang, Bo-Han Kung, Shang-Tse Chen",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15174"" target=""_blank"">2505.15174</a>","<a href=""https://github.com/ntuaislab/BRONet"" target=""_blank"">ntuaislab</a>",2025-12-03 22:39:25
BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution,"Ji Guo, Xiaolei Wen, Wenbo Jiang, Cheng Huang, Jinjin Li, Hongwei Li",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15308"" target=""_blank"">2505.15308</a>",,2025-12-03 22:39:25
A Survey On Secure Machine Learning,"Taobo Liao, Taoran Li, Prathamesh Nadkarni",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15124"" target=""_blank"">2505.15124</a>",,2025-12-03 22:39:25
Adversarially Pretrained Transformers may be Universally Robust In-Context Learners,"Soichiro Kumano, Hiroshi Kera, Toshihiko Yamasaki",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14042"" target=""_blank"">2505.14042</a>","<a href=""https://github.com/s-kumano/universally-robust-in-context-learner"" target=""_blank"">s-kumano</a>",2025-12-03 22:39:25
LORE: Lagrangian-Optimized Robust Embeddings for Visual Encoders,"Borna Khodabandeh, Amirabbas Afzali, Amirhossein Afsharrad, Seyed Shahabeddin Mousavi, Sanjay Lall, Sajjad Amini, Seyed-Mohsen Moosavi-Dezfooli",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18884"" target=""_blank"">2505.18884</a>",,2025-12-03 22:39:25
Anomaly Detection Based on Critical Paths for Deep Neural Networks,"Fangzhen Zhao, Chenyi Zhang, Naipeng Dong, Ming Li, Jinxiao Shan",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14967"" target=""_blank"">2505.14967</a>",,2025-12-03 22:39:25
EVA: Red-Teaming GUI Agents via Evolving Indirect Prompt Injection,"Yijie Lu, Tianjie Ju, Manman Zhao, Xinbei Ma, Yuan Guo, ZhuoSheng Zhang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14289"" target=""_blank"">2505.14289</a>",,2025-12-03 22:39:25
AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models,"Guangke Chen, Fu Song, Zhe Zhao, Xiaojun Jia, Yang Liu, Yanchen Qiao, Weizhe Zhang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14103"" target=""_blank"">2505.14103</a>","<a href=""https://audiojailbreak.github.io/AudioJailbreak"" target=""_blank"">audiojailbreak.github.io</a>",2025-12-03 22:39:25
GraphemeAug: A Systematic Approach to Synthesized Hard Negative Keyword Spotting Examples,"Harry Zhang, Kurt Partridge, Pai Zhu, Neng Chen, Hyun Jin Park, Dhruuv Agarwal, Quan Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14814"" target=""_blank"">2505.14814</a>",,2025-12-03 22:39:25
"Trust Me, I Can Handle It: Self-Generated Adversarial Scenario Extrapolation for Robust Language Models","Md Rafi Ur Rashid, Vishnu Asutosh Dasu, Ye Wang, Gang Tan, Shagufta Mehnaz",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17089"" target=""_blank"">2505.17089</a>",,2025-12-03 22:39:25
Exploring Jailbreak Attacks on LLMs through Intent Concealment and Diversion,"Tiehan Cui, Yanxu Mao, Peipei Liu, Congying Liu, Datao You",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14316"" target=""_blank"">2505.14316</a>",,2025-12-03 22:39:25
Lessons from Defending Gemini Against Indirect Prompt Injections,"Chongyang Shi, Sharon Lin, Shuang Song, Jamie Hayes, Ilia Shumailov, Itay Yona, Juliette Pluto, Aneesh Pappu, Christopher A. Choquette-Choo, Milad Nasr, Chawin Sitawarin, Gena Gibson, Andreas Terzis, John ""Four"" Flynn",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14534"" target=""_blank"">2505.14534</a>",,2025-12-03 22:39:25
Vulnerability of Transfer-Learned Neural Networks to Data Reconstruction Attacks in Small-Data Regime,"Tomasz Maciążek, Robert Allison",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14323"" target=""_blank"">2505.14323</a>",,2025-12-03 22:39:25
Universal Acoustic Adversarial Attacks for Flexible Control of Speech-LLMs,"Rao Ma, Mengjie Qian, Vyas Raina, Mark Gales, Kate Knill",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14286"" target=""_blank"">2505.14286</a>",,2025-12-03 22:39:25
FedGraM: Defending Against Untargeted Attacks in Federated Learning via Embedding Gram Matrix,"Di Wu, Qian Li, Heng Yang, Yong Han",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14024"" target=""_blank"">2505.14024</a>",,2025-12-03 22:39:25
Adverseness vs,"Xinxin Fan, Wenxiong Chen, Mengfan Li, Wenqi Wei, Ling Liu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14463"" target=""_blank"">2505.14463</a>",,2025-12-03 22:39:25
Robustness Evaluation of Graph-based News Detection Using Network Structural Information,"Xianghua Zeng, Hao Peng, Angsheng Li",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14453"" target=""_blank"">2505.14453</a>",,2025-12-03 22:39:25
Challenger: Affordable Adversarial Driving Video Generation,"Zhiyuan Xu, Bohan Li, Huan-ang Gao, Mingju Gao, Yong Chen, Ming Liu, Chenxu Yan, Hang Zhao, Shuo Feng, Hao Zhao",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.15880"" target=""_blank"">2505.15880</a>",,2025-12-03 22:39:25
"All You Need is ""Leet"": Evading Hate-speech Detection AI","Sampanna Yashwant Kahu, Naman Ahuja",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.16263"" target=""_blank"">2505.16263</a>",,2025-12-03 22:39:25
Adversarial Training from Mean Field Perspective,"Soichiro Kumano, Hiroshi Kera, Toshihiko Yamasaki",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.14021"" target=""_blank"">2505.14021</a>",,2025-12-03 22:39:25
REOBench: Benchmarking Robustness of Earth Observation Foundation Models,"Xiang Li, Yong Tao, Siyuan Zhang, Siwei Liu, Zhitong Xiong, Chunbo Luo, Lu Liu, Mykola Pechenizkiy, Xiao Xiang Zhu, Tianjin Huang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.16793"" target=""_blank"">2505.16793</a>",,2025-12-03 22:39:25
LAMDA: A Longitudinal Android Malware Benchmark for Concept Drift Analysis,"Md Ahsanul Haque, Ismail Hossain, Md Mahmuduzzaman Kamol, Md Jahangir Alam, Suresh Kumar Amalapuram, Sajedul Talukder, Mohammad Saidur Rahman",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18551"" target=""_blank"">2505.18551</a>","<a href=""https://iqsec-lab.github.io/LAMDA/"" target=""_blank"">LAMDA</a>",2025-12-03 22:39:25
Chain-of-Lure: A Synthetic Narrative-Driven Approach to Compromise Large Language Models,"Wenhan Chang, Tianqing Zhu, Yu Zhao, Shuangyong Song, Ping Xiong, Wanlei Zhou, Yongxiang Li",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17519"" target=""_blank"">2505.17519</a>",,2025-12-03 22:39:25
A Critical Evaluation of Defenses against Prompt Injection Attacks,"Yuqi Jia, Zedian Shao, Yupei Liu, Jinyuan Jia, Dawn Song, Neil Zhenqiang Gong",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18333"" target=""_blank"">2505.18333</a>","<a href=""https://github.com/PIEval123/PIEval"" target=""_blank"">PIEval123</a>",2025-12-03 22:39:25
Temporal Consistency Constrained Transferable Adversarial Attacks with Background Mixup for Action Recognition,"Ping Li, Jianan Ni, Bo Pang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17807"" target=""_blank"">2505.17807</a>","<a href=""https://github.com/mlvccn/BMTC_TransferAttackVid"" target=""_blank"">mlvccn</a>",2025-12-03 22:39:25
Ownership Verification of DNN Models Using White-Box Adversarial Attacks with Specified Probability Manipulation,"Teruki Sano, Minoru Kuribayashi, Masao Sakai, Shuji Ishobe, Eisuke Koizumi",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17579"" target=""_blank"">2505.17579</a>",,2025-12-03 22:39:25
Towards more transferable adversarial attack in black-box manner,"Chun Tong Lei, Zhongliang Guo, Hon Chung Lee, Minh Quoc Duong, Chun Pong Lau",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18097"" target=""_blank"">2505.18097</a>",,2025-12-03 22:39:25
Enhancing Adversarial Robustness of Vision Language Models via Adversarial Mixture Prompt Tuning,"Shiji Zhao, Qihui Zhu, Shukun Xiong, Shouwei Ruan, Yize Fan, Ranjie Duan, Qing Guo, Xingxing Wei",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17509"" target=""_blank"">2505.17509</a>",,2025-12-03 22:39:25
$PD^3F$: A Pluggable and Dynamic DoS-Defense Framework Against Resource Consumption Attacks Targeting Large Language Models,"Yuanhe Zhang, Xinyue Wang, Haoran Gao, Zhenhong Zhou, Fanyu Meng, Yuyao Zhang, Sen Su",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18680"" target=""_blank"">2505.18680</a>",,2025-12-03 22:39:25
Exploring the Vulnerability of the Content Moderation Guardrail in Large Language Models via Intent Manipulation,"Jun Zhuang, Haibo Jin, Ye Zhang, Zhengjian Kang, Wenbin Zhang, Gaby G. Dagher, Haohan Wang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18556"" target=""_blank"">2505.18556</a>",,2025-12-03 22:39:25
Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models,"Jiawei Kong, Hao Fang, Xiaochen Yang, Kuofeng Gao, Bin Chen, Shu-Tao Xia, Yaowei Wang, Min Zhang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17601"" target=""_blank"">2505.17601</a>",,2025-12-03 22:39:25
Mal-D2GAN: Double-Detector based GAN for Malware Generation,"Nam Hoang Thanh, Trung Pham Duy, Lam Bui Thu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18806"" target=""_blank"">2505.18806</a>",,2025-12-03 22:39:25
Security Concerns for Large Language Models: A Survey,"Miles Q. Li, Benjamin C. M. Fung",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18889"" target=""_blank"">2505.18889</a>",,2025-12-03 22:39:25
Strong Membership Inference Attacks on Massive Datasets and (Moderately) Large Language Models,"Jamie Hayes, Ilia Shumailov, Christopher A. Choquette-Choo, Matthew Jagielski, George Kaissis, Katherine Lee, Milad Nasr, Sahra Ghalebikesabi, Niloofar Mireshghallah, Meenatchi Sundaram Mutu Selva Annamalai, Igor Shilov, Matthieu Meeus, Montjoye Yves-Alexandre de, Franziska Boenisch, Adam Dziedzic, A. Feder Cooper",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18773"" target=""_blank"">2505.18773</a>",,2025-12-03 22:39:25
StyleGuard: Preventing Text-to-Image-Model-based Style Mimicry Attacks by Style Perturbations,"Yanjie Li, Wenxuan Zhang, Xinqi Lyu, Yihao Liu, Bin Xiao",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18766"" target=""_blank"">2505.18766</a>",,2025-12-03 22:39:25
Mind the Gap: A Practical Attack on GGUF Quantization,"Kazuki Egashira, Robin Staab, Mark Vero, Jingxuan He, Martin Vechev",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.23786"" target=""_blank"">2505.23786</a>",,2025-12-03 22:39:25
Benchmarking Poisoning Attacks against Retrieval-Augmented Generation,"Baolei Zhang, Haoran Xin, Jiatong Li, Dongzhe Zhang, Minghong Fang, Zhuqing Liu, Lihai Nie, Zheli Liu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18543"" target=""_blank"">2505.18543</a>",,2025-12-03 22:39:25
When Safety Detectors Aren't Enough: A Stealthy and Effective Jailbreak Attack on LLMs via Steganographic Techniques,"Jianing Geng, Biao Yi, Zekun Fei, Tongxi Wu, Lihai Nie, Zheli Liu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.16765"" target=""_blank"">2505.16765</a>",,2025-12-03 22:39:25
What You Read Isn't What You Hear: Linguistic Sensitivity in Deepfake Speech Detection,"Binh Nguyen, Shuji Shi, Ryan Ofman, Thai Le",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17513"" target=""_blank"">2505.17513</a>",,2025-12-03 22:39:25
One Model Transfer to All: On Robust Jailbreak Prompts Generation against LLMs,"Linbao Li, Yannan Liu, Daojing He, Yu Li",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17598"" target=""_blank"">2505.17598</a>","<a href=""https://github.com/LLBao/ArrAttack"" target=""_blank"">LLBao</a>",2025-12-03 22:39:25
EVADE: Multimodal Benchmark for Evasive Content Detection in E-Commerce Applications,"Ancheng Xu, Zhihao Yang, Jingpeng Li, Guanghu Yuan, Longze Chen, Liang Yan, Jiehui Zhou, Zhen Qin, Hengyun Chang, Hamid Alinejad-Rokny, Bo Zheng, Min Yang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17654"" target=""_blank"">2505.17654</a>",,2025-12-03 22:39:25
Experimental robustness benchmark of quantum neural network on a superconducting quantum processor,"Hai-Feng Zhang, Zhao-Yun Chen, Peng Wang, Liang-Liang Guo, Tian-Le Wang, Xiao-Yan Yang, Ren-Ze Zhao, Ze-An Zhao, Sheng Zhang, Lei Du, Hao-Ran Tao, Zhi-Long Jia, Wei-Cheng Kong, Huan-Yu Liu, Athanasios V. Vasilakos, Yang Yang, Yu-Chun Wu, Ji Guan, Peng Duan, Guo-Ping Guo",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.16714"" target=""_blank"">2505.16714</a>",,2025-12-03 22:39:25
Secure and Private Federated Learning: Achieving Adversarial Resilience through Robust Aggregation,"Kun Yang, Neena Imam",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17226"" target=""_blank"">2505.17226</a>",,2025-12-03 22:39:25
Tropical Attention: Neural Algorithmic Reasoning for Combinatorial Algorithms,"Baran Hashemi, Kurt Pasque, Chris Teska, Ruriko Yoshida",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17190"" target=""_blank"">2505.17190</a>",,2025-12-03 22:39:25
BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization,"Xueyang Zhou, Guiyao Tie, Guowen Zhang, Hechang Wang, Pan Zhou, Lichao Sun",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.16640"" target=""_blank"">2505.16640</a>","<a href=""https://badvla-project.github.io/"" target=""_blank"">badvla-project.github.io</a>",2025-12-03 22:39:25
MixAT: Combining Continuous and Discrete Adversarial Training for LLMs,"Csaba Dékány, Stefan Balauca, Robin Staab, Dimitar I. Dimitrov, Martin Vechev",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.16947"" target=""_blank"">2505.16947</a>","<a href=""https://github.com/insait-institute/MixAT"" target=""_blank"">insait-institute</a>",2025-12-03 22:39:25
Chain-of-Thought Poisoning Attacks against R1-based Retrieval-Augmented Generation Systems,"Hongru Song, Yu-an Liu, Ruqing Zhang, Jiafeng Guo, Yixing Fan",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.16367"" target=""_blank"">2505.16367</a>",,2025-12-03 22:39:25
VEAttack: Downstream-agnostic Vision Encoder Attack against Large Vision Language Models,"Hefei Mei, Zirui Wang, Shen You, Minjing Dong, Chang Xu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17440"" target=""_blank"">2505.17440</a>","<a href=""https://github.com/hfmei/VEAttack-LVLM"" target=""_blank"">hfmei</a>",2025-12-03 22:39:25
Accelerating Targeted Hard-Label Adversarial Attacks in Low-Query Black-Box Settings,"Arjhun Swaminathan, Mete Akgün",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.16313"" target=""_blank"">2505.16313</a>",,2025-12-03 22:39:25
CAMME: Adaptive Deepfake Image Detection with Multi-Modal Cross-Attention,"Naseem Khan, Tuan Nguyen, Amine Bermak, Issa Khalil",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18035"" target=""_blank"">2505.18035</a>",,2025-12-03 22:39:25
SuperPure: Efficient Purification of Localized and Distributed Adversarial Patches via Super-Resolution GAN Models,"Hossein Khalili, Seongbin Park, Venkat Bollapragada, Nader Sehatbakhsh",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.16318"" target=""_blank"">2505.16318</a>",,2025-12-03 22:39:25
Architectural Backdoors for Within-Batch Data Stealing and Model Inference Manipulation,"Nicolas Küchler, Ivan Petrov, Conrad Grobler, Ilia Shumailov",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18323"" target=""_blank"">2505.18323</a>",,2025-12-03 22:39:25
Sec5GLoc: Securing 5G Indoor Localization via Adversary-Resilient Deep Learning Architecture,"Ildi Alla, Valeria Loscri",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17776"" target=""_blank"">2505.17776</a>","<a href=""https://github.com/sec5gloc/Sec5GLoc"" target=""_blank"">sec5gloc</a>",2025-12-03 22:39:25
JALMBench: Benchmarking Jailbreak Vulnerabilities in Audio Language Models,"Zifan Peng, Yule Liu, Zhen Sun, Mingchen Li, Zeren Luo, Jingyi Zheng, Wenhan Dong, Xinlei He, Xuechao Wang, Yingjie Xue, Shengmin Xu, Xinyi Huang",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17568"" target=""_blank"">2505.17568</a>",,2025-12-03 22:39:25
SemSegBench & DetecBench: Benchmarking Reliability and Generalization Beyond Classification,"Shashank Agnihotri, David Schader, Jonas Jakubassa, Nico Sharei, Simon Kral, Mehmet Ege Kaçar, Ruben Weber, Margret Keuper",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.18015"" target=""_blank"">2505.18015</a>",,2025-12-03 22:39:25
Understanding Pre-training and Fine-tuning from Loss Landscape Perspectives,"Huanran Chen, Yinpeng Dong, Zeming Wei, Yao Huang, Yichi Zhang, Hang Su, Jun Zhu",arXiv,2025-05,"<a href=""http://arxiv.org/abs/2505.17646"" target=""_blank"">2505.17646</a>",,2025-12-03 22:39:25
Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge,"Riccardo Cantini, Alessio Orsino, Massimo Ruggiero, Domenico Talia",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.07887"" target=""_blank"">2504.07887</a>",,2025-12-03 22:39:25
Defense against Prompt Injection Attacks via Mixture of Encodings,"Ruiyi Zhang, David Sullivan, Kyle Jackson, Pengtao Xie, Mei Chen",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.07467"" target=""_blank"">2504.07467</a>",,2025-12-03 22:39:25
X-Guard: Multilingual Guard Agent for Content Moderation,"Bibek Upadhayay, Vahid Behzadan, Ph. D",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.08848"" target=""_blank"">2504.08848</a>",,2025-12-03 22:39:25
AttentionDefense: Leveraging System Prompt Attention for Explainable Defense Against Novel Jailbreaks,"Charlotte Siska, Anush Sankaran",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.12321"" target=""_blank"">2504.12321</a>",,2025-12-03 22:39:25
Robust Steganography from Large Language Models,"Neil Perry, Sanket Gupte, Nishant Pitta, Lior Rotem",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.08977"" target=""_blank"">2504.08977</a>",,2025-12-03 22:39:25
EO-VLM: VLM-Guided Energy Overload Attacks on Vision Models,"Minjae Seo, Myoungsung You, Junhee Lee, Jaehan Kim, Hwanjo Heo, Jintae Oh, Jinwoo Kim",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.08205"" target=""_blank"">2504.08205</a>",,2025-12-03 22:39:25
Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning,"Li An, Yujian Liu, Yepeng Liu, Yang Zhang, Yuheng Bu, Shiyu Chang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.06575"" target=""_blank"">2504.06575</a>","<a href=""https://github.com/UCSB-NLP-Chang/contrastive-watermark"" target=""_blank"">UCSB-NLP-Chang</a>",2025-12-03 22:39:25
PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization,"Yang Jiao, Xiaodong Wang, Kai Yang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.07717"" target=""_blank"">2504.07717</a>",,2025-12-03 22:39:25
Deceptive Automated Interpretability: Language Models Coordinating to Fool Oversight Systems,"Simon Lermen, Mateusz Dziemian, Natalia Pérez-Campanero Antolín",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.07831"" target=""_blank"">2504.07831</a>",,2025-12-03 22:39:25
Achilles Heel of Distributed Multi-Agent Systems,"Yiting Zhang, Yijiang Li, Tianwei Zhao, Kaijie Zhu, Haohan Wang, Nuno Vasconcelos",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.07461"" target=""_blank"">2504.07461</a>",,2025-12-03 22:39:25
SafeMLRM: Demystifying Safety in Multi-modal Large Reasoning Models,"Junfeng Fang, Yukai Wang, Ruipeng Wang, Zijun Yao, Kun Wang, An Zhang, Xiang Wang, Tat-Seng Chua",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.08813"" target=""_blank"">2504.08813</a>",,2025-12-03 22:39:25
Secure Diagnostics: Adversarial Robustness Meets Clinical Interpretability,"Mohammad Hossein Najafi, Mohammad Morsali, Mohammadreza Pashanejad, Saman Soleimani Roudi, Mohammad Norouzi, Saeed Bagheri Shouraki",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.05483"" target=""_blank"">2504.05483</a>",,2025-12-03 22:39:25
Mind the Trojan Horse: Image Prompt Adapter Enabling Scalable and Deceptive Jailbreaking,"Junxi Chen, Junhao Dong, Xiaohua Xie",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.05838"" target=""_blank"">2504.05838</a>","<a href=""https://github.com/fhdnskfbeuv/attackIPA"" target=""_blank"">fhdnskfbeuv</a>",2025-12-03 22:39:25
Towards Calibration Enhanced Network by Inverse Adversarial Attack,"Yupeng Cheng, Zi Pong Lim, Sarthak Ketanbhai Modi, Yon Shin Teo, Yushi Cao, Shang-Wei Lin",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.06358"" target=""_blank"">2504.06358</a>",,2025-12-03 22:39:25
Adversarial Training of Reward Models,"Alexander Bukharin, Haifeng Qian, Shengyang Sun, Adithya Renduchintala, Soumye Singhal, Zhilin Wang, Oleksii Kuchaiev, Olivier Delalleau, Tuo Zhao",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.06141"" target=""_blank"">2504.06141</a>",,2025-12-03 22:39:25
Exploring Gradient-Guided Masked Language Model to Detect Textual Adversarial Attacks,"Xiaomei Zhang, Zhaoxi Zhang, Yanjun Zhang, Xufei Zheng, Leo Yu Zhang, Shengshan Hu, Shirui Pan",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.08798"" target=""_blank"">2504.08798</a>",,2025-12-03 22:39:25
StealthRank: LLM Ranking Manipulation via Stealthy Prompt Optimization,"Yiming Tang, Yi Fan, Chenxiao Yu, Tiankai Yang, Yue Zhao, Xiyang Hu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.05804"" target=""_blank"">2504.05804</a>","<a href=""https://github.com/Tangyiming205069/controllable-seo"" target=""_blank"">Tangyiming205069</a>",2025-12-03 22:39:25
Exploiting Meta-Learning-based Poisoning Attacks for Graph Link Prediction,"Mingchen Li, Di Zhuang, Keyu Chen, Dumindu Samaraweera, Morris Chang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.06492"" target=""_blank"">2504.06492</a>",,2025-12-03 22:39:25
Parasite: A Steganography-based Backdoor Attack Framework for Diffusion Models,"Jiahao Chen, Yu Pan, Yi Du, Chunkai Wu, Lin Wang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.05815"" target=""_blank"">2504.05815</a>",,2025-12-03 22:39:25
Defending Deep Neural Networks against Backdoor Attacks via Module Switching,"Weijun Li, Ansh Arora, Xuanli He, Mark Dras, Qiongkai Xu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.05902"" target=""_blank"">2504.05902</a>",,2025-12-03 22:39:25
Security Risks in Vision-Based Beam Prediction: From Spatial Proxy Attacks to Feature Refinement,"Avi Deb Raha, Kitae Kim, Mrityunjoy Gain, Apurba Adhikary, Zhu Han, Eui-Nam Huh, Choong Seon Hong",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.05222"" target=""_blank"">2504.05222</a>",,2025-12-03 22:39:25
"Don't Lag, RAG: Training-Free Adversarial Detection Using RAG","Roie Kazoom, Raz Lapid, Moshe Sipper, Ofer Hadar",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.04858"" target=""_blank"">2504.04858</a>",,2025-12-03 22:39:25
A Knowledge-guided Adversarial Defense for Resisting Malicious Visual Manipulation,"Dawei Zhou, Suzhi Gang, Decheng Liu, Tongliang Liu, Nannan Wang, Xinbo Gao",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.08411"" target=""_blank"">2504.08411</a>",,2025-12-03 22:39:25
Two is Better than One: Efficient Ensemble Defense for Robust and Compact Models,"Yoojin Jung, Byung Cheol Song",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.04747"" target=""_blank"">2504.04747</a>",,2025-12-03 22:39:25
Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking,"Yu-Hang Wu, Yu-Jie Xiong, Jie-Zhang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.05652"" target=""_blank"">2504.05652</a>",,2025-12-03 22:39:25
Multi-Robot Coordination with Adversarial Perception,"Rayan Bahrami, Hamidreza Jafarnejadsani",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.09047"" target=""_blank"">2504.09047</a>",,2025-12-03 22:39:25
CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent,"Liang-bo Ning, Shijie Wang, Wenqi Fan, Qing Li, Xin Xu, Hao Chen, Feiran Huang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.13192"" target=""_blank"">2504.13192</a>",,2025-12-03 22:39:25
On Transfer-based Universal Attacks in Pure Black-box Setting,"Mohammad A. A. K. Jalwana, Naveed Akhtar, Ajmal Mian, Nazanin Rahnavard, Mubarak Shah",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.08866"" target=""_blank"">2504.08866</a>",,2025-12-03 22:39:25
Robust SAM: On the Adversarial Robustness of Vision Foundation Models,"Jiahuan Long, Zhengqin Xu, Tingsong Jiang, Wen Yao, Shuai Jia, Chao Ma, Xiaoqian Chen",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.08906"" target=""_blank"">2504.08906</a>",,2025-12-03 22:39:25
The Sword of Damocles in ViTs: Computational Redundancy Amplifies Adversarial Transferability,"Jiani Liu, Zhiyuan Wang, Zeliang Zhang, Chao Huang, Susan Liang, Yunlong Tang, Chenliang Xu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.10804"" target=""_blank"">2504.10804</a>",,2025-12-03 22:39:25
Select Me! When You Need a Tool: A Black-box Text Attack on Tool Selection,"Liuji Chen, Hao Gao, Jinghao Zhang, Qiang Liu, Shu Wu, Liang Wang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.04809"" target=""_blank"">2504.04809</a>",,2025-12-03 22:39:25
Investigating cybersecurity incidents using large language models in latest-generation wireless networks,"Leonid Legashev, Arthur Zhigalov",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.13196"" target=""_blank"">2504.13196</a>",,2025-12-03 22:39:25
Quantifying Privacy Leakage in Split Inference via Fisher-Approximated Shannon Information Analysis,"Ruijun Deng, Zhihui Lu, Qiang Duan",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.10016"" target=""_blank"">2504.10016</a>",,2025-12-03 22:39:25
Towards Spatially-Aware and Optimally Faithful Concept-Based Explanations,"Shubham Kumar, Dwip Dalal, Narendra Ahuja",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.10833"" target=""_blank"">2504.10833</a>",,2025-12-03 22:39:25
Concept Enhancement Engineering: A Lightweight and Efficient Robust Defense Against Jailbreak Attacks in Embodied AI,"Jirui Yang, Zheyu Lin, Shuhan Yang, Zhihui Lu, Xin Du",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.13201"" target=""_blank"">2504.13201</a>",,2025-12-03 22:39:25
Shield Bash: Abusing Defensive Coherence State Retrieval to Break Timing Obfuscation,"Kartik Ramkrishnan, Antonia Zhai, Stephen McCamant, Pen Chung Yew",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.10318"" target=""_blank"">2504.10318</a>",,2025-12-03 22:39:25
Deep Audio Watermarks are Shallow: Limitations of Post-Hoc Watermarking Techniques for Speech,"Patrick O'Reilly, Zeyu Jin, Jiaqi Su, Bryan Pardo",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.10782"" target=""_blank"">2504.10782</a>",,2025-12-03 22:39:25
Ctrl-Z: Controlling AI Agents via Resampling,"Aryan Bhatt, Cody Rushing, Adam Kaufman, Tyler Tracy, Vasil Georgiev, David Matolcsi, Akbir Khan, Buck Shlegeris",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.10374"" target=""_blank"">2504.10374</a>",,2025-12-03 22:39:25
Beyond Worst-Case Online Classification: VC-Based Regret Bounds for Relaxed Benchmarks,"Omar Montasser, Abhishek Shetty, Nikita Zhivotovskiy",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.10598"" target=""_blank"">2504.10598</a>",,2025-12-03 22:39:25
SafeSpeech: Robust and Universal Voice Protection Against Malicious Speech Synthesis,"Zhisheng Zhang, Derui Wang, Qianyi Yang, Pengyang Huang, Junhan Pu, Yuxin Cao, Kai Ye, Jie Hao, Yixian Yang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.09839"" target=""_blank"">2504.09839</a>","<a href=""https://github.com/wxzyd123/SafeSpeech"" target=""_blank"">wxzyd123</a>",2025-12-03 22:39:25
RANSAC Revisited: An Improved Algorithm for Robust Subspace Recovery under Adversarial and Noisy Corruptions,"Guixian Chen, Jianhao Ma, Salar Fattahi",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.09648"" target=""_blank"">2504.09648</a>",,2025-12-03 22:39:25
ControlNET: A Firewall for RAG-based LLM System,"Hongwei Yao, Haoran Shi, Yidou Chen, Yixin Jiang, Cong Wang, Zhan Qin",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.09593"" target=""_blank"">2504.09593</a>",,2025-12-03 22:39:25
An Investigation of Large Language Models and Their Vulnerabilities in Spam Detection,"Qiyao Tang, Xiangyang Li",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.09776"" target=""_blank"">2504.09776</a>",,2025-12-03 22:39:25
AdaSteer: Your Aligned LLM is Inherently an Adaptive Jailbreak Defender,"Weixiang Zhao, Jiahe Guo, Yulin Hu, Yang Deng, An Zhang, Xingyu Sui, Xinyang Han, Yanyan Zhao, Bing Qin, Tat-Seng Chua, Ting Liu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.09466"" target=""_blank"">2504.09466</a>",,2025-12-03 22:39:25
FractalForensics: Proactive Deepfake Detection and Localization via Fractal Watermarks,"Tianyi Wang, Harry Cheng, Ming-Hui Liu, Mohan Kankanhalli",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.09451"" target=""_blank"">2504.09451</a>",,2025-12-03 22:39:25
The Structural Safety Generalization Problem,"Julius Broomfield, Tom Gibbs, Ethan Kosak-Hine, George Ingebretsen, Tia Nasir, Jason Zhang, Reihaneh Iranmanesh, Sara Pieri, Reihaneh Rabbany, Kellin Pelrine",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.09712"" target=""_blank"">2504.09712</a>",,2025-12-03 22:39:25
PapMOT: Exploring Adversarial Patch Attack against Multiple Object Tracking,"Jiahuan Long, Tingsong Jiang, Wen Yao, Shuai Jia, Weijia Zhang, Weien Zhou, Chao Ma, Xiaoqian Chen",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.09361"" target=""_blank"">2504.09361</a>",,2025-12-03 22:39:25
From Visual Explanations to Counterfactual Explanations with Latent Diffusion,"Tung Luu, Nam Le, Duc Le, Bac Le",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.09202"" target=""_blank"">2504.09202</a>",,2025-12-03 22:39:25
Bregman Linearized Augmented Lagrangian Method for Nonconvex Constrained Stochastic Zeroth-order Optimization,"Qiankun Shi, Xiao Wang, Hao Wang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.09409"" target=""_blank"">2504.09409</a>",,2025-12-03 22:39:25
"Towards More Efficient, Robust, Instance-adaptive, and Generalizable Sequential Decision making",Zhiyong Wang,arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.09192"" target=""_blank"">2504.09192</a>",,2025-12-03 22:39:25
Adversarial Examples in Environment Perception for Automated Driving (Review),"Jun Yan, Huilin Yin",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.08414"" target=""_blank"">2504.08414</a>",,2025-12-03 22:39:25
Toward Realistic Adversarial Attacks in IDS: A Novel Feasibility Metric for Transferability,"Sabrine Ennaji, Elhadj Benkhelifa, Luigi Vincenzo Mancini",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.08480"" target=""_blank"">2504.08480</a>",,2025-12-03 22:39:25
SINCon: Mitigate LLM-Generated Malicious Message Injection Attack for Rumor Detection,"Mingqing Zhang, Qiang Liu, Xiang Tao, Shu Wu, Liang Wang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.07135"" target=""_blank"">2504.07135</a>",,2025-12-03 22:39:25
Secure Generalization through Stochastic Bidirectional Parameter Updates Using Dual-Gradient Mechanism,"Shourya Goel, Himanshi Tibrewal, Anant Jain, Anshul Pundhir, Pravendra Singh",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.02213"" target=""_blank"">2504.02213</a>",,2025-12-03 22:39:25
P2Mark: Plug-and-play Parameter-intrinsic Watermarking for Neural Speech Generation,"Yong Ren, Jiangyan Yi, Tao Wang, Jianhua Tao, Zhengqi Wen, Chenxing Li, Zheng Lian, Ruibo Fu, Ye Bai, Xiaohui Zhang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.05197"" target=""_blank"">2504.05197</a>",,2025-12-03 22:39:25
Alleviating Performance Disparity in Adversarial Spatiotemporal Graph Learning Under Zero-Inflated Distribution,"Songran Bai, Yuheng Ji, Yue Liu, Xingwei Zhang, Xiaolong Zheng, Daniel Dajun Zeng",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.00721"" target=""_blank"">2504.00721</a>",,2025-12-03 22:39:25
"Multifaceted Evaluation of Audio-Visual Capability for MLLMs: Effectiveness, Efficiency, Generalizability and Robustness","Yusheng Zhao, Junyu Luo, Xiao Luo, Weizhi Zhang, Zhiping Xiao, Wei Ju, Philip S. Yu, Ming Zhang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.16936"" target=""_blank"">2504.16936</a>",,2025-12-03 22:39:25
Representation Bending for Large Language Model Safety,"Ashkan Yousefpour, Taeheon Kim, Ryan S. Kwon, Seungbeen Lee, Wonje Jeung, Seungju Han, Alvin Wan, Harrison Ngan, Youngjae Yu, Jonghyun Choi",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.01550"" target=""_blank"">2504.01550</a>",,2025-12-03 22:39:25
LightDefense: A Lightweight Uncertainty-Driven Defense against Jailbreaks via Shifted Token Distribution,"Zhuoran Yang, Jie Peng, Zhen Tan, Tianlong Chen, Yanyong Zhang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.01533"" target=""_blank"">2504.01533</a>",,2025-12-03 22:39:25
Evolving Security in LLMs: A Study of Jailbreak Attacks and Defenses,"Zhengchun Shang, Wenlan Wei",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.02080"" target=""_blank"">2504.02080</a>",,2025-12-03 22:39:25
Like Oil and Water: Group Robustness Methods and Poisoning Defenses May Be at Odds,"Michael-Andrei Panaitescu-Liess, Yigitcan Kaya, Sicheng Zhu, Furong Huang, Tudor Dumitras",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.02142"" target=""_blank"">2504.02142</a>",,2025-12-03 22:39:25
MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits,"Brandon Radosevich, John Halloran",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.03767"" target=""_blank"">2504.03767</a>","<a href=""https://github.com/leidosinc/McpSafetyScanner"" target=""_blank"">leidosinc</a>",2025-12-03 22:39:25
PiCo: Jailbreaking Multimodal Large Language Models via $\textbf{Pi}$ctorial $\textbf{Co}$de Contextualization,"Aofan Liu, Lulu Tang, Ting Pan, Yuguo Yin, Bin Wang, Ao Yang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.01444"" target=""_blank"">2504.01444</a>",,2025-12-03 22:39:25
Unleashing the Power of Pre-trained Encoders for Universal Adversarial Attack Detection,"Yinghe Zhang, Chi Liu, Shuai Zhou, Sheng Shen, Peng Gui",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.00429"" target=""_blank"">2504.00429</a>",,2025-12-03 22:39:25
Whispering Under the Eaves: Protecting User Privacy Against Commercial and LLM-powered Automatic Speech Recognition Systems,"Weifei Jin, Yuxin Cao, Junjie Su, Derui Wang, Yedi Zhang, Minhui Xue, Jie Hao, Jin Song Dong, Yixian Yang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.00858"" target=""_blank"">2504.00858</a>",,2025-12-03 22:39:25
TenAd: A Tensor-based Low-rank Black Box Adversarial Attack for Video Classification,"Kimia haghjooei, Mansoor Rezghi",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.01228"" target=""_blank"">2504.01228</a>",,2025-12-03 22:39:25
Safeguarding Vision-Language Models: Mitigating Vulnerabilities to Gaussian Noise in Perturbation-based Attacks,"Jiawei Wang, Yushen Zuo, Yuanjun Chai, Zhendong Liu, Yicheng Fu, Yichun Feng, Kin-Man Lam",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.01308"" target=""_blank"">2504.01308</a>","<a href=""https://github.com/JarvisUSTC/DiffPure-RobustVLM"" target=""_blank"">JarvisUSTC</a>",2025-12-03 22:39:25
Impact of Data Duplication on Deep Neural Network-Based Image Classifiers: Robust vs,"Alireza Aghabagherloo, Aydin Abadi, Sumanta Sarkar, Vishnu Asutosh Dasu, Bart Preneel",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.00638"" target=""_blank"">2504.00638</a>",,2025-12-03 22:39:25
Robust Unsupervised Domain Adaptation for 3D Point Cloud Segmentation Under Source Adversarial Attacks,"Haosheng Li, Yuecong Xu, Junjie Chen, Kemi Ding",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.01659"" target=""_blank"">2504.01659</a>",,2025-12-03 22:39:25
Multilingual and Multi-Accent Jailbreaking of Audio LLMs,"Jaechul Roh, Virat Shejwalkar, Amir Houmansadr",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.01094"" target=""_blank"">2504.01094</a>",,2025-12-03 22:39:25
Safety and Security Risk Mitigation in Satellite Missions via Attack-Fault-Defense Trees,"Reza Soltani, Pablo Diale, Milan Lopuhaä-Zwakenberg, Mariëlle Stoelinga",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.00988"" target=""_blank"">2504.00988</a>",,2025-12-03 22:39:25
FA^{3}-CLIP: Frequency-Aware Cues Fusion and Attack-Agnostic Prompt Learning for Unified Face Attack Detection,"Yongze Li, Ning Li, Ajian Liu, Hui Ma, Liying Yang, Xihong Chen, Zhiyao Liang, Yanyan Liang, Jun Wan, Zhen Lei",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.00454"" target=""_blank"">2504.00454</a>",,2025-12-03 22:39:25
Exposing the Ghost in the Transformer: Abnormal Detection for Large Language Models via Hidden State Forensics,"Shide Zhou, Kailong Wang, Ling Shi, Haoyu Wang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.00446"" target=""_blank"">2504.00446</a>",,2025-12-03 22:39:25
"Strategize Globally, Adapt Locally: A Multi-Turn Red Teaming Agent with Dual-Level Learning","Si Chen, Xiao Yu, Ninareh Mehrabi, Rahul Gupta, Zhou Yu, Ruoxi Jia",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.01278"" target=""_blank"">2504.01278</a>",,2025-12-03 22:39:25
$\textit{Agents Under Siege}$: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks,"Rana Muhammad Shahroz Khan, Zhen Tan, Sukwon Yun, Charles Flemming, Tianlong Chen",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.00218"" target=""_blank"">2504.00218</a>",,2025-12-03 22:39:25
AI-Enhanced Resilience in Power Systems: Adversarial Deep Learning for Robust Short-Term Voltage Stability Assessment under Cyber-Attacks,"Yang Li, Shitu Zhang, Yuanzheng Li",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.02859"" target=""_blank"">2504.02859</a>",,2025-12-03 22:39:25
"Misaligned Roles, Misplaced Images: Structural Input Perturbations Expose Multimodal Alignment Blind Spots","Erfan Shayegani, G M Shahariar, Sara Abdali, Lei Yu, Nael Abu-Ghazaleh, Yue Dong",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.03735"" target=""_blank"">2504.03735</a>",,2025-12-03 22:39:25
Revisiting the Relationship between Adversarial and Clean Training: Why Clean Training Can Make Adversarial Training Better,"MingWei Zhou, Xiaobing Pei",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.00038"" target=""_blank"">2504.00038</a>",,2025-12-03 22:39:25
Breach in the Shield: Unveiling the Vulnerabilities of Large Language Models,"Runpeng Dai, Run Yang, Fan Zhou, Hongtu Zhu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.03714"" target=""_blank"">2504.03714</a>",,2025-12-03 22:39:25
The Obvious Invisible Threat: LLM-Powered GUI Agents' Vulnerability to Fine-Print Injections,"Chaoran Chen, Zhiping Zhang, Bingcan Guo, Shang Ma, Ibrahim Khalilov, Simret A Gebreegziabher, Yanfang Ye, Ziang Xiao, Yaxing Yao, Tianshi Li, Toby Jia-Jun Li",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.11281"" target=""_blank"">2504.11281</a>",,2025-12-03 22:39:25
Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in Vision-Language Models,"Zhaochen Wang, Bryan Hooi, Yiwei Wang, Ming-Hsuan Yang, Zi Huang, Yujun Cai",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.01589"" target=""_blank"">2504.01589</a>",,2025-12-03 22:39:25
One Pic is All it Takes: Poisoning Visual Document Retrieval Augmented Generation with a Single Image,"Ezzeldin Shereen, Dan Ristea, Burak Hasircioglu, Shae McFadden, Vasilios Mavroudis, Chris Hicks",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.02132"" target=""_blank"">2504.02132</a>",,2025-12-03 22:39:25
Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language Models,"Jiawei Lian, Jianhong Pan, Lefan Wang, Yi Wang, Shaohui Mei, Lap-Pui Chau",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.05050"" target=""_blank"">2504.05050</a>",,2025-12-03 22:39:25
Nemotron-H: A Family of Accurate and Efficient Hybrid Mamba-Transformer Models,"NVIDIA, :, Aaron Blakeman, Aarti Basant, Abhinav Khattar, Adithya Renduchintala, Akhiad Bercovich, Aleksander Ficek, Alexis Bjorlin, Ali Taghibakhshi, Amala Sanjay Deshmukh, Ameya Sunil Mahabaleshwarkar, Andrew Tao, Anna Shors, Ashwath Aithal, Ashwin Poojary, Ayush Dattagupta, Balaram Buddharaju, Bobby Chen, Boris Ginsburg, Boxin Wang, Brandon Norick, Brian Butterfield, Bryan Catanzaro, Mundo Carlo del, Chengyu Dong, Christine Harvey, Christopher Parisien, Dan Su, Daniel Korzekwa, Danny Yin, Daria Gitman, David Mosallanezhad, Deepak Narayanan, Denys Fridman, Dima Rekesh, Ding Ma, Dmytro Pykhtar, Dong Ahn, Duncan Riach, Dusan Stosic, Eileen Long, Elad Segal, Ellie Evans, Eric Chung, Erick Galinkin, Evelina Bakhturina, Ewa Dobrowolska, Fei Jia, Fuxiao Liu, Gargi Prasad, Gerald Shen, Guilin Liu, Guo Chen, Haifeng Qian, Helen Ngo, Hongbin Liu, Hui Li, Igor Gitman, Ilia Karmanov, Ivan Moshkov, Izik Golan, Jan Kautz, Jane Polak Scowcroft, Jared Casper, Jarno Seppanen, Jason Lu, Jason Sewall, Jiaqi Zeng, Jiaxuan You, Jimmy Zhang, Jing Zhang, Jining Huang, Jinze Xue, Jocelyn Huang, Joey Conway, John Kamalu, Jon Barker, Jonathan Cohen, Joseph Jennings, Jupinder Parmar, Karan Sapra, Kari Briski, Kateryna Chumachenko, Katherine Luna, Keshav Santhanam, Kezhi Kong, Kirthi Sivamani, Krzysztof Pawelec, Kumar Anik, Kunlun Li, Lawrence McAfee, Leon Derczynski, Lindsey Pavao, Luis Vega, Lukas Voegtle, Maciej Bala, Melo Maer Rodrigues de, Makesh Narsimhan Sreedhar, Marcin Chochowski, Markus Kliegl, Marta Stepniewska-Dziubinska, Matthieu Le, Matvei Novikov, Mehrzad Samadi, Michael Andersch, Michael Evans, Miguel Martinez, Mike Chrzanowski, Mike Ranzinger, Mikolaj Blaz, Misha Smelyanskiy, Mohamed Fawzy, Mohammad Shoeybi, Mostofa Patwary, Nayeon Lee, Nima Tajbakhsh, Ning Xu, Oleg Rybakov, Oleksii Kuchaiev, Olivier Delalleau, Osvald Nitski, Parth Chadha, Pasha Shamis, Paulius Micikevicius, Pavlo Molchanov, Peter Dykas, Philipp Fischer, Pierre-Yves Aquilanti, Piotr Bialecki, Prasoon Varshney, Pritam Gundecha, Przemek Tredak, Rabeeh Karimi, Rahul Kandu, Ran El-Yaniv, Raviraj Joshi, Roger Waleffe, Ruoxi Zhang, Sabrina Kavanaugh, Sahil Jain, Samuel Kriman, Sangkug Lym, Sanjeev Satheesh, Saurav Muralidharan, Sean Narenthiran, Selvaraj Anandaraj, Seonmyeong Bak, Sergey Kashirsky, Seungju Han, Shantanu Acharya, Shaona Ghosh, Sharath Turuvekere Sreenivas, Sharon Clay, Shelby Thomas, Shrimai Prabhumoye, Shubham Pachori, Shubham Toshniwal, Shyamala Prayaga, Siddhartha Jain, Sirshak Das, Slawek Kierat, Somshubra Majumdar, Song Han, Soumye Singhal, Sriharsha Niverty, Stefania Alborghetti, Suseella Panguluri, Swetha Bhendigeri, Syeda Nahida Akter, Szymon Migacz, Tal Shiri, Terry Kong, Timo Roman, Tomer Ronen, Trisha Saar, Tugrul Konuk, Tuomas Rintamaki, Tyler Poon, Ushnish De, Vahid Noroozi, Varun Singh, Vijay Korthikanti, Vitaly Kurin, Wasi Uddin Ahmad, Wei Du, Wei Ping, Wenliang Dai, Wonmin Byeon, Xiaowei Ren, Yao Xu, Yejin Choi, Yian Zhang, Ying Lin, Yoshi Suhara, Zhiding Yu, Zhiqi Li, Zhiyu Li, Zhongbo Zhu, Zhuolin Yang, Zijia Chen",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.03624"" target=""_blank"">2504.03624</a>",,2025-12-03 22:39:25
SelfMAD: Enhancing Generalization and Robustness in Morphing Attack Detection via Self-Supervised Learning,"Marija Ivanovska, Leon Todorov, Naser Damer, Deepak Kumar Jain, Peter Peer, Vitomir Štruc",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.05504"" target=""_blank"">2504.05504</a>","<a href=""https://github.com/LeonTodorov/SelfMAD"" target=""_blank"">LeonTodorov</a>",2025-12-03 22:39:25
Technical Report: Full Version of Analyzing and Optimizing Perturbation of DP-SGD Geometrically,"Jiawei Duan, Haibo Hu, Qingqing Ye, Xinyue Sun",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.05618"" target=""_blank"">2504.05618</a>",,2025-12-03 22:39:25
Selective Masking Adversarial Attack on Automatic Speech Recognition Systems,"Zheng Fang, Shenyi Zhang, Tao Wang, Bowen Li, Lingchen Zhao, Zhangyi Wang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.04394"" target=""_blank"">2504.04394</a>",,2025-12-03 22:39:25
WeiDetect: Weibull Distribution-Based Defense against Poisoning Attacks in Federated Learning for Network Intrusion Detection Systems,"Sameera K. M., Vinod P., Anderson Rocha, Rafidha Rehiman K. A., Mauro Conti",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.04367"" target=""_blank"">2504.04367</a>",,2025-12-03 22:39:25
On the Robustness of GUI Grounding Models Against Image Attacks,"Haoren Zhao, Tianyi Chen, Zhen Wang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.04716"" target=""_blank"">2504.04716</a>","<a href=""https://github.com/ZZZhr-1/Robust_GUI_Grounding"" target=""_blank"">ZZZhr-1</a>",2025-12-03 22:39:25
Here Comes the Explanation: A Shapley Perspective on Multi-contrast Medical Image Segmentation,"Tianyi Ren, Juampablo Heras Rivera, Hitender Oswal, Yutong Pan, Agamdeep Chopra, Jacob Ruzevick, Mehmet Kurt",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.04645"" target=""_blank"">2504.04645</a>",,2025-12-03 22:39:25
Embedding Hidden Adversarial Capabilities in Pre-Trained Diffusion Models,"Lucas Beerens, Desmond J. Higham",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.08782"" target=""_blank"">2504.08782</a>","<a href=""https://github.com/LucasBeerens/CRAFTed-Diffusion"" target=""_blank"">LucasBeerens</a>",2025-12-03 22:39:25
QE-RAG: A Robust Retrieval-Augmented Generation Benchmark for Query Entry Errors,"Kepu Zhang, Zhongxiang Sun, Weijie Yu, Xiaoxue Zang, Kai Zheng, Yang Song, Han Li, Jun Xu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.04062"" target=""_blank"">2504.04062</a>",,2025-12-03 22:39:25
Impact of Error Rate Misreporting on Resource Allocation in Multi-tenant Quantum Computing and Defense,"Subrata Das, Swaroop Ghosh",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.04285"" target=""_blank"">2504.04285</a>",,2025-12-03 22:39:25
Disparate Privacy Vulnerability: Targeted Attribute Inference Attacks and Defenses,"Ehsanul Kabir, Lucas Craig, Shagufta Mehnaz",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.04033"" target=""_blank"">2504.04033</a>",,2025-12-03 22:39:25
Practical Poisoning Attacks against Retrieval-Augmented Generation,"Baolei Zhang, Yuxi Chen, Minghong Fang, Zhuqing Liu, Lihai Nie, Tong Li, Zheli Liu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.03957"" target=""_blank"">2504.03957</a>",,2025-12-03 22:39:25
PPFPL: Cross-silo Privacy-preserving Federated Prototype Learning Against Data Poisoning Attacks on Non-IID Data,"Hongliang Zhang, Jiguo Yu, Fenghua Xu, Chunqiang Hu, Yongzhao Zhang, Xiaofen Wang, Zhongyuan Yu, Xiaosong Zhang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.03173"" target=""_blank"">2504.03173</a>",,2025-12-03 22:39:25
Overlap-Aware Feature Learning for Robust Unsupervised Domain Adaptation for 3D Semantic Segmentation,"Junjie Chen, Yuecong Xu, Haosheng Li, Kemi Ding",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.01668"" target=""_blank"">2504.01668</a>",,2025-12-03 22:39:25
Moving Target Defense Against Adversarial False Data Injection Attacks In Power Grids,"Yexiang Chen, Subhash Lakshminarayana, H. Vincent Poor",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.03065"" target=""_blank"">2504.03065</a>",,2025-12-03 22:39:25
Evaluating and Enhancing Segmentation Model Robustness with Metamorphic Testing,"Seif Mzoughi, Mohamed Elshafeia, Foutse Khomh",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.02335"" target=""_blank"">2504.02335</a>",,2025-12-03 22:39:25
SLACK: Attacking LiDAR-based SLAM with Adversarial Point Injections,"Prashant Kumar, Dheeraj Vattikonda, Kshitij Madhav Bhat, Kunal Dargan, Prem Kalra",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.03089"" target=""_blank"">2504.03089</a>",,2025-12-03 22:39:25
Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation,"Liangbo Ning, Wenqi Fan, Qing Li",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.02458"" target=""_blank"">2504.02458</a>",,2025-12-03 22:39:25
Bridging the Theoretical Gap in Randomized Smoothing,"Blaise Delattre, Paul Caillon, Quentin Barthélemy, Erwan Fagnou, Alexandre Allauzen",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.02412"" target=""_blank"">2504.02412</a>",,2025-12-03 22:39:25
JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model,"Yi Nian, Shenzhe Zhu, Yuehan Qin, Li Li, Ziyi Wang, Chaowei Xiao, Yue Zhao",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.03770"" target=""_blank"">2504.03770</a>",,2025-12-03 22:39:25
ERPO: Advancing Safety Alignment via Ex-Ante Reasoning Preference Optimization,"Kehua Feng, Keyan Ding, Jing Yu, Menghan Li, Yuhao Wang, Tong Xu, Xinda Wang, Qiang Zhang, Huajun Chen",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.02725"" target=""_blank"">2504.02725</a>",,2025-12-03 22:39:25
AdPO: Enhancing the Adversarial Robustness of Large Vision-Language Models with Preference Optimization,"Chaohu Liu, Tianyi Gui, Yu Liu, Linli Xu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.01735"" target=""_blank"">2504.01735</a>",,2025-12-03 22:39:25
Leveraging Generalizability of Image-to-Image Translation for Enhanced Adversarial Defense,"Haibo Zhang, Zhihua Yao, Kouichi Sakurai, Takeshi Saitoh",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.01399"" target=""_blank"">2504.01399</a>",,2025-12-03 22:39:25
Benchmarking the Spatial Robustness of DNNs via Natural and Adversarial Localized Corruptions,"Giulia Marchiori Pietrosanti, Giulio Rossolini, Alessandro Biondi, Giorgio Buttazzo",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.01632"" target=""_blank"">2504.01632</a>",,2025-12-03 22:39:25
Breaking BERT: Gradient Attack on Twitter Sentiment Analysis for Targeted Misclassification,"Akil Raj Subedi, Taniya Shah, Aswani Kumar Cherukuri, Thanos Vasilakos",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.01345"" target=""_blank"">2504.01345</a>",,2025-12-03 22:39:25
Chypnosis: Stealthy Secret Extraction using Undervolting-based Static Side-channel Attacks,"Kyle Mitard, Saleh Khalaj Monfared, Fatemeh Khojasteh Dana, Shahin Tajik",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.11633"" target=""_blank"">2504.11633</a>",,2025-12-03 22:39:25
DYNAMITE: Dynamic Defense Selection for Enhancing Machine Learning-based Intrusion Detection Against Adversarial Attacks,"Jing Chen, Onat Gungor, Zhengli Shang, Elvin Li, Tajana Rosing",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.13301"" target=""_blank"">2504.13301</a>",,2025-12-03 22:39:25
Token-Level Constraint Boundary Search for Jailbreaking Text-to-Image Models,"Jiangtao Liu, Zhaoxin Wang, Handing Wang, Cong Tian, Yaochu Jin",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.11106"" target=""_blank"">2504.11106</a>",,2025-12-03 22:39:25
Latent Adversarial Training Improves the Representation of Refusal,"Alexandra Abbas, Nora Petrova, Helios Ael Lyons, Natalia Perez-Campanero",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.18872"" target=""_blank"">2504.18872</a>",,2025-12-03 22:39:25
What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift,"Jiamin Chang, Haoyang Li, Hammond Pearce, Ruoxi Sun, Bo Li, Minhui Xue",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21042"" target=""_blank"">2504.21042</a>",,2025-12-03 22:39:25
Adversarial Shallow Watermarking,"Guobiao Li, Lei Tan, Yuliang Xue, Gaozhi Liu, Zhenxing Qian, Sheng Li, Xinpeng Zhang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.19529"" target=""_blank"">2504.19529</a>",,2025-12-03 22:39:25
DeeCLIP: A Robust and Generalizable Transformer-Based Framework for Detecting AI-Generated Images,"Mamadou Keita, Wassim Hamidouche, Hessen Bougueffa Eutamene, Abdelmalik Taleb-Ahmed, Abdenour Hadid",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.19876"" target=""_blank"">2504.19876</a>","<a href=""https://github.com/Mamadou-Keita/DeeCLIP"" target=""_blank"">Mamadou-Keita</a>",2025-12-03 22:39:25
Forging and Removing Latent-Noise Diffusion Watermarks Using a Single Image,"Anubhav Jain, Yuya Kobayashi, Naoki Murata, Yuhta Takida, Takashi Shibuya, Yuki Mitsufuji, Niv Cohen, Nasir Memon, Julian Togelius",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.20111"" target=""_blank"">2504.20111</a>",,2025-12-03 22:39:25
FCGHunter: Towards Evaluating Robustness of Graph-Based Android Malware Detection,"Shiwen Song, Xiaofei Xie, Ruitao Feng, Qi Guo, Sen Chen",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.19456"" target=""_blank"">2504.19456</a>",,2025-12-03 22:39:25
CapsFake: A Multimodal Capsule Network for Detecting Instruction-Guided Deepfakes,"Tuan Nguyen, Naseem Khan, Issa Khalil",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.19212"" target=""_blank"">2504.19212</a>",,2025-12-03 22:39:25
JailbreaksOverTime: Detecting Jailbreak Attacks Under Distribution Shift,"Julien Piet, Xiao Huang, Dennis Jacob, Annabella Chow, Maha Alrashed, Geng Zhao, Zhanhao Hu, Chawin Sitawarin, Basel Alomair, David Wagner",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.19440"" target=""_blank"">2504.19440</a>",,2025-12-03 22:39:25
Doxing via the Lens: Revealing Location-related Privacy Leakage on Multi-modal Large Reasoning Models,"Weidi Luo, Tianyu Lu, Qiming Zhang, Xiaogeng Liu, Bin Hu, Yue Zhao, Jieyu Zhao, Song Gao, Patrick McDaniel, Zhen Xiang, Chaowei Xiao",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.19373"" target=""_blank"">2504.19373</a>",,2025-12-03 22:39:25
Unveiling and Mitigating Adversarial Vulnerabilities in Iterative Optimizers,"Elad Sofer, Tomer Shaked, Caroline Chaux, Nir Shlezinger",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.19000"" target=""_blank"">2504.19000</a>",,2025-12-03 22:39:25
Graph of Attacks: Improved Black-Box and Interpretable Jailbreaks for LLMs,"Mohammad Akbar-Tajari, Mohammad Taher Pilehvar, Mohammad Mahmoody",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.19019"" target=""_blank"">2504.19019</a>","<a href=""https://github.com/GoAT-pydev/Graph_of_Attacks"" target=""_blank"">GoAT-pydev</a>",2025-12-03 22:39:25
Test It Before You Trust It: Applying Software Testing for Trustworthy In-context Learning,"Teeradaj Racharak, Chaiyong Ragkhitwetsagul, Chommakorn Sontesadisai, Thanwadee Sunetnanta",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.18827"" target=""_blank"">2504.18827</a>",,2025-12-03 22:39:25
DiCE-Extended: A Robust Approach to Counterfactual Explanations in Machine Learning,"Volkan Bakir, Polat Goktas, Sureyya Akyuz",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.19027"" target=""_blank"">2504.19027</a>",,2025-12-03 22:39:25
A Case Study on the Use of Representativeness Bias as a Defense Against Adversarial Cyber Threats,"Briland Hitaj, Grit Denker, Laura Tinnel, Michael McAnally, Bruce DeBruhl, Nathan Bunting, Alex Fafard, Daniel Aaron, Richard D. Roberts, Joshua Lawson, Greg McCain, Dylan Starink",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.20245"" target=""_blank"">2504.20245</a>",,2025-12-03 22:39:25
Safety Interventions against Adversarial Patches in an Open-Source Driver Assistance System,"Cheng Chen, Grant Xiao, Daehyun Lee, Lishan Yang, Evgenia Smirni, Homa Alemzadeh, Xugui Zhou",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.18990"" target=""_blank"">2504.18990</a>",,2025-12-03 22:39:25
Edge-Based Learning for Improved Classification Under Adversarial Noise,"Manish Kansana, Keyan Alexander Rahimi, Elias Hossain, Iman Dehzangi, Noorbakhsh Amiri Golilarz",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.20077"" target=""_blank"">2504.20077</a>",,2025-12-03 22:39:25
Intelligent Attacks and Defense Methods in Federated Learning-enabled Energy-Efficient Wireless Networks,"Han Zhang, Hao Zhou, Medhat Elsayed, Majid Bavand, Raimundas Gaigalas, Yigit Ozcan, Melike Erol-Kantarci",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.18519"" target=""_blank"">2504.18519</a>",,2025-12-03 22:39:25
DeSIA: Attribute Inference Attacks Against Limited Fixed Aggregate Statistics,"Yifeng Mao, Bozhidar Stevanoski, Montjoye Yves-Alexandre de",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.18497"" target=""_blank"">2504.18497</a>",,2025-12-03 22:39:25
Unsupervised Corpus Poisoning Attacks in Continuous Space for Dense Retrieval,"Yongkang Li, Panagiotis Eustratiadis, Simon Lupart, Evangelos Kanoulas",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.17884"" target=""_blank"">2504.17884</a>",,2025-12-03 22:39:25
A Simple DropConnect Approach to Transfer-based Targeted Attack,"Tongrui Su, Qingbin Li, Shengyu Zhu, Wei Chen, Xueqi Cheng",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.18594"" target=""_blank"">2504.18594</a>",,2025-12-03 22:39:25
Unveiling Hidden Vulnerabilities in Digital Human Generation via Adversarial Attacks,"Zhiying Li, Yeying Jin, Fan Shen, Zhi Liu, Weibin Chen, Pengju Zhang, Xiaomei Zhang, Boyu Chen, Michael Shen, Kejian Wu, Zhaoxin Fan, Jin Dong",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.17457"" target=""_blank"">2504.17457</a>",,2025-12-03 22:39:25
Evaluating the Vulnerability of ML-Based Ethereum Phishing Detectors to Single-Feature Adversarial Perturbations,"Ahod Alghuried, Ali Alkinoon, Abdulaziz Alghamdi, Soohyeon Choi, Manar Mohaisen, David Mohaisen",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.17684"" target=""_blank"">2504.17684</a>",,2025-12-03 22:39:25
Fine-Tuning Adversarially-Robust Transformers for Single-Image Dehazing,"Vlad Vasilescu, Ana Neacsu, Daniela Faur",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.17829"" target=""_blank"">2504.17829</a>",,2025-12-03 22:39:25
Towards Robust LLMs: an Adversarial Robustness Measurement Framework,"Natan Levy, Adiel Ashrov, Guy Katz",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.17723"" target=""_blank"">2504.17723</a>",,2025-12-03 22:39:25
On the Generalization of Adversarially Trained Quantum Classifiers,"Petros Georgiou, Aaron Mark Thomas, Sharu Theresa Jose, Osvaldo Simeone",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.17690"" target=""_blank"">2504.17690</a>",,2025-12-03 22:39:25
Perception-aware Sampling for Scatterplot Visualizations,"Zafeiria Moumoulidou, Hamza Elhamdadi, Ke Yang, Subrata Mitra, Cindy Xiong Bearfield, Alexandra Meliou",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.20369"" target=""_blank"">2504.20369</a>",,2025-12-03 22:39:25
Prefill-Based Jailbreak: A Novel Approach of Bypassing LLM Safety Boundary,"Yakai Li, Jiekang Hu, Weiduan Sang, Luping Ma, Jing Xie, Weijuan Zhang, Aimin Yu, Shijie Zhao, Qingjia Huang, Qihang Zhou",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21038"" target=""_blank"">2504.21038</a>",,2025-12-03 22:39:25
The Ultimate Cookbook for Invisible Poison: Crafting Subtle Clean-Label Text Backdoors with Style Attributes,"Wencong You, Daniel Lowd",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.17300"" target=""_blank"">2504.17300</a>",,2025-12-03 22:39:25
Quantifying the Noise of Structural Perturbations on Graph Adversarial Attacks,"Junyuan Fang, Han Yang, Haixian Wen, Jiajing Wu, Zibin Zheng, Chi K. Tse",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.20869"" target=""_blank"">2504.20869</a>",,2025-12-03 22:39:25
Cert-SSB: Toward Certified Sample-Specific Backdoor Defense,"Ting Qiao, Yingjia Wang, Xing Liu, Sixing Wu, Jianbing Li, Yiming Li",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21730"" target=""_blank"">2504.21730</a>","<a href=""https://github.com/NcepuQiaoTing/Cert-SSB"" target=""_blank"">NcepuQiaoTing</a>",2025-12-03 22:39:25
How to Enhance Downstream Adversarial Robustness (almost) without Touching the Pre-Trained Foundation Model? (41%),"Meiqi Liu, Zhuoqun Huang, Yue Xing",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.10850"" target=""_blank"">2504.10850</a>",,2025-12-03 22:39:25
The Dual Power of Interpretable Token Embeddings: Jailbreaking Attacks and Defenses for Diffusion Model Unlearning,"Siyi Chen, Yimeng Zhang, Sijia Liu, Qing Qu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21307"" target=""_blank"">2504.21307</a>",,2025-12-03 22:39:25
How to Backdoor the Knowledge Distillation,"Chen Wu, Qian Ma, Prasenjit Mitra, Sencun Zhu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21323"" target=""_blank"">2504.21323</a>",,2025-12-03 22:39:25
Diffusion-based Adversarial Identity Manipulation for Facial Privacy Protection,"Liqin Wang, Qianyue Hu, Wei Lu, Xiangyang Luo",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21646"" target=""_blank"">2504.21646</a>",,2025-12-03 22:39:25
A Test Suite for Efficient Robustness Evaluation of Face Recognition Systems,"Ruihan Zhang, Jun Sun",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21420"" target=""_blank"">2504.21420</a>",,2025-12-03 22:39:25
Hoist with His Own Petard: Inducing Guardrails to Facilitate Denial-of-Service Attacks on Retrieval-Augmented Generation of LLMs,"Pan Suo, Yu-Ming Shang, San-Chuan Guo, Xi Zhang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21680"" target=""_blank"">2504.21680</a>",,2025-12-03 22:39:25
Traceback of Poisoning Attacks to Retrieval-Augmented Generation,"Baolei Zhang, Haoran Xin, Minghong Fang, Zhuqing Liu, Biao Yi, Tong Li, Zheli Liu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21668"" target=""_blank"">2504.21668</a>",,2025-12-03 22:39:25
Mitigating the Structural Bias in Graph Adversarial Defenses,"Junyuan Fang, Huimin Liu, Han Yang, Jiajing Wu, Zibin Zheng, Chi K. Tse",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.20848"" target=""_blank"">2504.20848</a>",,2025-12-03 22:39:25
SFIBA: Spatial-based Full-target Invisible Backdoor Attacks,"Yangxu Yin, Honglong Chen, Yudong Gao, Peng Sun, Zhishuai Li, Weifeng Liu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21052"" target=""_blank"">2504.21052</a>",,2025-12-03 22:39:25
Robustness via Referencing: Defending against Prompt Injection Attacks by Referencing the Executed Instruction,"Yulin Chen, Haoran Li, Yuan Sui, Yue Liu, Yufei He, Yangqiu Song, Bryan Hooi",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.20472"" target=""_blank"">2504.20472</a>",,2025-12-03 22:39:25
AegisLLM: Scaling Agentic Systems for Self-Reflective Defense in LLM Security,"Zikui Cai, Shayan Shabihi, Bang An, Zora Che, Brian R. Bartoldson, Bhavya Kailkhura, Tom Goldstein, Furong Huang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.20965"" target=""_blank"">2504.20965</a>","<a href=""https://github.com/zikuicai/aegisllm"" target=""_blank"">zikuicai</a>",2025-12-03 22:39:25
Prompt Injection Attack to Tool Selection in LLM Agents,"Jiawen Shi, Zenghui Yuan, Guiyao Tie, Pan Zhou, Neil Zhenqiang Gong, Lichao Sun",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.19793"" target=""_blank"">2504.19793</a>",,2025-12-03 22:39:25
Robust Multi-agent Communication Based on Decentralization-Oriented Adversarial Training,"Xuyan Ma, Yawen Wang, Junjie Wang, Xiaofei Xie, Boyu Wu, Shoubin Li, Fanjiang Xu, Qing Wang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21278"" target=""_blank"">2504.21278</a>",,2025-12-03 22:39:25
CachePrune: Neural-Based Attribution Defense Against Indirect Prompt Injection Attacks,"Rui Wang, Junda Wu, Yu Xia, Tong Yu, Ruiyi Zhang, Ryan Rossi, Lina Yao, Julian McAuley",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21228"" target=""_blank"">2504.21228</a>",,2025-12-03 22:39:25
GaussTrap: Stealthy Poisoning Attacks on 3D Gaussian Splatting for Targeted Scene Confusion,"Jiaxin Hong, Sixu Chen, Shuoyang Sun, Hongyao Yu, Hao Fang, Yuqi Tan, Bin Chen, Shuhan Qi, Jiawei Li",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.20829"" target=""_blank"">2504.20829</a>",,2025-12-03 22:39:25
Enhancing Leakage Attacks on Searchable Symmetric Encryption Using LLM-Based Synthetic Data Generation,"Joshua Chiu, Partha Protim Paul, Zahin Wahab",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.20414"" target=""_blank"">2504.20414</a>",,2025-12-03 22:39:25
Erased but Not Forgotten: How Backdoors Compromise Concept Erasure,"Jonas Henry Grebe, Tobias Braun, Marcus Rohrbach, Anna Rohrbach",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21072"" target=""_blank"">2504.21072</a>",,2025-12-03 22:39:25
NeuRel-Attack: Neuron Relearning for Safety Disalignment in Large Language Models,"Yi Zhou, Wenpeng Xing, Dezhang Kong, Changting Lin, Meng Han",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21053"" target=""_blank"">2504.21053</a>",,2025-12-03 22:39:25
Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression,"Yu Cui, Yujun Cai, Yiwei Wang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.20493"" target=""_blank"">2504.20493</a>",,2025-12-03 22:39:25
Evaluate-and-Purify: Fortifying Code Language Models Against Adversarial Attacks Using LLM-as-a-Judge,"Wenhan Mu, Ling Xu, Shuren Pei, Le Mi, Huichi Zhou",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.19730"" target=""_blank"">2504.19730</a>",,2025-12-03 22:39:25
The Dark Side of Digital Twins: Adversarial Attacks on AI-Driven Water Forecasting,"Mohammadhossein Homaei, Victor Gonzalez Morales, Oscar Mogollon-Gutierrez, Andres Caro",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.20295"" target=""_blank"">2504.20295</a>",,2025-12-03 22:39:25
AGATE: Stealthy Black-box Watermarking for Multimodal Model Copyright Protection,"Jianbo Gao, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.21044"" target=""_blank"">2504.21044</a>",,2025-12-03 22:39:25
A Cryptographic Perspective on Mitigation vs,"Greg Gluch, Shafi Goldwasser",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.20310"" target=""_blank"">2504.20310</a>",,2025-12-03 22:39:25
DCT-Shield: A Robust Frequency Domain Defense against Malicious Image Editing,"Aniruddha Bala, Rohit Chowdhury, Rohan Jaiswal, Siddharth Roheda",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.17894"" target=""_blank"">2504.17894</a>",,2025-12-03 22:39:25
Inception: Jailbreak the Memory Mechanism of Text-to-Image Generation Systems,"Shiqian Zhao, Jiayang Liu, Yiming Li, Runyi Hu, Xiaojun Jia, Wenshu Fan, Xinfeng Li, Jie Zhang, Wei Dong, Tianwei Zhang, Luu Anh Tuan",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.20376"" target=""_blank"">2504.20376</a>",,2025-12-03 22:39:25
"Evaluating Time Series Models for Urban Wastewater Management: Predictive Performance, Model Complexity and Resilience","Vipin Singh, Tianheng Ling, Teodor Chiaburu, Felix Biessmann",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.17461"" target=""_blank"">2504.17461</a>",,2025-12-03 22:39:25
NoisyRollout: Reinforcing Visual Reasoning with Data Augmentation,"Xiangyan Liu, Jinjie Ni, Zijian Wu, Chao Du, Longxu Dou, Haonan Wang, Tianyu Pang, Michael Qizhe Shieh",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.13055"" target=""_blank"">2504.13055</a>",,2025-12-03 22:39:25
DETAM: Defending LLMs Against Jailbreak Attacks via Targeted Attention Modification,"Yu Li, Han Jiang, Zhihua Wei",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.13562"" target=""_blank"">2504.13562</a>",,2025-12-03 22:39:25
VideoPASTA: 7K Preference Pairs That Matter for Video-LLM Alignment,"Yogesh Kulkarni, Pooyan Fazli",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.14096"" target=""_blank"">2504.14096</a>",,2025-12-03 22:39:25
BadApex: Backdoor Attack Based on Adaptive Optimization Mechanism of Black-box Large Language Models,"Zhengxian Wu, Juan Wen, Wanli Peng, Ziwei Zhang, Yinghan Zhou, Yiming Xue",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.13775"" target=""_blank"">2504.13775</a>",,2025-12-03 22:39:25
DoomArena: A framework for Testing AI Agents Against Evolving Security Threats,"Leo Boisvert, Mihir Bansal, Chandra Kiran Reddy Evuru, Gabriel Huang, Abhay Puri, Avinandan Bose, Maryam Fazel, Quentin Cappart, Jason Stanley, Alexandre Lacoste, Alexandre Drouin, Krishnamurthy Dvijotham",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.14064"" target=""_blank"">2504.14064</a>","<a href=""https://github.com/ServiceNow/DoomArena"" target=""_blank"">ServiceNow</a>",2025-12-03 22:39:25
Fairness and Robustness in Machine Unlearning,"Khoa Tran, Simon S. Woo",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.13610"" target=""_blank"">2504.13610</a>",,2025-12-03 22:39:25
Everything You Wanted to Know About LLM-based Vulnerability Detection But Were Afraid to Ask,"Yue Li, Xiao Li, Hao Wu, Minghui Xu, Yue Zhang, Xiuzhen Cheng, Fengyuan Xu, Sheng Zhong",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.13474"" target=""_blank"">2504.13474</a>",,2025-12-03 22:39:25
Quantum Computing Supported Adversarial Attack-Resilient Autonomous Vehicle Perception Module for Traffic Sign Classification,"Reek Majumder, Mashrur Chowdhury, Sakib Mahmud Khan, Zadid Khan, Fahim Ahmad, Frank Ngeni, Gurcan Comert, Judith Mwakalonge, Dimitra Michalaka",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.12644"" target=""_blank"">2504.12644</a>",,2025-12-03 22:39:25
A Client-level Assessment of Collaborative Backdoor Poisoning in Non-IID Federated Learning,"Phung Lai, Guanxiong Liu, Hai Phan, Issa Khalil, Abdallah Khreishah, Xintao Wu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.12875"" target=""_blank"">2504.12875</a>",,2025-12-03 22:39:25
ArtistAuditor: Auditing Artist Style Pirate in Text-to-Image Generation Models,"Linkang Du, Zheng Zhu, Min Chen, Zhou Su, Shouling Ji, Peng Cheng, Jiming Chen, Zhikun Zhang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.13061"" target=""_blank"">2504.13061</a>","<a href=""https://github.com/Jozenn/ArtistAuditor"" target=""_blank"">Jozenn</a>",2025-12-03 22:39:25
Privacy Protection Against Personalized Text-to-Image Synthesis via Cross-image Consistency Constraints,"Guanyu Wang, Kailong Wang, Yihao Huang, Mingyi Zhou, Zhang Qing cnwatcher, Geguang Pu, Li Li",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.12747"" target=""_blank"">2504.12747</a>",,2025-12-03 22:39:25
Effective Dual-Region Augmentation for Reduced Reliance on Large Amounts of Labeled Data,"Prasanna Reddy Pulakurthi, Majid Rabbani, Melo Celso M. de, Sohail A. Dianat, Raghuveer M. Rao",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.13077"" target=""_blank"">2504.13077</a>","<a href=""https://github.com/PrasannaPulakurthi/Foreground-Background-Augmentation"" target=""_blank"">PrasannaPulakurthi</a>",2025-12-03 22:39:25
SemDiff: Generating Natural Unrestricted Adversarial Examples via Semantic Attributes Optimization in Diffusion Models,"Zeyu Dai, Shengcai Liu, Rui He, Jiahao Wu, Ning Lu, Wenqi Fan, Qing Li, Ke Tang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.11923"" target=""_blank"">2504.11923</a>",,2025-12-03 22:39:25
Q-FAKER: Query-free Hard Black-box Attack via Controlled Generation,"CheolWon Na, YunSeok Choi, Jee-Hyong Lee",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.13551"" target=""_blank"">2504.13551</a>",,2025-12-03 22:39:25
Human Aligned Compression for Robust Models,"Samuel Räber, Andreas Plesner, Till Aczel, Roger Wattenhofer",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.12255"" target=""_blank"">2504.12255</a>",,2025-12-03 22:39:25
RDI: An adversarial robustness evaluation metric for deep neural networks based on sample clustering features,"Jialei Song, Xingquan Zuo, Feiyang Wang, Hai Huang, Tianle Zhang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.18556"" target=""_blank"">2504.18556</a>",,2025-12-03 22:39:25
Secure Transfer Learning: Training Clean Models Against Backdoor in (Both) Pre-trained Encoders and Downstream Datasets,"Yechao Zhang, Yuxuan Zhou, Tianyu Li, Minghui Li, Shengshan Hu, Wei Luo, Leo Yu Zhang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.11990"" target=""_blank"">2504.11990</a>",,2025-12-03 22:39:25
MDHP-Net: Detecting an Emerging Time-exciting Threat in IVN,"Qi Liu, Yanchen Liu, Ruifeng Li, Chenhong Cao, Yufeng Li, Xingyu Li, Peng Wang, Runhan Feng, Shiyang Bu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.11867"" target=""_blank"">2504.11867</a>",,2025-12-03 22:39:25
Towards Safe Synthetic Image Generation On the Web: A Multimodal Robust NSFW Defense and Million Scale Dataset,"Muhammad Shahid Muneer, Simon S. Woo",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.11707"" target=""_blank"">2504.11707</a>","<a href=""https://github.com/shahidmuneer/multimodal-nsfw-defense"" target=""_blank"">shahidmuneer</a>",2025-12-03 22:39:25
R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning,"Lijun Sheng, Jian Liang, Zilei Wang, Ran He",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.11195"" target=""_blank"">2504.11195</a>","<a href=""https://github.com/TomSheng21/R-TPT"" target=""_blank"">TomSheng21</a>",2025-12-03 22:39:25
Exploring Backdoor Attack and Defense for LLM-empowered Recommendations,"Liangbo Ning, Wenqi Fan, Qing Li",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.11182"" target=""_blank"">2504.11182</a>",,2025-12-03 22:39:25
Defending Against Frequency-Based Attacks with Diffusion Models,"Fatemeh Amerehi, Patrick Healy",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.11034"" target=""_blank"">2504.11034</a>",,2025-12-03 22:39:25
QAVA: Query-Agnostic Visual Attack to Large Vision-Language Models,"Yudong Zhang, Ruobing Xie, Jiansheng Chen, Xingwu Sun, Zhanhui Kang, Yu Wang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.11038"" target=""_blank"">2504.11038</a>","<a href=""https://github.com/btzyd/qava"" target=""_blank"">btzyd</a>",2025-12-03 22:39:25
Cluster-Aware Attacks on Graph Watermarks,"Alexander Nemecek, Emre Yilmaz, Erman Ayday",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.17971"" target=""_blank"">2504.17971</a>",,2025-12-03 22:39:25
RF Sensing Security and Malicious Exploitation: A Comprehensive Survey,"Mingda Han, Huanqi Yang, Wenhao Li, Weitao Xu, Xiuzhen Cheng, Prasant Mohapatra, Pengfei Hu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.10969"" target=""_blank"">2504.10969</a>",,2025-12-03 22:39:25
Rethinking Target Label Conditioning in Adversarial Attacks: A 2D Tensor-Guided Generative Approach,"Hangyu Liu, Bo Peng, Pengxiang Ding, Donglin Wang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.14137"" target=""_blank"">2504.14137</a>",,2025-12-03 22:39:25
RAID: An In-Training Defense against Attribute Inference Attacks in Recommender Systems,"Xiaohua Feng, Yuyuan Li, Fengyuan Yu, Ke Xiong, Junjie Fang, Li Zhang, Tianyu Du, Chaochao Chen",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.11510"" target=""_blank"">2504.11510</a>",,2025-12-03 22:39:25
Manipulating Multimodal Agents via Cross-Modal Prompt Injection,"Le Wang, Zonghao Ying, Tianyuan Zhang, Siyuan Liang, Shengshan Hu, Mingchuan Zhang, Aishan Liu, Xianglong Liu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.14348"" target=""_blank"">2504.14348</a>",,2025-12-03 22:39:25
Exploring the Role of Large Language Models in Cybersecurity: A Systematic Survey,"Shuang Tian, Tao Zhang, Jiqiang Liu, Jiacheng Wang, Xuangou Wu, Xiaoqiang Zhu, Ruichen Zhang, Weiting Zhang, Zhenhui Yuan, Shiwen Mao, Dong In Kim",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.15622"" target=""_blank"">2504.15622</a>",,2025-12-03 22:39:25
FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation,"Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.17311"" target=""_blank"">2504.17311</a>",,2025-12-03 22:39:25
Seeking Flat Minima over Diverse Surrogates for Improved Adversarial Transferability: A Theoretical Framework and Algorithmic Instantiation,"Meixi Zheng, Kehan Wu, Yanbo Fan, Rui Huang, Baoyuan Wu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.16474"" target=""_blank"">2504.16474</a>",,2025-12-03 22:39:25
BadVideo: Stealthy Backdoor Attack against Text-to-Video Generation,"Ruotong Wang, Mingli Zhu, Jiarong Ou, Rui Chen, Xin Tao, Pengfei Wan, Baoyuan Wu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.16907"" target=""_blank"">2504.16907</a>","<a href=""https://wrt2000.github.io/BadVideo2025/"" target=""_blank"">BadVideo2025</a>",2025-12-03 22:39:25
Enhancing Variational Autoencoders with Smooth Robust Latent Encoding,"Hyomin Lee, Minseon Kim, Sangwon Jang, Jongheon Jeong, Sung Ju Hwang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.17219"" target=""_blank"">2504.17219</a>",,2025-12-03 22:39:25
AUTHENTICATION: Identifying Rare Failure Modes in Autonomous Vehicle Perception Systems using Adversarially Guided Diffusion Models,"Mohammad Zarei, Melanie A Jutras, Eliana Evans, Mike Tan, Omid Aaramoon",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.17179"" target=""_blank"">2504.17179</a>",,2025-12-03 22:39:25
Human-Imperceptible Physical Adversarial Attack for NIR Face Recognition Models,"Songyan Xie, Jinghang Wen, Encheng Su, Qiucheng Yu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.15823"" target=""_blank"">2504.15823</a>",,2025-12-03 22:39:25
Property-Preserving Hashing for $\ell_1$-Distance Predicates: Applications to Countering Adversarial Input Attacks,"Hassan Asghar, Chenhan Zhang, Dali Kaafar",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.16355"" target=""_blank"">2504.16355</a>",,2025-12-03 22:39:25
TrojanDam: Detection-Free Backdoor Defense in Federated Learning through Proactive Model Robustification utilizing OOD Data,"Yanbo Dai, Songze Li, Zihan Gan, Xueluan Gong",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.15674"" target=""_blank"">2504.15674</a>",,2025-12-03 22:39:25
WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks,"Ivan Evtimov, Arman Zharmagambetov, Aaron Grattafiori, Chuan Guo, Kamalika Chaudhuri",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.18575"" target=""_blank"">2504.18575</a>",,2025-12-03 22:39:25
"A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment","Kun Wang, Guibin Zhang, Zhenhong Zhou, Jiahao Wu, Miao Yu, Shiqian Zhao, Chenlong Yin, Jinhu Fu, Yibo Yan, Hanjun Luo, Liang Lin, Zhihao Xu, Haolang Lu, Xinye Cao, Xinyun Zhou, Weifei Jin, Fanci Meng, Shicheng Xu, Junyuan Mao, Yu Wang, Hao Wu, Minghe Wang, Fan Zhang, Junfeng Fang, Wenjie Qu, Yue Liu, Chengwei Liu, Yifan Zhang, Qiankun Li, Chongye Guo, Yalan Qin, Zhaoxin Fan, Kai Wang, Yi Ding, Donghai Hong, Jiaming Ji, Yingxin Lai, Zitong Yu, Xinfeng Li, Yifan Jiang, Yanhui Li, Xinyu Deng, Junlin Wu, Dongxia Wang, Yihao Huang, Yufei Guo, Jen-tse Huang, Qiufeng Wang, Xiaolong Jin, Wenxuan Wang, Dongrui Liu, Yanwei Yue, Wenke Huang, Guancheng Wan, Heng Chang, Tianlin Li, Yi Yu, Chenghao Li, Jiawei Li, Lei Bai, Jie Zhang, Qing Guo, Jingyi Wang, Tianlong Chen, Joey Tianyi Zhou, Xiaojun Jia, Weisong Sun, Cong Wu, Jing Chen, Xuming Hu, Yiming Li, Xiao Wang, Ningyu Zhang, Luu Anh Tuan, Guowen Xu, Jiaheng Zhang, Tianwei Zhang, Xingjun Ma, Jindong Gu, Liang Pang, Xiang Wang, Bo An, Jun Sun, Mohit Bansal, Shirui Pan, Lingjuan Lyu, Yuval Elovici, Bhavya Kailkhura, Yaodong Yang, Hongwei Li, Wenyuan Xu, Yizhou Sun, Wei Wang, Qing Li, Ke Tang, Yu-Gang Jiang, Felix Juefei-Xu, Hui Xiong, Xiaofeng Wang, Dacheng Tao, Philip S. Yu, Qingsong Wen, Yang Liu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.15585"" target=""_blank"">2504.15585</a>",,2025-12-03 22:39:25
OPUS-VFL: Incentivizing Optimal Privacy-Utility Tradeoffs in Vertical Federated Learning,"Sindhuja Madabushi, Ahmad Faraz Khan, Haider Ali, Jin-Hee Cho",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.15995"" target=""_blank"">2504.15995</a>",,2025-12-03 22:39:25
BadMoE: Backdooring Mixture-of-Experts LLMs via Optimizing Routing Triggers and Infecting Dormant Experts,"Qingyue Wang, Qi Pang, Xixun Lin, Shuai Wang, Daoyuan Wu",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.18598"" target=""_blank"">2504.18598</a>",,2025-12-03 22:39:25
Unifying Image Counterfactuals and Feature Attributions with Latent-Space Adversarial Attacks,"Jeremy Goldwasser, Giles Hooker",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.15479"" target=""_blank"">2504.15479</a>",,2025-12-03 22:39:25
Trainable Quantum Neural Network for Multiclass Image Classification with the Power of Pre-trained Tree Tensor Networks,"Keisuke Murota, Takumi Kobori",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.14995"" target=""_blank"">2504.14995</a>",,2025-12-03 22:39:25
Fast Adversarial Training with Weak-to-Strong Spatial-Temporal Consistency in the Frequency Domain on Videos,"Songping Wang, Hanqing Liu, Yueming Lyu, Xiantao Hu, Ziwen He, Wei Wang, Caifeng Shan, Liang Wang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.14921"" target=""_blank"">2504.14921</a>",,2025-12-03 22:39:25
Hydra: An Agentic Reasoning Approach for Enhancing Adversarial Robustness and Mitigating Hallucinations in Vision-Language Models,"Johnny Chung-En, Neil Yu, Neil Hsuan-Chih, Chen, Brian Jalaian, Nathaniel D. Bastian",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.14395"" target=""_blank"">2504.14395</a>",,2025-12-03 22:39:25
Verifying Robust Unlearning: Probing Residual Knowledge in Unlearned Models,"Hao Xuan, Xingyu Li",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.14798"" target=""_blank"">2504.14798</a>",,2025-12-03 22:39:25
Towards Model Resistant to Transferable Adversarial Examples via Trigger Activation,"Yi Yu, Song Xia, Xun Lin, Chenqi Kong, Wenhan Yang, Shijian Lu, Yap-Peng Tan, Alex C. Kot",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.14541"" target=""_blank"">2504.14541</a>",,2025-12-03 22:39:25
Adversarial Attack for RGB-Event based Visual Object Tracking,"Qiang Chen, Xiao Wang, Haowen Wang, Bo Jiang, Lin Zhu, Dawei Zhang, Yonghong Tian, Jin Tang",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.14423"" target=""_blank"">2504.14423</a>","<a href=""https://github.com/Event-AHU/Adversarial_Attack_Defense"" target=""_blank"">Event-AHU</a>",2025-12-03 22:39:25
Backdoor Defense in Diffusion Models via Spatial Attention Unlearning,"Abha Jha, Ashwath Vaithinathan Aravindan, Matthew Salaway, Atharva Sandeep Bhide, Duygu Nur Yaldiz",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.18563"" target=""_blank"">2504.18563</a>",,2025-12-03 22:39:25
aiXamine: Simplified LLM Safety and Security,"Fatih Deniz, Dorde Popovic, Yazan Boshmaf, Euisuh Jeong, Minhaj Ahmad, Sanjay Chawla, Issa Khalil",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.14985"" target=""_blank"">2504.14985</a>",,2025-12-03 22:39:25
DualBreach: Efficient Dual-Jailbreaking via Target-Driven Initialization and Multi-Target Optimization,"Xinzhe Huang, Kedong Xiu, Tianhang Zheng, Churui Zeng, Wangze Ni, Zhan Qiin, Kui Ren, Chun Chen",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.18564"" target=""_blank"">2504.18564</a>",,2025-12-03 22:39:25
T2VShield: Model-Agnostic Jailbreak Defense for Text-to-Video Models,"Siyuan Liang, Jiayang Liu, Jiecheng Zhai, Tianmeng Fang, Rongcheng Tu, Aishan Liu, Xiaochun Cao, Dacheng Tao",arXiv,2025-04,"<a href=""http://arxiv.org/abs/2504.15512"" target=""_blank"">2504.15512</a>",,2025-12-03 22:39:25
Generalized Kullback-Leibler Divergence Loss,"Jiequan Cui, Beier Zhu, Qingshan Xu, Zhuotao Tian, Xiaojuan Qi, Bei Yu, Hanwang Zhang, Richang Hong",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.08038"" target=""_blank"">2503.08038</a>","<a href=""https://github.com/jiequancui/DKL"" target=""_blank"">jiequancui</a>",2025-12-03 22:39:25
Utilizing Jailbreak Probability to Attack and Safeguard Multimodal LLMs,"Wenzhuo Xu, Zhipeng Wei, Xiongtao Sun, Deyue Zhang, Dongdong Yang, Quanchen Zou, Xiangzheng Zhang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06989"" target=""_blank"">2503.06989</a>",,2025-12-03 22:39:25
MIGA: Mutual Information-Guided Attack on Denoising Models for Semantic Manipulation,"Guanghao Li, Mingzhi Chen, Hao Yu, Shuting Dong, Wenhao Jiang, Ming Tang, Chun Yuan",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06966"" target=""_blank"">2503.06966</a>",,2025-12-03 22:39:25
Breaking the Limits of Quantization-Aware Defenses: QADT-R for Robustness Against Patch-Based Adversarial Attacks in QNNs,"Amira Guesmi, Bassem Ouni, Muhammad Shafique",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.07058"" target=""_blank"">2503.07058</a>",,2025-12-03 22:39:25
Seal Your Backdoor with Variational Defense,"Ivan Sabolić, Matej Grcić, Siniša Šegvić",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.08829"" target=""_blank"">2503.08829</a>",,2025-12-03 22:39:25
Adv-CPG: A Customized Portrait Generation Framework with Facial Adversarial Attacks,"Junying Wang, Hongyuan Zhang, Yuan Yuan",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.08269"" target=""_blank"">2503.08269</a>",,2025-12-03 22:39:25
ReLATE: Resilient Learner Selection for Multivariate Time-Series Classification Against Adversarial Attacks,"Cagla Ipek Kocal, Onat Gungor, Aaron Tartz, Tajana Rosing, Baris Aksanli",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.07882"" target=""_blank"">2503.07882</a>",,2025-12-03 22:39:25
Not All Edges are Equally Robust: Evaluating the Robustness of Ranking-Based Federated Learning,"Zirui Gong, Yanjun Zhang, Leo Yu Zhang, Zhaoxi Zhang, Yong Xiang, Shirui Pan",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.08976"" target=""_blank"">2503.08976</a>",,2025-12-03 22:39:25
Birds look like cars: Adversarial analysis of intrinsically interpretable deep learning,"Hubert Baniecki, Przemyslaw Biecek",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.08636"" target=""_blank"">2503.08636</a>",,2025-12-03 22:39:25
Enhanced Estimation Techniques for Certified Radii in Randomized Smoothing,Zixuan Liang,arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.08801"" target=""_blank"">2503.08801</a>",,2025-12-03 22:39:25
Dialogue Injection Attack: Jailbreaking LLMs through Context Manipulation,"Wenlong Meng, Fan Zhang, Wendao Yao, Zhenyuan Guo, Yuwei Li, Chengkun Wei, Wenzhi Chen",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.08195"" target=""_blank"">2503.08195</a>",,2025-12-03 22:39:25
Battling Misinformation: An Empirical Study on Adversarial Factuality in Open-Source Large Language Models,"Shahnewaz Karim Sakib, Anindya Bijoy Das, Shibbir Ahmed",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.10690"" target=""_blank"">2503.10690</a>",,2025-12-03 22:39:25
CtrlRAG: Black-box Adversarial Attacks Based on Masked Language Models in Retrieval-Augmented Language Generation,Runqi Sui,arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06950"" target=""_blank"">2503.06950</a>",,2025-12-03 22:39:25
Runtime Detection of Adversarial Attacks in AI Accelerators Using Performance Counters,"Habibur Rahaman, Atri Chatterjee, Swarup Bhunia",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.07568"" target=""_blank"">2503.07568</a>",,2025-12-03 22:39:25
Detecting Backdoor Attacks in Federated Learning via Direction Alignment Inspection,"Jiahao Xu, Zikai Zhang, Rui Hu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.07978"" target=""_blank"">2503.07978</a>","<a href=""https://github.com/JiiahaoXU/AlignIns"" target=""_blank"">JiiahaoXU</a>",2025-12-03 22:39:25
Strengthening the Internal Adversarial Robustness in Lifted Neural Networks,Christopher Zach,arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.07818"" target=""_blank"">2503.07818</a>",,2025-12-03 22:39:25
PoisonedParrot: Subtle Data Poisoning Attacks to Elicit Copyright-Infringing Content from Large Language Models,"Michael-Andrei Panaitescu-Liess, Pankayaraj Pathmanathan, Yigitcan Kaya, Zora Che, Bang An, Sicheng Zhu, Aakriti Agrawal, Furong Huang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.07697"" target=""_blank"">2503.07697</a>",,2025-12-03 22:39:25
FairDeFace: Evaluating the Fairness and Adversarial Robustness of Face Obfuscation Methods,"Seyyed Mohammad Sadegh Moosavi Khorzooghi, Poojitha Thota, Mohit Singhal, Abolfazl Asudeh, Gautam Das, Shirin Nilizadeh",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.08731"" target=""_blank"">2503.08731</a>",,2025-12-03 22:39:25
Learning to Localize Leakage of Cryptographic Sensitive Variables,"Jimmy Gammell, Anand Raghunathan, Abolfazl Hashemi, Kaushik Roy",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.07464"" target=""_blank"">2503.07464</a>",,2025-12-03 22:39:25
MMARD: Improving the Min-Max Optimization Process in Adversarial Robustness Distillation,"Yuzheng Wang, Zhaoyu Chen, Dingkang Yang, Yuanhang Wang, Lizhe Qi",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06559"" target=""_blank"">2503.06559</a>",,2025-12-03 22:39:25
Long-tailed Adversarial Training with Self-Distillation,"Seungju Cho, Hongsin Lee, Changick Kim",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06461"" target=""_blank"">2503.06461</a>",,2025-12-03 22:39:25
Life-Cycle Routing Vulnerabilities of LLM Router,"Qiqi Lin, Xiaoyang Ji, Shengfang Zhai, Qingni Shen, Zhi Zhang, Yuejian Fang, Yansong Gao",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.08704"" target=""_blank"">2503.08704</a>",,2025-12-03 22:39:25
NaviDet: Efficient Input-level Backdoor Detection on Text-to-Image Synthesis via Neuron Activation Variation,"Shengfang Zhai, Jiajun Li, Yue Liu, Huanran Chen, Zhihua Tian, Wenjie Qu, Qingni Shen, Ruoxi Jia, Yinpeng Dong, Jiaheng Zhang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06453"" target=""_blank"">2503.06453</a>",,2025-12-03 22:39:25
Quantitative Analysis of Deeply Quantized Tiny Neural Networks Robust to Adversarial Attacks,"Idris Zakariyya, Ferheen Ayaz, Mounia Kharbouche-Harrari, Jeremy Singer, Sye Loong Keoh, Danilo Pau, José Cano",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.08973"" target=""_blank"">2503.08973</a>",,2025-12-03 22:39:25
Can Small Language Models Reliably Resist Jailbreak Attacks? A Comprehensive Evaluation,"Wenhui Zhang, Huiyu Xu, Zhibo Wang, Zeqing He, Ziqi Zhu, Kui Ren",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06519"" target=""_blank"">2503.06519</a>",,2025-12-03 22:39:25
TH-Bench: Evaluating Evading Attacks via Humanizing AI Text on Machine-Generated Text Detectors,"Jingyi Zheng, Junfeng Wang, Zhen Sun, Wenhan Dong, Yule Liu, Xinlei He",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.08708"" target=""_blank"">2503.08708</a>",,2025-12-03 22:39:25
A Grey-box Text Attack Framework using Explainable AI,"Esther Chiramal, Kelvin Soh Boon Kai",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.08226"" target=""_blank"">2503.08226</a>",,2025-12-03 22:39:25
A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4,"Zhaoyi Li, Xiaohan Zhao, Dong-Dong Wu, Jiacheng Cui, Zhiqiang Shen",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.10635"" target=""_blank"">2503.10635</a>","<a href=""https://github.com/VILA-Lab/M-Attack"" target=""_blank"">VILA-Lab</a>",2025-12-03 22:39:25
Prompt Inference Attack on Distributed Large Language Model Inference Frameworks,"Xinjian Luo, Ting Yu, Xiaokui Xiao",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09291"" target=""_blank"">2503.09291</a>",,2025-12-03 22:39:25
C^2 ATTACK: Towards Representation Backdoor on CLIP via Concept Confusion,"Lijie Hu, Junchi Liao, Weimin Lyu, Shaopeng Fu, Tianhao Huang, Shu Yang, Guimin Hu, Di Wang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09095"" target=""_blank"">2503.09095</a>",,2025-12-03 22:39:25
Weakly Supervised Contrastive Adversarial Training for Learning Robust Features from Semi-supervised Data,"Lilin Zhang, Chengpei Wu, Ning Yang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.11032"" target=""_blank"">2503.11032</a>",,2025-12-03 22:39:25
Robustness Tokens: Towards Adversarial Robustness of Transformers,"Brian Pulfer, Yury Belousov, Slava Voloshynovskiy",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.10191"" target=""_blank"">2503.10191</a>",,2025-12-03 22:39:25
AdvPaint: Protecting Images from Inpainting Manipulation via Adversarial Attention Disruption,"Joonsung Jeon, Woo Jae Kim, Suhyeon Ha, Sooel Son, Sung-eui Yoon",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.10081"" target=""_blank"">2503.10081</a>",,2025-12-03 22:39:25
Exploring the Vulnerabilities of Federated Learning: A Deep Dive into Gradient Inversion Attacks,"Pengxin Guo, Runxi Wang, Shuang Zeng, Jinjing Zhu, Haoning Jiang, Yanran Wang, Yuyin Zhou, Feifei Wang, Hui Xiong, Liangqiong Qu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.11514"" target=""_blank"">2503.11514</a>",,2025-12-03 22:39:25
TAIJI: Textual Anchoring for Immunizing Jailbreak Images in Vision Language Models,"Xiangyu Yin, Yi Qi, Jinwei Hu, Zhen Chen, Yi Dong, Xingyu Zhao, Xiaowei Huang, Wenjie Ruan",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.10872"" target=""_blank"">2503.10872</a>",,2025-12-03 22:39:25
Enhancing Facial Privacy Protection via Weakening Diffusion Purification,"Ali Salar, Qing Liu, Yingli Tian, Guoying Zhao",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.10350"" target=""_blank"">2503.10350</a>",,2025-12-03 22:39:25
WAFFLED: Exploiting Parsing Discrepancies to Bypass Web Application Firewalls,"Seyed Ali Akhavani, Bahruz Jabiyev, Ben Kallus, Cem Topcuoglu, Sergey Bratus, Engin Kirda",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.10846"" target=""_blank"">2503.10846</a>",,2025-12-03 22:39:25
"JPEG Compliant Compression for Both Human and Machine, A Report",Linfeng Ye,arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.10912"" target=""_blank"">2503.10912</a>",,2025-12-03 22:39:25
Enhancing Adversarial Example Detection Through Model Explanation,"Qian Ma, Ziping Ye",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09735"" target=""_blank"">2503.09735</a>",,2025-12-03 22:39:25
AdvAD: Exploring Non-Parametric Diffusion for Imperceptible Adversarial Attacks,"Jin Li, Ziqiang He, Anwei Luo, Jian-Fang Hu, Z. Jane Wang, Xiangui Kang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09124"" target=""_blank"">2503.09124</a>","<a href=""https://github.com/XianguiKang/AdvAD"" target=""_blank"">XianguiKang</a>",2025-12-03 22:39:25
CyberLLMInstruct: A New Dataset for Analysing Safety of Fine-Tuned LLMs Using Cyber Security Data,"Adel ElZemity, Budi Arief, Shujun Li",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09334"" target=""_blank"">2503.09334</a>","<a href=""https://github.com/Adelsamir01/CyberLLMInstruct"" target=""_blank"">Adelsamir01</a>",2025-12-03 22:39:25
Revisiting Backdoor Attacks on Time Series Classification in the Frequency Domain,"Yuanmin Huang, Mi Zhang, Zhaoxiang Wang, Wenxuan Li, Min Yang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09712"" target=""_blank"">2503.09712</a>",,2025-12-03 22:39:25
Probing Network Decisions: Capturing Uncertainties and Unveiling Vulnerabilities Without Label Information,"Youngju Joung, Sehyun Lee, Jaesik Choi",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09068"" target=""_blank"">2503.09068</a>",,2025-12-03 22:39:25
Probing Latent Subspaces in LLM for AI Security: Identifying and Manipulating Adversarial States,"Xin Wei Chia, Jonathan Pan",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09066"" target=""_blank"">2503.09066</a>",,2025-12-03 22:39:25
Boosting the Local Invariance for Better Adversarial Transferability,"Bohan Liu, Xiaosen Wang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06140"" target=""_blank"">2503.06140</a>",,2025-12-03 22:39:25
Detecting and Preventing Data Poisoning Attacks on AI Models,"Halima I. Kure, Pradipta Sarkar, Ahmed B. Ndanusa, Augustine O. Nwajana",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09302"" target=""_blank"">2503.09302</a>",,2025-12-03 22:39:25
Adaptive Backdoor Attacks with Reasonable Constraints on Graph Neural Networks,"Xuewen Dong, Jiachen Li, Shujun Li, Zhichao You, Qiang Qu, Yaroslav Kholodov, Yulong Shen",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09049"" target=""_blank"">2503.09049</a>",,2025-12-03 22:39:25
In-Context Defense in Computer Agents: An Empirical Study,"Pei Yang, Hai Ci, Mike Zheng Shou",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09241"" target=""_blank"">2503.09241</a>",,2025-12-03 22:39:25
How Feasible is Augmenting Fake Nodes with Learnable Features as a Counter-strategy against Link Stealing Attacks? (45%),"Mir Imtiaz Mostafiz, Imtiaz Karim, Elisa Bertino",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09726"" target=""_blank"">2503.09726</a>",,2025-12-03 22:39:25
ExtremeAIGC: Benchmarking LMM Vulnerability to AI-Generated Extremist Content,"Bhavik Chandna, Mariam Aboujenane, Usman Naseem",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09964"" target=""_blank"">2503.09964</a>",,2025-12-03 22:39:25
RESTRAIN: Reinforcement Learning-Based Secure Framework for Trigger-Action IoT Environment,"Md Morshed Alam, Lokesh Chandra Das, Sandip Roy, Sachin Shetty, Weichao Wang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09513"" target=""_blank"">2503.09513</a>",,2025-12-03 22:39:25
Silent Branding Attack: Trigger-free Data Poisoning Attack on Text-to-Image Diffusion Models,"Sangwon Jang, June Suk Choi, Jaehyeong Jo, Kimin Lee, Sung Ju Hwang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09669"" target=""_blank"">2503.09669</a>",,2025-12-03 22:39:25
Towards Hardware Supported Domain Generalization in DNN-Based Edge Computing Devices for Health Monitoring,"Johnson Loh, Lyubov Dudchenko, Justus Viga, Tobias Gemmeke",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09661"" target=""_blank"">2503.09661</a>",,2025-12-03 22:39:25
Sparse Autoencoder as a Zero-Shot Classifier for Concept Erasing in Text-to-Image Diffusion Models,"Zhihua Tian, Sirun Nan, Ming Xu, Shengfang Zhai, Wenjie Qu, Jian Liu, Kui Ren, Ruoxi Jia, Jiaheng Zhang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.09446"" target=""_blank"">2503.09446</a>","<a href=""https://github.com/NANSirun/Interpret-then-deactivate"" target=""_blank"">NANSirun</a>",2025-12-03 22:39:25
AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection,"Jialin Lu, Junjie Shan, Ziqi Zhao, Ka-Ho Chow",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06529"" target=""_blank"">2503.06529</a>",,2025-12-03 22:39:25
Adaptive Attacks Break Defenses Against Indirect Prompt Injection Attacks on LLM Agents,"Qiusi Zhan, Richard Fang, Henil Shalin Panchal, Daniel Kang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.00061"" target=""_blank"">2503.00061</a>","<a href=""https://github.com/uiuc-kang-lab/AdaptiveAttackAgent"" target=""_blank"">uiuc-kang-lab</a>",2025-12-03 22:39:25
Using Mechanistic Interpretability to Craft Adversarial Attacks against Large Language Models,"Thomas Winninger, Boussad Addad, Katarzyna Kapusta",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06269"" target=""_blank"">2503.06269</a>","<a href=""https://github.com/Sckathach/subspace-rerouting"" target=""_blank"">Sckathach</a>",2025-12-03 22:39:25
TAET: Two-Stage Adversarial Equalization Training on Long-Tailed Distributions,"Wang YuHang, Junkang Guo, Aolei Liu, Kaihao Wang, Zaitong Wu, Zhenyu Liu, Wenfei Yin, Jian Liu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.01924"" target=""_blank"">2503.01924</a>","<a href=""https://github.com/BuhuiOK/TAET-Two-Stage-Adversarial-Equalization-Training-on-Long-Tailed-Distributions"" target=""_blank"">BuhuiOK</a>",2025-12-03 22:39:25
Poisoning Attacks to Local Differential Privacy Protocols for Trajectory Data,"I-Jung Hsu, Chih-Hsun Lin, Chia-Mu Yu, Sy-Yen Kuo, Chun-Ying Huang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.07483"" target=""_blank"">2503.07483</a>",,2025-12-03 22:39:25
Improving LLM Safety Alignment with Dual-Objective Optimization,"Xuandong Zhao, Will Cai, Tianneng Shi, David Huang, Licong Lin, Song Mei, Dawn Song",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.03710"" target=""_blank"">2503.03710</a>","<a href=""https://github.com/wicai24/DOOR-Alignment"" target=""_blank"">wicai24</a>",2025-12-03 22:39:25
Mind the Gap: Detecting Black-box Adversarial Attacks in the Making through Query Update Analysis,"Jeonghwan Park, Niall McLaughlin, Ihsen Alouani",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.02986"" target=""_blank"">2503.02986</a>",,2025-12-03 22:39:25
AttackSeqBench: Benchmarking Large Language Models' Understanding of Sequential Patterns in Cyber Attacks,"Javier Yong, Haokai Ma, Yunshan Ma, Anis Yusof, Zhenkai Liang, Ee-Chien Chang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.03170"" target=""_blank"">2503.03170</a>","<a href=""https://github.com/Javiery3889/AttackSeqBench"" target=""_blank"">Javiery3889</a>",2025-12-03 22:39:25
"One Stone, Two Birds: Enhancing Adversarial Defense Through the Lens of Distributional Discrepancy","Jiacheng Zhang, Benjamin I. P. Rubinstein, Jingfeng Zhang, Feng Liu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.02169"" target=""_blank"">2503.02169</a>","<a href=""https://github.com/tmlr-group/DAD"" target=""_blank"">tmlr-group</a>",2025-12-03 22:39:25
Divide and Conquer: Heterogeneous Noise Integration for Diffusion-based Adversarial Purification,"Gaozheng Pei, Shaojie Lyu, Gong Chen, Ke Ma, Qianqian Xu, Yingfei Sun, Qingming Huang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.01407"" target=""_blank"">2503.01407</a>",,2025-12-03 22:39:25
A Lightweight and Secure Deep Learning Model for Privacy-Preserving Federated Learning in Intelligent Enterprises,"Reza Fotohi, Fereidoon Shams Aliee, Bahar Farahani",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.02017"" target=""_blank"">2503.02017</a>",,2025-12-03 22:39:25
Protecting DeFi Platforms against Non-Price Flash Loan Attacks,"Abdulrahman Alhaidari, Balaji Palanisamy, Prashant Krishnamurthy",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.01944"" target=""_blank"">2503.01944</a>",,2025-12-03 22:39:25
Improving the Transferability of Adversarial Attacks by an Input Transpose,"Qing Wan, Shilong Deng, Xun Wang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.00932"" target=""_blank"">2503.00932</a>",,2025-12-03 22:39:25
Exploiting Vulnerabilities in Speech Translation Systems through Targeted Adversarial Attacks,"Chang Liu, Haolin Wu, Xi Yang, Kui Zhang, Cong Wu, Weiming Zhang, Nenghai Yu, Tianwei Zhang, Qing Guo, Jie Zhang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.00957"" target=""_blank"">2503.00957</a>","<a href=""https://adv-st.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
AMUN: Adversarial Machine UNlearning,"Ali Ebrahimpour-Boroojeny, Hari Sundaram, Varun Chandrasekaran",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.00917"" target=""_blank"">2503.00917</a>",,2025-12-03 22:39:25
Unnatural Languages Are Not Bugs but Features for LLMs,"Keyu Duan, Yiran Zhao, Zhili Feng, Jinjie Ni, Tianyu Pang, Qian Liu, Tianle Cai, Longxu Dou, Kenji Kawaguchi, Anirudh Goyal, J. Zico Kolter, Michael Qizhe Shieh",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.01926"" target=""_blank"">2503.01926</a>",,2025-12-03 22:39:25
CURVALID: Geometrically-guided Adversarial Prompt Detection,"Canaan Yung, Hanxun Huang, Sarah Monazam Erfani, Christopher Leckie",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.03502"" target=""_blank"">2503.03502</a>","<a href=""https://github.com/Cancanxxx/CurvaLID"" target=""_blank"">Cancanxxx</a>",2025-12-03 22:39:25
"A Survey of Adversarial Defenses in Vision-based Systems: Categorization, Methods and Challenges","Nandish Chattopadhyay, Abdul Basit, Bassem Ouni, Muhammad Shafique",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.00384"" target=""_blank"">2503.00384</a>",,2025-12-03 22:39:25
Adversarial Attacks on Event-Based Pedestrian Detectors: A Physical Approach,"Guixu Lin, Muyao Niu, Qingtian Zhu, Zhengwei Yin, Zhuoxiao Li, Shengfeng He, Yinqiang Zheng",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.00377"" target=""_blank"">2503.00377</a>",,2025-12-03 22:39:25
BadJudge: Backdoor Vulnerabilities of LLM-as-a-Judge,"Terry Tong, Fei Wang, Zhe Zhao, Muhao Chen",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.00596"" target=""_blank"">2503.00596</a>",,2025-12-03 22:39:25
xIDS-EnsembleGuard: An Explainable Ensemble Learning-based Intrusion Detection System,"Muhammad Adil, Mian Ahmad Jan, Safayat Bin Hakim, Houbing Herbert Song, Zhanpeng Jin",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.00615"" target=""_blank"">2503.00615</a>",,2025-12-03 22:39:25
Transformer Meets Twicing: Harnessing Unattended Residual Information,"Laziz Abdullaev, Tan M. Nguyen",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.00687"" target=""_blank"">2503.00687</a>",,2025-12-03 22:39:25
Approaching the Harm of Gradient Attacks While Only Flipping Labels,"Abdessamad El-Kabid, El-Mahdi El-Mhamdi",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.00140"" target=""_blank"">2503.00140</a>",,2025-12-03 22:39:25
NoPain: No-box Point Cloud Attack via Optimal Transport Singular Boundary,"Zezeng Li, Xiaoyu Du, Na Lei, Liming Chen, Weimin Wang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.00063"" target=""_blank"">2503.00063</a>","<a href=""https://github.com/cognaclee/nopain"" target=""_blank"">cognaclee</a>",2025-12-03 22:39:25
ADAGE: Active Defenses Against GNN Extraction,"Jing Xu, Franziska Boenisch, Adam Dziedzic",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.00065"" target=""_blank"">2503.00065</a>",,2025-12-03 22:39:25
CRFU: Compressive Representation Forgetting Against Privacy Leakage on Machine Unlearning,"Weiqi Wang, Chenhan Zhang, Zhiyi Tian, Shushu Liu, Shui Yu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.00062"" target=""_blank"">2503.00062</a>",,2025-12-03 22:39:25
Guiding not Forcing: Enhancing the Transferability of Jailbreaking Attacks on LLMs via Removing Superfluous Constraints,"Junxiao Yang, Zhexin Zhang, Shiyao Cui, Hongning Wang, Minlie Huang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.01865"" target=""_blank"">2503.01865</a>",,2025-12-03 22:39:25
from Benign import Toxic: Jailbreaking the Language Model via Adversarial Metaphors,"Yu Yan, Sheng Sun, Zenghao Duan, Teli Liu, Min Liu, Zhiyi Yin, Jiangyu Lei, Qi Li",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.00038"" target=""_blank"">2503.00038</a>",,2025-12-03 22:39:25
GuardDoor: Safeguarding Against Malicious Diffusion Editing via Protective Backdoors,"Yaopei Zeng, Yuanpu Cao, Lu Lin",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.03944"" target=""_blank"">2503.03944</a>",,2025-12-03 22:39:25
"Towards Robust Universal Information Extraction: Benchmark, Evaluation, and Solution","Jizhao Zhu, Akang Shi, Zixuan Li, Long Bai, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.03201"" target=""_blank"">2503.03201</a>",,2025-12-03 22:39:25
Attackers Can Do Better: Over- and Understated Factors of Model Stealing Attacks,"Daryna Oliynyk, Rudolf Mayer, Andreas Rauber",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06188"" target=""_blank"">2503.06188</a>",,2025-12-03 22:39:25
SAS: Segment Anything Small for Ultrasound -- A Non-Generative Data Augmentation Technique for Robust Deep Learning in Ultrasound Imaging,"Danielle L. Ferreira, Ahana Gangopadhyay, Hsi-Ming Chang, Ravi Soni, Gopal Avinash",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.05916"" target=""_blank"">2503.05916</a>",,2025-12-03 22:39:25
CeTAD: Towards Certified Toxicity-Aware Distance in Vision Language Models,"Xiangyu Yin, Jiaxu Liu, Zhen Chen, Jinwei Hu, Yi Dong, Xiaowei Huang, Wenjie Ruan",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.10661"" target=""_blank"">2503.10661</a>",,2025-12-03 22:39:25
Reinforced Diffuser for Red Teaming Large Vision-Language Models,"Ruofan Wang, Xiang Zheng, Xiaosen Wang, Cong Wang, Xingjun Ma",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06223"" target=""_blank"">2503.06223</a>",,2025-12-03 22:39:25
Adversarial Robustness of Discriminative Self-Supervised Learning in Vision,"Ömer Veysel Çağatan, Ömer Faruk Tal, M. Emre Gürsoy",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06361"" target=""_blank"">2503.06361</a>",,2025-12-03 22:39:25
Poisoned-MRAG: Knowledge Poisoning Attacks to Multimodal Retrieval Augmented Generation,"Yinuo Liu, Zenghui Yuan, Guiyao Tie, Jiawen Shi, Lichao Sun, Neil Zhenqiang Gong",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06254"" target=""_blank"">2503.06254</a>",,2025-12-03 22:39:25
MAD-MAX: Modular And Diverse Malicious Attack MiXtures for Automated LLM Red Teaming,"Stefan Schoepf, Muhammad Zaid Hameed, Ambrish Rawat, Kieran Fraser, Giulio Zizzo, Giandomenico Cornacchia, Mark Purcell",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06253"" target=""_blank"">2503.06253</a>",,2025-12-03 22:39:25
Exploring Adversarial Transferability between Kolmogorov-arnold Networks,"Songping Wang, Xinquan Yue, Yueming Lyu, Caifeng Shan",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06276"" target=""_blank"">2503.06276</a>",,2025-12-03 22:39:25
Disrupting Model Merging: A Parameter-Level Defense Without Sacrificing Accuracy,"Wei Junhao, Yu Zhe, Sakuma Jun",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.07661"" target=""_blank"">2503.07661</a>",,2025-12-03 22:39:25
Backdoor Attacks on Discrete Graph Diffusion Models,"Jiawen Wang, Samin Karim, Yuan Hong, Binghui Wang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.06340"" target=""_blank"">2503.06340</a>",,2025-12-03 22:39:25
Robust Intrusion Detection System with Explainable Artificial Intelligence,"Betül Güvenç Paltun, Ramin Fuladi, Rim El Malki",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.05303"" target=""_blank"">2503.05303</a>",,2025-12-03 22:39:25
Are Your LLM-based Text-to-SQL Models Secure? Exploring SQL Injection via Backdoor Attacks,"Meiyu Lin, Haichuan Zhang, Jiale Lao, Renyuan Li, Yuanchun Zhou, Carl Yang, Yang Cao, Mingjie Tang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.05445"" target=""_blank"">2503.05445</a>",,2025-12-03 22:39:25
Enhancing Network Security: A Hybrid Approach for Detection and Mitigation of Distributed Denial-of-Service Attacks Using Machine Learning,"Nizo Jaman Shohan, Gazi Tanbhir, Faria Elahi, Ahsan Ullah, Md. Nazmus Sakib",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.05477"" target=""_blank"">2503.05477</a>",,2025-12-03 22:39:25
Scale-Invariant Adversarial Attack against Arbitrary-scale Super-resolution,"Yihao Huang, Xin Luo, Qing Guo, Felix Juefei-Xu, Xiaojun Jia, Weikai Miao, Geguang Pu, Yang Liu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.04385"" target=""_blank"">2503.04385</a>",,2025-12-03 22:39:25
Data Poisoning Attacks to Locally Differentially Private Range Query Protocols,"Ting-Wei Liao, Chih-Hsun Lin, Yu-Lin Tsai, Takao Murakami, Chia-Mu Yu, Jun Sakuma, Chun-Ying Huang, Hiroaki Kikuchi",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.03454"" target=""_blank"">2503.03454</a>",,2025-12-03 22:39:25
From Pixels to Trajectory: Universal Adversarial Example Detection via Temporal Imprints,"Yansong Gao, Huaibing Peng, Hua Ma, Zhiyang Dai, Shuo Wang, Hongsheng Hu, Anmin Fu, Minhui Xue",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.04853"" target=""_blank"">2503.04853</a>",,2025-12-03 22:39:25
Provable Robust Overfitting Mitigation in Wasserstein Distributionally Robust Optimization,"Shuang Liu, Yihan Wang, Yifan Zhu, Yibo Miao, Xiao-Shan Gao",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.04315"" target=""_blank"">2503.04315</a>",,2025-12-03 22:39:25
Energy-Latency Attacks: A New Adversarial Threat to Deep Learning,"Hanene F. Z. Brachemi Meftah, Wassim Hamidouche, Sid Ahmed Fezza, Olivier Deforges",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.04963"" target=""_blank"">2503.04963</a>",,2025-12-03 22:39:25
Poisoning Bayesian Inference via Data Deletion and Replication,"Matthieu Carreau, Roi Naveiro, William N. Caballero",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.04480"" target=""_blank"">2503.04480</a>",,2025-12-03 22:39:25
Know Thy Judge: On the Robustness Meta-Evaluation of LLM Safety Judges,"Francisco Eiras, Eliott Zemour, Eric Lin, Vaikkunth Mugunthan",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.04474"" target=""_blank"">2503.04474</a>",,2025-12-03 22:39:25
One-Shot is Enough: Consolidating Multi-Turn Attacks into Efficient Single-Turn Prompts for LLMs,"Junwoo Ha, Hyunjun Kim, Sangyoon Yu, Haon Park, Ashkan Yousefpour, Yuna Park, Suhyun Kim",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.04856"" target=""_blank"">2503.04856</a>",,2025-12-03 22:39:25
Task-Agnostic Attacks Against Vision Foundation Models,"Brian Pulfer, Yury Belousov, Vitaliy Kinakh, Teddy Furon, Slava Voloshynovskiy",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.03842"" target=""_blank"">2503.03842</a>",,2025-12-03 22:39:25
Towards Effective and Sparse Adversarial Attack on Spiking Neural Networks via Breaking Invisible Surrogate Gradients,"Li Lun, Kunyu Feng, Qinglong Ni, Ling Liang, Yuan Wang, Ying Li, Dunshan Yu, Xiaoxin Cui",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.03272"" target=""_blank"">2503.03272</a>","<a href=""https://github.com/ryime/PDSG-SDA"" target=""_blank"">ryime</a>",2025-12-03 22:39:25
CLIP is Strong Enough to Fight Back: Test-time Counterattacks towards Zero-shot Adversarial Robustness of CLIP,"Songlong Xing, Zhengyu Zhao, Nicu Sebe",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.03613"" target=""_blank"">2503.03613</a>","<a href=""https://github.com/Sxing2/CLIP-Test-time-Counterattacks"" target=""_blank"">Sxing2</a>",2025-12-03 22:39:25
Adversarial Example Based Fingerprinting for Robust Copyright Protection in Split Learning,"Zhangting Lin, Mingfu Xue, Kewei Chen, Wenmao Liu, Xiang Gao, Leo Yu Zhang, Jian Wang, Yushu Zhang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.04825"" target=""_blank"">2503.04825</a>",,2025-12-03 22:39:25
Adversarial Training for Multimodal Large Language Models against Jailbreak Attacks,"Liming Lu, Shuchao Pang, Siyuan Liang, Haotian Zhu, Xiyu Zeng, Aishan Liu, Yunhuai Liu, Yongbin Zhou",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.04833"" target=""_blank"">2503.04833</a>",,2025-12-03 22:39:25
Hierarchical Self-Supervised Adversarial Training for Robust Vision Models in Histopathology,"Hashmat Shadab Malik, Shahina Kunhimon, Muzammal Naseer, Fahad Shahbaz Khan, Salman Khan",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.10629"" target=""_blank"">2503.10629</a>","<a href=""https://github.com/HashmatShadab/HSAT"" target=""_blank"">HashmatShadab</a>",2025-12-03 22:39:25
Bitstream Collisions in Neural Image Compression via Adversarial Perturbations,"Jordan Madden, Lhamo Dorje, Xiaohua Li",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19817"" target=""_blank"">2503.19817</a>",,2025-12-03 22:39:25
A Framework for Evaluating Emerging Cyberattack Capabilities of AI,"Mikel Rodriguez, Raluca Ada Popa, Four Flynn, Lihao Liang, Allan Dafoe, Anna Wang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.11917"" target=""_blank"">2503.11917</a>",,2025-12-03 22:39:25
Robustness of deep learning classification to adversarial input on GPUs: asynchronous parallel accumulation is a source of vulnerability,"Sanjif Shanmugavelu, Mathieu Taillefumier, Christopher Culver, Vijay Ganesh, Oscar Hernandez, Ada Sedova",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.17173"" target=""_blank"">2503.17173</a>",,2025-12-03 22:39:25
Are We There Yet? Unraveling the State-of-the-Art Graph Network Intrusion Detection Systems,"Chenglong Wang, Pujia Zheng, Jiaping Gui, Cunqing Hua, Wajih Ul Hassan",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.20281"" target=""_blank"">2503.20281</a>",,2025-12-03 22:39:25
Towards Imperceptible Adversarial Attacks for Time Series Classification with Local Perturbations and Frequency Analysis,"Wenwei Gu, Renyi Zhong, Jianping Zhang, Michael R. Lyu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19519"" target=""_blank"">2503.19519</a>",,2025-12-03 22:39:25
Boosting the Transferability of Audio Adversarial Examples with Acoustic Representation Optimization,"Weifei Jin, Junjie Su, Hejia Wang, Yulin Ye, Jie Hao",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19591"" target=""_blank"">2503.19591</a>",,2025-12-03 22:39:25
Towards Benchmarking and Assessing the Safety and Robustness of Autonomous Driving on Safety-critical Scenarios,"Jingzheng Li, Xianglong Liu, Shikui Wei, Zhijun Chen, Bing Li, Qing Guo, Xianqi Yang, Yanjun Pu, Jiakai Wang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.23708"" target=""_blank"">2503.23708</a>",,2025-12-03 22:39:25
ImF: Implicit Fingerprint for Large Language Models,"Wu jiaxuan, Peng Wanli, Fu hang, Xue Yiming, Wen juan",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.21805"" target=""_blank"">2503.21805</a>",,2025-12-03 22:39:25
Stop Walking in Circles! Bailing Out Early in Projected Gradient Descent,"Philip Doldo, Derek Everett, Amol Khanna, Andre T Nguyen, Edward Raff",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19347"" target=""_blank"">2503.19347</a>",,2025-12-03 22:39:25
SITA: Structurally Imperceptible and Transferable Adversarial Attacks for Stylized Image Generation,"Jingdan Kang, Haoxin Yang, Yan Cai, Huaidong Zhang, Xuemiao Xu, Yong Du, Shengfeng He",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19791"" target=""_blank"">2503.19791</a>","<a href=""https://github.com/A-raniy-day/SITA"" target=""_blank"">A-raniy-day</a>",2025-12-03 22:39:25
Network Inversion for Generating Confidently Classified Counterfeits,"Pirzada Suhail, Amit Sethi",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.20187"" target=""_blank"">2503.20187</a>",,2025-12-03 22:39:25
Playing the Fool: Jailbreaking LLMs and Multimodal LLMs with Out-of-Distribution Strategy,"Joonhyun Jeong, Seyun Bae, Yeonsung Jung, Jaeryong Hwang, Eunho Yang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.20823"" target=""_blank"">2503.20823</a>","<a href=""https://github.com/naver-ai/JOOD"" target=""_blank"">naver-ai</a>",2025-12-03 22:39:25
Lifting Linear Sketches: Optimal Bounds and Adversarial Robustness,"Elena Gribelyuk, Honghao Lin, David P. Woodruff, Huacheng Yu, Samson Zhou",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19629"" target=""_blank"">2503.19629</a>",,2025-12-03 22:39:25
Membership Inference Attacks on Large-Scale Models: A Survey,"Hengyu Wu, Yang Cao",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19338"" target=""_blank"">2503.19338</a>",,2025-12-03 22:39:25
Nanopass Back-Translation of Call-Return Trees for Mechanized Secure Compilation Proofs,"Jérémy Thibault, Joseph Lenormand, Catalin Hritcu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19609"" target=""_blank"">2503.19609</a>",,2025-12-03 22:39:25
Efficient Adversarial Detection Frameworks for Vehicle-to-Microgrid Services in Edge Computing,"Ahmed Omara, Burak Kantarci",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19318"" target=""_blank"">2503.19318</a>",,2025-12-03 22:39:25
Deterministic Certification of Graph Neural Networks against Graph Poisoning Attacks with Arbitrary Perturbations,"Jiate Li, Meng Pang, Yun Dong, Binghui Wang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.18503"" target=""_blank"">2503.18503</a>",,2025-12-03 22:39:25
NullSwap: Proactive Identity Cloaking Against Deepfake Face Swapping,"Tianyi Wang, Harry Cheng, Xiao Zhang, Yinglong Wang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.18678"" target=""_blank"">2503.18678</a>",,2025-12-03 22:39:25
Defeating Prompt Injections by Design,"Edoardo Debenedetti, Ilia Shumailov, Tianqi Fan, Jamie Hayes, Nicholas Carlini, Daniel Fabian, Christoph Kern, Chongyang Shi, Andreas Terzis, Florian Tramèr",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.18813"" target=""_blank"">2503.18813</a>",,2025-12-03 22:39:25
Masks and Mimicry: Strategic Obfuscation and Impersonation Attacks on Authorship Verification,"Kenneth Alperin, Rohan Leekha, Adaku Uchendu, Trang Nguyen, Srilakshmi Medarametla, Carlos Levya Capote, Seth Aycock, Charlie Dagli",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19099"" target=""_blank"">2503.19099</a>",,2025-12-03 22:39:25
SoK: How Robust is Audio Watermarking in Generative AI models? (11%),"Yizhu Wen, Ashwin Innuganti, Aaron Bien Ramos, Hanqing Guo, Qiben Yan",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19176"" target=""_blank"">2503.19176</a>","<a href=""https://sokaudiowm.github.io/"" target=""_blank"">sokaudiowm.github.io</a>",2025-12-03 22:39:25
Graph-Level Label-Only Membership Inference Attack against Graph Neural Networks,"Jiazhu Dai, Yubing Lu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19070"" target=""_blank"">2503.19070</a>",,2025-12-03 22:39:25
Leveraging Perturbation Robustness to Enhance Out-of-Distribution Detection,"Wenxi Chen, Raymond A. Yeh, Shaoshuai Mou, Yan Gu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.18784"" target=""_blank"">2503.18784</a>",,2025-12-03 22:39:25
Robustness of Proof of Team Sprint (PoTS) Against Attacks: A Simulation-Based Analysis,Naoki Yonezawa,arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19293"" target=""_blank"">2503.19293</a>",,2025-12-03 22:39:25
Process or Result? Manipulated Ending Tokens Can Mislead Reasoning LLMs to Ignore the Correct Reasoning Steps,"Yu Cui, Bryan Hooi, Yujun Cai, Yiwei Wang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19326"" target=""_blank"">2503.19326</a>",,2025-12-03 22:39:25
Benchmarking Object Detectors under Real-World Distribution Shifts in Satellite Imagery,"Sara Al-Emadi, Yin Yang, Ferda Ofli",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.19202"" target=""_blank"">2503.19202</a>","<a href=""https://github.com/RWGAI/RWDS"" target=""_blank"">RWGAI</a>",2025-12-03 22:39:25
Metaphor-based Jailbreaking Attacks on Text-to-Image Models,"Chenyu Zhang, Yiwen Ma, Lanjun Wang, Wenhui Li, Yi Tu, An-An Liu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.17987"" target=""_blank"">2503.17987</a>",,2025-12-03 22:39:25
Model-Guardian: Protecting against Data-Free Model Stealing Using Gradient Representations and Deceptive Predictions,"Yunfei Yang, Xiaojun Chen, Yuexin Xuan, Zhendong Zhao",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.18081"" target=""_blank"">2503.18081</a>",,2025-12-03 22:39:25
Multi-agent Uncertainty-Aware Pessimistic Model-Based Reinforcement Learning for Connected Autonomous Vehicles,"Ruoqi Wen, Rongpeng Li, Xing Xu, Zhifeng Zhao",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.20462"" target=""_blank"">2503.20462</a>",,2025-12-03 22:39:25
DR-PETS: Learning-Based Control With Planning in Adversarial Environments,"Hozefa Jesawada, Antonio Acernese, Giovanni Russo, Vecchio Carmen Del",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.20660"" target=""_blank"">2503.20660</a>",,2025-12-03 22:39:25
Prototype Guided Backdoor Defense,"Venkat Adithya Amula, Sunayana Samavedam, Saurabh Saini, Avani Gupta, Narayanan P J",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.20925"" target=""_blank"">2503.20925</a>","<a href=""https://venkatadithya9.github.io/pgbd.github.io/"" target=""_blank"">pgbd.github.io</a>",2025-12-03 22:39:25
Adversarial Wear and Tear: Exploiting Natural Damage for Generating Physical-World Adversarial Examples,"Samra Irshad, Seungkyu Lee, Nassir Navab, Hong Joo Lee, Seong Tae Kim",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.21164"" target=""_blank"">2503.21164</a>",,2025-12-03 22:39:25
A Channel-Triggered Backdoor Attack on Wireless Semantic Image Reconstruction,"Jialin Wan, Nan Cheng, Jinglong Shen",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.23866"" target=""_blank"">2503.23866</a>",,2025-12-03 22:39:25
Detecting Functional Bugs in Smart Contracts through LLM-Powered and Bug-Oriented Composite Analysis,"Binbin Zhao, Xingshuang Lin, Yuan Tian, Saman Zonouz, Na Ruan, Jiliang Li, Raheem Beyah, Shouling Ji",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.23718"" target=""_blank"">2503.23718</a>",,2025-12-03 22:39:25
Buffer is All You Need: Defending Federated Learning against Backdoor Attacks under Non-iids via Buffering,"Xingyu Lyu, Ning Wang, Yang Xiao, Shixiong Li, Tao Li, Danjue Chen, Yimin Chen",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.23511"" target=""_blank"">2503.23511</a>",,2025-12-03 22:39:25
Adversarial Data Collection: Human-Collaborative Perturbations for Efficient and Robust Robotic Imitation Learning,"Siyuan Huang, Yue Liao, Siyuan Feng, Shu Jiang, Si Liu, Hongsheng Li, Maoqing Yao, Guanghui Ren",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.11646"" target=""_blank"">2503.11646</a>",,2025-12-03 22:39:25
A Survey on Unlearnable Data,"Jiahao Li, Yiqiang Chen, Yunbing Xing, Yang Gu, Xiangyuan Lan",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.23536"" target=""_blank"">2503.23536</a>",,2025-12-03 22:39:25
Two Heads Are Better than One: Model-Weight and Latent-Space Analysis for Federated Learning on Non-iid Data against Poisoning Attacks,"Xingyu Lyu, Ning Wang, Yang Xiao, Shixiong Li, Tao Li, Danjue Chen, Yimin Chen",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.23288"" target=""_blank"">2503.23288</a>",,2025-12-03 22:39:25
Towards Secure Semantic Communications in the Presence of Intelligent Eavesdroppers,"Shunpu Tang, Yuhao Chen, Qianqian Yang, Ruichen Zhang, Dusit Niyato, Zhiguo Shi",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.23103"" target=""_blank"">2503.23103</a>",,2025-12-03 22:39:25
Data-Free Universal Attack by Exploiting the Intrinsic Vulnerability of Deep Models,"YangTian Yan, Jinyu Tian",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.22205"" target=""_blank"">2503.22205</a>",,2025-12-03 22:39:25
Tropical Bisectors and Carlini-Wagner Attacks,"Gillian Grindstaff, Julia Lindberg, Daniela Schkoda, Miruna-Stefana Sorea, Ruriko Yoshida",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.22653"" target=""_blank"">2503.22653</a>",,2025-12-03 22:39:25
T-CIL: Temperature Scaling using Adversarial Perturbation for Calibration in Class-Incremental Learning,"Seong-Hyeon Hwang, Minsu Kim, Steven Euijong Whang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.22163"" target=""_blank"">2503.22163</a>",,2025-12-03 22:39:25
Imperceptible but Forgeable: Practical Invisible Watermark Forgery via Diffusion Models,"Ziping Dong, Chao Shuai, Zhongjie Ba, Peng Cheng, Zhan Qin, Qinglong Wang, Kui Ren",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.22330"" target=""_blank"">2503.22330</a>",,2025-12-03 22:39:25
Clean Image May be Dangerous: Data Poisoning Attacks Against Deep Hashing,"Shuai Li, Jie Zhang, Yuang Qi, Kejiang Chen, Tianwei Zhang, Weiming Zhang, Nenghai Yu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.21236"" target=""_blank"">2503.21236</a>",,2025-12-03 22:39:25
Protecting Your Video Content: Disrupting Automated Video-based LLM Annotations,"Haitong Liu, Kuofeng Gao, Yang Bai, Jinmin Li, Jinxiao Shan, Tao Dai, Shu-Tao Xia",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.21824"" target=""_blank"">2503.21824</a>","<a href=""https://github.com/ttthhl/Protecting_Your_Video_Content"" target=""_blank"">ttthhl</a>",2025-12-03 22:39:25
Non-control-Data Attacks and Defenses: A review,Lei Chong,arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.22765"" target=""_blank"">2503.22765</a>",,2025-12-03 22:39:25
Learning to Lie: Reinforcement Learning Attacks Damage Human-AI Teams and Teams of LLMs,"Abed Kareem Musaffar, Anand Gokhale, Sirui Zeng, Rasta Tadayon, Xifeng Yan, Ambuj Singh, Francesco Bullo",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.21983"" target=""_blank"">2503.21983</a>",,2025-12-03 22:39:25
Tricking Retrievers with Influential Tokens: An Efficient Black-Box Corpus Poisoning Attack,"Cheng Wang, Yiwei Wang, Yujun Cai, Bryan Hooi",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.21315"" target=""_blank"">2503.21315</a>",,2025-12-03 22:39:25
Data Poisoning in Deep Learning: A Survey,"Pinlong Zhao, Weiyao Zhu, Pengfei Jiao, Di Gao, Ou Wu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.22759"" target=""_blank"">2503.22759</a>","<a href=""https://github.com/Pinlong-Zhao/Data-Poisoning"" target=""_blank"">Pinlong-Zhao</a>",2025-12-03 22:39:25
"Improving $(\alpha, f)$-Byzantine Resilience in Federated Learning via layerwise aggregation and cosine distance","Mario García-Márquez, Nuria Rodríguez-Barroso, M. Victoria Luzón, Francisco Herrera",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.21244"" target=""_blank"">2503.21244</a>",,2025-12-03 22:39:25
ThinkEdit: Interpretable Weight Editing to Mitigate Overly Short Thinking in Reasoning Models,"Chung-En Sun, Ge Yan, Tsui-Wei Weng",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.22048"" target=""_blank"">2503.22048</a>","<a href=""https://github.com/Trustworthy-ML-Lab/ThinkEdit"" target=""_blank"">Trustworthy-ML-Lab</a>",2025-12-03 22:39:25
Enabling Heterogeneous Adversarial Transferability via Feature Permutation Attacks,"Tao Wu, Tie Luo",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.20310"" target=""_blank"">2503.20310</a>",,2025-12-03 22:39:25
Robust Deep Reinforcement Learning in Robotics via Adaptive Gradient-Masked Adversarial Attacks,"Zongyuan Zhang, Tianyang Duan, Zheng Lin, Dong Huang, Zihan Fang, Zekai Sun, Ling Xiong, Hongbin Liang, Heming Cui, Yong Cui, Yue Gao",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.20844"" target=""_blank"">2503.20844</a>",,2025-12-03 22:39:25
State-Aware Perturbation Optimization for Robust Deep Reinforcement Learning,"Zongyuan Zhang, Tianyang Duan, Zheng Lin, Dong Huang, Zihan Fang, Zekai Sun, Ling Xiong, Hongbin Liang, Heming Cui, Yong Cui",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.20613"" target=""_blank"">2503.20613</a>",,2025-12-03 22:39:25
Feature Statistics with Uncertainty Help Adversarial Robustness,"Ran Wang, Xinlei Zhou, Meng Hu, Rihao Li, Wenhui Wu, Yuheng Jia",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.20583"" target=""_blank"">2503.20583</a>",,2025-12-03 22:39:25
Lipschitz Constant Meets Condition Number: Learning Robust and Compact Deep Neural Networks,"Yangqi Feng, Shing-Ho J. Lin, Baoyuan Gao, Xian Wei",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.20454"" target=""_blank"">2503.20454</a>",,2025-12-03 22:39:25
STShield: Single-Token Sentinel for Real-Time Jailbreak Detection in Large Language Models,"Xunguang Wang, Wenxuan Wang, Zhenlan Ji, Zongjie Li, Pingchuan Ma, Daoyuan Wu, Shuai Wang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.17932"" target=""_blank"">2503.17932</a>",,2025-12-03 22:39:25
AuditVotes: A Framework Towards More Deployable Certified Robustness for Graph Neural Networks,"Yuni Lai, Yulin Zhu, Yixuan Sun, Yulun Wu, Bin Xiao, Gaolei Li, Jianhua Li, Kai Zhou",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.22998"" target=""_blank"">2503.22998</a>",,2025-12-03 22:39:25
EasyRobust: A Comprehensive and Easy-to-use Toolkit for Robust and Generalized Vision,"Xiaofeng Mao, Yuefeng Chen, Rong Zhang, Hui Xue, Zhao Li, Hang Su",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.16975"" target=""_blank"">2503.16975</a>","<a href=""https://github.com/alibaba/easyrobust"" target=""_blank"">alibaba</a>",2025-12-03 22:39:25
Trust Under Siege: Label Spoofing Attacks against Machine Learning for Android Malware Detection,"Tianwei Lan, Luca Demetrio, Farid Nait-Abdesselam, Yufei Han, Simone Aonzo",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.11841"" target=""_blank"">2503.11841</a>",,2025-12-03 22:39:25
RAT: Boosting Misclassification Detection Ability without Extra Data,"Ge Yan, Tsui-Wei Weng",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.14783"" target=""_blank"">2503.14783</a>",,2025-12-03 22:39:25
Survey of Adversarial Robustness in Multimodal Large Language Models,"Chengze Jiang, Zhuangzhuang Wang, Minjing Dong, Jie Gui",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.13962"" target=""_blank"">2503.13962</a>",,2025-12-03 22:39:25
MMDT: Decoding the Trustworthiness and Safety of Multimodal Foundation Models,"Chejian Xu, Jiawei Zhang, Zhaorun Chen, Chulin Xie, Mintong Kang, Yujin Potter, Zhun Wang, Zhuowen Yuan, Alexander Xiong, Zidi Xiong, Chenhui Zhang, Lingzhi Yuan, Yi Zeng, Peiyang Xu, Chengquan Guo, Andy Zhou, Jeffrey Ziwei Tan, Xuandong Zhao, Francesco Pinto, Zhen Xiang, Yu Gai, Zinan Lin, Dan Hendrycks, Bo Li, Dawn Song",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.14827"" target=""_blank"">2503.14827</a>","<a href=""https://mmdecodingtrust.github.io/"" target=""_blank"">mmdecodingtrust.github.io</a>",2025-12-03 22:39:25
Anomaly-Flow: A Multi-domain Federated Generative Adversarial Network for Distributed Denial-of-Service Detection,"Melo Leonardo Henrique de, Gustavo de Carvalho Bertoli, Michele Nogueira, Aldri Luiz dos Santos, Lourenço Alves Pereira Junior",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.14618"" target=""_blank"">2503.14618</a>",,2025-12-03 22:39:25
UntrustVul: An Automated Approach for Identifying Untrustworthy Alerts in Vulnerability Detection Models,"Lam Nguyen Tung, Xiaoning Du, Neelofar Neelofar, Aldeida Aleti",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.14852"" target=""_blank"">2503.14852</a>",,2025-12-03 22:39:25
TarPro: Targeted Protection against Malicious Image Editing,"Kaixin Shen, Ruijie Quan, Jiaxu Miao, Jun Xiao, Yi Yang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.13994"" target=""_blank"">2503.13994</a>",,2025-12-03 22:39:25
Evolution-based Region Adversarial Prompt Learning for Robustness Enhancement in Vision-Language Models,"Xiaojun Jia, Sensen Gao, Simeng Qin, Ke Ma, Xinfeng Li, Yihao Huang, Wei Dong, Yang Liu, Xiaochun Cao",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.12874"" target=""_blank"">2503.12874</a>","<a href=""https://github.com/jiaxiaojunQAQ/ER-APT"" target=""_blank"">jiaxiaojunQAQ</a>",2025-12-03 22:39:25
Improving Generalization of Universal Adversarial Perturbation via Dynamic Maximin Optimization,"Yechao Zhang, Yingzhe Xu, Junyu Shi, Leo Yu Zhang, Shengshan Hu, Minghui Li, Yanjun Zhang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.12793"" target=""_blank"">2503.12793</a>",,2025-12-03 22:39:25
GSBA$^K$: $top$-$K$ Geometric Score-based Black-box Attack,"Md Farhamdur Reza, Richeng Jin, Tianfu Wu, Huaiyu Dai",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.12827"" target=""_blank"">2503.12827</a>",,2025-12-03 22:39:25
Securing Virtual Reality Experiences: Unveiling and Tackling Cybersickness Attacks with Explainable AI,"Ripan Kumar Kundu, Matthew Denton, Genova Mongalo, Prasad Calyam, Khaza Anuarul Hoque",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.13419"" target=""_blank"">2503.13419</a>",,2025-12-03 22:39:25
MirrorGuard: Adaptive Defense Against Jailbreaks via Entropy-Guided Mirror Crafting,"Rui Pu, Chaozhuo Li, Rui Ha, Litian Zhang, Lirong Qiu, Xi Zhang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.12931"" target=""_blank"">2503.12931</a>",,2025-12-03 22:39:25
How Good is my Histopathology Vision-Language Foundation Model? A Holistic Benchmark,"Roba Al Majzoub, Hashmat Malik, Muzammal Naseer, Zaigham Zaheer, Tariq Mahmood, Salman Khan, Fahad Khan",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.12990"" target=""_blank"">2503.12990</a>",,2025-12-03 22:39:25
Unveiling the Role of Randomization in Multiclass Adversarial Classification: Insights from Graph Theory,"Lucas Gnecco-Heredia, Matteo Sammut, Muni Sreenivas Pydi, Rafael Pinot, Benjamin Negrevergne, Yann Chevaleyre",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.14299"" target=""_blank"">2503.14299</a>",,2025-12-03 22:39:25
ProDiF: Protecting Domain-Invariant Features to Secure Pre-Trained Models Against Extraction,"Tong Zhou, Shijin Duan, Gaowen Liu, Charles Fleming, Ramana Rao Kompella, Shaolei Ren, Xiaolin Xu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.13224"" target=""_blank"">2503.13224</a>",,2025-12-03 22:39:25
GAN-Based Single-Stage Defense for Traffic Sign Classification Under Adversarial Patch Attack,"Abyad Enan, Mashrur Chowdhury",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.12567"" target=""_blank"">2503.12567</a>",,2025-12-03 22:39:25
Algebraic Adversarial Attacks on Explainability Models,"Lachlan Simpson, Federico Costanza, Kyle Millar, Adriel Cheng, Cheng-Chew Lim, Hong Gunn Chew",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.12683"" target=""_blank"">2503.12683</a>",,2025-12-03 22:39:25
SAUCE: Selective Concept Unlearning in Vision-Language Models with Sparse Autoencoders,"Qing Li, Jiahui Geng, Derui Zhu, Fengyu Cai, Chenyang Lyu, Fakhri Karray",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.14530"" target=""_blank"">2503.14530</a>",,2025-12-03 22:39:25
Shape Bias and Robustness Evaluation via Cue Decomposition for Image Classification and Segmentation,"Edgar Heinert, Thomas Gottwald, Annika Mütze, Matthias Rottmann",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.12453"" target=""_blank"">2503.12453</a>",,2025-12-03 22:39:25
Defense Against Model Stealing Based on Account-Aware Distribution Discrepancy,"Jian-Ping Mei, Weibin Zhang, Jie Chen, Xuyun Zhang, Tiantian Zhu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.12497"" target=""_blank"">2503.12497</a>",,2025-12-03 22:39:25
Robust Dataset Distillation by Matching Adversarial Trajectories,"Wei Lai, Tianyu Ding, ren dongdong, Lei Wang, Jing Huo, Yang Gao, Wenbin Li",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.12069"" target=""_blank"">2503.12069</a>",,2025-12-03 22:39:25
Revisiting Training-Inference Trigger Intensity in Backdoor Attacks,"Chenhao Lin, Chenyang Zhao, Shiwei Wang, Longtian Wang, Chao Shen, Zhengyu Zhao",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.12058"" target=""_blank"">2503.12058</a>",,2025-12-03 22:39:25
Tit-for-Tat: Safeguarding Large Vision-Language Models Against Jailbreak Attacks via Adversarial Defense,"Shuyang Hao, Yiwei Wang, Bryan Hooi, Ming-Hsuan Yang, Jun Liu, Chengcheng Tang, Zi Huang, Yujun Cai",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.11619"" target=""_blank"">2503.11619</a>",,2025-12-03 22:39:25
Are Deep Speech Denoising Models Robust to Adversarial Noise? (67%),"Will Schwarzer, Philip S. Thomas, Andrea Fanelli, Xiaoyu Liu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.11627"" target=""_blank"">2503.11627</a>",,2025-12-03 22:39:25
Hi-ALPS -- An Experimental Robustness Quantification of Six LiDAR-based Object Detection Systems for Autonomous Driving,"Alexandra Arzberger, Ramin Tavakoli Kolagari",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.17168"" target=""_blank"">2503.17168</a>",,2025-12-03 22:39:25
Temporal Context Awareness: A Defense Framework Against Multi-turn Manipulation Attacks on Large Language Models,"Prashant Kulkarni, Assaf Namer",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.15560"" target=""_blank"">2503.15560</a>",,2025-12-03 22:39:25
Optimizing ML Training with Metagradient Descent,"Logan Engstrom, Andrew Ilyas, Benjamin Chen, Axel Feldmann, William Moses, Aleksander Madry",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.13751"" target=""_blank"">2503.13751</a>",,2025-12-03 22:39:25
Defending Against Gradient Inversion Attacks for Biomedical Images via Learnable Data Perturbation,"Shiyi Jiang, Farshad Firouzi, Krishnendu Chakrabarty",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.16542"" target=""_blank"">2503.16542</a>",,2025-12-03 22:39:25
From Head to Tail: Efficient Black-box Model Inversion Attack via Long-tailed Learning,"Ziang Li, Hongguang Zhang, Juan Wang, Meihui Chen, Hongxin Hu, Wenzhe Yi, Xiaoyang Xu, Mengda Yang, Chenjun Ma",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.16266"" target=""_blank"">2503.16266</a>",,2025-12-03 22:39:25
"Generating Realistic, Diverse, and Fault-Revealing Inputs with Latent Space Interpolation for Testing Deep Neural Networks","Bin Duan, Matthew B. Dwyer, Guowei Yang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.17630"" target=""_blank"">2503.17630</a>",,2025-12-03 22:39:25
Jailbreaking the Non-Transferable Barrier via Test-Time Data Disguising,"Yongli Xiang, Ziming Hong, Lina Yao, Dadong Wang, Tongliang Liu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.17198"" target=""_blank"">2503.17198</a>",,2025-12-03 22:39:25
Large Language Models Can Verbatim Reproduce Long Malicious Sequences,"Sharon Dj Lin, Dj Krishnamurthy, Dvijotham, Jamie Hayes, Chongyang Shi, Ilia Shumailov, Shuang Song",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.17578"" target=""_blank"">2503.17578</a>",,2025-12-03 22:39:25
Measuring the Robustness of Audio Deepfake Detectors,"Xiang Li, Pin-Yu Chen, Wenqi Wei",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.17577"" target=""_blank"">2503.17577</a>",,2025-12-03 22:39:25
Lie Detector: Unified Backdoor Detection via Cross-Examination Framework,"Xuan Wang, Siyuan Liang, Dongping Liao, Han Fang, Aishan Liu, Xiaochun Cao, Yu-liang Lu, Ee-Chien Chang, Xitong Gao",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.16872"" target=""_blank"">2503.16872</a>",,2025-12-03 22:39:25
XOXO: Stealthy Cross-Origin Context Poisoning Attacks against AI Coding Assistants,"Adam Štorek, Mukur Gupta, Noopur Bhatt, Aditya Gupta, Janie Kim, Prashast Srivastava, Suman Jana",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.14281"" target=""_blank"">2503.14281</a>",,2025-12-03 22:39:25
Principal Eigenvalue Regularization for Improved Worst-Class Certified Robustness of Smoothed Classifiers,"Gaojie Jin, Tianjin Huang, Ronghui Mu, Xiaowei Huang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.17172"" target=""_blank"">2503.17172</a>",,2025-12-03 22:39:25
TEMPO: Temporal Preference Optimization of Video LLMs via Difficulty Scheduling and Pre-SFT Alignment,"Shicheng Li, Lei Li, Kun Ouyang, Shuhuai Ren, Yuanxin Liu, Yuanxing Zhang, Fuzheng Zhang, Lingpeng Kong, Qi Liu, Xu Sun",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.16929"" target=""_blank"">2503.16929</a>",,2025-12-03 22:39:25
Narrowing Class-Wise Robustness Gaps in Adversarial Training,"Fatemeh Amerehi, Patrick Healy",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.16179"" target=""_blank"">2503.16179</a>",,2025-12-03 22:39:25
Real AI Agents with Fake Memories: Fatal Context Manipulation Attacks on Web3 Agents,"Atharv Singh Patlan, Peiyao Sheng, S. Ashwin Hebbar, Prateek Mittal, Pramod Viswanath",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.16248"" target=""_blank"">2503.16248</a>",,2025-12-03 22:39:25
ATOM: A Framework of Detecting Query-Based Model Extraction Attacks for Graph Neural Networks,"Zhan Cheng, Bolin Shen, Tianming Sha, Yuan Gao, Shibo Li, Yushun Dong",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.16693"" target=""_blank"">2503.16693</a>",,2025-12-03 22:39:25
Align in Depth: Defending Jailbreak Attacks via Progressive Answer Detoxification,"Yingjie Zhang, Tong Liu, Zhe Zhao, Guozhu Meng, Kai Chen",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.11185"" target=""_blank"">2503.11185</a>",,2025-12-03 22:39:25
Debugging and Runtime Analysis of Neural Networks with VLMs (A Case Study),"Boyue Caroline Hu, Divya Gopinath, Corina S. Pasareanu, Nina Narodytska, Ravi Mangal, Susmit Jha",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.17416"" target=""_blank"">2503.17416</a>",,2025-12-03 22:39:25
Rethinking the Role of Spatial Mixing,"George Cazenavette, Joel Julin, Simon Lucey",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.16760"" target=""_blank"">2503.16760</a>",,2025-12-03 22:39:25
Test-Time Backdoor Detection for Object Detection Models,"Hangtao Zhang, Yichen Wang, Shihui Yan, Chenyu Zhu, Ziqi Zhou, Linshan Hou, Shengshan Hu, Minghui Li, Yanjun Zhang, Leo Yu Zhang",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.15293"" target=""_blank"">2503.15293</a>",,2025-12-03 22:39:25
A Semantic and Clean-label Backdoor Attack against Graph Convolutional Networks,"Jiazhu Dai, Haoyu Sun",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.14922"" target=""_blank"">2503.14922</a>",,2025-12-03 22:39:25
REVAL: A Comprehension Evaluation on Reliability and Values of Large Vision-Language Models,"Jie Zhang, Zheng Yuan, Zhongqi Wang, Bei Yan, Sibo Wang, Xiangkui Cao, Zonghui Guo, Shiguang Shan, Xilin Chen",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.16566"" target=""_blank"">2503.16566</a>",,2025-12-03 22:39:25
Improving Adversarial Transferability on Vision Transformers via Forward Propagation Refinement,"Yuchen Ren, Zhengyu Zhao, Chenhao Lin, Bo Yang, Lu Zhou, Zhe Liu, Chao Shen",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.15404"" target=""_blank"">2503.15404</a>","<a href=""https://github.com/RYC-98/FPR"" target=""_blank"">RYC-98</a>",2025-12-03 22:39:25
Euclid Quick Data Release (Q1),"Collaboration Euclid, G. School of Physics, HH Wills Physics Laboratory, University of Bristol, Tyndall Avenue, Bristol, BS8 1TL, UK Stevens, S. School of Physics, HH Wills Physics Laboratory, University of Bristol, Tyndall Avenue, Bristol, BS8 1TL, UK Fotopoulou, M. N. School of Physics, HH Wills Physics Laboratory, University of Bristol, Tyndall Avenue, Bristol, BS8 1TL, UK Bremer, T. Matamoro School of Physics, HH Wills Physics Laboratory, University of Bristol, Tyndall Avenue, Bristol, BS8 1TL, UK Zatarain, K. Max-Planck-Institut für Astronomie, Königstuhl 17, 69117 Heidelberg, Germany Jahnke, B. SRON Netherlands Institute for Space Research, Landleven 12, 9747 AD, Groningen, The Netherlands Margalef-Bentabol, M. Instituto de Astrofísica de Canarias, Vía Láctea, 38205 La Laguna, Tenerife, Spain Instituto de Astrofísica de Canarias Université PSL, Observatoire de Paris, Sorbonne Université, CNRS, LERMA, 75014, Paris, France Université Paris-Cité, 5 Rue Thomas Mann, 75013, Paris, France Huertas-Company, M. J. School of Physics, Astronomy and Mathematics, University of Hertfordshire, College Lane, Hatfield AL10 9AB, UK Aspia Space, Falmouth, TR10 9TA, UK Smith, M. David A. Dunlap Department of Astronomy \& Astrophysics, University of Toronto, 50 St George Street, Toronto, Ontario M5S 3H4, Canada Jodrell Bank Centre for Astrophysics, Department of Physics and Astronomy, University of Manchester, Oxford Road, Manchester M13 9PL, UK Walmsley, M. Max Planck Institute for Extraterrestrial Physics, Giessenbachstr. 1, 85748 Garching, Germany Salvato, M. Institute of Space Sciences Institut d'Estudis Espacials de Catalunya Mezcua, A. Centro de Astrofísica da Universidade do Porto, Rua das Estrelas, 4150-762 Porto, Portugal Instituto de Astrofísica e Ciências do Espaço, Universidade do Porto, CAUP, Rua das Estrelas, PT4150-762 Porto, Portugal Paulino-Afonso, M. Instituto de Astrofísica de Canarias Institute of Space Sciences Siudek, M. Dipartimento di Fisica e Astronomia ""Augusto Righi"" - Alma Mater Studiorum Università di Bologna, via Piero Gobetti 93/2, 40129 Bologna, Italy INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Talia, F. Department of Mathematics and Physics, Roma Tre University, Via della Vasca Navale 84, 00146 Rome, Italy INAF-Osservatorio Astronomico di Roma, Via Frascati 33, 00078 Monteporzio Catone, Italy Ricci, W. Max Planck Institute for Extraterrestrial Physics, Giessenbachstr. 1, 85748 Garching, Germany Roster, N. Université Paris-Saclay, CNRS, Institut d'astrophysique spatiale, 91405, Orsay, France Aghanim, B. ESAC/ESA, Camino Bajo del Castillo, s/n., Urb. Villafranca del Castillo, 28692 Villanueva de la Cañada, Madrid, Spain Altieri, S. INAF-Osservatorio Astronomico di Brera, Via Brera 28, 20122 Milano, Italy Andreon, H. Université Paris-Saclay, Université Paris Cité, CEA, CNRS, AIM, 91191, Gif-sur-Yvette, France Aussel, C. IFPU, Institute for Fundamental Physics of the Universe, via Beirut 2, 34151 Trieste, Italy INAF-Osservatorio Astronomico di Trieste, Via G. B. Tiepolo 11, 34143 Trieste, Italy INFN, Sezione di Trieste, Via Valerio 2, 34127 Trieste TS, Italy SISSA, International School for Advanced Studies, Via Bonomea 265, 34136 Trieste TS, Italy Baccigalupi, M. Dipartimento di Fisica e Astronomia, Università di Bologna, Via Gobetti 93/2, 40129 Bologna, Italy INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy INFN-Sezione di Bologna, Viale Berti Pichat 6/2, 40127 Bologna, Italy Baldi, S. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Bardelli, P. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Battaglia, A. INAF-Osservatorio Astronomico di Trieste, Via G. B. Tiepolo 11, 34143 Trieste, Italy IFPU, Institute for Fundamental Physics of the Universe, via Beirut 2, 34151 Trieste, Italy Biviano, A. Space Science Data Center, Italian Space Agency, via del Politecnico snc, 00133 Roma, Italy Bonchi, E. Dipartimento di Fisica, Università di Genova, Via Dodecaneso 33, 16146, Genova, Italy INFN-Sezione di Genova, Via Dodecaneso 33, 16146, Genova, Italy INAF-Osservatorio Astronomico di Brera, Via Brera 28, 20122 Milano, Italy Branchini, M. Department of Physics ""E. Pancini"", University Federico II, Via Cinthia 6, 80126, Napoli, Italy INAF-Osservatorio Astronomico di Capodimonte, Via Moiariello 16, 80131 Napoli, Italy Brescia, J. Instituto de Astrofísica e Ciências do Espaço, Universidade do Porto, CAUP, Rua das Estrelas, PT4150-762 Porto, Portugal Faculdade de Ciências da Universidade do Porto, Rua do Campo de Alegre, 4150-007 Porto, Portugal Brinchmann, S. Dipartimento di Fisica, Università degli Studi di Torino, Via P. Giuria 1, 10125 Torino, Italy INFN-Sezione di Torino, Via P. Giuria 1, 10125 Torino, Italy INAF-Osservatorio Astrofisico di Torino, Via Osservatorio 20, 10025 Pino Torinese Camera, G. European Space Agency/ESTEC, Keplerlaan 1, 2201 AZ Noordwijk, The Netherlands Institute Lorentz, Leiden University, Niels Bohrweg 2, 2333 CA Leiden, The Netherlands Leiden Observatory, Leiden University, Einsteinweg 55, 2333 CC Leiden, The Netherlands Cañas-Herrera, V. INAF-Osservatorio Astrofisico di Torino, Via Osservatorio 20, 10025 Pino Torinese Capobianco, C. INAF-IASF Milano, Via Alfonso Corti 12, 20133 Milano, Italy Carbone, J. Centro de Investigaciones Energéticas, Medioambientales y Tecnológicas Port d'Informació Científica, Campus UAB, C. Albareda s/n, 08193 Bellaterra Carretero, M. INAF-Osservatorio Astronomico di Roma, Via Frascati 33, 00078 Monteporzio Catone, Italy Castellano, G. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Castignani, S. INAF-Osservatorio Astronomico di Capodimonte, Via Moiariello 16, 80131 Napoli, Italy INFN section of Naples, Via Cinthia 6, 80126, Napoli, Italy Cavuoti, K. C. Institute for Astronomy, University of Hawaii, 2680 Woodlawn Drive, Honolulu, HI 96822, USA Chambers, A. Dipartimento di Fisica e Astronomia ""Augusto Righi"" - Alma Mater Studiorum Università di Bologna, Viale Berti Pichat 6/2, 40127 Bologna, Italy Cimatti, C. Instituto de Astrofísica de Canarias, Vía Láctea, 38205 La Laguna, Tenerife, Spain Colodro-Conde, G. Institute for Astronomy, University of Edinburgh, Royal Observatory, Blackford Hill, Edinburgh EH9 3HJ, UK Congedo, C. J. Jodrell Bank Centre for Astrophysics, Department of Physics and Astronomy, University of Manchester, Oxford Road, Manchester M13 9PL, UK Conselice, L. European Space Agency/ESRIN, Largo Galileo Galilei 1, 00044 Frascati, Roma, Italy ESAC/ESA, Camino Bajo del Castillo, s/n., Urb. Villafranca del Castillo, 28692 Villanueva de la Cañada, Madrid, Spain Conversi, Y. Université Claude Bernard Lyon 1, CNRS/IN2P3, IP2I Lyon, UMR 5822, Villeurbanne, F-69100, France Copin, A. Aix-Marseille Université, CNRS, CNES, LAM, Marseille, France Costille, F. Institut de Ciències del Cosmos Institució Catalana de Recerca i Estudis Avançats Courbin, H. M. UCB Lyon 1, CNRS/IN2P3, IUF, IP2I Lyon, 4 rue Enrico Fermi, 69622 Villeurbanne, France Courtois, M. Mullard Space Science Laboratory, University College London, Holmbury St Mary, Dorking, Surrey RH5 6NT, UK Cropper, Silva A. Departamento de Física, Faculdade de Ciências, Universidade de Lisboa, Edifício C8, Campo Grande, PT1749-016 Lisboa, Portugal Instituto de Astrofísica e Ciências do Espaço, Faculdade de Ciências, Universidade de Lisboa, Campo Grande, 1749-016 Lisboa, Portugal Da, H. Department of Astronomy, University of Geneva, ch. d'Ecogia 16, 1290 Versoix, Switzerland Degaudenzi, Lucia G. INAF-Osservatorio Astronomico di Trieste, Via G. B. Tiepolo 11, 34143 Trieste, Italy De, C. Mullard Space Science Laboratory, University College London, Holmbury St Mary, Dorking, Surrey RH5 6NT, UK Dolding, H. Université Paris-Saclay, CNRS, Institut d'astrophysique spatiale, 91405, Orsay, France Dole, M. Université Paris-Saclay, CNRS, Institut d'astrophysique spatiale, 91405, Orsay, France Douspis, F. Department of Astronomy, University of Geneva, ch. d'Ecogia 16, 1290 Versoix, Switzerland Dubath, X. ESAC/ESA, Camino Bajo del Castillo, s/n., Urb. Villafranca del Castillo, 28692 Villanueva de la Cañada, Madrid, Spain Dupac, S. INFN-Padova, Via Marzolo 8, 35131 Padova, Italy Dusini, S. Aix-Marseille Université, CNRS/IN2P3, CPPM, Marseille, France Escoffier, M. INAF-Istituto di Astrofisica e Planetologia Spaziali, via del Fosso del Cavaliere, 100, 00100 Roma, Italy Farina, S. Université Claude Bernard Lyon 1, CNRS/IN2P3, IP2I Lyon, UMR 5822, Villeurbanne, F-69100, France Ferriol, K. Universitäts-Sternwarte München, Fakultät für Physik, Ludwig-Maximilians-Universität München, Scheinerstrasse 1, 81679 München, Germany George, C. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy INFN-Sezione di Bologna, Viale Berti Pichat 6/2, 40127 Bologna, Italy Giocoli, B. R. INAF-Osservatorio Astronomico di Brera, Via Brera 28, 20122 Milano, Italy Granett, A. INAF-Osservatorio Astronomico di Padova, Via dell'Osservatorio 5, 35122 Padova, Italy Grazian, F. Max Planck Institute for Extraterrestrial Physics, Giessenbachstr. 1, 85748 Garching, Germany Universitäts-Sternwarte München, Fakultät für Physik, Ludwig-Maximilians-Universität München, Scheinerstrasse 1, 81679 München, Germany Grupp, S. V. H. Institute of Theoretical Astrophysics, University of Oslo, P.O. Box 1029 Blindern, 0315 Oslo, Norway Haugan, I. M. Department of Physics, Lancaster University, Lancaster, LA1 4YB, UK Hook, F. Felix Hormuth Engineering, Goethestr. 17, 69181 Leimen, Germany Hormuth, A. Technical University of Denmark, Elektrovej 327, 2800 Kgs. Lyngby, Denmark Cosmic Dawn Center Hornstrup, P. Institut d'Astrophysique de Paris, UMR 7095, CNRS, and Sorbonne Université, 98 bis boulevard Arago, 75014 Paris, France Hudelot, M. NASA Goddard Space Flight Center, Greenbelt, MD 20771, USA Jhabvala, E. Department of Physics and Helsinki Institute of Physics, Gustaf Hällströmin katu 2, 00014 University of Helsinki, Finland Keihänen, S. Aix-Marseille Université, CNRS/IN2P3, CPPM, Marseille, France Kermiche, A. Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Drive, Pasadena, CA, 91109, USA Kiessling, M. Université Paris-Saclay, Université Paris Cité, CEA, CNRS, AIM, 91191, Gif-sur-Yvette, France Kilbinger, B. Université Claude Bernard Lyon 1, CNRS/IN2P3, IP2I Lyon, UMR 5822, Villeurbanne, F-69100, France Kubik, M. Universitäts-Sternwarte München, Fakultät für Physik, Ludwig-Maximilians-Universität München, Scheinerstrasse 1, 81679 München, Germany Kümmel, H. Department of Physics, P.O. Box 64, 00014 University of Helsinki, Finland Helsinki Institute of Physics, Gustaf Hällströmin katu 2, University of Helsinki, Helsinki, Finland Kurki-Suonio, Q. Le Centre de Calcul de l'IN2P3/CNRS, 21 avenue Pierre de Coubertin 69627 Villeurbanne Cedex, France Boulc'h, A. M. C. Le Laboratoire d'etude de l'Univers et des phenomenes eXtremes, Observatoire de Paris, Université PSL, Sorbonne Université, CNRS, 92190 Meudon, France Brun, D. Le Aix-Marseille Université, CNRS, CNES, LAM, Marseille, France Mignant, P. B. Institute of Theoretical Astrophysics, University of Oslo, P.O. Box 1029 Blindern, 0315 Oslo, Norway Lilje, V. Department of Physics, P.O. Box 64, 00014 University of Helsinki, Finland Helsinki Institute of Physics, Gustaf Hällströmin katu 2, University of Helsinki, Helsinki, Finland Lindholm, I. SKA Observatory, Jodrell Bank, Lower Withington, Macclesfield, Cheshire SK11 9FT, UK Lloro, G. Centre de Calcul de l'IN2P3/CNRS, 21 avenue Pierre de Coubertin 69627 Villeurbanne Cedex, France Mainetti, D. Dipartimento di Fisica ""Aldo Pontremoli"", Università degli Studi di Milano, Via Celoria 16, 20133 Milano, Italy INAF-IASF Milano, Via Alfonso Corti 12, 20133 Milano, Italy INFN-Sezione di Milano, Via Celoria 16, 20133 Milano, Italy Maino, E. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Maiorano, O. Universität Bonn, Argelander-Institut für Astronomie, Auf dem Hügel 71, 53121 Bonn, Germany Marggraf, M. INAF-Osservatorio Astronomico di Roma, Via Frascati 33, 00078 Monteporzio Catone, Italy INFN-Sezione di Roma, Piazzale Aldo Moro, 2 - c/o Dipartimento di Fisica, Edificio G. Marconi, 00185 Roma, Italy Martinelli, N. Aix-Marseille Université, CNRS, CNES, LAM, Marseille, France Martinet, F. Dipartimento di Fisica e Astronomia ""Augusto Righi"" - Alma Mater Studiorum Università di Bologna, via Piero Gobetti 93/2, 40129 Bologna, Italy INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy INFN-Sezione di Bologna, Viale Berti Pichat 6/2, 40127 Bologna, Italy Marulli, R. Department of Physics, Institute for Computational Cosmology, Durham University, South Road, Durham, DH1 3LE, UK Massey, S. Université Côte d'Azur, Observatoire de la Côte d'Azur, CNRS, Laboratoire Lagrange, Bd de l'Observatoire, CS 34229, 06304 Nice cedex 4, France Maurogordato, H. J. Institut d'Astrophysique de Paris, UMR 7095, CNRS, and Sorbonne Université, 98 bis boulevard Arago, 75014 Paris, France McCracken, E. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Medinaceli, S. Université Paris Cité, CNRS, Astroparticule et Cosmologie, 75013 Paris, France CNRS-UCB International Research Laboratory, Centre Pierre Binetruy, IRL2007, CPB-IN2P3, Berkeley, USA Mei, M. University of Applied Sciences and Arts of Northwestern Switzerland, School of Engineering, 5210 Windisch, Switzerland Melchior, M. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy INFN-Sezione di Bologna, Viale Berti Pichat 6/2, 40127 Bologna, Italy Meneghetti, E. INAF-Osservatorio Astronomico di Roma, Via Frascati 33, 00078 Monteporzio Catone, Italy Merlin, G. Institute of Physics, Laboratory of Astrophysics, Ecole Polytechnique Fédérale de Lausanne Meylan, A. Aurora Technology for European Space Agency Mora, M. Dipartimento di Fisica e Astronomia ""Augusto Righi"" - Alma Mater Studiorum Università di Bologna, via Piero Gobetti 93/2, 40129 Bologna, Italy INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Moresco, L. Dipartimento di Fisica e Astronomia ""Augusto Righi"" - Alma Mater Studiorum Università di Bologna, via Piero Gobetti 93/2, 40129 Bologna, Italy INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy INFN-Sezione di Bologna, Viale Berti Pichat 6/2, 40127 Bologna, Italy Moscardini, R. Universität Bonn, Argelander-Institut für Astronomie, Auf dem Hügel 71, 53121 Bonn, Germany Nakajima, C. Institut de Física d'Altes Energies Port d'Informació Científica, Campus UAB, C. Albareda s/n, 08193 Bellaterra Neissner, S. -M. European Space Agency/ESTEC, Keplerlaan 1, 2201 AZ Noordwijk, The Netherlands Niemi, C. Institut de Física d'Altes Energies Padilla, S. Department of Astronomy, University of Geneva, ch. d'Ecogia 16, 1290 Versoix, Switzerland Paltani, F. INAF-Osservatorio Astronomico di Trieste, Via G. B. Tiepolo 11, 34143 Trieste, Italy Pasian, K. DARK, Niels Bohr Institute, University of Copenhagen, Jagtvej 155, 2200 Copenhagen, Denmark Pedersen, W. J. Waterloo Centre for Astrophysics, University of Waterloo, Waterloo, Ontario N2L 3G1, Canada Department of Physics and Astronomy, University of Waterloo, Waterloo, Ontario N2L 3G1, Canada Perimeter Institute for Theoretical Physics, Waterloo, Ontario N2L 2Y5, Canada Percival, V. European Space Agency/ESTEC, Keplerlaan 1, 2201 AZ Noordwijk, The Netherlands Pettorino, G. Space Science Data Center, Italian Space Agency, via del Politecnico snc, 00133 Roma, Italy Polenta, M. Centre National d'Etudes Spatiales -- Centre spatial de Toulouse, 18 avenue Edouard Belin, 31401 Toulouse Cedex 9, France Poncet, L. A. Institute of Space Science, Str. Atomistilor, nr. 409 Măgurele, Ilfov, 077125, Romania Popa, L. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Pozzetti, F. Max Planck Institute for Extraterrestrial Physics, Giessenbachstr. 1, 85748 Garching, Germany Raison, R. Instituto de Astrofísica de Canarias, Vía Láctea, 38205 La Laguna, Tenerife, Spain Consejo Superior de Investigaciones Cientificas, Calle Serrano 117, 28006 Madrid, Spain Universidad de La Laguna, Departamento de Astrofísica, 38206 La Laguna, Tenerife, Spain Rebolo, A. Dipartimento di Fisica e Astronomia ""G. Galilei"", Università di Padova, Via Marzolo 8, 35131 Padova, Italy INFN-Padova, Via Marzolo 8, 35131 Padova, Italy Renzi, J. Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Drive, Pasadena, CA, 91109, USA Rhodes, G. INAF-Osservatorio Astronomico di Capodimonte, Via Moiariello 16, 80131 Napoli, Italy Riccio, E. INAF-Osservatorio Astronomico di Trieste, Via G. B. Tiepolo 11, 34143 Trieste, Italy Romelli, M. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Roncarelli, R. Universitäts-Sternwarte München, Fakultät für Physik, Ludwig-Maximilians-Universität München, Scheinerstrasse 1, 81679 München, Germany Max Planck Institute for Extraterrestrial Physics, Giessenbachstr. 1, 85748 Garching, Germany Saglia, A. G. Max Planck Institute for Extraterrestrial Physics, Giessenbachstr. 1, 85748 Garching, Germany Sánchez, D. Departamento de Física, FCFM, Universidad de Chile, Blanco Encalada 2008, Santiago, Chile Sapone, J. A. Institute for Astronomy, University of Edinburgh, Royal Observatory, Blackford Hill, Edinburgh EH9 3HJ, UK Schewtschenko, M. Max-Planck-Institut für Astronomie, Königstuhl 17, 69117 Heidelberg, Germany Schirmer, P. Universität Bonn, Argelander-Institut für Astronomie, Auf dem Hügel 71, 53121 Bonn, Germany Schneider, T. Universität Innsbruck, Institut für Astro- und Teilchenphysik, Technikerstr. 25/8, 6020 Innsbruck, Austria Schrabback, A. Aix-Marseille Université, CNRS/IN2P3, CPPM, Marseille, France Secroun, S. Institut d'Estudis Espacials de Catalunya Satlantis, University Science Park, Sede Bld 48940, Leioa-Bilbao, Spain Institute of Space Sciences Serrano, P. Universität Bonn, Argelander-Institut für Astronomie, Auf dem Hügel 71, 53121 Bonn, Germany Simon, C. Dipartimento di Fisica e Astronomia ""G. Galilei"", Università di Padova, Via Marzolo 8, 35131 Padova, Italy INFN-Padova, Via Marzolo 8, 35131 Padova, Italy Sirignano, G. INFN-Sezione di Bologna, Viale Berti Pichat 6/2, 40127 Bologna, Italy Sirri, J. Centre for Electronic Imaging, Open University, Walton Hall, Milton Keynes, MK7~6AA, UK Skottfelt, L. INFN-Padova, Via Marzolo 8, 35131 Padova, Italy Stanco, J. Max Planck Institute for Extraterrestrial Physics, Giessenbachstr. 1, 85748 Garching, Germany Steinwagner, P. Centro de Investigaciones Energéticas, Medioambientales y Tecnológicas Port d'Informació Científica, Campus UAB, C. Albareda s/n, 08193 Bellaterra Tallada-Crespí, A. N. Institute for Astronomy, University of Edinburgh, Royal Observatory, Blackford Hill, Edinburgh EH9 3HJ, UK Taylor, I. Departamento de Física, Faculdade de Ciências, Universidade de Lisboa, Edifício C8, Campo Grande, PT1749-016 Lisboa, Portugal Instituto de Astrofísica e Ciências do Espaço, Faculdade de Ciências, Universidade de Lisboa, Tapada da Ajuda, 1349-018 Lisboa, Portugal Tereno, S. Cosmic Dawn Center Niels Bohr Institute, University of Copenhagen, Jagtvej 128, 2200 Copenhagen, Denmark Toft, R. Universidad Politécnica de Cartagena, Departamento de Electrónica y Tecnología de Computadoras, Plaza del Hospital 1, 30202 Cartagena, Spain Toledo-Moreo, F. Port d'Informació Científica, Campus UAB, C. Albareda s/n, 08193 Bellaterra Centro de Investigaciones Energéticas, Medioambientales y Tecnológicas Torradeflot, I. Institut de Recherche en Astrophysique et Planétologie Tutusaus, L. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy INFN-Bologna, Via Irnerio 46, 40126 Bologna, Italy Valenziano, J. Department of Physics, P.O. Box 64, 00014 University of Helsinki, Finland Helsinki Institute of Physics, Gustaf Hällströmin katu 2, University of Helsinki, Helsinki, Finland Valiviita, T. Universitäts-Sternwarte München, Fakultät für Physik, Ludwig-Maximilians-Universität München, Scheinerstrasse 1, 81679 München, Germany INAF-Osservatorio Astronomico di Trieste, Via G. B. Tiepolo 11, 34143 Trieste, Italy Vassallo, G. Verdoes Kapteyn Astronomical Institute, University of Groningen, PO Box 800, 9700 AV Groningen, The Netherlands Kleijn, A. INAF-Osservatorio Astronomico di Brera, Via Brera 28, 20122 Milano, Italy INFN-Sezione di Genova, Via Dodecaneso 33, 16146, Genova, Italy Dipartimento di Fisica, Università di Genova, Via Dodecaneso 33, 16146, Genova, Italy Veropalumbo, Y. Infrared Processing and Analysis Center, California Institute of Technology, Pasadena, CA 91125, USA Wang, J. Universitäts-Sternwarte München, Fakultät für Physik, Ludwig-Maximilians-Universität München, Scheinerstrasse 1, 81679 München, Germany Max Planck Institute for Extraterrestrial Physics, Giessenbachstr. 1, 85748 Garching, Germany Weller, A. INAF-Osservatorio Astronomico di Trieste, Via G. B. Tiepolo 11, 34143 Trieste, Italy IFPU, Institute for Fundamental Physics of the Universe, via Beirut 2, 34151 Trieste, Italy Zacchei, G. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Zamorani, F. M. INAF-Osservatorio Astronomico di Brera, Via Brera 28, 20122 Milano, Italy Zerbi, I. A. Universitäts-Sternwarte München, Fakultät für Physik, Ludwig-Maximilians-Universität München, Scheinerstrasse 1, 81679 München, Germany Zinchenko, E. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Zucca, V. INAF-Osservatorio Astronomico di Capodimonte, Via Moiariello 16, 80131 Napoli, Italy Allevato, M. Dipartimento di Fisica e Scienze della Terra, Università degli Studi di Ferrara, Via Giuseppe Saragat 1, 44122 Ferrara, Italy Istituto Nazionale di Fisica Nucleare, Sezione di Ferrara, Via Giuseppe Saragat 1, 44122 Ferrara, Italy INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Ballardini, M. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Bolzonella, E. Department of Astronomy, University of Geneva, ch. d'Ecogia 16, 1290 Versoix, Switzerland Bozzo, C. INAF, Istituto di Radioastronomia, Via Piero Gobetti 101, 40129 Bologna, Italy INFN-Bologna, Via Irnerio 46, 40126 Bologna, Italy Burigana, R. Institut de Recherche en Astrophysique et Planétologie Cabanac, A. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Université Côte d'Azur, Observatoire de la Côte d'Azur, CNRS, Laboratoire Lagrange, Bd de l'Observatoire, CS 34229, 06304 Nice cedex 4, France Cappi, J. A. Escartin Max Planck Institute for Extraterrestrial Physics, Giessenbachstr. 1, 85748 Garching, Germany Vigo, L. Department of Physics, Oxford University, Keble Road, Oxford OX1 3RH, UK Gabarra, W. G. Department of Astronomy, University of Geneva, ch. d'Ecogia 16, 1290 Versoix, Switzerland Hartley, J. Aurora Technology for European Space Agency Martín-Fleitas, S. Institute for Astronomy, University of Edinburgh, Royal Observatory, Blackford Hill, Edinburgh EH9 3HJ, UK Matthew, R. B. Dipartimento di Fisica e Astronomia ""Augusto Righi"" - Alma Mater Studiorum Università di Bologna, via Piero Gobetti 93/2, 40129 Bologna, Italy INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Metcalf, A. INAF - Osservatorio Astronomico di Brera, via Emilio Bianchi 46, 23807 Merate, Italy Max Planck Institute for Extraterrestrial Physics, Giessenbachstr. 1, 85748 Garching, Germany Pezzotta, M. Department of Physics, P.O. Box 64, 00014 University of Helsinki, Finland Pöntinen, I. INAF-Osservatorio Astronomico di Brera, Via Brera 28, 20122 Milano, Italy, and INFN-Sezione di Genova, Via Dodecaneso 33, 16146, Genova, Italy Risso, V. Institut d'Astrophysique de Paris, 98bis Boulevard Arago, 75014, Paris, France ICL, Junia, Université Catholique de Lille, LITL, 59000 Lille, France Scottez, M. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy INFN-Sezione di Bologna, Viale Berti Pichat 6/2, 40127 Bologna, Italy Sereno, M. INFN-Sezione di Bologna, Viale Berti Pichat 6/2, 40127 Bologna, Italy Tenti, M. Institute of Theoretical Astrophysics, University of Oslo, P.O. Box 1029 Blindern, 0315 Oslo, Norway Wiesmann, Y. Instituto de Física Teórica UAM-CSIC, Campus de Cantoblanco, 28049 Madrid, Spain CERCA/ISO, Department of Physics, Case Western Reserve University, 10900 Euclid Avenue, Cleveland, OH 44106, USA Akrami, S. Dipartimento di Fisica e Scienze della Terra, Università degli Studi di Ferrara, Via Giuseppe Saragat 1, 44122 Ferrara, Italy Alvi, I. T. Technical University of Munich, TUM School of Natural Sciences, Physics Department, James-Franck-Str.~1, 85748 Garching, Germany Max-Planck-Institut für Astrophysik, Karl-Schwarzschild-Str.~1, 85748 Garching, Germany Andika, S. INFN-Padova, Via Marzolo 8, 35131 Padova, Italy Dipartimento di Fisica e Astronomia ""G. Galilei"", Università di Padova, Via Marzolo 8, 35131 Padova, Italy Laboratoire Univers et Théorie, Observatoire de Paris, Université PSL, Université Paris Cité, CNRS, 92190 Meudon, France Anselmi, M. Dipartimento di Fisica ""Aldo Pontremoli"", Università degli Studi di Milano, Via Celoria 16, 20133 Milano, Italy INFN-Sezione di Milano, Via Celoria 16, 20133 Milano, Italy Archidiacono, F. Departamento de Física Fundamental. Universidad de Salamanca. Plaza de la Merced s/n. 37008 Salamanca, Spain Atrio-Barandela, D. Dipartimento di Fisica e Astronomia ""G. Galilei"", Università di Padova, Via Marzolo 8, 35131 Padova, Italy INAF-Osservatorio Astronomico di Padova, Via dell'Osservatorio 5, 35122 Padova, Italy INFN-Padova, Via Marzolo 8, 35131 Padova, Italy Bertacca, M. Université de Strasbourg, CNRS, Observatoire astronomique de Strasbourg, UMR 7550, 67000 Strasbourg, France Bethermin, L. INAF-Osservatorio Astronomico di Padova, Via dell'Osservatorio 5, 35122 Padova, Italy Bisigello, A. Institut de Recherche en Astrophysique et Planétologie Blanchard, L. Center for Data-Driven Discovery, Kavli IPMU Laboratoire d'etude de l'Univers et des phenomenes eXtremes, Observatoire de Paris, Université PSL, Sorbonne Université, CNRS, 92190 Meudon, France Blot, S. Dipartimento di Fisica - Sezione di Astronomia, Università di Trieste, Via Tiepolo 11, 34131 Trieste, Italy IFPU, Institute for Fundamental Physics of the Universe, via Beirut 2, 34151 Trieste, Italy INAF-Osservatorio Astronomico di Trieste, Via G. B. Tiepolo 11, 34143 Trieste, Italy INFN, Sezione di Trieste, Via Valerio 2, 34127 Trieste TS, Italy ICSC - Centro Nazionale di Ricerca in High Performance Computing, Big Data e Quantum Computing, Via Magnanelli 2, Bologna, Italy Borgani, M. L. Jodrell Bank Centre for Astrophysics, Department of Physics and Astronomy, University of Manchester, Oxford Road, Manchester M13 9PL, UK Brown, S. California Institute of Technology, 1200 E California Blvd, Pasadena, CA 91125, USA Bruton, A. INAF-Osservatorio Astronomico di Roma, Via Frascati 33, 00078 Monteporzio Catone, Italy Calabro, F. INAF-Osservatorio Astronomico di Roma, Via Frascati 33, 00078 Monteporzio Catone, Italy Caro, T. INAF-Osservatorio Astronomico di Trieste, Via G. B. Tiepolo 11, 34143 Trieste, Italy INFN, Sezione di Trieste, Via Valerio 2, 34127 Trieste TS, Italy IFPU, Institute for Fundamental Physics of the Universe, via Beirut 2, 34151 Trieste, Italy ICSC - Centro Nazionale di Ricerca in High Performance Computing, Big Data e Quantum Computing, Via Magnanelli 2, Bologna, Italy Castro, F. Dipartimento di Fisica e Astronomia ""Augusto Righi"" - Alma Mater Studiorum Università di Bologna, via Piero Gobetti 93/2, 40129 Bologna, Italy INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Cogato, S. INFN-Sezione di Genova, Via Dodecaneso 33, 16146, Genova, Italy Davini, G. Kapteyn Astronomical Institute, University of Groningen, PO Box 800, 9700 AV Groningen, The Netherlands Desprez, A. Departamento Física Aplicada, Universidad Politécnica de Cartagena, Campus Muralla del Mar, 30202 Cartagena, Murcia, Spain Díaz-Sánchez, J. J. Instituto de Astrofísica de Canarias, Vía Láctea, 38205 La Laguna, Tenerife, Spain Diaz, Domizio S. Dipartimento di Fisica, Università di Genova, Via Dodecaneso 33, 16146, Genova, Italy INFN-Sezione di Genova, Via Dodecaneso 33, 16146, Genova, Italy Di, J. M. Instituto de Física de Cantabria, Edificio Juan Jordá, Avenida de los Castros, 39005 Santander, Spain Diego, P. -A. Université de Strasbourg, CNRS, Observatoire astronomique de Strasbourg, UMR 7550, 67000 Strasbourg, France Duc, A. Dipartimento di Fisica e Astronomia, Università di Bologna, Via Gobetti 93/2, 40129 Bologna, Italy INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Enia, Y. Universitäts-Sternwarte München, Fakultät für Physik, Ludwig-Maximilians-Universität München, Scheinerstrasse 1, 81679 München, Germany Fang, A. G. INFN-Sezione di Bologna, Viale Berti Pichat 6/2, 40127 Bologna, Italy Ferrari, A. Department of Physics, P.O. Box 64, 00014 University of Helsinki, Finland Finoguenov, A. INAF-Osservatorio Astronomico di Roma, Via Frascati 33, 00078 Monteporzio Catone, Italy Fontana, A. INFN, Sezione di Lecce, Via per Arnesano, CP-193, 73100, Lecce, Italy Department of Mathematics and Physics E. De Giorgi, University of Salento, Via per Arnesano, CP-I93, 73100, Lecce, Italy INAF-Sezione di Lecce, c/o Dipartimento Matematica e Fisica, Via per Arnesano, 73100, Lecce, Italy Franco, J. Instituto de Física Teórica UAM-CSIC, Campus de Cantoblanco, 28049 Madrid, Spain García-Bellido, T. INAF-Osservatorio Astronomico di Trieste, Via G. B. Tiepolo 11, 34143 Trieste, Italy Gasparetto, V. CEA Saclay, DFR/IRFU, Service d'Astrophysique, Bat. 709, 91191 Gif-sur-Yvette, France Gautard, E. Institute of Space Sciences Institut d'Estudis Espacials de Catalunya Institute of Cosmology and Gravitation, University of Portsmouth, Portsmouth PO1 3FX, UK Gaztanaga, F. INFN-Sezione di Bologna, Viale Berti Pichat 6/2, 40127 Bologna, Italy Giacomini, F. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Gianotti, M. Dipartimento di Fisica e Astronomia, Università di Bologna, Via Gobetti 93/2, 40129 Bologna, Italy INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Guidi, C. M. Instituto de Astrofí sica de Canarias, c/ Via Lactea s/n, La Laguna 38200, Spain. Departamento de Astrofí sica de la Universidad de La Laguna, Avda. Francisco Sanchez, La Laguna, 38200, Spain Gutierrez, A. Institute for Astronomy, University of Edinburgh, Royal Observatory, Blackford Hill, Edinburgh EH9 3HJ, UK Hall, S. Caltech/IPAC, 1200 E. California Blvd., Pasadena, CA 91125, USA Hemmati, H. Ruhr University Bochum, Faculty of Physics and Astronomy, Astronomical Institute Hildebrandt, J. DARK, Niels Bohr Institute, University of Copenhagen, Jagtvej 155, 2200 Copenhagen, Denmark Hjorth, J. J. E. Department of Physics and Astronomy, Vesilinnantie 5, 20014 University of Turku, Finland Serco for European Space Agency Kajava, Y. Department of Astronomy, University of Geneva, ch. d'Ecogia 16, 1290 Versoix, Switzerland Kang, V. ARC Centre of Excellence for Dark Matter Particle Physics, Melbourne, Australia Centre for Astrophysics \& Supercomputing, Swinburne University of Technology, Hawthorn, Victoria 3122, Australia Kansal, D. Dipartimento di Fisica e Scienze della Terra, Università degli Studi di Ferrara, Via Giuseppe Saragat 1, 44122 Ferrara, Italy Department of Physics and Astronomy, University of the Western Cape, Bellville, Cape Town, 7535, South Africa Karagiannis, C. C. Department of Physics and Helsinki Institute of Physics, Gustaf Hällströmin katu 2, 00014 University of Helsinki, Finland Kirkpatrick, S. ESAC/ESA, Camino Bajo del Castillo, s/n., Urb. Villafranca del Castillo, 28692 Villanueva de la Cañada, Madrid, Spain Kruk, L. DAMTP, Centre for Mathematical Sciences, Wilberforce Road, Cambridge CB3 0WA, UK Kavli Institute for Cosmology Cambridge, Madingley Road, Cambridge, CB3 0HA, UK Legrand, M. Dipartimento di Fisica e Scienze della Terra, Università degli Studi di Ferrara, Via Giuseppe Saragat 1, 44122 Ferrara, Italy Istituto Nazionale di Fisica Nucleare, Sezione di Ferrara, Via Giuseppe Saragat 1, 44122 Ferrara, Italy Lembo, F. Department of Astrophysics, University of Zurich, Winterthurerstrasse 190, 8057 Zurich, Switzerland Lepori, G. Department of Physics, Centre for Extragalactic Astronomy, Durham University, South Road, Durham, DH1 3LE, UK Department of Physics, Institute for Computational Cosmology, Durham University, South Road, Durham, DH1 3LE, UK Leroy, J. Institute for Theoretical Particle Physics and Cosmology Lesgourgues, L. Dipartimento di Fisica e Astronomia ""Augusto Righi"" - Alma Mater Studiorum Università di Bologna, via Piero Gobetti 93/2, 40129 Bologna, Italy INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Leuzzi, T. I. IRFU, CEA, Université Paris-Saclay 91191 Gif-sur-Yvette Cedex, France Liaudat, J. Univ. Grenoble Alpes, CNRS, Grenoble INP, LPSC-IN2P3, 53, Avenue des Martyrs, 38000, Grenoble, France Macias-Perez, M. INAF-Istituto di Astrofisica e Planetologia Spaziali, via del Fosso del Cavaliere, 100, 00100 Roma, Italy Magliocchetti, F. INAF-Osservatorio Astrofisico di Arcetri, Largo E. Fermi 5, 50125, Firenze, Italy Mannucci, R. Dipartimento di Fisica, Sapienza Università di Roma, Piazzale Aldo Moro 2, 00185 Roma, Italy INAF-Osservatorio Astronomico di Roma, Via Frascati 33, 00078 Monteporzio Catone, Italy Maoli, C. J. A. P. Centro de Astrofísica da Universidade do Porto, Rua das Estrelas, 4150-762 Porto, Portugal Instituto de Astrofísica e Ciências do Espaço, Universidade do Porto, CAUP, Rua das Estrelas, PT4150-762 Porto, Portugal Martins, L. Université Paris-Saclay, CNRS, Institut d'astrophysique spatiale, 91405, Orsay, France Maurin, M. ESAC/ESA, Camino Bajo del Castillo, s/n., Urb. Villafranca del Castillo, 28692 Villanueva de la Cañada, Madrid, Spain HE Space for European Space Agency Miluzio, P. Dipartimento di Fisica - Sezione di Astronomia, Università di Trieste, Via Tiepolo 11, 34131 Trieste, Italy INAF-Osservatorio Astronomico di Trieste, Via G. B. Tiepolo 11, 34143 Trieste, Italy INFN, Sezione di Trieste, Via Valerio 2, 34127 Trieste TS, Italy IFPU, Institute for Fundamental Physics of the Universe, via Beirut 2, 34151 Trieste, Italy Monaco, G. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Morgante, K. Institute of Cosmology and Gravitation, University of Portsmouth, Portsmouth PO1 3FX, UK Naidoo, A. Universität Bonn, Argelander-Institut für Astronomie, Auf dem Hügel 71, 53121 Bonn, Germany Navarro-Alsina, F. Dipartimento di Fisica e Astronomia ""G. Galilei"", Università di Padova, Via Marzolo 8, 35131 Padova, Italy INFN-Padova, Via Marzolo 8, 35131 Padova, Italy Passalacqua, K. Max-Planck-Institut für Astronomie, Königstuhl 17, 69117 Heidelberg, Germany Paterson, L. INFN-Sezione di Bologna, Viale Berti Pichat 6/2, 40127 Bologna, Italy Patrizii, A. Aix-Marseille Université, CNRS/IN2P3, CPPM, Marseille, France Pisani, D. Department of Astrophysics, University of Zurich, Winterthurerstrasse 190, 8057 Zurich, Switzerland Potter, S. Dipartimento di Fisica e Astronomia ""Augusto Righi"" - Alma Mater Studiorum Università di Bologna, via Piero Gobetti 93/2, 40129 Bologna, Italy INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Quai, M. INAF-Osservatorio Astronomico di Padova, Via dell'Osservatorio 5, 35122 Padova, Italy Radovich, P. -F. Université Paris-Saclay, CNRS, Institut d'astrophysique spatiale, 91405, Orsay, France Rocci, G. Dipartimento di Fisica e Astronomia ""G. Galilei"", Università di Padova, Via Marzolo 8, 35131 Padova, Italy INAF-Osservatorio Astronomico di Padova, Via dell'Osservatorio 5, 35122 Padova, Italy Rodighiero, S. Department of Mathematics and Physics E. De Giorgi, University of Salento, Via per Arnesano, CP-I93, 73100, Lecce, Italy INFN, Sezione di Lecce, Via per Arnesano, CP-193, 73100, Lecce, Italy INAF-Sezione di Lecce, c/o Dipartimento Matematica e Fisica, Via per Arnesano, 73100, Lecce, Italy Sacquegna, M. Theoretical astrophysics, Department of Physics and Astronomy, Uppsala University, Box 515, 751 20 Uppsala, Sweden Sahlén, D. B. Institute for Astronomy, University of Hawaii, 2680 Woodlawn Drive, Honolulu, HI 96822, USA Sanders, E. SISSA, International School for Advanced Studies, Via Bonomea 265, 34136 Trieste TS, Italy ICSC - Centro Nazionale di Ricerca in High Performance Computing, Big Data e Quantum Computing, Via Magnanelli 2, Bologna, Italy INFN, Sezione di Trieste, Via Valerio 2, 34127 Trieste TS, Italy Sarpa, A. Department of Astrophysics, University of Zurich, Winterthurerstrasse 190, 8057 Zurich, Switzerland Schneider, M. Université Côte d'Azur, Observatoire de la Côte d'Azur, CNRS, Laboratoire Lagrange, Bd de l'Observatoire, CS 34229, 06304 Nice cedex 4, France Schultheis, D. INAF-Osservatorio Astronomico di Roma, Via Frascati 33, 00078 Monteporzio Catone, Italy INFN-Sezione di Roma, Piazzale Aldo Moro, 2 - c/o Dipartimento di Fisica, Edificio G. Marconi, 00185 Roma, Italy Sciotti, E. Mathematical Institute, University of Leiden, Einsteinweg 55, 2333 CA Leiden, The Netherlands Leiden Observatory, Leiden University, Einsteinweg 55, 2333 CC Leiden, The Netherlands Sellentin, F. School of Physics \& Astronomy, University of Southampton, Highfield Campus, Southampton SO17 1BJ, UK Shankar, L. C. Institute of Astronomy, University of Cambridge, Madingley Road, Cambridge CB3 0HA, UK Smith, K. Department of Physics, Oxford University, Keble Road, Oxford OX1 3RH, UK Tanidis, G. INFN-Sezione di Genova, Via Dodecaneso 33, 16146, Genova, Italy Testera, R. Department of Astrophysical Sciences, Peyton Hall, Princeton University, Princeton, NJ 08544, USA Teyssier, S. Dipartimento di Fisica, Università di Genova, Via Dodecaneso 33, 16146, Genova, Italy INFN-Sezione di Genova, Via Dodecaneso 33, 16146, Genova, Italy INAF-Osservatorio Astronomico di Brera, Via Brera 28, 20122 Milano, Italy Tosi, A. Dipartimento di Fisica e Astronomia ""G. Galilei"", Università di Padova, Via Marzolo 8, 35131 Padova, Italy INFN-Padova, Via Marzolo 8, 35131 Padova, Italy Troja, M. Department of Astronomy, University of Geneva, ch. d'Ecogia 16, 1290 Versoix, Switzerland Tucci, C. INFN-Sezione di Bologna, Viale Berti Pichat 6/2, 40127 Bologna, Italy Valieri, D. INAF-Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Via Piero Gobetti 93/3, 40129 Bologna, Italy Vergani, G. Center for Computational Astrophysics, Flatiron Institute, 162 5th Avenue, 10010, New York, NY, USA Verza, N. A. Institute of Astronomy, University of Cambridge, Madingley Road, Cambridge CB3 0HA, UK Walton",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.15321"" target=""_blank"">2503.15321</a>",,2025-12-03 22:39:25
Make the Most of Everything: Further Considerations on Disrupting Diffusion-based Customization,"Long Tang, Dengpan Ye, Sirun Chen, Xiuwen Shi, Yunna Lv, Ziyi Liu",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.13945"" target=""_blank"">2503.13945</a>",,2025-12-03 22:39:25
Unified Enhancement of the Generalization and Robustness of Language Models via Bi-Stage Optimization,"Yudao Sun, Juan Yin, Juan Zhao, Fan Zhang, Yongheng Liu, Hongji Chen",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.16550"" target=""_blank"">2503.16550</a>",,2025-12-03 22:39:25
"RESFL: An Uncertainty-Aware Framework for Responsible Federated Learning by Balancing Privacy, Fairness and Utility in Autonomous Vehicles","Dawood Wasif, Terrence J. Moore, Jin-Hee Cho",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.16251"" target=""_blank"">2503.16251</a>",,2025-12-03 22:39:25
Automatically Generating Chinese Homophone Words to Probe Machine Translation Estimation Systems,"Shenbin Qian, Constantin Orăsan, Diptesh Kanojia, Félix do Carmo",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.16158"" target=""_blank"">2503.16158</a>",,2025-12-03 22:39:25
BadToken: Token-level Backdoor Attacks to Multi-modal Large Language Models,"Zenghui Yuan, Jiawen Shi, Pan Zhou, Neil Zhenqiang Gong, Lichao Sun",arXiv,2025-03,"<a href=""http://arxiv.org/abs/2503.16023"" target=""_blank"">2503.16023</a>",,2025-12-03 22:39:25
Krum Federated Chain (KFC): Using blockchain to defend against adversarial attacks in Federated Learning,"Mario García-Márquez, Nuria Rodríguez-Barroso, M. Victoria Luzón, Francisco Herrera",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.06917"" target=""_blank"">2502.06917</a>",,2025-12-03 22:39:25
SMAB: MAB based word Sensitivity Estimation Framework and its Applications in Adversarial Text Generation,"Saurabh Kumar Pandey, Sachin Vashistha, Debrup Das, Somak Aditya, Monojit Choudhury",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.07101"" target=""_blank"">2502.07101</a>",,2025-12-03 22:39:25
Do Spikes Protect Privacy? Investigating Black-Box Model Inversion Attacks in Spiking Neural Networks,"Hamed Poursiami, Ayana Moshruba, Maryam Parsa",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05509"" target=""_blank"">2502.05509</a>",,2025-12-03 22:39:25
DROP: Poison Dilution via Knowledge Distillation for Federated Learning,"Georgios Syros, Anshuman Suri, Farinaz Koushanfar, Cristina Nita-Rotaru, Alina Oprea",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.07011"" target=""_blank"">2502.07011</a>",,2025-12-03 22:39:25
When Data Manipulation Meets Attack Goals: An In-depth Survey of Attacks for VLMs,"Aobotao Dai, Xinyu Ma, Lei Chen, Songze Li, Lin Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.06390"" target=""_blank"">2502.06390</a>","<a href=""https://github.com/AobtDai/VLM_Attack_Paper_List"" target=""_blank"">AobtDai</a>",2025-12-03 22:39:25
Robust Watermarks Leak: Channel-Aware Feature Extraction Enables Adversarial Watermark Manipulation,"Zhongjie Ba, Yitao Zhang, Peng Cheng, Bin Gong, Xinyu Zhang, Qinglong Wang, Kui Ren",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.06418"" target=""_blank"">2502.06418</a>",,2025-12-03 22:39:25
Certifying Language Model Robustness with Fuzzed Randomized Smoothing: An Efficient Defense Against Backdoor Attacks,"Bowei He, Lihao Yin, Hui-Ling Zhen, Jianping Zhang, Lanqing Hong, Mingxuan Yuan, Chen Ma",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.06892"" target=""_blank"">2502.06892</a>",,2025-12-03 22:39:25
Detection of Physiological Data Tampering Attacks with Quantum Machine Learning,"Md. Saif Hassan Onim, Himanshu Thapliyal",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05966"" target=""_blank"">2502.05966</a>",,2025-12-03 22:39:25
Protecting Intellectual Property of EEG-based Neural Networks with Watermarking,"Ahmed Abdelaziz, Ahmed Fathi, Ahmed Fares",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05931"" target=""_blank"">2502.05931</a>",,2025-12-03 22:39:25
"Optimization under Attack: Resilience, Vulnerability, and the Path to Collapse","Amal Aldawsari, Evangelos Pournaras",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05954"" target=""_blank"">2502.05954</a>",,2025-12-03 22:39:25
Democratic Training Against Universal Adversarial Perturbations,"Bing Sun, Jun Sun, Wei Zhao",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05542"" target=""_blank"">2502.05542</a>",,2025-12-03 22:39:25
"Adversarial Machine Learning: Attacks, Defenses, and Open Challenges",Pranav K Jha,arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05637"" target=""_blank"">2502.05637</a>",,2025-12-03 22:39:25
Rigid Body Adversarial Attacks,"Aravind Ramakrishnan, David I. W. Levin, Alec Jacobson",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05669"" target=""_blank"">2502.05669</a>",,2025-12-03 22:39:25
Effective Black-Box Multi-Faceted Attacks Breach Vision Large Language Model Guardrails,"Yijun Yang, Lichao Wang, Xiao Yang, Lanqing Hong, Jun Zhu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05772"" target=""_blank"">2502.05772</a>",,2025-12-03 22:39:25
"Filter, Obstruct and Dilute: Defending Against Backdoor Attacks on Semi-Supervised Learning","Xinrui Wang, Chuanxing Geng, Wenhai Wan, Shao-yuan Li, Songcan Chen",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05755"" target=""_blank"">2502.05755</a>",,2025-12-03 22:39:25
Dual Defense: Enhancing Privacy and Mitigating Poisoning Attacks in Federated Learning,"Runhua Xu, Shiqi Gao, Chao Li, James Joshi, Jianxin Li",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05547"" target=""_blank"">2502.05547</a>",,2025-12-03 22:39:25
Impact of Data Poisoning Attacks on Feasibility and Optimality of Neural Power System Optimizers,"Nora Agah, Meiyi Li, Javad Mohammadi",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05727"" target=""_blank"">2502.05727</a>",,2025-12-03 22:39:25
Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey,"Bo Ni, Zheyuan Liu, Leyao Wang, Yongjia Lei, Yuying Zhao, Xueqi Cheng, Qingkai Zeng, Luna Dong, Yinglong Xia, Krishnaram Kenthapadi, Ryan Rossi, Franck Dernoncourt, Md Mehrab Tanjim, Nesreen Ahmed, Xiaorui Liu, Wenqi Fan, Erik Blasch, Yu Wang, Meng Jiang, Tyler Derr",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.06872"" target=""_blank"">2502.06872</a>",,2025-12-03 22:39:25
Mechanistic Understandings of Representation Vulnerabilities and Engineering Robust Vision Transformers,"Chashi Mahiul Islam, Samuel Jacob Chacko, Mao Nishino, Xiuwen Liu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.04679"" target=""_blank"">2502.04679</a>",,2025-12-03 22:39:25
Federated Learning for Anomaly Detection in Energy Consumption Data: Assessing the Vulnerability to Adversarial Attacks,"Yohannis Kifle Telila, Damitha Senevirathne, Dumindu Tissera, Apurva Narayan, Miriam A. M. Capretz, Katarina Grolinger",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05041"" target=""_blank"">2502.05041</a>",,2025-12-03 22:39:25
Robust Graph Learning Against Adversarial Evasion Attacks via Prior-Free Diffusion-Based Structure Purification,"Jiayi Luo, Qingyun Sun, Haonan Yuan, Xingcheng Fu, Jianxin Li",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05000"" target=""_blank"">2502.05000</a>",,2025-12-03 22:39:25
MELON: Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison,"Kaijie Zhu, Xianjun Yang, Jindong Wang, Wenbo Guo, William Yang Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05174"" target=""_blank"">2502.05174</a>",,2025-12-03 22:39:25
CP-Guard+: A New Paradigm for Malicious Agent Detection and Defense in Collaborative Perception,"Senkang Hu, Yihang Tao, Zihan Fang, Guowen Xu, Yiqin Deng, Sam Kwong, Yuguang Fang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.07807"" target=""_blank"">2502.07807</a>",,2025-12-03 22:39:25
DMPA: Model Poisoning Attacks on Decentralized Federated Learning for Model Differences,"Chao Feng, Yunlong Li, Yuanzhe Gao, Alberto Huertas Celdrán, der Assen Jan von, Gérôme Bovet, Burkhard Stiller",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.04771"" target=""_blank"">2502.04771</a>",,2025-12-03 22:39:25
Adversarially-Robust TD Learning with Markovian Data: Finite-Time Rates and Fundamental Limits,"Sreejeet Maity, Aritra Mitra",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.04662"" target=""_blank"">2502.04662</a>",,2025-12-03 22:39:25
The Rising Threat to Emerging AI-Powered Search Engines,"Zeren Luo, Zifan Peng, Yule Liu, Zhen Sun, Mingchen Li, Jingyi Zheng, Xinlei He",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.04951"" target=""_blank"">2502.04951</a>",,2025-12-03 22:39:25
Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond,"Chongyu Fan, Jinghan Jia, Yihua Zhang, Anil Ramakrishna, Mingyi Hong, Sijia Liu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05374"" target=""_blank"">2502.05374</a>","<a href=""https://github.com/OPTML-Group/Unlearn-Smooth"" target=""_blank"">OPTML-Group</a>",2025-12-03 22:39:25
SoK: State of the time: On Trustworthiness of Digital Clocks,"Adeel Nasrullah, Fatima M. Anwar",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.09837"" target=""_blank"">2502.09837</a>",,2025-12-03 22:39:25
CAT: Contrastive Adversarial Training for Evaluating the Robustness of Protective Perturbations in Latent Diffusion Models,"Sen Peng, Mingyue Wang, Jianfei He, Jijia Yang, Xiaohua Jia",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.07225"" target=""_blank"">2502.07225</a>","<a href=""https://github.com/senp98/CAT"" target=""_blank"">senp98</a>",2025-12-03 22:39:25
Amnesia as a Catalyst for Enhancing Black Box Pixel Attacks in Image Classification and Object Detection,"Dongsu Song, Daehwa Ko, Jay Hoon Jung",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.07821"" target=""_blank"">2502.07821</a>","<a href=""https://github.com/KAU-QuantumAILab/RFPAR"" target=""_blank"">KAU-QuantumAILab</a>",2025-12-03 22:39:25
Fast Proxies for LLM Robustness Evaluation,"Tim Beyer, Jan Schuchardt, Leo Schwinn, Stephan Günnemann",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.10487"" target=""_blank"">2502.10487</a>",,2025-12-03 22:39:25
X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from Multi-Turn Jailbreaks without Compromising Usability,"Xiaoya Lu, Dongrui Liu, Yi Yu, Luxin Xu, Jing Shao",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.09990"" target=""_blank"">2502.09990</a>","<a href=""https://github.com/AI45Lab/X-Boundary"" target=""_blank"">AI45Lab</a>",2025-12-03 22:39:25
Pulling Back the Curtain: Unsupervised Adversarial Detection via Contrastive Auxiliary Networks,"Eylon Mizrahi, Raz Lapid, Moshe Sipper",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.09110"" target=""_blank"">2502.09110</a>",,2025-12-03 22:39:25
SyntheticPop: Attacking Speaker Verification Systems With Synthetic VoicePops,"Eshaq Jamdar, Amith Kamath Belman",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.09553"" target=""_blank"">2502.09553</a>",,2025-12-03 22:39:25
Wasserstein distributional adversarial training for deep neural networks,"Xingjian Bai, Guangyi He, Yifan Jiang, Jan Obloj",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.09352"" target=""_blank"">2502.09352</a>",,2025-12-03 22:39:25
Making Them a Malicious Database: Exploiting Query Code to Jailbreak Aligned Large Language Models,"Qingsong Zou, Jingyu Xiao, Qing Li, Zhi Yan, Yuhang Wang, Li Xu, Wenxuan Wang, Kuofeng Gao, Ruoyu Li, Yong Jiang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.09723"" target=""_blank"">2502.09723</a>","<a href=""https://github.com/horizonsinzqs/QueryAttack"" target=""_blank"">horizonsinzqs</a>",2025-12-03 22:39:25
FLAME: Flexible LLM-Assisted Moderation Engine,"Ivan AIRI Moscow Institute of Physics and Technology Bakulin, Ilia AIRI Moscow Institute of Physics and Technology Kopanichuk, Iaroslav AIRI Bespalov, Nikita SberHealth Radchenko, Vladimir AIRI Skolkovo Institute of Science and Technology Shaposhnikov, Dmitry AIRI Skolkovo Institute of Science and Technology Dylov, Ivan AIRI Skolkovo Institute of Science and Technology Oseledets",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.09175"" target=""_blank"">2502.09175</a>",,2025-12-03 22:39:25
LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection,"Wenlun Zhang, Enyan Dai, Kentaro Yoshioka",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.09271"" target=""_blank"">2502.09271</a>",,2025-12-03 22:39:25
Confidence Elicitation: A New Attack Vector for Large Language Models,"Brian Formento, Chuan Sheng Foo, See-Kiong Ng",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.04643"" target=""_blank"">2502.04643</a>",,2025-12-03 22:39:25
Shortcut Learning Susceptibility in Vision Classifiers,"Pirzada Suhail, Amit Sethi",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.09150"" target=""_blank"">2502.09150</a>",,2025-12-03 22:39:25
RLSA-PFL: Robust Lightweight Secure Aggregation with Model Inconsistency Detection in Privacy-Preserving Federated Learning,"Nazatul H. Sultan, Yan Bo, Yansong Gao, Seyit Camtepe, Arash Mahboubi, Hang Thanh Bui, Aufeef Chauhan, Hamed Aboutorab, Michael Bewong, Praveen Gauravaram, Rafiqul Islam, Sharif Abuadbba",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.08989"" target=""_blank"">2502.08989</a>",,2025-12-03 22:39:25
AdvSwap: Covert Adversarial Perturbation with High Frequency Info-swapping for Autonomous Driving Perception,"Yuanhao Huang, Qinfan Zhang, Jiandong Xing, Mengyue Cheng, Haiyang Yu, Yilong Ren, Xiao Xiong",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.08374"" target=""_blank"">2502.08374</a>",,2025-12-03 22:39:25
Local Differential Privacy is Not Enough: A Sample Reconstruction Attack against Federated Learning with Local Differential Privacy,"Zhichao You, Xuewen Dong, Shujun Li, Ximeng Liu, Siqi Ma, Yulong Shen",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.08151"" target=""_blank"">2502.08151</a>",,2025-12-03 22:39:25
Examining Multilingual Embedding Models Cross-Lingually Through LLM-Generated Adversarial Examples,"Andrianos Michail, Simon Clematide, Rico Sennrich",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.08638"" target=""_blank"">2502.08638</a>",,2025-12-03 22:39:25
Typographic Attacks in a Multi-Image Setting,"Xiaomeng Wang, Zhengyu Zhao, Martha Larson",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.08193"" target=""_blank"">2502.08193</a>",,2025-12-03 22:39:25
Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks,"Ang Li, Yin Zhou, Vethavikashini Chithrra Raghuram, Tom Goldstein, Micah Goldblum",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.08586"" target=""_blank"">2502.08586</a>",,2025-12-03 22:39:25
Dynamic watermarks in images generated by diffusion models,"Yunzhuo Chen, Naveed Akhtar, Nur Al Hasan Haldar, Ajmal Mian",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.08927"" target=""_blank"">2502.08927</a>",,2025-12-03 22:39:25
Monge SAM: Robust Reparameterization-Invariant Sharpness-Aware Minimization Based on Loss Geometry,"Albert Kjøller Jacobsen, Georgios Arvanitidis",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.08448"" target=""_blank"">2502.08448</a>",,2025-12-03 22:39:25
Provably Robust Federated Reinforcement Learning,"Minghong Fang, Xilong Wang, Neil Zhenqiang Gong",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.08123"" target=""_blank"">2502.08123</a>",,2025-12-03 22:39:25
RoMA: Robust Malware Attribution via Byte-level Adversarial Training with Global Perturbations and Adversarial Consistency Regularization,"Yuxia Sun, Huihong Chen, Jingcai Guo, Aoxiang Sun, Zhetao Li, Haolin Liu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.07492"" target=""_blank"">2502.07492</a>",,2025-12-03 22:39:25
Universal Adversarial Attack on Aligned Multimodal LLMs,"Temurbek Rahmatullaev, Polina Druzhinina, Matvey Mikhalchuk, Andrey Kuznetsov, Anton Razzhigaev",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.07987"" target=""_blank"">2502.07987</a>",,2025-12-03 22:39:25
MAA: Meticulous Adversarial Attack against Vision-Language Pre-trained Models,"Peng-Fei Zhang, Guangdong Bai, Zi Huang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.08079"" target=""_blank"">2502.08079</a>",,2025-12-03 22:39:25
Direct Ascent Synthesis: Revealing Hidden Generative Capabilities in Discriminative Models,"Stanislav Fort, Jonathan Whitaker",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.07753"" target=""_blank"">2502.07753</a>",,2025-12-03 22:39:25
JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and Manipulation,"Shenyi Zhang, Yuchen Zhai, Keyan Guo, Hongxin Hu, Shengnan Guo, Zheng Fang, Lingchen Zhao, Chao Shen, Cong Wang, Qian Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.07557"" target=""_blank"">2502.07557</a>",,2025-12-03 22:39:25
Curvature Tuning: Provable Training-free Model Steering From a Single Parameter,"Leyang Hu, Randall Balestriero",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.07783"" target=""_blank"">2502.07783</a>","<a href=""https://github.com/Leon-Leyang/curvature-tuning"" target=""_blank"">Leon-Leyang</a>",2025-12-03 22:39:25
Spread them Apart: Towards Robust Watermarking of Generated Content,"Mikhail Pautov, Danil Ivanov, Andrey V. Galichin, Oleg Rogov, Ivan Oseledets",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.07845"" target=""_blank"">2502.07845</a>",,2025-12-03 22:39:25
SLVR: Securely Leveraging Client Validation for Robust Federated Learning,"Jihye Choi, Sai Rahul Rachuri, Ke Wang, Somesh Jha, Yizhen Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.08055"" target=""_blank"">2502.08055</a>",,2025-12-03 22:39:25
Short-length Adversarial Training Helps LLMs Defend Long-length Jailbreak Attacks: Theoretical and Empirical Evidence,"Shaopeng Fu, Liang Ding, Jingfeng Zhang, Di Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.04204"" target=""_blank"">2502.04204</a>","<a href=""https://github.com/fshp971/adv-icl"" target=""_blank"">fshp971</a>",2025-12-03 22:39:25
Semantic Entanglement-Based Ransomware Detection via Probabilistic Latent Encryption Mapping,"Mohammad Eisa, Quentin Yardley, Rafael Witherspoon, Harriet Pendlebury, Clement Rutherford",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.02730"" target=""_blank"">2502.02730</a>",,2025-12-03 22:39:25
Adapting to Evolving Adversaries with Regularized Continual Robust Training,"Sihui Dai, Christian Cianfarani, Arjun Bhagoji, Vikash Sehwag, Prateek Mittal",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.04248"" target=""_blank"">2502.04248</a>",,2025-12-03 22:39:25
From Compliance to Exploitation: Jailbreak Prompt Attacks on Multimodal LLMs,"Chun Wai Chiu, Linghan Huang, Bo Li, Huaming Chen",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.00735"" target=""_blank"">2502.00735</a>",,2025-12-03 22:39:25
Detecting Backdoor Samples in Contrastive Language Image Pretraining,"Hanxun Huang, Sarah Erfani, Yige Li, Xingjun Ma, James Bailey",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.01385"" target=""_blank"">2502.01385</a>","<a href=""https://github.com/HanxunH/Detect-CLIP-Backdoor-Samples"" target=""_blank"">HanxunH</a>",2025-12-03 22:39:25
Query-Based and Unnoticeable Graph Injection Attack from Neighborhood Perspective,"Chang Liu, Hai Huang, Yujie Xing, Xingquan Zuo",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.01936"" target=""_blank"">2502.01936</a>",,2025-12-03 22:39:25
INTACT: Inducing Noise Tolerance through Adversarial Curriculum Training for LiDAR-based Safety-Critical Perception and Autonomy,"Nastaran Darabi, Divake Kumar, Sina Tayebati, Amit Ranjan Trivedi",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.01896"" target=""_blank"">2502.01896</a>",,2025-12-03 22:39:25
Gradient Norm-based Fine-Tuning for Backdoor Defense in Automatic Speech Recognition,"Nanjun Zhou, Weilin Lin, Li Liu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.01152"" target=""_blank"">2502.01152</a>",,2025-12-03 22:39:25
Quantum Quandaries: Unraveling Encoding Vulnerabilities in Quantum Neural Networks,"Suryansh Upadhyay, Swaroop Ghosh",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.01486"" target=""_blank"">2502.01486</a>",,2025-12-03 22:39:25
Bias Beware: The Impact of Cognitive Biases on LLM-Driven Product Recommendations,"Giorgos Filandrianos, Angeliki Dimitriou, Maria Lymperaiou, Konstantinos Thomas, Giorgos Stamou",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.01349"" target=""_blank"">2502.01349</a>",,2025-12-03 22:39:25
Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities,"Zora Che, Stephen Casper, Robert Kirk, Anirudh Satheesh, Stewart Slocum, Lev E McKinney, Rohit Gandikota, Aidan Ewart, Domenic Rosati, Zichu Wu, Zikui Cai, Bilal Chughtai, Yarin Gal, Furong Huang, Dylan Hadfield-Menell",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05209"" target=""_blank"">2502.05209</a>",,2025-12-03 22:39:25
Breaking Focus: Contextual Distraction Curse in Large Language Models,"Yue Huang, Yanbo Wang, Zixiang Xu, Chujie Gao, Siyuan Wu, Jiayi Ye, Xiuying Chen, Pin-Yu Chen, Xiangliang Zhang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.01609"" target=""_blank"">2502.01609</a>","<a href=""https://github.com/wyf23187/LLM_CDV"" target=""_blank"">wyf23187</a>",2025-12-03 22:39:25
Jailbreaking with Universal Multi-Prompts,"Yu-Ling Hsu, Hsuan Su, Shang-Tse Chen",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.01154"" target=""_blank"">2502.01154</a>",,2025-12-03 22:39:25
AGNNCert: Defending Graph Neural Networks against Arbitrary Perturbations with Deterministic Certification,"Jiate Li, Binghui Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.00765"" target=""_blank"">2502.00765</a>",,2025-12-03 22:39:25
Safety at Scale: A Comprehensive Survey of Large Model Safety,"Xingjun Ma, Yifeng Gao, Yixu Wang, Ruofan Wang, Xin Wang, Ye Sun, Yifan Ding, Hengyuan Xu, Yunhao Chen, Yunhan Zhao, Hanxun Huang, Yige Li, Jiaming Zhang, Xiang Zheng, Yang Bai, Zuxuan Wu, Xipeng Qiu, Jingfeng Zhang, Yiming Li, Jun Sun, Cong Wang, Jindong Gu, Baoyuan Wu, Siheng Chen, Tianwei Zhang, Yang Liu, Mingming Gong, Tongliang Liu, Shirui Pan, Cihang Xie, Tianyu Pang, Yinpeng Dong, Ruoxi Jia, Yang Zhang, Shiqing Ma, Xiangyu Zhang, Neil Gong, Chaowei Xiao, Sarah Erfani, Bo Li, Masashi Sugiyama, Dacheng Tao, James Bailey, Yu-Gang Jiang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05206"" target=""_blank"">2502.05206</a>",,2025-12-03 22:39:25
Adversarial Robustness in Two-Stage Learning-to-Defer: Algorithms and Guarantees,"Yannis Montreuil, Axel Carlier, Lai Xing Ng, Wei Tsang Ooi",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.01027"" target=""_blank"">2502.01027</a>",,2025-12-03 22:39:25
Refining Adaptive Zeroth-Order Optimization at Ease,"Yao Shu, Qixin Zhang, Kun He, Zhongxiang Dai",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.01014"" target=""_blank"">2502.01014</a>",,2025-12-03 22:39:25
Mitigation of Camouflaged Adversarial Attacks in Autonomous Vehicles--A Case Study Using CARLA Simulator,"Yago Romano Martinez, Brady Carter, Abhijeet Solanki, Wesam Al Amiri, Syed Rafay Hasan, Terry N. Guo",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05208"" target=""_blank"">2502.05208</a>",,2025-12-03 22:39:25
Converting MLPs into Polynomials in Closed Form,"Nora Belrose, Alice Rigg",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.01032"" target=""_blank"">2502.01032</a>",,2025-12-03 22:39:25
Boosting Adversarial Robustness and Generalization with Structural Prior,"Zhichao Hou, Weizhi Gao, Hamid Krim, Xiaorui Liu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.00834"" target=""_blank"">2502.00834</a>",,2025-12-03 22:39:25
CAE-Net: Generalized Deepfake Image Detection using Convolution and Attention Mechanisms with Spatial and Frequency Domain Features,"Kafi Anan, Anindya Bhattacharjee, Ashir Intesher, Kaidul Islam, Abrar Assaeem Fuad, Utsab Saha, Hafiz Imtiaz",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.10682"" target=""_blank"">2502.10682</a>",,2025-12-03 22:39:25
Privacy Preserving Properties of Vision Classifiers,"Pirzada Suhail, Amit Sethi",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.00760"" target=""_blank"">2502.00760</a>",,2025-12-03 22:39:25
Towards Robust Multimodal Large Language Models Against Jailbreak Attacks,"Ziyi Yin, Yuanpu Cao, Han Liu, Ting Wang, Jinghui Chen, Fenhlong Ma",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.00653"" target=""_blank"">2502.00653</a>",,2025-12-03 22:39:25
Reformulation is All You Need: Addressing Malicious Text Features in DNNs,"Yi Jiang, Oubo Ma, Yong Yang, Tong Zhang, Shouling Ji",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.00652"" target=""_blank"">2502.00652</a>",,2025-12-03 22:39:25
Actor Critic with Experience Replay-based automatic treatment planning for prostate cancer intensity modulated radiotherapy,"Md Mainul Abrar, Parvat Sapkota, Damon Sprouts, Xun Jia, Yujie Chi",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.00346"" target=""_blank"">2502.00346</a>",,2025-12-03 22:39:25
TrojanTime: Backdoor Attacks on Time Series Classification,"Chang Dong, Zechao Sun, Guangdong Bai, Shuying Piao, Weitong Chen, Wei Emma Zhang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.00646"" target=""_blank"">2502.00646</a>",,2025-12-03 22:39:25
Explorations of the Softmax Space: Knowing When the Neural Network Doesn't Know,"Daniel Sikar, Artur d'Avila Garcez, Tillman Weyde",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.00456"" target=""_blank"">2502.00456</a>",,2025-12-03 22:39:25
It's Not Just a Phase: On Investigating Phase Transitions in Deep Learning-based Side-channel Analysis,"Sengim Karayalçin, Marina Krček, Stjepan Picek",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.00384"" target=""_blank"">2502.00384</a>",,2025-12-03 22:39:25
Adversarial Machine Learning: Attacking and Safeguarding Image Datasets,Koushik Chowdhury,arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05203"" target=""_blank"">2502.05203</a>",,2025-12-03 22:39:25
ALBAR: Adversarial Learning approach to mitigate Biases in Action Recognition,"Joseph Fioresi, Ishan Rajendrakumar Dave, Mubarak Shah",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.00156"" target=""_blank"">2502.00156</a>","<a href=""https://joefioresi718.github.io/ALBAR_webpage/"" target=""_blank"">ALBAR_webpage</a>",2025-12-03 22:39:25
Topic-FlipRAG: Topic-Orientated Adversarial Opinion Manipulation Attacks to Retrieval-Augmented Generation Models,"Yuyang Gong, Zhuo Chen, Miaokun Chen, Fengchang Yu, Wei Lu, Xiaofeng Wang, Xiaozhong Liu, Jiawei Liu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.01386"" target=""_blank"">2502.01386</a>",,2025-12-03 22:39:25
Robust-LLaVA: On the Effectiveness of Large-Scale Robust Image Encoders for Multi-modal Large Language Models,"Hashmat Shadab Malik, Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar, Fahad Khan, Salman Khan",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.01576"" target=""_blank"">2502.01576</a>","<a href=""https://github.com/HashmatShadab/Robust-LLaVA"" target=""_blank"">HashmatShadab</a>",2025-12-03 22:39:25
BitAbuse: A Dataset of Visually Perturbed Texts for Defending Phishing Attacks,"Hanyong Lee, Chaelyn Lee, Yongjae Lee, Jaesung Lee",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05225"" target=""_blank"">2502.05225</a>",,2025-12-03 22:39:25
Detecting Backdoor Attacks via Similarity in Semantic Communication Systems,"Ziyang Wei, Yili Jiang, Jiaqi Huang, Fangtian Zhong, Sohan Gyawali",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.03721"" target=""_blank"">2502.03721</a>",,2025-12-03 22:39:25
Optimizing Perturbations for Improved Training of Machine Learning Models,"Sagi Meir, Tommer D. Keidar, Shlomi Reuveni, Barak Hirshberg",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.04121"" target=""_blank"">2502.04121</a>",,2025-12-03 22:39:25
SoK: Benchmarking Poisoning Attacks and Defenses in Federated Learning,"Heyi Zhang, Yule Liu, Xinlei He, Jun Wu, Tianshuo Cong, Xinyi Huang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.03801"" target=""_blank"">2502.03801</a>","<a href=""https://github.com/vio1etus/FLPoison"" target=""_blank"">vio1etus</a>",2025-12-03 22:39:25
Provably Robust Explainable Graph Neural Networks against Graph Perturbation Attacks,"Jiate Li, Meng Pang, Yun Dong, Jinyuan Jia, Binghui Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.04224"" target=""_blank"">2502.04224</a>",,2025-12-03 22:39:25
Dark Distillation: Backdooring Distilled Datasets without Accessing Raw Data,"Ziyuan Yang, Ming Yan, Yi Zhang, Joey Tianyi Zhou",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.04229"" target=""_blank"">2502.04229</a>",,2025-12-03 22:39:25
XAttnMark: Learning Robust Audio Watermarking with Cross-Attention,"Yixin Liu, Lie Lu, Jihui Jin, Lichao Sun, Andrea Fanelli",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.04230"" target=""_blank"">2502.04230</a>","<a href=""https://liuyixin-louis.github.io/xattnmark/"" target=""_blank"">xattnmark</a>",2025-12-03 22:39:25
LR0,"Priyank Pathak, Shyam Marjit, Shruti Vyas, Yogesh S Rawat",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.03950"" target=""_blank"">2502.03950</a>","<a href=""https://github.com/shyammarjit/LR0.FM"" target=""_blank"">shyammarjit</a>",2025-12-03 22:39:25
How vulnerable is my policy? Adversarial attacks on modern behavior cloning policies,"Basavasagar Patil, Akansha Kalra, Guanhong Tao, Daniel S. Brown",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.03698"" target=""_blank"">2502.03698</a>",,2025-12-03 22:39:25
Optimizing Robustness and Accuracy in Mixture of Experts: A Dual-Model Approach,"Xu Zhang, Kaidi Xu, Ziqing Hu, Ren Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.06832"" target=""_blank"">2502.06832</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness via Phase and Amplitude-aware Prompting,"Yibo Xu, Dawei Zhou, Decheng Liu, Nannan Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.03758"" target=""_blank"">2502.03758</a>",,2025-12-03 22:39:25
Real-Time Privacy Risk Measurement with Privacy Tokens for Gradient Leakage,"Jiayang Meng, Tao Huang, Hong Chen, Xin Shi, Qingyu Huang, Chen Hou",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.02913"" target=""_blank"">2502.02913</a>",,2025-12-03 22:39:25
"A Survey on Backdoor Threats in Large Language Models (LLMs): Attacks, Defenses, and Evaluations","Yihe Zhou, Tao Ni, Wei-Bin Lee, Qingchuan Zhao",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05224"" target=""_blank"">2502.05224</a>",,2025-12-03 22:39:25
Large Language Model Adversarial Landscape Through the Lens of Attack Objectives,"Nan Wang, Kane Walter, Yansong Gao, Alsharif Abuadbba",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.02960"" target=""_blank"">2502.02960</a>",,2025-12-03 22:39:25
DocMIA: Document-Level Membership Inference Attacks against DocVQA Models,"Khanh Nguyen, Raouf Kerkouche, Mario Fritz, Dimosthenis Karatzas",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.03692"" target=""_blank"">2502.03692</a>",,2025-12-03 22:39:25
FSPGD: Rethinking Black-box Attacks on Semantic Segmentation,"Eun-Sol Park, MiSo Park, Seung Park, Yong-Goo Shin",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.01262"" target=""_blank"">2502.01262</a>","<a href=""https://github.com/KU-AIVS/FSPGD"" target=""_blank"">KU-AIVS</a>",2025-12-03 22:39:25
Understanding and Enhancing the Transferability of Jailbreaking Attacks,"Runqi Lin, Bo Han, Fengwang Li, Tongling Liu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.03052"" target=""_blank"">2502.03052</a>",,2025-12-03 22:39:25
CoRPA: Adversarial Image Generation for Chest X-rays Using Concept Vector Perturbations and Generative Models,"Amy Rafferty, Rishi Ramaesh, Ajitha Rajan",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05214"" target=""_blank"">2502.05214</a>",,2025-12-03 22:39:25
"Dual-Flow: Transferable Multi-Target, Instance-Agnostic Attacks via In-the-wild Cascading Flow Optimization","Yixiao Chen, Shikun Sun, Jianshu Li, Ruoyu Li, Zhe Li, Junliang Xing",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.02096"" target=""_blank"">2502.02096</a>",,2025-12-03 22:39:25
MARAGE: Transferable Multi-Model Adversarial Attack for Retrieval-Augmented Generation Data Extraction,"Xiao Hu, Eric Liu, Weizhou Wang, Xiangyu Guo, David Lie",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.04360"" target=""_blank"">2502.04360</a>",,2025-12-03 22:39:25
FRAUD-RLA: A new reinforcement learning adversarial attack against credit card fraud detection,"Daniele Lunghi, Yannick Molinghen, Alkis Simitsis, Tom Lenaerts, Gianluca Bontempi",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.02290"" target=""_blank"">2502.02290</a>",,2025-12-03 22:39:25
Uncertainty Quantification for Collaborative Object Detection Under Adversarial Attacks,"Huiqun Huang, Cong Chen, Jean-Philippe Monteuuis, Jonathan Petit, Fei Miao",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.02537"" target=""_blank"">2502.02537</a>",,2025-12-03 22:39:25
Adversarial ML Problems Are Getting Harder to Solve and to Evaluate,"Javier Rando, Jie Zhang, Nicholas Carlini, Florian Tramèr",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.02260"" target=""_blank"">2502.02260</a>",,2025-12-03 22:39:25
Wolfpack Adversarial Attack for Robust Multi-Agent Reinforcement Learning,"Sunwoo Lee, Jaebak Hwang, Yonghyeon Jo, Seungyul Han",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.02844"" target=""_blank"">2502.02844</a>","<a href=""https://github.com/sunwoolee0504/WALL"" target=""_blank"">sunwoolee0504</a>",2025-12-03 22:39:25
Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment,"Yaling Shen, Zhixiong Zhuang, Kun Yuan, Maria-Irina Nicolae, Nassir Navab, Nicolas Padoy, Mario Fritz",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.02438"" target=""_blank"">2502.02438</a>",,2025-12-03 22:39:25
An Attack-Driven Incident Response and Defense System (ADIRDS),"Anthony Cheuk Tung Lai, Siu Ming Yiu, Ping Fan Ke, Alan Ho",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.02230"" target=""_blank"">2502.02230</a>",,2025-12-03 22:39:25
Achievable distributional robustness when the robust risk is only partially identified,"Julia Kostin, Nicola Gnecco, Fanny Yang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.02710"" target=""_blank"">2502.02710</a>",,2025-12-03 22:39:25
Multi-Domain Graph Foundation Models: Robust Knowledge Transfer via Topology Alignment,"Shuo Wang, Bokui Wang, Zhixiang Shen, Boyan Deng, Zhao Kang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.02017"" target=""_blank"">2502.02017</a>",,2025-12-03 22:39:25
VocalCrypt: Novel Active Defense Against Deepfake Voice Based on Masking Effect,"Qingyuan Fei, Wenjie Hou, Xuan Hai, Xin Liu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.10329"" target=""_blank"">2502.10329</a>",,2025-12-03 22:39:25
"Decoding FL Defenses: Systemization, Pitfalls, and Remedies","Momin Ahmad Khan, Virat Shejwalkar, Yasra Chandio, Amir Houmansadr, Fatima Muhammad Anwar",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.05211"" target=""_blank"">2502.05211</a>",,2025-12-03 22:39:25
FaceSwapGuard: Safeguarding Facial Privacy from DeepFake Threats through Identity Obfuscation,"Li Wang, Zheng Li, Xuhong Zhang, Shouling Ji, Shanqing Guo",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.10801"" target=""_blank"">2502.10801</a>",,2025-12-03 22:39:25
Unified Prompt Attack Against Text-to-Image Generation Models,"Duo Peng, Qiuhong Ke, Mark He Huang, Ping Hu, Jun Liu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16423"" target=""_blank"">2502.16423</a>",,2025-12-03 22:39:25
Examining the Threat Landscape: Foundation Models and Model Stealing,"Ankita Raj, Deepankar Varma, Chetan Arora",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.18077"" target=""_blank"">2502.18077</a>","<a href=""https://github.com/rajankita/foundation_model_stealing"" target=""_blank"">rajankita</a>",2025-12-03 22:39:25
DeBUGCN -- Detecting Backdoors in CNNs Using Graph Convolutional Networks,"Akash Vartak, Khondoker Murad Hossain, Tim Oates",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.18592"" target=""_blank"">2502.18592</a>",,2025-12-03 22:39:25
On the Privacy-Preserving Properties of Spiking Neural Networks with Unique Surrogate Gradients and Quantization Levels,"Ayana Moshruba, Shay Snyder, Hamed Poursiami, Maryam Parsa",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.18623"" target=""_blank"">2502.18623</a>",,2025-12-03 22:39:25
Learning atomic forces from uncertainty-calibrated adversarial attacks,"Henrique Musseli Cezar, Tilmann Bodenstein, Henrik Andersen Sveinsson, Morten Ledum, Simen Reine, Sigbjørn Løland Bore",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.18314"" target=""_blank"">2502.18314</a>",,2025-12-03 22:39:25
VVRec: Reconstruction Attacks on DL-based Volumetric Video Upstreaming via Latent Diffusion Model with Gamma Distribution,"Rui Lu, Bihai Zhang, Dan Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.17880"" target=""_blank"">2502.17880</a>",,2025-12-03 22:39:25
Stealthy Backdoor Attack in Self-Supervised Learning Vision Encoders for Large Vision Language Models,"Zhaoyi Liu, Huan Zhang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.18290"" target=""_blank"">2502.18290</a>",,2025-12-03 22:39:25
Emoti-Attack: Zero-Perturbation Adversarial Attacks on NLP Systems via Emoji Sequences,Yangshijie Zhang,arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.17392"" target=""_blank"">2502.17392</a>",,2025-12-03 22:39:25
Improving the Transferability of Adversarial Examples by Inverse Knowledge Distillation,"Wenyuan Wu, Zheng Liu, Yong Chen, Chao Su, Dezhong Peng, Xu Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.17003"" target=""_blank"">2502.17003</a>",,2025-12-03 22:39:25
Adversarial Training for Defense Against Label Poisoning Attacks,"Melis Ilayda Bal, Volkan Cevher, Michael Muehlebach",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.17121"" target=""_blank"">2502.17121</a>",,2025-12-03 22:39:25
"REINFORCE Adversarial Attacks on Large Language Models: An Adaptive, Distributional, and Semantic Objective","Simon Geisler, Tom Wollschläger, M. H. I. Abdalla, Vincent Cohen-Addad, Johannes Gasteiger, Stephan Günnemann",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.17254"" target=""_blank"">2502.17254</a>",,2025-12-03 22:39:25
On the Vulnerability of Concept Erasure in Diffusion Models,"Lucas Beerens, Alex D. Richardson, Kaicheng Zhang, Dongdong Chen",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.17537"" target=""_blank"">2502.17537</a>","<a href=""https://github.com/LucasBeerens/RECORD"" target=""_blank"">LucasBeerens</a>",2025-12-03 22:39:25
MM-PoisonRAG: Disrupting Multimodal RAG with Local and Global Poisoning Attacks,"Hyeonjeong Ha, Qiusi Zhan, Jeonghwan Kim, Dimitrios Bralios, Saikrishna Sanniboina, Nanyun Peng, Kai-Wei Chang, Daniel Kang, Heng Ji",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.17832"" target=""_blank"">2502.17832</a>",,2025-12-03 22:39:25
A stochastic smoothing framework for nonconvex-nonconcave min-sum-max problems with applications to Wasserstein distributionally robust optimization,"Wei Liu, Muhammad Khan, Gabriel Mancino-Ball, Yangyang Xu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.17602"" target=""_blank"">2502.17602</a>",,2025-12-03 22:39:25
VGFL-SA: Vertical Graph Federated Learning Structure Attack Based on Contrastive Learning,"Yang Chen, Bin Zhou",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16793"" target=""_blank"">2502.16793</a>",,2025-12-03 22:39:25
Class-Conditional Neural Polarizer: A Lightweight and Effective Backdoor Defense by Purifying Poisoned Features,"Mingli Zhu, Shaokui Wei, Hongyuan Zha, Baoyuan Wu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.18520"" target=""_blank"">2502.18520</a>",,2025-12-03 22:39:25
Tracking the Copyright of Large Vision-Language Models through Parameter Learning Adversarial Images,"Yubo Wang, Jianting Tang, Chaohu Liu, Linli Xu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16593"" target=""_blank"">2502.16593</a>",,2025-12-03 22:39:25
Keeping up with dynamic attackers: Certifying robustness to adaptive online data poisoning,"Avinandan Bose, Laurent Lessard, Maryam Fazel, Krishnamurthy Dj Dvijotham",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16737"" target=""_blank"">2502.16737</a>","<a href=""https://github.com/Avinandan22/Certified-Robustness"" target=""_blank"">Avinandan22</a>",2025-12-03 22:39:25
Multi-Target Federated Backdoor Attack Based on Feature Aggregation,"Lingguag Hao, Kuangrong Hao, Bing Wei, Xue-song Tang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16545"" target=""_blank"">2502.16545</a>",,2025-12-03 22:39:25
Guardians of the Agentic System: Preventing Many Shots Jailbreak with Agentic System,"Saikat Barua, Mostafizur Rahman, Md Jafor Sadek, Rafiul Islam, Shehenaz Khaled, Ahmedul Kabir",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16750"" target=""_blank"">2502.16750</a>",,2025-12-03 22:39:25
Towards Optimal Adversarial Robust Reinforcement Learning with Infinity Measurement Error,"Haoran Li, Zicheng Zhang, Wang Luo, Congying Han, Jiayu Lv, Tiande Guo, Yudong Hu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16734"" target=""_blank"">2502.16734</a>",,2025-12-03 22:39:25
Pay Attention to Real World Perturbations! Natural Robustness Evaluation in Machine Reading Comprehension,"Yulong Wu, Viktor Schlegel, Riza Batista-Navarro",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16523"" target=""_blank"">2502.16523</a>",,2025-12-03 22:39:25
AISafetyLab: A Comprehensive Framework for AI Safety Evaluation and Improvement,"Zhexin Zhang, Leqi Lei, Junxiao Yang, Xijie Huang, Yida Lu, Shiyao Cui, Renmiao Chen, Qinglin Zhang, Xinyuan Wang, Hao Wang, Hao Li, Xianqi Lei, Chengwei Pan, Lei Sha, Hongning Wang, Minlie Huang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16776"" target=""_blank"">2502.16776</a>","<a href=""https://github.com/thu-coai/AISafetyLab"" target=""_blank"">thu-coai</a>",2025-12-03 22:39:25
REFINE: Inversion-Free Backdoor Defense via Model Reprogramming,"Yukun Chen, Shuo Shao, Enhao Huang, Yiming Li, Pin-Yu Chen, Zhan Qin, Kui Ren",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.18508"" target=""_blank"">2502.18508</a>",,2025-12-03 22:39:25
A Framework for Evaluating Vision-Language Model Safety: Building Trust in AI for Public Sector Applications,"Maisha Binte Rashid, Pablo Rivas",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16361"" target=""_blank"">2502.16361</a>",,2025-12-03 22:39:25
PersGuard: Preventing Malicious Personalization via Backdoor Attacks on Pre-trained Text-to-Image Diffusion Models,"Xinwei Liu, Xiaojun Jia, Yuan Xun, Hua Zhang, Xiaochun Cao",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16167"" target=""_blank"">2502.16167</a>",,2025-12-03 22:39:25
ELBA-Bench: An Efficient Learning Backdoor Attacks Benchmark for Large Language Models,"Xuxu Liu, Siyuan Liang, Mengya Han, Yong Luo, Aishan Liu, Xiantao Cai, Zheng He, Dacheng Tao",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.18511"" target=""_blank"">2502.18511</a>",,2025-12-03 22:39:25
FedNIA: Noise-Induced Activation Analysis for Mitigating Data Poisoning in FL,"Ehsan Hallaji, Roozbeh Razavi-Far, Mehrdad Saif",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16396"" target=""_blank"">2502.16396</a>",,2025-12-03 22:39:25
Exploring Graph Tasks with Pure LLMs: A Comprehensive Benchmark and Investigation,"Yuxiang Wang, Xinnan Dai, Wenqi Fan, Yao Ma",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.18771"" target=""_blank"">2502.18771</a>","<a href=""https://github.com/myflashbarry/LLM-benchmarking"" target=""_blank"">myflashbarry</a>",2025-12-03 22:39:25
CLIPure: Purification in Latent Space via CLIP for Adversarially Robust Zero-Shot Classification,"Mingkun Zhang, Keping Bi, Wei Chen, Jiafeng Guo, Xueqi Cheng",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.18176"" target=""_blank"">2502.18176</a>","<a href=""https://github.com/TMLResearchGroup-CAS/CLIPure"" target=""_blank"">TMLResearchGroup-CAS</a>",2025-12-03 22:39:25
Model-Free Adversarial Purification via Coarse-To-Fine Tensor Network Representation,"Guang Lin, Duc Thien Nguyen, Zerui Tao, Konstantinos Slavakis, Toshihisa Tanaka, Qibin Zhao",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.17972"" target=""_blank"">2502.17972</a>",,2025-12-03 22:39:25
Adversarial Robustness in Parameter-Space Classifiers,"Tamir Shor, Ethan Fetaya, Chaim Baskin, Alex Bronstein",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.20314"" target=""_blank"">2502.20314</a>",,2025-12-03 22:39:25
Rewrite to Jailbreak: Discover Learnable and Transferable Implicit Harmfulness Instruction,"Yuting Huang, Chengyuan Liu, Yifeng Feng, Yiquan Wu, Chao Wu, Fei Wu, Kun Kuang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.11084"" target=""_blank"">2502.11084</a>","<a href=""https://github.com/ythuang02/R2J/"" target=""_blank"">R2J</a>",2025-12-03 22:39:25
QFAL: Quantum Federated Adversarial Learning,"Walid El Maouaki, Nouhaila Innan, Alberto Marchisio, Taoufik Said, Mohamed Bennai, Muhammad Shafique",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.21171"" target=""_blank"">2502.21171</a>",,2025-12-03 22:39:25
Data-free Universal Adversarial Perturbation with Pseudo-semantic Prior,"Chanhui Lee, Yeonghwan Song, Jeany Son",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.21048"" target=""_blank"">2502.21048</a>","<a href=""https://github.com/ChnanChan/PSP-UAP"" target=""_blank"">ChnanChan</a>",2025-12-03 22:39:25
Concealed Adversarial attacks on neural networks for sequential data,"Petr Sokerin, Dmitry Anikin, Sofia Krehova, Alexey Zaytsev",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.20948"" target=""_blank"">2502.20948</a>",,2025-12-03 22:39:25
Decoder Gradient Shield: Provable and High-Fidelity Prevention of Gradient-Based Box-Free Watermark Removal,"Haonan An, Guang Hua, Zhengru Fang, Guowen Xu, Susanto Rahardja, Yuguang Fang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.20924"" target=""_blank"">2502.20924</a>",,2025-12-03 22:39:25
Fast Adversarial Training against Sparse Attacks Requires Loss Smoothing,"Xuyang Zhong, Yixiao Huang, Chen Liu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.21041"" target=""_blank"">2502.21041</a>",,2025-12-03 22:39:25
The RAG Paradox: A Black-Box Attack Exploiting Unintentional Vulnerabilities in Retrieval-Augmented Generation Systems,"Chanwoo Choi, Jinsoo Kim, Sukmin Cho, Soyeong Jeong, Buru Chang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.20995"" target=""_blank"">2502.20995</a>",,2025-12-03 22:39:25
Enabling AutoML for Zero-Touch Network Security: Use-Case Driven Analysis,"Li Yang, Mirna El Rajab, Abdallah Shami, Sami Muhaidat",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.21286"" target=""_blank"">2502.21286</a>",,2025-12-03 22:39:25
L-Lipschitz Gershgorin ResNet Network,"Marius F. R. Juston, William R. Norris, Dustin Nottage, Ahmet Soylemezoglu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.21279"" target=""_blank"">2502.21279</a>",,2025-12-03 22:39:25
LISArD: Learning Image Similarity to Defend Against Gray-box Adversarial Attacks,"Joana C. Costa, Tiago Roxo, Hugo Proença, Pedro R. M. Inácio",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.20562"" target=""_blank"">2502.20562</a>","<a href=""https://github.com/Joana-Cabral/LISArD"" target=""_blank"">Joana-Cabral</a>",2025-12-03 22:39:25
Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on Diffusion Models,"Yu Pan, Jiahao Chen, Bingrong Dai, Lin Wang, Yi Du, Jiao Liu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.20650"" target=""_blank"">2502.20650</a>","<a href=""https://github.com/paoche11/Gungnir"" target=""_blank"">paoche11</a>",2025-12-03 22:39:25
Exploring the Impact of Temperature Scaling in Softmax for Classification and Adversarial Robustness,"Hao Xuan, Bokai Yang, Xingyu Li",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.20604"" target=""_blank"">2502.20604</a>",,2025-12-03 22:39:25
On Adversarial Attacks In Acoustic Drone Localization,"Tamir Shor, Chaim Baskin, Alex Bronstein",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.20325"" target=""_blank"">2502.20325</a>",,2025-12-03 22:39:25
Adversarial Universal Stickers: Universal Perturbation Attacks on Traffic Sign using Stickers,"Anthony Etim, Jakub Szefer",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.18724"" target=""_blank"">2502.18724</a>",,2025-12-03 22:39:25
SecureGaze: Defending Gaze Estimation Against Backdoor Attacks,"Lingyu Du, Yupei Liu, Jinyuan Jia, Guohao Lan",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.20306"" target=""_blank"">2502.20306</a>",,2025-12-03 22:39:25
From Data to Sliding Mode Control of Uncertain Large-Scale Networks with Unknown Dynamics,"Behrad Samari, Gian Paolo Incremona, Antonella Ferrara, Abolfazl Lavaei",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.19806"" target=""_blank"">2502.19806</a>",,2025-12-03 22:39:25
Improving Adversarial Transferability in MLLMs via Dynamic Vision-Language Alignment Attack,"Chenhe Gu, Jindong Gu, Andong Hua, Yao Qin",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.19672"" target=""_blank"">2502.19672</a>",,2025-12-03 22:39:25
Snowball Adversarial Attack on Traffic Sign Classification,"Anthony Etim, Jakub Szefer",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.19757"" target=""_blank"">2502.19757</a>",,2025-12-03 22:39:25
Prompt-driven Transferable Adversarial Attack on Person Re-Identification with Attribute-aware Textual Inversion,"Yuan Bian, Min Liu, Yunqi Yi, Xueping Wang, Yaonan Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.19697"" target=""_blank"">2502.19697</a>",,2025-12-03 22:39:25
SAP-DIFF: Semantic Adversarial Patch Generation for Black-Box Face Recognition Models via Diffusion Models,"Mingsi Wang, Shuaiyin Yao, Chang Yue, Lijie Zhang, Guozhu Meng",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.19710"" target=""_blank"">2502.19710</a>",,2025-12-03 22:39:25
XSS Adversarial Attacks Based on Deep Reinforcement Learning: A Replication and Extension Study,"Samuele Pasini, Gianluca Maragliano, Jinhan Kim, Paolo Tonella",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.19095"" target=""_blank"">2502.19095</a>",,2025-12-03 22:39:25
HALO: Robust Out-of-Distribution Detection via Joint Optimisation,"Hugo Lyons Keenan, Sarah Erfani, Christopher Leckie",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.19755"" target=""_blank"">2502.19755</a>","<a href=""https://github.com/hugo0076/HALO"" target=""_blank"">hugo0076</a>",2025-12-03 22:39:25
A Dual-Purpose Framework for Backdoor Defense and Backdoor Amplification in Diffusion Models,"Vu Tuan Truong Long, Bao Le",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.19047"" target=""_blank"">2502.19047</a>",,2025-12-03 22:39:25
Towards Label-Only Membership Inference Attack against Pre-trained Large Language Models,"Yu He, Boheng Li, Liu Liu, Zhongjie Ba, Wei Dong, Yiming Li, Zhan Qin, Kui Ren, Chun Chen",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.18943"" target=""_blank"">2502.18943</a>",,2025-12-03 22:39:25
Evaluation of Hate Speech Detection Using Large Language Models and Geographical Contextualization,"Anwar Hossain Zahid, Monoshi Kumar Roy, Swarna Das",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.19612"" target=""_blank"">2502.19612</a>",,2025-12-03 22:39:25
Beyond Surface-Level Patterns: An Essence-Driven Defense Framework Against Jailbreak Attacks in LLMs,"Shiyu Xiang, Ansen Zhang, Yanfei Cao, Yang Fan, Ronghao Chen",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.19041"" target=""_blank"">2502.19041</a>",,2025-12-03 22:39:25
Verification of Bit-Flip Attacks against Quantized Neural Networks,"Yedi Zhang, Lei Huang, Pengfei Gao, Fu Song, Jun Sun, Jin Song Dong",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16286"" target=""_blank"">2502.16286</a>",,2025-12-03 22:39:25
LLMs Have Rhythm: Fingerprinting Large Language Models Using Inter-Token Times and Network Traffic Analysis,"Saeif Alhazbi, Ahmed Mohamed Hussain, Gabriele Oligeri, Panos Papadimitratos",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.20589"" target=""_blank"">2502.20589</a>",,2025-12-03 22:39:25
Detecting OOD Samples via Optimal Transport Scoring Function,"Heng Gao, Zhuolin He, Jian Pu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16115"" target=""_blank"">2502.16115</a>","<a href=""https://github.com/HengGao12/OTOD"" target=""_blank"">HengGao12</a>",2025-12-03 22:39:25
ReVeil: Unconstrained Concealed Backdoor Attack on Deep Neural Networks using Machine Unlearning,"Manaar Alam, Hithem Lamri, Michail Maniatakos",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.11687"" target=""_blank"">2502.11687</a>",,2025-12-03 22:39:25
DemonAgent: Dynamically Encrypted Multi-Backdoor Implantation Attack on LLM-based Agent,"Pengyu Zhu, Zhenhong Zhou, Yuanhe Zhang, Shilinlu Yan, Kun Wang, Sen Su",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.12575"" target=""_blank"">2502.12575</a>","<a href=""https://github.com/whfeLingYu/DemonAgent"" target=""_blank"">whfeLingYu</a>",2025-12-03 22:39:25
The Hidden Risks of Large Reasoning Models: A Safety Assessment of R1,"Kaiwen Zhou, Chengzhi Liu, Xuandong Zhao, Shreedhar Jangam, Jayanth Srinivasa, Gaowen Liu, Dawn Song, Xin Eric Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.12659"" target=""_blank"">2502.12659</a>",,2025-12-03 22:39:25
Reasoning-to-Defend: Safety-Aware Reasoning Can Defend Large Language Models from Jailbreaking,"Junda Zhu, Lingyong Yan, Shuaiqiang Wang, Dawei Yin, Lei Sha",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.12970"" target=""_blank"">2502.12970</a>",,2025-12-03 22:39:25
A Fuzzy Evaluation of Sentence Encoders on Grooming Risk Classification,"Geetanjali Bihani, Julia Rayz",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.12576"" target=""_blank"">2502.12576</a>",,2025-12-03 22:39:25
"H-CoT: Hijacking the Chain-of-Thought Safety Reasoning Mechanism to Jailbreak Large Reasoning Models, Including OpenAI o1/o3, DeepSeek-R1, and Gemini 2","Martin Kuo, Jianyi Zhang, Aolin Ding, Qinsi Wang, Louis DiValentin, Yujia Bao, Wei Wei, Hai Li, Yiran Chen",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.12893"" target=""_blank"">2502.12893</a>",,2025-12-03 22:39:25
Fragility-aware Classification for Understanding Risk and Improving Generalization,"Chen Yang, Zheng Cui, Daniel Zhuoyu Long, Jin Qi, Ruohan Zhan",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.13024"" target=""_blank"">2502.13024</a>",,2025-12-03 22:39:25
On the Privacy Risks of Spiking Neural Networks: A Membership Inference Analysis,"Junyi Guan, Abhijith Sharma, Chong Tian, Salem Lahlou",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.13191"" target=""_blank"">2502.13191</a>",,2025-12-03 22:39:25
Rethinking Audio-Visual Adversarial Vulnerability from Temporal and Modality Perspectives,"Zeliang Zhang, Susan Liang, Daiki Shimada, Chenliang Xu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.11858"" target=""_blank"">2502.11858</a>",,2025-12-03 22:39:25
Towards Robust and Secure Embodied AI: A Survey on Vulnerabilities and Attacks,"Wenpeng Xing, Minghao Li, Mohan Li, Meng Han",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.13175"" target=""_blank"">2502.13175</a>",,2025-12-03 22:39:25
Adversary-Aware DPO: Enhancing Safety Alignment in Vision Language Models via Adversarial Training,"Fenghua Weng, Jian Lou, Jun Feng, Minlie Huang, Wenjie Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.11455"" target=""_blank"">2502.11455</a>",,2025-12-03 22:39:25
Adversarially Robust CLIP Models Can Induce Better (Robust) Perceptual Metrics,"Francesco Croce, Christian Schlarmann, Naman Deep Singh, Matthias Hein",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.11725"" target=""_blank"">2502.11725</a>",,2025-12-03 22:39:25
Independence Tests for Language Models,"Sally Zhu, Ahmed Ahmed, Rohith Kuditipudi, Percy Liang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.12292"" target=""_blank"">2502.12292</a>",,2025-12-03 22:39:25
"Adversarial Alignment for LLMs Requires Simpler, Reproducible, and More Measurable Objectives","Leo Schwinn, Yan Scholten, Tom Wollschläger, Sophie Xhonneux, Stephen Casper, Stephan Günnemann, Gauthier Gidel",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.11910"" target=""_blank"">2502.11910</a>",,2025-12-03 22:39:25
Preventing the Popular Item Embedding Based Attack in Federated Recommendations,"Jun Zhang, Huan Li, Dazhong Rong, Yan Zhao, Ke Chen, Lidan Shou",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.12958"" target=""_blank"">2502.12958</a>",,2025-12-03 22:39:25
Can LLM Watermarks Robustly Prevent Unauthorized Knowledge Distillation? (10%),"Leyi Pan, Aiwei Liu, Shiyu Huang, Yijian Lu, Xuming Hu, Lijie Wen, Irwin King, Philip S. Yu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.11598"" target=""_blank"">2502.11598</a>","<a href=""https://github.com/THU-BPM/Watermark-Radioactivity-Attack"" target=""_blank"">THU-BPM</a>",2025-12-03 22:39:25
Robust Partial-Label Learning by Leveraging Class Activation Values,"Tobias Fuchs, Florian Kalinke",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.11743"" target=""_blank"">2502.11743</a>",,2025-12-03 22:39:25
DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with Model Editing,"Yi Wang, Fenghua Weng, Sibei Yang, Zhan Qin, Minlie Huang, Wenjie Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.11647"" target=""_blank"">2502.11647</a>",,2025-12-03 22:39:25
AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection,"Weidi Luo, Shenghong Dai, Xiaogeng Liu, Suman Banerjee, Huan Sun, Muhao Chen, Chaowei Xiao",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.11448"" target=""_blank"">2502.11448</a>",,2025-12-03 22:39:25
To Think or Not to Think: Exploring the Unthinking Vulnerability in Large Reasoning Models,"Zihao Zhu, Hongbao Zhang, Ruotong Wang, Ke Xu, Siwei Lyu, Baoyuan Wu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.12202"" target=""_blank"">2502.12202</a>",,2025-12-03 22:39:25
ShieldLearner: A New Paradigm for Jailbreak Attack Defense in LLMs,"Ziyi Ni, Hao Wang, Huacan Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.13162"" target=""_blank"">2502.13162</a>",,2025-12-03 22:39:25
Multi-Faceted Multimodal Monosemanticity,"Hanqi Yan, Xiangxiang Cui, Lu Yin, Paul Pu Liang, Yulan He, Yifei Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.14888"" target=""_blank"">2502.14888</a>",,2025-12-03 22:39:25
ALGEN: Few-shot Inversion Attacks on Textual Embeddings using Alignment and Generation,"Yiyi Chen, Qiongkai Xu, Johannes Bjerva",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.11308"" target=""_blank"">2502.11308</a>",,2025-12-03 22:39:25
Mimicking the Familiar: Dynamic Command Generation for Information Theft Attacks in LLM Tool-Learning System,"Ziyou Jiang, Mingyang Li, Guowei Yang, Junjie Wang, Yuekai Huang, Zhiyuan Chang, Qing Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.11358"" target=""_blank"">2502.11358</a>",,2025-12-03 22:39:25
G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems,"Shilong Wang, Guibin Zhang, Miao Yu, Guancheng Wan, Fanci Meng, Chongye Guo, Kun Wang, Yang Wang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.11127"" target=""_blank"">2502.11127</a>","<a href=""https://github.com/wslong20/G-safeguard"" target=""_blank"">wslong20</a>",2025-12-03 22:39:25
CCJA: Context-Coherent Jailbreak Attack for Aligned Large Language Models,"Guanghao Zhou, Panjia Qiu, Mingyuan Fan, Cen Chen, Mingyuan Chu, Xin Zhang, Jun Zhou",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.11379"" target=""_blank"">2502.11379</a>",,2025-12-03 22:39:25
Merger-as-a-Stealer: Stealing Targeted PII from Aligned LLMs with Model Merging,"Lin Lu, Zhigang Zuo, Ziji Sheng, Pan Zhou",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16094"" target=""_blank"">2502.16094</a>",,2025-12-03 22:39:25
"UniGuardian: A Unified Defense for Detecting Prompt Injection, Backdoor Attacks and Adversarial Attacks in Large Language Models","Huawei Lin, Yingjie Lao, Tong Geng, Tan Yu, Weijie Zhao",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.13141"" target=""_blank"">2502.13141</a>",,2025-12-03 22:39:25
A Comprehensive Survey on Concept Erasure in Text-to-Image Diffusion Models,"Changhoon Kim, Yanjun Qi",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.14896"" target=""_blank"">2502.14896</a>",,2025-12-03 22:39:25
Iron Sharpens Iron: Defending Against Attacks in Machine-Generated Text Detection with Adversarial Training,"Yuanfan Li, Zhaohan Zhang, Chengzhengxu Li, Chao Shen, Xiaoming Liu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.12734"" target=""_blank"">2502.12734</a>","<a href=""https://github.com/Liyuuuu111/GREATER"" target=""_blank"">Liyuuuu111</a>",2025-12-03 22:39:25
Generalization Certificates for Adversarially Robust Bayesian Linear Regression,"Mahalakshmi Sabanayagam, Russell Tsuchida, Cheng Soon Ong, Debarghya Ghoshdastidar",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.14298"" target=""_blank"">2502.14298</a>",,2025-12-03 22:39:25
A generative approach to LLM harmfulness detection with special red flag tokens,"Sophie Xhonneux, David Dobre, Mehrnaz Mohfakhami, Leo Schwinn, Gauthier Gidel",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16366"" target=""_blank"">2502.16366</a>",,2025-12-03 22:39:25
Toward Robust Non-Transferable Learning: A Survey and Benchmark,"Ziming Hong, Yongli Xiang, Tongliang Liu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.13593"" target=""_blank"">2502.13593</a>",,2025-12-03 22:39:25
Cross-Model Transferability of Adversarial Patches in Real-time Segmentation for Autonomous Driving,"Prashant Shekhar, Bidur Devkota, Dumindu Samaraweera, Laxima Niure Kandel, Manoj Babu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16012"" target=""_blank"">2502.16012</a>","<a href=""https://github.com/p-shekhar/adversarial-patch-transferability"" target=""_blank"">p-shekhar</a>",2025-12-03 22:39:25
A Defensive Framework Against Adversarial Attacks on Machine Learning-Based Network Intrusion Detection Systems,"Benyamin Tafreshian, Shengzhi Zhang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.15561"" target=""_blank"">2502.15561</a>",,2025-12-03 22:39:25
Model Privacy: A Unified Framework to Understand Model Stealing Attacks and Defenses,"Ganghua Wang, Yuhong Yang, Jie Ding",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.15567"" target=""_blank"">2502.15567</a>",,2025-12-03 22:39:25
SafeInt: Shielding Large Language Models from Jailbreak Attacks via Safety-Aware Representation Intervention,"Jiaqi Wu, Chen Chen, Chunyan Hou, Xiaojie Yuan",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.15594"" target=""_blank"">2502.15594</a>",,2025-12-03 22:39:25
TurboFuzzLLM: Turbocharging Mutation-based Fuzzing for Effectively Jailbreaking Large Language Models in Practice,"Aman Goel, Xian Carrie Wu, Zhe Wang, Dmitriy Bespalov, Yanjun Qi",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.18504"" target=""_blank"">2502.18504</a>",,2025-12-03 22:39:25
A Survey of Model Extraction Attacks and Defenses in Distributed Computing Environments,"Kaixiang Zhao, Lincan Li, Kaize Ding, Neil Zhenqiang Gong, Yue Zhao, Yushun Dong",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16065"" target=""_blank"">2502.16065</a>",,2025-12-03 22:39:25
Single-pass Detection of Jailbreaking Input in Large Language Models,"Leyla Naz Candogan, Yongtao Wu, Elias Abad Rocamora, Grigorios G. Chrysos, Volkan Cevher",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.15435"" target=""_blank"">2502.15435</a>",,2025-12-03 22:39:25
EigenShield: Causal Subspace Filtering via Random Matrix Theory for Adversarially Robust Vision-Language Models,"Nastaran Darabi, Devashri Naik, Sina Tayebati, Dinithi Jayasuriya, Ranganath Krishnan, Amit Ranjan Trivedi",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.14976"" target=""_blank"">2502.14976</a>",,2025-12-03 22:39:25
Moshi Moshi? A Model Selection Hijacking Adversarial Attack,"Riccardo Petrucci, Luca Pajola, Francesco Marchiori, Luca Pasa, Mauro conti",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.14586"" target=""_blank"">2502.14586</a>",,2025-12-03 22:39:25
Interpreting Adversarial Attacks and Defences using Architectures with Enhanced Interpretability,"Akshay G Rao, Chandrashekhar Lakshminarayanan, Arun Rajkumar",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.15017"" target=""_blank"">2502.15017</a>",,2025-12-03 22:39:25
"On the Trustworthiness of Generative Foundation Models: Guideline, Assessment, and Perspective","Yue Huang, Chujie Gao, Siyuan Wu, Haoran Wang, Xiangqi Wang, Yujun Zhou, Yanbo Wang, Jiayi Ye, Jiawen Shi, Qihui Zhang, Yuan Li, Han Bao, Zhaoyi Liu, Tianrui Guan, Dongping Chen, Ruoxi Chen, Kehan Guo, Andy Zou, Bryan Hooi Kuen-Yew, Caiming Xiong, Elias Stengel-Eskin, Hongyang Zhang, Hongzhi Yin, Huan Zhang, Huaxiu Yao, Jaehong Yoon, Jieyu Zhang, Kai Shu, Kaijie Zhu, Ranjay Krishna, Swabha Swayamdipta, Taiwei Shi, Weijia Shi, Xiang Li, Yiwei Li, Yuexing Hao, Yuexing Hao, Zhihao Jia, Zhize Li, Xiuying Chen, Zhengzhong Tu, Xiyang Hu, Tianyi Zhou, Jieyu Zhao, Lichao Sun, Furong Huang, Or Cohen Sasson, Prasanna Sattigeri, Anka Reuel, Max Lamparth, Yue Zhao, Nouha Dziri, Yu Su, Huan Sun, Heng Ji, Chaowei Xiao, Mohit Bansal, Nitesh V. Chawla, Jian Pei, Jianfeng Gao, Michael Backes, Philip S. Yu, Neil Zhenqiang Gong, Pin-Yu Chen, Bo Li, Dawn Song, Xiangliang Zhang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.14296"" target=""_blank"">2502.14296</a>",,2025-12-03 22:39:25
A Multi-Scale Isolation Forest Approach for Real-Time Detection and Filtering of FGSM Adversarial Attacks in Video Streams of Autonomous Vehicles,"Richard Abhulimhen, Negash Begashaw, Gurcan Comert, Chunheng Zhao, Pierluigi Pisu",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.16044"" target=""_blank"">2502.16044</a>",,2025-12-03 22:39:25
Factor Graph-based Interpretable Neural Networks,"Yicong Li, Kuanjiu Zhou, Shuo Yu, Qiang Zhang, Renqiang Luo, Xiaodong Li, Feng Xia",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.14572"" target=""_blank"">2502.14572</a>",,2025-12-03 22:39:25
Reliable Explainability of Deep Learning Spatial-Spectral Classifiers for Improved Semantic Segmentation in Autonomous Driving,"Jon Gutiérrez-Zaballa, Koldo Basterretxea, Javier Echanobe",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.14416"" target=""_blank"">2502.14416</a>",,2025-12-03 22:39:25
Efficient and Optimal Policy Gradient Algorithm for Corrupted Multi-armed Bandits,"Jiayuan Liu, Siwei Wang, Zhixuan Fang",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.14146"" target=""_blank"">2502.14146</a>",,2025-12-03 22:39:25
PPO-MI: Efficient Black-Box Model Inversion via Proximal Policy Optimization,Xinpeng Shou,arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.14370"" target=""_blank"">2502.14370</a>",,2025-12-03 22:39:25
SLAMSpoof: Practical LiDAR Spoofing Attacks on Localization Systems Guided by Scan Matching Vulnerability Analysis,"Rokuto Nagata, Kenji Koide, Yuki Hayakawa, Ryo Suzuki, Kazuma Ikeda, Ozora Sako, Qi Alfred Chen, Takami Sato, Kentaro Yoshioka",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.13641"" target=""_blank"">2502.13641</a>","<a href=""https://github.com/Keio-CSG/slamspoof"" target=""_blank"">Keio-CSG</a>",2025-12-03 22:39:25
Exploiting Prefix-Tree in Structured Output Interfaces for Enhancing Jailbreak Attacking,"Yanzeng Li, Yunfan Xiong, Jialun Zhong, Jinchao Zhang, Jie Zhou, Lei Zou",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.13527"" target=""_blank"">2502.13527</a>",,2025-12-03 22:39:25
Benchmarking Android Malware Detection: Rethinking the Role of Traditional and Deep Learning Models,"Guojun Liu, Doina Caragea, Xinming Ou, Sankardas Roy",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.15041"" target=""_blank"">2502.15041</a>",,2025-12-03 22:39:25
Poisoned Source Code Detection in Code Models,"Ehab Ghannoum, Mohammad Ghafari",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.13459"" target=""_blank"">2502.13459</a>",,2025-12-03 22:39:25
Fundamental Limitations in Defending LLM Finetuning APIs,"Xander Davies, Eric Winsor, Tomek Korbak, Alexandra Souly, Robert Kirk, Witt Christian Schroeder de, Yarin Gal",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.14828"" target=""_blank"">2502.14828</a>",,2025-12-03 22:39:25
MACPruning: Dynamic Operation Pruning to Mitigate Side-Channel DNN Model Extraction,"Ruyi Ding, Cheng Gongye, Davis Ranney, Aidong Adam Ding, Yunsi Fei",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.15020"" target=""_blank"">2502.15020</a>",,2025-12-03 22:39:25
Probabilistic Robustness in Deep Learning: A Concise yet Comprehensive Guide,Xingyu Zhao,arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.14833"" target=""_blank"">2502.14833</a>",,2025-12-03 22:39:25
Towards a perturbation-based explanation for medical AI as differentiable programs,"Takeshi Abe, Yoshiyuki Asai",arXiv,2025-02,"<a href=""http://arxiv.org/abs/2502.14001"" target=""_blank"">2502.14001</a>",,2025-12-03 22:39:25
Fine-tuning is Not Fine: Mitigating Backdoor Attacks in GNNs with Limited Clean Data,"Jiale Zhang, Bosen Rao, Chengcheng Zhu, Xiaobing Sun, Qingming Li, Haibo Hu, Xiapu Luo, Qingqing Ye, Shouling Ji",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.05835"" target=""_blank"">2501.05835</a>",,2025-12-03 22:39:25
KeTS: Kernel-based Trust Segmentation against Model Poisoning Attacks,"Ankit Gangwal, Mauro Conti, Tommaso Pauselli",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.06729"" target=""_blank"">2501.06729</a>",,2025-12-03 22:39:25
ZOQO: Zero-Order Quantized Optimization,"Noga Bar, Raja Giryes",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.06736"" target=""_blank"">2501.06736</a>",,2025-12-03 22:39:25
Protego: Detecting Adversarial Examples for Vision Transformers via Intrinsic Capabilities,"Jialin Wu, Kaikai Pan, Yanjiao Chen, Jiangyi Deng, Shengyuan Pang, Wenyuan Xu",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.07044"" target=""_blank"">2501.07044</a>",,2025-12-03 22:39:25
RogueRFM: Attacking Refresh Management for Covert-Channel and Denial-of-Service,"Hritvik Taneja, Moinuddin Qureshi",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.06646"" target=""_blank"">2501.06646</a>",,2025-12-03 22:39:25
SafeSplit: A Novel Defense Against Client-Side Backdoor Attacks in Split Learning,"Phillip Rieger, Alessandro Pegoraro, Kavita Kumari, Tigist Abera, Jonathan Knauer, Ahmad-Reza Sadeghi",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.06650"" target=""_blank"">2501.06650</a>",,2025-12-03 22:39:25
Effective faking of verbal deception detection with target-aligned adversarial attacks,"Bennett Kleinberg, Riccardo Loconte, Bruno Verschuere",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.05962"" target=""_blank"">2501.05962</a>",,2025-12-03 22:39:25
UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping,"Yanjie Li, Wenxuan Zhang, Kaisheng Liang, Bin Xiao",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.05783"" target=""_blank"">2501.05783</a>",,2025-12-03 22:39:25
DiffAttack: Diffusion-based Timbre-reserved Adversarial Attack in Speaker Identification,"Qing Wang, Jixun Yao, Zhaokai Sun, Pengcheng Guo, Lei Xie, John H. L. Hansen",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.05127"" target=""_blank"">2501.05127</a>",,2025-12-03 22:39:25
Towards Backdoor Stealthiness in Model Parameter Space,"Xiaoyun Xu, Zhuoran Liu, Stefanos Koffas, Stjepan Picek",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.05928"" target=""_blank"">2501.05928</a>",,2025-12-03 22:39:25
An Attention-Guided Deep Learning Approach for Classifying 39 Skin Lesion Types,"Sauda Adiv Hanum, Ashim Dey, Muhammad Ashad Kabir",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.05991"" target=""_blank"">2501.05991</a>","<a href=""https://github.com/akabircs/Skin-Lesions-Classification"" target=""_blank"">akabircs</a>",2025-12-03 22:39:25
HPAC-IDS: A Hierarchical Packet Attention Convolution for Intrusion Detection System,"Anass Grini, Btissam El Khamlichi, Abdellatif El Afia, Amal El Fallah-Seghrouchni",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.06264"" target=""_blank"">2501.06264</a>",,2025-12-03 22:39:25
A Survey of Early Exit Deep Neural Networks in NLP,"Divya Jyoti Bajpai, Manjesh Kumar Hanawal",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.07670"" target=""_blank"">2501.07670</a>",,2025-12-03 22:39:25
Enforcing Fundamental Relations via Adversarial Attacks on Input Parameter Correlations,"Timo Saala, Lucie Flek, Alexander Jung, Akbar Karimi, Alexander Schmidt, Matthias Schott, Philipp Soldin, Christopher Wiebusch",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.05588"" target=""_blank"">2501.05588</a>",,2025-12-03 22:39:25
SpaLLM-Guard: Pairing SMS Spam Detection Using Open-source and Commercial LLMs,"Muhammad Salman, Muhammad Ikram, Nardine Basta, Mohamed Ali Kaafar",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.04985"" target=""_blank"">2501.04985</a>",,2025-12-03 22:39:25
SC-Pro: Training-Free Framework for Defending Unsafe Image Synthesis Attack,"Junha Park, Jaehui Hwang, Ian Ryu, Hyungkeun Park, Jiyoon Kim, Jong-Seok Lee",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.05359"" target=""_blank"">2501.05359</a>",,2025-12-03 22:39:25
"On Measuring Unnoticeability of Graph Adversarial Attacks: Observations, New Measure, and Applications","Hyeonsoo Jo, Hyunjin Hwang, Fanchen Bu, Soo Yong Lee, Chanyoung Park, Kijung Shin",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.05015"" target=""_blank"">2501.05015</a>",,2025-12-03 22:39:25
KabaddiPy: A package to enable access to Professional Kabaddi Data,"Bhaskar Lalwani, Aniruddha Mukherjee",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.05168"" target=""_blank"">2501.05168</a>","<a href=""https://github.com/kabaddiPy/kabaddiPy"" target=""_blank"">kabaddiPy</a>",2025-12-03 22:39:25
Is Your Autonomous Vehicle Safe? Understanding the Threat of Electromagnetic Signal Injection Attacks on Traffic Scene Perception,"Wenhao Liao, Sineng Yan, Youqian Zhang, Xinwei Zhai, Yuanyuan Wang, Eugene Yujun Fu",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.05239"" target=""_blank"">2501.05239</a>",,2025-12-03 22:39:25
Towards the Pseudorandomness of Expander Random Walks for Read-Once ACC0 circuits,Emile Anand,arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.07752"" target=""_blank"">2501.07752</a>",,2025-12-03 22:39:25
Gandalf the Red: Adaptive Security for LLMs,"Niklas Pfister, Václav Volhejn, Manuel Knott, Santiago Arias, Julia Bazińska, Mykhailo Bichurin, Alan Commike, Janet Darling, Peter Dienes, Matthew Fiedler, David Haber, Matthias Kraft, Marco Lancini, Max Mathys, Damián Pascual-Ortiz, Jakub Podolak, Adrià Romero-López, Kyriacos Shiarlis, Andreas Signer, Zsolt Terek, Athanasios Theocharis, Daniel Timbrell, Samuel Trautwein, Samuel Watts, Yun-Han Wu, Mateo Rojas-Carulla",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.07927"" target=""_blank"">2501.07927</a>",,2025-12-03 22:39:25
A4O: All Trigger for One sample,"Duc Anh Vu, Anh Tuan Tran, Cong Tran, Cuong Pham",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.07192"" target=""_blank"">2501.07192</a>",,2025-12-03 22:39:25
ARMOR: Shielding Unlearnable Examples against Data Augmentation,"Xueluan Gong, Yuji Wang, Yanjiao Chen, Haocheng Dong, Yiming Li, Mengyuan Sun, Shuaike Li, Qian Wang, Chen Chen",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.08862"" target=""_blank"">2501.08862</a>",,2025-12-03 22:39:25
Latent-space adversarial training with post-aware calibration for defending large language models against jailbreak attacks,"Xin Yi, Yue Li, Dongsheng Shi, Linlin Wang, Xiaoling Wang, Liang He",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.10639"" target=""_blank"">2501.10639</a>",,2025-12-03 22:39:25
LayerMix: Enhanced Data Augmentation through Fractal Integration for Robust Deep Learning,"Hafiz Mughees Ahmad, Dario Morle, Afshin Rahimi",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.04861"" target=""_blank"">2501.04861</a>","<a href=""https://github.com/ahmadmughees/layermix"" target=""_blank"">ahmadmughees</a>",2025-12-03 22:39:25
Double Visual Defense: Adversarial Pre-training and Instruction Tuning for Improving Vision-Language Model Robustness,"Zeyu Wang, Cihang Xie, Brian Bartoldson, Bhavya Kailkhura",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.09446"" target=""_blank"">2501.09446</a>","<a href=""https://doublevisualdefense.github.io/"" target=""_blank"">doublevisualdefense.github.io</a>",2025-12-03 22:39:25
Adversarial-Ensemble Kolmogorov Arnold Networks for Enhancing Indoor Wi-Fi Positioning: A Defensive Approach Against Spoofing and Signal Manipulation Attacks,"Mitul Goswami, Romit Chatterjee, Somnath Mahato, Prasant Kumar Pattnaik",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.09609"" target=""_blank"">2501.09609</a>",,2025-12-03 22:39:25
Cooperative Decentralized Backdoor Attacks on Vertical Federated Learning,"Seohyun Lee, Wenzhi Fang, Anindya Bijoy Das, Seyyedali Hosseinalipour, David J. Love, Christopher G. Brinton",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.09320"" target=""_blank"">2501.09320</a>",,2025-12-03 22:39:25
Computing Optimization-Based Prompt Injections Against Closed-Weights Models By Misusing a Fine-Tuning API,"Andrey Labunets, Nishit V. Pandya, Ashish Hooda, Xiaohan Fu, Earlence Fernandes",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.09798"" target=""_blank"">2501.09798</a>",,2025-12-03 22:39:25
Neural Honeytrace: A Robust Plug-and-Play Watermarking Framework against Model Extraction Attacks,"Yixiao Xu, Binxing Fang, Rui Wang, Yinghai Zhou, Shouling Ji, Yuan Liu, Mohan Li, Zhihong Tian",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.09328"" target=""_blank"">2501.09328</a>",,2025-12-03 22:39:25
Salient Information Preserving Adversarial Training Improves Clean and Robust Accuracy,"Timothy Redgrave, Adam Czajka",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.09086"" target=""_blank"">2501.09086</a>",,2025-12-03 22:39:25
Improving Stability Estimates in Adversarial Explainable AI through Alternate Search Methods,"Christopher Burger, Charles Walter",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.09006"" target=""_blank"">2501.09006</a>",,2025-12-03 22:39:25
Generating Poisoning Attacks against Ridge Regression Models with Categorical Features,"Monse Guedes-Ayala, Lars Schewe, Zeynep Suvak, Miguel Anjos",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.07275"" target=""_blank"">2501.07275</a>",,2025-12-03 22:39:25
Improving the Efficiency of Self-Supervised Adversarial Training through Latent Clustering-Based Selection,"Somrita Ghosh, Yuelin Xu, Xiao Zhang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.10466"" target=""_blank"">2501.10466</a>",,2025-12-03 22:39:25
VENOM: Text-driven Unrestricted Adversarial Example Generation with Diffusion Models,"Hui Kuurila-Zhang, Haoyu Chen, Guoying Zhao",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.07922"" target=""_blank"">2501.07922</a>",,2025-12-03 22:39:25
Cross-Modal Transferable Image-to-Video Attack on Video Quality Metrics,"Georgii Gotin, Ekaterina Shumitskaya, Anastasia Antsiferova, Dmitriy Vatolin",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.08415"" target=""_blank"">2501.08415</a>",,2025-12-03 22:39:25
Towards an End-to-End (E2E) Adversarial Learning and Application in the Physical World,"Dudi Biton, Jacob Shams, Satoru Koda, Asaf Shabtai, Yuval Elovici, Ben Nassi",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.08258"" target=""_blank"">2501.08258</a>",,2025-12-03 22:39:25
Energy Backdoor Attack to Deep Neural Networks,"Hanene F. Z. Brachemi Meftah, Wassim Hamidouche, Sid Ahmed Fezza, Olivier Déforges, Kassem Kallas",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.08152"" target=""_blank"">2501.08152</a>","<a href=""https://github.com/hbrachemi/energy_backdoor"" target=""_blank"">hbrachemi</a>",2025-12-03 22:39:25
Playing Devil's Advocate: Unmasking Toxicity and Vulnerabilities in Large Vision-Language Models,"Abdulkadir Erol, Trilok Padhi, Agnik Saha, Ugur Kursuncu, Mehmet Emin Aktas",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.09039"" target=""_blank"">2501.09039</a>",,2025-12-03 22:39:25
MOS-Attack: A Scalable Multi-objective Adversarial Attack Framework,"Ping Guo, Cheng Gong, Xi Lin, Fei Liu, Zhichao Lu, Qingfu Zhang, Zhenkun Wang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.07251"" target=""_blank"">2501.07251</a>",,2025-12-03 22:39:25
Exploring and Mitigating Adversarial Manipulation of Voting-Based Leaderboards,"Yangsibo Huang, Milad Nasr, Anastasios Angelopoulos, Nicholas Carlini, Wei-Lin Chiang, Christopher A. Choquette-Choo, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Ken Ziyu Liu, Ion Stoica, Florian Tramer, Chiyuan Zhang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.07493"" target=""_blank"">2501.07493</a>",,2025-12-03 22:39:25
RAG-WM: An Efficient Black-Box Watermarking Approach for Retrieval-Augmented Generation of Large Language Models,"Peizhuo Lv, Mengjie Sun, Hao Wang, Xiaofeng Wang, Shengzhi Zhang, Yuxuan Chen, Kai Chen, Limin Sun",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.05249"" target=""_blank"">2501.05249</a>",,2025-12-03 22:39:25
Stealthy Backdoor Attack to Real-world Models in Android Apps,"Jiali Wei, Ming Fan, Xicheng Zhang, Wenjing Jiao, Haijun Wang, Ting Liu",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.01263"" target=""_blank"">2501.01263</a>",,2025-12-03 22:39:25
Reproducing HotFlip for Corpus Poisoning Attacks in Dense Retrieval,"Yongkang Li, Panagiotis Eustratiadis, Evangelos Kanoulas",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.04802"" target=""_blank"">2501.04802</a>",,2025-12-03 22:39:25
Gradient Purification: Defense Against Poisoning Attack in Decentralized Federated Learning,"Bin Li, Xiaoye Miao, Yongheng Shang, Xinkui Zhao, Shuiguang Deng, Jianwei Yin",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.04453"" target=""_blank"">2501.04453</a>",,2025-12-03 22:39:25
Adaptive Meta-learning-based Adversarial Training for Robust Automatic Modulation Classification,"Amirmohammad Bamdad, Ali Owfi, Fatemeh Afghah",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.01620"" target=""_blank"">2501.01620</a>",,2025-12-03 22:39:25
AIM: Additional Image Guided Generation of Transferable Adversarial Attacks,"Teng Li, Xingjun Ma, Yu-Gang Jiang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.01106"" target=""_blank"">2501.01106</a>",,2025-12-03 22:39:25
HoneypotNet: Backdoor Attacks Against Model Extraction,"Yixu Wang, Tianle Gu, Yan Teng, Yingchun Wang, Xingjun Ma",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.01090"" target=""_blank"">2501.01090</a>",,2025-12-03 22:39:25
Improving Robustness Estimates in Natural Language Explainable AI though Synonymity Weighted Similarity Measures,Christopher Burger,arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.01516"" target=""_blank"">2501.01516</a>",,2025-12-03 22:39:25
SAFER: Sharpness Aware layer-selective Finetuning for Enhanced Robustness in vision transformers,"Bhavna Gopal, Huanrui Yang, Mark Horton, Yiran Chen",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.01529"" target=""_blank"">2501.01529</a>",,2025-12-03 22:39:25
Test Input Validation for Vision-based DL Systems: An Active Learning Approach,"Delaram Ghobari, Mohammad Hossein Amini, Dai Quoc Tran, Seunghee Park, Shiva Nejati, Mehrdad Sabetzadeh",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.01606"" target=""_blank"">2501.01606</a>",,2025-12-03 22:39:25
Predicting the Performance of Black-box LLMs through Self-Queries,"Dylan Sam, Marc Finzi, J. Zico Kolter",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.01558"" target=""_blank"">2501.01558</a>",,2025-12-03 22:39:25
Boosting Adversarial Transferability with Spatial Adversarial Alignment,"Zhaoyu Chen, Haijing Guo, Kaixun Jiang, Jiyuan Fu, Xinyu Zhou, Dingkang Yang, Hao Tang, Bo Li, Wenqiang Zhang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.01015"" target=""_blank"">2501.01015</a>",,2025-12-03 22:39:25
Towards Adversarially Robust Deep Metric Learning,Xiaopeng Ke,arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.01025"" target=""_blank"">2501.01025</a>",,2025-12-03 22:39:25
Image-based Multimodal Models as Intruders: Transferable Multimodal Attacks on Video-based MLLMs,"Linhao Huang, Xue Jiang, Zhiqiang Wang, Wentao Mo, Xi Xiao, Bo Han, Yongjie Yin, Feng Zheng",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.01042"" target=""_blank"">2501.01042</a>",,2025-12-03 22:39:25
Dynamics of Adversarial Attacks on Large Language Model-Based Search Engines,Xiyang Hu,arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.00745"" target=""_blank"">2501.00745</a>",,2025-12-03 22:39:25
TrustRAG: Enhancing Robustness and Trustworthiness in Retrieval-Augmented Generation,"Huichi Zhou, Kin-Hei Lee, Zhonghao Zhan, Yue Chen, Zhenhao Li, Zhaoyang Wang, Hamed Haddadi, Emine Yilmaz",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.00879"" target=""_blank"">2501.00879</a>",,2025-12-03 22:39:25
Defense Strategies for Autonomous Multi-agent Systems: Ensuring Safety and Resilience Under Exponentially Unbounded FDI Attacks,"Yichao Wang, Mohamadamin Rajabinezhad, Dimitra Panagou, Shan Zuo",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.00973"" target=""_blank"">2501.00973</a>",,2025-12-03 22:39:25
How Breakable Is Privacy: Probing and Resisting Model Inversion Attacks in Collaborative Inference,Rongke Liu,arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.00824"" target=""_blank"">2501.00824</a>",,2025-12-03 22:39:25
Everywhere Attack: Attacking Locally and Globally to Boost Targeted Transferability,"Hui Zeng, Sanshuai Cui, Biwei Chen, Anjie Peng",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.00707"" target=""_blank"">2501.00707</a>",,2025-12-03 22:39:25
Extending XReason: Formal Explanations for Adversarial Detection,"Amira Jemaa, Adnan Rashid, Sofiene Tahar",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.00537"" target=""_blank"">2501.00537</a>",,2025-12-03 22:39:25
On Adversarial Robustness of Language Models in Transfer Learning,"Bohdan Turbal, Anastasiia Mazur, Jiaxu Zhao, Mykola Pechenizkiy",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.00066"" target=""_blank"">2501.00066</a>",,2025-12-03 22:39:25
LLM-Virus: Evolutionary Jailbreak Attack on Large Language Models,"Miao Yu, Junfeng Fang, Yingjie Zhou, Xing Fan, Kun Wang, Shirui Pan, Qingsong Wen",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.00055"" target=""_blank"">2501.00055</a>",,2025-12-03 22:39:25
"CaFA: Cost-aware, Feasible Attacks With Database Constraints Against Neural Tabular Classifiers","Matan Ben-Tov, Daniel Deutch, Nave Frost, Mahmood Sharif",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.10013"" target=""_blank"">2501.10013</a>",,2025-12-03 22:39:25
How Toxic Can You Get? Search-based Toxicity Testing for Large Language Models,"Simone Corbo, Luca Bancale, Gennaro Valeria De, Livia Lestingi, Vincenzo Scotti, Matteo Camilli",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.01741"" target=""_blank"">2501.01741</a>",,2025-12-03 22:39:25
AdaMixup: A Dynamic Defense Framework for Membership Inference Attack Mitigation,"Ying Chen, Jiajing Chen, Yijie Weng, ChiaHua Chang, Dezhi Yu, Guanbiao Lin",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.02182"" target=""_blank"">2501.02182</a>",,2025-12-03 22:39:25
Mingling with the Good to Backdoor Federated Learning,Nuno Neves,arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.01913"" target=""_blank"">2501.01913</a>",,2025-12-03 22:39:25
Layer-Level Self-Exposure and Patch: Affirmative Token Mitigation for Jailbreak Attack Defense,"Yang Ouyang, Hengrui Gu, Shuhang Lin, Wenyue Hua, Jie Peng, Bhavya Kailkhura, Meijun Gao, Tianlong Chen, Kaixiong Zhou",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.02629"" target=""_blank"">2501.02629</a>","<a href=""https://github.com/oyy2000/LayerAdvPatcher"" target=""_blank"">oyy2000</a>",2025-12-03 22:39:25
Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency,"Shiji Zhao, Ranjie Duan, Fengxiang Wang, Chi Chen, Caixin Kang, Jialing Tao, YueFeng Chen, Hui Xue, Xingxing Wei",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.04931"" target=""_blank"">2501.04931</a>",,2025-12-03 22:39:25
Towards Fair Class-wise Robustness: Class Optimal Distribution Adversarial Training,"Hongxin Zhi, Hongtao Yu, Shaome Li, Xiuming Zhao, Yiteng Wu",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.04527"" target=""_blank"">2501.04527</a>",,2025-12-03 22:39:25
Rethinking Adversarial Attacks in Reinforcement Learning from Policy Distribution Perspective,"Tianyang Duan, Zongyuan Zhang, Zheng Lin, Yue Gao, Ling Xiong, Yong Cui, Hongbin Liang, Xianhao Chen, Heming Cui, Dong Huang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.03562"" target=""_blank"">2501.03562</a>",,2025-12-03 22:39:25
FlipedRAG: Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation of Large Language Models,"Zhuo Chen, Yuyang Gong, Miaokun Chen, Haotan Liu, Qikai Cheng, Fan Zhang, Wei Lu, Xiaozhong Liu, Jiawei Liu",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.02968"" target=""_blank"">2501.02968</a>",,2025-12-03 22:39:25
An Empirical Study of Accuracy-Robustness Tradeoff and Training Efficiency in Self-Supervised Learning,"Fatemeh Ghofrani, Pooyan Jamshidi",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.03507"" target=""_blank"">2501.03507</a>","<a href=""https://github.com/softsys4ai/CF-AMC-SSL"" target=""_blank"">softsys4ai</a>",2025-12-03 22:39:25
Rethinking Byzantine Robustness in Federated Recommendation from Sparse Aggregation Perspective,"Zhongjian Zhang, Mengmei Zhang, Xiao Wang, Lingjuan Lyu, Bo Yan, Junping Du, Chuan Shi",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.03301"" target=""_blank"">2501.03301</a>",,2025-12-03 22:39:25
Seeing the Whole in the Parts in Self-Supervised Representation Learning,"Arthur Aubret, Céline Teulière, Jochen Triesch",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.02860"" target=""_blank"">2501.02860</a>",,2025-12-03 22:39:25
GCP: Guarded Collaborative Perception with Spatial-Temporal Aware Malicious Agent Detection,"Yihang Tao, Senkang Hu, Yue Hu, Haonan An, Hangcheng Cao, Yuguang Fang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.02450"" target=""_blank"">2501.02450</a>","<a href=""https://github.com/CP-Security/GCP"" target=""_blank"">CP-Security</a>",2025-12-03 22:39:25
"Tougher Text, Smarter Models: Raising the Bar for Adversarial Defence Benchmarks","Yang Wang, Chenghua Lin",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.02654"" target=""_blank"">2501.02654</a>",,2025-12-03 22:39:25
AVTrustBench: Assessing and Enhancing Reliability and Robustness in Audio-Visual LLMs,"Sanjoy Chowdhury, Sayan Nag, Subhrajyoti Dasgupta, Yaoting Wang, Mohamed Elhoseiny, Ruohan Gao, Dinesh Manocha",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.02135"" target=""_blank"">2501.02135</a>",,2025-12-03 22:39:25
Persistence of Backdoor-based Watermarks for Neural Networks: A Comprehensive Evaluation,"Anh Tu Ngo, Chuan Song Heng, Nandish Chattopadhyay, Anupam Chattopadhyay",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.02704"" target=""_blank"">2501.02704</a>",,2025-12-03 22:39:25
Distillation-Enhanced Physical Adversarial Attacks,"Wei Liu, Yonglin Wu, Chaoqun Li, Zhuodong Liu, Huanqian Yan",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.02232"" target=""_blank"">2501.02232</a>",,2025-12-03 22:39:25
Zero-Shot Statistical Tests for LLM-Generated Text Detection using Finite Sample Concentration Inequalities,"Tara Radvand, Mojtaba Abdolmaleki, Mohamed Mostagir, Ambuj Tewari",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.02406"" target=""_blank"">2501.02406</a>","<a href=""https://github.com/TaraRadvand74/llm-text-detection"" target=""_blank"">TaraRadvand74</a>",2025-12-03 22:39:25
Backdoor Token Unlearning: Exposing and Defending Backdoors in Pretrained Language Models,"Peihai Jiang, Xixiang Lyu, Yige Li, Jing Ma",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.03272"" target=""_blank"">2501.03272</a>","<a href=""https://github.com/XDJPH/BTU"" target=""_blank"">XDJPH</a>",2025-12-03 22:39:25
BADTV: Unveiling Backdoor Threats in Third-Party Task Vectors,"Chia-Yi Hsu, Yu-Lin Tsai, Yu Zhe, Yan-Lun Chen, Chih-Hsun Lin, Chia-Mu Yu, Yang Zhang, Chun-Ying Huang, Jun Sakuma",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.02373"" target=""_blank"">2501.02373</a>",,2025-12-03 22:39:25
Towards Robust and Accurate Stability Estimation of Local Surrogate Models in Text-based Explainable AI,"Christopher Burger, Charles Walter, Thai Le, Lingwei Chen",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.02042"" target=""_blank"">2501.02042</a>",,2025-12-03 22:39:25
Exploring Secure Machine Learning Through Payload Injection and FGSM Attacks on ResNet-50,"Umesh Yadav, Suman Niraula, Gaurav Kumar Gupta, Bicky Yadav",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.02147"" target=""_blank"">2501.02147</a>",,2025-12-03 22:39:25
Rerouting LLM Routers,"Avital Shafran, Roei Schuster, Thomas Ristenpart, Vitaly Shmatikov",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.01818"" target=""_blank"">2501.01818</a>",,2025-12-03 22:39:25
Differentiable Adversarial Attacks for Marked Temporal Point Processes,"Pritish Chakraborty, Vinayak Gupta, Rahul R, Srikanta J. Bedathur, Abir De",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.10606"" target=""_blank"">2501.10606</a>",,2025-12-03 22:39:25
GaussMark: A Practical Approach for Structural Watermarking of Language Models,"Adam Block, Ayush Sekhari, Alexander Rakhlin",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.13941"" target=""_blank"">2501.13941</a>",,2025-12-03 22:39:25
"A comprehensive survey on RPL routing-based attacks, defences and future directions in Internet of Things","Anil K Prajapati, Emmanuel S Pilli, Ramesh B Battula, Vijay Varadharajan, Abhishek Verma, R C Joshi",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.10817"" target=""_blank"">2501.10817</a>",,2025-12-03 22:39:25
Hiding in Plain Sight: An IoT Traffic Camouflage Framework for Enhanced Privacy,"Daniel Adu Worae, Spyridon Mastorakis",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.15395"" target=""_blank"">2501.15395</a>",,2025-12-03 22:39:25
Scanning Trojaned Models Using Out-of-Distribution Samples,"Hossein Mirzaei, Ali Ansari, Bahar Dibaei Nia, Mojtaba Nafez, Moein Madadi, Sepehr Rezaee, Zeinab Sadat Taghavi, Arad Maleki, Kian Shamsaie, Mahdi Hajialilue, Jafar Habibi, Mohammad Sabokrou, Mohammad Hossein Rohban",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.17151"" target=""_blank"">2501.17151</a>",,2025-12-03 22:39:25
Document Screenshot Retrievers are Vulnerable to Pixel Poisoning Attacks,"Shengyao Zhuang, Ekaterina Khramtsova, Xueguang Ma, Bevan Koopman, Jimmy Lin, Guido Zuccon",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.16902"" target=""_blank"">2501.16902</a>",,2025-12-03 22:39:25
Do We Really Need to Design New Byzantine-robust Aggregation Rules? (13%),"Minghong Fang, Seyedsina Nabavirazavi, Zhuqing Liu, Wei Sun, Sundararaja Sitharama Iyengar, Haibo Yang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.17381"" target=""_blank"">2501.17381</a>",,2025-12-03 22:39:25
Graph of Attacks with Pruning: Optimizing Stealthy Jailbreak Prompt Generation for Enhanced LLM Content Moderation,"Daniel Schwartz, Dmitriy Bespalov, Zhe Wang, Ninad Kulkarni, Yanjun Qi",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.18638"" target=""_blank"">2501.18638</a>","<a href=""https://github.com/dsbuddy/GAP-LLM-Safety"" target=""_blank"">dsbuddy</a>",2025-12-03 22:39:25
xJailbreak: Representation Space Guided Reinforcement Learning for Interpretable LLM Jailbreaking,"Sunbowen Lee, Shiwen Ni, Chi Wei, Shuaimin Li, Liyang Fan, Ahmadreza Argha, Hamid Alinejad-Rokny, Ruifeng Xu, Yicheng Gong, Min Yang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.16727"" target=""_blank"">2501.16727</a>","<a href=""https://github.com/Aegis1863/xJailbreak"" target=""_blank"">Aegis1863</a>",2025-12-03 22:39:25
RODEO: Robust Outlier Detection via Exposing Adaptive Out-of-Distribution Samples,"Hossein Mirzaei, Mohammad Jafari, Hamid Reza Dehbashi, Ali Ansari, Sepehr Ghobadi, Masoud Hadi, Arshia Soltani Moakhar, Mohammad Azizmalayeri, Mahdieh Soleymani Baghshah, Mohammad Hossein Rohban",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.16971"" target=""_blank"">2501.16971</a>",,2025-12-03 22:39:25
A Dual-Agent Adversarial Framework for Robust Generalization in Deep Reinforcement Learning,"Zhengpeng Xie, Jiahang Cao, Yulong Zhang, Qiang Zhang, Renjing Xu",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.17384"" target=""_blank"">2501.17384</a>",,2025-12-03 22:39:25
WASUP: Interpretable Classification with Weight-Input Alignment and Class-Discriminative SUPports Vectors,"Tom Nuno Wolf, Christian Wachinger",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.17328"" target=""_blank"">2501.17328</a>",,2025-12-03 22:39:25
The Relationship Between Network Similarity and Transferability of Adversarial Attacks,"Gerrit Klause, Niklas Bunzel",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.18629"" target=""_blank"">2501.18629</a>",,2025-12-03 22:39:25
Data-Free Model-Related Attacks: Unleashing the Potential of Generative AI,"Dayong Ye, Tianqing Zhu, Shang Wang, Bo Liu, Leo Yu Zhang, Wanlei Zhou, Yang Zhang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.16671"" target=""_blank"">2501.16671</a>",,2025-12-03 22:39:25
Towards Safe AI Clinicians: A Comprehensive Study on Large Language Model Jailbreaking in Healthcare,"Hang Zhang, Qian Lou, Yanshan Wang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.18632"" target=""_blank"">2501.18632</a>",,2025-12-03 22:39:25
Indiana Jones: There Are Always Some Useful Ancient Relics,"Junchen Ding, Jiahao Zhang, Yi Liu, Ziqi Ding, Gelei Deng, Yuekang Li",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.18628"" target=""_blank"">2501.18628</a>",,2025-12-03 22:39:25
LLM-attacker: Enhancing Closed-loop Adversarial Scenario Generation for Autonomous Driving with Large Language Models,"Yuewen Mei, Tong Nie, Jian Sun, Ye Tian",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.15850"" target=""_blank"">2501.15850</a>",,2025-12-03 22:39:25
Data Duplication: A Novel Multi-Purpose Attack Paradigm in Machine Unlearning,"Dayong Ye, Tianqing Zhu, Jiayang Li, Kun Gao, Bo Liu, Leo Yu Zhang, Wanlei Zhou, Yang Zhang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.16663"" target=""_blank"">2501.16663</a>",,2025-12-03 22:39:25
Mitigating Spurious Negative Pairs for Robust Industrial Anomaly Detection,"Hossein Mirzaei, Mojtaba Nafez, Jafar Habibi, Mohammad Sabokrou, Mohammad Hossein Rohban",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.15434"" target=""_blank"">2501.15434</a>","<a href=""https://github.com/rohban-lab/COBRA"" target=""_blank"">rohban-lab</a>",2025-12-03 22:39:25
PCAP-Backdoor: Backdoor Poisoning Generator for Network Traffic in CPS/IoT Environments,"Ajesh Koyatan Chathoth, Stephen Lee",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.15563"" target=""_blank"">2501.15563</a>",,2025-12-03 22:39:25
CENSOR: Defense Against Gradient Inversion via Orthogonal Subspace Bayesian Sampling,"Kaiyuan Zhang, Siyuan Cheng, Guangyu Shen, Bruno Ribeiro, Shengwei An, Pin-Yu Chen, Xiangyu Zhang, Ninghui Li",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.15718"" target=""_blank"">2501.15718</a>","<a href=""https://censor-gradient.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
A Privacy Enhancing Technique to Evade Detection by Street Video Cameras Without Using Adversarial Accessories,"Jacob Shams, Ben Nassi, Satoru Koda, Asaf Shabtai, Yuval Elovici",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.15653"" target=""_blank"">2501.15653</a>",,2025-12-03 22:39:25
Towards Communication-Efficient Adversarial Federated Learning for Robust Edge Intelligence,"Yu Qiao, Apurba Adhikary, Huy Q. Le, Eui-Nam Huh, Zhu Han, Choong Seon Hong",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.15257"" target=""_blank"">2501.15257</a>",,2025-12-03 22:39:25
Adversarial Masked Autoencoder Purifier with Defense Transferability,"Yuan-Chih Chen, Chun-Shien Lu",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.16904"" target=""_blank"">2501.16904</a>",,2025-12-03 22:39:25
HateBench: Benchmarking Hate Speech Detectors on LLM-Generated Content and Hate Campaigns,"Xinyue Shen, Yixin Wu, Yiting Qu, Michael Backes, Savvas Zannettou, Yang Zhang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.16750"" target=""_blank"">2501.16750</a>",,2025-12-03 22:39:25
Bones of Contention: Exploring Query-Efficient Attacks Against Skeleton Recognition Systems,"Yuxin Cao, Kai Ye, Derui Wang, Minhui Xue, Hao Ge, Chenxiong Qian, Jin Song Dong",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.16843"" target=""_blank"">2501.16843</a>",,2025-12-03 22:39:25
Understanding Oversmoothing in GNNs as Consensus in Opinion Dynamics,"Keqin Wang, Yulong Yang, Ishan Saha, Christine Allen-Blanchette",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.19089"" target=""_blank"">2501.19089</a>",,2025-12-03 22:39:25
Explainable Adversarial Attacks on Coarse-to-Fine Classifiers,"Akram Heidarizadeh, Connor Hatfield, Lorenzo Lazzarotto, HanQin Cai, George Atia",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.10906"" target=""_blank"">2501.10906</a>",,2025-12-03 22:39:25
Towards the Worst-case Robustness of Large Language Models,"Huanran Chen, Yinpeng Dong, Zeming Wei, Hang Su, Jun Zhu",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.19040"" target=""_blank"">2501.19040</a>",,2025-12-03 22:39:25
Improving LLM Unlearning Robustness via Random Perturbations,"Dang Huu-Tien, Hoang Thanh-Tung, Anh Bui, Le-Minh Nguyen, Naoya Inoue",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.19202"" target=""_blank"">2501.19202</a>",,2025-12-03 22:39:25
Redefining Machine Unlearning: A Conformal Prediction-Motivated Approach,"Yingdan Shi, Ren Wang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.19403"" target=""_blank"">2501.19403</a>",,2025-12-03 22:39:25
Adversarial Attacks on AI-Generated Text Detection Models: A Token Probability-Based Approach Using Embeddings,"Ahmed K. Kadhim, Lei Jiao, Rishad Shafik, Ole-Christoffer Granmo",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.18998"" target=""_blank"">2501.18998</a>",,2025-12-03 22:39:25
Enhancing Model Defense Against Jailbreaks with Proactive Safety Reasoning,"Xianglin Yang, Gelei Deng, Jieming Shi, Tianwei Zhang, Jin Song Dong",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.19180"" target=""_blank"">2501.19180</a>",,2025-12-03 22:39:25
Deep Learning Model Inversion Attacks and Defenses: A Comprehensive Survey,"Wencheng Yang, Song Wang, Di Wu, Taotao Cai, Yanming Zhu, Shicheng Wei, Yiying Zhang, Xu Yang, Yan Li",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.18934"" target=""_blank"">2501.18934</a>","<a href=""https://github.com/overgter/Deep-Learning-Model-Inversion-Attacks-and-Defenses"" target=""_blank"">overgter</a>",2025-12-03 22:39:25
Imitation Game for Adversarial Disillusion with Multimodal Generative Chain-of-Thought Role-Play,"Ching-Chun Chang, Fan-Yun Chen, Shih-Hong Gu, Kai Gao, Hanrui Wang, Isao Echizen",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.19143"" target=""_blank"">2501.19143</a>",,2025-12-03 22:39:25
Distorting Embedding Space for Safety: A Defense Mechanism for Adversarially Robust Diffusion Models,"Jaesin Ahn, Heechul Jung",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.18877"" target=""_blank"">2501.18877</a>","<a href=""https://github.com/aei13/DES"" target=""_blank"">aei13</a>",2025-12-03 22:39:25
How Much Do Code Language Models Remember? An Investigation on Data Extraction Attacks before and after Fine-tuning,"Fabio Salerno, Ali Al-Kaswan, Maliheh Izadi",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.17501"" target=""_blank"">2501.17501</a>",,2025-12-03 22:39:25
"Illusions of Relevance: Using Content Injection Attacks to Deceive Retrievers, Rerankers, and LLM Judges","Manveer Singh Tamber, Jimmy Lin",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.18536"" target=""_blank"">2501.18536</a>",,2025-12-03 22:39:25
Trading Inference-Time Compute for Adversarial Robustness,"Wojciech Zaremba, Evgenia Nitishinskaya, Boaz Barak, Stephanie Lin, Sam Toyer, Yaodong Yu, Rachel Dias, Eric Wallace, Kai Xiao, Johannes Heidecke, Amelia Glaese",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.18841"" target=""_blank"">2501.18841</a>",,2025-12-03 22:39:25
Jailbreaking LLMs' Safeguard with Universal Magic Words for Text Embedding Models,"Haoyu Liang, Youran Sun, Yunfeng Cai, Jun Zhu, Bo Zhang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.18280"" target=""_blank"">2501.18280</a>",,2025-12-03 22:39:25
Topological Signatures of Adversaries in Multimodal Alignments,"Minh Vu, Geigh Zollicoffer, Huy Mai, Ben Nebgen, Boian Alexandrov, Manish Bhattarai",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.18006"" target=""_blank"">2501.18006</a>",,2025-12-03 22:39:25
CAMP in the Odyssey: Provably Robust Reinforcement Learning with Certified Radius Maximization,"Derui Wang, Kristen Moore, Diksha Goel, Minjune Kim, Gang Li, Yang Li, Robin Doss, Minhui Xue, Bo Li, Seyit Camtepe, Liming Zhu",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.17667"" target=""_blank"">2501.17667</a>","<a href=""https://github.com/NeuralSec/camp-robust-rl"" target=""_blank"">NeuralSec</a>",2025-12-03 22:39:25
Disentangling Safe and Unsafe Corruptions via Anisotropy and Locality,"Ramchandran Muthukumar, Ambar Pal, Jeremias Sulam, Rene Vidal",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.18098"" target=""_blank"">2501.18098</a>",,2025-12-03 22:39:25
SAeUron: Interpretable Concept Unlearning in Diffusion Models with Sparse Autoencoders,"Bartosz Cywiński, Kamil Deja",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.18052"" target=""_blank"">2501.18052</a>",,2025-12-03 22:39:25
P-TAME: Explain Any Image Classifier with Trained Perturbations,"Mariano V. Ntrougkas, Vasileios Mezaris, Ioannis Patras",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.17813"" target=""_blank"">2501.17813</a>",,2025-12-03 22:39:25
Killing it with Zero-Shot: Adversarially Robust Novelty Detection,"Hossein Mirzaei, Mohammad Jafari, Hamid Reza Dehbashi, Zeinab Sadat Taghavi, Mohammad Sabokrou, Mohammad Hossein Rohban",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.15271"" target=""_blank"">2501.15271</a>","<a href=""https://github.com/rohban-lab/ZARND"" target=""_blank"">rohban-lab</a>",2025-12-03 22:39:25
Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming,"Mrinank Sharma, Meg Tong, Jesse Mu, Jerry Wei, Jorrit Kruthoff, Scott Goodfriend, Euan Ong, Alwin Peng, Raj Agarwal, Cem Anil, Amanda Askell, Nathan Bailey, Joe Benton, Emma Bluemke, Samuel R. Bowman, Eric Christiansen, Hoagy Cunningham, Andy Dau, Anjali Gopal, Rob Gilson, Logan Graham, Logan Howard, Nimit Kalra, Taesung Lee, Kevin Lin, Peter Lofgren, Francesco Mosconi, Clare O'Hara, Catherine Olsson, Linda Petrini, Samir Rajani, Nikhil Saxena, Alex Silverstein, Tanya Singh, Theodore Sumers, Leonard Tang, Kevin K. Troy, Constantin Weisser, Ruiqi Zhong, Giulio Zhou, Jan Leike, Jared Kaplan, Ethan Perez",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.18837"" target=""_blank"">2501.18837</a>",,2025-12-03 22:39:25
Comprehensive Evaluation of Cloaking Backdoor Attacks on Object Detector in Real-World,"Hua Ma, Alsharif Abuadbba, Yansong Gao, Hyoungshick Kim, Surya Nepal",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.15101"" target=""_blank"">2501.15101</a>",,2025-12-03 22:39:25
Transferable Adversarial Attacks on Audio Deepfake Detection,"Muhammad Umar Farooq, Awais Khan, Kutub Uddin, Khalid Mahmood Malik",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.11902"" target=""_blank"">2501.11902</a>",,2025-12-03 22:39:25
Heterogeneous Multi-Player Multi-Armed Bandits Robust To Adversarial Attacks,"Akshayaa Magesh, Venugopal V. Veeravalli",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.17882"" target=""_blank"">2501.17882</a>",,2025-12-03 22:39:25
Extend Adversarial Policy Against Neural Machine Translation via Unknown Token,"Wei Zou, Shujian Huang, Jiajun Chen",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.12183"" target=""_blank"">2501.12183</a>",,2025-12-03 22:39:25
Topology of Out-of-Distribution Examples in Deep Neural Networks,"Esha Datta, Johanna Hennig, Eva Domschot, Connor Mattes, Michael R. Smith",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.12522"" target=""_blank"">2501.12522</a>",,2025-12-03 22:39:25
Benchmarking Image Perturbations for Testing Automated Driving Assistance Systems,"Stefano Carlo Lambertenghi, Hannes Leonhard, Andrea Stocco",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.12269"" target=""_blank"">2501.12269</a>",,2025-12-03 22:39:25
A margin-based replacement for cross-entropy loss,"Michael W. Spratling, Heiko H. Schütt",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.12191"" target=""_blank"">2501.12191</a>",,2025-12-03 22:39:25
You Can't Eat Your Cake and Have It Too: The Performance Degradation of LLMs with Jailbreak Defense,"Wuyuao Mai, Geng Hong, Pei Chen, Xudong Pan, Baojun Liu, Yuan Zhang, Haixin Duan, Min Yang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.12210"" target=""_blank"">2501.12210</a>",,2025-12-03 22:39:25
Graph Defense Diffusion Model,"Xin He, Wenqi Fan, Yili Wang, Chengyi Liu, Rui Miao, Xin Juan, Xin Wang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.11568"" target=""_blank"">2501.11568</a>",,2025-12-03 22:39:25
FedMUA: Exploring the Vulnerabilities of Federated Learning to Malicious Unlearning Attacks,"Jian Chen, Zehui Lin, Wanyu Lin, Wenlong Shi, Xiaoyan Yin, Di Wang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.11848"" target=""_blank"">2501.11848</a>",,2025-12-03 22:39:25
Poison-RAG: Adversarial Data Poisoning Attacks on Retrieval-Augmented Generation in Recommender Systems,"Fatemeh Nazary, Yashar Deldjoo, Noia Tommaso di",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.11759"" target=""_blank"">2501.11759</a>","<a href=""https://github.com/atenanaz/Poison-RAG"" target=""_blank"">atenanaz</a>",2025-12-03 22:39:25
On the Adversarial Vulnerabilities of Transfer Learning in Remote Sensing,"Tao Bai, Xingjian Tian, Yonghao Xu, Bihan Wen",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.11462"" target=""_blank"">2501.11462</a>",,2025-12-03 22:39:25
Cross-Entropy Attacks to Language Models via Rare Event Simulation,"Mingze Ni, Yongshun Gong, Wei Liu",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.11852"" target=""_blank"">2501.11852</a>",,2025-12-03 22:39:25
Rethinking Membership Inference Attacks Against Transfer Learning,"Cong Wu, Jing Chen, Qianru Fang, Kun He, Ziming Zhao, Hao Ren, Guowen Xu, Yang Liu, Yang Xiang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.11577"" target=""_blank"">2501.11577</a>",,2025-12-03 22:39:25
CogMorph: Cognitive Morphing Attacks for Text-to-Image Models,"Zonglei Jing, Zonghao Ying, Le Wang, Siyuan Liang, Aishan Liu, Xianglong Liu, Dacheng Tao",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.11815"" target=""_blank"">2501.11815</a>",,2025-12-03 22:39:25
Effectiveness of Adversarial Benign and Malware Examples in Evasion and Poisoning Attacks,"Matouš Kozák, Martin Jureček",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.10996"" target=""_blank"">2501.10996</a>",,2025-12-03 22:39:25
GRID: Protecting Training Graph from Link Stealing Attacks on GNN Models,"Jiadong Lou, Xu Yuan, Rui Zhang, Xingliang Yuan, Neil Gong, Nian-Feng Tzeng",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.10985"" target=""_blank"">2501.10985</a>",,2025-12-03 22:39:25
Can Safety Fine-Tuning Be More Principled? Lessons Learned from Cybersecurity,"David Williams-King, Linh Le, Adam Oberman, Yoshua Bengio",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.11183"" target=""_blank"">2501.11183</a>",,2025-12-03 22:39:25
Mirage in the Eyes: Hallucination Attack on Multi-modal Large Language Models with Only Attention Sink,"Yining Wang, Mi Zhang, Junjie Sun, Chenyue Wang, Min Yang, Hui Xue, Jialing Tao, Ranjie Duan, Jiexi Liu",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.15269"" target=""_blank"">2501.15269</a>",,2025-12-03 22:39:25
Temporal Analysis of Adversarial Attacks in Federated Learning,"Rohit Mapakshi, Sayma Akther, Mark Stamp",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.11054"" target=""_blank"">2501.11054</a>",,2025-12-03 22:39:25
Counteracting temporal attacks in Video Copy Detection,"Katarzyna Fojcik, Piotr Syga",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.11171"" target=""_blank"">2501.11171</a>",,2025-12-03 22:39:25
Robustness of Selected Learning Models under Label-Flipping Attack,"Sarvagya Bhargava, Mark Stamp",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.12516"" target=""_blank"">2501.12516</a>",,2025-12-03 22:39:25
Dagger Behind Smile: Fool LLMs with a Happy Ending Story,"Xurui Song, Zhixin Xie, Shuo Huai, Jiayi Kong, Jun Luo",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.13115"" target=""_blank"">2501.13115</a>",,2025-12-03 22:39:25
With Great Backbones Comes Great Adversarial Transferability,"Erik Arakelyan, Karen Hambardzumyan, Davit Papikyan, Pasquale Minervini, Albert Gordo, Isabelle Augenstein, Aram H. Markosyan",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.12275"" target=""_blank"">2501.12275</a>",,2025-12-03 22:39:25
Crossfire: An Elastic Defense Framework for Graph Neural Networks Under Bit Flip Attacks,"Lorenz Kummer, Samir Moustafa, Wilfried Gansterer, Nils Kriege",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.13776"" target=""_blank"">2501.13776</a>",,2025-12-03 22:39:25
VideoPure: Diffusion-based Adversarial Purification for Video Recognition,"Kaixun Jiang, Zhaoyu Chen, Jiyuan Fu, Lingyi Hong, Jinglun Li, Wenqiang Zhang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.14999"" target=""_blank"">2501.14999</a>","<a href=""https://github.com/deep-kaixun/VideoPure"" target=""_blank"">deep-kaixun</a>",2025-12-03 22:39:25
A Note on Implementation Errors in Recent Adaptive Attacks Against Multi-Resolution Self-Ensembles,Stanislav Fort,arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.14496"" target=""_blank"">2501.14496</a>",,2025-12-03 22:39:25
AI-Driven Secure Data Sharing: A Trustworthy and Privacy-Preserving Approach,"Al Amin, Kamrul Hasan, Sharif Ullah, Liang Hong",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.15363"" target=""_blank"">2501.15363</a>",,2025-12-03 22:39:25
Enhancing Adversarial Transferability via Component-Wise Transformation,"Hangyu Liu, Bo Peng, Can Cui, Pengxiang Ding, Donglin Wang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.11901"" target=""_blank"">2501.11901</a>",,2025-12-03 22:39:25
Siren: A Learning-Based Multi-Turn Attack Framework for Simulating Real-World Human Jailbreak Behaviors,"Yi Zhao, Youzhi Zhang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.14250"" target=""_blank"">2501.14250</a>","<a href=""https://github.com/YiyiyiZhao/siren"" target=""_blank"">YiyiyiZhao</a>",2025-12-03 22:39:25
GreedyPixel: Fine-Grained Black-Box Adversarial Attack Via Greedy Algorithm,"Hanrui Wang, Ching-Chun Chang, Chun-Shien Lu, Christopher Leckie, Isao Echizen",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.14230"" target=""_blank"">2501.14230</a>",,2025-12-03 22:39:25
Reinforcement Learning Platform for Adversarial Black-box Attacks with Custom Distortion Filters,"Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad Mousavi, Vineet Gundecha, Sahand Ghorbanpour, Avisek Naug, Ricardo Luna Gutierrez, Antonio Guillen",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.14122"" target=""_blank"">2501.14122</a>",,2025-12-03 22:39:25
Black-Box Adversarial Attack on Vision Language Models for Autonomous Driving,"Lu Wang, Tianyuan Zhang, Yang Qu, Siyuan Liang, Yuwei Chen, Aishan Liu, Xianglong Liu, Dacheng Tao",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.13563"" target=""_blank"">2501.13563</a>",,2025-12-03 22:39:25
Defending against Adversarial Malware Attacks on ML-based Android Malware Detection Systems,"Ping He, Lorenzo Cavallaro, Shouling Ji",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.13782"" target=""_blank"">2501.13782</a>",,2025-12-03 22:39:25
Device-aware Optical Adversarial Attack for a Portable Projector-camera System,"Ning School of Software & Microelectronics, Peking University, Beijing, China Mashang Consumer Finance Co., Ltd., Chongqing, China Jiang, Yanhong Mashang Consumer Finance Co., Ltd., Chongqing, China Liu, Dingheng Mashang Consumer Finance Co., Ltd., Chongqing, China Zeng, Yue Mashang Consumer Finance Co., Ltd., Chongqing, China Feng, Weihong Mashang Consumer Finance Co., Ltd., Chongqing, China Deng, Ying School of Software & Microelectronics, Peking University, Beijing, China Li",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.14005"" target=""_blank"">2501.14005</a>",,2025-12-03 22:39:25
Certified Robustness Under Bounded Levenshtein Distance,"Elias Abad Rocamora, Grigorios G. Chrysos, Volkan Cevher",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.13676"" target=""_blank"">2501.13676</a>",,2025-12-03 22:39:25
Robust Representation Consistency Model via Contrastive Denoising,"Jiachen Lei, Julius Berner, Jiongxiao Wang, Zhongzhu Chen, Zhongjia Ba, Kui Ren, Jun Zhu, Anima Anandkumar",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.13094"" target=""_blank"">2501.13094</a>","<a href=""https://github.com/jiachenlei/rRCM"" target=""_blank"">jiachenlei</a>",2025-12-03 22:39:25
Logical Maneuvers: Detecting and Mitigating Adversarial Hardware Faults in Space,"Fatemeh Khojasteh Dana, Saleh Khalaj Monfared, Shahin Tajik",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.13894"" target=""_blank"">2501.13894</a>",,2025-12-03 22:39:25
Are We Learning the Right Features? A Framework for Evaluating DL-Based Software Vulnerability Detection Solutions,"Satyaki Das, Syeda Tasnim Fabiha, Saad Shafiq, Nenad Medvidovic",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.13291"" target=""_blank"">2501.13291</a>",,2025-12-03 22:39:25
Modality Unified Attack for Omni-Modality Person Re-Identification,"Yuan Bian, Min Liu, Yunqi Yi, Xueping Wang, Yunfeng Ma, Yaonan Wang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.12761"" target=""_blank"">2501.12761</a>",,2025-12-03 22:39:25
Bad-PFL: Exploring Backdoor Attacks against Personalized Federated Learning,"Mingyuan Fan, Zhanyi Hu, Fuyi Wang, Cen Chen",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.12736"" target=""_blank"">2501.12736</a>",,2025-12-03 22:39:25
Watching the AI Watchdogs: A Fairness and Robustness Analysis of AI Safety Moderation Classifiers,"Akshit Achara, Anshuman Chhabra",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.13302"" target=""_blank"">2501.13302</a>",,2025-12-03 22:39:25
GraphRAG under Fire,"Jiacheng Liang, Yuhui Wang, Changjiang Li, Rongyi Zhu, Tanqiu Jiang, Neil Gong, Ting Wang",arXiv,2025-01,"<a href=""http://arxiv.org/abs/2501.14050"" target=""_blank"">2501.14050</a>",,2025-12-03 22:39:25
MAGIC: Mastering Physical Adversarial Generation in Context through Collaborative LLM Agents,"Yun Xing, Nhat Chung, Jie Zhang, Yue Cao, Ivor Tsang, Yang Liu, Lei Ma, Qing Guo",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.08014"" target=""_blank"">2412.08014</a>",,2025-12-03 22:39:25
Adaptive Epsilon Adversarial Training for Robust Gravitational Wave Parameter Estimation Using Normalizing Flows,"Yiqian Yang, Xihua Zhu, Fan Zhang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07559"" target=""_blank"">2412.07559</a>",,2025-12-03 22:39:25
DynamicPAE: Generating Scene-Aware Physical Adversarial Examples in Real-Time,"Jin Hu, Xianglong Liu, Jiakai Wang, Junkai Zhang, Xianqi Yang, Haotong Qin, Yuqing Ma, Ke Xu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.08053"" target=""_blank"">2412.08053</a>",,2025-12-03 22:39:25
What You See Is Not Always What You Get: An Empirical Study of Code Comprehension by Large Language Models,"Bangshuo Zhu, Jiawen Wen, Huaming Chen",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.08098"" target=""_blank"">2412.08098</a>",,2025-12-03 22:39:25
Defending Against Neural Network Model Inversion Attacks via Data Poisoning,"Shuai Zhou, Dayong Ye, Tianqing Zhu, Wanlei Zhou",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07575"" target=""_blank"">2412.07575</a>",,2025-12-03 22:39:25
Adversarial Vulnerabilities in Large Language Models for Time Series Forecasting,"Fuqiang Liu, Sicong Jiang, Luis Miranda-Moreno, Seongjin Choi, Lijun Sun",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.08099"" target=""_blank"">2412.08099</a>",,2025-12-03 22:39:25
AHSG: Adversarial Attack on High-level Semantics in Graph Neural Networks,"Kai Yuan, Jiahao Zhang, Yidi Wang, Xiaobing Pei",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07468"" target=""_blank"">2412.07468</a>",,2025-12-03 22:39:25
Backdoor Attacks against No-Reference Image Quality Assessment Models via a Scalable Trigger,"Yi Yu, Song Xia, Xun Lin, Wenhan Yang, Shijian Lu, Yap-peng Tan, Alex Kot",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07277"" target=""_blank"">2412.07277</a>","<a href=""https://github.com/yuyi-sd/BAIQA"" target=""_blank"">yuyi-sd</a>",2025-12-03 22:39:25
A Generative Victim Model for Segmentation,"Aixuan Li, Jing Zhang, Jiawei Shi, Yiran Zhong, Yuchao Dai",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07274"" target=""_blank"">2412.07274</a>",,2025-12-03 22:39:25
Addressing Key Challenges of Adversarial Attacks and Defenses in the Tabular Domain: A Methodological Framework for Coherence and Consistency,"Yael Itzhakev, Amit Giloni, Yuval Elovici, Asaf Shabtai",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07326"" target=""_blank"">2412.07326</a>",,2025-12-03 22:39:25
Stealthy and Robust Backdoor Attack against 3D Point Clouds through Additional Point Features,"Xiaoyang Ning, Qing Xie, Jinyu Xu, Wenbo Jiang, Jiachen Li, Yanchun Ma",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07511"" target=""_blank"">2412.07511</a>",,2025-12-03 22:39:25
Model-Editing-Based Jailbreak against Safety-aligned Large Language Models,"Yuxi Li, Zhibo Zhang, Kailong Wang, Ling Shi, Haoyu Wang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.08201"" target=""_blank"">2412.08201</a>",,2025-12-03 22:39:25
FlexLLM: Exploring LLM Customization for Moving Target Defense on Black-Box LLMs Against Jailbreak Attacks,"Bocheng Chen, Hanqing Guo, Qiben Yan",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07672"" target=""_blank"">2412.07672</a>",,2025-12-03 22:39:25
Take Fake as Real: Realistic-like Robust Black-box Adversarial Attack to Evade AIGC Detection,"Caiyun Xie, Dengpan Ye, Yunming Zhang, Long Tang, Yunna Lv, Jiacheng Deng, Jiawei Song",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.06727"" target=""_blank"">2412.06727</a>",,2025-12-03 22:39:25
Adversarial Filtering Based Evasion and Backdoor Attacks to EEG-Based Brain-Computer Interfaces,"Lubin Meng, Xue Jiang, Xiaoqing Chen, Wenzhong Liu, Hanbin Luo, Dongrui Wu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07231"" target=""_blank"">2412.07231</a>",,2025-12-03 22:39:25
A Parametric Approach to Adversarial Augmentation for Cross-Domain Iris Presentation Attack Detection,"Debasmita Pal, Redwan Sony, Arun Ross",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07199"" target=""_blank"">2412.07199</a>","<a href=""https://github.com/iPRoBe-lab/ADV-GEN-IrisPAD"" target=""_blank"">iPRoBe-lab</a>",2025-12-03 22:39:25
Na'vi or Knave: Jailbreaking Language Models via Metaphorical Avatars,"Yu Yan, Sheng Sun, Junqi Tong, Min Liu, Qi Li",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.12145"" target=""_blank"">2412.12145</a>",,2025-12-03 22:39:25
CapGen:An Environment-Adaptive Generator of Adversarial Patches,"Chaoqun Li, Zhuodong Liu, Huanqian Yan, Hang Su",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07253"" target=""_blank"">2412.07253</a>",,2025-12-03 22:39:25
PrisonBreak: Jailbreaking Large Language Models with Fewer Than Twenty-Five Targeted Bit-flips,"Zachary Coalson, Jeonghyun Woo, Yu Sun, Shiyang Chen, Lishan Yang, Prashant Nair, Bo Fang, Sanghyun Hong",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07192"" target=""_blank"">2412.07192</a>",,2025-12-03 22:39:25
Buster: Implanting Semantic Backdoor into Text Encoder to Mitigate NSFW Content Generation,"Xin Zhao, Xiaojun Chen, Yuexin Xuan, Zhendong Zhao, Xiaojun Jia, Xinfeng Li, Xiaofeng Wang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07249"" target=""_blank"">2412.07249</a>",,2025-12-03 22:39:25
Proactive Adversarial Defense: Harnessing Prompt Tuning in Vision-Language Models to Detect Unseen Backdoored Images,"Kyle Stein, Andrew Arash Mahyari, Guillermo Francia, Eman El-Sheikh",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.08755"" target=""_blank"">2412.08755</a>",,2025-12-03 22:39:25
Defensive Dual Masking for Robust Adversarial Defense,"Wangli Yang, Jie Yang, Yi Guo, Johan Barthelemy",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07078"" target=""_blank"">2412.07078</a>",,2025-12-03 22:39:25
A Real-Time Defense Against Object Vanishing Adversarial Patch Attacks for Object Detection in Autonomous Vehicles,Jaden Mu,arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.06215"" target=""_blank"">2412.06215</a>",,2025-12-03 22:39:25
Data Free Backdoor Attacks,"Bochuan Cao, Jinyuan Jia, Chuxuan Hu, Wenbo Guo, Zhen Xiang, Jinghui Chen, Bo Li, Dawn Song",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.06219"" target=""_blank"">2412.06219</a>",,2025-12-03 22:39:25
On Evaluating the Durability of Safeguards for Open-Weight LLMs,"Xiangyu Qi, Boyi Wei, Nicholas Carlini, Yangsibo Huang, Tinghao Xie, Luxi He, Matthew Jagielski, Milad Nasr, Prateek Mittal, Peter Henderson",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07097"" target=""_blank"">2412.07097</a>",,2025-12-03 22:39:25
"Machine Unlearning Doesn't Do What You Think: Lessons for Generative AI Policy, Research, and Practice","A. Feder Cooper, Christopher A. Choquette-Choo, Miranda Bogen, Matthew Jagielski, Katja Filippova, Ken Ziyu Liu, Alexandra Chouldechova, Jamie Hayes, Yangsibo Huang, Niloofar Mireshghallah, Ilia Shumailov, Eleni Triantafillou, Peter Kairouz, Nicole Mitchell, Percy Liang, Daniel E. Ho, Yejin Choi, Sanmi Koyejo, Fernando Delgado, James Grimmelmann, Vitaly Shmatikov, Sa Christopher De, Solon Barocas, Amy Cyphert, Mark Lemley, danah boyd, Jennifer Wortman Vaughan, Miles Brundage, David Bau, Seth Neel, Abigail Z. Jacobs, Andreas Terzis, Hanna Wallach, Nicolas Papernot, Katherine Lee",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.06966"" target=""_blank"">2412.06966</a>",,2025-12-03 22:39:25
StyleMark: A Robust Watermarking Method for Art Style Images Against Black-Box Arbitrary Style Transfer,"Yunming Zhang, Dengpan Ye, Sipeng Shen, Jun Wang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07129"" target=""_blank"">2412.07129</a>",,2025-12-03 22:39:25
Understanding Gradient Descent through the Training Jacobian,"Nora Belrose, Adam Scherlis",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.07003"" target=""_blank"">2412.07003</a>",,2025-12-03 22:39:25
"Vulnerability, Where Art Thou? An Investigation of Vulnerability Management in Android Smartphone Chipsets","Daniel Klischies, Philipp Mackensen, Veelasha Moonsamy",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.06556"" target=""_blank"">2412.06556</a>",,2025-12-03 22:39:25
Backdoor attacks on DNN and GBDT -- A Case Study from the insurance domain,"Robin Kühlem, Daniel Otten, Daniel Ludwig, Anselm Hudde, Alexander Rosenbaum, Andreas Mauthe",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.08366"" target=""_blank"">2412.08366</a>",,2025-12-03 22:39:25
Evaluating Adversarial Attacks on Traffic Sign Classifiers beyond Standard Baselines,"Svetlana Pavlitska, Leopold Müller, J. Marius Zöllner",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.09150"" target=""_blank"">2412.09150</a>","<a href=""https://github.com/KASTEL-MobilityLab/attacks-on-traffic-sign-recognition/"" target=""_blank"">attacks-on-traffic-sign-recognition</a>",2025-12-03 22:39:25
AdvWave: Stealthy Adversarial Jailbreak Attack against Large Audio-Language Models,"Mintong Kang, Chejian Xu, Bo Li",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.08608"" target=""_blank"">2412.08608</a>",,2025-12-03 22:39:25
Adversarial Robustness of Bottleneck Injected Deep Neural Networks for Task-Oriented Communication,"Alireza Furutanpey, Pantelis A. Frangoudis, Patrik Szabo, Schahram Dustdar",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.10265"" target=""_blank"">2412.10265</a>",,2025-12-03 22:39:25
An Effective and Resilient Backdoor Attack Framework against Deep Neural Networks and Vision Transformers,"Xueluan Gong, Bowei Tian, Meng Xue, Yuan Wu, Yanjiao Chen, Qian Wang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.06149"" target=""_blank"">2412.06149</a>",,2025-12-03 22:39:25
Unbiased General Annotated Dataset Generation,"Dengyang Jiang, Haoyu Wang, Lei Zhang, Wei Wei, Guang Dai, Mengmeng Wang, Jingdong Wang, Yanning Zhang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.10831"" target=""_blank"">2412.10831</a>",,2025-12-03 22:39:25
Prompt2Perturb (P2P): Text-Guided Diffusion-Based Adversarial Attacks on Breast Ultrasound Images,"Yasamin Medghalchi, Moein Heidari, Clayton Allard, Leonid Sigal, Ilker Hacihaliloglu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.09910"" target=""_blank"">2412.09910</a>","<a href=""https://github.com/yasamin-med/P2P"" target=""_blank"">yasamin-med</a>",2025-12-03 22:39:25
Robust image classification with multi-modal large language models,"Francesco Villani, Igor Maljkovic, Dario Lazzaro, Angelo Sotgiu, Antonio Emanuele Cinà, Fabio Roli",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.10353"" target=""_blank"">2412.10353</a>",,2025-12-03 22:39:25
A2RNet: Adversarial Attack Resilient Network for Robust Infrared and Visible Image Fusion,"Jiawei Li, Hongwei Yu, Jiansheng Chen, Xinlong Ding, Jinlong Wang, Jinyuan Liu, Bochao Zou, Huimin Ma",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.09954"" target=""_blank"">2412.09954</a>","<a href=""https://github.com/lok-18/A2RNet"" target=""_blank"">lok-18</a>",2025-12-03 22:39:25
Err on the Side of Texture: Texture Bias on Real Data,"Blaine Hoak, Ryan Sheatsley, Patrick McDaniel",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.10597"" target=""_blank"">2412.10597</a>",,2025-12-03 22:39:25
BinarySelect to Improve Accessibility of Black-Box Attack Research,"Shatarupa Ghosh, Jonathan Rusert",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.10617"" target=""_blank"">2412.10617</a>",,2025-12-03 22:39:25
FaceShield: Defending Facial Image against Deepfake Threats,"Jaehwan Jeong, Sumin In, Sieun Kim, Hannie Shin, Jongheon Jeong, Sang Ho Yoon, Jaewook Chung, Sangpil Kim",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.09921"" target=""_blank"">2412.09921</a>",,2025-12-03 22:39:25
On Adversarial Robustness and Out-of-Distribution Robustness of Large Language Models,"April Yang, Jordan Tab, Parth Shah, Paul Kotchavong",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.10535"" target=""_blank"">2412.10535</a>",,2025-12-03 22:39:25
SuperMark: Robust and Training-free Image Watermarking via Diffusion-based Super-Resolution,"Runyi Hu, Jie Zhang, Yiming Li, Jiwei Li, Qing Guo, Han Qiu, Tianwei Zhang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.10049"" target=""_blank"">2412.10049</a>",,2025-12-03 22:39:25
Client-Side Patching against Backdoor Attacks in Federated Learning,Borja Molina-Coronado,arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.10605"" target=""_blank"">2412.10605</a>",,2025-12-03 22:39:25
No Free Lunch for Defending Against Prefilling Attack by In-Context Learning,"Zhiyu Xue, Guangliang Liu, Bocheng Chen, Kristen Marie Johnson, Ramtin Pedarsani",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.12192"" target=""_blank"">2412.12192</a>",,2025-12-03 22:39:25
Active Poisoning: Efficient Backdoor Attacks on Transfer Learning-Based Brain-Computer Interfaces,"X. Jiang, L. Meng, S. Li, D. Wu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.09933"" target=""_blank"">2412.09933</a>",,2025-12-03 22:39:25
BiCert: A Bilinear Mixed Integer Programming Formulation for Precise Certified Bounds Against Data Poisoning Attacks,"Tobias Lorenz, Marta Kwiatkowska, Mario Fritz",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.10186"" target=""_blank"">2412.10186</a>",,2025-12-03 22:39:25
Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models,"Jiahui Li, Yongchang Hao, Haoyu Xu, Xing Wang, Yu Hong",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.08615"" target=""_blank"">2412.08615</a>","<a href=""https://github.com/jiah-li/magic"" target=""_blank"">jiah-li</a>",2025-12-03 22:39:25
From Allies to Adversaries: Manipulating LLM Tool-Calling through Adversarial Injection,"Haowei Wang, Rupeng Zhang, Junjie Wang, Mingyang Li, Yuekai Huang, Dandan Wang, Qing Wang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.10198"" target=""_blank"">2412.10198</a>",,2025-12-03 22:39:25
Three-in-One: Robust Enhanced Universal Transferable Anti-Facial Retrieval in Online Social Networks,"Yunna Lv, Long Tang, Dengpan Ye, Caiyun Xie, Jiacheng Deng, Yiheng He",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.09692"" target=""_blank"">2412.09692</a>",,2025-12-03 22:39:25
On the Generation and Removal of Speaker Adversarial Perturbation for Voice-Privacy Protection,"Chenyang Guo, Liping Chen, Zhuhai Li, Kong Aik Lee, Zhen-Hua Ling, Wu Guo",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.09195"" target=""_blank"">2412.09195</a>","<a href=""https://voiceprivacy.github.io/Perturbation-Generation-Removal/"" target=""_blank"">Perturbation-Generation-Removal</a>",2025-12-03 22:39:25
Real-time Identity Defenses against Malicious Personalization of Diffusion Models,"Hanzhong Guo, Shen Nie, Chao Du, Tianyu Pang, Hao Sun, Chongxuan Li",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.09844"" target=""_blank"">2412.09844</a>",,2025-12-03 22:39:25
Deep Learning Model Security: Threats and Defenses,"Tianyang Wang, Ziqian Bi, Yichao Zhang, Ming Liu, Weiche Hsieh, Pohsun Feng, Lawrence K. Q. Yan, Yizhu Wen, Benji Peng, Junyu Liu, Keyu Chen, Sen Zhang, Ming Li, Chuanqi Jiang, Xinyuan Song, Junjie Yang, Bowen Jing, Jintao Ren, Junhao Song, Hong-Ming Tseng, Silin Chen, Yunze Wang, Chia Xin Liang, Jiawei Xu, Xuanhe Pan, Jinlang Wang, Qian Niu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.08969"" target=""_blank"">2412.08969</a>",,2025-12-03 22:39:25
A Semi Black-Box Adversarial Bit-Flip Attack with Limited DNN Model Information,"Behnam Ghavami, Mani Sadati, Mohammad Shahidzadeh, Lesley Shannon, Steve Wilton",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.09450"" target=""_blank"">2412.09450</a>",,2025-12-03 22:39:25
SVasP: Self-Versatility Adversarial Style Perturbation for Cross-Domain Few-Shot Learning,"Wenqian Li, Pengfei Fang, Hui Xue",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.09073"" target=""_blank"">2412.09073</a>","<a href=""https://github.com/liwenqianSEU/SVasP"" target=""_blank"">liwenqianSEU</a>",2025-12-03 22:39:25
Obfuscated Activations Bypass LLM Latent-Space Defenses,"Luke Bailey, Alex Serrano, Abhay Sheshadri, Mikhail Seleznyov, Jordan Taylor, Erik Jenner, Jacob Hilton, Stephen Casper, Carlos Guestrin, Scott Emmons",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.09565"" target=""_blank"">2412.09565</a>",,2025-12-03 22:39:25
Towards Understanding the Robustness of LLM-based Evaluations under Perturbations,"Manav Chaudhary, Harshit Gupta, Savita Bhat, Vasudeva Varma",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.09269"" target=""_blank"">2412.09269</a>",,2025-12-03 22:39:25
L-WISE: Boosting Human Image Category Learning Through Model-Based Image Selection And Enhancement,"Morgan B. Talbot, Gabriel Kreiman, James J. DiCarlo, Guy Gaziv",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.09765"" target=""_blank"">2412.09765</a>",,2025-12-03 22:39:25
Adversarial Purification by Consistency-aware Latent Space Optimization on Data Manifolds,"Shuhai Zhang, Jiahao Yang, Hui Luo, Jie Chen, Li Wang, Feng Liu, Bo Han, Mingkui Tan",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.08394"" target=""_blank"">2412.08394</a>",,2025-12-03 22:39:25
Doubly-Universal Adversarial Perturbations: Deceiving Vision-Language Models Across Both Images and Text with a Single Perturbation,"Hee-Seon Kim, Minbeom Kim, Changick Kim",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.08108"" target=""_blank"">2412.08108</a>",,2025-12-03 22:39:25
Grimm: A Plug-and-Play Perturbation Rectifier for Graph Neural Networks Defending against Poisoning Attacks,"Ao Liu, Wenshan Li, Beibei Li, Wengang Ma, Tao Li, Pan Zhou",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.08555"" target=""_blank"">2412.08555</a>",,2025-12-03 22:39:25
Adversarial Transferability in Deep Denoising Models: Theoretical Insights and Robustness Enhancement via Out-of-Distribution Typical Set Sampling,"Jie Ning, Jiebao Sun, Shengzhu Shi, Zhichang Guo, Yao Li, Hongwei Li, Boying Wu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.05943"" target=""_blank"">2412.05943</a>",,2025-12-03 22:39:25
Robust and Transferable Backdoor Attacks Against Deep Image Compression With Selective Frequency Prior,"Yi Yu, Yufei Wang, Wenhan Yang, Lanqing Guo, Shijian Lu, Ling-Yu Duan, Yap-Peng Tan, Alex C. Kot",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.01646"" target=""_blank"">2412.01646</a>",,2025-12-03 22:39:25
Anti-Reference: Universal and Immediate Defense Against Reference-Based Generation,"Yiren Song, Shengtao Lou, Xiaokang Liu, Hai Ci, Pei Yang, Jiaming Liu, Mike Zheng Shou",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.05980"" target=""_blank"">2412.05980</a>",,2025-12-03 22:39:25
Reactive Synthesis of Sensor Revealing Strategies in Hypergames on Graphs,"Sumukha Udupa, Ahmed Hemida, Charles A. Kamhoua, Jie Fu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.01975"" target=""_blank"">2412.01975</a>",,2025-12-03 22:39:25
TSCheater: Generating High-Quality Tibetan Adversarial Texts via Visual Similarity,"Xi Cao, Quzong Gesang, Yuan Sun, Nuo Qun, Tashi Nyima",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.02371"" target=""_blank"">2412.02371</a>",,2025-12-03 22:39:25
The Efficacy of Transfer-based No-box Attacks on Image Watermarking: A Pragmatic Analysis,"Qilong Wu, Varun Chandrasekaran",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.02576"" target=""_blank"">2412.02576</a>","<a href=""https://github.com/Ardor-Wu/transfer"" target=""_blank"">Ardor-Wu</a>",2025-12-03 22:39:25
AdvDreamer Unveils: Are Vision-Language Models Truly Ready for Real-World 3D Variations? (61%),"Shouwei Ruan, Hanqing Liu, Yao Huang, Xiaoqi Wang, Caixin Kang, Hang Su, Yinpeng Dong, Xingxing Wei",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.03002"" target=""_blank"">2412.03002</a>",,2025-12-03 22:39:25
Defending Against Diverse Attacks in Federated Learning Through Consensus-Based Bi-Level Optimization,"Nicolás García Trillos, Aditya Kumar Akash, Sixu Li, Konstantin Riedl, Yuhua Zhu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.02535"" target=""_blank"">2412.02535</a>",,2025-12-03 22:39:25
OODFace: Benchmarking Robustness of Face Recognition under Common Corruptions and Appearance Variations,"Caixin Kang, Yubo Chen, Shouwei Ruan, Shiji Zhao, Ruochen Zhang, Jiayi Wang, Shan Fu, Xingxing Wei",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.02479"" target=""_blank"">2412.02479</a>",,2025-12-03 22:39:25
Gracefully Filtering Backdoor Samples for Generative Large Language Models without Retraining,"Zongru Wu, Pengzhou Cheng, Lingyong Fang, Zhuosheng Zhang, Gongshen Liu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.02454"" target=""_blank"">2412.02454</a>","<a href=""https://github.com/ZrW00/GraceFul"" target=""_blank"">ZrW00</a>",2025-12-03 22:39:25
Traversing the Subspace of Adversarial Patches,"Jens Bayer, Stefan Becker, David Münch, Michael Arens, Jürgen Beyerer",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.01527"" target=""_blank"">2412.01527</a>",,2025-12-03 22:39:25
DiffPatch: Generating Customizable Adversarial Patches using Diffusion Model,"Zhixiang Wang, Guangnan Ye, Xiaosen Wang, Siheng Chen, Zhibo Wang, Xingjun Ma, Yu-Gang Jiang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.01440"" target=""_blank"">2412.01440</a>",,2025-12-03 22:39:25
Exploring the Robustness of AI-Driven Tools in Digital Forensics: A Preliminary Study,"Silvia Lucia Sanna, Leonardo Regano, Davide Maiorca, Giorgio Giacinto",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.01363"" target=""_blank"">2412.01363</a>",,2025-12-03 22:39:25
Adversarial Sample-Based Approach for Tighter Privacy Auditing in Final Model-Only Scenarios,"Sangyeon Yoon, Wonje Jeung, Albert No",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.01756"" target=""_blank"">2412.01756</a>",,2025-12-03 22:39:25
Adversarial Attacks on Hyperbolic Networks,"Spengler Max van, Jan Zahálka, Pascal Mettes",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.01495"" target=""_blank"">2412.01495</a>",,2025-12-03 22:39:25
Compromising the Intelligence of Modern DNNs: On the Effectiveness of Targeted RowPress,"Ranyang Zhou, Jacqueline T. Liu, Sabbir Ahmed, Shaahin Angizi, Adnan Siraj Rakin",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.02156"" target=""_blank"">2412.02156</a>",,2025-12-03 22:39:25
R,"Trung-Hieu Hoang, Duc Minh Vo, Minh N. Do",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.01154"" target=""_blank"">2412.01154</a>",,2025-12-03 22:39:25
Precision Profile Pollution Attack on Sequential Recommenders via Influence Function,"Xiaoyu Du, Yingying Chen, Yang Zhang, Jinhui Tang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.01127"" target=""_blank"">2412.01127</a>",,2025-12-03 22:39:25
SABER: Model-agnostic Backdoor Attack on Chain-of-Thought in Neural Code Generation,"Naizhu Jin, Zhong Li, Yinggang Guo, Chao Su, Tian Zhang, Qingkai Zeng",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.05829"" target=""_blank"">2412.05829</a>",,2025-12-03 22:39:25
Intermediate Outputs Are More Sensitive Than You Think,"Tao Huang, Qingyu Huang, Jiayang Meng",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.00696"" target=""_blank"">2412.00696</a>",,2025-12-03 22:39:25
Hiding Faces in Plain Sight: Defending DeepFakes by Disrupting Face Detection,"Delong Zhu, Yuezun Li, Baoyuan Wu, Jiaran Zhou, Zhibo Wang, Siwei Lyu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.01101"" target=""_blank"">2412.01101</a>",,2025-12-03 22:39:25
Online Poisoning Attack Against Reinforcement Learning under Black-box Environments,"Jianhui Li, Bokang Zhang, Junfeng Wu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.00797"" target=""_blank"">2412.00797</a>",,2025-12-03 22:39:25
Hard-Label Black-Box Attacks on 3D Point Clouds,"Daizong Liu, Yunbo Tao, Pan Zhou, Wei Hu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.00404"" target=""_blank"">2412.00404</a>",,2025-12-03 22:39:25
Exposing LLM Vulnerabilities: Adversarial Scam Detection and Performance,"Chen-Wei Chang, Shailik Sarkar, Shutonu Mitra, Qi Zhang, Hossein Salemi, Hemant Purohit, Fengxiu Zhang, Michin Hong, Jin-Hee Cho, Chang-Tien Lu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.00621"" target=""_blank"">2412.00621</a>",,2025-12-03 22:39:25
Exact Certification of (Graph) Neural Networks Against Label Poisoning,"Mahalakshmi Sabanayagam, Lukas Gosch, Stephan Günnemann, Debarghya Ghoshdastidar",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.00537"" target=""_blank"">2412.00537</a>",,2025-12-03 22:39:25
Jailbreak Large Vision-Language Models Through Multi-Modal Linkage,"Yu Wang, Xiaofei Zhou, Yichen Wang, Geyuan Zhang, Tianxing He",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.00473"" target=""_blank"">2412.00473</a>","<a href=""https://github.com/wangyu-ovo/MML"" target=""_blank"">wangyu-ovo</a>",2025-12-03 22:39:25
Robust Table Integration in Data Lakes,"Daomin Ji, Hui Luo, Zhifeng Bao, Shane Culpepper",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.00324"" target=""_blank"">2412.00324</a>",,2025-12-03 22:39:25
Fusing Physics-Driven Strategies and Cross-Modal Adversarial Learning: Toward Multi-Domain Applications,"Hana Satou, Alan Mitkiy",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.00341"" target=""_blank"">2412.00341</a>",,2025-12-03 22:39:25
SceneTAP: Scene-Coherent Typographic Adversarial Planner against Vision-Language Models in Real-World Environments,"Yue Cao, Yun Xing, Jie Zhang, Di Lin, Tianwei Zhang, Ivor Tsang, Yang Liu, Qing Guo",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.00114"" target=""_blank"">2412.00114</a>",,2025-12-03 22:39:25
Artificial intelligence and cybersecurity in banking sector: opportunities and risks,"Ana Kovacevic, Sonja D. Radenkovic, Dragana Nikolic",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.04495"" target=""_blank"">2412.04495</a>",,2025-12-03 22:39:25
Poison Attacks and Adversarial Prompts Against an Informed University Virtual Assistant,"Ivan A. Fernandez, Subash Neupane, Sudip Mittal, Shahram Rahimi",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.06788"" target=""_blank"">2412.06788</a>",,2025-12-03 22:39:25
Towards Action Hijacking of Large Language Model-based Agent,"Yuyang Zhang, Kangjie Chen, Jiaxin Gao, Ronghao Cui, Run Wang, Lina Wang, Tianwei Zhang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.10807"" target=""_blank"">2412.10807</a>",,2025-12-03 22:39:25
Hijacking Vision-and-Language Navigation Agents with Adversarial Environmental Attacks,"Zijiao Yang, Xiangxi Shi, Eric Slyman, Stefan Lee",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.02795"" target=""_blank"">2412.02795</a>",,2025-12-03 22:39:25
Can't Slow me Down: Learning Robust and Hardware-Adaptive Object Detectors against Latency Attacks for Edge Devices,"Tianyi Zhejiang University, Hangzhou, China Wang, Zichen Zhejiang University, Hangzhou, China Wang, Cong Zhejiang University, Hangzhou, China Wang, Yuanchao Zhejiang University, Hangzhou, China Shu, Ruilong Zhejiang University, Hangzhou, China Deng, Peng Zhejiang University, Hangzhou, China Cheng, Jiming Zhejiang University, Hangzhou, China Chen",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.02171"" target=""_blank"">2412.02171</a>",,2025-12-03 22:39:25
Pay Attention to the Robustness of Chinese Minority Language Models! Syllable-level Textual Adversarial Attack on Tibetan Script,"Xi Cao, Dolma Dawa, Nuo Qun, Trashi Nyima",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.02323"" target=""_blank"">2412.02323</a>",,2025-12-03 22:39:25
Multi-Granularity Tibetan Textual Adversarial Attack Method Based on Masked Language Model,"Xi Cao, Nuo Qun, Quzong Gesang, Yulei Zhu, Trashi Nyima",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.02343"" target=""_blank"">2412.02343</a>",,2025-12-03 22:39:25
Enhancing Adversarial Resistance in LLMs with Recursion,"Bryan Li, Sounak Bagchi, Zizhan Wang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.06181"" target=""_blank"">2412.06181</a>",,2025-12-03 22:39:25
Membership Inference Attacks and Defenses in Federated Learning: A Survey,"Li Bai, Haibo Hu, Qingqing Ye, Haoyang Li, Leixia Wang, Jianliang Xu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.06157"" target=""_blank"">2412.06157</a>",,2025-12-03 22:39:25
DeMem: Privacy-Enhanced Robust Adversarial Learning via De-Memorization,"Xiaoyu Luo, Qiongxiu Li",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.05767"" target=""_blank"">2412.05767</a>",,2025-12-03 22:39:25
From Flexibility to Manipulation: The Slippery Slope of XAI Evaluation,"Kristoffer Wickstrøm, Marina Marie-Claire Höhne, Anna Hedström",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.05592"" target=""_blank"">2412.05592</a>",,2025-12-03 22:39:25
Nearly Solved? Robust Deepfake Detection Requires More than Visual Forensics,"Guy Levy, Nathan Liebmann",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.05676"" target=""_blank"">2412.05676</a>",,2025-12-03 22:39:25
LIAR: Leveraging Alignment (Best-of-N) to Jailbreak LLMs in Seconds,"James Beetham, Souradip Chakraborty, Mengdi Wang, Furong Huang, Amrit Singh Bedi, Mubarak Shah",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.05232"" target=""_blank"">2412.05232</a>",,2025-12-03 22:39:25
Not Just Text: Uncovering Vision Modality Typographic Threats in Image Generation Models,"Hao Cheng, Erjia Xiao, Jiayan Yang, Jiahang Cao, Qiang Zhang, Jize Zhang, Kaidi Xu, Jindong Gu, Renjing Xu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.05538"" target=""_blank"">2412.05538</a>",,2025-12-03 22:39:25
Towards Predicting the Success of Transfer-based Attacks by Quantifying Shared Feature Representations,"Ashley S. Dale, Mei Qiu, Foo Bin Che, Thomas Bsaibes, Lauren Christopher, Paul Salama",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.05351"" target=""_blank"">2412.05351</a>",,2025-12-03 22:39:25
Backdooring Outlier Detection Methods: A Novel Attack Approach,"ZeinabSadat Taghavi, Hossein Mirzaei",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.05010"" target=""_blank"">2412.05010</a>",,2025-12-03 22:39:25
Intriguing Properties of Robust Classification,"Bernd Prach, Christoph H. Lampert",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.04245"" target=""_blank"">2412.04245</a>",,2025-12-03 22:39:25
On the Lack of Robustness of Binary Function Similarity Systems,"Gianluca Capozzi, Tong Tang, Jie Wan, Ziqi Yang, Daniele Cono D'Elia, Luna Giuseppe Antonio Di, Lorenzo Cavallaro, Leonardo Querzoni",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.04163"" target=""_blank"">2412.04163</a>",,2025-12-03 22:39:25
Megatron: Evasive Clean-Label Backdoor Attacks against Vision Transformer,"Xueluan Gong, Bowei Tian, Meng Xue, Shuike Li, Yanjiao Chen, Qian Wang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.04776"" target=""_blank"">2412.04776</a>",,2025-12-03 22:39:25
Can Targeted Clean-Label Poisoning Attacks Generalize? (13%),"Zhizhen Chen, Subrat Kishore Dutta, Zhengyu Zhao, Chenhao Lin, Chao Shen, Xiao Zhang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.03908"" target=""_blank"">2412.03908</a>","<a href=""https://github.com/jiaangk/generalizable_tcpa"" target=""_blank"">jiaangk</a>",2025-12-03 22:39:25
LaserGuider: A Laser Based Physical Backdoor Attack against Deep Neural Networks,"Yongjie Xu, Guangke Chen, Fu Song, Yuqi Chen",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.03993"" target=""_blank"">2412.03993</a>",,2025-12-03 22:39:25
Safeguarding Text-to-Image Generation via Inference-Time Prompt-Noise Optimization,"Jiangweizhi Peng, Zhiwei Tang, Gaowen Liu, Charles Fleming, Mingyi Hong",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.03876"" target=""_blank"">2412.03876</a>",,2025-12-03 22:39:25
Targeting the Core: A Simple and Effective Method to Attack RAG-based Agents via Direct LLM Manipulation,"Xuying Li, Zhuo Li, Yuji Kosuga, Yasuhiro Yoshida, Victor Bian",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.04415"" target=""_blank"">2412.04415</a>",,2025-12-03 22:39:25
NODE-AdvGAN: Improving the transferability and perceptual similarity of adversarial examples by dynamic-system-driven adversarial generative model,"Xinheng Xie, Yue Wu, Cuiyu He",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.03539"" target=""_blank"">2412.03539</a>",,2025-12-03 22:39:25
Does Safety Training of LLMs Generalize to Semantically Related Natural Prompts? (99%),"Sravanti Addepalli, Yerram Varun, Arun Suggala, Karthikeyan Shanmugam, Prateek Jain",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.03235"" target=""_blank"">2412.03235</a>",,2025-12-03 22:39:25
Less is More: A Stealthy and Efficient Adversarial Attack Method for DRL-based Autonomous Driving Policies,"Junchao Fan, Xuyang Lei, Xiaolin Chang, Jelena Mišić, Vojislav B. Mišić",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.03051"" target=""_blank"">2412.03051</a>",,2025-12-03 22:39:25
PBP: Post-training Backdoor Purification for Malware Classifiers,"Dung Thuy Nguyen, Ngoc N. Tran, Taylor T. Johnson, Kevin Leach",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.03441"" target=""_blank"">2412.03441</a>","<a href=""https://github.com/judydnguyen/pbp-backdoor-purification-official"" target=""_blank"">judydnguyen</a>",2025-12-03 22:39:25
Testing Neural Network Verifiers: A Soundness Benchmark with Hidden Counterexamples,"Xingjian Zhou, Hongji Xu, Andy Xu, Zhouxing Shi, Cho-Jui Hsieh, Huan Zhang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.03154"" target=""_blank"">2412.03154</a>","<a href=""https://github.com/MVP-Harry/SoundnessBench"" target=""_blank"">MVP-Harry</a>",2025-12-03 22:39:25
Black-Box Forgery Attacks on Semantic Watermarks for Diffusion Models,"Andreas Müller, Denis Lukovnikov, Jonas Thietke, Asja Fischer, Erwin Quiring",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.03283"" target=""_blank"">2412.03283</a>",,2025-12-03 22:39:25
Designing DNNs for a trade-off between robustness and processing performance in embedded devices,"Jon Gutiérrez-Zaballa, Koldo Basterretxea, Javier Echanobe",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.03682"" target=""_blank"">2412.03682</a>",,2025-12-03 22:39:25
Pre-trained Multiple Latent Variable Generative Models are good defenders against Adversarial Attacks,"Dario Serez, Marco Cristani, Bue Alessio Del, Vittorio Murino, Pietro Morerio",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.03453"" target=""_blank"">2412.03453</a>","<a href=""https://github.com/SerezD/gen_adversarial"" target=""_blank"">SerezD</a>",2025-12-03 22:39:25
Evaluating Single Event Upsets in Deep Neural Networks for Semantic Segmentation: an embedded system perspective,"Jon Gutiérrez-Zaballa, Koldo Basterretxea, Javier Echanobe",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.03630"" target=""_blank"">2412.03630</a>","<a href=""https://github.com/jonGuti13/TensorFI2"" target=""_blank"">jonGuti13</a>",2025-12-03 22:39:25
Sustainable Self-evolution Adversarial Training,"Wenxuan Wang, Chenglei Wang, Huihui Qi, Menghao Ye, Xuelin Qian, Peng Wang, Yanning Zhang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.02270"" target=""_blank"">2412.02270</a>",,2025-12-03 22:39:25
Gaussian Splatting Under Attack: Investigating Adversarial Noise in 3D Objects,"Abdurrahman Zeybey, Mehmet Ergezer, Tommy Nguyen",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.02803"" target=""_blank"">2412.02803</a>",,2025-12-03 22:39:25
Are Language Models Agnostic to Linguistically Grounded Perturbations? A Case Study of Indic Languages,"Poulami Ghosh, Raj Dabre, Pushpak Bhattacharyya",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.10805"" target=""_blank"">2412.10805</a>",,2025-12-03 22:39:25
PBI-Attack: Prior-Guided Bimodal Interactive Black-Box Jailbreak Attack for Toxicity Maximization,"Ruoxi Cheng, Yizhong Ding, Shuirong Cao, Ranjie Duan, Xiaoshuang Jia, Shaowei Yuan, Zhiqiang Wang, Xiaojun Jia",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.05892"" target=""_blank"">2412.05892</a>",,2025-12-03 22:39:25
One Pixel is All I Need,"Deng Siqin, Zhou Xiaoyi",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.10681"" target=""_blank"">2412.10681</a>",,2025-12-03 22:39:25
Stability Bounds for the Unfolded Forward-Backward Algorithm,"Emilie Chouzenoux, Valle Cecile Della, Jean-Christophe Pesquet",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.17888"" target=""_blank"">2412.17888</a>",,2025-12-03 22:39:25
Evaluating the Adversarial Robustness of Detection Transformers,"Amirhossein Nazeri, Chunheng Zhao, Pierluigi Pisu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18718"" target=""_blank"">2412.18718</a>",,2025-12-03 22:39:25
Robustness-aware Automatic Prompt Optimization,"Zeru Shi, Zhenting Wang, Yongye Su, Weidi Luo, Fan Yang, Yongfeng Zhang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18196"" target=""_blank"">2412.18196</a>",,2025-12-03 22:39:25
Attack-in-the-Chain: Bootstrapping Large Language Models for Attacks Against Black-box Neural Ranking Models,"Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Rijke Maarten de, Yixing Fan, Xueqi Cheng",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18770"" target=""_blank"">2412.18770</a>",,2025-12-03 22:39:25
On the Effectiveness of Adversarial Training on Malware Classifiers,"Hamid Bostani, Jacopo Cortellazzi, Daniel Arp, Fabio Pierazzi, Veelasha Moonsamy, Lorenzo Cavallaro",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18218"" target=""_blank"">2412.18218</a>",,2025-12-03 22:39:25
Efficient Contrastive Explanations on Demand,"Yacine Izza, Joao Marques-Silva",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18262"" target=""_blank"">2412.18262</a>",,2025-12-03 22:39:25
An Empirical Analysis of Federated Learning Models Subject to Label-Flipping Adversarial Attack,"Kunal Bhatnagar, Sagana Chattanathan, Angela Dang, Bhargav Eranki, Ronnit Rana, Charan Sridhar, Siddharth Vedam, Angie Yao, Mark Stamp",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18507"" target=""_blank"">2412.18507</a>",,2025-12-03 22:39:25
Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks Against GNN-Based Fraud Detectors,"Jinhyeok Choi, Heehyeon Kim, Joyce Jiyoung Whang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18370"" target=""_blank"">2412.18370</a>",,2025-12-03 22:39:25
Token Highlighter: Inspecting and Mitigating Jailbreak Prompts for Large Language Models,"Xiaomeng Hu, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18171"" target=""_blank"">2412.18171</a>",,2025-12-03 22:39:25
Hypergraph Attacks via Injecting Homogeneous Nodes into Elite Hyperedges,"Meixia He, Peican Zhu, Keke Tang, Yangming Guo",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18365"" target=""_blank"">2412.18365</a>",,2025-12-03 22:39:25
Re-assessing ImageNet: How aligned is its single-label assumption with its multi-label nature? (4%),"Esla Timothy Anzaku, Seyed Amir Mousavi, Messem Arnout Van, Neve Wesley De",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18409"" target=""_blank"">2412.18409</a>",,2025-12-03 22:39:25
Retention Score: Quantifying Jailbreak Risks for Vision Language Models,"Zaitang Li, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.17544"" target=""_blank"">2412.17544</a>",,2025-12-03 22:39:25
Emerging Security Challenges of Large Language Models,"Herve Debar, Sven Dietrich, Pavel Laskov, Emil C. Lupu, Eirini Ntoutsi",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.17614"" target=""_blank"">2412.17614</a>",,2025-12-03 22:39:25
Double Landmines: Invisible Textual Backdoor Attacks based on Dual-Trigger,"Yang Hou, Qiuling Yue, Lujia Chai, Guozhao Liao, Wenbao Han, Wei Ou",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.17531"" target=""_blank"">2412.17531</a>",,2025-12-03 22:39:25
AEIOU: A Unified Defense Framework against NSFW Prompts in Text-to-Image Models,"Yiming Wang, Jiahao Chen, Qingming Li, Xing Yang, Shouling Ji",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18123"" target=""_blank"">2412.18123</a>",,2025-12-03 22:39:25
CL-attack: Textual Backdoor Attacks via Cross-Lingual Triggers,"Jingyi Zheng, Tianyi Hu, Tianshuo Cong, Xinlei He",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.19037"" target=""_blank"">2412.19037</a>",,2025-12-03 22:39:25
Sensitivity Curve Maximization: Attacking Robust Aggregators in Distributed Learning,"Christian A. Schroth, Stefan Vlaski, Abdelhak M. Zoubir",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.17740"" target=""_blank"">2412.17740</a>",,2025-12-03 22:39:25
DiffusionAttacker: Diffusion-Driven Prompt Manipulation for LLM Jailbreak,"Hao Wang, Hao Li, Junda Zhu, Xinyuan Wang, Chengwei Pan, MinLie Huang, Lei Sha",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.17522"" target=""_blank"">2412.17522</a>",,2025-12-03 22:39:25
ErasableMask: A Robust and Erasable Privacy Protection Scheme against Black-box Face Recognition Models,"Sipeng Shen, Yunming Zhang, Dengpan Ye, Xiuwen Shi, Long Tang, Haoran Duan, Ziyi Liu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.17038"" target=""_blank"">2412.17038</a>",,2025-12-03 22:39:25
NumbOD: A Spatial-Frequency Fusion Attack Against Object Detectors,"Ziqi Zhou, Bowen Li, Yufei Song, Zhifei Yu, Shengshan Hu, Wei Wan, Leo Yu Zhang, Dezhong Yao, Hai Jin",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16955"" target=""_blank"">2412.16955</a>",,2025-12-03 22:39:25
Breaking Barriers in Physical-World Adversarial Examples: Improving Robustness and Transferability via Robust Feature,"Yichen Wang, Yuxuan Chou, Ziqi Zhou, Hangtao Zhang, Wei Wan, Shengshan Hu, Minghui Li",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16958"" target=""_blank"">2412.16958</a>",,2025-12-03 22:39:25
Preventing Non-intrusive Load Monitoring Privacy Invasion: A Precise Adversarial Attack Scheme for Networked Smart Meters,"Jialing He, Jiacheng Wang, Ning Wang, Shangwei Guo, Liehuang Zhu, Dusit Niyato, Tao Xiang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16893"" target=""_blank"">2412.16893</a>",,2025-12-03 22:39:25
A Backdoor Attack Scheme with Invisible Triggers Based on Model Architecture Modification,"Yuan Ma, Xu Ma, Jiankang Wei, Jinmeng Tang, Xiaoyu Zhang, Yilun Lyu, Kehao Chen, Jingtong Huang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16905"" target=""_blank"">2412.16905</a>",,2025-12-03 22:39:25
Attack by Yourself: Effective and Unnoticeable Multi-Category Graph Backdoor Attacks with Subgraph Triggers Pool,"Jiangtong Li, Dungy Liu, Dawei Cheng, Changchun Jiang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.17213"" target=""_blank"">2412.17213</a>",,2025-12-03 22:39:25
Shaping the Safety Boundaries: Understanding and Defending Against Jailbreaks in Large Language Models,"Lang Gao, Xiangliang Zhang, Preslav Nakov, Xiuying Chen",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.17034"" target=""_blank"">2412.17034</a>",,2025-12-03 22:39:25
Robustness of Large Language Models Against Adversarial Attacks,"Yiyi Tao, Yixian Shen, Hang Zhang, Yanxin Shen, Lun Wang, Chuanqi Shi, Shaoshuai Du",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.17011"" target=""_blank"">2412.17011</a>",,2025-12-03 22:39:25
PB-UAP: Hybrid Universal Adversarial Attack For Image Segmentation,"Yufei Song, Ziqi Zhou, Minghui Li, Xianlong Wang, Menghao Deng, Wei Wan, Shengshan Hu, Leo Yu Zhang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16651"" target=""_blank"">2412.16651</a>",,2025-12-03 22:39:25
Adversarial Attack Against Images Classification based on Generative Adversarial Networks,Yahe Yang,arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16662"" target=""_blank"">2412.16662</a>",,2025-12-03 22:39:25
OpenAI o1 System Card,"OpenAI, :, Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, Alex Iftimie, Alex Karpenko, Alex Tachard Passos, Alexander Neitz, Alexander Prokofiev, Alexander Wei, Allison Tam, Ally Bennett, Ananya Kumar, Andre Saraiva, Andrea Vallone, Andrew Duberstein, Andrew Kondrich, Andrey Mishchenko, Andy Applebaum, Angela Jiang, Ashvin Nair, Barret Zoph, Behrooz Ghorbani, Ben Rossen, Benjamin Sokolowsky, Boaz Barak, Bob McGrew, Borys Minaiev, Botao Hao, Bowen Baker, Brandon Houghton, Brandon McKinzie, Brydon Eastman, Camillo Lugaresi, Cary Bassin, Cary Hudson, Chak Ming Li, Bourcy Charles de, Chelsea Voss, Chen Shen, Chong Zhang, Chris Koch, Chris Orsinger, Christopher Hesse, Claudia Fischer, Clive Chan, Dan Roberts, Daniel Kappler, Daniel Levy, Daniel Selsam, David Dohan, David Farhi, David Mely, David Robinson, Dimitris Tsipras, Doug Li, Dragos Oprica, Eben Freeman, Eddie Zhang, Edmund Wong, Elizabeth Proehl, Enoch Cheung, Eric Mitchell, Eric Wallace, Erik Ritter, Evan Mays, Fan Wang, Felipe Petroski Such, Filippo Raso, Florencia Leoni, Foivos Tsimpourlas, Francis Song, Lohmann Fred von, Freddie Sulit, Geoff Salmon, Giambattista Parascandolo, Gildas Chabot, Grace Zhao, Greg Brockman, Guillaume Leclerc, Hadi Salman, Haiming Bao, Hao Sheng, Hart Andrin, Hessam Bagherinezhad, Hongyu Ren, Hunter Lightman, Hyung Won Chung, Ian Kivlichan, Ian O'Connell, Ian Osband, Ignasi Clavera Gilaberte, Ilge Akkaya, Ilya Kostrikov, Ilya Sutskever, Irina Kofman, Jakub Pachocki, James Lennon, Jason Wei, Jean Harb, Jerry Twore, Jiacheng Feng, Jiahui Yu, Jiayi Weng, Jie Tang, Jieqi Yu, Joaquin Quiñonero Candela, Joe Palermo, Joel Parish, Johannes Heidecke, John Hallman, John Rizzo, Jonathan Gordon, Jonathan Uesato, Jonathan Uesato, Jonathan Ward, Joost Huizinga, Julie Wang, Kai Chen, Kai Xiao, Karan Singhal, Karina Nguyen, Karl Cobbe, Katy Shi, Kayla Wood, Kendra Rimbach, Keren Gu-Lemberg, Keren GuLemberg, Kevin Liu, Kevin Lu, Kevin Stone, Kevin Yu, Lama Ahmad, Lauren Yang, Leo Liu, Leon Maksin, Leyton Ho, Liam Fedus, Lilian Weng, Linden Li, Lindsay McCallum, Lindsey Held, Lorenz Kuhn, Lukas Kondraciuk, Lukasz Kaiser, Luke Metz, Madelaine Boyd, Maja Trebacz, Manas Joglekar, Mark Chen, Marko Tintor, Mason Meyer, Matt Jones, Matt Kaufer, Max Schwarzer, Meghan Shah, Mehmet Yatbaz, Melody Guan, Mengyuan Xu, Mengyuan Yan, Mia Glaese, Mianna Chen, Mianna Chen, Michael Lampe, Michael Malek, Michele Wang, Michelle Fradin, Mike McClay, Mikhail Pavlov, Miles Wang, Mingxuan Wang, Mira Murati, Mo Bavarian, Mostafa Rohaninejad, Nat McAleese, Neil Chowdhury, Neil Chowdhury, Nick Ryder, Nikolas Tezak, Noam Brown, Ofir Nachum, Oleg Boiko, Oleg Murk, Olivia Watkins, Patrick Chao, Paul Ashbourne, Pavel Izmailov, Peter Zhokhov, Rachel Dias, Rahul Arora, Randall Lin, Rapha Gontijo Lopes, Raz Gaon, Reah Miyara, Reimar Leike, Renny Hwang, Rhythm Garg, Robin Brown, Roshan James, Rui Shu, Ryan Cheu, Ryan Greene, Saachi Jain, Sam Altman, Sam Toizer, Sam Toyer, Samuel Miserendino, Sandhini Agarwal, Santiago Hernandez, Sasha Baker, Scott McKinney, Scottie Yan, Shengjia Zhao, Shengli Hu, Shibani Santurkar, Shraman Ray Chaudhuri, Shuyuan Zhang, Siyuan Fu, Spencer Papay, Steph Lin, Suchir Balaji, Suvansh Sanjeev, Szymon Sidor, Tal Broda, Aidan Clark, Tao Wang, Taylor Gordon, Ted Sanders, Tejal Patwardhan, Thibault Sottiaux, Thomas Degry, Thomas Dimson, Tianhao Zheng, Timur Garipov, Tom Stasi, Trapit Bansal, Trevor Creech, Troy Peterson, Tyna Eloundou, Valerie Qi, Vineet Kosaraju, Vinnie Monaco, Vitchyr Pong, Vlad Fomenko, Weiyi Zheng, Wenda Zhou, Wes McCabe, Wojciech Zaremba, Yann Dubois, Yinghai Lu, Yining Chen, Young Cha, Yu Bai, Yuchen He, Yuchen Zhang, Yunyun Wang, Zheng Shao, Zhuohan Li",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16720"" target=""_blank"">2412.16720</a>",,2025-12-03 22:39:25
SurvAttack: Black-Box Attack On Survival Models through Ontology-Informed EHR Perturbation,"Mohsen Nayebi Kerdabadi, Arya Hadizadeh Moghaddam, Bin Liu, Mei Liu, Zijun Yao",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18706"" target=""_blank"">2412.18706</a>",,2025-12-03 22:39:25
Protective Perturbations against Unauthorized Data Usage in Diffusion-based Image Generation,"Sen Peng, Jijia Yang, Mingyue Wang, Jianfei He, Xiaohua Jia",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18791"" target=""_blank"">2412.18791</a>",,2025-12-03 22:39:25
TrojFlow: Flow Models are Natural Targets for Trojan Attacks,"Zhengyang Qi, Xiaohua Xu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16512"" target=""_blank"">2412.16512</a>",,2025-12-03 22:39:25
On the Validity of Traditional Vulnerability Scoring Systems for Adversarial Attacks against LLMs,"Atmane Ayoub Mansour Bahar, Ahmad Samer Wazan",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20087"" target=""_blank"">2412.20087</a>",,2025-12-03 22:39:25
Adversarial Attack and Defense for LoRa Device Identification and Authentication via Deep Learning,"Yalin E. Sagduyu, Tugba Erpek",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.21164"" target=""_blank"">2412.21164</a>",,2025-12-03 22:39:25
Sample Correlation for Fingerprinting Deep Face Recognition,"Jiyang Guan, Jian Liang, Yanbo Wang, Ran He",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20768"" target=""_blank"">2412.20768</a>","<a href=""https://github.com/guanjiyang/SAC_JC"" target=""_blank"">guanjiyang</a>",2025-12-03 22:39:25
Two Heads Are Better Than One: Averaging along Fine-Tuning to Improve Targeted Transferability,"Hui Zeng, Sanshuai Cui, Biwei Chen, Anjie Peng",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20807"" target=""_blank"">2412.20807</a>",,2025-12-03 22:39:25
GASLITEing the Retrieval: Exploring Vulnerabilities in Dense Embedding-based Search,"Matan Ben-Tov, Mahmood Sharif",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20953"" target=""_blank"">2412.20953</a>",,2025-12-03 22:39:25
Unsupervised dense retrieval with conterfactual contrastive learning,"Haitian Chen, Qingyao Ai, Xiao Wang, Yiqun Liu, Fen Lin, Qin Liu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20756"" target=""_blank"">2412.20756</a>",,2025-12-03 22:39:25
RobustBlack: Challenging Black-Box Adversarial Attacks on State-of-the-Art Defenses,"Mohamed Djilani, Salah Ghamizi, Maxime Cordy",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20987"" target=""_blank"">2412.20987</a>",,2025-12-03 22:39:25
ExpShield: Safeguarding Web Text from Unauthorized Crawling and Language Modeling Exploitation,"Ruixuan Liu, Toan Tran, Tianhao Wang, Hongsheng Hu, Shuo Wang, Li Xiong",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.21123"" target=""_blank"">2412.21123</a>",,2025-12-03 22:39:25
Automated Robustness Testing for LLM-based NLP Software,"Mingxuan Xiao, Yan Xiao, Shunhui Ji, Hanbo Cai, Lei Xue, Pengcheng Zhang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.21016"" target=""_blank"">2412.21016</a>",,2025-12-03 22:39:25
DELA: A Novel Approach for Detecting Errors Induced by Large Atomic Condition Numbers,"Youshuai Tan, Zhanwei Zhang, Jinfu Chen, Zishuo Ding, Jifeng Xuan, Weiyi Shang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20804"" target=""_blank"">2412.20804</a>",,2025-12-03 22:39:25
Defending Multimodal Backdoored Models by Repulsive Visual Prompt Tuning,"Zhifang Zhang, Shuo He, Bingquan Shen, Lei Feng",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20392"" target=""_blank"">2412.20392</a>",,2025-12-03 22:39:25
Prototypical Distillation and Debiased Tuning for Black-box Unsupervised Domain Adaptation,"Jian Liang, Lijun Sheng, Hongmin Liu, Ran He",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20670"" target=""_blank"">2412.20670</a>","<a href=""https://github.com/tim-learn/ProDDing/"" target=""_blank"">ProDDing</a>",2025-12-03 22:39:25
Attacks on the neural network and defense methods,"A. Korenev, G. Belokrylov, B. Lodonova, A. Novokhrestov",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20529"" target=""_blank"">2412.20529</a>",,2025-12-03 22:39:25
Cut the Deadwood Out: Post-Training Model Purification with Selective Module Substitution,"Yao Tong, Weijun Li, Xuanli He, Haolan Zhan, Qiongkai Xu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20476"" target=""_blank"">2412.20476</a>",,2025-12-03 22:39:25
MAFT: Efficient Model-Agnostic Fairness Testing for Deep Neural Networks via Zero-Order Gradient Search,"Zhaohui Wang, Min Zhang, Jingran Yang, Bojie Shao, Min Zhang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20086"" target=""_blank"">2412.20086</a>",,2025-12-03 22:39:25
Injecting Bias into Text Classification Models using Backdoor Attacks,"A. Dilara Yavuz, M. Emre Gursoy",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18975"" target=""_blank"">2412.18975</a>",,2025-12-03 22:39:25
Defending Against Network Attacks for Secure AI Agent Migration in Vehicular Metaverses,"Xinru Wen, Jinbo Wen, Ming Xiao, Jiawen Kang, Tao Zhang, Xiaohuan Li, Chuanxi Chen, Dusit Niyato",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20154"" target=""_blank"">2412.20154</a>",,2025-12-03 22:39:25
Standard-Deviation-Inspired Regularization for Improving Adversarial Robustness,"Olukorede Fakorede, Modeste Atsague, Jin Tian",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.19947"" target=""_blank"">2412.19947</a>",,2025-12-03 22:39:25
Adversarial Robustness for Deep Learning-based Wildfire Detection Models,"Ryo Ide, Lei Yang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20006"" target=""_blank"">2412.20006</a>",,2025-12-03 22:39:25
Enhancing Adversarial Robustness of Deep Neural Networks Through Supervised Contrastive Learning,"Longwei Wang, Navid Nayyem, Abdullah Rakin",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.19747"" target=""_blank"">2412.19747</a>",,2025-12-03 22:39:25
Attribution for Enhanced Explanation with Transferable Adversarial eXploration,"Zhiyu Zhu, Jiayu Zhang, Zhibo Jin, Huaming Chen, Jianlong Zhou, Fang Chen",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.19523"" target=""_blank"">2412.19523</a>",,2025-12-03 22:39:25
Federated Hybrid Training and Self-Adversarial Distillation: Towards Robust Edge Networks,"Yu Qiao, Apurba Adhikary, Kitae Kim, Eui-Nam Huh, Zhu Han, Choong Seon Hong",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.19354"" target=""_blank"">2412.19354</a>",,2025-12-03 22:39:25
An Engorgio Prompt Makes Large Language Model Babble on,"Jianshuo Dong, Ziyuan Zhang, Qingjie Zhang, Tianwei Zhang, Hao Wang, Hewu Li, Qi Li, Chao Zhang, Ke Xu, Han Qiu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.19394"" target=""_blank"">2412.19394</a>","<a href=""https://github.com/jianshuod/Engorgio-prompt"" target=""_blank"">jianshuod</a>",2025-12-03 22:39:25
xSRL: Safety-Aware Explainable Reinforcement Learning -- Safety as a Product of Explainability,"Risal Shahriar Shefin, Md Asifur Rahman, Thai Le, Sarra Alqahtani",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.19311"" target=""_blank"">2412.19311</a>","<a href=""https://github.com/risal-shefin/xSRL"" target=""_blank"">risal-shefin</a>",2025-12-03 22:39:25
Distortion-Aware Adversarial Attacks on Bounding Boxes of Object Detectors,"Pham Phuc, Son Vuong, Khang Nguyen, Tuan Dang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18815"" target=""_blank"">2412.18815</a>","<a href=""https://github.com/anonymous20210106/attack_detector"" target=""_blank"">anonymous20210106</a>",2025-12-03 22:39:25
Improving Integrated Gradient-based Transferable Adversarial Examples by Refining the Integration Path,"Yuchen Ren, Zhengyu Zhao, Chenhao Lin, Bo Yang, Lu Zhou, Zhe Liu, Chao Shen",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18844"" target=""_blank"">2412.18844</a>","<a href=""https://github.com/RYC-98/MuMoDIG"" target=""_blank"">RYC-98</a>",2025-12-03 22:39:25
Imperceptible Adversarial Attacks on Point Clouds Guided by Point-to-Surface Field,"Keke Tang, Weiyao Ke, Weilong Peng, Xiaofei Wang, Ziyong Du, Zhize Wu, Peican Zhu, Zhihong Tian",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.19015"" target=""_blank"">2412.19015</a>",,2025-12-03 22:39:25
Adversarial Training for Graph Neural Networks via Graph Subspace Energy Optimization,"Ganlin Liu, Ziling Liang, Xiaowei Huang, Xinping Yi, Shi Jin",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18886"" target=""_blank"">2412.18886</a>",,2025-12-03 22:39:25
Bridging Interpretability and Robustness Using LIME-Guided Model Refinement,"Navid Nayyem, Abdullah Rakin, Longwei Wang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.18952"" target=""_blank"">2412.18952</a>",,2025-12-03 22:39:25
RAT: Adversarial Attacks on Deep Reinforcement Agents for Targeted Behaviors,"Fengshuo Bai, Runze Liu, Yali Du, Ying Wen, Yaodong Yang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.10713"" target=""_blank"">2412.10713</a>",,2025-12-03 22:39:25
A Robust Adversarial Ensemble with Causal (Feature Interaction) Interpretations for Image Classification,"Chunheng Zhao, Pierluigi Pisu, Gurcan Comert, Negash Begashaw, Varghese Vaidyan, Nina Christine Hubig",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.20025"" target=""_blank"">2412.20025</a>",,2025-12-03 22:39:25
Towards More Robust Retrieval-Augmented Generation: Evaluating RAG Under Adversarial Poisoning Attacks,"Jinyan Su, Jin Peng Zhou, Zhengxin Zhang, Preslav Nakov, Claire Cardie",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16708"" target=""_blank"">2412.16708</a>",,2025-12-03 22:39:25
Red Pill and Blue Pill: Controllable Website Fingerprinting Defense via Dynamic Backdoor Learning,"Siyuan Liang, Jiajun Gong, Tianmeng Fang, Aishan Liu, Tao Wang, Xianglong Liu, Xiaochun Cao, Dacheng Tao, Chang Ee-Chien",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11471"" target=""_blank"">2412.11471</a>",,2025-12-03 22:39:25
Practicable Black-box Evasion Attacks on Link Prediction in Dynamic Graphs -- A Graph Sequential Embedding Method,"Jiate Li, Meng Pang, Binghui Wang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13134"" target=""_blank"">2412.13134</a>",,2025-12-03 22:39:25
Jailbreaking? One Step Is Enough! (64%),"Weixiong Zheng, Peijian Zeng, Yiwei Li, Hongyan Wu, Nankai Lin, Junhao Chen, Aimin Yang, Yongmei Zhou",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.12621"" target=""_blank"">2412.12621</a>",,2025-12-03 22:39:25
Toxicity Detection towards Adaptability to Changing Perturbations,"Hankun Kang, Jianhao Chen, Yongqi Li, Xin Miao, Mayi Xu, Ming Zhong, Yuanyuan Zhu, Tieyun Qian",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.15267"" target=""_blank"">2412.15267</a>",,2025-12-03 22:39:25
A New Adversarial Perspective for LiDAR-based 3D Object Detection,"Shijun Zheng, Weiquan Liu, Yu Guo, Yu Zang, Siqi Shen, Cheng Wang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13017"" target=""_blank"">2412.13017</a>",,2025-12-03 22:39:25
Accuracy Limits as a Barrier to Biometric System Security,"Axel Durbet, Paul-Marie Grollemund, Pascal Lafourcade, Kevin Thiry-Atighehchi",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13099"" target=""_blank"">2412.13099</a>",,2025-12-03 22:39:25
Neural Control and Certificate Repair via Runtime Monitoring,"Emily Yu, Đorđe Žikelić, Thomas A. Henzinger",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.12996"" target=""_blank"">2412.12996</a>",,2025-12-03 22:39:25
Training Verification-Friendly Neural Networks via Neuron Behavior Consistency,"Zongxin Liu, Zhe Zhao, Fu Song, Jun Sun, Pengfei Yang, Xiaowei Huang, Lijun Zhang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13229"" target=""_blank"">2412.13229</a>",,2025-12-03 22:39:25
Distribution Shifts at Scale: Out-of-distribution Detection in Earth Observation,"Burak Ekim, Girmaw Abebe Tadesse, Caleb Robinson, Gilles Hacheme, Michael Schmitt, Rahul Dodhia, Juan M. Lavista Ferres",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13394"" target=""_blank"">2412.13394</a>","<a href=""https://github.com/microsoft/geospatial-ood-detection"" target=""_blank"">microsoft</a>",2025-12-03 22:39:25
Adversarially robust generalization theory via Jacobian regularization for deep neural networks,"Dongya Wu, Xin Li",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.12449"" target=""_blank"">2412.12449</a>",,2025-12-03 22:39:25
Human-in-the-Loop Generation of Adversarial Texts: A Case Study on Tibetan Script,"Xi Cao, Yuan Sun, Jiajun Li, Quzong Gesang, Nuo Qun, Tashi Nyima",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.12478"" target=""_blank"">2412.12478</a>",,2025-12-03 22:39:25
Transferable Adversarial Face Attack with Text Controlled Attribute,"Wenyun Li, Zheng Zhang, Xiangyuan Lan, Dongmei Jiang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11735"" target=""_blank"">2412.11735</a>",,2025-12-03 22:39:25
Towards Adversarial Robustness of Model-Level Mixture-of-Experts Architectures for Semantic Segmentation,"Svetlana Pavlitska, Enrico Eisen, J. Marius Zöllner",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11608"" target=""_blank"">2412.11608</a>","<a href=""https://github.com/KASTEL-MobilityLab/mixtures-of-experts/"" target=""_blank"">mixtures-of-experts</a>",2025-12-03 22:39:25
WFCAT: Augmenting Website Fingerprinting with Channel-wise Attention on Timing Features,"Jiajun Gong, Wei Cai, Siyuan Liang, Zhong Guan, Tao Wang, Ee-Chien Chang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11487"" target=""_blank"">2412.11487</a>",,2025-12-03 22:39:25
"Sonar-based Deep Learning in Underwater Robotics: Overview, Robustness and Challenges","Martin Aubard, Ana Madureira, Luís Teixeira, José Pinto",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11840"" target=""_blank"">2412.11840</a>",,2025-12-03 22:39:25
Exploring Query Efficient Data Generation towards Data-free Model Stealing in Hard Label Setting,"Gaozheng Pei, Shaojie lyu, Ke Ma, Pinci Yang, Qianqian Xu, Yingfei Sun",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.15276"" target=""_blank"">2412.15276</a>",,2025-12-03 22:39:25
CP-Guard: Malicious Agent Detection and Defense in Collaborative Bird's Eye View Perception,"Senkang Hu, Yihang Tao, Guowen Xu, Yiqin Deng, Xianhao Chen, Yuguang Fang, Sam Kwong",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.12000"" target=""_blank"">2412.12000</a>","<a href=""https://github.com/CP-Security/CP-Guard"" target=""_blank"">CP-Security</a>",2025-12-03 22:39:25
Stepwise Reasoning Error Disruption Attack of LLMs,"Jingyu Peng, Maolin Wang, Xiangyu Zhao, Kai Zhang, Wanyu Wang, Pengyue Jia, Qidong Liu, Ruocheng Guo, Qi Liu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11934"" target=""_blank"">2412.11934</a>","<a href=""https://github.com/Applied-Machine-Learning-Lab/SEED-Attack"" target=""_blank"">Applied-Machine-Learning-Lab</a>",2025-12-03 22:39:25
"Comprehensive Survey on Adversarial Examples in Cybersecurity: Impacts, Challenges, and Mitigation Strategies",Li Li,arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.12217"" target=""_blank"">2412.12217</a>",,2025-12-03 22:39:25
Unpacking the Resilience of SNLI Contradiction Examples to Attacks,"Chetan Verma, Archit Agarwal",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11172"" target=""_blank"">2412.11172</a>",,2025-12-03 22:39:25
Impact of Adversarial Attacks on Deep Learning Model Explainability,"Gazi Nazia Nur, Mohammad Ahnaf Sadat",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11119"" target=""_blank"">2412.11119</a>",,2025-12-03 22:39:25
UIBDiffusion: Universal Imperceptible Backdoor Attack for Diffusion Models,"Yuning Han, Bingyin Zhao, Rui Chu, Feng Luo, Biplab Sikdar, Yingjie Lao",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11441"" target=""_blank"">2412.11441</a>",,2025-12-03 22:39:25
Learning Robust and Privacy-Preserving Representations via Information Theory,"Binghui Zhang, Sayedeh Leila Noorbakhsh, Yun Dong, Yuan Hong, Binghui Wang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11066"" target=""_blank"">2412.11066</a>",,2025-12-03 22:39:25
A Comprehensive Review of Adversarial Attacks on Machine Learning,"Syed Quiser Ahmed, Bharathi Vokkaliga Ganesh, Sathyanarayana Sampath Kumar, Prakhar Mishra, Ravi Anand, Bhanuteja Akurathi",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11384"" target=""_blank"">2412.11384</a>",,2025-12-03 22:39:25
Finding a Wolf in Sheep's Clothing: Combating Adversarial Text-To-Image Prompts with Text Summarization,"Portia Cooper, Harshita Narnoli, Mihai Surdeanu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.12212"" target=""_blank"">2412.12212</a>",,2025-12-03 22:39:25
Set-Valued Sensitivity Analysis of Deep Neural Networks,"Xin Jeff Wang, Feiling Jeff wang, Xuegang Jeff Ban",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11057"" target=""_blank"">2412.11057</a>",,2025-12-03 22:39:25
SpearBot: Leveraging Large Language Models in a Generative-Critique Framework for Spear-Phishing Email Generation,"Qinglin Qi, Yun Luo, Yijia Xu, Wenbo Guo, Yong Fang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11109"" target=""_blank"">2412.11109</a>",,2025-12-03 22:39:25
POEX: Policy Executable Embodied AI Jailbreak Attacks,"Xuancun Lu, Zhengxian Huang, Xinfeng Li, Xiaoyu ji, Wenyuan Xu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16633"" target=""_blank"">2412.16633</a>",,2025-12-03 22:39:25
"A3E: Aligned and Augmented Adversarial Ensemble for Accurate, Robust and Privacy-Preserving EEG Decoding","Xiaoqing Chen, Tianwang Jia, Dongrui Wu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11390"" target=""_blank"">2412.11390</a>",,2025-12-03 22:39:25
Fooling LLM graders into giving better grades through neural activity guided adversarial prompting,"Atsushi Yamamura, Surya Ganguli",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.15275"" target=""_blank"">2412.15275</a>",,2025-12-03 22:39:25
PGD-Imp: Rethinking and Unleashing Potential of Classic PGD with Dual Strategies for Imperceptible Adversarial Attacks,"Jin Li, Zitong Yu, Ziqiang He, Z. Jane Wang, Xiangui Kang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.11168"" target=""_blank"">2412.11168</a>",,2025-12-03 22:39:25
AdvIRL: Reinforcement Learning-Based Adversarial Attacks on 3D NeRF Models,"Tommy Nguyen, Mehmet Ergezer, Christian Green",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16213"" target=""_blank"">2412.16213</a>","<a href=""https://github.com/Tommy-Nguyen-cpu/AdvIRL/tree/MultiView-Clean"" target=""_blank"">tree</a>",2025-12-03 22:39:25
Boosting GNN Performance via Training Sample Selection Based on Adversarial Robustness Evaluation,Yongyu Wang,arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.14738"" target=""_blank"">2412.14738</a>",,2025-12-03 22:39:25
Forget Vectors at Play: Universal Input Perturbations Driving Machine Unlearning in Image Classification,"Changchang Sun, Ren Wang, Yihua Zhang, Jinghan Jia, Jiancheng Liu, Gaowen Liu, Sijia Liu, Yan Yan",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16780"" target=""_blank"">2412.16780</a>","<a href=""https://github.com/Changchangsun/Forget-Vector"" target=""_blank"">Changchangsun</a>",2025-12-03 22:39:25
The Task Shield: Enforcing Task Alignment to Defend Against Indirect Prompt Injection in LLM Agents,"Feiran Jia, Tong Wu, Xin Qin, Anna Squicciarini",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16682"" target=""_blank"">2412.16682</a>",,2025-12-03 22:39:25
Targeted View-Invariant Adversarial Perturbations for 3D Object Recognition,"Christian Green, Mehmet Ergezer, Abdurrahman Zeybey",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13376"" target=""_blank"">2412.13376</a>",,2025-12-03 22:39:25
RoboSignature: Robust Signature and Watermarking on Network Attacks,"Aryaman Shaan, Garvit Banga, Raghav Mantri",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.19834"" target=""_blank"">2412.19834</a>",,2025-12-03 22:39:25
Adversarial Robustness through Dynamic Ensemble Learning,"Hetvi Waghela, Jaydip Sen, Sneha Rakshit",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16254"" target=""_blank"">2412.16254</a>",,2025-12-03 22:39:25
EMPRA: Embedding Perturbation Rank Attack against Neural Ranking Models,"Amin Bigdeli, Negar Arabzadeh, Ebrahim Bagheri, Charles L. A. Clarke",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16382"" target=""_blank"">2412.16382</a>",,2025-12-03 22:39:25
Human-Readable Adversarial Prompts: An Investigation into LLM Vulnerabilities Using Situational Context,"Nilanjana Das, Edward Raff, Aman Chadha, Manas Gaur",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16359"" target=""_blank"">2412.16359</a>",,2025-12-03 22:39:25
JailPO: A Novel Black-box Jailbreak Framework via Preference Optimization against Aligned LLMs,"Hongyi Li, Jiawei Ye, Jie Wu, Tianjie Yan, Chu Wang, Zhixin Li",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.15623"" target=""_blank"">2412.15623</a>",,2025-12-03 22:39:25
PoisonCatcher: Revealing and Identifying LDP Poisoning Attacks in IIoT,"Lisha Shuai, Shaofeng Tan, Nan Zhang, Jiamin Zhang, Min Zhang, Xiaolong Yang",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.15704"" target=""_blank"">2412.15704</a>",,2025-12-03 22:39:25
Technical Report for ICML 2024 TiFA Workshop MLLM Attack Challenge: Suffix Injection and Projected Gradient Descent Can Easily Fool An MLLM,"Yangyang Guo, Ziwei Xu, Xilie Xu, YongKang Wong, Liqiang Nie, Mohan Kankanhalli",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.15614"" target=""_blank"">2412.15614</a>",,2025-12-03 22:39:25
Texture- and Shape-based Adversarial Attacks for Vehicle Detection in Synthetic Overhead Imagery,"Mikael Yeghiazaryan, Sai Abhishek Siddhartha Namburu, Emily Kim, Stanislav Panev, Melo Celso de, Brent Lance, la Torre Fernando De, Jessica K. Hodgins",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16358"" target=""_blank"">2412.16358</a>",,2025-12-03 22:39:25
Robust random graph matching in dense graphs via vector approximate message passing,Zhangsong Li,arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.16457"" target=""_blank"">2412.16457</a>",,2025-12-03 22:39:25
AutoTrust: Benchmarking Trustworthiness in Large Vision Language Models for Autonomous Driving,"Shuo Xing, Hongyuan Hua, Xiangbo Gao, Shenzhe Zhu, Renjie Li, Kexin Tian, Xiaopeng Li, Heng Huang, Tianbao Yang, Zhangyang Wang, Yang Zhou, Huaxiu Yao, Zhengzhong Tu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.15206"" target=""_blank"">2412.15206</a>","<a href=""https://github.com/taco-group/AutoTrust"" target=""_blank"">taco-group</a>",2025-12-03 22:39:25
Watertox: The Art of Simplicity in Universal Attacks A Cross-Model Framework for Robust Adversarial Generation,"Zhenghao Gao, Shengjie Xu, Meixi Chen, Fangyao Zhao",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.15924"" target=""_blank"">2412.15924</a>",,2025-12-03 22:39:25
A Review of the Duality of Adversarial Learning in Network Intrusion: Attacks and Countermeasures,"Shalini Saini, Anitha Chennamaneni, Babatunde Sawyerr",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13880"" target=""_blank"">2412.13880</a>",,2025-12-03 22:39:25
Speech Watermarking with Discrete Intermediate Representations,"Shengpeng Ji, Ziyue Jiang, Jialong Zuo, Minghui Fang, Yifu Chen, Tao Jin, Zhou Zhao",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13917"" target=""_blank"">2412.13917</a>","<a href=""https://DiscreteWM.github.io/discrete_wm"" target=""_blank"">DiscreteWM.github.io</a>",2025-12-03 22:39:25
Improving the Transferability of 3D Point Cloud Attack via Spectral-aware Admix and Optimization Designs,"Shiyu Hu, Daizong Liu, Wei Hu",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.12626"" target=""_blank"">2412.12626</a>",,2025-12-03 22:39:25
Novel AI Camera Camouflage: Face Cloaking Without Full Disguise,"David Noever, Forrest McKee",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13507"" target=""_blank"">2412.13507</a>",,2025-12-03 22:39:25
SHAP scores fail pervasively even when Lipschitz succeeds,"Olivier Letoffe, Xuanxiang Huang, Joao Marques-Silva",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13866"" target=""_blank"">2412.13866</a>",,2025-12-03 22:39:25
Mesoscopic Insights: Orchestrating Multi-scale & Hybrid Architecture for Image Manipulation Localization,"Xuekang Zhu, Xiaochen Ma, Lei Su, Zhuohang Jiang, Bo Du, Xiwen Wang, Zeyu Lei, Wentao Feng, Chi-Man Pun, Jizhe Zhou",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13753"" target=""_blank"">2412.13753</a>",,2025-12-03 22:39:25
On the Robustness of Distributed Machine Learning against Transfer Attacks,"Sébastien Andreina, Pascal Zimmer, Ghassan Karame",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.14080"" target=""_blank"">2412.14080</a>",,2025-12-03 22:39:25
Hybrid Data-Free Knowledge Distillation,"Jialiang Tang, Shuo Chen, Chen Gong",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13525"" target=""_blank"">2412.13525</a>","<a href=""https://github.com/tangjialiang97/HiDFD"" target=""_blank"">tangjialiang97</a>",2025-12-03 22:39:25
Physics-Based Adversarial Attack on Near-Infrared Human Detector for Nighttime Surveillance Camera Systems,"Muyao Niu, Zhuoxiao Li, Yifan Zhan, Huy H. Nguyen, Isao Echizen, Yinqiang Zheng",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13709"" target=""_blank"">2412.13709</a>","<a href=""https://github.com/MyNiuuu/AdvNIR"" target=""_blank"">MyNiuuu</a>",2025-12-03 22:39:25
Mitigating Adversarial Attacks in LLMs through Defensive Suffix Generation,"Minkyoung Kim, Yunha Kim, Hyeram Seo, Heejung Choi, Jiye Han, Gaeun Kee, Soyoung Ko, HyoJe Jung, Byeolhee Kim, Young-Hak Kim, Sanghyun Park, Tae Joon Jun",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13705"" target=""_blank"">2412.13705</a>",,2025-12-03 22:39:25
A Black-Box Evaluation Framework for Semantic Robustness in Bird's Eye View Detection,"Fu Wang, Yanghao Zhang, Xiangyu Yin, Guangliang Cheng, Zeyu Fu, Xiaowei Huang, Wenjie Ruan",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13913"" target=""_blank"">2412.13913</a>",,2025-12-03 22:39:25
Cultivating Archipelago of Forests: Evolving Robust Decision Trees through Island Coevolution,"Adam Żychowski, Andrew Perrault, Jacek Mańdziuk",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13762"" target=""_blank"">2412.13762</a>",,2025-12-03 22:39:25
Adversarial Hubness in Multi-Modal Retrieval,"Tingwei Zhang, Fnu Suya, Rishi Jha, Collin Zhang, Vitaly Shmatikov",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.14113"" target=""_blank"">2412.14113</a>",,2025-12-03 22:39:25
Crabs: Consuming Resrouce via Auto-generation for LLM-DoS Attack under Black-box Settings,"Yuanhe Zhang, Zhenhong Zhou, Wei Zhang, Xinyue Wang, Xiaojun Jia, Yang Liu, Sen Su",arXiv,2024-12,"<a href=""http://arxiv.org/abs/2412.13879"" target=""_blank"">2412.13879</a>","<a href=""https://github.com/shuita2333/AutoDoS"" target=""_blank"">shuita2333</a>",2025-12-03 22:39:25
Adaptive Meta-Learning for Robust Deepfake Detection: A Multi-Agent Framework to Data Drift and Model Generalization,"Dinesh Srivasthav P, Badri Narayan Subudhi",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.08148"" target=""_blank"">2411.08148</a>",,2025-12-03 22:39:25
Boosting the Targeted Transferability of Adversarial Examples via Salient Region & Weighted Feature Drop,"Shanjun Xu, Linghui Li, Kaiguo Yuan, Bingyu Li",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.06784"" target=""_blank"">2411.06784</a>",,2025-12-03 22:39:25
Aligning Visual Contrastive learning models via Preference Optimization,"Amirabbas Afzali, Borna Khodabandeh, Ali Rasekh, Mahyar JafariNodeh, Sepehr kazemi, Simon Gottschalk",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.08923"" target=""_blank"">2411.08923</a>",,2025-12-03 22:39:25
SequentialBreak: Large Language Models Can be Fooled by Embedding Jailbreak Prompts into Sequential Prompt Chains,"Bijoy Ahmed Saiem, MD Sadik Hossain Shanto, Rakib Ahsan, Md Rafi ur Rashid",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.06426"" target=""_blank"">2411.06426</a>",,2025-12-03 22:39:25
Computable Model-Independent Bounds for Adversarial Quantum Machine Learning,"Bacui Li, Tansu Alpcan, Chandra Thapa, Udaya Parampalli",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.06863"" target=""_blank"">2411.06863</a>",,2025-12-03 22:39:25
The Inherent Adversarial Robustness of Analog In-Memory Computing,"Corey Lammie, Julian Büchel, Athanasios Vasilopoulos, Manuel Le Gallo, Abu Sebastian",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.07023"" target=""_blank"">2411.07023</a>",,2025-12-03 22:39:25
Rapid Response: Mitigating LLM Jailbreaks with a Few Examples,"Alwin Peng, Julian Michael, Henry Sleight, Ethan Perez, Mrinank Sharma",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.07494"" target=""_blank"">2411.07494</a>",,2025-12-03 22:39:25
Semi-Truths: A Large-Scale Dataset of AI-Augmented Images for Evaluating Robustness of AI-Generated Image detectors,"Anisha Pal, Julia Kruk, Mansi Phute, Manognya Bhattaram, Diyi Yang, Duen Horng Chau, Judy Hoffman",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.07472"" target=""_blank"">2411.07472</a>","<a href=""https://github.com/J-Kruk/SemiTruths"" target=""_blank"">J-Kruk</a>",2025-12-03 22:39:25
Adversarial Detection with a Dynamically Stable System,"Xiaowei Long, Jie Lin, Xiangyuan Yang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.06666"" target=""_blank"">2411.06666</a>",,2025-12-03 22:39:25
Deferred Backdoor Functionality Attacks on Deep Learning Models,"Jeongjin Shin, Sangdon Park",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14449"" target=""_blank"">2411.14449</a>",,2025-12-03 22:39:25
Saliency Assisted Quantization for Neural Networks,"Elmira Mousa Rezabeyk, Salar Beigzad, Yasin Hamzavi, Mohsen Bagheritabar, Seyedeh Sogol Mirikhoozani",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.05858"" target=""_blank"">2411.05858</a>",,2025-12-03 22:39:25
Target-driven Attack for Large Language Models,"Chong Zhang, Mingyu Jin, Dong Shu, Taowen Wang, Dongfang Liu, Xiaobo Jin",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.07268"" target=""_blank"">2411.07268</a>",,2025-12-03 22:39:25
AI-Compass: A Comprehensive and Effective Multi-module Testing Tool for AI Systems,"Zhiyu Zhu, Zhibo Jin, Hongsheng Hu, Minhui Xue, Ruoxi Sun, Seyit Camtepe, Praveen Gauravaram, Huaming Chen",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.06146"" target=""_blank"">2411.06146</a>",,2025-12-03 22:39:25
Post-Hoc Robustness Enhancement in Graph Neural Networks with Conditional Random Fields,"Yassine Abbahaddou, Sofiane Ennadir, Johannes F. Lutzeyer, Fragkiskos D. Malliaros, Michalis Vazirgiannis",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.05399"" target=""_blank"">2411.05399</a>",,2025-12-03 22:39:25
Reasoning Robustness of LLMs to Adversarial Typographical Errors,"Esther Gan, Yiran Zhao, Liying Cheng, Yancan Mao, Anirudh Goyal, Kenji Kawaguchi, Min-Yen Kan, Michael Shieh",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.05345"" target=""_blank"">2411.05345</a>",,2025-12-03 22:39:25
MISGUIDE: Security-Aware Attack Analytics for Smart Grid Load Frequency Control,"Nur Imtiazul Haque, Prabin Mali, Mohammad Zakaria Haider, Mohammad Ashiqur Rahman, Sumit Paudyal",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.04731"" target=""_blank"">2411.04731</a>",,2025-12-03 22:39:25
Towards a Re-evaluation of Data Forging Attacks in Practice,"Mohamed Suliman, Anisa Halimi, Swanand Kadhe, Nathalie Baracaldo, Douglas Leith",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.05658"" target=""_blank"">2411.05658</a>",,2025-12-03 22:39:25
Neural Fingerprints for Adversarial Attack Detection,"Haim Fisher, Moni Shahar, Yehezkel S. Resheff",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.04533"" target=""_blank"">2411.04533</a>",,2025-12-03 22:39:25
Seeing is Deceiving: Exploitation of Visual Pathways in Multi-Modal Language Models,"Pete Janowczyk, Linda Laurier, Ave Giulietta, Arlo Octavia, Meade Cleti",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.05056"" target=""_blank"">2411.05056</a>",,2025-12-03 22:39:25
Attention Masks Help Adversarial Attacks to Bypass Safety Detectors,Yunfan Shi,arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.04772"" target=""_blank"">2411.04772</a>",,2025-12-03 22:39:25
Defending Deep Regression Models against Backdoor Attacks,"Lingyu Du, Yupei Liu, Jinyuan Jia, Guohao Lan",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.04811"" target=""_blank"">2411.04811</a>",,2025-12-03 22:39:25
"A Survey on Adversarial Machine Learning for Code Data: Realistic Threats, Countermeasures, and Interpretations","Yulong Yang, Haoran Fan, Chenhao Lin, Qian Li, Zhengyu Zhao, Chao Shen, Xiaohong Guan",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.07597"" target=""_blank"">2411.07597</a>",,2025-12-03 22:39:25
Hardware and Software Platform Inference,"Cheng Zhang, Hanna Foerster, Robert D. Mullins, Yiren Zhao, Ilia Shumailov",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.05197"" target=""_blank"">2411.05197</a>",,2025-12-03 22:39:25
New Emerged Security and Privacy of Pre-trained Model: a Survey and Outlook,"Meng Yang, Tianqing Zhu, Chi Liu, WanLei Zhou, Shui Yu, Philip S. Yu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.07691"" target=""_blank"">2411.07691</a>",,2025-12-03 22:39:25
RenderBender: A Survey on Adversarial Attacks Using Differentiable Rendering,"Matthew Hull, Haoran Wang, Matthew Lau, Alec Helbling, Mansi Phute, Chao Zhang, Zsolt Kira, Willian Lunardi, Martin Andreoni, Wenke Lee, Polo Chau",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.09749"" target=""_blank"">2411.09749</a>",,2025-12-03 22:39:25
Deceiving Question-Answering Models: A Hybrid Word-Level Adversarial Approach,"Jiyao Li, Mingze Ni, Yongshun Gong, Wei Liu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.08248"" target=""_blank"">2411.08248</a>",,2025-12-03 22:39:25
BEARD: Benchmarking the Adversarial Robustness for Dataset Distillation,"Zheng Zhou, Wenquan Feng, Shuchang Lyu, Guangliang Cheng, Xiaowei Huang, Qi Zhao",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.09265"" target=""_blank"">2411.09265</a>",,2025-12-03 22:39:25
Edge-Only Universal Adversarial Attacks in Distributed Learning,"Giulio Rossolini, Tommaso Baldi, Alessandro Biondi, Giorgio Buttazzo",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.10500"" target=""_blank"">2411.10500</a>",,2025-12-03 22:39:25
Deferred Poisoning: Making the Model More Vulnerable via Hessian Singularization,"Yuhao He, Jinyu Tian, Xianwei Zheng, Li Dong, Yuanman Li, Leo Yu Zhang, Jiantao Zhou",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03752"" target=""_blank"">2411.03752</a>",,2025-12-03 22:39:25
Prompt-Guided Environmentally Consistent Adversarial Patch,"Chaoqun Li, Huanqian Yan, Lifeng Zhou, Tairan Chen, Zhuodong Liu, Hang Su",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.10498"" target=""_blank"">2411.10498</a>",,2025-12-03 22:39:25
Continual Adversarial Reinforcement Learning (CARL) of False Data Injection detection: forgetting and explainability,"Pooja Aslami, Kejun Chen, Timothy M. Hansen, Malik Hassanaly",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.10367"" target=""_blank"">2411.10367</a>",,2025-12-03 22:39:25
EveGuard: Defeating Vibration-based Side-Channel Eavesdropping with Audio Adversarial Perturbations,"Jung-Woo Chang, Ke Sun, David Xia, Xinyu Zhang, Farinaz Koushanfar",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.10034"" target=""_blank"">2411.10034</a>",,2025-12-03 22:39:25
Safe Text-to-Image Generation: Simply Sanitize the Prompt Embedding,"Huming Qiu, Guanxu Chen, Mi Zhang, Min Yang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.10329"" target=""_blank"">2411.10329</a>",,2025-12-03 22:39:25
Measuring Non-Adversarial Reproduction of Training Data in Large Language Models,"Michael Aerni, Javier Rando, Edoardo Debenedetti, Nicholas Carlini, Daphne Ippolito, Florian Tramèr",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.10242"" target=""_blank"">2411.10242</a>",,2025-12-03 22:39:25
MDHP-Net: Detecting an Emerging Time-exciting Threat in IVN,"Qi Liu, Yanchen Liu, Ruifeng Li, Chenhong Cao, Yufeng Li, Xingyu Li, Peng Wang, Runhan Feng, Shiyang Bu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.10258"" target=""_blank"">2411.10258</a>",,2025-12-03 22:39:25
Toward Robust and Accurate Adversarial Camouflage Generation against Vehicle Detectors,"Jiawei Zhou, Linye Lyu, Daojing He, Yu Li",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.10029"" target=""_blank"">2411.10029</a>",,2025-12-03 22:39:25
RedTest: Towards Measuring Redundancy in Deep Neural Networks Effectively,"Yao Lu, Peixin Zhang, Jingyi Wang, Lei Ma, Xiaoniu Yang, Qi Xuan",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.10507"" target=""_blank"">2411.10507</a>",,2025-12-03 22:39:25
Transferable Adversarial Attacks against ASR,"Xiaoxue Gao, Zexin Li, Yiming Chen, Cong Liu, Haizhou Li",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.09220"" target=""_blank"">2411.09220</a>",,2025-12-03 22:39:25
Zer0-Jack: A Memory-efficient Gradient-based Jailbreaking Method for Black-box Multi-modal Large Language Models,"Tiejin Chen, Kaishen Wang, Hua Wei",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.07559"" target=""_blank"">2411.07559</a>",,2025-12-03 22:39:25
Jailbreak Attacks and Defenses against Multimodal Generative Models: A Survey,"Xuannan Liu, Xing Cui, Peipei Li, Zekun Li, Huaibo Huang, Shuhan Xia, Miaoxuan Zhang, Yueying Zou, Ran He",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.09259"" target=""_blank"">2411.09259</a>","<a href=""https://github.com/liuxuannan/Awesome-Multimodal-Jailbreak"" target=""_blank"">liuxuannan</a>",2025-12-03 22:39:25
Your Fixed Watermark is Fragile: Towards Semantic-Aware Watermark for EaaS Copyright Protection,"Zekun Fei, Biao Yi, Jianing Geng, Ruiqi He, Lihai Nie, Zheli Liu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.09359"" target=""_blank"">2411.09359</a>","<a href=""https://github.com/Zk4-ps/EaaS-Embedding-Watermark"" target=""_blank"">Zk4-ps</a>",2025-12-03 22:39:25
Are nuclear masks all you need for improved out-of-domain generalisation? A closer look at cancer classification in histopathology,"Dhananjay Tomar, Alexander Binder, Andreas Kleppe",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.09373"" target=""_blank"">2411.09373</a>","<a href=""https://github.com/undercutspiky/SFL/"" target=""_blank"">SFL</a>",2025-12-03 22:39:25
Confidence-aware Denoised Fine-tuning of Off-the-shelf Models for Certified Robustness,"Suhyeok Jang, Seojin Kim, Jinwoo Shin, Jongheon Jeong",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.08933"" target=""_blank"">2411.08933</a>",,2025-12-03 22:39:25
Trap-MID: Trapdoor-based Defense against Model Inversion Attacks,"Zhen-Ting Liu, Shang-Tse Chen",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.08460"" target=""_blank"">2411.08460</a>","<a href=""https://github.com/ntuaislab/Trap-MID"" target=""_blank"">ntuaislab</a>",2025-12-03 22:39:25
Robust Optimal Power Flow Against Adversarial Attacks: A Tri-Level Optimization Approach,"Saman Mazaheri Khamaneh, Tong Wu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.08618"" target=""_blank"">2411.08618</a>",,2025-12-03 22:39:25
The VLLM Safety Paradox: Dual Ease in Jailbreak Attack and Defense,"Yangyang Guo, Fangkai Jiao, Liqiang Nie, Mohan Kankanhalli",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.08410"" target=""_blank"">2411.08410</a>",,2025-12-03 22:39:25
LLMStinger: Jailbreaking LLMs using RL fine-tuned LLMs,"Piyush Jha, Arnav Arora, Vijay Ganesh",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.08862"" target=""_blank"">2411.08862</a>",,2025-12-03 22:39:25
Chain Association-based Attacking and Shielding Natural Language Processing Systems,"Jiacheng Huang, Long Chen",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.07843"" target=""_blank"">2411.07843</a>",,2025-12-03 22:39:25
IAE: Irony-based Adversarial Examples for Sentiment Analysis Systems,"Xiaoyin Yi, Jiacheng Huang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.07850"" target=""_blank"">2411.07850</a>",,2025-12-03 22:39:25
Game-Theoretic Defenses for Robust Conformal Prediction Against Adversarial Attacks in Medical Imaging,"Rui Luo, Jie Bao, Zhixin Zhou, Chuangyin Dang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.04376"" target=""_blank"">2411.04376</a>",,2025-12-03 22:39:25
Quantum Token Obfuscation via Superposition,"S. M. Yousuf Iqbal Tomal, Abdullah Al Shafin",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01252"" target=""_blank"">2411.01252</a>",,2025-12-03 22:39:25
FedSECA: Sign Election and Coordinate-wise Aggregation of Gradients for Byzantine Tolerant Federated Learning,"Joseph Geo Benjamin, Mothilal Asokan, Mohammad Yaqub, Karthik Nandakumar",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03861"" target=""_blank"">2411.03861</a>","<a href=""https://github.com/JosephGeoBenjamin/FedSECA-ByzantineTolerance"" target=""_blank"">JosephGeoBenjamin</a>",2025-12-03 22:39:25
Plentiful Jailbreaks with String Compositions,Brian R. Y. Huang,arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01084"" target=""_blank"">2411.01084</a>",,2025-12-03 22:39:25
TabSec: A Collaborative Framework for Novel Insider Threat Detection,"Zilin Huang, Xiangyan Tang, Hongyu Li, Xinyi Cao, Jieren Cheng",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01779"" target=""_blank"">2411.01779</a>",,2025-12-03 22:39:25
Learning predictable and robust neural representations by straightening image sequences,"Xueyan Niu, Cristina Savin, Eero P. Simoncelli",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01777"" target=""_blank"">2411.01777</a>",,2025-12-03 22:39:25
$B^4$: A Black-Box Scrubbing Attack on LLM Watermarks,"Baizhou Huang, Xiao Pu, Xiaojun Wan",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01222"" target=""_blank"">2411.01222</a>",,2025-12-03 22:39:25
What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks,"Nathalie Maria Kirch, Severin Field, Stephen Casper",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03343"" target=""_blank"">2411.03343</a>",,2025-12-03 22:39:25
Replace-then-Perturb: Targeted Adversarial Attacks With Visual Reasoning for Vision-Language Models,"Jonggyu Jang, Hyeonsu Lyu, Jungyeon Koh, Hyun Jong Yang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00898"" target=""_blank"">2411.00898</a>",,2025-12-03 22:39:25
Defense Against Prompt Injection Attack by Leveraging Attack Techniques,"Yulin Chen, Haoran Li, Zihao Zheng, Yangqiu Song, Dekai Wu, Bryan Hooi",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00459"" target=""_blank"">2411.00459</a>",,2025-12-03 22:39:25
Certified Robustness for Deep Equilibrium Models via Serialized Random Smoothing,"Weizhi Gao, Zhichao Hou, Han Xu, Xiaorui Liu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00899"" target=""_blank"">2411.00899</a>","<a href=""https://github.com/WeizhiGao/Serialized-Randomized-Smoothing"" target=""_blank"">WeizhiGao</a>",2025-12-03 22:39:25
Attention Tracker: Detecting Prompt Injection Attacks in LLMs,"Kuo-Han Hung, Ching-Yun Ko, Ambrish Rawat, I-Hsin Chung, Winston H. Hsu, Pin-Yu Chen",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00348"" target=""_blank"">2411.00348</a>",,2025-12-03 22:39:25
Outlier-Oriented Poisoning Attack: A Grey-box Approach to Disturb Decision Boundaries by Perturbing Outliers in Multiclass Learning,"Anum Paracha, Junaid Arshad, Mohamed Ben Farah, Khalid Ismail",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00519"" target=""_blank"">2411.00519</a>",,2025-12-03 22:39:25
Identify Backdoored Model in Federated Learning via Individual Unlearning,"Jiahao Xu, Zikai Zhang, Rui Hu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01040"" target=""_blank"">2411.01040</a>","<a href=""https://github.com/JiiahaoXU/MASA"" target=""_blank"">JiiahaoXU</a>",2025-12-03 22:39:25
Uncertainty-based Offline Variational Bayesian Reinforcement Learning for Robustness under Diverse Data Corruptions,"Rui Yang, Jie Wang, Guoping Wu, Bin Li",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00465"" target=""_blank"">2411.00465</a>",,2025-12-03 22:39:25
MRJ-Agent: An Effective Jailbreak Agent for Multi-Round Dialogue,"Fengxiang Wang, Ranjie Duan, Peng Xiao, Xiaojun Jia, Shiji Zhao, Cheng Wei, YueFeng Chen, Chongwen Wang, Jialing Tao, Hang Su, Jun Zhu, Hui Xue",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03814"" target=""_blank"">2411.03814</a>",,2025-12-03 22:39:25
Examining Attacks on Consensus and Incentive Systems in Proof-of-Work Blockchains: A Systematic Literature Review,"Dinitha Wijewardhana, Sugandima Vidanagamachchi, Nalin Arachchilage",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00349"" target=""_blank"">2411.00349</a>",,2025-12-03 22:39:25
B-cosification: Transforming Deep Neural Networks to be Inherently Interpretable,"Shreyash Arya, Sukrut Rao, Moritz Böhle, Bernt Schiele",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00715"" target=""_blank"">2411.00715</a>","<a href=""https://github.com/shrebox/B-cosification"" target=""_blank"">shrebox</a>",2025-12-03 22:39:25
Towards Building Secure UAV Navigation with FHE-aware Knowledge Distillation,"Arjun Ramesh Kaushik, Charanjit Jutla, Nalini Ratha",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00403"" target=""_blank"">2411.00403</a>",,2025-12-03 22:39:25
Protecting Feed-Forward Networks from Adversarial Attacks Using Predictive Coding,"Ehsan Ganjidoost, Jeff Orchard",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00222"" target=""_blank"">2411.00222</a>",,2025-12-03 22:39:25
I Can Hear You: Selective Robust Training for Deepfake Audio Detection,"Zirui Zhang, Wei Hao, Aroon Sankoh, William Lin, Emanuel Mendiola-Ortiz, Junfeng Yang, Chengzhi Mao",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00121"" target=""_blank"">2411.00121</a>",,2025-12-03 22:39:25
Optical Lens Attack on Monocular Depth Estimation for Autonomous Driving,"Ce Michigan State University Zhou, Qiben Michigan State University Yan, Daniel Michigan State University Kent, Guangjing University of South Florida Wang, Weikang Michigan State University Ding, Ziqi Peking University Zhang, Hayder Michigan State University Radha",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00192"" target=""_blank"">2411.00192</a>",,2025-12-03 22:39:25
CausAdv: A Causal-based Framework for Detecting Adversarial Examples,Hichem Debbi,arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00839"" target=""_blank"">2411.00839</a>","<a href=""https://github.com/HichemDebbi/CausAdv"" target=""_blank"">HichemDebbi</a>",2025-12-03 22:39:25
Longitudinal Mammogram Exam-based Breast Cancer Diagnosis Models: Vulnerability to Adversarial Attacks,"Zhengbo Zhou, Degan Hao, Dooman Arefan, Margarita Zuley, Jules Sumkin, Shandong Wu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00837"" target=""_blank"">2411.00837</a>",,2025-12-03 22:39:25
DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models,"Chengke Zou, Xingang Guo, Rui Yang, Junyu Zhang, Bin Hu, Huan Zhang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00836"" target=""_blank"">2411.00836</a>",,2025-12-03 22:39:25
Comparing Robustness Against Adversarial Attacks in Code Generation: LLM-Generated vs,"Md Abdul Awal, Mrigank Rochan, Chanchal K. Roy",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.10565"" target=""_blank"">2411.10565</a>",,2025-12-03 22:39:25
Rotation Perturbation Robustness in Point Cloud Analysis: A Perspective of Manifold Distillation,"Xinyu Xu, Huazhen Liu, Feiming Wei, Huilin Xiong, Wenxian Yu, Tao Zhang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01748"" target=""_blank"">2411.01748</a>",,2025-12-03 22:39:25
UniGuard: Towards Universal Safety Guardrails for Jailbreak Attacks on Multimodal Large Language Models,"Sejoon Oh, Yiqiao Jin, Megha Sharma, Donghyun Kim, Eric Ma, Gaurav Verma, Srijan Kumar",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01703"" target=""_blank"">2411.01703</a>",,2025-12-03 22:39:25
SQL Injection Jailbreak: a structural disaster of large language models,"Jiawei Zhao, Kejiang Chen, Weiming Zhang, Nenghai Yu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01565"" target=""_blank"">2411.01565</a>","<a href=""https://github.com/weiyezhimeng/SQL-Injection-Jailbreak"" target=""_blank"">weiyezhimeng</a>",2025-12-03 22:39:25
Undermining Image and Text Classification Algorithms Using Adversarial Attacks,"Langalibalele Lunga, Suhas Sreehari",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03348"" target=""_blank"">2411.03348</a>",,2025-12-03 22:39:25
Towards Secured Smart Grid 2,"Lan-Huong Nguyen, Van-Linh Nguyen, Ren-Hung Hwang, Jian-Jhih Kuo, Yu-Wen Chen, Chien-Chung Huang, Ping-I Pan",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.04365"" target=""_blank"">2411.04365</a>",,2025-12-03 22:39:25
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion,"Tiantian Liu, Hongwei Yao, Tong Wu, Zhan Qin, Feng Lin, Kui Ren, Chun Chen",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.05034"" target=""_blank"">2411.05034</a>",,2025-12-03 22:39:25
Enhancing Adversarial Robustness via Uncertainty-Aware Distributional Adversarial Training,"Junhao Dong, Xinghua Qu, Z. Jane Wang, Yew-Soon Ong",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02871"" target=""_blank"">2411.02871</a>",,2025-12-03 22:39:25
Region-Guided Attack on the Segment Anything Model (SAM),"Xiaoliang Liu, Furao Shen, Jian Zhao",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02974"" target=""_blank"">2411.02974</a>",,2025-12-03 22:39:25
Double Whammy: Stealthy Data Manipulation aided Reconstruction Attack on Graph Federated Learning,"Jinyin Chen, Minying Ma, Haibin Zheng, Qi Xuan",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02866"" target=""_blank"">2411.02866</a>",,2025-12-03 22:39:25
Flashy Backdoor: Real-world Environment Backdoor Attack on SNNs with DVS Cameras,"Roberto Riaño, Gorka Abad, Stjepan Picek, Aitor Urbieta",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03022"" target=""_blank"">2411.03022</a>",,2025-12-03 22:39:25
Formal Logic-guided Robust Federated Learning against Poisoning Attacks,"Dung Thuy Nguyen, Ziyan An, Taylor T. Johnson, Meiyi Ma, Kevin Leach",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03231"" target=""_blank"">2411.03231</a>",,2025-12-03 22:39:25
Oblivious Defense in ML Models: Backdoor Removal without Detection,"Shafi Goldwasser, Jonathan Shafer, Neekon Vafa, Vinod Vaikuntanathan",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03279"" target=""_blank"">2411.03279</a>",,2025-12-03 22:39:25
DM4Steal: Diffusion Model For Link Stealing Attack On Graph Neural Networks,"Jinyin Chen, Haonan Ma, Haibin Zheng",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03364"" target=""_blank"">2411.03364</a>",,2025-12-03 22:39:25
FEDLAD: Federated Evaluation of Deep Leakage Attacks and Defenses,"Isaac Baglin, Xiatian Zhu, Simon Hadfield",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03019"" target=""_blank"">2411.03019</a>",,2025-12-03 22:39:25
Lost in Context: The Influence of Context on Feature Attribution Methods for Object Recognition,"Sayanta Adhikari, Rishav Kumar, Konda Reddy Mopuri, Rajalakshmi Pachamuthu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02833"" target=""_blank"">2411.02833</a>",,2025-12-03 22:39:25
Benchmarking Vision Language Model Unlearning via Fictitious Facial Identity Dataset,"Yingzi Ma, Jiongxiao Wang, Fei Wang, Siyuan Ma, Jiazhao Li, Jinsheng Pan, Xiujun Li, Furong Huang, Lichao Sun, Bo Li, Yejin Choi, Muhao Chen, Chaowei Xiao",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03554"" target=""_blank"">2411.03554</a>",,2025-12-03 22:39:25
Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters,"Kevin Y. Li, Sachin Goyal, Joao D. Semedo, J. Zico Kolter",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.03312"" target=""_blank"">2411.03312</a>","<a href=""https://github.com/locuslab/llava-token-compression"" target=""_blank"">locuslab</a>",2025-12-03 22:39:25
Query-Efficient Adversarial Attack Against Vertical Federated Graph Learning,"Jinyin Chen, Wenbo Mu, Luxin Zhang, Guohan Huang, Haibin Zheng, Yao Cheng",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02809"" target=""_blank"">2411.02809</a>",,2025-12-03 22:39:25
Semantic-Aligned Adversarial Evolution Triangle for High-Transferability Vision-Language Attack,"Xiaojun Jia, Sensen Gao, Qing Guo, Ke Ma, Yihao Huang, Simeng Qin, Yang Liu, Ivor Tsang Fellow, Xiaochun Cao",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02669"" target=""_blank"">2411.02669</a>","<a href=""https://github.com/jiaxiaojunQAQ/SA-AET"" target=""_blank"">jiaxiaojunQAQ</a>",2025-12-03 22:39:25
LiDAttack: Robust Black-box Attack on LiDAR-based Object Detection,"Jinyin Chen, Danxin Liao, Sheng Xiang, Haibin Zheng",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.01889"" target=""_blank"">2411.01889</a>",,2025-12-03 22:39:25
Alignment-Based Adversarial Training (ABAT) for Improving the Robustness and Accuracy of EEG-Based BCIs,"Xiaoqing Chen, Ziwei Wang, Dongrui Wu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02094"" target=""_blank"">2411.02094</a>",,2025-12-03 22:39:25
Attacking Vision-Language Computer Agents via Pop-ups,"Yanzhe Zhang, Tao Yu, Diyi Yang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02391"" target=""_blank"">2411.02391</a>",,2025-12-03 22:39:25
Stochastic Monkeys at Play: Random Augmentations Cheaply Break LLM Safety Alignment,"Jason Vega, Junsheng Huang, Gaokai Zhang, Hangoo Kang, Minjia Zhang, Gagandeep Singh",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02785"" target=""_blank"">2411.02785</a>",,2025-12-03 22:39:25
FactTest: Factuality Testing in Large Language Models with Statistical Guarantees,"Fan Nie, Xiaotian Hou, Shuhang Lin, James Zou, Huaxiu Yao, Linjun Zhang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02603"" target=""_blank"">2411.02603</a>",,2025-12-03 22:39:25
Differentially Private Integrated Decision Gradients (IDG-DP) for Radar-based Human Activity Recognition,"Idris Zakariyya, Linda Tran, Kaushik Bhargav Sivangi, Paul Henderson, Fani Deligianni",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.02099"" target=""_blank"">2411.02099</a>",,2025-12-03 22:39:25
A Hard-Label Cryptanalytic Extraction of Non-Fully Connected Deep Neural Networks using Side-Channel Attacks,"Benoit Coqueret, Mathieu Carbone, Olivier Sentieys, Gabriel Zaid",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.10174"" target=""_blank"">2411.10174</a>",,2025-12-03 22:39:25
IDEATOR: Jailbreaking and Benchmarking Large Vision-Language Models Using Themselves,"Ruofan Wang, Juncheng Li, Yixu Wang, Bo Wang, Xiaosen Wang, Yan Teng, Yingchun Wang, Xingjun Ma, Yu-Gang Jiang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.00827"" target=""_blank"">2411.00827</a>",,2025-12-03 22:39:25
Destabilizing a Social Network Model via Intrinsic Feedback Vulnerabilities,"Lane H. Rogers, Emma J. Reid, Robert A. Bridges",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.10868"" target=""_blank"">2411.10868</a>",,2025-12-03 22:39:25
RED: Robust Environmental Design,Jinghan Yang,arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.17026"" target=""_blank"">2411.17026</a>",,2025-12-03 22:39:25
Multi-Objective Reinforcement Learning for Automated Resilient Cyber Defence,"Ross O'Driscoll, Claudia Hagen, Joe Bater, James M. Adams",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.17585"" target=""_blank"">2411.17585</a>",,2025-12-03 22:39:25
Passive Deepfake Detection Across Multi-modalities: A Comprehensive Survey,"Hong-Hanh Nguyen-Le, Van-Tuan Tran, Dinh-Thuc Nguyen, Nhien-An Le-Khac",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.17911"" target=""_blank"">2411.17911</a>",,2025-12-03 22:39:25
Imperceptible Adversarial Examples in the Physical World,"Weilin Xu, Sebastian Szyller, Cory Cornelius, Luis Murillo Rojas, Marius Arvinte, Alvaro Velasquez, Jason Martin, Nageen Himayat",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16622"" target=""_blank"">2411.16622</a>",,2025-12-03 22:39:25
DiffBreak: Is Diffusion-Based Purification Robust? (99%),"Andre Kassis, Urs Hengartner, Yaoliang Yu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16598"" target=""_blank"">2411.16598</a>",,2025-12-03 22:39:25
Scaling Laws for Black box Adversarial Attacks,"Chuan Liu, Huanran Chen, Yichi Zhang, Yinpeng Dong, Jun Zhu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16782"" target=""_blank"">2411.16782</a>",,2025-12-03 22:39:25
Privacy Protection in Personalized Diffusion Models via Targeted Cross-Attention Adversarial Attack,"Xide Xu, Muhammad Atif Butt, Sandesh Kamath, Bogdan Raducanu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16437"" target=""_blank"">2411.16437</a>",,2025-12-03 22:39:25
UVCG: Leveraging Temporal Consistency for Universal Video Protection,"KaiZhou Li, Jindong Gu, Xinchun Yu, Junjie Cao, Yansong Tang, Xiao-Ping Zhang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.17746"" target=""_blank"">2411.17746</a>",,2025-12-03 22:39:25
Guarding the Gate: ConceptGuard Battles Concept-Level Backdoors in Concept Bottleneck Models,"Songning Lai, Yu Huang, Jiayu Yang, Gaoxiang Huang, Wenshuo Chen, Yutao Yue",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16512"" target=""_blank"">2411.16512</a>",,2025-12-03 22:39:25
Edit Away and My Face Will not Stay: Personal Biometric Defense against Malicious Generative Editing,"Hanhui Wang, Yihua Zhang, Ruizheng Bai, Yue Zhao, Sijia Liu, Zhengzhong Tu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16832"" target=""_blank"">2411.16832</a>","<a href=""https://github.com/taco-group/FaceLock"" target=""_blank"">taco-group</a>",2025-12-03 22:39:25
Sparse patches adversarial attacks via extrapolating point-wise information,"Yaniv Nemcovsky, Avi Mendelson, Chaim Baskin",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16162"" target=""_blank"">2411.16162</a>","<a href=""https://github.com/yanemcovsky/SparsePatches"" target=""_blank"">yanemcovsky</a>",2025-12-03 22:39:25
DeDe: Detecting Backdoor Samples for SSL Encoders via Decoders,"Sizai Hou, Songze Li, Duanyi Yao",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16154"" target=""_blank"">2411.16154</a>",,2025-12-03 22:39:25
PEFTGuard: Detecting Backdoor Attacks Against Parameter-Efficient Fine-Tuning,"Zhen Sun, Tianshuo Cong, Yule Liu, Chenhao Lin, Xinlei He, Rongmao Chen, Xingshuo Han, Xinyi Huang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.17453"" target=""_blank"">2411.17453</a>",,2025-12-03 22:39:25
BadSFL: Backdoor Attack against Scaffold Federated Learning,"Xingshuo Han, Xuanye Zhang, Xiang Lan, Haozhao Wang, Shengmin Xu, Shen Ren, Jason Zeng, Ming Wu, Michael Heinrich, Tianwei Zhang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16167"" target=""_blank"">2411.16167</a>",,2025-12-03 22:39:25
Why the Agent Made that Decision: Explaining Deep Reinforcement Learning with Vision Masks,"Rui Zuo, Zifan Wang, Simon Khan, Garrett Ethan Katz, Qinru Qiu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16120"" target=""_blank"">2411.16120</a>",,2025-12-03 22:39:25
XAI and Android Malware Models,"Maithili Kulkarni, Mark Stamp",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16817"" target=""_blank"">2411.16817</a>",,2025-12-03 22:39:25
Revisiting Marr in Face: The Building of 2D--2,"Xiangyu Zhu, Chang Yu, Jiankuo Zhao, Zhaoxiang Zhang, Stan Z. Li, Zhen Lei",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16148"" target=""_blank"">2411.16148</a>",,2025-12-03 22:39:25
Chain of Attack: On the Robustness of Vision-Language Models Against Transfer-Based Adversarial Attacks,"Peng Xie, Yequan Bie, Jianda Mao, Yangqiu Song, Yang Wang, Hao Chen, Kani Chen",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.15720"" target=""_blank"">2411.15720</a>",,2025-12-03 22:39:25
ExAL: An Exploration Enhanced Adversarial Learning Algorithm,"A Vinil, Aneesh Sreevallabh Chivukula, Pranav Chintareddy",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.15878"" target=""_blank"">2411.15878</a>",,2025-12-03 22:39:25
A Tunable Despeckling Neural Network Stabilized via Diffusion Equation,"Yi Ran, Zhichang Guo, Jia Li, Yao Li, Martin Burger, Boying Wu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.15921"" target=""_blank"">2411.15921</a>",,2025-12-03 22:39:25
Hide in Plain Sight: Clean-Label Backdoor for Auditing Membership Inference,"Depeng Chen, Hao Chen, Hulin Jin, Jie Cui, Hong Zhong",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16763"" target=""_blank"">2411.16763</a>",,2025-12-03 22:39:25
Stealth Attacks Against Moving Target Defense for Smart Grid,"Ke Sun, Iñaki Esnaola, H. Vincent Poor",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16024"" target=""_blank"">2411.16024</a>",,2025-12-03 22:39:25
DRIVE: Dual-Robustness via Information Variability and Entropic Consistency in Source-Free Unsupervised Domain Adaptation,"Ruiqiang Xiao, Songning Lai, Yijun Yang, Jiemin Wu, Yutao Yue, Lei Zhu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.15976"" target=""_blank"">2411.15976</a>",,2025-12-03 22:39:25
Improved Parallel Derandomization via Finite Automata with Applications,"Jeff Giliberti, David G. Harris",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.18028"" target=""_blank"">2411.18028</a>",,2025-12-03 22:39:25
Privacy-preserving Robotic-based Multi-factor Authentication Scheme for Secure Automated Delivery System,"Yang Yang, Aryan Mohammadi Pasikhani, Prosanta Gope, Biplab Sikdar",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.18027"" target=""_blank"">2411.18027</a>",,2025-12-03 22:39:25
Improving the Transferability of Adversarial Attacks on Face Recognition with Diverse Parameters Augmentation,"Fengfan Zhou, Bangjie Yin, Hefei Ling, Qianyu Zhou, Wenxuan Wang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.15555"" target=""_blank"">2411.15555</a>",,2025-12-03 22:39:25
Enhancing Neural Network Robustness Against Fault Injection Through Non-linear Weight Transformations,"Ninnart Fuengfusin, Hakaru Tamukoh",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.19027"" target=""_blank"">2411.19027</a>",,2025-12-03 22:39:25
Towards Class-wise Robustness Analysis,"Tejaswini Medi, Julia Grabinski, Margret Keuper",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.19853"" target=""_blank"">2411.19853</a>",,2025-12-03 22:39:25
FLARE: Towards Universal Dataset Purification against Backdoor Attacks,"Linshan Hou, Wei Luo, Zhongyun Hua, Songhua Chen, Leo Yu Zhang, Yiming Li",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.19479"" target=""_blank"">2411.19479</a>",,2025-12-03 22:39:25
On the Adversarial Robustness of Instruction-Tuned Large Language Models for Code,"Md Imran Hossen, Xiali Hei",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.19508"" target=""_blank"">2411.19508</a>",,2025-12-03 22:39:25
Parallel Stacked Aggregated Network for Voice Authentication in IoT-Enabled Smart Devices,"Awais Khan, Ijaz Ul Haq, Khalid Mahmood Malik",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.19841"" target=""_blank"">2411.19841</a>",,2025-12-03 22:39:25
SURE-VQA: Systematic Understanding of Robustness Evaluation in Medical VQA Tasks,"Kim-Celine Kahl, Selen Erkan, Jeremias Traub, Carsten T. Lüth, Klaus Maier-Hein, Lena Maier-Hein, Paul F. Jaeger",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.19688"" target=""_blank"">2411.19688</a>","<a href=""https://github.com/IML-DKFZ/sure-vqa"" target=""_blank"">IML-DKFZ</a>",2025-12-03 22:39:25
PEFT-as-an-Attack! Jailbreaking Language Models during Federated Parameter-Efficient Fine-Tuning,"Shenghui Li, Edith C. -H. Ngai, Fanghua Ye, Thiemo Voigt",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.19335"" target=""_blank"">2411.19335</a>",,2025-12-03 22:39:25
Variational Bayesian Bow tie Neural Networks with Shrinkage,"Alisa Sheinkman, Sara Wade",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.11132"" target=""_blank"">2411.11132</a>",,2025-12-03 22:39:25
Random Sampling for Diffusion-based Adversarial Purification,"Jiancheng Zhang, Peiran Dong, Yongyong Chen, Yin-Ping Zhao, Song Guo",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.18956"" target=""_blank"">2411.18956</a>",,2025-12-03 22:39:25
Understanding and Improving Training-Free AI-Generated Image Detections with Vision Foundation Models,"Chung-Ting Tsai, Ching-Yun Ko, I-Hsin Chung, Yu-Chiang Frank Wang, Pin-Yu Chen",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.19117"" target=""_blank"">2411.19117</a>",,2025-12-03 22:39:25
LADDER: Multi-objective Backdoor Attack via Evolutionary Algorithm,"Dazhuang Liu, Yanqi Qiao, Rui Wang, Kaitai Liang, Georgios Smaragdakis",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.19075"" target=""_blank"">2411.19075</a>",,2025-12-03 22:39:25
Visual Adversarial Attack on Vision-Language Models for Autonomous Driving,"Tianyuan Zhang, Lu Wang, Xinwei Zhang, Yitong Zhang, Boyi Jia, Siyuan Liang, Shengshan Hu, Qiang Fu, Aishan Liu, Xianglong Liu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.18275"" target=""_blank"">2411.18275</a>",,2025-12-03 22:39:25
Exploring Visual Vulnerabilities via Multi-Loss Adversarial Search for Jailbreaking Vision-Language Models,"Shuyang Hao, Bryan Hooi, Jun Liu, Kai-Wei Chang, Zi Huang, Yujun Cai",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.18000"" target=""_blank"">2411.18000</a>",,2025-12-03 22:39:25
Fall Leaf Adversarial Attack on Traffic Sign Classification,"Anthony Etim, Jakub Szefer",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.18776"" target=""_blank"">2411.18776</a>",,2025-12-03 22:39:25
Immune: Improving Safety Against Jailbreaks in Multi-modal LLMs via Inference-Time Alignment,"Soumya Suvra Ghosal, Souradip Chakraborty, Vaibhav Singh, Tianrui Guan, Mengdi Wang, Ahmad Beirami, Furong Huang, Alvaro Velasquez, Dinesh Manocha, Amrit Singh Bedi",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.18688"" target=""_blank"">2411.18688</a>",,2025-12-03 22:39:25
Neutralizing Backdoors through Information Conflicts for Large Language Models,"Chen Chen, Yuchen Sun, Xueluan Gong, Jiaxin Gao, Kwok-Yan Lam",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.18280"" target=""_blank"">2411.18280</a>",,2025-12-03 22:39:25
Hidden Data Privacy Breaches in Federated Learning,"Xueluan Gong, Yuji Wang, Shuaike Li, Mengyuan Sun, Songze Li, Qian Wang, Kwok-Yan Lam, Chen Chen",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.18269"" target=""_blank"">2411.18269</a>",,2025-12-03 22:39:25
SoK: Watermarking for AI-Generated Content,"Xuandong Zhao, Sam Gunn, Miranda Christ, Jaiden Fairoze, Andres Fabrega, Nicholas Carlini, Sanjam Garg, Sanghyun Hong, Milad Nasr, Florian Tramer, Somesh Jha, Lei Li, Yu-Xiang Wang, Dawn Song",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.18479"" target=""_blank"">2411.18479</a>",,2025-12-03 22:39:25
Adversarial Training in Low-Label Regimes with Margin-Based Interpolation,"Tian Ye, Rajgopal Kannan, Viktor Prasanna",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.17959"" target=""_blank"">2411.17959</a>",,2025-12-03 22:39:25
BadScan: An Architectural Backdoor Attack on Visual State Space Models,"Om Suhas Deshmukh, Sankalp Nagaonkar, Achyut Mani Tripathi, Ashish Mishra",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.17283"" target=""_blank"">2411.17283</a>",,2025-12-03 22:39:25
Stealthy Multi-Task Adversarial Attacks,"Jiacheng Guo, Tianyun Zhang, Lei Li, Haochen Yang, Hongkai Yu, Minghai Qin",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.17936"" target=""_blank"">2411.17936</a>",,2025-12-03 22:39:25
Adversarial Bounding Boxes Generation (ABBG) Attack against Visual Object Trackers,"Fatemeh Nourilenjan Nokabadi, Jean-Francois Lalonde, Christian Gagné",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.17468"" target=""_blank"">2411.17468</a>",,2025-12-03 22:39:25
MADE: Graph Backdoor Defense with Masked Unlearning,"Xiao Lin, Mingjie Li, Yisen Wang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.18648"" target=""_blank"">2411.18648</a>",,2025-12-03 22:39:25
Improving Transferable Targeted Attacks with Feature Tuning Mixup,"Kaisheng Liang, Xuelong Dai, Yanjie Li, Dong Wang, Bin Xiao",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.15553"" target=""_blank"">2411.15553</a>",,2025-12-03 22:39:25
From Open Vocabulary to Open World: Teaching Vision Language Models to Detect Novel Objects,"Zizhao Li, Zhengkang Xiang, Joseph West, Kourosh Khoshelham",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.18207"" target=""_blank"">2411.18207</a>",,2025-12-03 22:39:25
LoBAM: LoRA-Based Backdoor Attack on Model Merging,"Ming Yin, Jingyang Zhang, Jingwei Sun, Minghong Fang, Hai Li, Yiran Chen",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16746"" target=""_blank"">2411.16746</a>",,2025-12-03 22:39:25
DeTrigger: A Gradient-Centric Approach to Backdoor Attack Mitigation in Federated Learning,"Kichang Lee, Yujin Shin, Jonghyuk Yun, Jun Han, JeongGil Ko",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.12220"" target=""_blank"">2411.12220</a>",,2025-12-03 22:39:25
AI-generated Image Detection: Passive or Watermark? (31%),"Moyang Guo, Yuepeng Hu, Zhengyuan Jiang, Zeyu Li, Amir Sadovnik, Arka Daw, Neil Gong",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.13553"" target=""_blank"">2411.13553</a>","<a href=""https://github.com/moyangkuo/ImageDetectBench"" target=""_blank"">moyangkuo</a>",2025-12-03 22:39:25
SoK: A Systems Perspective on Compound AI Threats and Countermeasures,"Sarbartha Banerjee, Prateek Sahu, Mulong Luo, Anjo Vahldiek-Oberwagner, Neeraja J. Yadwadkar, Mohit Tiwari",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.13459"" target=""_blank"">2411.13459</a>",,2025-12-03 22:39:25
CopyrightMeter: Revisiting Copyright Protection in Text-to-image Models,"Naen Xu, Changjiang Li, Tianyu Du, Minxi Li, Wenjie Luo, Jiacheng Liang, Yuyuan Li, Xuhong Zhang, Meng Han, Jianwei Yin, Ting Wang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.13144"" target=""_blank"">2411.13144</a>",,2025-12-03 22:39:25
WaterPark: A Robustness Assessment of Language Model Watermarking,"Jiacheng Liang, Zian Wang, Lauren Hong, Shouling Ji, Ting Wang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.13425"" target=""_blank"">2411.13425</a>",,2025-12-03 22:39:25
NMT-Obfuscator Attack: Ignore a sentence in translation with only one word,"Sahar Sadrizadeh, César Descalzo, Ljiljana Dolamic, Pascal Frossard",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.12473"" target=""_blank"">2411.12473</a>",,2025-12-03 22:39:25
Stochastic BIQA: Median Randomized Smoothing for Certified Blind Image Quality Assessment,"Ekaterina Shumitskaya, Mikhail Pautov, Dmitriy Vatolin, Anastasia Antsiferova",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.12575"" target=""_blank"">2411.12575</a>",,2025-12-03 22:39:25
When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations,"Huaizhi Ge, Yiming Li, Qifan Wang, Yongfeng Zhang, Ruixiang Tang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.12701"" target=""_blank"">2411.12701</a>",,2025-12-03 22:39:25
Theoretical Corrections and the Leveraging of Reinforcement Learning to Enhance Triangle Attack,"Nicole Meng, Caleb Manicke, David Chen, Yingjie Lao, Caiwen Ding, Pengyu Hong, Kaleel Mahmood",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.12071"" target=""_blank"">2411.12071</a>",,2025-12-03 22:39:25
Adapting to Cyber Threats: A Phishing Evolution Network (PEN) Framework for Phishing Generation and Analyzing Evolution Patterns using Large Language Models,"Fengchao Chen, Tingmin Wu, Van Nguyen, Shuo Wang, Hongsheng Hu, Alsharif Abuadbba, Carsten Rudolph",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.11389"" target=""_blank"">2411.11389</a>",,2025-12-03 22:39:25
CROW: Eliminating Backdoors from Large Language Models via Internal Consistency Regularization,"Nay Myat Min, Long H. Pham, Yige Li, Jun Sun",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.12768"" target=""_blank"">2411.12768</a>",,2025-12-03 22:39:25
Reliable Poisoned Sample Detection against Backdoor Attacks Enhanced by Sharpness Aware Minimization,"Mingda Zhang, Mingli Zhu, Zihao Zhu, Baoyuan Wu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.11525"" target=""_blank"">2411.11525</a>",,2025-12-03 22:39:25
A Survey on Adversarial Robustness of LiDAR-based Machine Learning Perception in Autonomous Vehicles,"Junae Kim, Amardeep Kaur",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.13778"" target=""_blank"">2411.13778</a>",,2025-12-03 22:39:25
CLUE-MARK: Watermarking Diffusion Models using CLWE,"Kareem Shehata, Aashish Kolluri, Prateek Saxena",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.11434"" target=""_blank"">2411.11434</a>",,2025-12-03 22:39:25
The Dark Side of Trust: Authority Citation-Driven Jailbreak Attacks on Large Language Models,"Xikang Yang, Xuehai Tang, Jizhong Han, Songlin Hu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.11407"" target=""_blank"">2411.11407</a>",,2025-12-03 22:39:25
"Exploring adversarial robustness of JPEG AI: methodology, comparison and new methods","Egor Kovalev, Georgii Bychkov, Khaled Abud, Aleksandr Gushchin, Anna Chistyakova, Sergey Lavrushkin, Dmitriy Vatolin, Anastasia Antsiferova",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.11795"" target=""_blank"">2411.11795</a>",,2025-12-03 22:39:25
Exploring the Adversarial Vulnerabilities of Vision-Language-Action Models in Robotics,"Taowen Wang, Cheng Han, James Chenhao Liang, Wenhao Yang, Dongfang Liu, Luna Xinyu Zhang, Qifan Wang, Jiebo Luo, Ruixiang Tang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.13587"" target=""_blank"">2411.13587</a>",,2025-12-03 22:39:25
JailbreakLens: Interpreting Jailbreak Mechanism in the Lens of Representation and Circuit,"Zeqing He, Zhibo Wang, Zhixuan Chu, Huiyu Xu, Rui Zheng, Kui Ren, Chun Chen",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.11114"" target=""_blank"">2411.11114</a>",,2025-12-03 22:39:25
Semantic Shield: Defending Vision-Language Models Against Backdooring and Poisoning via Fine-grained Knowledge Alignment,"Alvi Md Ishmam, Christopher Thomas",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.15673"" target=""_blank"">2411.15673</a>",,2025-12-03 22:39:25
CLMIA: Membership Inference Attacks via Unsupervised Contrastive Learning,"Depeng School of Computer Science and Technology, Anhui University Chen, Xiao School of Computer Science and Technology, Anhui University Liu, Jie School of Computer Science and Technology, Anhui University Cui, Hong School of Computer Science and Technology, Anhui University Zhong",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.11144"" target=""_blank"">2411.11144</a>",,2025-12-03 22:39:25
Countering Backdoor Attacks in Image Recognition: A Survey and Evaluation of Mitigation Strategies,"Kealan Dunnett, Reza Arablouei, Dimity Miller, Volkan Dedeoglu, Raja Jurdak",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.11200"" target=""_blank"">2411.11200</a>",,2025-12-03 22:39:25
SoK: Unifying Cybersecurity and Cybersafety of Multimodal Foundation Models with an Information Theory Approach,"Ruoxi Sun, Jiamin Chang, Hammond Pearce, Chaowei Xiao, Bo Li, Qi Wu, Surya Nepal, Minhui Xue",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.11195"" target=""_blank"">2411.11195</a>",,2025-12-03 22:39:25
BackdoorMBTI: A Backdoor Learning Multimodal Benchmark Tool Kit for Backdoor Defense Evaluation,"Haiyang Yu, Tian Xie, Jiaping Gui, Pengyang Wang, Ping Yi, Yue Wu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.11006"" target=""_blank"">2411.11006</a>","<a href=""https://github.com/SJTUHaiyangYu/BackdoorMBTI"" target=""_blank"">SJTUHaiyangYu</a>",2025-12-03 22:39:25
Rethinking the Intermediate Features in Adversarial Attacks: Misleading Robotic Models via Adversarial Distillation,"Ke Wuhan University Zhao, Huayang Wuhan University Huang, Miao Wuhan University Li, Yu Wuhan University Wu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.15222"" target=""_blank"">2411.15222</a>",,2025-12-03 22:39:25
Few-shot Model Extraction Attacks against Sequential Recommender Systems,"Hui Zhang, Fu Liu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.11677"" target=""_blank"">2411.11677</a>",,2025-12-03 22:39:25
Provably Efficient Action-Manipulation Attack Against Continuous Reinforcement Learning,"Zhi Luo, Xiyuan Yang, Pan Zhou, Di Wang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.13116"" target=""_blank"">2411.13116</a>",,2025-12-03 22:39:25
Generating Realistic Adversarial Examples for Business Processes using Variational Autoencoders,"Alexander Stevens, Jari Peeperkorn, Smedt Johannes De, Weerdt Jochen De",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14263"" target=""_blank"">2411.14263</a>",,2025-12-03 22:39:25
Who Can Withstand Chat-Audio Attacks? An Evaluation Benchmark for Large Language Models,"Wanqi Yang, Yanda Li, Meng Fang, Yunchao Wei, Tianyi Zhou, Ling Chen",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14842"" target=""_blank"">2411.14842</a>",,2025-12-03 22:39:25
Universal and Context-Independent Triggers for Precise Control of LLM Outputs,"Jiashuo Liang, Guancheng Li, Yang Yu",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14738"" target=""_blank"">2411.14738</a>",,2025-12-03 22:39:25
Exploring the Robustness and Transferability of Patch-Based Adversarial Attacks in Quantized Neural Networks,"Amira Guesmi, Bassem Ouni, Muhammad Shafique",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.15246"" target=""_blank"">2411.15246</a>",,2025-12-03 22:39:25
TAPT: Test-Time Adversarial Prompt Tuning for Robust Inference in Vision-Language Models,"Xin Wang, Kai Chen, Jiaming Zhang, Jingjing Chen, Xingjun Ma",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.13136"" target=""_blank"">2411.13136</a>",,2025-12-03 22:39:25
Gradient Masking All-at-Once: Ensemble Everything Everywhere Is Not Robust,"Jie Zhang, Kristina Nikolić, Nicholas Carlini, Florian Tramèr",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14834"" target=""_blank"">2411.14834</a>",,2025-12-03 22:39:25
Benchmarking the Robustness of Optical Flow Estimation to Corruptions,"Zhonghua Yi, Hao Shi, Qi Jiang, Yao Gao, Ze Wang, Yufan Zhang, Kailun Yang, Kaiwei Wang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14865"" target=""_blank"">2411.14865</a>","<a href=""https://github.com/ZhonghuaYi/optical_flow_robustness_benchmark"" target=""_blank"">ZhonghuaYi</a>",2025-12-03 22:39:25
Geminio: Language-Guided Gradient Inversion Attacks in Federated Learning,"Junjie Shan, Ziqi Zhao, Jialin Lu, Rui Zhang, Siu Ming Yiu, Ka-Ho Chow",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14937"" target=""_blank"">2411.14937</a>",,2025-12-03 22:39:25
Heavy-tailed Contamination is Easier than Adversarial Contamination,"Yeshwanth Cherapanamjeri, Daniel Lee",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.15306"" target=""_blank"">2411.15306</a>",,2025-12-03 22:39:25
Exploiting Watermark-Based Defense Mechanisms in Text-to-Image Diffusion Models for Unauthorized Data Usage,"Soumil Datta, Shih-Chieh Dai, Leo Yu, Guanhong Tao",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.15367"" target=""_blank"">2411.15367</a>",,2025-12-03 22:39:25
Steering Away from Harm: An Adaptive Approach to Defending Vision Language Model Against Jailbreaks,"Han Wang, Gang Wang, Huan Zhang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.16721"" target=""_blank"">2411.16721</a>",,2025-12-03 22:39:25
Reliable Evaluation of Attribution Maps in CNNs: A Perturbation-Based Approach,"Lars Nieradzik, Henrike Stephani, Janis Keuper",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14946"" target=""_blank"">2411.14946</a>",,2025-12-03 22:39:25
Twin Trigger Generative Networks for Backdoor Attacks against Object Detection,"Zhiying Li, Zhi Liu, Guanggang Geng, Shreyank N Gowda, Shuyuan Lin, Jian Weng, Xiaobo Jin",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.15439"" target=""_blank"">2411.15439</a>",,2025-12-03 22:39:25
Learning Fair Robustness via Domain Mixup,"Meiyu Zhong, Ravi Tandon",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14424"" target=""_blank"">2411.14424</a>",,2025-12-03 22:39:25
AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection,"Jialin Lu, Junjie Shan, Ziqi Zhao, Ka-Ho Chow",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14243"" target=""_blank"">2411.14243</a>",,2025-12-03 22:39:25
Indiscriminate Disruption of Conditional Inference on Multivariate Gaussians,"William N. Caballero, Matthew LaRosa, Alexander Fisher, Vahid Tarokh",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14351"" target=""_blank"">2411.14351</a>",,2025-12-03 22:39:25
Towards Million-Scale Adversarial Robustness Evaluation With Stronger Individual Attacks,"Yong Xie, Weijie Zheng, Hanxun Huang, Guangnan Ye, Xingjun Ma",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.15210"" target=""_blank"">2411.15210</a>",,2025-12-03 22:39:25
GraphTheft: Quantifying Privacy Risks in Graph Prompt Learning,"Jiani Zhu, Xi Lin, Yuxin Qi, Qinghua Mao",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14718"" target=""_blank"">2411.14718</a>",,2025-12-03 22:39:25
Memory Backdoor Attacks on Neural Networks,"Eden Luzon, Guy Amit, Roy Weiss, Yisroel Mirsky",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14516"" target=""_blank"">2411.14516</a>",,2025-12-03 22:39:25
Evaluating the Robustness of Analogical Reasoning in Large Language Models,"Martha Lewis, Melanie Mitchell",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14215"" target=""_blank"">2411.14215</a>",,2025-12-03 22:39:25
GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs,"Advik Raj Basani, Xiao Zhang",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14133"" target=""_blank"">2411.14133</a>",,2025-12-03 22:39:25
Global Challenge for Safe and Secure LLMs Track 1,"Xiaojun Jia, Yihao Huang, Yang Liu, Peng Yan Tan, Weng Kuan Yau, Mun-Thye Mak, Xin Ming Sim, Wee Siong Ng, See Kiong Ng, Hanqing Liu, Lifeng Zhou, Huanqian Yan, Xiaobing Sun, Wei Liu, Long Wang, Yiming Qian, Yong Liu, Junxiao Yang, Zhexin Zhang, Leqi Lei, Renmiao Chen, Yida Lu, Shiyao Cui, Zizhou Wang, Shaohua Li, Yan Wang, Rick Siow Mong Goh, Liangli Zhen, Yingjie Zhang, Zhe Zhao",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14502"" target=""_blank"">2411.14502</a>",,2025-12-03 22:39:25
TrojanEdit: Multimodal Backdoor Attack Against Image Editing Model,"Ji Guo, Peihong Chen, Wenbo Jiang, Xiaolei Wen, Jiaming He, Jiachen Li, Guoming Lu, Aiguo Chen, Hongwei Li",arXiv,2024-11,"<a href=""http://arxiv.org/abs/2411.14681"" target=""_blank"">2411.14681</a>",,2025-12-03 22:39:25
Invisibility Cloak: Disappearance under Human Pose Estimation via Backdoor Attacks,"Minxing Zhang, Michael Backes, Xiao Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.07670"" target=""_blank"">2410.07670</a>",,2025-12-03 22:39:25
Bilinear MLPs enable weight-based mechanistic interpretability,"Michael T. Pearce, Thomas Dooms, Alice Rigg, Jose M. Oramas, Lee Sharkey",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08417"" target=""_blank"">2410.08417</a>",,2025-12-03 22:39:25
Securing HHL Quantum Algorithm against Quantum Computer Attacks,"Yizhuo Tan, Hrvoje Kukina, Jakub Szefer",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08010"" target=""_blank"">2410.08010</a>",,2025-12-03 22:39:25
Towards Assurance of LLM Adversarial Robustness using Ontology-Driven Argumentation,"Tomas Bueno Momcilovic, Beat Buesser, Giulio Zizzo, Mark Purcell, Dian Balta",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.07962"" target=""_blank"">2410.07962</a>",,2025-12-03 22:39:25
A Survey on Physical Adversarial Attacks against Face Recognition Systems,"Mingsi Wang, Jiachen Zhou, Tianlin Li, Guozhu Meng, Kai Chen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16317"" target=""_blank"">2410.16317</a>",,2025-12-03 22:39:25
Understanding Adversarially Robust Generalization via Weight-Curvature Index,"Yuelin Xu, Xiao Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.07719"" target=""_blank"">2410.07719</a>",,2025-12-03 22:39:25
Adversarial Training Can Provably Improve Robustness: Theoretical Analysis of Feature Learning Process Under Structured Data,"Binghui Li, Yuanzhi Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08503"" target=""_blank"">2410.08503</a>",,2025-12-03 22:39:25
"AI Learning Algorithms: Deep Learning, Hybrid Models, and Large-Scale Model Integration","Noorbakhsh Amiri Golilarz, Elias Hossain, Abdoljalil Addeh, Keyan Alexander Rahimi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09186"" target=""_blank"">2410.09186</a>",,2025-12-03 22:39:25
Time Traveling to Defend Against Adversarial Example Attacks in Image Classification,"Anthony Etim, Jakub Szefer",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08338"" target=""_blank"">2410.08338</a>",,2025-12-03 22:39:25
JAILJUDGE: A Comprehensive Jailbreak Judge Benchmark with Multi-Agent Enhanced Explanation Evaluation Framework,"Fan Liu, Yue Feng, Zhao Xu, Lixin Su, Xinyu Ma, Dawei Yin, Hao Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12855"" target=""_blank"">2410.12855</a>",,2025-12-03 22:39:25
RePD: Defending Jailbreak Attack through a Retrieval-based Prompt Decomposition Process,"Peiran Wang, Xiaogeng Liu, Chaowei Xiao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08660"" target=""_blank"">2410.08660</a>",,2025-12-03 22:39:25
RAB$^2$-DEF: Dynamic and explainable defense against adversarial attacks in Federated Learning to fair poor clients,"Nuria Rodríguez-Barroso, M. Victoria Luzón, Francisco Herrera",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08244"" target=""_blank"">2410.08244</a>",,2025-12-03 22:39:25
F2A: An Innovative Approach for Prompt Injection by Utilizing Feign Security Detection Agents,Yupeng Ren,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08776"" target=""_blank"">2410.08776</a>",,2025-12-03 22:39:25
Adversarial Robustness Overestimation and Instability in TRADES,"Jonathan Weiping Li, Ren-Wei Liang, Cheng-Han Yeh, Cheng-Chang Tsai, Kuanchun Yu, Chun-Shien Lu, Shang-Tse Chen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.07675"" target=""_blank"">2410.07675</a>",,2025-12-03 22:39:25
JPEG Inspired Deep Learning,"Ahmed H. Salamah, Kaixiang Zheng, Yiwen Liu, En-Hui Yang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.07081"" target=""_blank"">2410.07081</a>","<a href=""https://github.com/AhmedHussKhalifa/JPEG-Inspired-DL"" target=""_blank"">AhmedHussKhalifa</a>",2025-12-03 22:39:25
Poison-splat: Computation Cost Attack on 3D Gaussian Splatting,"Jiahao Lu, Yifan Zhang, Qiuhong Shen, Xinchao Wang, Shuicheng Yan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08190"" target=""_blank"">2410.08190</a>",,2025-12-03 22:39:25
A Closer Look at Machine Unlearning for Large Language Models,"Xiaojian Yuan, Tianyu Pang, Chao Du, Kejiang Chen, Weiming Zhang, Min Lin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08109"" target=""_blank"">2410.08109</a>","<a href=""https://github.com/sail-sg/closer-look-LLM-unlearning"" target=""_blank"">sail-sg</a>",2025-12-03 22:39:25
Filtered Randomized Smoothing: A New Defense for Robust Modulation Classification,"Wenhan Zhang, Meiyu Zhong, Ravi Tandon, Marwan Krunz",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06339"" target=""_blank"">2410.06339</a>",,2025-12-03 22:39:25
"The Good, the Bad and the Ugly: Watermarks, Transferable Attacks and Adversarial Defenses","Grzegorz Głuch, Berkant Turan, Sai Ganesh Nagarajan, Sebastian Pokutta",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08864"" target=""_blank"">2410.08864</a>",,2025-12-03 22:39:25
Hyper Adversarial Tuning for Boosting Adversarial Robustness of Pretrained Large Vision Models,"Kangtao Lv, Huangsen Cao, Kainan Tu, Yihuai Xu, Zhimeng Zhang, Xin Ding, Yongwei Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05951"" target=""_blank"">2410.05951</a>",,2025-12-03 22:39:25
Utilize the Flow before Stepping into the Same River Twice: Certainty Represented Knowledge Flow for Refusal-Aware Instruction Tuning,"Runchuan Zhu, Zhipeng Ma, Jiang Wu, Junyuan Gao, Jiaqi Wang, Dahua Lin, Conghui He",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06913"" target=""_blank"">2410.06913</a>","<a href=""https://github.com/opendatalab/CRaFT"" target=""_blank"">opendatalab</a>",2025-12-03 22:39:25
PII-Scope: A Comprehensive Study on Training Data PII Extraction Attacks in LLMs,"Krishna Kanth Nakka, Ahmed Frikha, Ricardo Mendes, Xue Jiang, Xuebing Zhou",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06704"" target=""_blank"">2410.06704</a>",,2025-12-03 22:39:25
AdaRC: Mitigating Graph Structure Shifts during Test-Time,"Wenxuan Bao, Zhichen Zeng, Zhining Liu, Hanghang Tong, Jingrui He",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06976"" target=""_blank"">2410.06976</a>",,2025-12-03 22:39:25
Mind Your Questions! Towards Backdoor Attacks on Text-to-Visualization Models,"Shuaimin Li, Yuanfeng Song, Xuanang Chen, Anni Peng, Zhuoyue Wan, Chen Jason Zhang, Raymond Chi-Wing Wong",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06782"" target=""_blank"">2410.06782</a>",,2025-12-03 22:39:25
Cheating Automatic LLM Benchmarks: Null Models Achieve High Win Rates,"Xiaosen Zheng, Tianyu Pang, Chao Du, Qian Liu, Jing Jiang, Min Lin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.07137"" target=""_blank"">2410.07137</a>","<a href=""https://github.com/sail-sg/Cheating-LLM-Benchmarks"" target=""_blank"">sail-sg</a>",2025-12-03 22:39:25
Adversarial Vulnerability as a Consequence of On-Manifold Inseparibility,"Rajdeep Haldar, Yue Xing, Qifan Song, Guang Lin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06921"" target=""_blank"">2410.06921</a>",,2025-12-03 22:39:25
Average Certified Radius is a Poor Metric for Randomized Smoothing,"Chenhao Sun, Yuhao Mao, Mark Niklas Müller, Martin Vechev",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06895"" target=""_blank"">2410.06895</a>",,2025-12-03 22:39:25
Data Taggants: Dataset Ownership Verification via Harmless Targeted Data Poisoning,"Wassim Bouaziz, El-Mahdi El-Mhamdi, Nicolas Usunier",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09101"" target=""_blank"">2410.09101</a>",,2025-12-03 22:39:25
Can DeepFake Speech be Reliably Detected? (62%),"Hongbin Liu, Youzheng Chen, Arun Narayanan, Athula Balachandran, Pedro J. Moreno, Lun Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06572"" target=""_blank"">2410.06572</a>",,2025-12-03 22:39:25
Secure Video Quality Assessment Resisting Adversarial Attacks,"Ao-Xiang Zhang, Yu Ran, Weixuan Tang, Yuan-Gen Wang, Qingxiao Guan, Chunsheng Yang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06866"" target=""_blank"">2410.06866</a>",,2025-12-03 22:39:25
Understanding Model Ensemble in Transferable Adversarial Attack,"Wei Yao, Zeliang Zhang, Huayi Tang, Yong Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06851"" target=""_blank"">2410.06851</a>",,2025-12-03 22:39:25
Break the Visual Perception: Adversarial Attacks Targeting Encoded Visual Tokens of Large Vision-Language Models,"Yubo Wang, Chaohu Liu, Yanqiu Qu, Haoyu Cao, Deqiang Jiang, Linli Xu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06699"" target=""_blank"">2410.06699</a>",,2025-12-03 22:39:25
Impeding LLM-assisted Cheating in Introductory Programming Assignments via Adversarial Perturbation,"Saiful Islam Salim, Rubin Yuchan Yang, Alexander Cooper, Suryashree Ray, Saumya Debray, Sazzadur Rahaman",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09318"" target=""_blank"">2410.09318</a>",,2025-12-03 22:39:25
Enhancing Robustness in Deep Reinforcement Learning: A Lyapunov Exponent Approach,"Rory Young, Nicolas Pugeault",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10674"" target=""_blank"">2410.10674</a>",,2025-12-03 22:39:25
AttnGCG: Enhancing Jailbreaking Attacks on LLMs with Attention Manipulation,"Zijun Wang, Haoqin Tu, Jieru Mei, Bingchen Zhao, Yisen Wang, Cihang Xie",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09040"" target=""_blank"">2410.09040</a>","<a href=""https://github.com/UCSC-VLAA/AttnGCG-attack"" target=""_blank"">UCSC-VLAA</a>",2025-12-03 22:39:25
Feature Averaging: An Implicit Bias of Gradient Descent Leading to Non-Robustness in Neural Networks,"Binghui Li, Zhixuan Pan, Kaifeng Lyu, Jian Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10322"" target=""_blank"">2410.10322</a>",,2025-12-03 22:39:25
The Implicit Bias of Structured State Space Models Can Be Poisoned With Clean Labels,"Yonatan Slutzky, Yotam Alexander, Noam Razin, Nadav Cohen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10473"" target=""_blank"">2410.10473</a>",,2025-12-03 22:39:25
Generalized Adversarial Code-Suggestions: Exploiting Contexts of LLM-based Code-Completion,"Karl Rubel, Maximilian Noppel, Christian Wressnegger",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10526"" target=""_blank"">2410.10526</a>",,2025-12-03 22:39:25
LLMs know their vulnerabilities: Uncover Safety Gaps through Natural Distribution Shifts,"Qibing Ren, Hao Li, Dongrui Liu, Zhanxu Xie, Xiaoya Lu, Yu Qiao, Lei Sha, Junchi Yan, Lizhuang Ma, Jing Shao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10700"" target=""_blank"">2410.10700</a>","<a href=""https://github.com/AI45Lab/ActorAttack"" target=""_blank"">AI45Lab</a>",2025-12-03 22:39:25
How to Backdoor Consistency Models? (56%),"Chengen Wang, Murat Kantarcioglu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.19785"" target=""_blank"">2410.19785</a>",,2025-12-03 22:39:25
ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection,"Martin Aubard, László Antal, Ana Madureira, Luis F. Teixeira, Erika Ábrahám",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10554"" target=""_blank"">2410.10554</a>","<a href=""https://github.com/remaro-network/ROSAR-framework"" target=""_blank"">remaro-network</a>",2025-12-03 22:39:25
Adversarially Guided Stateful Defense Against Backdoor Attacks in Federated Deep Learning,"Hassan Ali, Surya Nepal, Salil S. Kanhere, Sanjay Jha",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11205"" target=""_blank"">2410.11205</a>","<a href=""https://github.com/hassanalikhatim/AGSD"" target=""_blank"">hassanalikhatim</a>",2025-12-03 22:39:25
Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings,"Hossein Mirzaei, Mackenzie W. Mathis",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10744"" target=""_blank"">2410.10744</a>",,2025-12-03 22:39:25
PoisonBench: Assessing Large Language Model Vulnerability to Data Poisoning,"Tingchen Fu, Mrinank Sharma, Philip Torr, Shay B. Cohen, David Krueger, Fazl Barez",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08811"" target=""_blank"">2410.08811</a>",,2025-12-03 22:39:25
Towards Calibrated Losses for Adversarial Robust Reject Option Classification,"Vrund Shah, Tejas Chaudhari, Naresh Manwani",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10736"" target=""_blank"">2410.10736</a>",,2025-12-03 22:39:25
Denial-of-Service Poisoning Attacks against Large Language Models,"Kuofeng Gao, Tianyu Pang, Chao Du, Yong Yang, Shu-Tao Xia, Min Lin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10760"" target=""_blank"">2410.10760</a>","<a href=""https://github.com/sail-sg/P-DoS"" target=""_blank"">sail-sg</a>",2025-12-03 22:39:25
G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks,"Guibin Zhang, Yanwei Yue, Xiangguo Sun, Guancheng Wan, Miao Yu, Junfeng Fang, Kun Wang, Dawei Cheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11782"" target=""_blank"">2410.11782</a>",,2025-12-03 22:39:25
Geometric Inductive Biases of Deep Networks: The Role of Data and Architecture,"Sajad Movahedi, Antonio Orvieto, Seyed-Mohsen Moosavi-Dezfooli",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12025"" target=""_blank"">2410.12025</a>",,2025-12-03 22:39:25
Multi-round jailbreak attack on large language models,"Yihua Zhou, Xiaochuan Shi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11533"" target=""_blank"">2410.11533</a>",,2025-12-03 22:39:25
Polynomial Time Cryptanalytic Extraction of Deep Neural Networks in the Hard-Label Setting,"Nicholas Carlini, Jorge Chávez-Saab, Anna Hambitzer, Francisco Rodríguez-Henríquez, Adi Shamir",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05750"" target=""_blank"">2410.05750</a>",,2025-12-03 22:39:25
Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance,"Sachin Goyal, Christina Baek, J. Zico Kolter, Aditi Raghunathan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10796"" target=""_blank"">2410.10796</a>",,2025-12-03 22:39:25
Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models,"Zhongye Liu, Hongbin Liu, Yuepeng Hu, Zedian Shao, Neil Zhenqiang Gong",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11242"" target=""_blank"">2410.11242</a>","<a href=""https://github.com/lycheeefish/VHExpansion"" target=""_blank"">lycheeefish</a>",2025-12-03 22:39:25
On Calibration of LLM-based Guard Models for Reliable Content Moderation,"Hongfu Liu, Hengguan Huang, Xiangming Gu, Hao Wang, Ye Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10414"" target=""_blank"">2410.10414</a>",,2025-12-03 22:39:25
Regularized Robustly Reliable Learners and Instance Targeted Attacks,"Avrim Blum, Donya Saless",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10572"" target=""_blank"">2410.10572</a>",,2025-12-03 22:39:25
"S$^4$ST: A Strong, Self-transferable, faSt, and Simple Scale Transformation for Transferable Targeted Attack","Yongxiang Liu, Bowen Peng, Li Liu, Xiang Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13891"" target=""_blank"">2410.13891</a>",,2025-12-03 22:39:25
Understanding Robustness of Parameter-Efficient Tuning for Image Classification,"Jiacheng Ruan, Xian Gao, Suncheng Xiang, Mingye Xie, Ting Liu, Yuzhuo Fu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09845"" target=""_blank"">2410.09845</a>","<a href=""https://github.com/JCruan519/PETRobustness"" target=""_blank"">JCruan519</a>",2025-12-03 22:39:25
Out-of-Bounding-Box Triggers: A Stealthy Approach to Cheat Object Detectors,"Tao Lin, Lijia Yu, Gaojie Jin, Renjue Li, Peng Wu, Lijun Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.10091"" target=""_blank"">2410.10091</a>","<a href=""https://github.com/linToTao/Out-of-bbox-attack"" target=""_blank"">linToTao</a>",2025-12-03 22:39:25
"Uncovering, Explaining, and Mitigating the Superficial Safety of Backdoor Defense","Rui Min, Zeyu Qin, Nevin L. Zhang, Li Shen, Minhao Cheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09838"" target=""_blank"">2410.09838</a>",,2025-12-03 22:39:25
BlackDAN: A Black-Box Multi-Objective Approach for Effective and Contextual Jailbreaking of Large Language Models,"Xinyuan Wang, Victor Shea-Jay Huang, Renmiao Chen, Hao Wang, Chengwei Pan, Lei Sha, Minlie Huang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09804"" target=""_blank"">2410.09804</a>",,2025-12-03 22:39:25
Targeted Vaccine: Safety Alignment for Large Language Models against Harmful Fine-Tuning via Layer-wise Perturbation,"Guozhi Liu, Weiwei Lin, Tiansheng Huang, Ruichao Mo, Qi Mu, Li Shen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09760"" target=""_blank"">2410.09760</a>","<a href=""https://github.com/Lslland/T-Vaccine"" target=""_blank"">Lslland</a>",2025-12-03 22:39:25
Unlearn and Burn: Adversarial Machine Unlearning Requests Destroy Model Accuracy,"Yangsibo Huang, Daogao Liu, Lynn Chua, Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Milad Nasr, Amer Sinha, Chiyuan Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09591"" target=""_blank"">2410.09591</a>",,2025-12-03 22:39:25
Robust 3D Point Clouds Classification based on Declarative Defenders,"Kaidong Li, Tianxiao Zhang, Cuncong Zhong, Ziming Zhang, Guanghui Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09691"" target=""_blank"">2410.09691</a>","<a href=""https://github.com/KaidongLi/pytorch-LatticePointClassifier"" target=""_blank"">KaidongLi</a>",2025-12-03 22:39:25
"On the Adversarial Transferability of Generalized ""Skip Connections""","Yisen Wang, Yichuan Mo, Dongxian Wu, Mingjie Li, Xingjun Ma, Zhouchen Lin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08950"" target=""_blank"">2410.08950</a>","<a href=""https://github.com/mo666666/SGM"" target=""_blank"">mo666666</a>",2025-12-03 22:39:25
Natural Language Induced Adversarial Images,"Xiaopei Zhu, Peiyang Xu, Guanning Zeng, Yingpeng Dong, Xiaolin Hu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08620"" target=""_blank"">2410.08620</a>","<a href=""https://github.com/zxp555/Natural-Language-Induced-Adversarial-Images"" target=""_blank"">zxp555</a>",2025-12-03 22:39:25
Fragile Giants: Understanding the Susceptibility of Models to Subpopulation Attacks,"Isha Gupta, Hidde Lycklama, Emanuel Opel, Evan Rose, Anwar Hithnawi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.08872"" target=""_blank"">2410.08872</a>",,2025-12-03 22:39:25
AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents,"Maksym Andriushchenko, Alexandra Souly, Mateusz Dziemian, Derek Duenas, Maxwell Lin, Justin Wang, Dan Hendrycks, Andy Zou, Zico Kolter, Matt Fredrikson, Eric Winsor, Jerome Wynne, Yarin Gal, Xander Davies",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09024"" target=""_blank"">2410.09024</a>",,2025-12-03 22:39:25
Training on Fake Labels: Mitigating Label Leakage in Split Learning via Secure Dimension Transformation,"Yukun Jiang, Peiran Wang, Chengguo Lin, Ziyue Huang, Yong Cheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09125"" target=""_blank"">2410.09125</a>",,2025-12-03 22:39:25
CALoR: Towards Comprehensive Model Inversion Defense,"Hongyao Yu, Yixiang Qiu, Hao Fang, Bin Chen, Sijin Yu, Bin Wang, Shu-Tao Xia, Ke Xu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05814"" target=""_blank"">2410.05814</a>",,2025-12-03 22:39:25
Universally Optimal Watermarking Schemes for LLMs: from Theory to Practice,"Haiyun He, Yepeng Liu, Ziqiao Wang, Yongyi Mao, Yuheng Bu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02890"" target=""_blank"">2410.02890</a>",,2025-12-03 22:39:25
Training-free LLM-generated Text Detection by Mining Token Probability Sequences,"Yihuai Xu, Yongwei Wang, Yifei Bi, Huangsen Cao, Zhouhan Lin, Yu Zhao, Fei Wu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06072"" target=""_blank"">2410.06072</a>",,2025-12-03 22:39:25
IndicSentEval: How Effectively do Multilingual Transformer Models encode Linguistic Properties for Indic Languages? (1%),"Akhilesh Aravapalli, Mounika Marreddy, Subba Reddy Oota, Radhika Mamidi, Manish Gupta",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02611"" target=""_blank"">2410.02611</a>",,2025-12-03 22:39:25
Signal Adversarial Examples Generation for Signal Detection Network via White-Box Attack,"Dongyang Li, Linyuan Wang, Guangwei Xiong, Bin Yan, Dekui Ma, Jinxian Peng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01393"" target=""_blank"">2410.01393</a>",,2025-12-03 22:39:25
Impact of White-Box Adversarial Attacks on Convolutional Neural Networks,"Rakesh Podder, Sudipto Ghosh",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02043"" target=""_blank"">2410.02043</a>",,2025-12-03 22:39:25
Erasing Conceptual Knowledge from Language Models,"Rohit Gandikota, Sheridan Feucht, Samuel Marks, David Bau",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02760"" target=""_blank"">2410.02760</a>",,2025-12-03 22:39:25
Buckle Up: Robustifying LLMs at Every Customization Stage via Data Curation,"Xiaoqun Liu, Jiacheng Liang, Luoxi Tang, Chenyu You, Muchao Ye, Zhaohan Xi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02220"" target=""_blank"">2410.02220</a>",,2025-12-03 22:39:25
Backdoor Attack on Vertical Federated Graph Neural Network Learning,"Jirui Yang, Peng Chen, Zhihui Lu, Ruijun Deng, Qiang Duan, Jianping Zeng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11290"" target=""_blank"">2410.11290</a>",,2025-12-03 22:39:25
BACKTIME: Backdoor Attacks on Multivariate Time Series Forecasting,"Xiao Lin, Zhining Liu, Dongqi Fu, Ruizhong Qiu, Hanghang Tong",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02195"" target=""_blank"">2410.02195</a>","<a href=""https://github.com/xiaolin-cs/BackTime"" target=""_blank"">xiaolin-cs</a>",2025-12-03 22:39:25
Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems,"Guibin Zhang, Yanwei Yue, Zhixun Li, Sukwon Yun, Guancheng Wan, Kun Wang, Dawei Cheng, Jeffrey Xu Yu, Tianlong Chen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02506"" target=""_blank"">2410.02506</a>",,2025-12-03 22:39:25
MOREL: Enhancing Adversarial Robustness through Multi-Objective Representation Learning,"Sedjro Salomon Hotegni, Sebastian Peitz",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01697"" target=""_blank"">2410.01697</a>","<a href=""https://github.com/salomonhotegni/MOREL"" target=""_blank"">salomonhotegni</a>",2025-12-03 22:39:25
MTDNS: Moving Target Defense for Resilient DNS Infrastructure,"Abdullah Aydeger, Pei Zhou, Sanzida Hoque, Marco Carvalho, Engin Zeydan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02254"" target=""_blank"">2410.02254</a>",,2025-12-03 22:39:25
Jailbreak Antidote: Runtime Safety-Utility Balance via Sparse Representation Adjustment in Large Language Models,"Guobin Shen, Dongcheng Zhao, Yiting Dong, Xiang He, Yi Zeng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02298"" target=""_blank"">2410.02298</a>",,2025-12-03 22:39:25
"Unveiling AI's Blind Spots: An Oracle for In-Domain, Out-of-Domain, and Adversarial Errors","Shuangpeng Han, Mengmi Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02384"" target=""_blank"">2410.02384</a>",,2025-12-03 22:39:25
F-Fidelity: A Robust Framework for Faithfulness Evaluation of Explainable AI,"Xu Zheng, Farhad Shirani, Zhuomin Chen, Chaohao Lin, Wei Cheng, Wenbo Guo, Dongsheng Luo",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02970"" target=""_blank"">2410.02970</a>",,2025-12-03 22:39:25
Optimizing Adaptive Attacks against Watermarks for Language Models,"Abdulrahman Diaa, Toluwani Aremu, Nils Lukas",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02440"" target=""_blank"">2410.02440</a>","<a href=""https://github.com/nilslukas/ada-wm-evasion"" target=""_blank"">nilslukas</a>",2025-12-03 22:39:25
Demonstration Attack against In-Context Learning for Code Intelligence,"Yifei Ge, Weisong Sun, Yihang Lou, Chunrong Fang, Yiran Zhang, Yiming Li, Xiaofang Zhang, Yang Liu, Zhihong Zhao, Zhenyu Chen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02841"" target=""_blank"">2410.02841</a>",,2025-12-03 22:39:25
On Using Certified Training towards Empirical Robustness,"Palma Alessandro De, Serge Durand, Zakaria Chihani, François Terrier, Caterina Urban",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01617"" target=""_blank"">2410.01617</a>",,2025-12-03 22:39:25
Adversarial Robustness of AI-Generated Image Detectors in the Real World,"Sina Mavali, Jonas Ricker, David Pape, Asja Fischer, Lea Schönherr",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01574"" target=""_blank"">2410.01574</a>",,2025-12-03 22:39:25
PFAttack: Stealthy Attack Bypassing Group Fairness in Federated Learning,"Jiashi Gao, Ziwei Wang, Xiangyu Zhao, Xin Yao, Xuetao Wei",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.06509"" target=""_blank"">2410.06509</a>",,2025-12-03 22:39:25
One Wave to Explain Them All: A Unifying Perspective on Post-hoc Explainability,"Gabriel Kasmi, Amandine Brunetto, Thomas Fel, Jayneel Parekh",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01482"" target=""_blank"">2410.01482</a>",,2025-12-03 22:39:25
Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving,"Ehsan Ahmadi, Ray Mercurius, Soheil Alizadeh, Kasra Rezaee, Amir Rasouli",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.07191"" target=""_blank"">2410.07191</a>","<a href=""https://ehsan-ami.github.io/critic"" target=""_blank"">ehsan-ami.github.io</a>",2025-12-03 22:39:25
Survey of Security and Data Attacks on Machine Unlearning In Financial and E-Commerce,Carl E. J. Brodzinski,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.00055"" target=""_blank"">2410.00055</a>",,2025-12-03 22:39:25
VLMGuard: Defending VLMs against Malicious Prompts via Unlabeled Data,"Xuefeng Du, Reshmi Ghosh, Robert Sim, Ahmed Salem, Vitor Carvalho, Emily Lawton, Yixuan Li, Jack W. Stokes",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.00296"" target=""_blank"">2410.00296</a>",,2025-12-03 22:39:25
Resonance Reduction Against Adversarial Attacks in Dynamic Networks via Eigenspectrum Optimization,"Alp Sahin, Nicolas Kozachuk, Rick S. Blum, Subhrajit Bhattacharya",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.00126"" target=""_blank"">2410.00126</a>",,2025-12-03 22:39:25
Adversarial Suffixes May Be Features Too! (45%),"Wei Zhao, Zhe Li, Yige Li, Jun Sun",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.00451"" target=""_blank"">2410.00451</a>","<a href=""https://github.com/suffix-maybe-feature/adver-suffix-maybe-features"" target=""_blank"">suffix-maybe-feature</a>",2025-12-03 22:39:25
Empirical Perturbation Analysis of Linear System Solvers from a Data Poisoning Perspective,"Yixin Liu, Arielle Carr, Lichao Sun",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.00878"" target=""_blank"">2410.00878</a>",,2025-12-03 22:39:25
Automated Red Teaming with GOAT: the Generative Offensive Agent Tester,"Maya Pavlova, Erik Brinkman, Krithika Iyer, Vitor Albiero, Joanna Bitton, Hailey Nguyen, Joe Li, Cristian Canton Ferrer, Ivan Evtimov, Aaron Grattafiori",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01606"" target=""_blank"">2410.01606</a>",,2025-12-03 22:39:25
"""No Matter What You Do"": Purifying GNN Models via Backdoor Unlearning","Jiale Zhang, Chengcheng Zhu, Bosen Rao, Hao Sui, Xiaobing Sun, Bing Chen, Chunyi Zhou, Shouling Ji",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01272"" target=""_blank"">2410.01272</a>",,2025-12-03 22:39:25
Controlled Generation of Natural Adversarial Documents for Stealthy Retrieval Poisoning,"Collin Zhang, Tingwei Zhang, Vitaly Shmatikov",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02163"" target=""_blank"">2410.02163</a>",,2025-12-03 22:39:25
BadCM: Invisible Backdoor Attack Against Cross-Modal Learning,"Zheng Zhang, Xu Yuan, Lei Zhu, Jingkuan Song, Liqiang Nie",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02182"" target=""_blank"">2410.02182</a>","<a href=""https://github.com/xandery-geek/BadCM"" target=""_blank"">xandery-geek</a>",2025-12-03 22:39:25
Endless Jailbreaks with Bijection Learning,"Brian R. Y. Huang, Maximilian Li, Leonard Tang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01294"" target=""_blank"">2410.01294</a>",,2025-12-03 22:39:25
The Great Contradiction Showdown: How Jailbreak and Stealth Wrestle in Vision-Language Models? (38%),"Ching-Chia Kao, Chia-Mu Yu, Chun-Shien Lu, Chu-Song Chen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01438"" target=""_blank"">2410.01438</a>",,2025-12-03 22:39:25
The Unlikely Hero: Nonideality in Analog Photonic Neural Networks as Built-in Defender Against Adversarial Attacks,"Haotian Lu, Ziang Yin, Partho Bhoumik, Sanmitra Banerjee, Krishnendu Chakrabarty, Jiaqi Gu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01289"" target=""_blank"">2410.01289</a>","<a href=""https://github.com/ScopeX-ASU/Unlikely_Hero"" target=""_blank"">ScopeX-ASU</a>",2025-12-03 22:39:25
Social Media Authentication and Combating Deepfakes using Semi-fragile Invisible Image Watermarking,"Aakash Varma Nadimpalli, Ajita Rattani",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.01906"" target=""_blank"">2410.01906</a>",,2025-12-03 22:39:25
AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs,"Xiaogeng Liu, Peiran Li, Edward Suh, Yevgeniy Vorobeychik, Zhuoqing Mao, Somesh Jha, Patrick McDaniel, Huan Sun, Bo Li, Chaowei Xiao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05295"" target=""_blank"">2410.05295</a>",,2025-12-03 22:39:25
Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents,"Hanrong Zhang, Jingyuan Huang, Kai Mei, Yifei Yao, Zhenting Wang, Chenlu Zhan, Hongwei Wang, Yongfeng Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02644"" target=""_blank"">2410.02644</a>","<a href=""https://github.com/agiresearch/ASB"" target=""_blank"">agiresearch</a>",2025-12-03 22:39:25
Towards Universal Certified Robustness with Multi-Norm Training,"Enyi Jiang, David S. Cheung, Gagandeep Singh",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03000"" target=""_blank"">2410.03000</a>",,2025-12-03 22:39:25
SecAlign: Defending Against Prompt Injection with Preference Optimization,"Sizhe Chen, Arman Zharmagambetov, Saeed Mahloujifar, Kamalika Chaudhuri, David Wagner, Chuan Guo",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05451"" target=""_blank"">2410.05451</a>","<a href=""https://github.com/facebookresearch/SecAlign"" target=""_blank"">facebookresearch</a>",2025-12-03 22:39:25
TA3: Testing Against Adversarial Attacks on Machine Learning Models,"Yuanzhe Jin, Min Chen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05334"" target=""_blank"">2410.05334</a>",,2025-12-03 22:39:25
On the Adversarial Risk of Test Time Adaptation: An Investigation into Realistic Test-Time Data Poisoning,"Yongyi Su, Yushu Li, Nanqing Liu, Kui Jia, Xulei Yang, Chuan-Sheng Foo, Xun Xu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04682"" target=""_blank"">2410.04682</a>",,2025-12-03 22:39:25
Graded Suspiciousness of Adversarial Texts to Human,"Shakila Mahjabin Tonni, Pedro Faustini, Mark Dras",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04377"" target=""_blank"">2410.04377</a>",,2025-12-03 22:39:25
Towards World Simulator: Crafting Physical Commonsense-Based Benchmark for Video Generation,"Fanqing Meng, Jiaqi Liao, Xinyu Tan, Wenqi Shao, Quanfeng Lu, Kaipeng Zhang, Yu Cheng, Dianqi Li, Yu Qiao, Ping Luo",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05363"" target=""_blank"">2410.05363</a>","<a href=""https://github.com/OpenGVLab/PhyGenBench"" target=""_blank"">OpenGVLab</a>",2025-12-03 22:39:25
Collaboration! Towards Robust Neural Methods for Routing Problems,"Jianan Zhou, Yaoxin Wu, Zhiguang Cao, Wen Song, Jie Zhang, Zhiqi Shen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04968"" target=""_blank"">2410.04968</a>",,2025-12-03 22:39:25
Double Oracle Neural Architecture Search for Game Theoretic Deep Learning Models,"Aye Phyu Phyu Aung, Xinrun Wang, Ruiyu Wang, Hau Chan, Bo An, Xiaoli Li, J. Senthilnath",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04764"" target=""_blank"">2410.04764</a>",,2025-12-03 22:39:25
STOP! Camera Spoofing via the in-Vehicle IP Network,"Dror Peri, Avishai Wool",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05417"" target=""_blank"">2410.05417</a>",,2025-12-03 22:39:25
LLM Safeguard is a Double-Edged Sword: Exploiting False Positives for Denial-of-Service Attacks,"Qingzhao Zhang, Ziyang Xiong, Z. Morley Mao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02916"" target=""_blank"">2410.02916</a>",,2025-12-03 22:39:25
MIBench: A Comprehensive Framework for Benchmarking Model Inversion Attack and Defense,"Yixiang Qiu, Hongyao Yu, Hao Fang, Tianqu Zhuang, Wenbo Yu, Bin Chen, Xuan Wang, Shu-Tao Xia, Ke Xu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05159"" target=""_blank"">2410.05159</a>",,2025-12-03 22:39:25
Patch is Enough: Naturalistic Adversarial Patch against Vision-Language Pre-training Models,"Dehong Kong, Siyuan Liang, Xiaopeng Zhu, Yuansheng Zhong, Wenqi Ren",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04884"" target=""_blank"">2410.04884</a>",,2025-12-03 22:39:25
TaeBench: Improving Quality of Toxic Adversarial Examples,"Xuan Zhu, Dmitriy Bespalov, Liwen You, Ninad Kulkarni, Yanjun Qi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05573"" target=""_blank"">2410.05573</a>",,2025-12-03 22:39:25
AnyAttack: Towards Large-scale Self-supervised Adversarial Attacks on Vision-language Models,"Jiaming Zhang, Junhong Ye, Xingjun Ma, Yige Li, Yunfan Yang, Yunhao Chen, Jitao Sang, Dit-Yan Yeung",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05346"" target=""_blank"">2410.05346</a>",,2025-12-03 22:39:25
LOTOS: Layer-wise Orthogonalization for Training Robust Ensembles,"Ali Ebrahimpour-Boroojeny, Hari Sundaram, Varun Chandrasekaran",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.05136"" target=""_blank"">2410.05136</a>",,2025-12-03 22:39:25
"Recent advancements in LLM Red-Teaming: Techniques, Defenses, and Ethical Considerations","Tarun Raheja, Nilay Pochhi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09097"" target=""_blank"">2410.09097</a>",,2025-12-03 22:39:25
Robustness Reprogramming for Representation Learning,"Zhichao Hou, MohamadAli Torkamani, Hamid Krim, Xiaorui Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04577"" target=""_blank"">2410.04577</a>",,2025-12-03 22:39:25
Towards Understanding and Enhancing Security of Proof-of-Training for DNN Model Ownership Verification,"Yijia Chang, Hanrui Jiang, Chao Lin, Xinyi Huang, Jian Weng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04397"" target=""_blank"">2410.04397</a>",,2025-12-03 22:39:25
Federated Learning Nodes Can Reconstruct Peers' Image Data,"Ethan Wilson, Kai Yue, Chau-Wai Wong, Huaiyu Dai",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04661"" target=""_blank"">2410.04661</a>",,2025-12-03 22:39:25
Harnessing Task Overload for Scalable Jailbreak Attacks on Large Language Models,"Yiting Dong, Guobin Shen, Dongcheng Zhao, Xiang He, Yi Zeng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04190"" target=""_blank"">2410.04190</a>",,2025-12-03 22:39:25
ConDa: Fast Federated Unlearning with Contribution Dampening,"Vikram S Chundawat, Pushkar Niroula, Prasanna Dhungana, Stefan Schoepf, Murari Mandal, Alexandra Brintrup",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.04144"" target=""_blank"">2410.04144</a>",,2025-12-03 22:39:25
Mitigating Adversarial Perturbations for Deep Reinforcement Learning via Vector Quantization,"Tung M. Luu, Thanh Nguyen, Tee Joshua Tian Jin, Sungwoon Kim, Chang D. Yoo",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03376"" target=""_blank"">2410.03376</a>",,2025-12-03 22:39:25
RAFT: Realistic Attacks to Fool Text Detectors,"James Wang, Ran Li, Junfeng Yang, Chengzhi Mao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03658"" target=""_blank"">2410.03658</a>",,2025-12-03 22:39:25
A Brain-Inspired Regularizer for Adversarial Robustness,"Elie Attias, Cengiz Pehlevan, Dina Obeid",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03952"" target=""_blank"">2410.03952</a>",,2025-12-03 22:39:25
Gradient-based Jailbreak Images for Multimodal Fusion Models,"Javier Rando, Hannah Korevaar, Erik Brinkman, Ivan Evtimov, Florian Tramèr",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03489"" target=""_blank"">2410.03489</a>",,2025-12-03 22:39:25
You Know What I'm Saying -- Jailbreak Attack via Implicit Reference,"Tianyu Wu, Lingrui Mei, Ruibin Yuan, Lujun Li, Wei Xue, Yike Guo",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03857"" target=""_blank"">2410.03857</a>","<a href=""https://github.com/Lucas-TY/llm_Implicit_reference"" target=""_blank"">Lucas-TY</a>",2025-12-03 22:39:25
Impact of Regularization on Calibration and Robustness: from the Representation Space Perspective,"Jonghyun Park, Juyeop Kim, Jong-Seok Lee",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03999"" target=""_blank"">2410.03999</a>",,2025-12-03 22:39:25
Make Interval Bound Propagation great again,"Patryk Krukowski, Daniel Wilczak, Jacek Tabor, Anna Bielawska, Przemysław Spurek",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03373"" target=""_blank"">2410.03373</a>",,2025-12-03 22:39:25
Classification-Denoising Networks,"Louis Thiry, Florentin Guth",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03505"" target=""_blank"">2410.03505</a>",,2025-12-03 22:39:25
Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs,"Tomas Bueno Momcilovic, Dian Balta, Beat Buesser, Giulio Zizzo, Mark Purcell",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.09078"" target=""_blank"">2410.09078</a>",,2025-12-03 22:39:25
BN-SCAFFOLD: controlling the drift of Batch Normalization statistics in Federated Learning,"Gonzalo Iñaki Quintana, Laurence Vancamberg, Vincent Jugnon, Mathilde Mougeot, Agnès Desolneux",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03281"" target=""_blank"">2410.03281</a>",,2025-12-03 22:39:25
Chain-of-Jailbreak Attack for Image Generation Models via Editing Step by Step,"Wenxuan Wang, Kuiyi Gao, Zihan Jia, Youliang Yuan, Jen-tse Huang, Qiuzhi Liu, Shuai Wang, Wenxiang Jiao, Zhaopeng Tu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.03869"" target=""_blank"">2410.03869</a>",,2025-12-03 22:39:25
SCA: Highly Efficient Semantic-Consistent Unrestricted Adversarial Attack,"Zihao Pan, Weibin Wu, Yuhang Cao, Zibin Zheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.02240"" target=""_blank"">2410.02240</a>",,2025-12-03 22:39:25
AdvBDGen: Adversarially Fortified Prompt-Specific Fuzzy Backdoor Generator Against LLM Alignment,"Pankayaraj Pathmanathan, Udari Madhushani Sehwag, Michael-Andrei Panaitescu-Liess, Furong Huang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11283"" target=""_blank"">2410.11283</a>",,2025-12-03 22:39:25
Efficient and Effective Universal Adversarial Attack against Vision-Language Pre-training Models,"Fan Yang, Yihao Huang, Kailong Wang, Ling Shi, Geguang Pu, Yang Liu, Haoyu Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11639"" target=""_blank"">2410.11639</a>",,2025-12-03 22:39:25
Cognitive Overload Attack:Prompt Injection for Long Context,"Bibek Upadhayay, Vahid Behzadan, Amin Karbasi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11272"" target=""_blank"">2410.11272</a>",,2025-12-03 22:39:25
SCULPT: Systematic Tuning of Long Prompts,"Shanu Kumar, Akhila Yesantarao Venkata, Shubhanshu Khandelwal, Bishal Santra, Parag Agrawal, Manish Gupta",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20788"" target=""_blank"">2410.20788</a>",,2025-12-03 22:39:25
Generative Adversarial Patches for Physical Attacks on Cross-Modal Pedestrian Re-Identification,"Yue Su, Hao Li, Maoguo Gong",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20097"" target=""_blank"">2410.20097</a>",,2025-12-03 22:39:25
Transferable Adversarial Attacks on SAM and Its Downstream Models,"Song Xia, Wenhan Yang, Yi Yu, Xun Lin, Henghui Ding, Ling-Yu Duan, Xudong Jiang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20197"" target=""_blank"">2410.20197</a>","<a href=""https://github.com/xiasong0501/GRAT"" target=""_blank"">xiasong0501</a>",2025-12-03 22:39:25
Adversarial Attacks Against Double RIS-Assisted MIMO Systems-based Autoencoder in Finite-Scattering Environments,"Bui Duc Son, Ngo Nam Khanh, Chien Trinh Van, Dong In Kim",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20103"" target=""_blank"">2410.20103</a>",,2025-12-03 22:39:25
Fine-tuned Large Language Models (LLMs): Improved Prompt Injection Attacks Detection,"Md Abdur Rahman, Fan Wu, Alfredo Cuzzocrea, Sheikh Iqbal Ahamed",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21337"" target=""_blank"">2410.21337</a>",,2025-12-03 22:39:25
LLM Robustness Against Misinformation in Biomedical Question Answering,"Alexander Bondarenko, Adrian Viehweger",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21330"" target=""_blank"">2410.21330</a>",,2025-12-03 22:39:25
Integrating uncertainty quantification into randomized smoothing based robustness guarantees,"Sina Däubener, Kira Maag, David Krueger, Asja Fischer",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20432"" target=""_blank"">2410.20432</a>",,2025-12-03 22:39:25
Palisade -- Prompt Injection Detection Framework,"Sahasra Kokkula, Somanathan R, Nandavardhan R, Aashishkumar, G Divya",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21146"" target=""_blank"">2410.21146</a>",,2025-12-03 22:39:25
BlueSuffix: Reinforced Blue Teaming for Vision-Language Models Against Jailbreak Attacks,"Yunhan Zhao, Xiang Zheng, Lin Luo, Yige Li, Xingjun Ma, Yu-Gang Jiang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20971"" target=""_blank"">2410.20971</a>","<a href=""https://github.com/Vinsonzyh/BlueSuffix"" target=""_blank"">Vinsonzyh</a>",2025-12-03 22:39:25
Mitigating Paraphrase Attacks on Machine-Text Detectors via Paraphrase Inversion,"Rafael Rivera Soto, Barry Chen, Nicholas Andrews",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21637"" target=""_blank"">2410.21637</a>",,2025-12-03 22:39:25
Mitigating Unauthorized Speech Synthesis for Voice Protection,"Zhisheng Zhang, Qianyi Yang, Derui Wang, Pengyang Huang, Yuxin Cao, Kai Ye, Jie Hao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20742"" target=""_blank"">2410.20742</a>",,2025-12-03 22:39:25
Stealthy Jailbreak Attacks on Large Language Models via Benign Data Mirroring,"Honglin Mu, Han He, Yuxin Zhou, Yunlong Feng, Yang Xu, Libo Qin, Xiaoming Shi, Zeming Liu, Xudong Han, Qi Shi, Qingfu Zhu, Wanxiang Che",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21083"" target=""_blank"">2410.21083</a>",,2025-12-03 22:39:25
Hacking Back the AI-Hacker: Prompt Injection as a Defense Against LLM-driven Cyberattacks,"Dario Pasquini, Evgenios M. Kornaropoulos, Giuseppe Ateniese",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20911"" target=""_blank"">2410.20911</a>","<a href=""https://github.com/pasquini-dario/project_mantis"" target=""_blank"">pasquini-dario</a>",2025-12-03 22:39:25
Attacking Misinformation Detection Using Adversarial Examples Generated by Language Models,Piotr Przybyła,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20940"" target=""_blank"">2410.20940</a>",,2025-12-03 22:39:25
TACO: Adversarial Camouflage Optimization on Trucks to Fool Object Detectors,"Adonisz Dimitriu, Tamás Michaletzky, Viktor Remeli",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21443"" target=""_blank"">2410.21443</a>",,2025-12-03 22:39:25
CodePurify: Defend Backdoor Attacks on Neural Code Models via Entropy-based Purification,"Fangwen Mu, Junjie Wang, Zhuohao Yu, Lin Shi, Song Wang, Mingyang Li, Qing Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20136"" target=""_blank"">2410.20136</a>",,2025-12-03 22:39:25
Robust Model Evaluation over Large-scale Federated Networks,"Amir Najafi, Samin Mahdizadeh Sani, Farzan Farnia",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20250"" target=""_blank"">2410.20250</a>",,2025-12-03 22:39:25
GPT-4o System Card,"Tony OpenAI, Tony :, Aaron Tony Hurst, Adam Tony Lerer, Adam P. Tony Goucher, Adam Tony Perelman, Aditya Tony Ramesh, Aidan Tony Clark, AJ Tony Ostrow, Akila Tony Welihinda, Alan Tony Hayes, Alec Tony Radford, Aleksander Tony Mądry, Alex Tony Baker-Whitcomb, Alex Tony Beutel, Alex Tony Borzunov, Alex Tony Carney, Alex Tony Chow, Alex Tony Kirillov, Alex Tony Nichol, Alex Tony Paino, Alex Tony Renzin, Alex Tachard Tony Passos, Alexander Tony Kirillov, Alexi Tony Christakis, Alexis Tony Conneau, Ali Tony Kamali, Allan Tony Jabri, Allison Tony Moyer, Allison Tony Tam, Amadou Tony Crookes, Amin Tony Tootoochian, Amin Tony Tootoonchian, Ananya Tony Kumar, Andrea Tony Vallone, Andrej Tony Karpathy, Andrew Tony Braunstein, Andrew Tony Cann, Andrew Tony Codispoti, Andrew Tony Galu, Andrew Tony Kondrich, Andrew Tony Tulloch, Andrey Tony Mishchenko, Angela Tony Baek, Angela Tony Jiang, Antoine Tony Pelisse, Antonia Tony Woodford, Anuj Tony Gosalia, Arka Tony Dhar, Ashley Tony Pantuliano, Avi Tony Nayak, Avital Tony Oliver, Barret Tony Zoph, Behrooz Tony Ghorbani, Ben Tony Leimberger, Ben Tony Rossen, Ben Tony Sokolowsky, Ben Tony Wang, Benjamin Tony Zweig, Beth Tony Hoover, Blake Tony Samic, Bob Tony McGrew, Bobby Tony Spero, Bogo Tony Giertler, Bowen Tony Cheng, Brad Tony Lightcap, Brandon Tony Walkin, Brendan Tony Quinn, Brian Tony Guarraci, Brian Tony Hsu, Bright Tony Kellogg, Brydon Tony Eastman, Camillo Tony Lugaresi, Carroll Tony Wainwright, Cary Tony Bassin, Cary Tony Hudson, Casey Tony Chu, Chad Tony Nelson, Chak Tony Li, Chan Jun Tony Shern, Channing Tony Conger, Charlotte Tony Barette, Chelsea Tony Voss, Chen Tony Ding, Cheng Tony Lu, Chong Tony Zhang, Chris Tony Beaumont, Chris Tony Hallacy, Chris Tony Koch, Christian Tony Gibson, Christina Tony Kim, Christine Tony Choi, Christine Tony McLeavey, Christopher Tony Hesse, Claudia Tony Fischer, Clemens Tony Winter, Coley Tony Czarnecki, Colin Tony Jarvis, Colin Tony Wei, Constantin Tony Koumouzelis, Dane Tony Sherburn, Daniel Tony Kappler, Daniel Tony Levin, Daniel Tony Levy, David Tony Carr, David Tony Farhi, David Tony Mely, David Tony Robinson, David Tony Sasaki, Denny Tony Jin, Dev Tony Valladares, Dimitris Tony Tsipras, Doug Tony Li, Duc Phong Tony Nguyen, Duncan Tony Findlay, Edede Tony Oiwoh, Edmund Tony Wong, Ehsan Tony Asdar, Elizabeth Tony Proehl, Elizabeth Tony Yang, Eric Tony Antonow, Eric Tony Kramer, Eric Tony Peterson, Eric Tony Sigler, Eric Tony Wallace, Eugene Tony Brevdo, Evan Tony Mays, Farzad Tony Khorasani, Felipe Petroski Tony Such, Filippo Tony Raso, Francis Tony Zhang, Lohmann Fred Tony von, Freddie Tony Sulit, Gabriel Tony Goh, Gene Tony Oden, Geoff Tony Salmon, Giulio Tony Starace, Greg Tony Brockman, Hadi Tony Salman, Haiming Tony Bao, Haitang Tony Hu, Hannah Tony Wong, Haoyu Tony Wang, Heather Tony Schmidt, Heather Tony Whitney, Heewoo Tony Jun, Hendrik Tony Kirchner, Henrique Ponde de Oliveira Tony Pinto, Hongyu Tony Ren, Huiwen Tony Chang, Hyung Won Tony Chung, Ian Tony Kivlichan, Ian Tony O'Connell, Ian Tony O'Connell, Ian Tony Osband, Ian Tony Silber, Ian Tony Sohl, Ibrahim Tony Okuyucu, Ikai Tony Lan, Ilya Tony Kostrikov, Ilya Tony Sutskever, Ingmar Tony Kanitscheider, Ishaan Tony Gulrajani, Jacob Tony Coxon, Jacob Tony Menick, Jakub Tony Pachocki, James Tony Aung, James Tony Betker, James Tony Crooks, James Tony Lennon, Jamie Tony Kiros, Jan Tony Leike, Jane Tony Park, Jason Tony Kwon, Jason Tony Phang, Jason Tony Teplitz, Jason Tony Wei, Jason Tony Wolfe, Jay Tony Chen, Jeff Tony Harris, Jenia Tony Varavva, Jessica Gan Tony Lee, Jessica Tony Shieh, Ji Tony Lin, Jiahui Tony Yu, Jiayi Tony Weng, Jie Tony Tang, Jieqi Tony Yu, Joanne Tony Jang, Joaquin Quinonero Tony Candela, Joe Tony Beutler, Joe Tony Landers, Joel Tony Parish, Johannes Tony Heidecke, John Tony Schulman, Jonathan Tony Lachman, Jonathan Tony McKay, Jonathan Tony Uesato, Jonathan Tony Ward, Jong Wook Tony Kim, Joost Tony Huizinga, Jordan Tony Sitkin, Jos Tony Kraaijeveld, Josh Tony Gross, Josh Tony Kaplan, Josh Tony Snyder, Joshua Tony Achiam, Joy Tony Jiao, Joyce Tony Lee, Juntang Tony Zhuang, Justyn Tony Harriman, Kai Tony Fricke, Kai Tony Hayashi, Karan Tony Singhal, Katy Tony Shi, Kavin Tony Karthik, Kayla Tony Wood, Kendra Tony Rimbach, Kenny Tony Hsu, Kenny Tony Nguyen, Keren Tony Gu-Lemberg, Kevin Tony Button, Kevin Tony Liu, Kiel Tony Howe, Krithika Tony Muthukumar, Kyle Tony Luther, Lama Tony Ahmad, Larry Tony Kai, Lauren Tony Itow, Lauren Tony Workman, Leher Tony Pathak, Leo Tony Chen, Li Tony Jing, Lia Tony Guy, Liam Tony Fedus, Liang Tony Zhou, Lien Tony Mamitsuka, Lilian Tony Weng, Lindsay Tony McCallum, Lindsey Tony Held, Long Tony Ouyang, Louis Tony Feuvrier, Lu Tony Zhang, Lukas Tony Kondraciuk, Lukasz Tony Kaiser, Luke Tony Hewitt, Luke Tony Metz, Lyric Tony Doshi, Mada Tony Aflak, Maddie Tony Simens, Madelaine Tony Boyd, Madeleine Tony Thompson, Marat Tony Dukhan, Mark Tony Chen, Mark Tony Gray, Mark Tony Hudnall, Marvin Tony Zhang, Marwan Tony Aljubeh, Mateusz Tony Litwin, Matthew Tony Zeng, Max Tony Johnson, Maya Tony Shetty, Mayank Tony Gupta, Meghan Tony Shah, Mehmet Tony Yatbaz, Meng Jia Tony Yang, Mengchao Tony Zhong, Mia Tony Glaese, Mianna Tony Chen, Michael Tony Janner, Michael Tony Lampe, Michael Tony Petrov, Michael Tony Wu, Michele Tony Wang, Michelle Tony Fradin, Michelle Tony Pokrass, Miguel Tony Castro, Castro Miguel Oom Temudo Tony de, Mikhail Tony Pavlov, Miles Tony Brundage, Miles Tony Wang, Minal Tony Khan, Mira Tony Murati, Mo Tony Bavarian, Molly Tony Lin, Murat Tony Yesildal, Nacho Tony Soto, Natalia Tony Gimelshein, Natalie Tony Cone, Natalie Tony Staudacher, Natalie Tony Summers, Natan Tony LaFontaine, Neil Tony Chowdhury, Nick Tony Ryder, Nick Tony Stathas, Nick Tony Turley, Nik Tony Tezak, Niko Tony Felix, Nithanth Tony Kudige, Nitish Tony Keskar, Noah Tony Deutsch, Noel Tony Bundick, Nora Tony Puckett, Ofir Tony Nachum, Ola Tony Okelola, Oleg Tony Boiko, Oleg Tony Murk, Oliver Tony Jaffe, Olivia Tony Watkins, Olivier Tony Godement, Owen Tony Campbell-Moore, Patrick Tony Chao, Paul Tony McMillan, Pavel Tony Belov, Peng Tony Su, Peter Tony Bak, Peter Tony Bakkum, Peter Tony Deng, Peter Tony Dolan, Peter Tony Hoeschele, Peter Tony Welinder, Phil Tony Tillet, Philip Tony Pronin, Philippe Tony Tillet, Prafulla Tony Dhariwal, Qiming Tony Yuan, Rachel Tony Dias, Rachel Tony Lim, Rahul Tony Arora, Rajan Tony Troll, Randall Tony Lin, Rapha Gontijo Tony Lopes, Raul Tony Puri, Reah Tony Miyara, Reimar Tony Leike, Renaud Tony Gaubert, Reza Tony Zamani, Ricky Tony Wang, Rob Tony Donnelly, Rob Tony Honsby, Rocky Tony Smith, Rohan Tony Sahai, Rohit Tony Ramchandani, Romain Tony Huet, Rory Tony Carmichael, Rowan Tony Zellers, Roy Tony Chen, Ruby Tony Chen, Ruslan Tony Nigmatullin, Ryan Tony Cheu, Saachi Tony Jain, Sam Tony Altman, Sam Tony Schoenholz, Sam Tony Toizer, Samuel Tony Miserendino, Sandhini Tony Agarwal, Sara Tony Culver, Scott Tony Ethersmith, Scott Tony Gray, Sean Tony Grove, Sean Tony Metzger, Shamez Tony Hermani, Shantanu Tony Jain, Shengjia Tony Zhao, Sherwin Tony Wu, Shino Tony Jomoto, Shirong Tony Wu, Tony Shuaiqi, Xia, Sonia Phene, Spencer Papay, Srinivas Narayanan, Steve Coffey, Steve Lee, Stewart Hall, Suchir Balaji, Tal Broda, Tal Stramer, Tao Xu, Tarun Gogineni, Taya Christianson, Ted Sanders, Tejal Patwardhan, Thomas Cunninghman, Thomas Degry, Thomas Dimson, Thomas Raoux, Thomas Shadwell, Tianhao Zheng, Todd Underwood, Todor Markov, Toki Sherbakov, Tom Rubin, Tom Stasi, Tomer Kaftan, Tristan Heywood, Troy Peterson, Tyce Walters, Tyna Eloundou, Valerie Qi, Veit Moeller, Vinnie Monaco, Vishal Kuo, Vlad Fomenko, Wayne Chang, Weiyi Zheng, Wenda Zhou, Wesam Manassra, Will Sheu, Wojciech Zaremba, Yash Patil, Yilei Qian, Yongjik Kim, Youlong Cheng, Yu Zhang, Yuchen He, Yuchen Zhang, Yujia Jin, Yunxing Dai, Yury Malkov",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21276"" target=""_blank"">2410.21276</a>",,2025-12-03 22:39:25
RobustKV: Defending Large Language Models against Jailbreak Attacks via KV Eviction,"Tanqiu Jiang, Zian Wang, Jiacheng Liang, Changjiang Li, Yuhui Wang, Ting Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.19937"" target=""_blank"">2410.19937</a>",,2025-12-03 22:39:25
Attacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions,"Poojitha Thota, Shirin Nilizadeh",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20019"" target=""_blank"">2410.20019</a>",,2025-12-03 22:39:25
Expose Before You Defend: Unifying and Enhancing Backdoor Defenses via Exposed Models,"Yige Li, Hanxun Huang, Jiaming Zhang, Xingjun Ma, Yu-Gang Jiang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.19427"" target=""_blank"">2410.19427</a>","<a href=""https://github.com/bboylyg/Expose-Before-You-Defend"" target=""_blank"">bboylyg</a>",2025-12-03 22:39:25
Towards Robust Algorithms for Surgical Phase Recognition via Digital Twin-based Scene Representation,"Hao Ding, Yuqian Zhang, Hongchao Shu, Xu Lian, Ji Woong Kim, Axel Krieger, Mathias Unberath",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20026"" target=""_blank"">2410.20026</a>",,2025-12-03 22:39:25
GADT: Enhancing Transferable Adversarial Attacks through Gradient-guided Adversarial Data Transformation,"Yating Ma, Xiaogang Xu, Liming Fang, Zhe Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18648"" target=""_blank"">2410.18648</a>",,2025-12-03 22:39:25
Adversarial Attacks on Large Language Models Using Regularized Relaxation,"Samuel Jacob Chacko, Sajib Biswas, Chashi Mahiul Islam, Fatema Tabassum Liza, Xiuwen Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.19160"" target=""_blank"">2410.19160</a>",,2025-12-03 22:39:25
Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities,"Chung-En Sun, Xiaodong Liu, Weiwei Yang, Tsui-Wei Weng, Hao Cheng, Aidan San, Michel Galley, Jianfeng Gao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18469"" target=""_blank"">2410.18469</a>",,2025-12-03 22:39:25
Humanizing the Machine: Proxy Attacks to Mislead LLM Detectors,"Tianchun Wang, Yuanzhou Chen, Zichuan Liu, Zhanwen Chen, Haifeng Chen, Xiang Zhang, Wei Cheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.19230"" target=""_blank"">2410.19230</a>",,2025-12-03 22:39:25
Complexity Matters: Effective Dimensionality as a Measure for Adversarial Robustness,"David Khachaturov, Robert Mullins",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18556"" target=""_blank"">2410.18556</a>",,2025-12-03 22:39:25
Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances,"Shilin Lu, Zihan Zhou, Jiayou Lu, Yuanzhi Zhu, Adams Wai-Kin Kong",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18775"" target=""_blank"">2410.18775</a>","<a href=""https://github.com/Shilin-LU/VINE"" target=""_blank"">Shilin-LU</a>",2025-12-03 22:39:25
Advancing NLP Security by Leveraging LLMs as Adversarial Engines,"Sudarshan Srinivasan, Maria Mahbub, Amir Sadovnik",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18215"" target=""_blank"">2410.18215</a>",,2025-12-03 22:39:25
Backdoor in Seconds: Unlocking Vulnerabilities in Large Pre-trained Models via Model Editing,"Dongliang Guo, Mengxuan Hu, Zihan Guan, Junfeng Guo, Thomas Hartvigsen, Sheng Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18267"" target=""_blank"">2410.18267</a>",,2025-12-03 22:39:25
Breaking the Illusion: Real-world Challenges for Adversarial Patches in Object Detection,"Jakob Shack, Katarina Petrovic, Olga Saukh",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.19863"" target=""_blank"">2410.19863</a>",,2025-12-03 22:39:25
Slot: Provenance-Driven APT Detection through Graph Reinforcement Learning,"Wei Qiao, Yebo Feng, Teng Li, Zhuo Ma, Yulong Shen, JianFeng Ma, Yang Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17910"" target=""_blank"">2410.17910</a>",,2025-12-03 22:39:25
FATH: Authentication-based Test-time Defense against Indirect Prompt Injection Attacks,"Jiongxiao Wang, Fangzhou Wu, Wendi Li, Jinsheng Pan, Edward Suh, Z. Morley Mao, Muhao Chen, Chaowei Xiao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21492"" target=""_blank"">2410.21492</a>","<a href=""https://github.com/Jayfeather1024/FATH"" target=""_blank"">Jayfeather1024</a>",2025-12-03 22:39:25
AdvI2I: Adversarial Image Attack on Image-to-Image Diffusion models,"Yaopei Zeng, Yuanpu Cao, Bochuan Cao, Yurui Chang, Jinghui Chen, Lu Lin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21471"" target=""_blank"">2410.21471</a>",,2025-12-03 22:39:25
Securing Federated Learning against Backdoor Threats with Foundation Model Integration,"Xiaohuan Bi, Xi Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17573"" target=""_blank"">2410.17573</a>",,2025-12-03 22:39:25
Keep on Swimming: Real Attackers Only Need Partial Knowledge of a Multi-Model System,"Julian Collado, Kevin Stangl",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23483"" target=""_blank"">2410.23483</a>",,2025-12-03 22:39:25
Teaching a Language Model to Distinguish Between Similar Details using a Small Adversarial Training Set,Chris Achard,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23118"" target=""_blank"">2410.23118</a>",,2025-12-03 22:39:25
Understanding and Improving Adversarial Collaborative Filtering for Robust Recommendation,"Kaike Zhang, Qi Cao, Yunfan Wu, Fei Sun, Huawei Shen, Xueqi Cheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22844"" target=""_blank"">2410.22844</a>",,2025-12-03 22:39:25
HijackRAG: Hijacking Attacks against Retrieval-Augmented Large Language Models,"Yucheng Zhang, Qinfeng Li, Tianyu Du, Xuhong Zhang, Xinkui Zhao, Zhengwen Feng, Jianwei Yin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22832"" target=""_blank"">2410.22832</a>",,2025-12-03 22:39:25
Effective and Efficient Adversarial Detection for Vision-Language Models via A Single Vector,"Youcheng Huang, Fengbin Zhu, Jingkun Tang, Pan Zhou, Wenqiang Lei, Jiancheng Lv, Tat-Seng Chua",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22888"" target=""_blank"">2410.22888</a>","<a href=""https://github.com/mob-scu/RADAR-NEARSIDE"" target=""_blank"">mob-scu</a>",2025-12-03 22:39:25
One Prompt to Verify Your Models: Black-Box Text-to-Image Models Verification via Non-Transferable Adversarial Attacks,"Ji Guo, Wenbo Jiang, Rui Zhang, Guoming Lu, Hongwei Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22725"" target=""_blank"">2410.22725</a>",,2025-12-03 22:39:25
CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense,"Mingkun Zhang, Keping Bi, Wei Chen, Quanrun Chen, Jiafeng Guo, Xueqi Cheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23091"" target=""_blank"">2410.23091</a>","<a href=""https://github.com/CAS-AISafetyBasicResearchGroup/CausalDiff"" target=""_blank"">CAS-AISafetyBasicResearchGroup</a>",2025-12-03 22:39:25
FAIR-TAT: Improving Model Fairness Using Targeted Adversarial Training,"Tejaswini Medi, Steffen Jung, Margret Keuper",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23142"" target=""_blank"">2410.23142</a>",,2025-12-03 22:39:25
Evaluating the Robustness of LiDAR Point Cloud Tracking Against Adversarial Attack,"Shengjing Tian, Yinan Han, Xiantong Zhao, Bin Liu, Xiuping Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.20893"" target=""_blank"">2410.20893</a>",,2025-12-03 22:39:25
Adversarial Attacks of Vision Tasks in the Past 10 Years: A Survey,"Chiyu Zhang, Xiaogang Xu, Jiafei Wu, Zhe Liu, Lu Zhou",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23687"" target=""_blank"">2410.23687</a>",,2025-12-03 22:39:25
ARQ: A Mixed-Precision Quantization Framework for Accurate and Certifiably Robust DNNs,"Yuchen Yang, Shubham Ugare, Yifan Zhao, Gagandeep Singh, Sasa Misailovic",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.24214"" target=""_blank"">2410.24214</a>",,2025-12-03 22:39:25
Pseudo-Conversation Injection for LLM Goal Hijacking,"Zheng Chen, Buhui Yao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23678"" target=""_blank"">2410.23678</a>",,2025-12-03 22:39:25
DiffPAD: Denoising Diffusion-based Adversarial Patch Decontamination,"Jia Fu, Xiao Zhang, Sepideh Pashami, Fatemeh Rahimian, Anders Holst",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.24006"" target=""_blank"">2410.24006</a>","<a href=""https://github.com/JasonFu1998/DiffPAD"" target=""_blank"">JasonFu1998</a>",2025-12-03 22:39:25
Wide Two-Layer Networks can Learn from Adversarial Perturbations,"Soichiro Kumano, Hiroshi Kera, Toshihiko Yamasaki",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23677"" target=""_blank"">2410.23677</a>","<a href=""https://github.com/s-kumano/perturbation-learning"" target=""_blank"">s-kumano</a>",2025-12-03 22:39:25
Noise as a Double-Edged Sword: Reinforcement Learning Exploits Randomized Defenses in Neural Networks,"Steve Bakos, Pooria Madani, Heidar Davoudi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23870"" target=""_blank"">2410.23870</a>",,2025-12-03 22:39:25
Backdoor Attack Against Vision Transformers via Attention Gradient-Based Image Erosion,"Ji Guo, Hongwei Li, Wenbo Jiang, Guoming Lu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22678"" target=""_blank"">2410.22678</a>",,2025-12-03 22:39:25
Geometry Cloak: Preventing TGS-based 3D Reconstruction from Copyrighted Images,"Qi Song, Ziyuan Luo, Ka Chun Cheung, Simon See, Renjie Wan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22705"" target=""_blank"">2410.22705</a>","<a href=""https://qsong2001.github.io/geometry_cloak"" target=""_blank"">qsong2001.github.io</a>",2025-12-03 22:39:25
On Memorization of Large Language Models in Logical Reasoning,"Chulin Xie, Yangsibo Huang, Chiyuan Zhang, Da Yu, Xinyun Chen, Bill Yuchen Lin, Bo Li, Badih Ghazi, Ravi Kumar",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23123"" target=""_blank"">2410.23123</a>","<a href=""https://memkklogic.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Byzantine-Robust Federated Learning: An Overview With Focus on Developing Sybil-based Attacks to Backdoor Augmented Secure Aggregation Protocols,Atharv Deshmukh,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22680"" target=""_blank"">2410.22680</a>",,2025-12-03 22:39:25
ProTransformer: Robustify Transformers via Plug-and-Play Paradigm,"Zhichao Hou, Weizhi Gao, Yuchen Shen, Feiyi Wang, Xiaorui Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23182"" target=""_blank"">2410.23182</a>",,2025-12-03 22:39:25
Attribute-to-Delete: Machine Unlearning via Datamodel Matching,"Kristian Georgiev, Roy Rinberg, Sung Min Park, Shivam Garg, Andrew Ilyas, Aleksander Madry, Seth Neel",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.23232"" target=""_blank"">2410.23232</a>",,2025-12-03 22:39:25
Stealing User Prompts from Mixture of Experts,"Itay Yona, Ilia Shumailov, Jamie Hayes, Nicholas Carlini",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22884"" target=""_blank"">2410.22884</a>",,2025-12-03 22:39:25
BeniFul: Backdoor Defense via Middle Feature Analysis for Deep Neural Networks,"Xinfu Li, Junying Zhang, Xindi Ma",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14723"" target=""_blank"">2410.14723</a>",,2025-12-03 22:39:25
On the Robustness of Adversarial Training Against Uncertainty Attacks,"Emanuele Ledda, Giovanni Scodeller, Daniele Angioni, Giorgio Piras, Antonio Emanuele Cinà, Giorgio Fumera, Battista Biggio, Fabio Roli",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21952"" target=""_blank"">2410.21952</a>",,2025-12-03 22:39:25
Text-Guided Attention is All You Need for Zero-Shot Robustness in Vision-Language Models,"Lu Yu, Haiyang Zhang, Changsheng Xu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21802"" target=""_blank"">2410.21802</a>","<a href=""https://github.com/zhyblue424/TGA-ZSR"" target=""_blank"">zhyblue424</a>",2025-12-03 22:39:25
Automated Trustworthiness Oracle Generation for Machine Learning Text Classifiers,"Lam Nguyen Tung, Steven Cho, Xiaoning Du, Neelofar Neelofar, Valerio Terragni, Stefano Ruberto, Aldeida Aleti",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22663"" target=""_blank"">2410.22663</a>",,2025-12-03 22:39:25
AmpleGCG-Plus: A Strong Generative Model of Adversarial Suffixes to Jailbreak LLMs with Higher Success Rates in Fewer Attempts,"Vishal Kumar, Zeyi Liao, Jaylen Jones, Huan Sun",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22143"" target=""_blank"">2410.22143</a>",,2025-12-03 22:39:25
Embedding-based classifiers can detect prompt injection attacks,"Md. Ahsan Ayub, Subhabrata Majumdar",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22284"" target=""_blank"">2410.22284</a>",,2025-12-03 22:39:25
Enhancing Adversarial Attacks through Chain of Thought,Jingbo Su,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21791"" target=""_blank"">2410.21791</a>","<a href=""https://github.com/sujingbo0217/CS222W24-LLM-Attack"" target=""_blank"">sujingbo0217</a>",2025-12-03 22:39:25
Power side-channel leakage localization through adversarial training of deep neural networks,"Jimmy Gammell, Anand Raghunathan, Kaushik Roy",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22425"" target=""_blank"">2410.22425</a>",,2025-12-03 22:39:25
Enhancing Safety and Robustness of Vision-Based Controllers via Reachability Analysis,"Kaustav Chakraborty, Aryaman Gupta, Somil Bansal",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.21736"" target=""_blank"">2410.21736</a>",,2025-12-03 22:39:25
SVIP: Towards Verifiable Inference of Open-source Large Language Models,"Yifan Sun, Yuhang Li, Yue Zhang, Yuchen Jin, Huan Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22307"" target=""_blank"">2410.22307</a>",,2025-12-03 22:39:25
Guide for Defense (G4D): Dynamic Guidance for Robust and Balanced Defense in Large Language Models,"He Cao, Weidi Luo, Yu Wang, Zijing Liu, Bing Feng, Yuan Yao, Yu Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17922"" target=""_blank"">2410.17922</a>",,2025-12-03 22:39:25
InjecGuard: Benchmarking and Mitigating Over-defense in Prompt Injection Guardrail Models,"Hao Li, Xiaogeng Liu, Chaowei Xiao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.22770"" target=""_blank"">2410.22770</a>","<a href=""https://github.com/SaFoLab-WISC/InjecGuard"" target=""_blank"">SaFoLab-WISC</a>",2025-12-03 22:39:25
Towards Understanding the Fragility of Multilingual LLMs against Fine-Tuning Attacks,"Samuele Poppi, Zheng-Xin Yong, Yifei He, Bobbie Chern, Han Zhao, Aobo Yang, Jianfeng Chi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18210"" target=""_blank"">2410.18210</a>",,2025-12-03 22:39:25
SPIN: Self-Supervised Prompt INjection,"Leon Zhou, Junfeng Yang, Chengzhi Mao",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13236"" target=""_blank"">2410.13236</a>",,2025-12-03 22:39:25
DAT: Improving Adversarial Robustness via Generative Amplitude Mix-up in Frequency Domain,"Fengpeng Li, Kemou Li, Haiwei Wu, Jinyu Tian, Jiantao Zhou",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12307"" target=""_blank"">2410.12307</a>",,2025-12-03 22:39:25
"Golyadkin's Torment: Doppelg\""angers and Adversarial Vulnerability",George I. Kamberov,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13193"" target=""_blank"">2410.13193</a>",,2025-12-03 22:39:25
Do LLMs Have Political Correctness? Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems,"Isack Lee, Haebin Seong",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13334"" target=""_blank"">2410.13334</a>",,2025-12-03 22:39:25
Trojan Prompt Attacks on Graph Neural Networks,"Minhua Lin, Zhiwei Zhang, Enyan Dai, Zongyu Wu, Yilong Wang, Xiang Zhang, Suhang Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13974"" target=""_blank"">2410.13974</a>",,2025-12-03 22:39:25
Persistent Pre-Training Poisoning of LLMs,"Yiming Zhang, Javier Rando, Ivan Evtimov, Jianfeng Chi, Eric Michael Smith, Nicholas Carlini, Florian Tramèr, Daphne Ippolito",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13722"" target=""_blank"">2410.13722</a>",,2025-12-03 22:39:25
Jailbreaking LLM-Controlled Robots,"Alexander Robey, Zachary Ravichandran, Vijay Kumar, Hamed Hassani, George J. Pappas",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13691"" target=""_blank"">2410.13691</a>",,2025-12-03 22:39:25
Adversarial Inception for Bounded Backdoor Poisoning in Deep Reinforcement Learning,"Ethan Rathbun, Christopher Amato, Alina Oprea",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13995"" target=""_blank"">2410.13995</a>",,2025-12-03 22:39:25
Attack as Defense: Run-time Backdoor Implantation for Image Content Protection,"Haichuan Zhang, Meiyu Lin, Zhaoyi Liu, Renyuan Li, Zhiyuan Cheng, Carl Yang, Mingjie Tang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14966"" target=""_blank"">2410.14966</a>",,2025-12-03 22:39:25
DMGNN: Detecting and Mitigating Backdoor Attacks in Graph Neural Networks,"Hao Sui, Bing Chen, Jiale Zhang, Chengcheng Zhu, Di Wu, Qinghua Lu, Guodong Long",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14105"" target=""_blank"">2410.14105</a>",,2025-12-03 22:39:25
MMAD-Purify: A Precision-Optimized Framework for Efficient and Scalable Multi-Modal Attacks,"Xinxin Liu, Zhongliang Guo, Siyuan Huang, Chun Pong Lau",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14089"" target=""_blank"">2410.14089</a>",,2025-12-03 22:39:25
Adversarial Score identity Distillation: Rapidly Surpassing the Teacher in One Step,"Mingyuan Zhou, Huangjie Zheng, Yi Gu, Zhendong Wang, Hai Huang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14919"" target=""_blank"">2410.14919</a>",,2025-12-03 22:39:25
Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation,"Shuai Zhao, Xiaobao Wu, Cong-Duy Nguyen, Meihuizi Jia, Yichao Feng, Luu Anh Tuan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14425"" target=""_blank"">2410.14425</a>",,2025-12-03 22:39:25
Real-time Fake News from Adversarial Feedback,"Sanxing Chen, Yukun Huang, Bhuwan Dhingra",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14651"" target=""_blank"">2410.14651</a>",,2025-12-03 22:39:25
Feint and Attack: Attention-Based Strategies for Jailbreaking and Protecting LLMs,"Rui Pu, Chaozhuo Li, Rui Ha, Zejian Chen, Litian Zhang, Zheng Liu, Lirong Qiu, Xi Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16327"" target=""_blank"">2410.16327</a>",,2025-12-03 22:39:25
Boosting Imperceptibility of Stable Diffusion-based Adversarial Examples Generation with Momentum,"Nashrah Haque, Xiang Li, Zhehui Chen, Yanzhao Wu, Lei Yu, Arun Iyengar, Wenqi Wei",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13122"" target=""_blank"">2410.13122</a>",,2025-12-03 22:39:25
New Paradigm of Adversarial Training: Breaking Inherent Trade-Off between Accuracy and Robustness via Dummy Classes,"Yanyun Wang, Li Liu, Zi Liang, Qingqing Ye, Haibo Hu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12671"" target=""_blank"">2410.12671</a>",,2025-12-03 22:39:25
Perseus: Leveraging Common Data Patterns with Curriculum Learning for More Robust Graph Neural Networks,"Kaiwen Xia, Huijun Wu, Duanyu Li, Min Xie, Ruibo Wang, Wenzhe Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12425"" target=""_blank"">2410.12425</a>",,2025-12-03 22:39:25
Low-Rank Adversarial PGD Attack,"Dayana Savostianova, Emanuele Zangrando, Francesco Tudisco",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12607"" target=""_blank"">2410.12607</a>",,2025-12-03 22:39:25
Data Defenses Against Large Language Models,"William Agnew, Harry H. Jiang, Cella Sum, Maarten Sap, Sauvik Das",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13138"" target=""_blank"">2410.13138</a>","<a href=""https://github.com/wagnew3/LLMDataDefenses"" target=""_blank"">wagnew3</a>",2025-12-03 22:39:25
Hiding-in-Plain-Sight (HiPS) Attack on CLIP for Targetted Object Removal from Images,"Arka Daw, Megan Hong-Thanh Chung, Maria Mahbub, Amir Sadovnik",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13010"" target=""_blank"">2410.13010</a>",,2025-12-03 22:39:25
NSmark: Null Space Based Black-box Watermarking Defense Framework for Pre-trained Language Models,"Haodong Zhao, Jinming Hu, Peixuan Li, Fangqi Li, Jinrui Sha, Peixuan Chen, Zhuosheng Zhang, Gongshen Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13907"" target=""_blank"">2410.13907</a>","<a href=""https://github.com/dongdongzhaoUP/NSmark"" target=""_blank"">dongdongzhaoUP</a>",2025-12-03 22:39:25
Mitigating the Backdoor Effect for Multi-Task Model Merging via Safety-Aware Subspace,"Jinluan Yang, Anke Tang, Didi Zhu, Zhengyu Chen, Li Shen, Fei Wu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13910"" target=""_blank"">2410.13910</a>",,2025-12-03 22:39:25
Reconstruction of Differentially Private Text Sanitization via Large Language Models,"Shuchao Pang, Zhigang Lu, Haichen Wang, Peng Fu, Yongbin Zhou, Minhui Xue, Bo Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12443"" target=""_blank"">2410.12443</a>",,2025-12-03 22:39:25
Unitary Multi-Margin BERT for Robust Natural Language Processing,"Hao-Yuan Chang, Kang L. Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12759"" target=""_blank"">2410.12759</a>",,2025-12-03 22:39:25
FedGTST: Boosting Global Transferability of Federated Models via Statistics Tuning,"Evelyn Ma, Chao Pan, Rasoul Etesami, Han Zhao, Olgica Milenkovic",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13045"" target=""_blank"">2410.13045</a>",,2025-12-03 22:39:25
Consistency Calibration: Improving Uncertainty Calibration via Consistency among Perturbed Neighbors,"Linwei Tao, Haolan Guo, Minjing Dong, Chang Xu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12295"" target=""_blank"">2410.12295</a>",,2025-12-03 22:39:25
Efficient Optimization Algorithms for Linear Adversarial Training,"Antônio H. RIbeiro, Thomas B. Schön, Dave Zahariah, Francis Bach",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12677"" target=""_blank"">2410.12677</a>",,2025-12-03 22:39:25
PromptExp: Multi-granularity Prompt Explanation of Large Language Models,"Ximing Dong, Shaowei Wang, Dayi Lin, Gopi Krishnan Rajbahadur, Boquan Zhou, Shichao Liu, Ahmed E. Hassan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.13073"" target=""_blank"">2410.13073</a>",,2025-12-03 22:39:25
Long-Tailed Backdoor Attack Using Dynamic Data Augmentation Operations,"Lu Pang, Tao Sun, Weimin Lyu, Haibin Ling, Chao Chen",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12955"" target=""_blank"">2410.12955</a>",,2025-12-03 22:39:25
Countering Autonomous Cyber Threats,"Kade M. Heckel, Adrian Weller",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.18312"" target=""_blank"">2410.18312</a>",,2025-12-03 22:39:25
Deciphering the Chaos: Enhancing Jailbreak Attacks via Adversarial Prompt Translation,"Qizhang Li, Xiaochen Yang, Wangmeng Zuo, Yiwen Guo",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.11317"" target=""_blank"">2410.11317</a>","<a href=""https://github.com/qizhangli/Adversarial-Prompt-Translator"" target=""_blank"">qizhangli</a>",2025-12-03 22:39:25
Stochastic Gradient Descent Jittering for Inverse Problems: Alleviating the Accuracy-Robustness Tradeoff,"Peimeng Guan, Mark A. Davenport",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14667"" target=""_blank"">2410.14667</a>",,2025-12-03 22:39:25
Taking off the Rose-Tinted Glasses: A Critical Look at Adversarial ML Through the Lens of Evasion Attacks,"Kevin Eykholt, Farhan Ahmed, Pratik Vaishnavi, Amir Rahmati",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.12076"" target=""_blank"">2410.12076</a>",,2025-12-03 22:39:25
Class-RAG: Content Moderation with Retrieval Augmented Generation,"Jianfa Chen, Emily Shen, Trupti Bavalatti, Xiaowen Lin, Yongkai Wang, Shuming Hu, Harihar Subramanyam, Ksheeraj Sai Vepuri, Ming Jiang, Ji Qi, Li Chen, Nan Jiang, Ankit Jain",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14881"" target=""_blank"">2410.14881</a>",,2025-12-03 22:39:25
Evaluating the Effectiveness of Attack-Agnostic Features for Morphing Attack Detection,"Laurent Colbois, Sébastien Marcel",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16802"" target=""_blank"">2410.16802</a>",,2025-12-03 22:39:25
Robust Feature Learning for Multi-Index Models in High Dimensions,"Alireza Mousavi-Hosseini, Adel Javanmard, Murat A. Erdogdu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16449"" target=""_blank"">2410.16449</a>",,2025-12-03 22:39:25
Conflict-Aware Adversarial Training,"Zhiyu Xue, Haohan Wang, Yao Qin, Ramtin Pedarsani",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16579"" target=""_blank"">2410.16579</a>",,2025-12-03 22:39:25
Model Mimic Attack: Knowledge Distillation for Provably Transferable Adversarial Examples,"Kirill Lukyanov, Andrew Perminov, Denis Turdakov, Mikhail Pautov",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15889"" target=""_blank"">2410.15889</a>",,2025-12-03 22:39:25
A Hybrid Simulation of DNN-based Gray Box Models,"Aayushya Agarwal, Yihan Ruan, Larry Pileggi",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17103"" target=""_blank"">2410.17103</a>",,2025-12-03 22:39:25
Invisible Manipulation Deep Reinforcement Learning Enhanced Stealthy Attacks on Battery Energy Management Systems,"Qi Xiao, Lidong Song, Jongha Woo, Rongxing Hu, Bei Xu, Ning Lu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17402"" target=""_blank"">2410.17402</a>",,2025-12-03 22:39:25
BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers,"Jiaqi Xue, Qian Lou, Mengxin Zheng",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17492"" target=""_blank"">2410.17492</a>",,2025-12-03 22:39:25
On the Vulnerability of Text Sanitization,"Meng Tong, Kejiang Chen, Xiaojian Yuang, Jiayang Liu, Weiming Zhang, Nenghai Yu, Jie Zhang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17052"" target=""_blank"">2410.17052</a>","<a href=""https://github.com/mengtong0110/On-the-Vulnerability-of-Text-Sanitization"" target=""_blank"">mengtong0110</a>",2025-12-03 22:39:25
Metric as Transform: Exploring beyond Affine Transform for Interpretable Neural Network,Suman Sapkota,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16159"" target=""_blank"">2410.16159</a>",,2025-12-03 22:39:25
Meta Stackelberg Game: Robust Federated Learning against Adaptive and Mixed Poisoning Attacks,"Tao Li, Henger Li, Yunian Pan, Tianyi Xu, Zizhan Zheng, Quanyan Zhu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17431"" target=""_blank"">2410.17431</a>",,2025-12-03 22:39:25
AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents,"Chejian Xu, Mintong Kang, Jiawei Zhang, Zeyi Liao, Lingbo Mo, Mengqi Yuan, Huan Sun, Bo Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17401"" target=""_blank"">2410.17401</a>","<a href=""https://ai-secure.github.io/AdvWeb/"" target=""_blank"">AdvWeb</a>",2025-12-03 22:39:25
Test-time Adversarial Defense with Opposite Adversarial Path and High Attack Time Cost,"Cheng-Han Yeh, Kuanchun Yu, Chun-Shien Lu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16805"" target=""_blank"">2410.16805</a>",,2025-12-03 22:39:25
Is Smoothness the Key to Robustness? A Comparison of Attention and Convolution Models Using a Novel Metric,Baiyuan Chen,arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17628"" target=""_blank"">2410.17628</a>",,2025-12-03 22:39:25
A Hybrid Defense Strategy for Boosting Adversarial Robustness in Vision-Language Models,"Yuhan Liang, Yijun Li, Yumeng Niu, Qianhe Shen, Hangyu Liu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.14911"" target=""_blank"">2410.14911</a>",,2025-12-03 22:39:25
Detecting Adversarial Examples,"Furkan Mumcu, Yasin Yilmaz",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17442"" target=""_blank"">2410.17442</a>",,2025-12-03 22:39:25
Dual-Model Defense: Safeguarding Diffusion Models from Membership Inference Attacks through Disjoint Data Splitting,"Bao Q. Tran, Viet Nguyen, Anh Tran, Toan Tran",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16657"" target=""_blank"">2410.16657</a>",,2025-12-03 22:39:25
Context-aware Prompt Tuning: Advancing In-Context Learning with Adversarial Methods,"Tsachi Blau, Moshe Kimhi, Yonatan Belinkov, Alexander Bronstein, Chaim Baskin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.17222"" target=""_blank"">2410.17222</a>",,2025-12-03 22:39:25
A Realistic Threat Model for Large Language Model Jailbreaks,"Valentyn Boreiko, Alexander Panfilov, Vaclav Voracek, Matthias Hein, Jonas Geiping",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16222"" target=""_blank"">2410.16222</a>",,2025-12-03 22:39:25
SLIC: Secure Learned Image Codec through Compressed Domain Watermarking to Defend Image Manipulation,"Chen-Hsiu Huang, Ja-Ling Wu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15075"" target=""_blank"">2410.15075</a>",,2025-12-03 22:39:25
Vulnerabilities in Machine Learning-Based Voice Disorder Detection Systems,"Gianpaolo Perelli, Andrea Panzino, Roberto Casula, Marco Micheletto, Giulia Orrù, Gian Luca Marcialis",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16341"" target=""_blank"">2410.16341</a>",,2025-12-03 22:39:25
Toward Robust RALMs: Revealing the Impact of Imperfect Retrieval on Retrieval-Augmented Language Models,"Seong-Il Park, Jay-Yoon Lee",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15107"" target=""_blank"">2410.15107</a>",,2025-12-03 22:39:25
DynaMO: Protecting Mobile DL Models through Coupling Obfuscated DL Operators,"Mingyi Zhou, Xiang Gao, Xiao Chen, Chunyang Chen, John Grundy, Li Li",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15033"" target=""_blank"">2410.15033</a>",,2025-12-03 22:39:25
Adversarial Training: A Survey,"Mengnan Zhao, Lihe Zhang, Jingwen Ye, Huchuan Lu, Baocai Yin, Xinchao Wang",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15042"" target=""_blank"">2410.15042</a>",,2025-12-03 22:39:25
Jailbreaking and Mitigation of Vulnerabilities in Large Language Models,"Benji Peng, Ziqian Bi, Qian Niu, Ming Liu, Pohsun Feng, Tianyang Wang, Lawrence K. Q. Yan, Yizhu Wen, Yichao Zhang, Caitlyn Heqi Yin",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15236"" target=""_blank"">2410.15236</a>",,2025-12-03 22:39:25
Bayesian Concept Bottleneck Models with LLM Priors,"Jean Feng, Avni Kothari, Luke Zier, Chandan Singh, Yan Shuo Tan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15555"" target=""_blank"">2410.15555</a>",,2025-12-03 22:39:25
Faster-GCG: Efficient Discrete Optimization Jailbreak Attacks against Aligned Large Language Models,"Xiao Li, Zhuhong Li, Qiongxiu Li, Bingze Lee, Jinghao Cui, Xiaolin Hu",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15362"" target=""_blank"">2410.15362</a>",,2025-12-03 22:39:25
The Best Defense is a Good Offense: Countering LLM-Powered Cyberattacks,"Daniel Ayzenshteyn, Roy Weiss, Yisroel Mirsky",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15396"" target=""_blank"">2410.15396</a>",,2025-12-03 22:39:25
Efficient Model Extraction via Boundary Sampling,"Maor Biton Dor, Yisroel Mirsky",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15429"" target=""_blank"">2410.15429</a>",,2025-12-03 22:39:25
Extracting Spatiotemporal Data from Gradients with Large Language Models,"Lele Zheng, Yang Cao, Renhe Jiang, Kenjiro Taura, Yulong Shen, Sheng Li, Masatoshi Yoshikawa",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16121"" target=""_blank"">2410.16121</a>",,2025-12-03 22:39:25
Boosting Jailbreak Transferability for Large Language Models,"Hanqing Liu, Lifeng Zhou, Huanqian Yan",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15645"" target=""_blank"">2410.15645</a>",,2025-12-03 22:39:25
On the Geometry of Regularization in Adversarial Training: High-Dimensional Asymptotics and Generalization Bounds,"Matteo Vilucchio, Nikolaos Tsilivis, Bruno Loureiro, Julia Kempe",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.16073"" target=""_blank"">2410.16073</a>",,2025-12-03 22:39:25
Beyond Pruning Criteria: The Dominant Role of Fine-Tuning and Adaptive Ratios in Neural Network Robustness,"Lincen Bai, Hedi Tabia, Raúl Santos-Rodríguez",arXiv,2024-10,"<a href=""http://arxiv.org/abs/2410.15176"" target=""_blank"">2410.15176</a>",,2025-12-03 22:39:25
Unrevealed Threats: A Comprehensive Study of the Adversarial Robustness of Underwater Image Enhancement Models,"Siyu Zhai, Zhibo He, Xiaofeng Cong, Junming Hou, Jie Gui, Jian Wei You, Xin Gong, James Tin-Yau Kwok, Yuan Yan Tang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.06420"" target=""_blank"">2409.06420</a>",,2025-12-03 22:39:25
Advancing Hybrid Defense for Byzantine Attacks in Federated Learning,"Kai Yue, Richeng Jin, Chau-Wai Wong, Huaiyu Dai",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.06474"" target=""_blank"">2409.06474</a>",,2025-12-03 22:39:25
Enhancing adversarial robustness in Natural Language Inference using explanations,"Alexandros Koulakos, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07423"" target=""_blank"">2409.07423</a>",,2025-12-03 22:39:25
Understanding Knowledge Drift in LLMs through Misinformation,"Alina Fastowski, Gjergji Kasneci",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07085"" target=""_blank"">2409.07085</a>","<a href=""https://github.com/afastowski/knowledge_drift"" target=""_blank"">afastowski</a>",2025-12-03 22:39:25
AdvLogo: Adversarial Patch Attack against Object Detectors based on Diffusion Models,"Boming Miao, Chunxiao Li, Yao Zhu, Weixiang Sun, Zizhe Wang, Xiaoyi Wang, Chuanlong Xie",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07002"" target=""_blank"">2409.07002</a>",,2025-12-03 22:39:25
DV-FSR: A Dual-View Target Attack Framework for Federated Sequential Recommendation,"Qitao Qin, Yucong Luo, Mingyue Cheng, Qingyang Mao, Chenyi Lei",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07500"" target=""_blank"">2409.07500</a>",,2025-12-03 22:39:25
On the Vulnerability of Applying Retrieval-Augmented Generation within Knowledge-Intensive Application Domains,"Xun Xian, Ganghua Wang, Xuan Bi, Jayanth Srinivasa, Ashish Kundu, Charles Fleming, Mingyi Hong, Jie Ding",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17275"" target=""_blank"">2409.17275</a>",,2025-12-03 22:39:25
Attack End-to-End Autonomous Driving through Module-Wise Noise,"Lu Wang, Tianyuan Zhang, Yikai Han, Muyang Fang, Ting Jin, Jiaqi Kang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07706"" target=""_blank"">2409.07706</a>",,2025-12-03 22:39:25
Adversarial Attacks to Multi-Modal Models,"Zhihao Dou, Xin Hu, Haibo Yang, Zhuqing Liu, Minghong Fang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.06793"" target=""_blank"">2409.06793</a>",,2025-12-03 22:39:25
Re-evaluating the Advancements of Heterophilic Graph Learning,"Sitao Luan, Qincheng Lu, Chenqing Hua, Xinyu Wang, Jiaqi Zhu, Xiao-Wen Chang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.05755"" target=""_blank"">2409.05755</a>",,2025-12-03 22:39:25
Seeing Through the Mask: Rethinking Adversarial Examples for CAPTCHAs,"Yahya Jabary, Andreas Plesner, Turlan Kuzhagaliyev, Roger Wattenhofer",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.05558"" target=""_blank"">2409.05558</a>",,2025-12-03 22:39:25
Adversarial Attacks on Data Attribution,"Xinhe Wang, Pingbang Hu, Junwei Deng, Jiaqi W. Ma",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.05657"" target=""_blank"">2409.05657</a>",,2025-12-03 22:39:25
Unlearning or Concealment? A Critical Analysis and Evaluation Metrics for Unlearning in Diffusion Models,"Aakash Sen Sharma, Niladri Sarkar, Vikram Chundawat, Ankur A Mali, Murari Mandal",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.05668"" target=""_blank"">2409.05668</a>","<a href=""https://respailab.github.io/unlearning-or-concealment"" target=""_blank"">respailab.github.io</a>",2025-12-03 22:39:25
Input Space Mode Connectivity in Deep Neural Networks,"Jakub Vrabel, Ori Shem-Ur, Yaron Oz, David Krueger",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.05800"" target=""_blank"">2409.05800</a>",,2025-12-03 22:39:25
On the Weaknesses of Backdoor-based Model Watermarking: An Information-theoretic Perspective,"Aoting Hu, Yanzhi Chen, Renjie Xie, Adrian Weller",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.06130"" target=""_blank"">2409.06130</a>",,2025-12-03 22:39:25
PIP: Detecting Adversarial Examples in Large Vision-Language Models via Attention Patterns of Irrelevant Probe Questions,"Yudong Zhang, Ruobing Xie, Jiansheng Chen, Xingwu Sun, Yu Wang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.05076"" target=""_blank"">2409.05076</a>","<a href=""https://github.com/btzyd/pip"" target=""_blank"">btzyd</a>",2025-12-03 22:39:25
2DSig-Detect: a semi-supervised framework for anomaly detection on image data using 2D-signatures,"Xinheng Xie, Kureha Yamaguchi, Margaux Leblanc, Simon Malzard, Varun Chhabra, Victoria Nockles, Yue Wu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04982"" target=""_blank"">2409.04982</a>",,2025-12-03 22:39:25
Vision-fused Attack: Advancing Aggressive and Stealthy Adversarial Text against Neural Machine Translation,"Yanni Xue, Haojie Hao, Jiakai Wang, Qiang Sheng, Renshuai Tao, Yu Liang, Pu Feng, Xianglong Liu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.05021"" target=""_blank"">2409.05021</a>",,2025-12-03 22:39:25
Natias: Neuron Attribution based Transferable Image Adversarial Steganography,"Zexin Fan, Kejiang Chen, Kai Zeng, Jiansong Zhang, Weiming Zhang, Nenghai Yu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04968"" target=""_blank"">2409.04968</a>",,2025-12-03 22:39:25
Phrase-Level Adversarial Training for Mitigating Bias in Neural Network-based Automatic Essay Scoring,"Haddad Philip, Tsegaye Misikir Tashu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04795"" target=""_blank"">2409.04795</a>",,2025-12-03 22:39:25
D-CAPTCHA++: A Study of Resilience of Deepfake CAPTCHA under Transferable Imperceptible Adversarial Attack,"Hong-Hanh Nguyen-Le, Van-Tuan Tran, Dinh-Thuc Nguyen, Nhien-An Le-Khac",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07390"" target=""_blank"">2409.07390</a>",,2025-12-03 22:39:25
A Cost-Aware Approach to Adversarial Robustness in Neural Networks,"Charles Meyers, Mohammad Reza Saleh Sedghpour, Tommy Löfstedt, Erik Elmroth",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07609"" target=""_blank"">2409.07609</a>",,2025-12-03 22:39:25
XSub: Explanation-Driven Adversarial Attack against Blackbox Classifiers via Feature Substitution,"Kiana Vu, Phung Lai, Truc Nguyen",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08919"" target=""_blank"">2409.08919</a>",,2025-12-03 22:39:25
Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks,"Md Zarif Hossain, Ahmed Imteaj",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07353"" target=""_blank"">2409.07353</a>","<a href=""https://github.com/speedlab-git/Robust-Encoder-against-Jailbreak-attack"" target=""_blank"">speedlab-git</a>",2025-12-03 22:39:25
Introducing Perturb-ability Score (PS) to Enhance Robustness Against Evasion Adversarial Attacks on ML-NIDS,"Mohamed elShehaby, Ashraf Matrawy",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07448"" target=""_blank"">2409.07448</a>",,2025-12-03 22:39:25
Hard-Label Cryptanalytic Extraction of Neural Network Models,"Yi Chen, Xiaoyang Dong, Jian Guo, Yantian Shen, Anyu Wang, Xiaoyun Wang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.11646"" target=""_blank"">2409.11646</a>",,2025-12-03 22:39:25
Towards Physically-Realizable Adversarial Attacks in Embodied Vision Navigation,"Meng Chen, Jiawei Tu, Chao Qi, Yonghao Dang, Feng Zhou, Wei Wei, Jianqin Yin",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.10071"" target=""_blank"">2409.10071</a>","<a href=""https://github.com/chen37058/Physical-Attacks-in-Embodied-Navigation]"" target=""_blank"">chen37058</a>",2025-12-03 22:39:25
CaBaGe: Data-Free Model Extraction using ClAss BAlanced Generator Ensemble,"Jonathan Rosenthal, Shanchao Liang, Kevin Zhang, Lin Tan",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.10643"" target=""_blank"">2409.10643</a>",,2025-12-03 22:39:25
Realistic Extreme Behavior Generation for Improved AV Testing,"Robert Dyro, Matthew Foutter, Ruolin Li, Lillo Luigi Di, Edward Schmerling, Xilin Zhou, Marco Pavone",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.10669"" target=""_blank"">2409.10669</a>",,2025-12-03 22:39:25
Jailbreaking Large Language Models with Symbolic Mathematics,"Emet Bethany, Mazal Bethany, Juan Arturo Nolazco Flores, Sumit Kumar Jha, Peyman Najafirad",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.11445"" target=""_blank"">2409.11445</a>",,2025-12-03 22:39:25
Speaker Contrastive Learning for Source Speaker Tracing,"Qing Wang, Hongmei Guo, Jian Kang, Mengjie Du, Jie Li, Xiao-Lei Zhang, Lei Xie",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.10072"" target=""_blank"">2409.10072</a>",,2025-12-03 22:39:25
Revisiting Physical-World Adversarial Attack on Traffic Sign Recognition: A Commercial Systems Perspective,"Ningfei Wang, Shaoyuan Xie, Takami Sato, Yunpeng Luo, Kaidi Xu, Qi Alfred Chen",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.09860"" target=""_blank"">2409.09860</a>",,2025-12-03 22:39:25
Federated Learning in Adversarial Environments: Testbed Design and Poisoning Resilience in Cybersecurity,"Hao Jian Huang, Bekzod Iskandarov, Mizanur Rahman, Hakan T. Otal, M. Abdullah Canbaz",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.09794"" target=""_blank"">2409.09794</a>",,2025-12-03 22:39:25
Real-world Adversarial Defense against Patch Attacks based on Diffusion Model,"Xingxing Wei, Caixin Kang, Yinpeng Dong, Zhengyi Wang, Shouwei Ruan, Yubo Chen, Hang Su",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.09406"" target=""_blank"">2409.09406</a>",,2025-12-03 22:39:25
"Top-GAP: Integrating Size Priors in CNNs for more Interpretability, Robustness, and Bias Mitigation","Lars Nieradzik, Henrike Stephani, Janis Keuper",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04819"" target=""_blank"">2409.04819</a>",,2025-12-03 22:39:25
Are Existing Road Design Guidelines Suitable for Autonomous Vehicles? (41%),"Yang Sun, Christopher M. Poskitt, Jun Sun",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.10562"" target=""_blank"">2409.10562</a>",,2025-12-03 22:39:25
Clean Label Attacks against SLU Systems,"Henry Li Xinyuan, Sonal Joshi, Thomas Thebaud, Jesus Villalba, Najim Dehak, Sanjeev Khudanpur",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08985"" target=""_blank"">2409.08985</a>",,2025-12-03 22:39:25
FAST: Boosting Uncertainty-based Test Prioritization Methods for Neural Networks via Feature Selection,"Jialuo Chen, Jingyi Wang, Xiyue Zhang, Youcheng Sun, Marta Kwiatkowska, Jiming Chen, Peng Cheng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.09130"" target=""_blank"">2409.09130</a>",,2025-12-03 22:39:25
LoRID: Low-Rank Iterative Diffusion for Adversarial Purification,"Geigh Zollicoffer, Minh Vu, Ben Nebgen, Juan Castorena, Boian Alexandrov, Manish Bhattarai",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08255"" target=""_blank"">2409.08255</a>",,2025-12-03 22:39:25
High-Frequency Anti-DreamBooth: Robust Defense against Personalized Image Synthesis,"Takuto Onikubo, Yusuke Matsui",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08167"" target=""_blank"">2409.08167</a>",,2025-12-03 22:39:25
FedProphet: Memory-Efficient Federated Adversarial Training via Theoretic-Robustness and Low-Inconsistency Cascade Learning,"Minxue Tang, Yitu Wang, Jingyang Zhang, Louis DiValentin, Aolin Ding, Amin Hass, Yiran Chen, Hai ""Helen"" Li",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08372"" target=""_blank"">2409.08372</a>",,2025-12-03 22:39:25
Exploiting Supervised Poison Vulnerability to Strengthen Self-Supervised Defense,"Jeremy Styborski, Mingzhi Lyu, Yi Huang, Adams Kong",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08509"" target=""_blank"">2409.08509</a>",,2025-12-03 22:39:25
Sub-graph Based Diffusion Model for Link Prediction,"Hang Li, Wei Jin, Geri Skenderi, Harry Shomer, Wenzhuo Tang, Wenqi Fan, Jiliang Tang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08487"" target=""_blank"">2409.08487</a>",,2025-12-03 22:39:25
Risks When Sharing LoRA Fine-Tuned Diffusion Model Weights,Dixi Yao,arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08482"" target=""_blank"">2409.08482</a>",,2025-12-03 22:39:25
Unleashing Worms and Extracting Data: Escalating the Outcome of Attacks against RAG-based Inference in Scale and Severity Using Jailbreaking,"Stav Cohen, Ron Bitton, Ben Nassi",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.08045"" target=""_blank"">2409.08045</a>",,2025-12-03 22:39:25
Module-wise Adaptive Adversarial Training for End-to-end Autonomous Driving,"Tianyuan Zhang, Lu Wang, Jiaqi Kang, Xinwei Zhang, Siyuan Liang, Yuwei Chen, Aishan Liu, Xianglong Liu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.07321"" target=""_blank"">2409.07321</a>",,2025-12-03 22:39:25
PIXHELL Attack: Leaking Sensitive Information from Air-Gap Computers via `Singing Pixels',Mordechai Guri,arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04930"" target=""_blank"">2409.04930</a>",,2025-12-03 22:39:25
TASAR: Transfer-based Attack on Skeletal Action Recognition,"Yunfeng Diao, Baiqi Wu, Ruixuan Zhang, Ajian Liu, Xiaoshuai Hao, Xingxing Wei, Meng Wang, He Wang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02483"" target=""_blank"">2409.02483</a>","<a href=""https://github.com/yunfengdiao/Skeleton-Robustness-Benchmark"" target=""_blank"">yunfengdiao</a>",2025-12-03 22:39:25
Learning to Learn Transferable Generative Attack for Person Re-Identification,"Yuan Bian, Min Liu, Xueping Wang, Yunfeng Ma, Yaonan Wang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04208"" target=""_blank"">2409.04208</a>",,2025-12-03 22:39:25
PANTS: Practical Adversarial Network Traffic Samples against ML-powered Networking Classifiers,"Minhao Jin, Maria Apostolaki",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04691"" target=""_blank"">2409.04691</a>",,2025-12-03 22:39:25
On the Vulnerability of Skip Connections to Model Inversion Attacks,"Jun Hao Koh, Sy-Tuyen Ho, Ngoc-Bao Nguyen, Ngai-man Cheung",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01696"" target=""_blank"">2409.01696</a>","<a href=""https://Pillowkoh.github.io/projects/RoLSS/"" target=""_blank"">RoLSS</a>",2025-12-03 22:39:25
One-Index Vector Quantization Based Adversarial Attack on Image Classification,"Haiju Fan, Xiaona Qin, Shuang Chen, Hubert P. H. Shum, Ming Li",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01282"" target=""_blank"">2409.01282</a>",,2025-12-03 22:39:25
Adversarial Pruning: A Survey and Benchmark of Pruning Methods for Adversarial Robustness,"Giorgio Piras, Maura Pintor, Ambra Demontis, Battista Biggio, Giorgio Giacinto, Fabio Roli",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01249"" target=""_blank"">2409.01249</a>","<a href=""https://github.com/pralab/AdversarialPruningBenchmark"" target=""_blank"">pralab</a>",2025-12-03 22:39:25
Phantom: Untargeted Poisoning Attacks on Semi-Supervised Learning (Full Version),"Jonathan Knauer, Phillip Rieger, Hossein Fereidooni, Ahmad-Reza Sadeghi",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01470"" target=""_blank"">2409.01470</a>",,2025-12-03 22:39:25
CLIBE: Detecting Dynamic Backdoors in Transformer-based NLP Models,"Rui Zeng, Xi Chen, Yuwen Pu, Xuhong Zhang, Tianyu Du, Shouling Ji",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01193"" target=""_blank"">2409.01193</a>",,2025-12-03 22:39:25
Agentic Copyright Watermarking against Adversarial Evidence Forgery with Purification-Agnostic Curriculum Proxy Learning,"Erjin Bao, Ching-Chun Chang, Hanrui Wang, Isao Echizen",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01541"" target=""_blank"">2409.01541</a>",,2025-12-03 22:39:25
Unveiling the Vulnerability of Private Fine-Tuning in Split-Based Frameworks for Large Language Models: A Bidirectionally Enhanced Attack,"Guanzhong Chen, Zhenghan Qin, Mingxin Yang, Yajie Zhou, Tao Fan, Tianyu Du, Zenglin Xu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00960"" target=""_blank"">2409.00960</a>",,2025-12-03 22:39:25
A Review of Image Retrieval Techniques: Data Augmentation and Adversarial Learning Approaches,Kim Jinwoo,arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01219"" target=""_blank"">2409.01219</a>",,2025-12-03 22:39:25
Spatial-Aware Conformal Prediction for Trustworthy Hyperspectral Image Classification,"Kangdao Liu, Tianhao Sun, Hao Zeng, Yongshan Zhang, Chi-Man Pun, Chi-Man Vong",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01236"" target=""_blank"">2409.01236</a>","<a href=""https://github.com/J4ckLiu/SACP"" target=""_blank"">J4ckLiu</a>",2025-12-03 22:39:25
"Comprehensive Botnet Detection by Mitigating Adversarial Attacks, Navigating the Subtleties of Perturbation Distances and Fortifying Predictions with Conformal Layers","Rahul Yumlembam, Biju Issac, Seibu Mary Jacob, Longzhi Yang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00667"" target=""_blank"">2409.00667</a>",,2025-12-03 22:39:25
Accurate Forgetting for All-in-One Image Restoration Model,"Xin Su, Zhuoran Zheng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00685"" target=""_blank"">2409.00685</a>",,2025-12-03 22:39:25
The Dark Side of Human Feedback: Poisoning Large Language Models via User Inputs,"Bocheng Chen, Hanqing Guo, Guangjing Wang, Yuanda Wang, Qiben Yan",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00787"" target=""_blank"">2409.00787</a>",,2025-12-03 22:39:25
Fisher Information guided Purification against Backdoor Attacks,"Nazmul Karim, Abdullah Al Arafat, Adnan Siraj Rakin, Zhishan Guo, Nazanin Rahnavard",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00863"" target=""_blank"">2409.00863</a>",,2025-12-03 22:39:25
HSF: Defending against Jailbreak Attacks with Hidden State Filtering,"Cheng Qian, Hainan Zhang, Lei Sha, Zhiming Zheng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03788"" target=""_blank"">2409.03788</a>",,2025-12-03 22:39:25
Is Difficulty Calibration All We Need? Towards More Practical Membership Inference Attacks,"Yu He, Boheng Li, Yao Wang, Mengda Yang, Juan Wang, Hongxin Hu, Xingyu Zhao",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00426"" target=""_blank"">2409.00426</a>",,2025-12-03 22:39:25
Robust off-policy Reinforcement Learning via Soft Constrained Adversary,"Kosuke Nakanishi, Akihiro Kubo, Yuji Yasui, Shin Ishii",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00418"" target=""_blank"">2409.00418</a>",,2025-12-03 22:39:25
Cognitive Networks and Performance Drive fMRI-Based State Classification Using DNN Models,"Murat Kucukosmanoglu, Javier O. Garcia, Justin Brooks, Kanika Bansal",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00003"" target=""_blank"">2409.00003</a>",,2025-12-03 22:39:25
PRADA: Proactive Risk Assessment and Mitigation of Misinformed Demand Attacks on Navigational Route Recommendations,"Ya-Ting Yang, Haozhe Lei, Quanyan Zhu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00243"" target=""_blank"">2409.00243</a>",,2025-12-03 22:39:25
Feedback-based Modal Mutual Search for Attacking Vision-Language Pre-training Models,"Renhua Ding, Xinze Zhang, Xiao Yang, Kun He",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.06726"" target=""_blank"">2409.06726</a>",,2025-12-03 22:39:25
Dual Adversarial Perturbators Generate rich Views for Recommendation,"Lijun Zhang, Yuan Yao, Haibo Ye",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.06719"" target=""_blank"">2409.06719</a>",,2025-12-03 22:39:25
EIA: Environmental Injection Attack on Generalist Web Agents for Privacy Leakage,"Zeyi Liao, Lingbo Mo, Chejian Xu, Mintong Kang, Jiawei Zhang, Chaowei Xiao, Yuan Tian, Bo Li, Huan Sun",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.11295"" target=""_blank"">2409.11295</a>",,2025-12-03 22:39:25
Reassessing Noise Augmentation Methods in the Context of Adversarial Speech,"Karla Pizzi, Matías Pizarro, Asja Fischer",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01813"" target=""_blank"">2409.01813</a>",,2025-12-03 22:39:25
NoiseAttack: An Evasive Sample-Specific Multi-Targeted Backdoor Attack Through White Gaussian Noise,"Abdullah Arafat Miah, Kaan Icer, Resit Sendag, Yu Bi",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02251"" target=""_blank"">2409.02251</a>","<a href=""https://github.com/SiSL-URI/NoiseAttack/tree/main"" target=""_blank"">tree</a>",2025-12-03 22:39:25
Dynamic Guidance Adversarial Distillation with Enhanced Teacher Knowledge,"Hyejin Park, Dongbo Min",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01627"" target=""_blank"">2409.01627</a>",,2025-12-03 22:39:25
WaterMAS: Sharpness-Aware Maximization for Neural Network Watermarking,"Carl De Sousa Trias, Mihai Mitrea, Attilio Fiandrotti, Marco Cagnazzo, Sumanta Chaudhuri, Enzo Tartaglione",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03902"" target=""_blank"">2409.03902</a>",,2025-12-03 22:39:25
Secure Traffic Sign Recognition: An Attention-Enabled Universal Image Inpainting Mechanism against Light Patch Attacks,"Hangcheng Cao, Longzhi Yuan, Guowen Xu, Ziyang He, Zhengru Fang, Yuguang Fang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04133"" target=""_blank"">2409.04133</a>",,2025-12-03 22:39:25
Mind The Gap: Can Air-Gaps Keep Your Private Data Secure? (74%),Mordechai Guri,arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04190"" target=""_blank"">2409.04190</a>",,2025-12-03 22:39:25
Exploiting the Data Gap: Utilizing Non-ignorable Missingness to Manipulate Model Learning,"Deniz Koyuncu, Alex Gittens, Bülent Yener, Moti Yung",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04407"" target=""_blank"">2409.04407</a>",,2025-12-03 22:39:25
Context is the Key: Backdoor Attacks for In-Context Learning with Vision Transformers,"Gorka Abad, Stjepan Picek, Lorenzo Cavallaro, Aitor Urbieta",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04142"" target=""_blank"">2409.04142</a>",,2025-12-03 22:39:25
Dual-stream Feature Augmentation for Domain Generalization,"Shanshan Wang, ALuSi, Xun Yang, Ke Xu, Huibin Tan, Xingyi Zhang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.04699"" target=""_blank"">2409.04699</a>","<a href=""https://github.com/alusi123/DFA"" target=""_blank"">alusi123</a>",2025-12-03 22:39:25
A practical approach to evaluating the adversarial distance for machine learning classifiers,"Georg Siedel, Ekagra Gupta, Andrey Morozov",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03598"" target=""_blank"">2409.03598</a>",,2025-12-03 22:39:25
Non-Uniform Illumination Attack for Fooling Convolutional Neural Networks,"Akshay Jain, Shiv Ram Dubey, Satish Kumar Singh, KC Santosh, Bidyut Baran Chaudhuri",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03458"" target=""_blank"">2409.03458</a>",,2025-12-03 22:39:25
Limited but consistent gains in adversarial robustness by co-training object recognition models with human EEG,"Manshan Guo, Bhavin Choksi, Sari Sadiya, Alessandro T. Gifford, Martina G. Vilas, Radoslaw M. Cichy, Gemma Roig",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03646"" target=""_blank"">2409.03646</a>",,2025-12-03 22:39:25
Recent Advances in Attack and Defense Approaches of Large Language Models,"Jing Cui, Yishi Xu, Zhewei Huang, Shuchang Zhou, Jianbin Jiao, Junge Zhang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03274"" target=""_blank"">2409.03274</a>",,2025-12-03 22:39:25
Understanding Data Importance in Machine Learning Attacks: Does Valuable Data Pose Greater Harm? (1%),"Rui Wen, Michael Backes, Yang Zhang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03741"" target=""_blank"">2409.03741</a>",,2025-12-03 22:39:25
Exploiting the Vulnerability of Large Language Models via Defense-Aware Architectural Backdoor,"Abdullah Arafat Miah, Yu Bi",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.01952"" target=""_blank"">2409.01952</a>","<a href=""https://github.com/SiSL-URI/Arch_Backdoor_LLM"" target=""_blank"">SiSL-URI</a>",2025-12-03 22:39:25
Bypassing DARCY Defense: Indistinguishable Universal Adversarial Triggers,"Zuquan Peng, Yuanyuan He, Jianbing Ni, Ben Niu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03183"" target=""_blank"">2409.03183</a>",,2025-12-03 22:39:25
OpenFact at CheckThat! 2024: Combining Multiple Attack Methods for Effective Adversarial Text Generation,"Włodzimierz Lewoniewski, Piotr Stolarski, Milena Stróżyna, Elzbieta Lewańska, Aleksandra Wojewoda, Ewelina Księżniak, Marcin Sawiński",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02649"" target=""_blank"">2409.02649</a>",,2025-12-03 22:39:25
Adversarial Attacks on Machine Learning-Aided Visualizations,"Takanori Fujiwara, Kostiantyn Kucher, Junpeng Wang, Rafael M. Martins, Andreas Kerren, Anders Ynnerman",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02485"" target=""_blank"">2409.02485</a>",,2025-12-03 22:39:25
Transfer-based Adversarial Poisoning Attacks for Online (MIMO-)Deep Receviers,"Kunze Wu, Weiheng Jiang, Dusit Niyato, Yinghuan Li, Chuang Luo",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02430"" target=""_blank"">2409.02430</a>",,2025-12-03 22:39:25
Boosting Certificate Robustness for Time Series Classification with Efficient Self-Ensemble,"Chang Dong, Zhengyang Li, Liangwei Zheng, Weitong Chen, Wei Emma Zhang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02802"" target=""_blank"">2409.02802</a>",,2025-12-03 22:39:25
AdvSecureNet: A Python Toolkit for Adversarial Machine Learning,"Melih Catal, Manuel Günther",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02629"" target=""_blank"">2409.02629</a>",,2025-12-03 22:39:25
Active Fake: DeepFake Camouflage,"Pu Sun, Honggang Qi, Yuezun Li",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03200"" target=""_blank"">2409.03200</a>",,2025-12-03 22:39:25
"Well, that escalated quickly: The Single-Turn Crescendo Attack (STCA)",Alan Aqrawi,arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.03131"" target=""_blank"">2409.03131</a>",,2025-12-03 22:39:25
"""Yes, My LoRD","Zi Liang, Qingqing Ye, Yanyun Wang, Sen Zhang, Yaxin Xiao, Ronghua Li, Jianliang Xu, Haibo Hu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.02718"" target=""_blank"">2409.02718</a>","<a href=""https://github.com/liangzid/LoRD-MEA"" target=""_blank"">liangzid</a>",2025-12-03 22:39:25
Contextual Breach: Assessing the Robustness of Transformer-based QA Models,"Asir Saadat, Nahian Ibn Asad, Md Farhan Ishmam",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.10997"" target=""_blank"">2409.10997</a>",,2025-12-03 22:39:25
LightPure: Realtime Adversarial Image Purification for Mobile Devices Using Diffusion Models,"Hossein Khalili, Seongbin Park, Vincent Li, Brandan Bright, Ali Payani, Ramana Rao Kompella, Nader Sehatbakhsh",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.00340"" target=""_blank"">2409.00340</a>",,2025-12-03 22:39:25
Golden Ratio Search: A Low-Power Adversarial Attack for Deep Learning based Modulation Classification,"Deepsayan Sadhukhan, Nitin Priyadarshini Shankar, Sheetal Kalyani",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.11454"" target=""_blank"">2409.11454</a>",,2025-12-03 22:39:25
Proactive Schemes: A Survey of Adversarial Attacks for Social Good,"Vishal Asnani, Xi Yin, Xiaoming Liu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.16491"" target=""_blank"">2409.16491</a>",,2025-12-03 22:39:25
Faithfulness and the Notion of Adversarial Sensitivity in NLP Explanations,"Supriya Manna, Niladri Sett",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17774"" target=""_blank"">2409.17774</a>",,2025-12-03 22:39:25
CleanerCLIP: Fine-grained Counterfactual Semantic Augmentation for Backdoor Defense in Contrastive Learning,"Yuan Xun, Siyuan Liang, Xiaojun Jia, Xinwei Liu, Xiaochun Cao",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17601"" target=""_blank"">2409.17601</a>",,2025-12-03 22:39:25
DarkSAM: Fooling Segment Anything Model to Segment Nothing,"Ziqi Zhou, Yufei Song, Minghui Li, Shengshan Hu, Xianlong Wang, Leo Yu Zhang, Dezhong Yao, Hai Jin",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17874"" target=""_blank"">2409.17874</a>",,2025-12-03 22:39:25
"Perturb, Attend, Detect and Localize (PADL): Robust Proactive Image Defense","Filippo Bartolucci, Iacopo Masi, Giuseppe Lisanti",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17941"" target=""_blank"">2409.17941</a>",,2025-12-03 22:39:25
Development of an Edge Resilient ML Ensemble to Tolerate ICS Adversarial Attacks,"Likai Yao, Qinxuan Shi, Zhanglong Yang, Sicong Shao, Salim Hariri",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18244"" target=""_blank"">2409.18244</a>",,2025-12-03 22:39:25
Backdoor Attacks for LLMs with Weak-To-Strong Knowledge Distillation,"Shuai Zhao, Leilei Gan, Zhongliang Guo, Xiaobao Wu, Luwei Xiao, Xiaoyu Xu, Cong-Duy Nguyen, Luu Anh Tuan",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17946"" target=""_blank"">2409.17946</a>",,2025-12-03 22:39:25
Harmful Fine-tuning Attacks and Defenses for Large Language Models: A Survey,"Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim Furkan Tekin, Ling Liu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18169"" target=""_blank"">2409.18169</a>","<a href=""https://github.com/git-disl/awesome_LLM-harmful-fine-tuning-papers"" target=""_blank"">git-disl</a>",2025-12-03 22:39:25
Dark Miner: Defend against unsafe generation for text-to-image diffusion models,"Zheling Meng, Bo Peng, Xiaochuan Jin, Yue Jiang, Jing Dong, Wei Wang, Tieniu Tan",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17682"" target=""_blank"">2409.17682</a>",,2025-12-03 22:39:25
An Adversarial Perspective on Machine Unlearning for AI Safety,"Jakub Łucki, Boyi Wei, Yangsibo Huang, Peter Henderson, Florian Tramèr, Javier Rando",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18025"" target=""_blank"">2409.18025</a>",,2025-12-03 22:39:25
Revolutionizing Payload Inspection: A Self-Supervised Journey to Precision with Few Shots,"Kyle Stein, Arash Mahyari, Guillermo III Francia, Eman El-Sheikh",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18219"" target=""_blank"">2409.18219</a>",,2025-12-03 22:39:25
Improving the Shortest Plank: Vulnerability-Aware Adversarial Training for Robust Recommender System,"Kaike Zhang, Qi Cao, Yunfan Wu, Fei Sun, Huawei Shen, Xueqi Cheng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17476"" target=""_blank"">2409.17476</a>",,2025-12-03 22:39:25
A Hybrid Quantum-Classical AI-Based Detection Strategy for Generative Adversarial Network-Based Deepfake Attacks on an Autonomous Vehicle Traffic Sign Classification System,"M Sabbir Salek, Shaozhi Li, Mashrur Chowdhury",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17311"" target=""_blank"">2409.17311</a>",,2025-12-03 22:39:25
RED QUEEN: Safeguarding Large Language Models against Concealed Multi-Turn Jailbreaking,"Yifan Jiang, Kriti Aggarwal, Tanmay Laud, Kashif Munir, Jay Pujara, Subhabrata Mukherjee",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17458"" target=""_blank"">2409.17458</a>","<a href=""https://github.com/kriti-hippo/red_queen"" target=""_blank"">kriti-hippo</a>",2025-12-03 22:39:25
Transient Adversarial 3D Projection Attacks on Object Detection in Autonomous Driving,"Ce Zhou, Qiben Yan, Sijia Liu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17403"" target=""_blank"">2409.17403</a>",,2025-12-03 22:39:25
Examining the Rat in the Tunnel: Interpretable Multi-Label Classification of Tor-based Malware,"Ishan Karunanayake, Mashael AlSabah, Nadeem Ahmed, Sanjay Jha",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.16639"" target=""_blank"">2409.16639</a>",,2025-12-03 22:39:25
SWE2: SubWord Enriched and Significant Word Emphasized Framework for Hate Speech Detection,"Guanyi Mou, Pengyi Ye, Kyumin Lee",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.16673"" target=""_blank"">2409.16673</a>",,2025-12-03 22:39:25
SHEATH: Defending Horizontal Collaboration for Distributed CNNs against Adversarial Noise,"Muneeba Asif, Mohammad Kumail Kazmi, Mohammad Ashiqur Rahman, Syed Rafay Hasan, Soamar Homsi",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17279"" target=""_blank"">2409.17279</a>",,2025-12-03 22:39:25
Claim-Guided Textual Backdoor Attack for Practical Applications,"Minkyoo Song, Hanna Kim, Jaehan Kim, Youngjin Jin, Seungwon Shin",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.16618"" target=""_blank"">2409.16618</a>","<a href=""https://github.com/PaperCGBA/CGBA"" target=""_blank"">PaperCGBA</a>",2025-12-03 22:39:25
Cat-and-Mouse Satellite Dynamics: Divergent Adversarial Reinforcement Learning for Contested Multi-Agent Space Operations,"Cameron Mehlman, Joseph Abramov, Gregory Falco",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17443"" target=""_blank"">2409.17443</a>",,2025-12-03 22:39:25
Adversarial Backdoor Defense in CLIP,"Junhao Kuang, Siyuan Liang, Jiawei Liang, Kuanrong Liu, Xiaochun Cao",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15968"" target=""_blank"">2409.15968</a>",,2025-12-03 22:39:25
Revisiting Acoustic Features for Robust ASR,"Muhammad A. Shah, Bhiksha Raj",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.16399"" target=""_blank"">2409.16399</a>",,2025-12-03 22:39:25
Improving Fast Adversarial Training via Self-Knowledge Guidance,"Chengze Jiang, Junkai Wang, Minjing Dong, Jie Gui, Xinli Shi, Yuan Cao, Yuan Yan Tang, James Tin-Yau Kwok",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17589"" target=""_blank"">2409.17589</a>",,2025-12-03 22:39:25
Cross-Modality Attack Boosted by Gradient-Evolutionary Multiform Optimization,"Yunpeng Gong, Qingyuan Zeng, Dejun Xu, Zhenzhong Wang, Min Jiang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17977"" target=""_blank"">2409.17977</a>",,2025-12-03 22:39:25
Showing Many Labels in Multi-label Classification Models: An Empirical Study of Adversarial Examples,"Yujiang Liu, Wenjian Luo, Zhijian Chen, Muhammad Luqman Naseem",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.17568"" target=""_blank"">2409.17568</a>",,2025-12-03 22:39:25
Towards Robust Extractive Question Answering Models: Rethinking the Training Methodology,"Son Quoc Tran, Matt Kretchmar",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19766"" target=""_blank"">2409.19766</a>",,2025-12-03 22:39:25
Characterizing Model Robustness via Natural Input Gradients,"Adrián Rodríguez-Muñoz, Tongzhou Wang, Antonio Torralba",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.20139"" target=""_blank"">2409.20139</a>",,2025-12-03 22:39:25
Robust LLM safeguarding via refusal feature adversarial training,"Lei Yu, Virginie Do, Karen Hambardzumyan, Nicola Cancedda",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.20089"" target=""_blank"">2409.20089</a>",,2025-12-03 22:39:25
Navigating Threats: A Survey of Physical Adversarial Attacks on LiDAR Perception Systems in Autonomous Vehicles,"Amira Guesmi, Muhammad Shafique",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.20426"" target=""_blank"">2409.20426</a>",,2025-12-03 22:39:25
Understanding Implosion in Text-to-Image Generative Models,"Wenxin Ding, Cathy Y. Li, Shawn Shan, Ben Y. Zhao, Haitao Zheng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12314"" target=""_blank"">2409.12314</a>",,2025-12-03 22:39:25
MASKDROID: Robust Android Malware Detection with Masked Graph Representations,"Jingnan Zheng, Jiaohao Liu, An Zhang, Jun Zeng, Ziqi Yang, Zhenkai Liang, Tat-Seng Chua",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19594"" target=""_blank"">2409.19594</a>",,2025-12-03 22:39:25
Adversarial Examples for DNA Classification,Hyunwoo Yoo,arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19788"" target=""_blank"">2409.19788</a>",,2025-12-03 22:39:25
Discerning the Chaos: Detecting Adversarial Perturbations while Disentangling Intentional from Unintentional Noises,"Anubhooti Jain, Susim Roy, Kwanit Gupta, Mayank Vatsa, Richa Singh",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19619"" target=""_blank"">2409.19619</a>",,2025-12-03 22:39:25
Nonideality-aware training makes memristive networks more robust to adversarial attacks,"Dovydas Joksas, Luis Muñoz-González, Emil Lupu, Adnan Mehonic",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19671"" target=""_blank"">2409.19671</a>",,2025-12-03 22:39:25
Infighting in the Dark: Multi-Labels Backdoor Attack in Federated Learning,"Ye Li, Yanchao Zhao, Chengcheng Zhu, Jiale Zhang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19601"" target=""_blank"">2409.19601</a>",,2025-12-03 22:39:25
Learning Robust Policies via Interpretable Hamilton-Jacobi Reachability-Guided Disturbances,"Hanyang Hu, Xilun Zhang, Xubo Lyu, Mo Chen",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19746"" target=""_blank"">2409.19746</a>",,2025-12-03 22:39:25
In-depth Analysis of Privacy Threats in Federated Learning for Medical Data,"Badhan Chandra Das, M. Hadi Amini, Yanzhao Wu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18907"" target=""_blank"">2409.18907</a>",,2025-12-03 22:39:25
IDEAW: Robust Neural Audio Watermarking with Invertible Dual-Embedding,"Pengcheng Li, Xulong Zhang, Jing Xiao, Jianzong Wang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19627"" target=""_blank"">2409.19627</a>",,2025-12-03 22:39:25
Can Models Learn Skill Composition from Examples? (1%),"Haoyu Zhao, Simran Kaur, Dingli Yu, Anirudh Goyal, Sanjeev Arora",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19808"" target=""_blank"">2409.19808</a>",,2025-12-03 22:39:25
Efficient Backdoor Defense in Multimodal Contrastive Learning: A Token-Level Unlearning Method for Mitigating Threats,"Kuanrong Liu, Siyuan Liang, Jiawei Liang, Pengwen Dai, Xiaochun Cao",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19526"" target=""_blank"">2409.19526</a>",,2025-12-03 22:39:25
GenTel-Safe: A Unified Benchmark and Shielding Framework for Defending Against Prompt Injection Attacks,"Rongchang Li, Minjie Chen, Chang Hu, Han Chen, Wenpeng Xing, Meng Han",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19521"" target=""_blank"">2409.19521</a>","<a href=""https://gentellab.github.io/gentel-safe.github.io/"" target=""_blank"">gentel-safe.github.io</a>",2025-12-03 22:39:25
Leveraging MTD to Mitigate Poisoning Attacks in Decentralized FL with Non-IID Data,"Chao Feng, Alberto Huertas Celdrán, Zien Zeng, Zi Ye, der Assen Jan von, Gerome Bovet, Burkhard Stiller",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19302"" target=""_blank"">2409.19302</a>",,2025-12-03 22:39:25
Privacy Attack in Federated Learning is Not Easy: An Experimental Study,"Hangyu Zhu, Liyuan Huang, Zhenping Xie",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19301"" target=""_blank"">2409.19301</a>",,2025-12-03 22:39:25
Adversarial Challenges in Network Intrusion Detection Systems: Research Insights and Future Prospects,"Sabrine Ennaji, Gaspari Fabio De, Dorjan Hitaj, Alicia K/Bidi, Luigi V. Mancini",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18736"" target=""_blank"">2409.18736</a>",,2025-12-03 22:39:25
Enhancing Robustness of Graph Neural Networks through p-Laplacian,"Anuj Kumar Sirohi, Subhanu Halder, Kabir Kumar, Sandeep Kumar",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.19096"" target=""_blank"">2409.19096</a>",,2025-12-03 22:39:25
Efficient Noise Mitigation for Enhancing Inference Accuracy in DNNs on Mixed-Signal Accelerators,"Seyedarmin Azizi, Mohammad Erfan Sadeghi, Mehdi Kamal, Massoud Pedram",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18553"" target=""_blank"">2409.18553</a>",,2025-12-03 22:39:25
Adversarial Watermarking for Face Recognition,"Yuguang Yao, Anil Jain, Sijia Liu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.16056"" target=""_blank"">2409.16056</a>",,2025-12-03 22:39:25
Discovering New Shadow Patterns for Black-Box Attacks on Lane Detection of Autonomous Vehicles,"Pedram MohajerAnsari, Alkim Domeke, Voor Jan de, Arkajyoti Mitra, Grace Johnson, Amir Salarpour, Habeeb Olufowobi, Mohammad Hamad, Mert D. Pesé",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.18248"" target=""_blank"">2409.18248</a>",,2025-12-03 22:39:25
Privacy Evaluation Benchmarks for NLP Models,"Wei Huang, Yinggui Wang, Cen Chen",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15868"" target=""_blank"">2409.15868</a>","<a href=""https://github.com/user2311717757/nlp_doctor"" target=""_blank"">user2311717757</a>",2025-12-03 22:39:25
Defending against Reverse Preference Attacks is Difficult,"Domenic Rosati, Giles Edkins, Harsh Raj, David Atanasov, Subhabrata Majumdar, Janarthanan Rajendran, Frank Rudzicz, Hassan Sajjad",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12914"" target=""_blank"">2409.12914</a>",,2025-12-03 22:39:25
ViTGuard: Attention-aware Detection against Adversarial Examples for Vision Transformer,"Shihua Sun, Kenechukwu Nwodo, Shridatt Sugrim, Angelos Stavrou, Haining Wang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13828"" target=""_blank"">2409.13828</a>",,2025-12-03 22:39:25
Certified Adversarial Robustness via Partition-based Randomized Smoothing,"Hossein Goli, Farzan Farnia",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13546"" target=""_blank"">2409.13546</a>",,2025-12-03 22:39:25
ID-Guard: A Universal Framework for Combating Facial Manipulation via Breaking Identification,"Zuomin Qu, Wei Lu, Xiangyang Luo, Qian Wang, Xiaochun Cao",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13349"" target=""_blank"">2409.13349</a>",,2025-12-03 22:39:25
Relationship between Uncertainty in DNNs and Adversarial Attacks,"Mabel Ogonna, Abigail Adeniran, Adewale Adeyemo",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13232"" target=""_blank"">2409.13232</a>",,2025-12-03 22:39:25
PureDiffusion: Using Backdoor to Counter Backdoor in Generative Diffusion Models,"Vu Tuan Truong, Long Bao Le",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13945"" target=""_blank"">2409.13945</a>",,2025-12-03 22:39:25
On the Feasibility of Fully AI-automated Vishing Attacks,"João Figueiredo, Afonso Carvalho, Daniel Castro, Daniel Gonçalves, Nuno Santos",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13793"" target=""_blank"">2409.13793</a>",,2025-12-03 22:39:25
Deep generative models as an adversarial attack strategy for tabular machine learning,"Salijona Dyrmishi, Mihaela Cătălina Stoian, Eleonora Giunchiglia, Maxime Cordy",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12642"" target=""_blank"">2409.12642</a>",,2025-12-03 22:39:25
TEAM: Temporal Adversarial Examples Attack Model against Network Intrusion Detection System Applied to RNN,"Ziyi Liu, Dengpan Ye, Long Tang, Yunming Zhang, Jiacheng Deng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12472"" target=""_blank"">2409.12472</a>",,2025-12-03 22:39:25
A constrained optimization approach to improve robustness of neural networks,"Shudian Zhao, Jan Kronqvist",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13770"" target=""_blank"">2409.13770</a>",,2025-12-03 22:39:25
Revisiting Semi-supervised Adversarial Robustness via Noise-aware Online Robust Distillation,"Tsung-Han Wu, Hung-Ting Su, Shang-Tse Chen, Winston H. Hsu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12946"" target=""_blank"">2409.12946</a>",,2025-12-03 22:39:25
Data-centric NLP Backdoor Defense from the Lens of Memorization,"Zhenting Wang, Zhizhi Wang, Mingyu Jin, Mengnan Du, Juan Zhai, Shiqing Ma",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14200"" target=""_blank"">2409.14200</a>",,2025-12-03 22:39:25
VCAT: Vulnerability-aware and Curiosity-driven Adversarial Training for Enhancing Autonomous Vehicle Robustness,"Xuan Cai, Zhiyong Cui, Xuesong Bai, Ruimin Ke, Zhenshu Ma, Haiyang Yu, Yilong Ren",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12997"" target=""_blank"">2409.12997</a>","<a href=""https://github.com/caixxuan/VCAT"" target=""_blank"">caixxuan</a>",2025-12-03 22:39:25
Data Poisoning and Leakage Analysis in Federated Learning,"Wenqi Wei, Tiansheng Huang, Zachary Yahn, Anoop Singhal, Margaret Loper, Ling Liu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13004"" target=""_blank"">2409.13004</a>",,2025-12-03 22:39:25
Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End Vision Language Action Models,"Hao Cheng, Erjia Xiao, Chengyuan Yu, Zhao Yao, Jiahang Cao, Qiang Zhang, Jiaxu Wang, Mengshu Sun, Kaidi Xu, Jindong Gu, Renjing Xu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13174"" target=""_blank"">2409.13174</a>","<a href=""https://chaducheng.github.io/Manipulat-Facing-Threats/"" target=""_blank"">Manipulat-Facing-Threats</a>",2025-12-03 22:39:25
"Hidden in Plain Sound: Environmental Backdoor Poisoning Attacks on Whisper, and Mitigations","Jonatan Bartolini, Todor Stoyanov, Alberto Giaretta",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12553"" target=""_blank"">2409.12553</a>",,2025-12-03 22:39:25
Enhancing 3D Robotic Vision Robustness by Minimizing Adversarial Mutual Information through a Curriculum Training Approach,"Nastaran Darabi, Dinithi Jayasuriya, Devashri Naik, Theja Tulabandhula, Amit Ranjan Trivedi",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12379"" target=""_blank"">2409.12379</a>","<a href=""https://github.com/nstrndrbi/Mine-N-Learn"" target=""_blank"">nstrndrbi</a>",2025-12-03 22:39:25
ITPatch: An Invisible and Triggered Physical Adversarial Patch against Traffic Sign Recognition,"Shuai Yuan, Hongwei Li, Xingshuo Han, Guowen Xu, Wenbo Jiang, Tao Ni, Qingchuan Zhao, Yuguang Fang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12394"" target=""_blank"">2409.12394</a>",,2025-12-03 22:39:25
NPAT Null-Space Projected Adversarial Training Towards Zero Deterioration,"Hanyi Hu, Qiao Han, Kui Chen, Yao Yang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.11754"" target=""_blank"">2409.11754</a>",,2025-12-03 22:39:25
ID-Free Not Risk-Free: LLM-Powered Agents Unveil Risks in ID-Free Recommender Systems,"Zongwei Wang, Min Gao, Junliang Yu, Xinyi Gao, Quoc Viet Hung Nguyen, Shazia Sadiq, Hongzhi Yin",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.11690"" target=""_blank"">2409.11690</a>",,2025-12-03 22:39:25
Towards Robust Object Detection: Identifying and Removing Backdoors via Module Inconsistency Analysis,"Xianda Zhang, Siyuan Liang",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.16057"" target=""_blank"">2409.16057</a>",,2025-12-03 22:39:25
Efficient Visualization of Neural Networks with Generative Models and Adversarial Perturbations,Athanasios Karagounis,arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13559"" target=""_blank"">2409.13559</a>",,2025-12-03 22:39:25
Hidden Activations Are Not Enough: A General Approach to Neural Network Predictions,"Samuel Leblanc, Aiky Rasolomanana, Marco Armenta",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.13163"" target=""_blank"">2409.13163</a>","<a href=""https://github.com/MarcoArmenta/Hidden-Activations-are-not-Enough"" target=""_blank"">MarcoArmenta</a>",2025-12-03 22:39:25
PAD-FT: A Lightweight Defense for Backdoor Attacks via Data Purification and Fine-Tuning,"Yukai Xu, Yujie Gu, Kouichi Sakurai",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.12072"" target=""_blank"">2409.12072</a>",,2025-12-03 22:39:25
Room Impulse Responses help attackers to evade Deep Fake Detection,"Hieu-Thi Luong, Duc-Tuan Truong, Kong Aik Lee, Eng Siong Chng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14712"" target=""_blank"">2409.14712</a>",,2025-12-03 22:39:25
PACE: Poisoning Attacks on Learned Cardinality Estimation,"Jintao Tsinghua University Zhang, Chao Tsinghua University Zhang, Guoliang Tsinghua University Li, Chengliang Beijing Institute of Technology Chai",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15990"" target=""_blank"">2409.15990</a>",,2025-12-03 22:39:25
Perfect Gradient Inversion in Federated Learning: A New Paradigm from the Hidden Subset Sum Problem,"Qiongxiu Li, Lixia Luo, Agnese Gini, Changlong Ji, Zhanhao Hu, Xiao Li, Chengfang Fang, Jie Shi, Xiaolin Hu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14260"" target=""_blank"">2409.14260</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness for 3D Point Cloud Recognition at Test-Time through Purified Self-Training,"Jinpeng Lin, Xulei Yang, Tianrui Li, Xun Xu",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14940"" target=""_blank"">2409.14940</a>",,2025-12-03 22:39:25
Interpretability-Guided Test-Time Adversarial Defense,"Akshay Kulkarni, Tsui-Wei Weng",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15190"" target=""_blank"">2409.15190</a>",,2025-12-03 22:39:25
PAPILLON: Efficient and Stealthy Fuzz Testing-Powered Jailbreaks for LLMs,"Xueluan Gong, Mingzhe Li, Yilin Zhang, Fengyuan Ran, Chen Chen, Yanjiao Chen, Qian Wang, Kwok-Yan Lam",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14866"" target=""_blank"">2409.14866</a>",,2025-12-03 22:39:25
Data Poisoning-based Backdoor Attack Framework against Supervised Learning Rules of Spiking Neural Networks,"Lingxin Jin, Meiyu Lin, Wei Jiang, Jinyu Zhan",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15670"" target=""_blank"">2409.15670</a>",,2025-12-03 22:39:25
PROMPTFUZZ: Harnessing Fuzzing Techniques for Robust Testing of Prompt Injection in LLMs,"Jiahao Yu, Yangguang Shao, Hanwen Miao, Junzheng Shi",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14729"" target=""_blank"">2409.14729</a>",,2025-12-03 22:39:25
Log-normal Mutations and their Use in Detecting Surreptitious Fake Images,"Ismail Labiad, Thomas Bäck, Pierre Fernandez, Laurent Najman, Tom Sander, Furong Ye, Mariia Zameshina, Olivier Teytaud",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15119"" target=""_blank"">2409.15119</a>",,2025-12-03 22:39:25
Toward Mixture-of-Experts Enabled Trustworthy Semantic Communication for 6G Networks,"Jiayi He, Xiaofeng Luo, Jiawen Kang, Hongyang Du, Zehui Xiong, Ci Chen, Dusit Niyato, Xuemin Shen",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15695"" target=""_blank"">2409.15695</a>",,2025-12-03 22:39:25
Attack Atlas: A Practitioner's Perspective on Challenges and Pitfalls in Red Teaming GenAI,"Ambrish Rawat, Stefan Schoepf, Giulio Zizzo, Giandomenico Cornacchia, Muhammad Zaid Hameed, Kieran Fraser, Erik Miehling, Beat Buesser, Elizabeth M. Daly, Mark Purcell, Prasanna Sattigeri, Pin-Yu Chen, Kush R. Varshney",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15398"" target=""_blank"">2409.15398</a>",,2025-12-03 22:39:25
AIM 2024 Sparse Neural Rendering Challenge: Dataset and Benchmark,"Michal Nazarczuk, Thomas Tanay, Sibi Catley-Chandar, Richard Shaw, Radu Timofte, Eduardo Pérez-Pellitero",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15041"" target=""_blank"">2409.15041</a>","<a href=""https://sparebenchmark.github.io/"" target=""_blank"">sparebenchmark.github.io</a>",2025-12-03 22:39:25
Cloud Adversarial Example Generation for Remote Sensing Image Classification,"Fei Ma, Yuqiang Feng, Fan Zhang, Yongsheng Zhou",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14240"" target=""_blank"">2409.14240</a>",,2025-12-03 22:39:25
ESPERANTO: Evaluating Synthesized Phrases to Enhance Robustness in AI Detection for Text Origination,"Navid Ayoobi, Lily Knab, Wen Cheng, David Pantoja, Hamidreza Alikhani, Sylvain Flamant, Jin Kim, Arjun Mukherjee",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14285"" target=""_blank"">2409.14285</a>",,2025-12-03 22:39:25
UTrace: Poisoning Forensics for Private Collaborative Learning,"Evan Rose, Hidde Lycklama, Harsh Chaudhari, Anwar Hithnawi, Alina Oprea",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15126"" target=""_blank"">2409.15126</a>",,2025-12-03 22:39:25
When Witnesses Defend: A Witness Graph Topological Layer for Adversarial Graph Learning,"Naheed Anjum Arafat, Debabrota Basu, Yulia Gel, Yuzhou Chen",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14161"" target=""_blank"">2409.14161</a>",,2025-12-03 22:39:25
Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation,"G M Shahariar, Jia Chen, Jiachen Li, Yue Dong",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.15381"" target=""_blank"">2409.15381</a>","<a href=""https://github.com/shahariar-shibli/Adversarial-Attack-on-POS-Tags"" target=""_blank"">shahariar-shibli</a>",2025-12-03 22:39:25
PathSeeker: Exploring LLM Security Vulnerabilities with a Reinforcement Learning-Based Jailbreak Approach,"Zhihao Lin, Wei Ma, Mingyi Zhou, Yanjie Zhao, Haoyu Wang, Yang Liu, Jun Wang, Li Li",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14177"" target=""_blank"">2409.14177</a>",,2025-12-03 22:39:25
Evaluating the Performance and Robustness of LLMs in Materials Science Q&A and Property Predictions,"Hongchen Wang, Kangming Li, Scott Ramsay, Yao Fehlis, Edward Kim, Jason Hattrick-Simpers",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14572"" target=""_blank"">2409.14572</a>",,2025-12-03 22:39:25
Enhancing LLM-based Autonomous Driving Agents to Mitigate Perception Attacks,"Ruoyu Song, Muslum Ozgur Ozmen, Hyungsub Kim, Antonio Bianchi, Z. Berkay Celik",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14488"" target=""_blank"">2409.14488</a>",,2025-12-03 22:39:25
SDBA: A Stealthy and Long-Lasting Durable Backdoor Attack in Federated Learning,"Minyeong Choe, Cheolhee Park, Changho Seo, Hyunil Kim",arXiv,2024-09,"<a href=""http://arxiv.org/abs/2409.14805"" target=""_blank"">2409.14805</a>",,2025-12-03 22:39:25
Ensemble everything everywhere: Multi-scale aggregation for adversarial robustness,"Stanislav Fort, Balaji Lakshminarayanan",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05446"" target=""_blank"">2408.05446</a>",,2025-12-03 22:39:25
Kov: Transferable and Naturalistic Black-Box LLM Attacks using Markov Decision Processes and Tree Search,Robert J. Moss,arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08899"" target=""_blank"">2408.08899</a>","<a href=""https://github.com/sisl/Kov.jl"" target=""_blank"">sisl</a>",2025-12-03 22:39:25
ReToMe-VA: Recursive Token Merging for Video Diffusion-based Unrestricted Adversarial Attack,"Ziyi Gao, Kai Chen, Zhipeng Wei, Tingshu Mou, Jingjing Chen, Zhiyu Tan, Hao Li, Yu-Gang Jiang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05479"" target=""_blank"">2408.05479</a>",,2025-12-03 22:39:25
StealthDiffusion: Towards Evading Diffusion Forensic Detection through Diffusion Model,"Ziyin Zhou, Ke Sun, Zhongxi Chen, Huafeng Kuang, Xiaoshuai Sun, Rongrong Ji",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05669"" target=""_blank"">2408.05669</a>",,2025-12-03 22:39:25
PointNCBW: Towards Dataset Ownership Verification for Point Clouds via Negative Clean-label Backdoor Watermark,"Cheng Wei, Yang Wang, Kuofeng Gao, Shuo Shao, Yiming Li, Zhibo Wang, Zhan Qin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05500"" target=""_blank"">2408.05500</a>",,2025-12-03 22:39:25
Modeling Electromagnetic Signal Injection Attacks on Camera-based Smart Systems: Applications and Mitigation,"Youqian Zhang, Michael Cheung, Chunxi Yang, Xinwei Zhai, Zitong Shen, Xinyu Ji, Eugene Y. Fu, Sze-Yiu Chau, Xiapu Luo",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05124"" target=""_blank"">2408.05124</a>",,2025-12-03 22:39:25
A Jailbroken GenAI Model Can Cause Substantial Harm: GenAI-powered Applications are Vulnerable to PromptWares,"Stav Cohen, Ron Bitton, Ben Nassi",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05061"" target=""_blank"">2408.05061</a>",,2025-12-03 22:39:25
Rag and Roll: An End-to-End Evaluation of Indirect Prompt Manipulations in LLM-based Application Frameworks,"Stefano Gianluca De, Lea Schönherr, Giancarlo Pellegrino",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05025"" target=""_blank"">2408.05025</a>",,2025-12-03 22:39:25
TrajFM: A Vehicle Trajectory Foundation Model for Region and Task Transferability,"Yan Lin, Tonglong Wei, Zeyu Zhou, Haomin Wen, Jilin Hu, Shengnan Guo, Youfang Lin, Huaiyu Wan",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15251"" target=""_blank"">2408.15251</a>",,2025-12-03 22:39:25
Constructing Adversarial Examples for Vertical Federated Learning: Optimal Client Corruption through Multi-Armed Bandit,"Duanyi Yao, Songze Li, Ye Xue, Jin Liu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04310"" target=""_blank"">2408.04310</a>",,2025-12-03 22:39:25
Adversarially Robust Industrial Anomaly Detection Through Diffusion Model,"Yuanpu Cao, Lu Lin, Jinghui Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04839"" target=""_blank"">2408.04839</a>",,2025-12-03 22:39:25
LaFA: Latent Feature Attacks on Non-negative Matrix Factorization,"Minh Vu, Ben Nebgen, Erik Skau, Geigh Zollicoffer, Juan Castorena, Kim Rasmussen, Boian Alexandrov, Manish Bhattarai",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03909"" target=""_blank"">2408.03909</a>",,2025-12-03 22:39:25
Eliminating Backdoors in Neural Code Models via Trigger Inversion,"Weisong Sun, Yuchen Chen, Chunrong Fang, Yebo Feng, Yuan Xiao, An Guo, Quanjun Zhang, Yang Liu, Baowen Xu, Zhenyu Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04683"" target=""_blank"">2408.04683</a>",,2025-12-03 22:39:25
Improving Network Interpretability via Explanation Consistency Evaluation,"Hefeng Wu, Hao Jiang, Keze Wang, Ziyi Tang, Xianghuan He, Liang Lin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04600"" target=""_blank"">2408.04600</a>",,2025-12-03 22:39:25
Unveiling Hidden Visual Information: A Reconstruction Attack Against Adversarial Visual Information Hiding,"Jonggyu Jang, Hyeonsu Lyu, Seongjin Hwang, Hyun Jong Yang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04261"" target=""_blank"">2408.04261</a>",,2025-12-03 22:39:25
"Towards Resilient and Efficient LLMs: A Comparative Study of Efficiency, Performance, and Adversarial Robustness","Xiaojing Fan, Chunliang Tao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04585"" target=""_blank"">2408.04585</a>",,2025-12-03 22:39:25
Stability Analysis of Equivariant Convolutional Representations Through The Lens of Equivariant Multi-layered CKNs,Soutrik Roy Chowdhury,arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04277"" target=""_blank"">2408.04277</a>",,2025-12-03 22:39:25
h4rm3l: A Dynamic Benchmark of Composable Jailbreak Attacks for LLM Safety Assessment,"Moussa Koulako Bala Doumbouya, Ananjan Nandi, Gabriel Poesia, Davide Ghilardi, Anna Goldie, Federico Bianchi, Dan Jurafsky, Christopher D. Manning",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04811"" target=""_blank"">2408.04811</a>",,2025-12-03 22:39:25
VideoQA in the Era of LLMs: An Empirical Study,"Junbin Xiao, Nanxin Huang, Hangyu Qin, Dongyang Li, Yicong Li, Fengbin Zhu, Zhulin Tao, Jianxing Yu, Liang Lin, Tat-Seng Chua, Angela Yao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04223"" target=""_blank"">2408.04223</a>",,2025-12-03 22:39:25
Enhancing Output Diversity Improves Conjugate Gradient-based Adversarial Attacks,"Keiichiro Yamamura, Issa Oe, Hiroki Ishikura, Katsuki Fujisawa",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03972"" target=""_blank"">2408.03972</a>","<a href=""https://github.com/yamamura-k/ReACG"" target=""_blank"">yamamura-k</a>",2025-12-03 22:39:25
EdgeShield: A Universal and Efficient Edge Computing Framework for Robust AI,"Duo Zhong, Bojing Li, Xiang Chen, Chenchen Liu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04181"" target=""_blank"">2408.04181</a>",,2025-12-03 22:39:25
MORTAR: A Model-based Runtime Action Repair Framework for AI-enabled Cyber-Physical Systems,"Renzhi Wang, Zhehua Zhou, Jiayang Song, Xuan Xie, Xiaofei Xie, Lei Ma",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03892"" target=""_blank"">2408.03892</a>",,2025-12-03 22:39:25
EnJa: Ensemble Jailbreak on Large Language Models,"Jiahao Zhang, Zilong Wang, Ruofan Wang, Xingjun Ma, Yu-Gang Jiang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03603"" target=""_blank"">2408.03603</a>",,2025-12-03 22:39:25
Evaluating Text Classification Robustness to Part-of-Speech Adversarial Examples,"Anahita Samadi, Allison Sullivan",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08374"" target=""_blank"">2408.08374</a>",,2025-12-03 22:39:25
Classifier Guidance Enhances Diffusion-based Adversarial Purification by Preserving Predictive Information,"Mingkun Zhang, Jianing Li, Wei Chen, Jiafeng Guo, Xueqi Cheng",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05900"" target=""_blank"">2408.05900</a>",,2025-12-03 22:39:25
TabularBench: Benchmarking Adversarial Robustness for Tabular Deep Learning in Real-world Use-cases,"Thibault Simonetto, Salah Ghamizi, Maxime Cordy",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07579"" target=""_blank"">2408.07579</a>","<a href=""https://github.com/serval-uni-lu/tabularbench"" target=""_blank"">serval-uni-lu</a>",2025-12-03 22:39:25
FDI: Attack Neural Code Generation Systems through User Feedback Channel,"Zhensu Sun, Xiaoning Du, Xiapu Luo, Fu Song, David Lo, Li Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.04194"" target=""_blank"">2408.04194</a>",,2025-12-03 22:39:25
DFT-Based Adversarial Attack Detection in MRI Brain Imaging: Enhancing Diagnostic Accuracy in Alzheimer's Case Studies,"Mohammad Hossein Najafi, Mohammad Morsali, Mohammadmahdi Vahediahmar, Saeed Bagheri Shouraki",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08489"" target=""_blank"">2408.08489</a>",,2025-12-03 22:39:25
A Multi-task Adversarial Attack Against Face Authentication,"Hanrui Wang, Shuo Wang, Cunjian Chen, Massimo Tistarelli, Zhe Jin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08205"" target=""_blank"">2408.08205</a>",,2025-12-03 22:39:25
Unlearnable Examples Detection via Iterative Filtering,"Yi Yu, Qichen Zheng, Siyuan Yang, Wenhan Yang, Jun Liu, Shijian Lu, Yap-Peng Tan, Kwok-Yan Lam, Alex Kot",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08143"" target=""_blank"">2408.08143</a>",,2025-12-03 22:39:25
A Survey of Trojan Attacks and Defenses to Deep Neural Networks,"Lingxin Jin, Xianyu Wen, Wei Jiang, Jinyu Zhan",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08920"" target=""_blank"">2408.08920</a>",,2025-12-03 22:39:25
Prefix Guidance: A Steering Wheel for Large Language Models to Defend Against Jailbreak Attacks,"Jiawei Zhao, Kejiang Chen, Xiaojian Yuan, Weiming Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08924"" target=""_blank"">2408.08924</a>",,2025-12-03 22:39:25
$\textit{MMJ-Bench}$: A Comprehensive Study on Jailbreak Attacks and Defenses for Multimodal Large Language Models,"Fenghua Weng, Yue Xu, Chengyan Fu, Wenjie Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08464"" target=""_blank"">2408.08464</a>",,2025-12-03 22:39:25
Random Gradient Masking as a Defensive Measure to Deep Leakage in Federated Learning,"Joon Kim, Sejin Park",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08430"" target=""_blank"">2408.08430</a>",,2025-12-03 22:39:25
A Robust Multi-Stage Intrusion Detection System for In-Vehicle Network Security using Hierarchical Federated Learning,"Muzun Althunayyan, Amir Javed, Omer Rana",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08433"" target=""_blank"">2408.08433</a>",,2025-12-03 22:39:25
Enhancing Adversarial Attacks via Parameter Adaptive Adversarial Attack,"Zhibo Jin, Jiayu Zhang, Zhiyu Zhu, Chenyu Zhang, Jiahao Huang, Jianlong Zhou, Fang Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07733"" target=""_blank"">2408.07733</a>",,2025-12-03 22:39:25
Robust Active Learning (RoAL): Countering Dynamic Adversaries in Active Learning with Elastic Weight Consolidation,"Ricky Maulana Fajri, Yulong Pei, Lu Yin, Mykola Pechenizkiy",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07364"" target=""_blank"">2408.07364</a>",,2025-12-03 22:39:25
Improving Adversarial Transferability with Neighbourhood Gradient Information,"Haijing Guo, Jiafeng Wang, Zhaoyu Chen, Kaixun Jiang, Lingyi Hong, Pinxue Guo, Jinglun Li, Wenqiang Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.05745"" target=""_blank"">2408.05745</a>",,2025-12-03 22:39:25
Achieving Data Efficient Neural Networks with Hybrid Concept-based Models,"Tobias A. Opsahl, Vegard Antun",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07438"" target=""_blank"">2408.07438</a>",,2025-12-03 22:39:25
Sonic: Fast and Transferable Data Poisoning on Clustering Algorithms,"Francesco Villani, Dario Lazzaro, Antonio Emanuele Cinà, Matteo Dell'Amico, Battista Biggio, Fabio Roli",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07558"" target=""_blank"">2408.07558</a>",,2025-12-03 22:39:25
BadMerging: Backdoor Attacks Against Model Merging,"Jinghuai Zhang, Jianfeng Chi, Zheng Li, Kunlin Cai, Yang Zhang, Yuan Tian",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07362"" target=""_blank"">2408.07362</a>",,2025-12-03 22:39:25
BAPLe: Backdoor Attacks on Medical Foundational Models using Prompt Learning,"Asif Hanif, Fahad Shamshad, Muhammad Awais, Muzammal Naseer, Fahad Shahbaz Khan, Karthik Nandakumar, Salman Khan, Rao Muhammad Anwer",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07440"" target=""_blank"">2408.07440</a>","<a href=""https://asif-hanif.github.io/baple/"" target=""_blank"">baple</a>",2025-12-03 22:39:25
DePatch: Towards Robust Adversarial Patch for Evading Person Detectors in the Real World,"Jikang Cheng, Ying Zhang, Zhongyuan Wang, Zou Qin, Chen Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.06625"" target=""_blank"">2408.06625</a>",,2025-12-03 22:39:25
Robust Black-box Testing of Deep Neural Networks using Co-Domain Coverage,"Aishwarya Gupta, Indranil Saha, Piyush Rai",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.06766"" target=""_blank"">2408.06766</a>",,2025-12-03 22:39:25
Imagen 3,"Imagen-Team-Google, :, Jason Baldridge, Jakob Bauer, Mukul Bhutani, Nicole Brichtova, Andrew Bunner, Lluis Castrejon, Kelvin Chan, Yichang Chen, Sander Dieleman, Yuqing Du, Zach Eaton-Rosen, Hongliang Fei, Freitas Nando de, Yilin Gao, Evgeny Gladchenko, Sergio Gómez Colmenarejo, Mandy Guo, Alex Haig, Will Hawkins, Hexiang Hu, Huilian Huang, Tobenna Peter Igwe, Christos Kaplanis, Siavash Khodadadeh, Yelin Kim, Ksenia Konyushkova, Karol Langner, Eric Lau, Rory Lawton, Shixin Luo, Soňa Mokrá, Henna Nandwani, Yasumasa Onoe, Aäron van den Oord, Zarana Parekh, Jordi Pont-Tuset, Hang Qi, Rui Qian, Deepak Ramachandran, Poorva Rane, Abdullah Rashwan, Ali Razavi, Robert Riachi, Hansa Srinivasan, Srivatsan Srinivasan, Robin Strudel, Benigno Uria, Oliver Wang, Su Wang, Austin Waters, Chris Wolff, Auriel Wright, Zhisheng Xiao, Hao Xiong, Keyang Xu, Zee Marc van, Junlin Zhang, Katie Zhang, Wenlei Zhou, Konrad Zolna, Ola Aboubakar, Canfer Akbulut, Oscar Akerlund, Isabela Albuquerque, Nina Anderson, Marco Andreetto, Lora Aroyo, Ben Bariach, David Barker, Sherry Ben, Dana Berman, Courtney Biles, Irina Blok, Pankil Botadra, Jenny Brennan, Karla Brown, John Buckley, Rudy Bunel, Elie Bursztein, Christina Butterfield, Ben Caine, Viral Carpenter, Norman Casagrande, Ming-Wei Chang, Solomon Chang, Shamik Chaudhuri, Tony Chen, John Choi, Dmitry Churbanau, Nathan Clement, Matan Cohen, Forrester Cole, Mikhail Dektiarev, Vincent Du, Praneet Dutta, Tom Eccles, Ndidi Elue, Ashley Feden, Shlomi Fruchter, Frankie Garcia, Roopal Garg, Weina Ge, Ahmed Ghazy, Bryant Gipson, Andrew Goodman, Dawid Górny, Sven Gowal, Khyatti Gupta, Yoni Halpern, Yena Han, Susan Hao, Jamie Hayes, Jonathan Heek, Amir Hertz, Ed Hirst, Emiel Hoogeboom, Tingbo Hou, Heidi Howard, Mohamed Ibrahim, Dirichi Ike-Njoku, Joana Iljazi, Vlad Ionescu, William Isaac, Reena Jana, Gemma Jennings, Donovon Jenson, Xuhui Jia, Kerry Jones, Xiaoen Ju, Ivana Kajic, Christos Kaplanis, Burcu Karagol Ayan, Jacob Kelly, Suraj Kothawade, Christina Kouridi, Ira Ktena, Jolanda Kumakaw, Dana Kurniawan, Dmitry Lagun, Lily Lavitas, Jason Lee, Tao Li, Marco Liang, Maggie Li-Calis, Yuchi Liu, Javier Lopez Alberca, Matthieu Kim Lorrain, Peggy Lu, Kristian Lum, Yukun Ma, Chase Malik, John Mellor, Thomas Mensink, Inbar Mosseri, Tom Murray, Aida Nematzadeh, Paul Nicholas, Signe Nørly, João Gabriel Oliveira, Guillermo Ortiz-Jimenez, Michela Paganini, Tom Le Paine, Roni Paiss, Alicia Parrish, Anne Peckham, Vikas Peswani, Igor Petrovski, Tobias Pfaff, Alex Pirozhenko, Ryan Poplin, Utsav Prabhu, Yuan Qi, Matthew Rahtz, Cyrus Rashtchian, Charvi Rastogi, Amit Raul, Ali Razavi, Sylvestre-Alvise Rebuffi, Susanna Ricco, Felix Riedel, Dirk Robinson, Pankaj Rohatgi, Bill Rosgen, Sarah Rumbley, Moonkyung Ryu, Anthony Salgado, Tim Salimans, Sahil Singla, Florian Schroff, Candice Schumann, Tanmay Shah, Eleni Shaw, Gregory Shaw, Brendan Shillingford, Kaushik Shivakumar, Dennis Shtatnov, Zach Singer, Evgeny Sluzhaev, Valerii Sokolov, Thibault Sottiaux, Florian Stimberg, Brad Stone, David Stutz, Yu-Chuan Su, Eric Tabellion, Shuai Tang, David Tao, Kurt Thomas, Gregory Thornton, Andeep Toor, Cristian Udrescu, Aayush Upadhyay, Cristina Vasconcelos, Alex Vasiloff, Andrey Voynov, Amanda Walker, Luyu Wang, Miaosen Wang, Simon Wang, Stanley Wang, Qifei Wang, Yuxiao Wang, Ágoston Weisz, Olivia Wiles, Chenxia Wu, Xingyu Federico Xu, Andrew Xue, Jianbo Yang, Luo Yu, Mete Yurtoglu, Ali Zand, Han Zhang, Jiageng Zhang, Catherine Zhao, Adilet Zhaxybay, Miao Zhou, Shengqi Zhu, Zhenkai Zhu, Dawn Bloxwich, Mahyar Bordbar, Luis C. Cobo, Eli Collins, Shengyang Dai, Tulsee Doshi, Anca Dragan, Douglas Eck, Demis Hassabis, Sissie Hsiao, Tom Hume, Koray Kavukcuoglu, Helen King, Jack Krawczyk, Yeqing Li, Kathy Meier-Hellstern, Andras Orban, Yury Pinsky, Amar Subramanya, Oriol Vinyals, Ting Yu, Yori Zwols",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.07009"" target=""_blank"">2408.07009</a>",,2025-12-03 22:39:25
Towards Adversarial Robustness via Debiased High-Confidence Logit Alignment,"Kejia Zhang, Juanjuan Weng, Zhiming Luo, Shaozi Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.06079"" target=""_blank"">2408.06079</a>",,2025-12-03 22:39:25
Fooling SHAP with Output Shuffling Attacks,"Jun Yuan, Aritra Dasgupta",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.06509"" target=""_blank"">2408.06509</a>",,2025-12-03 22:39:25
Understanding Byzantine Robustness in Federated Learning with A Black-box Server,"Fangyuan Zhao, Yuexiang Xie, Xuebin Ren, Bolin Ding, Shusen Yang, Yaliang Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.06042"" target=""_blank"">2408.06042</a>","<a href=""https://github.com/alibaba/FederatedScope/tree/Byzantine_attack_defense"" target=""_blank"">tree</a>",2025-12-03 22:39:25
MTDSense: AI-Based Fingerprinting of Moving Target Defense Techniques in Software-Defined Networking,"Tina Moghaddam, Guowei Yang, Chandra Thapa, Seyit Camtepe, Dan Dongseong Kim",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03758"" target=""_blank"">2408.03758</a>",,2025-12-03 22:39:25
On Feasibility of Intent Obfuscating Attacks,"Zhaobin Li, Patrick Shafto",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02674"" target=""_blank"">2408.02674</a>",,2025-12-03 22:39:25
Hard to Explain: On the Computational Hardness of In-Distribution Model Interpretation,"Guy Amir, Shahaf Bassan, Guy Katz",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03915"" target=""_blank"">2408.03915</a>",,2025-12-03 22:39:25
ADBM: Adversarial diffusion bridge model for reliable adversarial purification,"Xiao Li, Wenxuan Sun, Huanran Chen, Qiongxiu Li, Yining Liu, Yingzhe He, Jie Shi, Xiaolin Hu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00315"" target=""_blank"">2408.00315</a>",,2025-12-03 22:39:25
EmoBack: Backdoor Attacks Against Speaker Identification Using Emotional Prosody,"Coen Schoof, Stefanos Koffas, Mauro Conti, Stjepan Picek",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01178"" target=""_blank"">2408.01178</a>",,2025-12-03 22:39:25
Interpreting Global Perturbation Robustness of Image Models using Axiomatic Spectral Importance Decomposition,"Róisín Luo, James McDermott, Colm O'Riordan",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01139"" target=""_blank"">2408.01139</a>",,2025-12-03 22:39:25
Assessing Robustness of Machine Learning Models using Covariate Perturbations,"Arun Prakash R, Anwesha Bhattacharyya, Joel Vaughan, Vijayan N. Nair",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01300"" target=""_blank"">2408.01300</a>",,2025-12-03 22:39:25
Certifiably Robust Encoding Schemes,"Aman Saxena, Tom Wollschläger, Nicola Franco, Jeanette Miriam Lorenz, Stephan Günnemann",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01200"" target=""_blank"">2408.01200</a>",,2025-12-03 22:39:25
Hallu-PI: Evaluating Hallucination in Multi-modal Large Language Models within Perturbed Inputs,"Peng Ding, Jingyu Wu, Jun Kuang, Dan Ma, Xuezhi Cao, Xunliang Cai, Shi Chen, Jiajun Chen, Shujian Huang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01355"" target=""_blank"">2408.01355</a>","<a href=""https://github.com/NJUNLP/Hallu-PI"" target=""_blank"">NJUNLP</a>",2025-12-03 22:39:25
Blockchain Amplification Attack,"Taro Tsuchiya, Liyi Zhou, Kaihua Qin, Arthur Gervais, Nicolas Christin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01508"" target=""_blank"">2408.01508</a>",,2025-12-03 22:39:25
Autonomous LLM-Enhanced Adversarial Attack for Text-to-Motion,"Honglei Miao, Fan Ma, Ruijie Quan, Kun Zhan, Yi Yang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00352"" target=""_blank"">2408.00352</a>",,2025-12-03 22:39:25
OTAD: An Optimal Transport-Induced Robust Model for Agnostic Adversarial Attack,"Kuo Gai, Sicong Wang, Shihua Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00329"" target=""_blank"">2408.00329</a>",,2025-12-03 22:39:25
Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks,"Angona Biswas, MD Abdullah Al Nasim, Kishor Datta Gupta, Roy George, Abdur Rashid",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00348"" target=""_blank"">2408.00348</a>",,2025-12-03 22:39:25
CERT-ED: Certifiably Robust Text Classification for Edit Distance,"Zhuoqun Huang, Neil G Marchant, Olga Ohrimenko, Benjamin I. P. Rubinstein",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00728"" target=""_blank"">2408.00728</a>",,2025-12-03 22:39:25
Discrete Randomized Smoothing Meets Quantum Computing,"Tom Wollschläger, Aman Saxena, Nicola Franco, Jeanette Miriam Lorenz, Stephan Günnemann",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00895"" target=""_blank"">2408.00895</a>",,2025-12-03 22:39:25
Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models,"Shachi H Kumar, Saurav Sahay, Sahisnu Mazumder, Eda Okur, Ramesh Manuvinakurike, Nicole Beckage, Hsuan Su, Hung-yi Lee, Lama Nachman",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03907"" target=""_blank"">2408.03907</a>",,2025-12-03 22:39:25
Adversarial Text Rewriting for Text-aware Recommender Systems,"Sejoon Oh, Gaurav Verma, Srijan Kumar",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00312"" target=""_blank"">2408.00312</a>",,2025-12-03 22:39:25
MAARS: Multi-Rate Attack-Aware Randomized Scheduling for Securing Real-time Systems,"Arkaprava Sain, Sunandan Adhikary, Ipsita Koley, Soumyajit Dey",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00341"" target=""_blank"">2408.00341</a>",,2025-12-03 22:39:25
"Pathway to Secure and Trustworthy ZSM for LLMs: Attacks, Defense, and Opportunities","Sunder Ali Khowaja, Parus Khuwaja, Kapal Dev, Hussam Al Hamadi, Engin Zeydan",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00722"" target=""_blank"">2408.00722</a>",,2025-12-03 22:39:25
On the Perturbed States for Transformed Input-robust Reinforcement Learning,"Tung M. Luu, Haeyong Kang, Tri Ton, Thanh Nguyen, Chang D. Yoo",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00023"" target=""_blank"">2408.00023</a>",,2025-12-03 22:39:25
Certifying Robustness of Learning-Based Keypoint Detection and Pose Estimation Methods,"Xusheng Luo, Tianhao Wei, Simin Liu, Ziwei Wang, Luis Mattei-Mendez, Taylor Loper, Joshua Neighbor, Casidhe Hutchison, Changliu Liu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00117"" target=""_blank"">2408.00117</a>",,2025-12-03 22:39:25
Vera Verto: Multimodal Hijacking Attack,"Minxing Zhang, Ahmed Salem, Michael Backes, Yang Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.00129"" target=""_blank"">2408.00129</a>",,2025-12-03 22:39:25
Visual-Friendly Concept Protection via Selective Adversarial Perturbations,"Xiaoyue Mi, Fan Tang, Juan Cao, Peng Li, Yang Liu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08518"" target=""_blank"">2408.08518</a>",,2025-12-03 22:39:25
Taxonomy Driven Fast Adversarial Training,"Kun Tong, Chengze Jiang, Jie Gui, Yuan Cao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03944"" target=""_blank"">2408.03944</a>","<a href=""https://github.com/bookman233/TDAT"" target=""_blank"">bookman233</a>",2025-12-03 22:39:25
Explainable AI-based Intrusion Detection System for Industry 5,"Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03335"" target=""_blank"">2408.03335</a>",,2025-12-03 22:39:25
Transferable Adversarial Facial Images for Privacy Protection,"Minghui Li, Jiangxiong Wang, Hao Zhang, Ziqi Zhou, Shengshan Hu, Xiaobing Pei",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01428"" target=""_blank"">2408.01428</a>",,2025-12-03 22:39:25
Trustworthy Machine Learning under Social and Adversarial Data Sources,Han Shao,arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01596"" target=""_blank"">2408.01596</a>",,2025-12-03 22:39:25
Guardians of Image Quality: Benchmarking Defenses Against Adversarial Attacks on Image Quality Metrics,"Alexander Gushchin, Khaled Abud, Georgii Bychkov, Ekaterina Shumitskaya, Anna Chistyakova, Sergey Lavrushkin, Bader Rasheed, Kirill Malyshev, Dmitriy Vatolin, Anastasia Antsiferova",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01541"" target=""_blank"">2408.01541</a>",,2025-12-03 22:39:25
Downstream Transfer Attack: Adversarial Attacks on Downstream Models with Pre-trained Vision Transformers,"Weijie Zheng, Xingjun Ma, Hanxun Huang, Zuxuan Wu, Yu-Gang Jiang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01705"" target=""_blank"">2408.01705</a>",,2025-12-03 22:39:25
Joint Universal Adversarial Perturbations with Interpretations,"Liang-bo Ning, Zeyu Dai, Wenqi Fan, Jingran Su, Chao Pan, Luning Wang, Qing Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01715"" target=""_blank"">2408.01715</a>",,2025-12-03 22:39:25
Adversarial Robustness of Open-source Text Classification Models and Fine-Tuning Chains,"Hao Qin, Mingyang Li, Junjie Wang, Qing Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02963"" target=""_blank"">2408.02963</a>",,2025-12-03 22:39:25
Sample-agnostic Adversarial Perturbation for Vision-Language Pre-training Models,"Haonan Zheng, Wen Jiang, Xinyang Deng, Wenrui Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02980"" target=""_blank"">2408.02980</a>","<a href=""https://github.com/LibertazZ/MUAP"" target=""_blank"">LibertazZ</a>",2025-12-03 22:39:25
Simple Perturbations Subvert Ethereum Phishing Transactions Detection: An Empirical Analysis,"Ahod Alghureid, David Mohaisen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03441"" target=""_blank"">2408.03441</a>",,2025-12-03 22:39:25
Attacks and Defenses for Generative Diffusion Models: A Comprehensive Survey,"Vu Tuan Truong, Luan Ba Dang, Long Bao Le",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03400"" target=""_blank"">2408.03400</a>",,2025-12-03 22:39:25
A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems,"Wenxiao Zhang, Xiangrui Kong, Conan Dewitt, Thomas Braunl, Jin B. Hong",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.03515"" target=""_blank"">2408.03515</a>",,2025-12-03 22:39:25
On the Robustness of Malware Detectors to Adversarial Samples,"Muhammad Salman, Benjamin Zi Hao Zhao, Hassan Jameel Asghar, Muhammad Ikram, Sidharth Kaushik, Mohamed Ali Kaafar",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02310"" target=""_blank"">2408.02310</a>",,2025-12-03 22:39:25
Mitigating Malicious Attacks in Federated Learning via Confidence-aware Defense,"Qilei Li, Ahmed M. Abdelmoniem",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02813"" target=""_blank"">2408.02813</a>",,2025-12-03 22:39:25
Black-Box Adversarial Attacks on LLM-Based Code Completion,"Slobodan Jenko, Niels Mündler, Jingxuan He, Mark Vero, Martin Vechev",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02509"" target=""_blank"">2408.02509</a>",,2025-12-03 22:39:25
SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models,"Muxi Diao, Rumei Li, Shiyang Liu, Guogang Liao, Jingang Wang, Xunliang Cai, Weiran Xu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02632"" target=""_blank"">2408.02632</a>","<a href=""https://SEAS-LLM.github.io/"" target=""_blank"">SEAS-LLM.github.io</a>",2025-12-03 22:39:25
Pre-trained Encoder Inference: Revealing Upstream Encoders In Downstream Machine Learning Services,"Shaopeng Fu, Xuexue Sun, Ke Qing, Tianhang Zheng, Di Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02814"" target=""_blank"">2408.02814</a>","<a href=""https://github.com/fshp971/encoder-inference"" target=""_blank"">fshp971</a>",2025-12-03 22:39:25
Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models,"Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, Haoyang Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02416"" target=""_blank"">2408.02416</a>","<a href=""https://github.com/liangzid/PromptExtractionEval"" target=""_blank"">liangzid</a>",2025-12-03 22:39:25
Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models? (8%),"Mohammad Bahrami Karkevandi, Nishant Vishwamitra, Peyman Najafirad",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02651"" target=""_blank"">2408.02651</a>",,2025-12-03 22:39:25
RCDM: Enabling Robustness for Conditional Diffusion Model,"Weifeng Xu, Xiang Zhu, Xiaoyong Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02710"" target=""_blank"">2408.02710</a>",,2025-12-03 22:39:25
Compromising Embodied Agents with Contextual Backdoor Attacks,"Aishan Liu, Yuguang Zhou, Xianglong Liu, Tianyuan Zhang, Siyuan Liang, Jiakai Wang, Yanjun Pu, Tianlin Li, Junqi Zhang, Wenbo Zhou, Qing Guo, Dacheng Tao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02882"" target=""_blank"">2408.02882</a>",,2025-12-03 22:39:25
AdvQDet: Detecting Query-Based Adversarial Attacks with Adversarial Contrastive Prompt Tuning,"Xin Wang, Kai Chen, Xingjun Ma, Zhineng Chen, Jingjing Chen, Yu-Gang Jiang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01978"" target=""_blank"">2408.01978</a>","<a href=""https://github.com/xinwong/AdvQDet"" target=""_blank"">xinwong</a>",2025-12-03 22:39:25
A Survey and Evaluation of Adversarial Attacks for Object Detection,"Khoi Nguyen Tiet Nguyen, Wenyu Zhang, Kangkang Lu, Yuhuan Wu, Xingjian Zheng, Hui Li Tan, Liangli Zhen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01934"" target=""_blank"">2408.01934</a>",,2025-12-03 22:39:25
Label Augmentation for Neural Networks Robustness,"Fatemeh Amerehi, Patrick Healy",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01977"" target=""_blank"">2408.01977</a>",,2025-12-03 22:39:25
Model Hijacking Attack in Federated Learning,"Zheng Li, Siyuan Wu, Ruichuan Chen, Paarijaat Aditya, Istemi Ekin Akkus, Manohar Vanga, Min Zhang, Hao Li, Yang Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02131"" target=""_blank"">2408.02131</a>",,2025-12-03 22:39:25
Robustness of Watermarking on Text-to-Image Diffusion Models,"Xiaodong Wu, Xiangman Li, Jianbing Ni",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02035"" target=""_blank"">2408.02035</a>",,2025-12-03 22:39:25
FovEx: Human-inspired Explanations for Vision Transformers and Convolutional Neural Networks,"Mahadev Prasad Panda, Matteo Tiezzi, Martina Vilas, Gemma Roig, Bjoern M. Eskofier, Dario Zanca",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.02123"" target=""_blank"">2408.02123</a>",,2025-12-03 22:39:25
ALIF: Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms using Linguistic Features,"Peng Cheng, Yuwei Wang, Peng Huang, Zhongjie Ba, Xiaodong Lin, Feng Lin, Li Lu, Kui Ren",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.01808"" target=""_blank"">2408.01808</a>",,2025-12-03 22:39:25
Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons,"Binbin Ding, Penghui Yang, Zeqing Ge, Shengjun Huang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08655"" target=""_blank"">2408.08655</a>",,2025-12-03 22:39:25
Efficient Image-to-Image Diffusion Classifier for Adversarial Robustness,"Hefei Mei, Minjing Dong, Chang Xu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08502"" target=""_blank"">2408.08502</a>","<a href=""https://github.com/hfmei/IDC"" target=""_blank"">hfmei</a>",2025-12-03 22:39:25
Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks? (83%),"Zhongjian Zhang, Xiao Wang, Huichi Zhou, Yue Yu, Mengmei Zhang, Cheng Yang, Chuan Shi",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08685"" target=""_blank"">2408.08685</a>",,2025-12-03 22:39:25
A Practical Trigger-Free Backdoor Attack on Neural Networks,"Jiahao Wang, Xianglong Zhang, Xiuzhen Cheng, Pengfei Hu, Guoming Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11444"" target=""_blank"">2408.11444</a>",,2025-12-03 22:39:25
Investigating the Effectiveness of Bayesian Spam Filters in Detecting LLM-modified Spam Mails,"Malte Josten, Torben Weis",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14293"" target=""_blank"">2408.14293</a>",,2025-12-03 22:39:25
On the Robustness of Kolmogorov-Arnold Networks: An Adversarial Perspective,"Tal Alter, Raz Lapid, Moshe Sipper",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13809"" target=""_blank"">2408.13809</a>",,2025-12-03 22:39:25
HTS-Attack: Heuristic Token Search for Jailbreaking Text-to-Image Models,"Sensen Gao, Xiaojun Jia, Yihao Huang, Ranjie Duan, Jindong Gu, Yang Bai, Yang Liu, Qing Guo",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13896"" target=""_blank"">2408.13896</a>",,2025-12-03 22:39:25
TF-Attack: Transferable and Fast Adversarial Attacks on Large Language Models,"Zelin Li, Kehai Chen, Lemao Liu, Xuefeng Bai, Mingming Yang, Yang Xiang, Min Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13985"" target=""_blank"">2408.13985</a>",,2025-12-03 22:39:25
Sample-Independent Federated Learning Backdoor Attack in Speaker Recognition,"Weida Xu, Yang Xu, Sicong Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13849"" target=""_blank"">2408.13849</a>",,2025-12-03 22:39:25
Generalization of Graph Neural Networks is Robust to Model Mismatch,"Zhiyang Wang, Juan Cervino, Alejandro Ribeiro",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13878"" target=""_blank"">2408.13878</a>",,2025-12-03 22:39:25
Probing the Robustness of Vision-Language Pretrained Models: A Multimodal Adversarial Attack Approach,"Jiwei Guan, Tianyu Ding, Longbing Cao, Lei Pan, Chen Wang, Xi Zheng",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13461"" target=""_blank"">2408.13461</a>",,2025-12-03 22:39:25
Evaluating the Robustness of LiDAR-based 3D Obstacles Detection and Its Impacts on Autonomous Driving Systems,"Tri Minh Triet Pham, Bo Yang, Jinqiu Yang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13653"" target=""_blank"">2408.13653</a>",,2025-12-03 22:39:25
Dynamic Label Adversarial Training for Deep Learning Robustness Against Adversarial Attacks,"Zhenyu Liu, Haoran Duan, Huizhi Liang, Yang Long, Vaclav Snasel, Guiseppe Nicosia, Rajiv Ranjan, Varun Ojha",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13102"" target=""_blank"">2408.13102</a>",,2025-12-03 22:39:25
Toward Improving Synthetic Audio Spoofing Detection Robustness via Meta-Learning and Disentangled Training With Adversarial Examples,"Zhenyu Wang, John H. L. Hansen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13341"" target=""_blank"">2408.13341</a>",,2025-12-03 22:39:25
Disentangled Training with Adversarial Examples For Robust Small-footprint Keyword Spotting,"Zhenyu Wang, Li Wan, Biqiao Zhang, Yiteng Huang, Shang-Wen Li, Ming Sun, Xin Lei, Zhaojun Yang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13355"" target=""_blank"">2408.13355</a>",,2025-12-03 22:39:25
Protecting against simultaneous data poisoning attacks,"Neel Alex, Shoaib Ahmed Siddiqui, Amartya Sanyal, David Krueger",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13221"" target=""_blank"">2408.13221</a>",,2025-12-03 22:39:25
Top Score on the Wrong Exam: On Benchmarking in Machine Learning for Vulnerability Detection,"Niklas Risse, Jing Liu, Marcel Böhme",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12986"" target=""_blank"">2408.12986</a>",,2025-12-03 22:39:25
Enhancing Transferability of Adversarial Attacks with GE-AdvGAN+: A Comprehensive Framework for Gradient Editing,"Zhibo Jin, Jiayu Zhang, Zhiyu Zhu, Yuchen Zhang, Jiahao Huang, Jianlong Zhou, Fang Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12673"" target=""_blank"">2408.12673</a>","<a href=""https://github.com/GEAdvGANP"" target=""_blank"">github.com</a>",2025-12-03 22:39:25
Leveraging Information Consistency in Frequency and Spatial Domain for Adversarial Attacks,"Zhibo Jin, Jiayu Zhang, Zhiyu Zhu, Xinyi Wang, Yiyun Huang, Huaming Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12670"" target=""_blank"">2408.12670</a>","<a href=""https://github.com/LMBTough/FSA"" target=""_blank"">LMBTough</a>",2025-12-03 22:39:25
MakeupAttack: Feature Space Black-box Backdoor Attack on Face Recognition via Makeup Transfer,"Ming Sun, Lihua Jing, Zixuan Zhu, Rui Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12312"" target=""_blank"">2408.12312</a>",,2025-12-03 22:39:25
BankTweak: Adversarial Attack against Multi-Object Trackers by Manipulating Feature Banks,"Woojin Shin, Donghwa Kang, Daejin Choi, Brent Kang, Jinkyu Lee, Hyeongboo Baek",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12727"" target=""_blank"">2408.12727</a>",,2025-12-03 22:39:25
On the Credibility of Backdoor Attacks Against Object Detectors in the Physical World,"Bao Gia Doan, Dang Quang Nguyen, Callum Lindquist, Paul Montague, Tamas Abraham, Vel Olivier De, Seyit Camtepe, Salil S. Kanhere, Ehsan Abbasnejad, Damith C. Ranasinghe",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12122"" target=""_blank"">2408.12122</a>",,2025-12-03 22:39:25
BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks on Large Language Models,"Yige Li, Hanxun Huang, Yunhan Zhao, Xingjun Ma, Jun Sun",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12798"" target=""_blank"">2408.12798</a>","<a href=""https://github.com/bboylyg/BackdoorLLM"" target=""_blank"">bboylyg</a>",2025-12-03 22:39:25
Is Generative AI the Next Tactical Cyber Weapon For Threat Actors? Unforeseen Implications of AI Generated Cyber Attacks,"Yusuf Usman, Aadesh Upadhyay, Prashnna Gyawali, Robin Chataut",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12806"" target=""_blank"">2408.12806</a>",,2025-12-03 22:39:25
VALE: A Multimodal Visual and Language Explanation Framework for Image Classifiers using eXplainable AI and Language Models,"Purushothaman Natarajan, Athira Nambiar",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12808"" target=""_blank"">2408.12808</a>",,2025-12-03 22:39:25
Quantifying Psychological Sophistication of Malicious Emails,"Theodore Longtchi, Rosana Montañez Rodriguez, Kora Gwartney, Ekzhin Ear, David P. Azari, Christopher P. Kelley, Shouhuai Xu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12217"" target=""_blank"">2408.12217</a>",,2025-12-03 22:39:25
Query-Efficient Video Adversarial Attack with Stylized Logo,"Duoxun Tang, Yuxin Cao, Xi Xiao, Derui Wang, Sheng Wen, Tianqing Zhu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12099"" target=""_blank"">2408.12099</a>",,2025-12-03 22:39:25
STEREO: Towards Adversarially Robust Concept Erasing from Text-to-Image Generation Models,"Koushik Srivatsan, Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.16807"" target=""_blank"">2408.16807</a>","<a href=""https://github.com/koushiksrivats/robust-concept-erasing"" target=""_blank"">koushiksrivats</a>",2025-12-03 22:39:25
Celtibero: Robust Layered Aggregation for Federated Learning,Borja Molina-Coronado,arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14240"" target=""_blank"">2408.14240</a>",,2025-12-03 22:39:25
2D-Malafide: Adversarial Attacks Against Face Deepfake Detection Systems,"Chiara Galdi, Michele Panariello, Massimiliano Todisco, Nicholas Evans",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14143"" target=""_blank"">2408.14143</a>",,2025-12-03 22:39:25
Fusing Pruned and Backdoored Models: Optimal Transport-based Data-free Backdoor Mitigation,"Weilin Lin, Li Liu, Jianze Li, Hui Xiong",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15861"" target=""_blank"">2408.15861</a>",,2025-12-03 22:39:25
PromptSmooth: Certifying Robustness of Medical Vision-Language Models via Prompt Learning,"Noor Hussein, Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.16769"" target=""_blank"">2408.16769</a>","<a href=""https://github.com/nhussein/promptsmooth"" target=""_blank"">nhussein</a>",2025-12-03 22:39:25
SFR-GNN: Simple and Fast Robust GNNs against Structural Attacks,"Xing Ai, Guanyu Zhu, Yulin Zhu, Yu Zheng, Gaolei Li, Jianhua Li, Kai Zhou",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.16537"" target=""_blank"">2408.16537</a>",,2025-12-03 22:39:25
Evaluating Reliability in Medical DNNs: A Critical Analysis of Feature and Confidence-Based OOD Detection,"Harry Anthony, Konstantinos Kamnitsas",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.17337"" target=""_blank"">2408.17337</a>","<a href=""https://github.com/HarryAnthony/Evaluating_OOD_detection"" target=""_blank"">HarryAnthony</a>",2025-12-03 22:39:25
Instant Adversarial Purification with Adversarial Consistency Distillation,"Chun Tong Lei, Hon Ming Yam, Zhongliang Guo, Chun Pong Lau",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.17064"" target=""_blank"">2408.17064</a>",,2025-12-03 22:39:25
LEVIS: Large Exact Verifiable Input Spaces for Neural Networks,"Mohamad Fares El Hajj Chehade, Brian Wesley Bell, Russell Bent, Hao Zhu, Wenting Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08824"" target=""_blank"">2408.08824</a>",,2025-12-03 22:39:25
Analyzing Inference Privacy Risks Through Gradients in Machine Learning,"Zhuohang Li, Andrew Lowy, Jing Liu, Toshiaki Koike-Akino, Kieran Parsons, Bradley Malin, Ye Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.16913"" target=""_blank"">2408.16913</a>",,2025-12-03 22:39:25
"Tex-ViT: A Generalizable, Robust, Texture-based dual-branch cross-attention deepfake detector","Deepak Dagar, Dinesh Kumar Vishwakarma",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.16892"" target=""_blank"">2408.16892</a>",,2025-12-03 22:39:25
Evaluating Model Robustness Using Adaptive Sparse L0 Regularization,"Weiyou Liu, Zhenyang Li, Weitong Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15702"" target=""_blank"">2408.15702</a>",,2025-12-03 22:39:25
Defending Text-to-image Diffusion Models: Surprising Efficacy of Textual Perturbations Against Backdoor Attacks,"Oscar Chew, Po-Yi Lu, Jayden Lin, Hsuan-Tien Lin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15721"" target=""_blank"">2408.15721</a>","<a href=""https://github.com/oscarchew/t2i-backdoor-defense"" target=""_blank"">oscarchew</a>",2025-12-03 22:39:25
Network transferability of adversarial patches in real-time object detection,"Jens Bayer, Stefan Becker, David Münch, Michael Arens",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15833"" target=""_blank"">2408.15833</a>",,2025-12-03 22:39:25
VFLIP: A Backdoor Defense for Vertical Federated Learning via Identification and Purification,"Yungi Cho, Woorim Han, Miseon Yu, Younghan Lee, Ho Bae, Yunheung Paek",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15591"" target=""_blank"">2408.15591</a>","<a href=""https://github.com/blingcho/VFLIP-esorics24"" target=""_blank"">blingcho</a>",2025-12-03 22:39:25
TART: Boosting Clean Accuracy Through Tangent Direction Guided Adversarial Training,"Bongsoo Yi, Rongjie Lai, Yao Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14728"" target=""_blank"">2408.14728</a>",,2025-12-03 22:39:25
FRACTURED-SORRY-Bench: Framework for Revealing Attacks in Conversational Turns Undermining Refusal Efficacy and Defenses over SORRY-Bench (Automated Multi-shot Jailbreaks),"Aman Priyanshu, Supriti Vijay",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.16163"" target=""_blank"">2408.16163</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defenses in Multivariate Time-Series Forecasting for Smart and Connected Infrastructures,"Pooja Krishan, Rohan Mohapatra, Saptarshi Sengupta",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14875"" target=""_blank"">2408.14875</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness in Android Malware Detection by Reducing the Impact of Spurious Correlations,"Hamid Bostani, Zhengyu Zhao, Veelasha Moonsamy",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.16025"" target=""_blank"">2408.16025</a>",,2025-12-03 22:39:25
Certified Causal Defense with Generalizable Robustness,"Yiran Qiao, Yu Yin, Chen Chen, Jing Ma",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15451"" target=""_blank"">2408.15451</a>",,2025-12-03 22:39:25
Adversarial Manhole: Challenging Monocular Depth Estimation and Semantic Segmentation Models with Patch Attack,"Naufal Suryanto, Andro Aprila Adiputra, Ahmada Yusril Kadiptya, Yongsu Kim, Howon Kim",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14879"" target=""_blank"">2408.14879</a>",,2025-12-03 22:39:25
LLM Defenses Are Not Robust to Multi-Turn Human Jailbreaks Yet,"Nathaniel Li, Ziwen Han, Ian Steneker, Willow Primack, Riley Goodside, Hugh Zhang, Zifan Wang, Cristina Menghini, Summer Yue",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15221"" target=""_blank"">2408.15221</a>",,2025-12-03 22:39:25
Understanding the Effectiveness of Coverage Criteria for Large Language Models: A Special Angle from Jailbreak Attacks,"Shide Zhou, Tianlin Li, Kailong Wang, Yihao Huang, Ling Shi, Yang Liu, Haoyu Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15207"" target=""_blank"">2408.15207</a>",,2025-12-03 22:39:25
Detecting AI Flaws: Target-Driven Attacks on Internal Faults in Language Models,"Yuhao Du, Zhuo Li, Pengyu Cheng, Xiang Wan, Anningzhe Gao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14853"" target=""_blank"">2408.14853</a>",,2025-12-03 22:39:25
SpecGuard: Specification Aware Recovery for Robotic Autonomous Vehicles from Physical Attacks,"Pritam Dash, Ethan Chan, Karthik Pattabiraman",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15200"" target=""_blank"">2408.15200</a>",,2025-12-03 22:39:25
EmoAttack: Utilizing Emotional Voice Conversion for Speech Backdoor Attacks on Deep Speech Classification Models,"Wenhan Yao, Zedong XingXiarun Chen, Jia Liu, yongqiang He, Weiping Wen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.15508"" target=""_blank"">2408.15508</a>",,2025-12-03 22:39:25
Pixel Is Not A Barrier: An Effective Evasion Attack for Pixel-Domain Diffusion Models,"Chun-Yen Shih, Li-Xuan Peng, Jia-Wei Liao, Ernie Chu, Cheng-Fu Chou, Jun-Cheng Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11810"" target=""_blank"">2408.11810</a>",,2025-12-03 22:39:25
Surprisingly Fragile: Assessing and Addressing Prompt Instability in Multimodal Foundation Models,"Ian Stewart, Sameera Horawalavithana, Brendan Kennedy, Sai Munikoti, Karl Pazdernik",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.14595"" target=""_blank"">2408.14595</a>",,2025-12-03 22:39:25
First line of defense: A robust first layer mitigates adversarial attacks,"Janani Suresh, Nancy Nayak, Sheetal Kalyani",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11680"" target=""_blank"">2408.11680</a>","<a href=""https://github.com/janani-suresh-97/first-line-defence"" target=""_blank"">janani-suresh-97</a>",2025-12-03 22:39:25
Detecting Adversarial Attacks in Semantic Segmentation via Uncertainty Estimation: A Deep Analysis,"Kira Maag, Roman Resner, Asja Fischer",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10021"" target=""_blank"">2408.10021</a>",,2025-12-03 22:39:25
Segment-Anything Models Achieve Zero-shot Robustness in Autonomous Driving,"Jun Yan, Pengyu Wang, Danni Wang, Weiquan Huang, Daniel Watzenig, Huilin Yin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09839"" target=""_blank"">2408.09839</a>","<a href=""https://github.com/momo1986/robust_sam_iv"" target=""_blank"">momo1986</a>",2025-12-03 22:39:25
Criticality Leveraged Adversarial Training (CLAT) for Boosted Performance via Parameter Efficiency,"Bhavna Gopal, Huanrui Yang, Jingyang Zhang, Mark Horton, Yiran Chen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10204"" target=""_blank"">2408.10204</a>",,2025-12-03 22:39:25
The Brittleness of AI-Generated Image Watermarking Techniques: Examining Their Robustness Against Visual Paraphrasing Attacks,"Niyar R Barman, Krish Sharma, Ashhar Aziz, Shashwat Bajpai, Shwetangshu Biswas, Vasu Sharma, Vinija Jain, Aman Chadha, Amit Sheth, Amitava Das",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10446"" target=""_blank"">2408.10446</a>",,2025-12-03 22:39:25
Transferring Backdoors between Large Language Models by Knowledge Distillation,"Pengzhou Cheng, Zongru Wu, Tianjie Ju, Wei Du, Zhuosheng Zhang Gongshen Liu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09878"" target=""_blank"">2408.09878</a>",,2025-12-03 22:39:25
Enhance Modality Robustness in Text-Centric Multimodal Alignment with Adversarial Prompting,"Yun-Da Tsai, Ting-Yu Yen, Keng-Te Liao, Shou-De Lin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09798"" target=""_blank"">2408.09798</a>",,2025-12-03 22:39:25
Perfectly Undetectable Reflection and Scaling False Data Injection Attacks via Affine Transformation on Mobile Robot Trajectory Tracking Control,"Jun Ueda, Hyukbin Kwon",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10177"" target=""_blank"">2408.10177</a>",,2025-12-03 22:39:25
Enhancing Adversarial Transferability with Adversarial Weight Tuning,"Jiahao Chen, Zhou Feng, Rui Zeng, Yuwen Pu, Chunyi Zhou, Yi Jiang, Yuyou Gan, Jinbao Li, Shouling Ji",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09469"" target=""_blank"">2408.09469</a>",,2025-12-03 22:39:25
Regularization for Adversarial Robust Learning,"Jie Wang, Rui Gao, Yao Xie",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09672"" target=""_blank"">2408.09672</a>",,2025-12-03 22:39:25
GANPrompt: Enhancing Robustness in LLM-Based Recommendations with GAN-Enhanced Diversity Prompts,"Xinyu Li, Chuang Zhao, Hongke Zhao, Likang Wu, Ming HE",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09671"" target=""_blank"">2408.09671</a>",,2025-12-03 22:39:25
Global BGP Attacks that Evade Route Monitoring,"Henry Birge-Lee, Maria Apostolaki, Jennifer Rexford",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09622"" target=""_blank"">2408.09622</a>",,2025-12-03 22:39:25
Training Verifiably Robust Agents Using Set-Based Reinforcement Learning,"Manuel Wendl, Lukas Koller, Tobias Ladner, Matthias Althoff",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09112"" target=""_blank"">2408.09112</a>",,2025-12-03 22:39:25
DiffZOO: A Purely Query-Based Black-Box Attack for Red-teaming Text-to-Image Generative Model via Zeroth Order Optimization,"Pucheng Dang, Xing Hu, Dong Li, Rui Zhang, Qi Guo, Kaidi Xu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11071"" target=""_blank"">2408.11071</a>",,2025-12-03 22:39:25
PADetBench: Towards Benchmarking Physical Attacks against Object Detection,"Jiawei Lian, Jianhong Pan, Lefan Wang, Yi Wang, Lap-Pui Chau, Shaohui Mei",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09181"" target=""_blank"">2408.09181</a>","<a href=""https://github.com/JiaweiLian/Benchmarking_Physical_Attack"" target=""_blank"">JiaweiLian</a>",2025-12-03 22:39:25
Malacopula: adversarial automatic speaker verification attacks using a neural-based generalised Hammerstein model,"Massimiliano Todisco, Michele Panariello, Xin Wang, Héctor Delgado, Kong Aik Lee, Nicholas Evans",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09300"" target=""_blank"">2408.09300</a>",,2025-12-03 22:39:25
Towards Physical World Backdoor Attacks against Skeleton Action Recognition,"Qichen Zheng, Yi Yu, Siyuan Yang, Jun Liu, Kwok-Yan Lam, Alex Kot",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08671"" target=""_blank"">2408.08671</a>","<a href=""https://qichenzheng.github.io/psba-website"" target=""_blank"">qichenzheng.github.io</a>",2025-12-03 22:39:25
BaThe: Defense against the Jailbreak Attack in Multimodal Large Language Models by Treating Harmful Instruction as Backdoor Trigger,"Yulin Chen, Haoran Li, Zihao Zheng, Yangqiu Song",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09093"" target=""_blank"">2408.09093</a>",,2025-12-03 22:39:25
Exploring Robustness of Visual State Space model against Backdoor Attacks,"Cheng-Yi Lee, Cheng-Chang Tsai, Chia-Mu Yu, Chun-Shien Lu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11679"" target=""_blank"">2408.11679</a>",,2025-12-03 22:39:25
"Ask, Attend, Attack: A Effective Decision-Based Black-Box Targeted Attack for Image-to-Text Models","Qingyuan Zeng, Zhenzhong Wang, Yiu-ming Cheung, Min Jiang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.08989"" target=""_blank"">2408.08989</a>",,2025-12-03 22:39:25
Characterizing and Evaluating the Reliability of LLMs against Jailbreak Attacks,"Kexin Chen, Yi Liu, Dongxia Wang, Jiaying Chen, Wenhai Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09326"" target=""_blank"">2408.09326</a>",,2025-12-03 22:39:25
Out-of-distribution materials property prediction using adversarial learning based fine-tuning,"Qinyang Li, Nicholas Miklaucic, Jianjun Hu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09297"" target=""_blank"">2408.09297</a>",,2025-12-03 22:39:25
PREMAP: A Unifying PREiMage APproximation Framework for Neural Networks,"Xiyue Zhang, Benjie Wang, Marta Kwiatkowska, Huan Zhang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09262"" target=""_blank"">2408.09262</a>",,2025-12-03 22:39:25
Robust Image Classification: Defensive Strategies against FGSM and PGD Adversarial Attacks,"Hetvi Waghela, Jaydip Sen, Sneha Rakshit",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.13274"" target=""_blank"">2408.13274</a>",,2025-12-03 22:39:25
Adversarial Attacked Teacher for Unsupervised Domain Adaptive Object Detection,"Kaiwen Wang, Yinzhe Shen, Martin Lauer",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.09431"" target=""_blank"">2408.09431</a>",,2025-12-03 22:39:25
Learning Randomized Algorithms with Transformers,"Oswald Johannes von, Seijin Kobayashi, Yassir Akram, Angelika Steger",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10818"" target=""_blank"">2408.10818</a>",,2025-12-03 22:39:25
Towards Robust Knowledge Unlearning: An Adversarial Framework for Assessing and Improving Unlearning Robustness in Large Language Models,"Hongbang Yuan, Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10682"" target=""_blank"">2408.10682</a>",,2025-12-03 22:39:25
Latent Feature and Attention Dual Erasure Attack against Multi-View Diffusion Models for 3D Assets Protection,"Jingwei Sun, Xuchong Zhang, Changfeng Sun, Qicheng Bai, Hongbin Sun",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11408"" target=""_blank"">2408.11408</a>",,2025-12-03 22:39:25
Large Language Models are Good Attackers: Efficient and Stealthy Textual Backdoor Attacks,"Ziqiang Li, Yueqi Zeng, Pengfei Xia, Lei Liu, Zhangjie Fu, Bin Li",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11587"" target=""_blank"">2408.11587</a>",,2025-12-03 22:39:25
GAIM: Attacking Graph Neural Networks via Adversarial Influence Maximization,"Xiaodong Yang, Xiaoting Li, Huiyuan Chen, Yiwei Cai",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10948"" target=""_blank"">2408.10948</a>",,2025-12-03 22:39:25
Correlation Analysis of Adversarial Attack in Time Series Classification,"Zhengyang Li, Wenhao Liang, Chang Dong, Weitong Chen, Dong Huang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11264"" target=""_blank"">2408.11264</a>",,2025-12-03 22:39:25
MEGen: Generative Backdoor in Large Language Models via Model Editing,"Jiyang Qiu, Xinbei Ma, Zhuosheng Zhang, Hai Zhao",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10722"" target=""_blank"">2408.10722</a>",,2025-12-03 22:39:25
"Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks","Yiyi Chen, Russa Biswas, Heather Lent, Johannes Bjerva",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11749"" target=""_blank"">2408.11749</a>",,2025-12-03 22:39:25
Privacy-preserving Universal Adversarial Defense for Black-box Models,"Qiao Li, Cong Wu, Jing Chen, Zijun Zhang, Kun He, Ruiying Du, Xinxin Wang, Qingchuang Zhao, Yang Liu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10647"" target=""_blank"">2408.10647</a>",,2025-12-03 22:39:25
MsMemoryGAN: A Multi-scale Memory GAN for Palm-vein Adversarial Purification,"Huafeng Qin, Yuming Fu, Huiyan Zhang, Mounim A. El-Yacoubi, Xinbo Gao, Qun Song, Jun Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10694"" target=""_blank"">2408.10694</a>",,2025-12-03 22:39:25
Revisiting Min-Max Optimization Problem in Adversarial Training,"Sina Hajer Ahmadi, Hassan Bahrami",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11218"" target=""_blank"">2408.11218</a>",,2025-12-03 22:39:25
Iterative Window Mean Filter: Thwarting Diffusion-based Adversarial Purification,"Hanrui Wang, Ruoxi Sun, Cunjian Chen, Minhui Xue, Lay-Ki Soon, Shuo Wang, Zhe Jin",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10673"" target=""_blank"">2408.10673</a>",,2025-12-03 22:39:25
Adversarial Attack for Explanation Robustness of Rationalization Models,"Yuankai Zhang, Lingxiao Kong, Haozhao Wang, Ruixuan Li, Jun Wang, Yuhua Li, Wei Liu",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10795"" target=""_blank"">2408.10795</a>",,2025-12-03 22:39:25
Prompt-Agnostic Adversarial Perturbation for Customized Diffusion Models,"Cong Wan, Yuhang He, Xiang Song, Yihong Gong",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10571"" target=""_blank"">2408.10571</a>",,2025-12-03 22:39:25
A Grey-box Attack against Latent Diffusion Model-based Image Editing by Posterior Collapse,"Zhongliang Guo, Lei Fang, Jingyu Lin, Yifei Qian, Shuai Zhao, Zeyu Wang, Junhao Dong, Cunjian Chen, Ognjen Arandjelović, Chun Pong Lau",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10901"" target=""_blank"">2408.10901</a>",,2025-12-03 22:39:25
Ferret: Faster and Effective Automated Red Teaming with Reward-Based Scoring Technique,"Tej Deep Pala, Vernon Y. H. Toh, Rishabh Bhardwaj, Soujanya Poria",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10701"" target=""_blank"">2408.10701</a>","<a href=""https://github.com/declare-lab/ferret"" target=""_blank"">declare-lab</a>",2025-12-03 22:39:25
Security Attacks on LLM-based Code Completion Tools,"Wen Cheng, Ke Sun, Xinyu Zhang, Wei Wang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11006"" target=""_blank"">2408.11006</a>",,2025-12-03 22:39:25
Unlocking Adversarial Suffix Optimization Without Affirmative Phrases: Efficient Black-box Jailbreaking via LLM as Optimizer,"Weipeng Jiang, Zhenting Wang, Juan Zhai, Shiqing Ma, Zhengyu Zhao, Chao Shen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11313"" target=""_blank"">2408.11313</a>",,2025-12-03 22:39:25
Accelerating the Surrogate Retraining for Poisoning Attacks against Recommender Systems,"Yunfan Wu, Qi Cao, Shuchang Tao, Kaike Zhang, Fei Sun, Huawei Shen",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10666"" target=""_blank"">2408.10666</a>",,2025-12-03 22:39:25
EEG-Defender: Defending against Jailbreak through Early Exit Generation of Large Language Models,"Chongwen Zhao, Zhihao Dou, Kaizhu Huang",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11308"" target=""_blank"">2408.11308</a>",,2025-12-03 22:39:25
Makeup-Guided Facial Privacy Protection via Untrained Neural Network Priors,"Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.12387"" target=""_blank"">2408.12387</a>","<a href=""https://github.com/fahadshamshad/deep-facial-privacy-prior"" target=""_blank"">fahadshamshad</a>",2025-12-03 22:39:25
Improving Out-of-Distribution Data Handling and Corruption Resistance via Modern Hopfield Networks,"Saleh Sargolzaei, Luis Rueda",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.11309"" target=""_blank"">2408.11309</a>","<a href=""https://github.com/salehsargolzaee/Hopfield-integrated-test"" target=""_blank"">salehsargolzaee</a>",2025-12-03 22:39:25
Security Assessment of Hierarchical Federated Deep Learning,"D Alqattan, R Sun, H Liang, G Nicosia, V Snasel, R Ranjan, V Ojha",arXiv,2024-08,"<a href=""http://arxiv.org/abs/2408.10752"" target=""_blank"">2408.10752</a>",,2025-12-03 22:39:25
Performance Evaluation of Knowledge Graph Embedding Approaches under Non-adversarial Attacks,"Sourabh Kapoor, Arnab Sharma, Michael Röder, Caglar Demir, Axel-Cyrille Ngonga Ngomo",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06855"" target=""_blank"">2407.06855</a>",,2025-12-03 22:39:25
The Quantum Imitation Game: Reverse Engineering of Quantum Machine Learning Models,"Archisman Ghosh, Swaroop Ghosh",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07237"" target=""_blank"">2407.07237</a>",,2025-12-03 22:39:25
Robust Neural Information Retrieval: An Adversarial and Out-of-distribution Perspective,"Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Rijke Maarten de, Yixing Fan, Xueqi Cheng",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06992"" target=""_blank"">2407.06992</a>","<a href=""https://sigir2024-robust-information-retrieval.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Distribution System Reconfiguration to Mitigate Load Altering Attacks via Stackelberg Games,"Sajjad Maleki, Subhash Lakshminarayana, Charalambos Konstantinou, E. Veronica Belmaga",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07065"" target=""_blank"">2407.07065</a>",,2025-12-03 22:39:25
Attack GAN (AGAN ): A new Security Evaluation Tool for Perceptual Encryption,"Umesh Kashyap, Sudev Kumar Padhi, Sk. Subidh Ali",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06570"" target=""_blank"">2407.06570</a>",,2025-12-03 22:39:25
Shedding More Light on Robust Classifiers under the lens of Energy-based Models,"Mujtaba Hussain Mirza, Maria Rosaria Briglia, Senad Beadini, Iacopo Masi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06315"" target=""_blank"">2407.06315</a>","<a href=""http://github.com/OmnAI-Lab/Robust-Classifiers-under-the-lens-of-EBM/"" target=""_blank"">Robust-Classifiers-under-the-lens-of-EBM</a>",2025-12-03 22:39:25
Non-Robust Features are Not Always Useful in One-Class Classification,"Matthew Lau, Haoran Wang, Alec Helbling, Matthew Hul, ShengYun Peng, Martin Andreoni, Willian T. Lunardi, Wenke Lee",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06372"" target=""_blank"">2407.06372</a>",,2025-12-03 22:39:25
Exposing Privacy Gaps: Membership Inference Attack on Preference Data for LLM Alignment,"Qizhang Feng, Siva Rajesh Kasa, Hyokun Yun, Choon Hui Teo, Sravan Babu Bodapati",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06443"" target=""_blank"">2407.06443</a>",,2025-12-03 22:39:25
Mjolnir: Breaking the Shield of Perturbation-Protected Gradients via Adaptive Diffusion,"Xuan Liu, Siqi Cai, Qihua Zhou, Song Guo, Ruibin Li, Kaiwei Lin",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.05285"" target=""_blank"">2407.05285</a>",,2025-12-03 22:39:25
Rethinking Targeted Adversarial Attacks For Neural Machine Translation,"Junjie Wu, Lemao Liu, Wei Bi, Dit-Yan Yeung",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.05319"" target=""_blank"">2407.05319</a>","<a href=""https://github.com/wujunjie1998/TWGA"" target=""_blank"">wujunjie1998</a>",2025-12-03 22:39:25
Jailbreak Attacks and Defenses Against Large Language Models: A Survey,"Sibo Yi, Yule Liu, Zhen Sun, Tianshuo Cong, Xinlei He, Jiaxing Song, Ke Xu, Qi Li",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04295"" target=""_blank"">2407.04295</a>",,2025-12-03 22:39:25
An accurate detection is not all you need to combat label noise in web-noisy datasets,"Paul Albert, Jack Valmadre, Eric Arazo, Tarun Krishna, Noel E. O'Connor, Kevin McGuinness",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.05528"" target=""_blank"">2407.05528</a>",,2025-12-03 22:39:25
Detecting new obfuscated malware variants: A lightweight and interpretable machine learning approach,"Oladipo A. Madamidola, Felix Ngobigha, Adnane Ez-zizi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07918"" target=""_blank"">2407.07918</a>",,2025-12-03 22:39:25
Evolutionary Trigger Detection and Lightweight Model Repair Based Backdoor Defense,"Qi Zhou, Zipeng Ye, Yubo Tang, Wenjian Luo, Yuhui Shi, Yan Jia",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.05396"" target=""_blank"">2407.05396</a>",,2025-12-03 22:39:25
A Novel Bifurcation Method for Observation Perturbation Attacks on Reinforcement Learning Agents: Load Altering Attacks on a Cyber Physical Power System,"Kiernan Broda-Milian, Ranwa Al-Mallah, Hanane Dagdougui",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.05182"" target=""_blank"">2407.05182</a>",,2025-12-03 22:39:25
Releasing Malevolence from Benevolence: The Menace of Benign Data on Machine Unlearning,"Binhao Ma, Tianhang Zheng, Hongsheng Hu, Di Wang, Shuo Wang, Zhongjie Ba, Zhan Qin, Kui Ren",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.05112"" target=""_blank"">2407.05112</a>",,2025-12-03 22:39:25
GCON: Differentially Private Graph Convolutional Network via Objective Perturbation,"Jianxin Wei, Yizheng Zhu, Xiaokui Xiao, Ergute Bao, Yin Yang, Kuntai Cai, Beng Chin Ooi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.05034"" target=""_blank"">2407.05034</a>",,2025-12-03 22:39:25
Remembering Everything Makes You Vulnerable: A Limelight on Machine Unlearning for Personalized Healthcare Sector,"Ahan Chatterjee, Sai Anirudh Aryasomayajula, Rajat Chaudhari, Subhajit Paul, Vishwa Mohan Singh",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04589"" target=""_blank"">2407.04589</a>",,2025-12-03 22:39:25
Controlling Whisper: Universal Acoustic Adversarial Attacks to Control Speech Foundation Models,"Vyas Raina, Mark Gales",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04482"" target=""_blank"">2407.04482</a>",,2025-12-03 22:39:25
Self-Supervised Representation Learning for Adversarial Attack Detection,"Yi Li, Plamen Angelov, Neeraj Suri",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04382"" target=""_blank"">2407.04382</a>",,2025-12-03 22:39:25
On Evaluating The Performance of Watermarked Machine-Generated Texts Under Adversarial Attacks,"Zesen Liu, Tianshuo Cong, Xinlei He, Qi Li",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04794"" target=""_blank"">2407.04794</a>",,2025-12-03 22:39:25
Hiding Local Manipulations on SAR Images: a Counter-Forensic Attack,"Sara Mandelli, Edoardo Daniele Cannas, Paolo Bestagini, Stefano Tebaldini, Stefano Tubaro",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07041"" target=""_blank"">2407.07041</a>",,2025-12-03 22:39:25
Late Breaking Results: Fortifying Neural Networks: Safeguarding Against Adversarial Attacks with Stochastic Computing,"Faeze S. Banitaba, Sercan Aygun, M. Hassan Najafi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04861"" target=""_blank"">2407.04861</a>",,2025-12-03 22:39:25
Tracing Back the Malicious Clients in Poisoning Attacks to Federated Learning,"Yuqi Jia, Minghong Fang, Hongbin Liu, Jinghuai Zhang, Neil Zhenqiang Gong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07221"" target=""_blank"">2407.07221</a>",,2025-12-03 22:39:25
DeCE: Deceptive Cross-Entropy Loss Designed for Defending Backdoor Attacks,"Guang Yang, Yu Zhou, Xiang Chen, Xiangyu Zhang, Terry Yue Zhuo, David Lo, Taolue Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08956"" target=""_blank"">2407.08956</a>",,2025-12-03 22:39:25
Improving the Transferability of Adversarial Examples by Feature Augmentation,"Donghua Wang, Wen Yao, Tingsong Jiang, Xiaohu Zheng, Junqi Wu, Xiaoqian Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06714"" target=""_blank"">2407.06714</a>",,2025-12-03 22:39:25
Countermeasures Against Adversarial Examples in Radio Signal Classification,"Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Basil AsSadhan, Fabio Roli",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06796"" target=""_blank"">2407.06796</a>",,2025-12-03 22:39:25
BoBa: Boosting Backdoor Detection through Data Distribution Inference in Federated Learning,"Ning Wang, Shanghao Shi, Yang Xiao, Yimin Chen, Y. Thomas Hou, Wenjing Lou",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09658"" target=""_blank"">2407.09658</a>",,2025-12-03 22:39:25
Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training,"Youliang Yuan, Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Jiahao Xu, Tian Liang, Pinjia He, Zhaopeng Tu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09121"" target=""_blank"">2407.09121</a>","<a href=""https://github.com/RobustNLP/DeRTa"" target=""_blank"">RobustNLP</a>",2025-12-03 22:39:25
Rethinking the Threat and Accessibility of Adversarial Attacks against Face Recognition Systems,"Yuxin Cao, Yumeng Zhu, Derui Wang, Sheng Wen, Minhui Xue, Jin Lu, Hao Ge",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08514"" target=""_blank"">2407.08514</a>",,2025-12-03 22:39:25
MaPPing Your Model: Assessing the Impact of Adversarial Attacks on LLM-based Programming Assistants,"John Heibel, Daniel Lowd",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11072"" target=""_blank"">2407.11072</a>",,2025-12-03 22:39:25
Boosting Adversarial Transferability for Skeleton-based Action Recognition via Exploring the Model Posterior Space,"Yunfeng Diao, Baiqi Wu, Ruixuan Zhang, Xun Yang, Meng Wang, He Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08572"" target=""_blank"">2407.08572</a>",,2025-12-03 22:39:25
Distributed Backdoor Attacks on Federated Graph Learning and Certified Defenses,"Yuxin College of Computer Science and Technology, Jilin University Illinois Institute of Technology Yang, Qiang College of Computer Science and Technology, Jilin University Li, Jinyuan The Pennsylvania State University Jia, Yuan University of Connecticut Hong, Binghui Illinois Institute of Technology Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08935"" target=""_blank"">2407.08935</a>","<a href=""https://github.com/Yuxin104/Opt-GDBA"" target=""_blank"">Yuxin104</a>",2025-12-03 22:39:25
HO-FMN: Hyperparameter Optimization for Fast Minimum-Norm Attacks,"Raffaele Mura, Giuseppe Floris, Luca Scionis, Giorgio Piras, Maura Pintor, Ambra Demontis, Giorgio Giacinto, Battista Biggio, Fabio Roli",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08806"" target=""_blank"">2407.08806</a>","<a href=""https://github.com/pralab/HO-FMN"" target=""_blank"">pralab</a>",2025-12-03 22:39:25
How to beat a Bayesian adversary,"Zihan Ding, Kexin Jin, Jonas Latz, Chenguang Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08678"" target=""_blank"">2407.08678</a>",,2025-12-03 22:39:25
Soft Prompts Go Hard: Steering Visual Language Models with Hidden Meta-Instructions,"Tingwei Zhang, Collin Zhang, John X. Morris, Eugene Bagdasarian, Vitaly Shmatikov",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08970"" target=""_blank"">2407.08970</a>",,2025-12-03 22:39:25
DART: A Solution for Decentralized Federated Learning Model Robustness Analysis,"Chao Feng, Alberto Huertas Celdrán, der Assen Jan von, Enrique Tomás Martínez Beltrán, Gérôme Bovet, Burkhard Stiller",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08652"" target=""_blank"">2407.08652</a>",,2025-12-03 22:39:25
Quantitative Evaluation of the Saliency Map for Alzheimer's Disease Classifier with Anatomical Segmentation,"Yihan Zhang, Xuanshuo Zhang, Wei Wu, Haohan Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08546"" target=""_blank"">2407.08546</a>",,2025-12-03 22:39:25
Enhancing Privacy of Spatiotemporal Federated Learning against Gradient Inversion Attacks,"Lele Zheng, Yang Cao, Renhe Jiang, Kenjiro Taura, Yulong Shen, Sheng Li, Masatoshi Yoshikawa",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08529"" target=""_blank"">2407.08529</a>",,2025-12-03 22:39:25
Deep Learning for Network Anomaly Detection under Data Contamination: Evaluating Robustness and Mitigating Performance Degradation,"D'Jeff K. Nkashama, Jordan Masakuna Félicien, Arian Soltani, Jean-Charles Verdier, Pierre-Martin Tardif, Marc Frappier, Froduald Kabanza",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08838"" target=""_blank"">2407.08838</a>",,2025-12-03 22:39:25
Are Large Language Models Really Bias-Free? Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation,"Riccardo Cantini, Giada Cosenza, Alessio Orsino, Domenico Talia",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08441"" target=""_blank"">2407.08441</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defenses on Text-to-Image Diffusion Models: A Survey,"Chenyu Zhang, Mingwang Hu, Wenhui Li, Lanjun Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15861"" target=""_blank"">2407.15861</a>","<a href=""https://github.com/datar001/Awesome-AD-on-T2IDM"" target=""_blank"">datar001</a>",2025-12-03 22:39:25
"A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends","Daizong Liu, Mingyu Yang, Xiaoye Qu, Pan Zhou, Wei Hu, Yu Cheng",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07403"" target=""_blank"">2407.07403</a>","<a href=""https://github.com/liudaizong/Awesome-LVLM-Attack"" target=""_blank"">liudaizong</a>",2025-12-03 22:39:25
Model-agnostic clean-label backdoor mitigation in cybersecurity environments,"Giorgio Severi, Simona Boboila, John Holodnak, Kendra Kratkiewicz, Rauf Izmailov, Lucia Michael J. De, Alina Oprea",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.08159"" target=""_blank"">2407.08159</a>",,2025-12-03 22:39:25
Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities,"Tianjie Ju, Yiting Wang, Xinbei Ma, Pengzhou Cheng, Haodong Zhao, Yulong Wang, Lifeng Liu, Jian Xie, Zhuosheng Zhang, Gongshen Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07791"" target=""_blank"">2407.07791</a>",,2025-12-03 22:39:25
Invisible Optical Adversarial Stripes on Traffic Sign against Autonomous Vehicles,"Dongfang Guo, Yuting Wu, Yimin Dai, Pengfei Zhou, Xin Lou, Rui Tan",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07510"" target=""_blank"">2407.07510</a>",,2025-12-03 22:39:25
"A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities","Arastoo Zibaeirad, Farnoosh Koleini, Shengping Bi, Tao Hou, Tao Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07966"" target=""_blank"">2407.07966</a>",,2025-12-03 22:39:25
Was it Slander? Towards Exact Inversion of Generative Language Models,"Adrians Skapars, Edoardo Manino, Youcheng Sun, Lucas C. Cordeiro",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11059"" target=""_blank"">2407.11059</a>",,2025-12-03 22:39:25
CHILLI: A data context-aware perturbation method for XAI,"Saif Anwar, Nathan Griffiths, Abhir Bhalerao, Thomas Popham",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07521"" target=""_blank"">2407.07521</a>",,2025-12-03 22:39:25
A Hybrid Training-time and Run-time Defense Against Adversarial Attacks in Modulation Classification,"Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Guisheng Liao, Ambra Demontis, Fabio Roli",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06807"" target=""_blank"">2407.06807</a>",,2025-12-03 22:39:25
Universal Multi-view Black-box Attack against Object Detectors via Layout Optimization,"Donghua Wang, Wen Yao, Tingsong Jiang, Chao Li, Xiaoqian Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06688"" target=""_blank"">2407.06688</a>",,2025-12-03 22:39:25
DLOVE: A new Security Evaluation Tool for Deep Learning Based Watermarking Techniques,"Sudev Kumar Padhi, Sk. Subidh Ali",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06552"" target=""_blank"">2407.06552</a>",,2025-12-03 22:39:25
Regulating Model Reliance on Non-Robust Features by Smoothing Input Marginal Density,"Peiyu Yang, Naveed Akhtar, Mubarak Shah, Ajmal Mian",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04370"" target=""_blank"">2407.04370</a>",,2025-12-03 22:39:25
Unveiling the Unseen: Exploring Whitebox Membership Inference through the Lens of Explainability,"Chenxi Li, Abhinav Kumar, Zhen Guo, Jie Hou, Reza Tourani",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01306"" target=""_blank"">2407.01306</a>",,2025-12-03 22:39:25
Data Poisoning Attacks in Intelligent Transportation Systems: A Survey,"Feilong Wang, Xin Wang, Xuegang Ban",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15855"" target=""_blank"">2407.15855</a>",,2025-12-03 22:39:25
Non-Cooperative Backdoor Attacks in Federated Learning: A New Threat Landscape,"Tuan Nguyen, Dung Thuy Nguyen, Khoa D Doan, Kok-Seng Wong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.07917"" target=""_blank"">2407.07917</a>",,2025-12-03 22:39:25
Breach By A Thousand Leaks: Unsafe Information Leakage in `Safe' AI Responses,"David Glukhov, Ziwen Han, Ilia Shumailov, Vardan Papyan, Nicolas Papernot",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02551"" target=""_blank"">2407.02551</a>",,2025-12-03 22:39:25
Light-weight Fine-tuning Method for Defending Adversarial Noise in Pre-trained Medical Vision-Language Models,"Xu Han, Linghao Jin, Xuezhe Ma, Xiaofeng Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02716"" target=""_blank"">2407.02716</a>",,2025-12-03 22:39:25
Beyond Full Poisoning: Effective Availability Attacks with Partial Perturbation,"Yu Zhe, Jun Sakuma",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02437"" target=""_blank"">2407.02437</a>",,2025-12-03 22:39:25
Towards More Realistic Extraction Attacks: An Adversarial Perspective,"Yash More, Prakhar Ganesh, Golnoosh Farnadi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02596"" target=""_blank"">2407.02596</a>",,2025-12-03 22:39:25
On the Robustness of Graph Reduction Against GNN Backdoor,"Yuxuan Zhu, Michael Mandulak, Kerui Wu, George Slota, Yuseok Jeon, Ka-Ho Chow, Lei Yu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02431"" target=""_blank"">2407.02431</a>",,2025-12-03 22:39:25
MALT Powers Up Adversarial Attacks,"Odelia Melamed, Gilad Yehudai, Adi Shamir",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02240"" target=""_blank"">2407.02240</a>",,2025-12-03 22:39:25
Face Reconstruction Transfer Attack as Out-of-Distribution Generalization,"Yoon Gyo Jung, Jaewoo Park, Xingbo Dong, Hojin Park, Andrew Beng Jin Teoh, Octavia Camps",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02403"" target=""_blank"">2407.02403</a>",,2025-12-03 22:39:25
Robust ADAS: Enhancing Robustness of Machine Learning-based Advanced Driver Assistance Systems for Adverse Weather,"Muhammad Zaeem Shahzad, Muhammad Abdullah Hanif, Muhammad Shafique",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02581"" target=""_blank"">2407.02581</a>",,2025-12-03 22:39:25
Multi-View Black-Box Physical Attacks on Infrared Pedestrian Detectors Using Adversarial Infrared Grid,"Kalibinuer Tiliwalidi, Chengyin Hu, Weiwen Shi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01168"" target=""_blank"">2407.01168</a>",,2025-12-03 22:39:25
DeepiSign-G: Generic Watermark to Stamp Hidden DNN Parameters for Self-contained Tracking,"Alsharif Abuadbba, Nicholas Rhodes, Kristen Moore, Bushra Sabir, Shuo Wang, Yansong Gao",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01260"" target=""_blank"">2407.01260</a>",,2025-12-03 22:39:25
Looking From the Future: Multi-order Iterations Can Enhance Adversarial Attack Transferability,"Zijian Ying, Qianmu Li, Tao Wang, Zhichao Lian, Shunmei Meng, Xuyun Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01925"" target=""_blank"">2407.01925</a>",,2025-12-03 22:39:25
QUEEN: Query Unlearning against Model Extraction,"Huajie Chen, Tianqing Zhu, Lefeng Zhang, Bo Liu, Derui Wang, Wanlei Zhou, Minhui Xue",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01251"" target=""_blank"">2407.01251</a>",,2025-12-03 22:39:25
Formal Verification of Object Detection,"Avraham Raviv, Yizhak Y. Elboher, Michelle Aluf-Medina, Yael Leibovich Weiss, Omer Cohen, Roy Assa, Guy Katz, Hillel Kugler",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01295"" target=""_blank"">2407.01295</a>",,2025-12-03 22:39:25
SoP: Unlock the Power of Social Facilitation for Automatic Jailbreak Attack,"Yan Yang, Zeguan Xiao, Xin Lu, Hongru Wang, Hailiang Huang, Guanhua Chen, Yun Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01902"" target=""_blank"">2407.01902</a>","<a href=""https://github.com/Yang-Yan-Yang-Yan/SoP"" target=""_blank"">Yang-Yan-Yang-Yan</a>",2025-12-03 22:39:25
Securing Distributed Network Digital Twin Systems Against Model Poisoning Attacks,"Zifan Zhang, Minghong Fang, Mingzhe Chen, Gaolei Li, Xi Lin, Yuchen Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01917"" target=""_blank"">2407.01917</a>",,2025-12-03 22:39:25
A Fingerprint for Large Language Models,"Zhiguang Yang, Hanzhou Wu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01235"" target=""_blank"">2407.01235</a>",,2025-12-03 22:39:25
Unaligning Everything: Or Aligning Any Text to Any Image in Multimodal Models,"Shaeke Salman, Md Montasir Bin Shams, Xiuwen Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01157"" target=""_blank"">2407.01157</a>",,2025-12-03 22:39:25
Learning Robust 3D Representation from CLIP via Dual Denoising,"Shuqing Luo, Bowen Qu, Wei Gao",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.00905"" target=""_blank"">2407.00905</a>","<a href=""https://github.com/luoshuqing2001/Dual_Denoising"" target=""_blank"">luoshuqing2001</a>",2025-12-03 22:39:25
Consistency Purification: Effective and Efficient Diffusion Purification towards Certified Robustness,"Yiquan Li, Zhongzhu Chen, Kun Jin, Jiongxiao Wang, Bo Li, Chaowei Xiao",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.00623"" target=""_blank"">2407.00623</a>",,2025-12-03 22:39:25
UWBAD: Towards Effective and Imperceptible Jamming Attacks Against UWB Ranging Systems with COTS Chips,"Yuqiao Yang, Zhongjie Wu, Yongzhao Zhang, Ting Chen, Jun Li, Jie Yang, Wenhao Liu, Xiaosong Zhang, Ruicong Shi, Jingwei Li, Yu Jiang, Zhuo Su",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.00682"" target=""_blank"">2407.00682</a>",,2025-12-03 22:39:25
Query-Efficient Hard-Label Black-Box Attack against Vision Transformers,"Chao Zhou, Xiaowen Shi, Yuan-Gen Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.00389"" target=""_blank"">2407.00389</a>",,2025-12-03 22:39:25
DiffuseDef: Improved Robustness to Adversarial Attacks,"Zhenhao Li, Marek Rei, Lucia Specia",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.00248"" target=""_blank"">2407.00248</a>",,2025-12-03 22:39:25
On Discrete Prompt Optimization for Diffusion Models,"Ruochen Wang, Ting Liu, Cho-Jui Hsieh, Boqing Gong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.01606"" target=""_blank"">2407.01606</a>",,2025-12-03 22:39:25
Logicbreaks: A Framework for Understanding Subversion of Rule-based Inference,"Anton Xue, Avishree Khare, Rajeev Alur, Surbhi Goel, Eric Wong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.00075"" target=""_blank"">2407.00075</a>",,2025-12-03 22:39:25
Refusing Safe Prompts for Multi-modal Large Language Models,"Zedian Shao, Hongbin Liu, Yuepeng Hu, Neil Zhenqiang Gong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09050"" target=""_blank"">2407.09050</a>","<a href=""https://github.com/Sadcardation/MLLM-Refusal"" target=""_blank"">Sadcardation</a>",2025-12-03 22:39:25
Adversarial Magnification to Deceive Deepfake Detection through Super Resolution,"Davide Alessandro Coccomini, Roberto Caldelli, Giuseppe Amato, Fabrizio Falchi, Claudio Gennaro",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02670"" target=""_blank"">2407.02670</a>","<a href=""https://github.com/davide-coccomini/Adversarial-Magnification-to-Deceive-Deepfake-Detection-through-Super-Resolution"" target=""_blank"">davide-coccomini</a>",2025-12-03 22:39:25
EvolBA: Evolutionary Boundary Attack under Hard-label Black Box condition,"Ayane Tajima, Satoshi Ono",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02248"" target=""_blank"">2407.02248</a>",,2025-12-03 22:39:25
Secure Semantic Communication via Paired Adversarial Residual Networks,"Boxiang He, Fanggang Wang, Tony Q. S. Quek",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02053"" target=""_blank"">2407.02053</a>",,2025-12-03 22:39:25
A Wolf in Sheep's Clothing: Practical Black-box Adversarial Attacks for Evading Learning-based Windows Malware Detection in the Wild,"Xiang Ling, Zhiyu Wu, Bin Wang, Wei Deng, Jingzheng Wu, Shouling Ji, Tianyue Luo, Yanjun Wu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02886"" target=""_blank"">2407.02886</a>",,2025-12-03 22:39:25
Tackling Data Corruption in Offline Reinforcement Learning via Sequence Modeling,"Jiawei Xu, Rui Yang, Shuang Qiu, Feng Luo, Meng Fang, Baoxiang Wang, Lei Han",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04285"" target=""_blank"">2407.04285</a>","<a href=""https://github.com/jiawei415/RobustDecisionTransformer"" target=""_blank"">jiawei415</a>",2025-12-03 22:39:25
TrackPGD: A White-box Attack using Binary Masks against Robust Transformer Trackers,"Fatemeh Nourilenjan Nokabadi, Yann Batiste Pequignot, Jean-Francois Lalonde, Christian Gagné",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03946"" target=""_blank"">2407.03946</a>",,2025-12-03 22:39:25
Adversarial Robustness of VAEs across Intersectional Subgroups,"Chethan Krishnamurthy Ramanaik, Arjun Roy, Eirini Ntoutsi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03864"" target=""_blank"">2407.03864</a>",,2025-12-03 22:39:25
Protecting Deep Learning Model Copyrights with Adversarial Example-Free Reuse Detection,"Xiaokun Luan, Xiyue Zhang, Jingyi Wang, Meng Sun",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03883"" target=""_blank"">2407.03883</a>",,2025-12-03 22:39:25
Mitigating Low-Frequency Bias: Feature Recalibration and Frequency Attention Regularization for Adversarial Robustness,"Kejia Zhang, Juanjuan Weng, Yuanzheng Cai, Zhiming Luo, Shaozi Li",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04016"" target=""_blank"">2407.04016</a>",,2025-12-03 22:39:25
Securing Multi-turn Conversational Language Models Against Distributed Backdoor Triggers,"Terry Tong, Jiashu Xu, Qin Liu, Muhao Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04151"" target=""_blank"">2407.04151</a>",,2025-12-03 22:39:25
Charging Ahead: A Hierarchical Adversarial Framework for Counteracting Advanced Cyber Threats in EV Charging Stations,"Mohammed Al-Mehdhar, Abdullatif Albaseer, Mohamed Abdallah, Ala Al-Fuqaha",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03729"" target=""_blank"">2407.03729</a>",,2025-12-03 22:39:25
T2IShield: Defending Against Backdoors on Text-to-Image Diffusion Models,"Zhongqi Wang, Jie Zhang, Shiguang Shan, Xilin Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04215"" target=""_blank"">2407.04215</a>","<a href=""https://github.com/Robin-WZQ/T2IShield"" target=""_blank"">Robin-WZQ</a>",2025-12-03 22:39:25
Automated Progressive Red Teaming,"Bojian Jiang, Yi Jing, Tianhao Shen, Tong Wu, Qing Yang, Deyi Xiong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03876"" target=""_blank"">2407.03876</a>",,2025-12-03 22:39:25
Quantifying Prediction Consistency Under Model Multiplicity in Tabular LLMs,"Faisal Hamman, Pasan Dissanayake, Saumitra Mishra, Freddy Lecue, Sanghamitra Dutta",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04173"" target=""_blank"">2407.04173</a>",,2025-12-03 22:39:25
Certifiably Robust Image Watermark,"Zhengyuan Jiang, Moyang Guo, Yuepeng Hu, Jinyuan Jia, Neil Zhenqiang Gong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.04086"" target=""_blank"">2407.04086</a>","<a href=""https://github.com/zhengyuan-jiang/Watermark-Library"" target=""_blank"">zhengyuan-jiang</a>",2025-12-03 22:39:25
$L_p$-norm Distortion-Efficient Adversarial Attack,"Chao Zhou, Yuan-Gen Wang, Zi-jia Wang, Xiangui Kang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03115"" target=""_blank"">2407.03115</a>",,2025-12-03 22:39:25
Purification Of Contaminated Convolutional Neural Networks Via Robust Recovery: An Approach with Theoretical Guarantee in One-Hidden-Layer Case,"Hanxiao Lu, Zeyu Huang, Ren Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11031"" target=""_blank"">2407.11031</a>",,2025-12-03 22:39:25
SPLITZ: Certifiable Robustness via Split Lipschitz Randomized Smoothing,"Meiyu Zhong, Ravi Tandon",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02811"" target=""_blank"">2407.02811</a>",,2025-12-03 22:39:25
JailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets,"Zhihua Jin, Shiyi Liu, Haotian Li, Xun Zhao, Huamin Qu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03045"" target=""_blank"">2407.03045</a>",,2025-12-03 22:39:25
Venomancer: Towards Imperceptible and Target-on-Demand Backdoor Attacks in Federated Learning,"Son Nguyen, Thinh Nguyen, Khoa Doan, Kok-Seng Wong",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03144"" target=""_blank"">2407.03144</a>",,2025-12-03 22:39:25
A Geometric Framework for Adversarial Vulnerability in Machine Learning,Brian Bell,arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11029"" target=""_blank"">2407.11029</a>",,2025-12-03 22:39:25
Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks,"Zhexin Zhang, Junxiao Yang, Pei Ke, Shiyao Cui, Chujie Zheng, Hongning Wang, Minlie Huang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.02855"" target=""_blank"">2407.02855</a>","<a href=""https://github.com/thu-coai/SafeUnlearning"" target=""_blank"">thu-coai</a>",2025-12-03 22:39:25
Self-Evaluation as a Defense Against Adversarial Attacks on LLMs,"Hannah Brown, Leon Lin, Kenji Kawaguchi, Michael Shieh",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03234"" target=""_blank"">2407.03234</a>","<a href=""https://github.com/Linlt-leon/self-eval"" target=""_blank"">Linlt-leon</a>",2025-12-03 22:39:25
Backdoor Graph Condensation,"Jiahao Wu, Ning Lu, Zeiyu Dai, Wenqi Fan, Shengcai Liu, Qing Li, Ke Tang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11025"" target=""_blank"">2407.11025</a>",,2025-12-03 22:39:25
Federated Learning for Zero-Day Attack Detection in 5G and Beyond V2X Networks,"Abdelaziz Amara korba, Abdelwahab Boualouache, Bouziane Brik, Rabah Rahal, Yacine Ghamri-Doudane, Sidi Mohammed Senouci",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03070"" target=""_blank"">2407.03070</a>",,2025-12-03 22:39:25
An Empirical Study on Capability of Large Language Models in Understanding Code Semantics,"Thu-Trang Nguyen, Thanh Trong Vu, Hieu Dinh Vo, Son Nguyen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03611"" target=""_blank"">2407.03611</a>",,2025-12-03 22:39:25
On Large Language Models in National Security Applications,"William N. Caballero, Phillip R. Jenkins",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.03453"" target=""_blank"">2407.03453</a>",,2025-12-03 22:39:25
Robust Adaptation of Foundation Models with Black-Box Visual Prompting,"Changdae Oh, Gyeongdeok Seo, Geunyoung Jung, Zhi-Qi Cheng, Hosik Choi, Jiyoung Jung, Kyungwoo Song",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.17491"" target=""_blank"">2407.17491</a>",,2025-12-03 22:39:25
Security Matrix for Multimodal Agents on Mobile Devices: A Systematic and Proof of Concept Study,"Yulong Yang, Xinshan Yang, Shuaidong Li, Chenhao Lin, Zhengyu Zhao, Chao Shen, Tianwei Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09295"" target=""_blank"">2407.09295</a>",,2025-12-03 22:39:25
Exploring the Causality of End-to-End Autonomous Driving,"Jiankun Li, Hao Li, Jiangjiang Liu, Zhikang Zou, Xiaoqing Ye, Fan Wang, Jizhou Huang, Hua Wu, Haifeng Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.06546"" target=""_blank"">2407.06546</a>","<a href=""https://github.com/bdvisl/DriveInsight"" target=""_blank"">bdvisl</a>",2025-12-03 22:39:25
Robust Yet Efficient Conformal Prediction Sets,"Soroush H. Zargarbashi, Mohammad Sadegh Akhondzadeh, Aleksandar Bojchevski",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09165"" target=""_blank"">2407.09165</a>",,2025-12-03 22:39:25
Multimodal Unlearnable Examples: Protecting Data against Multimodal Contrastive Learning,"Xinwei Liu, Xiaojun Jia, Yuan Xun, Siyuan Liang, Xiaochun Cao",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.16307"" target=""_blank"">2407.16307</a>","<a href=""https://github.com/thinwayliu/Multimodal-Unlearnable-Examples"" target=""_blank"">thinwayliu</a>",2025-12-03 22:39:25
Scaling Trends in Language Model Robustness,"Nikolaus Howe, Ian McKenzie, Oskar Hollinsworth, Michał Zajac, Tom Tseng, Aaron Tucker, Pierre-Luc Bacon, Adam Gleave",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18213"" target=""_blank"">2407.18213</a>",,2025-12-03 22:39:25
A Unified Understanding of Adversarial Vulnerability Regarding Unimodal Models and Vision-Language Pre-training Models,"Haonan Zheng, Xinyang Deng, Wen Jiang, Wenrui Li",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.17797"" target=""_blank"">2407.17797</a>",,2025-12-03 22:39:25
RIDA: A Robust Attack Framework on Incomplete Graphs,"Jianke Yu, Hanchen Wang, Chen Chen, Xiaoyang Wang, Lu Qin, Wenjie Zhang, Ying Zhang, Xijuan Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18170"" target=""_blank"">2407.18170</a>",,2025-12-03 22:39:25
Adversarially Robust Decision Transformer,"Xiaohang Tang, Afonso Marques, Parameswaran Kamalaruban, Ilija Bogunovic",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18414"" target=""_blank"">2407.18414</a>",,2025-12-03 22:39:25
Peak-Controlled Logits Poisoning Attack in Federated Distillation,"Yuhan Tang, Aoxu Zhang, Zhiyuan Wu, Bo Gao, Tian Wen, Yuwei Wang, Sheng Sun",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18039"" target=""_blank"">2407.18039</a>",,2025-12-03 22:39:25
Network Inversion of Convolutional Neural Nets,"Pirzada Suhail, Amit Sethi",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18002"" target=""_blank"">2407.18002</a>",,2025-12-03 22:39:25
Regret-Optimal Defense Against Stealthy Adversaries: A System Level Approach,"Hiroyasu Tsukamoto, Joudi Hajar, Soon-Jo Chung, Fred Y. Hadaegh",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18448"" target=""_blank"">2407.18448</a>",,2025-12-03 22:39:25
Physical Adversarial Attack on Monocular Depth Estimation via Shape-Varying Patches,"Chenxing Zhao, Yang Li, Shihao Wu, Wenyi Tan, Shuangju Zhou, Quan Pan",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.17312"" target=""_blank"">2407.17312</a>",,2025-12-03 22:39:25
FLRT: Fluent Student-Teacher Redteaming,"T. Ben Confirm Labs Thompson, Michael Confirm Labs Sklar",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.17447"" target=""_blank"">2407.17447</a>",,2025-12-03 22:39:25
S-E Pipeline: A Vision Transformer (ViT) based Resilient Classification Pipeline for Medical Imaging Against Adversarial Attacks,"Neha A S, Vivek Chaturvedi, Muhammad Shafique",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.17587"" target=""_blank"">2407.17587</a>",,2025-12-03 22:39:25
Algebraic Adversarial Attacks on Integrated Gradients,"Lachlan Simpson, Federico Costanza, Kyle Millar, Adriel Cheng, Cheng-Chew Lim, Hong Gunn Chew",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.16233"" target=""_blank"">2407.16233</a>",,2025-12-03 22:39:25
When AI Defeats Password Deception! A Deep Learning Framework to Distinguish Passwords and Honeywords,"Jimmy Dani, Brandon McCulloh, Nitesh Saxena",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.16964"" target=""_blank"">2407.16964</a>",,2025-12-03 22:39:25
UniForensics: Face Forgery Detection via General Facial Representation,"Ziyuan Fang, Hanqing Zhao, Tianyi Wei, Wenbo Zhou, Ming Wan, Zhanyi Wang, Weiming Zhang, Nenghai Yu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19079"" target=""_blank"">2407.19079</a>",,2025-12-03 22:39:25
Figure it Out: Analyzing-based Jailbreak Attack on Large Language Models,"Shi Lin, Rongchang Li, Xun Wang, Changting Lin, Wenpeng Xing, Meng Han",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.16205"" target=""_blank"">2407.16205</a>","<a href=""https://github.com/theshi-1128/ABJ-Attack"" target=""_blank"">theshi-1128</a>",2025-12-03 22:39:25
RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent,"Huiyu Xu, Wenhui Zhang, Zhibo Wang, Feng Xiao, Rui Zheng, Yunhe Feng, Zhongjie Ba, Kui Ren",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.16667"" target=""_blank"">2407.16667</a>",,2025-12-03 22:39:25
From Sands to Mansions: Towards Automated Cyberattack Emulation with Classical Planning and Large Language Models,"Lingzhi Wang, Zhenyuan Li, Yi Jiang, Zhengkai Wang, Zonghan Guo, Jiahui Wang, Yangyang Wei, Xiangmin Shen, Wei Ruan, Yan Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.16928"" target=""_blank"">2407.16928</a>",,2025-12-03 22:39:25
Enhancing Transferability of Targeted Adversarial Examples: A Self-Universal Perspective,"Bowen Peng, Li Liu, Tianpeng Liu, Zhen Liu, Yongxiang Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15683"" target=""_blank"">2407.15683</a>",,2025-12-03 22:39:25
Towards Robust Vision Transformer via Masked Adaptive Ensemble,"Fudong Lin, Jiadong Lou, Xu Yuan, Nian-Feng Tzeng",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15385"" target=""_blank"">2407.15385</a>",,2025-12-03 22:39:25
Towards Efficient Transferable Preemptive Adversarial Defense,"Hanrui Wang, Ching-Chun Chang, Chun-Shien Lu, Isao Echizen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15524"" target=""_blank"">2407.15524</a>",,2025-12-03 22:39:25
Poisoning with A Pill: Circumventing Detection in Federated Learning,"Hanxi Guo, Hao Wang, Tao Song, Tianhang Zheng, Yang Hua, Haibing Guan, Xiangyu Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15389"" target=""_blank"">2407.15389</a>",,2025-12-03 22:39:25
Revisiting the Robust Alignment of Circuit Breakers,"Leo Schwinn, Simon Geisler",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15902"" target=""_blank"">2407.15902</a>","<a href=""https://github.com/SchwinnL/circuit-breakers-eval"" target=""_blank"">SchwinnL</a>",2025-12-03 22:39:25
Imposter,"Xiao Liu, Liangzhi Li, Tong Xiang, Fuying Ye, Lu Wei, Wangyue Li, Noa Garcia",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15399"" target=""_blank"">2407.15399</a>",,2025-12-03 22:39:25
Virtual Reality and Augmented Reality Security: A Reconnaissance and Vulnerability Assessment Approach,Sarina Dastgerdy,arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15984"" target=""_blank"">2407.15984</a>",,2025-12-03 22:39:25
Failures to Find Transferable Image Jailbreaks Between Vision-Language Models,"Rylan Schaeffer, Dan Valentine, Luke Bailey, James Chua, Cristóbal Eyzaguirre, Zane Durante, Joe Benton, Brando Miranda, Henry Sleight, John Hughes, Rajashree Agrawal, Mrinank Sharma, Scott Emmons, Sanmi Koyejo, Ethan Perez",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15211"" target=""_blank"">2407.15211</a>",,2025-12-03 22:39:25
Sparse vs Contiguous Adversarial Pixel Perturbations in Multimodal Models: An Empirical Analysis,"Cristian-Alexandru Botocan, Raphael Meier, Ljiljana Dolamic",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18251"" target=""_blank"">2407.18251</a>",,2025-12-03 22:39:25
A Survey of Malware Detection Using Deep Learning,"Ahmed Bensaoud, Jugal Kalita, Mahmoud Bensaoud",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19153"" target=""_blank"">2407.19153</a>",,2025-12-03 22:39:25
SeqMIA: Sequential-Metric Based Membership Inference Attack,"Hao Li, Zheng Li, Siyuan Wu, Chengrui Hu, Yutong Ye, Min Zhang, Dengguo Feng, Yang Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15098"" target=""_blank"">2407.15098</a>",,2025-12-03 22:39:25
Adversarial Robustness in RGB-Skeleton Action Recognition: Leveraging Attention Modality Reweighter,"Chao Liu, Xin Liu, Zitong Yu, Yonghong Hou, Huanjing Yue, Jingyu Yang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19981"" target=""_blank"">2407.19981</a>",,2025-12-03 22:39:25
Cross-modality Information Check for Detecting Jailbreaking in Multimodal Large Language Models,"Yue Xu, Xiuyuan Qi, Zhan Qin, Wenjie Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.21659"" target=""_blank"">2407.21659</a>",,2025-12-03 22:39:25
Deep Adversarial Defense Against Multilevel-Lp Attacks,"Ren Wang, Yuxuan Li, Alfred Hero",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09251"" target=""_blank"">2407.09251</a>",,2025-12-03 22:39:25
The Llama 3 Herd of Models,"Abhimanyu Jack Dubey, Abhinav Jack Jauhri, Abhinav Jack Pandey, Abhishek Jack Kadian, Ahmad Jack Al-Dahle, Aiesha Jack Letman, Akhil Jack Mathur, Alan Jack Schelten, Amy Jack Yang, Angela Jack Fan, Anirudh Jack Goyal, Anthony Jack Hartshorn, Aobo Jack Yang, Archi Jack Mitra, Archie Jack Sravankumar, Artem Jack Korenev, Arthur Jack Hinsvark, Arun Jack Rao, Aston Jack Zhang, Aurelien Jack Rodriguez, Austen Jack Gregerson, Ava Jack Spataru, Baptiste Jack Roziere, Bethany Jack Biron, Binh Jack Tang, Bobbie Jack Chern, Charlotte Jack Caucheteux, Chaya Jack Nayak, Chloe Jack Bi, Chris Jack Marra, Chris Jack McConnell, Christian Jack Keller, Christophe Jack Touret, Chunyang Jack Wu, Corinne Jack Wong, Cristian Canton Jack Ferrer, Cyrus Jack Nikolaidis, Damien Jack Allonsius, Daniel Jack Song, Danielle Jack Pintz, Danny Jack Livshits, David Jack Esiobu, Dhruv Jack Choudhary, Dhruv Jack Mahajan, Diego Jack Garcia-Olano, Diego Jack Perino, Dieuwke Jack Hupkes, Egor Jack Lakomkin, Ehab Jack AlBadawy, Elina Jack Lobanova, Emily Jack Dinan, Eric Michael Jack Smith, Filip Jack Radenovic, Frank Jack Zhang, Gabriel Jack Synnaeve, Gabrielle Jack Lee, Georgia Lewis Jack Anderson, Graeme Jack Nail, Gregoire Jack Mialon, Guan Jack Pang, Guillem Jack Cucurell, Hailey Jack Nguyen, Hannah Jack Korevaar, Hu Jack Xu, Hugo Jack Touvron, Iliyan Jack Zarov, Imanol Arrieta Jack Ibarra, Isabel Jack Kloumann, Ishan Jack Misra, Ivan Jack Evtimov, Jade Jack Copet, Jaewon Jack Lee, Jan Jack Geffert, Jana Jack Vranes, Jason Jack Park, Jay Jack Mahadeokar, Jeet Jack Shah, der Linde Jelmer Jack van, Jennifer Jack Billock, Jenny Jack Hong, Jenya Jack Lee, Jeremy Jack Fu, Jianfeng Jack Chi, Jianyu Jack Huang, Jiawen Jack Liu, Jie Jack Wang, Jiecao Jack Yu, Joanna Jack Bitton, Joe Jack Spisak, Jongsoo Jack Park, Joseph Jack Rocca, Joshua Jack Johnstun, Joshua Jack Saxe, Junteng Jack Jia, Kalyan Vasuden Jack Alwala, Kartikeya Jack Upasani, Kate Jack Plawiak, Ke Jack Li, Kenneth Jack Heafield, Kevin Jack Stone, Khalid Jack El-Arini, Krithika Jack Iyer, Kshitiz Jack Malik, Kuenley Jack Chiu, Kunal Jack Bhalla, Lauren Jack Rantala-Yeary, der Maaten Laurens Jack van, Lawrence Jack Chen, Liang Jack Tan, Liz Jack Jenkins, Louis Jack Martin, Lovish Jack Madaan, Lubo Jack Malo, Lukas Jack Blecher, Lukas Jack Landzaat, Oliveira Luke Jack de, Madeline Jack Muzzi, Mahesh Jack Pasupuleti, Mannat Jack Singh, Manohar Jack Paluri, Marcin Jack Kardas, Mathew Jack Oldham, Mathieu Jack Rita, Maya Jack Pavlova, Melanie Jack Kambadur, Mike Jack Lewis, Min Jack Si, Mitesh Kumar Jack Singh, Mona Jack Hassan, Naman Jack Goyal, Narjes Jack Torabi, Nikolay Jack Bashlykov, Nikolay Jack Bogoychev, Niladri Jack Chatterji, Olivier Jack Duchenne, Onur Jack Çelebi, Patrick Jack Alrassy, Pengchuan Jack Zhang, Pengwei Jack Li, Petar Jack Vasic, Peter Jack Weng, Prajjwal Jack Bhargava, Pratik Jack Dubal, Praveen Jack Krishnan, Punit Singh Jack Koura, Puxin Jack Xu, Qing Jack He, Qingxiao Jack Dong, Ragavan Jack Srinivasan, Raj Jack Ganapathy, Ramon Jack Calderer, Ricardo Silveira Jack Cabral, Robert Jack Stojnic, Roberta Jack Raileanu, Rohit Jack Girdhar, Rohit Jack Patel, Romain Jack Sauvestre, Ronnie Jack Polidoro, Roshan Jack Sumbaly, Ross Jack Taylor, Ruan Jack Silva, Rui Jack Hou, Rui Jack Wang, Saghar Jack Hosseini, Sahana Jack Chennabasappa, Sanjay Jack Singh, Sean Jack Bell, Seohyun Sonia Jack Kim, Sergey Jack Edunov, Shaoliang Jack Nie, Sharan Jack Narang, Sharath Jack Raparthy, Sheng Jack Shen, Shengye Jack Wan, Shruti Jack Bhosale, Shun Jack Zhang, Simon Jack Vandenhende, Soumya Jack Batra, Spencer Jack Whitman, Sten Jack Sootla, Stephane Jack Collot, Suchin Jack Gururangan, Sydney Jack Borodinsky, Tamar Jack Herman, Tara Jack Fowler, Tarek Jack Sheasha, Thomas Jack Georgiou, Thomas Jack Scialom, Tobias Jack Speckbacher, Todor Jack Mihaylov, Tong Jack Xiao, Ujjwal Jack Karn, Vedanuj Jack Goswami, Vibhor Jack Gupta, Vignesh Jack Ramanathan, Viktor Jack Kerkez, Vincent Jack Gonguet, Virginie Jack Do, Vish Jack Vogeti, Vladan Jack Petrovic, Weiwei Jack Chu, Wenhan Jack Xiong, Wenyin Jack Fu, Whitney Jack Meers, Xavier Jack Martinet, Xiaodong Jack Wang, Xiaoqing Ellen Jack Tan, Xinfeng Jack Xie, Xuchao Jack Jia, Xuewei Jack Wang, Yaelle Jack Goldschlag, Yashesh Jack Gaur, Yasmine Jack Babaei, Yi Jack Wen, Yiwen Jack Song, Yuchen Jack Zhang, Yue Jack Li, Yuning Jack Mao, Zacharie Delpierre Jack Coudert, Zheng Jack Yan, Zhengxing Jack Chen, Zoe Jack Papakipos, Aaditya Jack Singh, Aaron Jack Grattafiori, Abha Jack Jain, Adam Jack Kelsey, Adam Jack Shajnfeld, Adithya Jack Gangidi, Adolfo Jack Victoria, Ahuva Jack Goldstand, Ajay Jack Menon, Ajay Jack Sharma, Alex Jack Boesenberg, Alex Jack Vaughan, Alexei Jack Baevski, Allie Jack Feinstein, Amanda Jack Kallet, Amit Jack Sangani, Anam Jack Yunus, Andrei Jack Lupu, Andres Jack Alvarado, Andrew Jack Caples, Andrew Jack Gu, Andrew Jack Ho, Andrew Jack Poulton, Andrew Jack Ryan, Ankit Jack Ramchandani, Annie Jack Franco, Aparajita Jack Saraf, Arkabandhu Jack Chowdhury, Ashley Jack Gabriel, Ashwin Jack Bharambe, Assaf Jack Eisenman, Azadeh Jack Yazdan, Beau Jack James, Ben Jack Maurer, Benjamin Jack Leonhardi, Bernie Jack Huang, Beth Jack Loyd, Paola Beto Jack De, Bhargavi Jack Paranjape, Bing Jack Liu, Bo Jack Wu, Boyu Jack Ni, Braden Jack Hancock, Bram Jack Wasti, Brandon Jack Spence, Brani Jack Stojkovic, Brian Jack Gamido, Britt Jack Montalvo, Carl Jack Parker, Carly Jack Burton, Catalina Jack Mejia, Changhan Jack Wang, Changkyu Jack Kim, Chao Jack Zhou, Chester Jack Hu, Ching-Hsiang Jack Chu, Chris Jack Cai, Chris Jack Tindal, Christoph Jack Feichtenhofer, Damon Jack Civin, Dana Jack Beaty, Daniel Jack Kreymer, Daniel Jack Li, Danny Jack Wyatt, David Jack Adkins, David Jack Xu, Davide Jack Testuggine, Delia Jack David, Devi Jack Parikh, Diana Jack Liskovich, Didem Jack Foss, Dingkang Jack Wang, Duc Jack Le, Dustin Jack Holland, Edward Jack Dowling, Eissa Jack Jamil, Elaine Jack Montgomery, Eleonora Jack Presani, Emily Jack Hahn, Emily Jack Wood, Erik Jack Brinkman, Esteban Jack Arcaute, Evan Jack Dunbar, Evan Jack Smothers, Fei Jack Sun, Felix Jack Kreuk, Feng Jack Tian, Firat Jack Ozgenel, Francesco Jack Caggioni, Francisco Jack Guzmán, Frank Jack Kanayet, Frank Jack Seide, Gabriela Medina Jack Florez, Gabriella Jack Schwarz, Gada Jack Badeer, Georgia Jack Swee, Gil Jack Halpern, Govind Jack Thattai, Grant Jack Herman, Grigory Jack Sizov, Jack Guangyi, Sid Zhang, Guna Sid Lakshminarayanan, Hamid Sid Shojanazeri, Han Sid Zou, Hannah Sid Wang, Hanwen Sid Zha, Haroun Sid Habeeb, Harrison Sid Rudolph, Helen Sid Suk, Henry Sid Aspegren, Hunter Sid Goldman, Igor Sid Molybog, Igor Sid Tufanov, Irina-Elena Sid Veliche, Itai Sid Gat, Jake Sid Weissman, James Sid Geboski, James Sid Kohli, Japhet Sid Asher, Jean-Baptiste Sid Gaya, Jeff Sid Marcus, Jeff Sid Tang, Jennifer Sid Chan, Jenny Sid Zhen, Jeremy Sid Reizenstein, Jeremy Sid Teboul, Jessica Sid Zhong, Jian Sid Jin, Jingyi Sid Yang, Joe Sid Cummings, Jon Sid Carvill, Jon Sid Shepard, Jonathan Sid McPhie, Jonathan Sid Torres, Josh Sid Ginsburg, Junjie Sid Wang, Kai Sid Wu, Kam Hou Sid U, Karan Sid Saxena, Karthik Sid Prasad, Kartikay Sid Khandelwal, Katayoun Sid Zand, Kathy Sid Matosich, Kaushik Sid Veeraraghavan, Kelly Sid Michelena, Keqian Sid Li, Kun Sid Huang, Kunal Sid Chawla, Kushal Sid Lakhotia, Kyle Sid Huang, Lailin Sid Chen, Lakshya Sid Garg, Lavender Sid A, Leandro Sid Silva, Lee Sid Bell, Lei Sid Zhang, Liangpeng Sid Guo, Licheng Sid Yu, Liron Sid Moshkovich, Luca Sid Wehrstedt, Madian Sid Khabsa, Manav Sid Avalani, Manish Sid Bhatt, Maria Sid Tsimpoukelli, Martynas Sid Mankus, Matan Sid Hasson, Matthew Sid Lennie, Matthias Sid Reso, Maxim Sid Groshev, Maxim Sid Naumov, Maya Sid Lathi, Meghan Sid Keneally, Michael L. Sid Seltzer, Michal Sid Valko, Michelle Sid Restrepo, Mihir Sid Patel, Mik Sid Vyatskov, Mikayel Sid Samvelyan, Mike Sid Clark, Mike Sid Macey, Mike Sid Wang, Miquel Jubert Sid Hermoso, Mo Sid Metanat, Mohammad Sid Rastegari, Munish Sid Bansal, Nandhini Sid Santhanam, Natascha Sid Parks, Natasha Sid White, Navyata Sid Bawa, Nayan Sid Singhal, Nick Sid Egebo, Nicolas Sid Usunier, Nikolay Pavlovich Sid Laptev, Ning Sid Dong, Ning Sid Zhang, Norman Sid Cheng, Oleg Sid Chernoguz, Olivia Sid Hart, Omkar Sid Salpekar, Ozlem Sid Kalinli, Parkin Sid Kent, Parth Sid Parekh, Paul Sid Saab, Pavan Sid Balaji, Pedro Sid Rittner, Philip Sid Bontrager, Pierre Sid Roux, Piotr Sid Dollar, Polina Sid Zvyagina, Prashant Sid Ratanchandani, Pritish Sid Yuvraj, Qian Sid Liang, Rachad Sid Alao, Rachel Sid Rodriguez, Rafi Sid Ayub, Raghotham Sid Murthy, Raghu Sid Nayani, Rahul Sid Mitra, Raymond Sid Li, Rebekkah Sid Hogan, Robin Sid Battey, Rocky Sid Wang, Rohan Sid Maheswari, Russ Sid Howes, Ruty Sid Rinott, Sai Jayesh Sid Bondu, Samyak Sid Datta, Sara Sid Chugh, Sara Sid Hunt, Sargun Sid Dhillon, Sasha Sid Sidorov, Satadru Sid Pan, Saurabh Sid Verma, Seiji Sid Yamamoto, Sharadh Sid Ramaswamy, Shaun Sid Lindsay, Shaun Sid Lindsay, Sheng Sid Feng, Shenghao Sid Lin, Shengxin Cindy Sid Zha, Shiva Sid Shankar, Shuqiang Sid Zhang, Shuqiang Sid Zhang, Sinong Sid Wang, Sneha Sid Agarwal, Soji Sid Sajuyigbe, Soumith Sid Chintala, Stephanie Sid Max, Stephen Sid Chen, Steve Sid Kehoe, Steve Sid Satterfield, Sudarshan Sid Govindaprasad, Sumit Sid Gupta, Sungmin Sid Cho, Sunny Sid Virk, Suraj Sid Subramanian, Sy Sid Choudhury, Sydney Sid Goldman, Tal Sid Remez, Tamar Sid Glaser, Tamara Sid Best, Thilo Sid Kohler, Thomas Sid Robinson, Tianhe Sid Li, Tianjun Sid Zhang, Tim Sid Matthews, Timothy Sid Chou, Tzook Sid Shaked, Varun Sid Vontimitta, Victoria Sid Ajayi, Victoria Sid Montanez, Vijai Sid Mohan, Vinay Satish Sid Kumar, Vishal Sid Mangla, Vlad Sid Ionescu, Vlad Sid Poenaru, Vlad Tiberiu Sid Mihailescu, Vladimir Sid Ivanov, Wei Sid Li, Wenchen Sid Wang, Wenwen Sid Jiang, Wes Sid Bouaziz, Will Sid Constable, Xiaocheng Sid Tang, Xiaofang Sid Wang, Xiaojian Sid Wu, Xiaolan Sid Wang, Xide Sid Xia, Xilun Sid Wu, Xinbo Sid Gao, Yanjun Sid Chen, Ye Sid Hu, Ye Sid Jia, Ye Sid Qi, Yenda Sid Li, Yilin Sid Zhang, Ying Sid Zhang, Yossi Sid Adi, Youngjin Sid Nam, Sid Yu, Wang, Yuchen Hao, Yundi Qian, Yuzi He, Zach Rait, Zachary DeVito, Zef Rosnbrick, Zhaoduo Wen, Zhenyu Yang, Zhiwei Zhao",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.21783"" target=""_blank"">2407.21783</a>",,2025-12-03 22:39:25
Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks,"Hunmin Yang, Jongoh Jeong, Kuk-Jin Yoon",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20657"" target=""_blank"">2407.20657</a>",,2025-12-03 22:39:25
AI Safety in Practice: Enhancing Adversarial Robustness in Multimodal Image Captioning,"Maisha Binte Rashid, Pablo Rivas",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.21174"" target=""_blank"">2407.21174</a>",,2025-12-03 22:39:25
FACL-Attack: Frequency-Aware Contrastive Learning for Transferable Adversarial Attacks,"Hunmin Yang, Jongoh Jeong, Kuk-Jin Yoon",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20653"" target=""_blank"">2407.20653</a>",,2025-12-03 22:39:25
Vulnerabilities in AI-generated Image Detection: The Challenge of Adversarial Attacks,"Yunfeng Diao, Naixin Zhai, Changtao Miao, Zitong Yu, Xingxing Wei, Xun Yang, Meng Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20836"" target=""_blank"">2407.20836</a>",,2025-12-03 22:39:25
Diff-Cleanse: Identifying and Mitigating Backdoor Attacks in Diffusion Models,"Jiang Hao, Xiao Jin, Hu Xiaoguang, Chen Tianyou",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.21316"" target=""_blank"">2407.21316</a>","<a href=""https://github.com/shymuel/diff-cleanse"" target=""_blank"">shymuel</a>",2025-12-03 22:39:25
DeepBaR: Fault Backdoor Attack on Deep Neural Network Layers,"C. A. Martínez-Mejía, J. Solano, J. Breier, D. Bucko, X. Hou",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.21220"" target=""_blank"">2407.21220</a>",,2025-12-03 22:39:25
Breaking Agents: Compromising Autonomous LLM Agents Through Malfunction Amplification,"Boyang Zhang, Yicong Tan, Yun Shen, Ahmed Salem, Michael Backes, Savvas Zannettou, Yang Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20859"" target=""_blank"">2407.20859</a>",,2025-12-03 22:39:25
Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Neural Networks,"Bao Gia Doan, Afshar Shamsi, Xiao-Yu Guo, Arash Mohammadi, Hamid Alinejad-Rokny, Dino Sejdinovic, Damith C. Ranasinghe, Ehsan Abbasnejad",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20891"" target=""_blank"">2407.20891</a>",,2025-12-03 22:39:25
Enhancing Adversarial Text Attacks on BERT Models with Projected Gradient Descent,"Hetvi Waghela, Jaydip Sen, Sneha Rakshit",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.21073"" target=""_blank"">2407.21073</a>",,2025-12-03 22:39:25
Adversarial Robustification via Text-to-Image Diffusion Models,"Daewon Choi, Jongheon Jeong, Huiwon Jang, Jinwoo Shin",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18658"" target=""_blank"">2407.18658</a>",,2025-12-03 22:39:25
From ML to LLM: Evaluating the Robustness of Phishing Webpage Detection Models against Adversarial Attacks,"Aditya Kulkarni, Vivek Balachandran, Dinil Mon Divakaran, Tamal Das",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20361"" target=""_blank"">2407.20361</a>",,2025-12-03 22:39:25
Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability,"Jorge García-Carrasco, Alejandro Maté, Juan Trujillo",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19842"" target=""_blank"">2407.19842</a>",,2025-12-03 22:39:25
DDAP: Dual-Domain Anti-Personalization against Text-to-Image Diffusion Models,"Jing Yang, Runping Xi, Yingxin Lai, Xun Lin, Zitong Yu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20141"" target=""_blank"">2407.20141</a>",,2025-12-03 22:39:25
RSC-SNN: Exploring the Trade-off Between Adversarial Robustness and Accuracy in Spiking Neural Networks via Randomized Smoothing Coding,"Keming Wu, Man Yao, Yuhong Chou, Xuerui Qiu, Rui Yang, Bo Xu, Guoqi Li",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20099"" target=""_blank"">2407.20099</a>","<a href=""https://github.com/KemingWu/RSC-SNN"" target=""_blank"">KemingWu</a>",2025-12-03 22:39:25
Can Editing LLMs Inject Harm? (9%),"Canyu Chen, Baixiang Huang, Zekun Li, Zhaorun Chen, Shiyang Lai, Xiongxiao Xu, Jia-Chen Gu, Jindong Gu, Huaxiu Yao, Chaowei Xiao, Xifeng Yan, William Yang Wang, Philip Torr, Dawn Song, Kai Shu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20224"" target=""_blank"">2407.20224</a>",,2025-12-03 22:39:25
BackdoorBench: A Comprehensive Benchmark and Analysis of Backdoor Learning,"Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Mingli Zhu, Ruotong Wang, Li Liu, Chao Shen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19845"" target=""_blank"">2407.19845</a>",,2025-12-03 22:39:25
ImagiNet: A Multi-Content Dataset for Generalizable Synthetic Image Detection via Contrastive Learning,"Delyan Boychev, Radostin Cholakov",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.20020"" target=""_blank"">2407.20020</a>","<a href=""https://github.com/delyan-boychev/imaginet"" target=""_blank"">delyan-boychev</a>",2025-12-03 22:39:25
Exploring the Adversarial Robustness of CLIP for AI-generated Image Detection,"Rosa Vincenzo De, Fabrizio Guillaro, Giovanni Poggi, Davide Cozzolino, Luisa Verdoliva",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19553"" target=""_blank"">2407.19553</a>",,2025-12-03 22:39:25
EaTVul: ChatGPT-based Evasion Attack Against Software Vulnerability Detection,"Shigang Liu, Di Cao, Junae Kim, Tamas Abraham, Paul Montague, Seyit Camtepe, Jun Zhang, Yang Xiang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19216"" target=""_blank"">2407.19216</a>",,2025-12-03 22:39:25
Debiased Graph Poisoning Attack via Contrastive Surrogate Objective,"Kanghoon Yoon, Yeonjun In, Namkyeong Lee, Kibum Kim, Chanyoung Park",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.19155"" target=""_blank"">2407.19155</a>",,2025-12-03 22:39:25
Robust VAEs via Generating Process of Noise Augmented Data,"Hiroo Irobe, Wataru Aoki, Kimihiro Yamazaki, Yuhui Zhang, Takumi Nakagawa, Hiroki Waida, Yuichiro Wada, Takafumi Kanamori",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18632"" target=""_blank"">2407.18632</a>",,2025-12-03 22:39:25
A Learning-Based Attack Framework to Break SOTA Poisoning Defenses in Federated Learning,"Yuxin College of Computer Science and Technology, Jilin University Illinois Institute of Technology Yang, Qiang College of Computer Science and Technology, Jilin University Li, Chenfei College of Computer Science and Technology, Jilin University Nie, Yuan University of Connecticut Hong, Meng Nanchang University Pang, Binghui Illinois Institute of Technology Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15267"" target=""_blank"">2407.15267</a>","<a href=""https://github.com/Yuxin104/"" target=""_blank"">Yuxin104</a>",2025-12-03 22:39:25
Unveiling Privacy Vulnerabilities: Investigating the Role of Structure in Graph Data,"Hanyang Yuan, Jiarong Xu, Cong Wang, Ziqi Yang, Chunping Wang, Keting Yin, Yang Yang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.18564"" target=""_blank"">2407.18564</a>",,2025-12-03 22:39:25
Benchmark Granularity and Model Robustness for Image-Text Retrieval,"Mariya Hendriksen, Shuo Zhang, Ridho Reinanda, Mohamed Yahya, Edgar Meij, Rijke Maarten de",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.15239"" target=""_blank"">2407.15239</a>",,2025-12-03 22:39:25
Feature Inference Attack on Shapley Values,"Xinjian Luo, Yangfan Jiang, Xiaokui Xiao",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11359"" target=""_blank"">2407.11359</a>",,2025-12-03 22:39:25
Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness,"Kai Guo, Zewen Liu, Zhikai Chen, Hongzhi Wen, Wei Jin, Jiliang Tang, Yi Chang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12068"" target=""_blank"">2407.12068</a>",,2025-12-03 22:39:25
SegSTRONG-C: Segmenting Surgical Tools Robustly On Non-adversarial Generated Corruptions -- An EndoVis'24 Challenge,"Hao Ding, Tuxun Lu, Yuqian Zhang, Ruixing Liang, Hongchao Shu, Lalithkumar Seenivasan, Yonghao Long, Qi Dou, Cong Gao, Mathias Unberath",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11906"" target=""_blank"">2407.11906</a>",,2025-12-03 22:39:25
Does Refusal Training in LLMs Generalize to the Past Tense? (15%),"Maksym Andriushchenko, Nicolas Flammarion",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11969"" target=""_blank"">2407.11969</a>","<a href=""https://github.com/tml-epfl/llm-past-tense"" target=""_blank"">tml-epfl</a>",2025-12-03 22:39:25
Cover-separable Fixed Neural Network Steganography via Deep Generative Models,"Guobiao Li, Sheng Li, Zhenxing Qian, Xinpeng Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11405"" target=""_blank"">2407.11405</a>",,2025-12-03 22:39:25
Model Inversion Attacks Through Target-Specific Conditional Diffusion Models,"Ouxiang Li, Yanbin Hao, Zhicai Wang, Bin Zhu, Shuo Wang, Zaixi Zhang, Fuli Feng",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11424"" target=""_blank"">2407.11424</a>",,2025-12-03 22:39:25
IPA-NeRF: Illusory Poisoning Attack Against Neural Radiance Fields,"Wenxiang Ocean University of China Jiang, Hanwei Saarland University Institute of Intelligent Software, Guangzhou Zhang, Shuo Ocean University of China Zhao, Zhongwen Ocean University of China Guo, Hao Xidian University, China Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11921"" target=""_blank"">2407.11921</a>","<a href=""https://github.com/jiang-wenxiang/IPA-NeRF"" target=""_blank"">jiang-wenxiang</a>",2025-12-03 22:39:25
Wicked Oddities: Selectively Poisoning for Effective Clean-Label Backdoor Attacks,"Quang H. Nguyen, Nguyen Ngoc-Hieu, The-Anh Ta, Thanh Nguyen-Tang, Kok-Seng Wong, Hoang Thanh-Tung, Khoa D. Doan",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10825"" target=""_blank"">2407.10825</a>",,2025-12-03 22:39:25
Backdoor Attacks against Image-to-Image Networks,"Wenbo Jiang, Hongwei Li, Jiaming He, Rui Zhang, Guowen Xu, Tianwei Zhang, Rongxing Lu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10445"" target=""_blank"">2407.10445</a>",,2025-12-03 22:39:25
Towards Adversarially Robust Vision-Language Models: Insights from Design Choices and Prompt Formatting Techniques,"Rishika Bhagwatkar, Shravan Nayak, Reza Bayat, Alexis Roger, Daniel Z Kaplan, Pouya Bashivan, Irina Rish",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11121"" target=""_blank"">2407.11121</a>",,2025-12-03 22:39:25
PartImageNet++ Dataset: Scaling up Part-based Models for Robust Recognition,"Xiao Li, Yining Liu, Na Dong, Sitian Qin, Xiaolin Hu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10918"" target=""_blank"">2407.10918</a>",,2025-12-03 22:39:25
Uncertainty is Fragile: Manipulating Uncertainty in Large Language Models,"Qingcheng Zeng, Mingyu Jin, Qinkai Yu, Zhenting Wang, Wenyue Hua, Zihao Zhou, Guangyan Sun, Yanda Meng, Shiqing Ma, Qifan Wang, Felix Juefei-Xu, Kaize Ding, Fan Yang, Ruixiang Tang, Yongfeng Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11282"" target=""_blank"">2407.11282</a>","<a href=""https://github.com/qcznlp/uncertainty_attack"" target=""_blank"">qcznlp</a>",2025-12-03 22:39:25
Transferable 3D Adversarial Shape Completion using Diffusion Models,"Xuelong Dai, Bin Xiao",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10077"" target=""_blank"">2407.10077</a>",,2025-12-03 22:39:25
Relaxing Graph Transformers for Adversarial Attacks,"Philipp Foth, Lukas Gosch, Simon Geisler, Leo Schwinn, Stephan Günnemann",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11764"" target=""_blank"">2407.11764</a>",,2025-12-03 22:39:25
Towards Robust Recommendation via Decision Boundary-aware Graph Contrastive Learning,"Jiakai Tang, Sunhao Dai, Zexu Sun, Xu Chen, Jun Xu, Wenhui Yu, Lantao Hu, Peng Jiang, Han Li",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10184"" target=""_blank"">2407.10184</a>",,2025-12-03 22:39:25
Defending Against Repetitive-based Backdoor Attacks on Semi-supervised Learning through Lens of Rate-Distortion-Perception Trade-off,"Cheng-Yi Lee, Ching-Chia Kao, Cheng-Han Yeh, Chun-Shien Lu, Chia-Mu Yu, Chu-Song Chen",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10180"" target=""_blank"">2407.10180</a>",,2025-12-03 22:39:25
CLIP-Guided Networks for Transferable Targeted Attacks,"Hao Fang, Jiawei Kong, Bin Chen, Tao Dai, Hao Wu, Shu-Tao Xia",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10179"" target=""_blank"">2407.10179</a>",,2025-12-03 22:39:25
SENTINEL: Securing Indoor Localization against Adversarial Attacks with Capsule Neural Networks,"Danish Gufran, Pooja Anandathirtha, Sudeep Pasricha",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11091"" target=""_blank"">2407.11091</a>",,2025-12-03 22:39:25
Augmented Neural Fine-Tuning for Efficient Backdoor Purification,"Nazmul Karim, Abdullah Al Arafat, Umar Khalid, Zhishan Guo, Nazanin Rahnavard",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10052"" target=""_blank"">2407.10052</a>",,2025-12-03 22:39:25
Partner in Crime: Boosting Targeted Poisoning Attacks against Federated Learning,"Shihua Sun, Shridatt Sugrim, Angelos Stavrou, Haining Wang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09958"" target=""_blank"">2407.09958</a>",,2025-12-03 22:39:25
Team up GBDTs and DNNs: Advancing Efficient and Effective Tabular Prediction with Tree-hybrid MLPs,"Jiahuan Yan, Jintai Chen, Qianxing Wang, Danny Z. Chen, Jian Wu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09790"" target=""_blank"">2407.09790</a>",,2025-12-03 22:39:25
SemiAdv: Query-Efficient Black-Box Adversarial Attack with Unlabeled Images,"Mingyuan Fan, Yang Liu, Cen Chen, Ximeng Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11073"" target=""_blank"">2407.11073</a>",,2025-12-03 22:39:25
Sim-CLIP: Unsupervised Siamese Adversarial Fine-Tuning for Robust and Semantically-Rich Vision-Language Models,"Md Zarif Hossain, Ahmed Imteaj",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.14971"" target=""_blank"">2407.14971</a>",,2025-12-03 22:39:25
Evaluating the Adversarial Robustness of Semantic Segmentation: Trying Harder Pays Off,"Levente Halmosi, Bálint Mohos, Márk Jelasity",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09150"" target=""_blank"">2407.09150</a>",,2025-12-03 22:39:25
TAPI: Towards Target-Specific and Adversarial Prompt Injection against Code LLMs,"Yuchen Yang, Hongwei Yao, Bingrun Yang, Yiling He, Yiming Li, Tianwei Zhang, Zhan Qin, Kui Ren",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.09164"" target=""_blank"">2407.09164</a>",,2025-12-03 22:39:25
Turning Generative Models Degenerate: The Power of Data Poisoning Attacks,"Shuli Jiang, Swanand Ravindra Kadhe, Yi Zhou, Farhan Ahmed, Ling Cai, Nathalie Baracaldo",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12281"" target=""_blank"">2407.12281</a>",,2025-12-03 22:39:25
Provable Robustness of (Graph) Neural Networks Against Data Poisoning and Backdoor Attacks,"Lukas Gosch, Mahalakshmi Sabanayagam, Debarghya Ghoshdastidar, Stephan Günnemann",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.10867"" target=""_blank"">2407.10867</a>",,2025-12-03 22:39:25
Prover-Verifier Games improve legibility of LLM outputs,"Jan Hendrik Kirchner, Yining Chen, Harri Edwards, Jan Leike, Nat McAleese, Yuri Burda",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13692"" target=""_blank"">2407.13692</a>",,2025-12-03 22:39:25
Context-Aware Fuzzing for Robustness Enhancement of Deep Learning Models,"Haipeng Wang, Zhengyuan Wei, Qilin Zhou, Wing-Kwong Chan",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12428"" target=""_blank"">2407.12428</a>",,2025-12-03 22:39:25
Human-Interpretable Adversarial Prompt Attack on Large Language Models with Situational Context,"Nilanjana Das, Edward Raff, Manas Gaur",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.14644"" target=""_blank"">2407.14644</a>",,2025-12-03 22:39:25
Adversarial Databases Improve Success in Retrieval-based Large Language Models,"Sean Wu, Michael Koo, Li Yo Kao, Andy Black, Lesley Blum, Fabien Scalzo, Ira Kurtz",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.14609"" target=""_blank"">2407.14609</a>",,2025-12-03 22:39:25
UNIT: Backdoor Mitigation via Automated Neural Distribution Tightening,"Siyuan Cheng, Guangyu Shen, Kaiyuan Zhang, Guanhong Tao, Shengwei An, Hanxi Guo, Shiqing Ma, Xiangyu Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11372"" target=""_blank"">2407.11372</a>","<a href=""https://github.com/Megum1/UNIT"" target=""_blank"">Megum1</a>",2025-12-03 22:39:25
On the Robustness of Fully-Spiking Neural Networks in Open-World Scenarios using Forward-Only Learning Algorithms,"Erik B. Terres-Escudero, Ser Javier Del, Aitor Martínez-Seras, Pablo Garcia-Bringas",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.14097"" target=""_blank"">2407.14097</a>",,2025-12-03 22:39:25
Cross-Task Attack: A Self-Supervision Generative Framework Based on Attention Shift,"Qingyuan Zeng, Yunpeng Gong, Min Jiang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13700"" target=""_blank"">2407.13700</a>",,2025-12-03 22:39:25
Beyond Dropout: Robust Convolutional Neural Networks Based on Local Feature Masking,"Yunpeng Gong, Chuangliang Zhang, Yongjie Hou, Lifei Chen, Min Jiang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13646"" target=""_blank"">2407.13646</a>",,2025-12-03 22:39:25
Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation of Large Language Models,"Zhuo Chen, Jiawei Liu, Haotan Liu, Qikai Cheng, Fan Zhang, Wei Lu, Xiaozhong Liu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13757"" target=""_blank"">2407.13757</a>",,2025-12-03 22:39:25
Compressed models are NOT miniature versions of large models,"Rohit Raj Rai, Rishant Pal, Amit Awekar",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13174"" target=""_blank"">2407.13174</a>",,2025-12-03 22:39:25
Distributionally and Adversarially Robust Logistic Regression via Intersecting Wasserstein Balls,"Aras Selvi, Eleonora Kreacic, Mohsen Ghassemi, Vamsi Potluru, Tucker Balch, Manuela Veloso",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13625"" target=""_blank"">2407.13625</a>",,2025-12-03 22:39:25
A Closer Look at GAN Priors: Exploiting Intermediate Features for Enhanced Model Inversion Attacks,"Yixiang Qiu, Hao Fang, Hongyao Yu, Bin Chen, MeiKang Qiu, Shu-Tao Xia",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13863"" target=""_blank"">2407.13863</a>","<a href=""https://github.com/final-solution/IF-GMI"" target=""_blank"">final-solution</a>",2025-12-03 22:39:25
PG-Attack: A Precision-Guided Adversarial Attack Framework Against Vision Foundation Models for Autonomous Driving,"Jiyuan Fu, Zhaoyu Chen, Kaixun Jiang, Haijing Guo, Shuyong Gao, Wenqiang Zhang",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13111"" target=""_blank"">2407.13111</a>","<a href=""https://github.com/fuhaha824/PG-Attack"" target=""_blank"">fuhaha824</a>",2025-12-03 22:39:25
Preventing Catastrophic Overfitting in Fast Adversarial Training: A Bi-level Optimization Perspective,"Zhaoxin Wang, Handing Wang, Cong Tian, Yaochu Jin",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12443"" target=""_blank"">2407.12443</a>",,2025-12-03 22:39:25
Data Poisoning: An Overlooked Threat to Power Grid Resilience,"Nora Agah, Javad Mohammadi, Alex Aved, David Ferris, Erika Ardiles Cruz, Philip Morrone",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.14684"" target=""_blank"">2407.14684</a>",,2025-12-03 22:39:25
AEMIM: Adversarial Examples Meet Masked Image Modeling,"Wenzhao Xiang, Chang Liu, Hang Su, Hongyang Yu",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11537"" target=""_blank"">2407.11537</a>",,2025-12-03 22:39:25
Contrastive Adversarial Training for Unsupervised Domain Adaptation,"Jiahong Chen, Zhilin Zhang, Lucy Li, Behzad Shahrasbi, Arjun Mishra",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12782"" target=""_blank"">2407.12782</a>",,2025-12-03 22:39:25
Investigating Imperceptibility of Adversarial Attacks on Tabular Data: An Empirical Analysis,"Zhipeng He, Chun Ouyang, Laith Alzubaidi, Alistair Barros, Catarina Moreira",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11463"" target=""_blank"">2407.11463</a>",,2025-12-03 22:39:25
Krait: A Backdoor Attack Against Graph Prompt Tuning,"Ying Song, Rita Singh, Balaji Palanisamy",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13068"" target=""_blank"">2407.13068</a>",,2025-12-03 22:39:25
Variational Randomized Smoothing for Sample-Wise Adversarial Robustness,"Ryo Hase, Ye Wang, Toshiaki Koike-Akino, Jing Liu, Kieran Parsons",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11844"" target=""_blank"">2407.11844</a>",,2025-12-03 22:39:25
Rethinking Video-Text Understanding: Retrieval from Counterfactually Augmented Data,"Wufei Ma, Kai Li, Zhongshi Jiang, Moustafa Meshry, Qihao Liu, Huiyu Wang, Christian Häne, Alan Yuille",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.13094"" target=""_blank"">2407.13094</a>","<a href=""https://feint6k.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Any Target Can be Offense: Adversarial Example Generation via Generalized Latent Infection,"Youheng Sun, Shengming Yuan, Xuanhan Wang, Lianli Gao, Jingkuan Song",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12292"" target=""_blank"">2407.12292</a>","<a href=""https://github.com/VL-Group/GAKer"" target=""_blank"">VL-Group</a>",2025-12-03 22:39:25
Direct Unlearning Optimization for Robust and Safe Text-to-Image Models,"Yong-Hyun Park, Sangdoo Yun, Jin-Hwa Kim, Junho Kim, Geonhui Jang, Yonghyun Jeong, Junghyo Jo, Gayoung Lee",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.21035"" target=""_blank"">2407.21035</a>",,2025-12-03 22:39:25
Benchmarking Robust Self-Supervised Learning Across Diverse Downstream Tasks,"Antoni Kowalczuk, Jan Dubiński, Atiyeh Ashari Ghomi, Yi Sui, George Stein, Jiapeng Wu, Jesse C. Cresswell, Franziska Boenisch, Adam Dziedzic",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12588"" target=""_blank"">2407.12588</a>",,2025-12-03 22:39:25
AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases,"Zhaorun Chen, Zhen Xiang, Chaowei Xiao, Dawn Song, Bo Li",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.12784"" target=""_blank"">2407.12784</a>",,2025-12-03 22:39:25
Enhancing TinyML Security: Study of Adversarial Attack Transferability,"Parin Shah, Yuvaraj Govindarajulu, Pavan Kulkarni, Manojkumar Parmar",arXiv,2024-07,"<a href=""http://arxiv.org/abs/2407.11599"" target=""_blank"">2407.11599</a>",,2025-12-03 22:39:25
PSBD: Prediction Shift Uncertainty Unlocks Backdoor Detection,"Wei Li, Pin-Yu Chen, Sijia Liu, Ren Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05826"" target=""_blank"">2406.05826</a>",,2025-12-03 22:39:25
Self-supervised Adversarial Training of Monocular Depth Estimation against Physical-World Attacks,"Zhiyuan Cheng, Cheng Han, James Liang, Qifan Wang, Xiangyu Zhang, Dongfang Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05857"" target=""_blank"">2406.05857</a>",,2025-12-03 22:39:25
Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents,"Avital Shafran, Roei Schuster, Vitaly Shmatikov",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05870"" target=""_blank"">2406.05870</a>",,2025-12-03 22:39:25
Certified Robustness to Data Poisoning in Gradient-Based Training,"Philip Sosnin, Mark N. Müller, Maximilian Baader, Calvin Tsay, Matthew Wicker",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05670"" target=""_blank"">2406.05670</a>",,2025-12-03 22:39:25
ProFeAT: Projected Feature Adversarial Training for Self-Supervised Learning of Robust Representations,"Sravanti Addepalli, Priyam Dey, R. Venkatesh Babu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05796"" target=""_blank"">2406.05796</a>",,2025-12-03 22:39:25
SlowPerception: Physical-World Latency Attack against Visual Perception in Autonomous Driving,"Chen Ma, Ningfei Wang, Zhengyu Zhao, Qi Alfred Chen, Chao Shen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05800"" target=""_blank"">2406.05800</a>",,2025-12-03 22:39:25
Fast White-Box Adversarial Streaming Without a Random Oracle,"Ying Feng, Aayush Jain, David P. Woodruff",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06808"" target=""_blank"">2406.06808</a>",,2025-12-03 22:39:25
ControlLoc: Physical-World Hijacking Attack on Visual Perception in Autonomous Driving,"Chen Ma, Ningfei Wang, Zhengyu Zhao, Qian Wang, Qi Alfred Chen, Chao Shen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05810"" target=""_blank"">2406.05810</a>",,2025-12-03 22:39:25
Stealthy Targeted Backdoor Attacks against Image Captioning,"Wenshu Fan, Hongwei Li, Wenbo Jiang, Meng Hao, Shui Yu, Xiao Zhang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05874"" target=""_blank"">2406.05874</a>",,2025-12-03 22:39:25
MeanSparse: Post-Training Robustness Enhancement Through Mean-Centered Feature Sparsification,"Sajjad Amini, Mohammadreza Teymoorianfard, Shiqing Ma, Amir Houmansadr",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05927"" target=""_blank"">2406.05927</a>","<a href=""https://github.com/SPIN-UMass/MeanSparse"" target=""_blank"">SPIN-UMass</a>",2025-12-03 22:39:25
DMS: Addressing Information Loss with More Steps for Pragmatic Adversarial Attacks,"Zhiyu Zhu, Jiayu Zhang, Xinyi Wang, Zhibo Jin, Huaming Chen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07580"" target=""_blank"">2406.07580</a>",,2025-12-03 22:39:25
Unveiling the Safety of GPT-4o: An Empirical Study using Jailbreak Attacks,"Zonghao Ying, Aishan Liu, Xianglong Liu, Dacheng Tao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06302"" target=""_blank"">2406.06302</a>","<a href=""https://github.com/NY1024/Jailbreak_GPT4o"" target=""_blank"">NY1024</a>",2025-12-03 22:39:25
Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models,"Xi Li, Yusen Zhang, Renze Lou, Chen Wu, Jiaqi Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05948"" target=""_blank"">2406.05948</a>",,2025-12-03 22:39:25
Compositional Curvature Bounds for Deep Neural Networks,"Taha Entesari, Sina Sharifi, Mahyar Fazlyab",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05119"" target=""_blank"">2406.05119</a>",,2025-12-03 22:39:25
ADBA:Approximation Decision Boundary Approach for Black-Box Adversarial Attacks,"Feiyang Wang, Xingquan Zuo, Hai Huang, Gang Chen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04998"" target=""_blank"">2406.04998</a>","<a href=""https://github.com/BUPTAIOC/ADBA"" target=""_blank"">BUPTAIOC</a>",2025-12-03 22:39:25
A Relevance Model for Threat-Centric Ranking of Cybersecurity Vulnerabilities,"Corren McCoy, Ross Gore, Michael L. Nelson, Michele C. Weigle",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05933"" target=""_blank"">2406.05933</a>",,2025-12-03 22:39:25
Safety Alignment Should Be Made More Than Just a Few Tokens Deep,"Xiangyu Qi, Ashwinee Panda, Kaifeng Lyu, Xiao Ma, Subhrajit Roy, Ahmad Beirami, Prateek Mittal, Peter Henderson",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05946"" target=""_blank"">2406.05946</a>",,2025-12-03 22:39:25
Injecting Undetectable Backdoors in Obfuscated Neural Networks and Language Models,"Alkis Kalavasis, Amin Karbasi, Argyris Oikonomou, Katerina Sotiraki, Grigoris Velegkas, Manolis Zampetakis",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05660"" target=""_blank"">2406.05660</a>",,2025-12-03 22:39:25
SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner,"Xunguang Wang, Daoyuan Wu, Zhenlan Ji, Zongjie Li, Pingchuan Ma, Shuai Wang, Yingjiu Li, Yang Liu, Ning Liu, Juergen Rahmel",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05498"" target=""_blank"">2406.05498</a>",,2025-12-03 22:39:25
One Perturbation is Enough: On Generating Universal Adversarial Perturbations against Vision-Language Pre-training Models,"Hao Fang, Jiawei Kong, Wenbo Yu, Bin Chen, Jiawei Li, Hao Wu, Shutao Xia, Ke Xu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05491"" target=""_blank"">2406.05491</a>",,2025-12-03 22:39:25
Bridging the Gap: Rademacher Complexity in Robust and Standard Generalization,"Jiancong Xiao, Ruoyu Sun, Qi Long, Weijie J. Su",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05372"" target=""_blank"">2406.05372</a>",,2025-12-03 22:39:25
Perturbation Towards Easy Samples Improves Targeted Adversarial Transferability,"Junqi Gao, Biqing Qi, Yao Li, Zhichang Guo, Dong Li, Yuming Xing, Dazhi Zhang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05535"" target=""_blank"">2406.05535</a>","<a href=""https://github.com/gjq100/ESMA"" target=""_blank"">gjq100</a>",2025-12-03 22:39:25
Enhancing Adversarial Transferability via Information Bottleneck Constraints,"Biqing Qi, Junqi Gao, Jianxing Liu, Ligang Wu, Bowen Zhou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05531"" target=""_blank"">2406.05531</a>","<a href=""https://github.com/Biqing-Qi/Enhancing-Adversarial-Transferability-via-Information-Bottleneck-Constraints"" target=""_blank"">Biqing-Qi</a>",2025-12-03 22:39:25
Exploring Adversarial Robustness of Deep State Space Models,"Biqing Qi, Yang Luo, Junqi Gao, Pengfei Li, Kai Tian, Zhiyuan Ma, Bowen Zhou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05532"" target=""_blank"">2406.05532</a>",,2025-12-03 22:39:25
Adversarial flows: A gradient flow characterization of adversarial attacks,"Lukas Weigand, Tim Roith, Martin Burger",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05376"" target=""_blank"">2406.05376</a>",,2025-12-03 22:39:25
On Minimizing Adversarial Counterfactual Error in Adversarial RL,"Roman Belaire, Arunesh Sinha, Pradeep Varakantham",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04724"" target=""_blank"">2406.04724</a>","<a href=""https://github.com/romanbelaire/acoe-robust-rl"" target=""_blank"">romanbelaire</a>",2025-12-03 22:39:25
Corpus Poisoning via Approximate Greedy Gradient Descent,"Jinyan Su, Preslav Nakov, Claire Cardie",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05087"" target=""_blank"">2406.05087</a>",,2025-12-03 22:39:25
A Survey of Backdoor Attacks and Defenses on Large Language Models: Implications for Security Measures,"Shuai Zhao, Meihuizi Jia, Zhongliang Guo, Leilei Gan, Jie Fu, Yichao Feng, Fengjun Pan, Luu Anh Tuan",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06852"" target=""_blank"">2406.06852</a>",,2025-12-03 22:39:25
An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection,"Shenao Yan, Shen Wang, Yue Duan, Hanbin Hong, Kiho Lee, Doowon Kim, Yuan Hong",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06822"" target=""_blank"">2406.06822</a>",,2025-12-03 22:39:25
On Evaluating Adversarial Robustness of Volumetric Medical Segmentation Models,"Hashmat Shadab Malik, Numan Saeed, Asif Hanif, Muzammal Naseer, Mohammad Yaqub, Salman Khan, Fahad Shahbaz Khan",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08486"" target=""_blank"">2406.08486</a>","<a href=""https://github.com/HashmatShadab/Robustness-of-Volumetric-Medical-Segmentation-Models"" target=""_blank"">HashmatShadab</a>",2025-12-03 22:39:25
Raccoon: Prompt Extraction Benchmark of LLM-Integrated Applications,"Junlin Wang, Tianyi Yang, Roy Xie, Bhuwan Dhingra",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06737"" target=""_blank"">2406.06737</a>","<a href=""https://github.com/M0gician/RaccoonBench"" target=""_blank"">M0gician</a>",2025-12-03 22:39:25
Adversarial Patch for 3D Local Feature Extractor,"Yu Wen Pao, Li Chang Lai, Hong-Yi Lin",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08102"" target=""_blank"">2406.08102</a>",,2025-12-03 22:39:25
"Clarifying Myths About the Relationship Between Shape Bias, Accuracy, and Robustness","Zahra Golpayegani, Patrick St-Amant, Nizar Bouguila",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05006"" target=""_blank"">2406.05006</a>",,2025-12-03 22:39:25
Understanding Hallucinations in Diffusion Models through Mode Interpolation,"Sumukh K Aithal, Pratyush Maini, Zachary C. Lipton, J. Zico Kolter",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09358"" target=""_blank"">2406.09358</a>","<a href=""https://github.com/locuslab/diffusion-model-hallucination"" target=""_blank"">locuslab</a>",2025-12-03 22:39:25
"I Don't Know You, But I Can Catch You: Real-Time Defense against Diverse Adversarial Patches for Object Detectors","Zijin Lin, Yue Zhao, Kai Chen, Jinwen He",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10285"" target=""_blank"">2406.10285</a>",,2025-12-03 22:39:25
Transformation-Dependent Adversarial Attacks,"Yaoteng Tan, Zikui Cai, M. Salman Asif",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08443"" target=""_blank"">2406.08443</a>",,2025-12-03 22:39:25
Adversarial Evasion Attack Efficiency against Large Language Models,"João Vitorino, Eva Maia, Isabel Praça",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08050"" target=""_blank"">2406.08050</a>",,2025-12-03 22:39:25
When LLM Meets DRL: Advancing Jailbreaking Efficiency via DRL-guided Search,"Xuan Chen, Yuzhou Nie, Wenbo Guo, Xiangyu Zhang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08705"" target=""_blank"">2406.08705</a>",,2025-12-03 22:39:25
RL-JACK: Reinforcement Learning-powered Black-box Jailbreaking Attack against LLMs,"Xuan Chen, Yuzhou Nie, Lu Yan, Yunshu Mao, Wenbo Guo, Xiangyu Zhang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08725"" target=""_blank"">2406.08725</a>",,2025-12-03 22:39:25
AdaNCA: Neural Cellular Automata As Adaptors For More Robust Vision Transformer,"Yitao Xu, Tong Zhang, Sabine Süsstrunk",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08298"" target=""_blank"">2406.08298</a>",,2025-12-03 22:39:25
On Security Weaknesses and Vulnerabilities in Deep Learning Systems,"Zhongzheng Lai, Huaming Chen, Ruoxi Sun, Yu Zhang, Minhui Xue, Dong Yuan",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08688"" target=""_blank"">2406.08688</a>","<a href=""https://github.com/codelzz/Vulnerabilities4DLSystem"" target=""_blank"">codelzz</a>",2025-12-03 22:39:25
Dataset and Lessons Learned from the 2024 SaTML LLM Capture-the-Flag Competition,"Edoardo Debenedetti, Javier Rando, Daniel Paleka, Silaghi Fineas Florin, Dragos Albastroiu, Niv Cohen, Yuval Lemberg, Reshmi Ghosh, Rui Wen, Ahmed Salem, Giovanni Cherubin, Santiago Zanella-Beguelin, Robin Schmid, Victor Klemm, Takahiro Miki, Chenhao Li, Stefan Kraft, Mario Fritz, Florian Tramèr, Sahar Abdelnabi, Lea Schönherr",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07954"" target=""_blank"">2406.07954</a>",,2025-12-03 22:39:25
Improving Noise Robustness through Abstractions and its Impact on Machine Learning,"Alfredo Personal Health Data Science, Sano - Centre for Computational Personalised Medicine Ibias, Karol Personal Health Data Science, Sano - Centre for Computational Personalised Medicine Capala, Varun Ravi Personal Health Data Science, Sano - Centre for Computational Personalised Medicine Varma, Anna Personal Health Data Science, Sano - Centre for Computational Personalised Medicine Drozdz, Jose Personal Health Data Science, Sano - Centre for Computational Personalised Medicine Sousa",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08428"" target=""_blank"">2406.08428</a>",,2025-12-03 22:39:25
StructuralSleight: Automated Jailbreak Attacks on Large Language Models Utilizing Uncommon Text-Organization Structures,"Bangxin Li, Hengrui Xing, Cong Tian, Chao Huang, Jin Qian, Huangqing Xiao, Linfeng Feng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08754"" target=""_blank"">2406.08754</a>",,2025-12-03 22:39:25
Erasing Radio Frequency Fingerprints via Active Adversarial Perturbation,"Zhaoyi Lu, Wenchao Xu, Ming Tu, Xin Xie, Cunqing Hua, Nan Cheng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07349"" target=""_blank"">2406.07349</a>",,2025-12-03 22:39:25
Reinforced Compressive Neural Architecture Search for Versatile Adversarial Robustness,"Dingrong Wang, Hitesh Sapkota, Zhiqiang Tao, Qi Yu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06792"" target=""_blank"">2406.06792</a>",,2025-12-03 22:39:25
AudioMarkBench: Benchmarking Robustness of Audio Watermarking,"Hongbin Liu, Moyang Guo, Zhengyuan Jiang, Lun Wang, Neil Zhenqiang Gong",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06979"" target=""_blank"">2406.06979</a>","<a href=""https://github.com/moyangkuo/AudioMarkBench"" target=""_blank"">moyangkuo</a>",2025-12-03 22:39:25
"On the H\""{o}lder Stability of Multiset and Graph Neural Networks","Yair Davidson, Nadav Dym",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06984"" target=""_blank"">2406.06984</a>",,2025-12-03 22:39:25
A Study of Backdoors in Instruction Fine-tuned Language Models,"Jayaram Raghuram, George Kesidis, David J. Miller",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07778"" target=""_blank"">2406.07778</a>",,2025-12-03 22:39:25
Merging Improves Self-Critique Against Jailbreak Attacks,Victor Gallego,arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07188"" target=""_blank"">2406.07188</a>","<a href=""https://github.com/vicgalle/merging-self-critique-jailbreaks"" target=""_blank"">vicgalle</a>",2025-12-03 22:39:25
Benchmarking Trustworthiness of Multimodal Large Language Models: A Comprehensive Study,"Yichi Zhang, Yao Huang, Yitong Sun, Chang Liu, Zhe Zhao, Zhengwei Fang, Yifan Wang, Huanran Chen, Xiao Yang, Xingxing Wei, Hang Su, Yinpeng Dong, Jun Zhu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07057"" target=""_blank"">2406.07057</a>","<a href=""https://multi-trust.github.io/"" target=""_blank"">multi-trust.github.io</a>",2025-12-03 22:39:25
Dual Thinking and Perceptual Analysis of Deep Learning Models using Human Adversarial Examples,"Kailas Dayanandan, Anand Sinha, Brejesh Lall",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06967"" target=""_blank"">2406.06967</a>",,2025-12-03 22:39:25
MoreauPruner: Robust Pruning of Large Language Models against Weight Perturbations,"Zixiao Wang, Jingwei Zhang, Wenqian Zhao, Farzan Farnia, Bei Yu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07017"" target=""_blank"">2406.07017</a>","<a href=""https://github.com/ShiningSord/MoreauPruner"" target=""_blank"">ShiningSord</a>",2025-12-03 22:39:25
Rethinking the impact of noisy labels in graph classification: A utility and privacy perspective,"De Li, Xianxian Li, Zeming Gan, Qiyu Li, Bin Qu, Jinyan Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07314"" target=""_blank"">2406.07314</a>",,2025-12-03 22:39:25
Agnostic Sharpness-Aware Minimization,"Van-Anh Nguyen, Quyen Tran, Tuan Truong, Thanh-Toan Do, Dinh Phung, Trung Le",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07107"" target=""_blank"">2406.07107</a>",,2025-12-03 22:39:25
Texture Re-scalable Universal Adversarial Perturbation,"Yihao Huang, Qing Guo, Felix Juefei-Xu, Ming Hu, Xiaojun Jia, Xiaochun Cao, Geguang Pu, Yang Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06089"" target=""_blank"">2406.06089</a>",,2025-12-03 22:39:25
Explainable Graph Neural Networks Under Fire,"Zhong Li, Simon Geisler, Yuhang Wang, Stephan Günnemann, Leeuwen Matthijs van",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06417"" target=""_blank"">2406.06417</a>",,2025-12-03 22:39:25
Lurking in the shadows: Unveiling Stealthy Backdoor Attacks against Personalized Federated Learning,"Xiaoting Lyu, Yufei Han, Wei Wang, Jingkai Liu, Yongsheng Zhu, Guangquan Xu, Jiqiang Liu, Xiangliang Zhang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06207"" target=""_blank"">2406.06207</a>",,2025-12-03 22:39:25
Adversarial Tuning: Defending Against Jailbreak Attacks for LLMs,"Fan Liu, Zhao Xu, Hao Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06622"" target=""_blank"">2406.06622</a>",,2025-12-03 22:39:25
Towards General Robustness Verification of MaxPool-based Convolutional Neural Networks via Tightening Linear Approximation,"Yuan Xiao, Shiqing Ma, Juan Zhai, Chunrong Fang, Jinyuan Jia, Zhenyu Chen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.00699"" target=""_blank"">2406.00699</a>","<a href=""https://github.com/xiaoyuanpigo/maxlin"" target=""_blank"">xiaoyuanpigo</a>",2025-12-03 22:39:25
GENIE: Watermarking Graph Neural Networks for Link Prediction,"Venkata Sai Pranav Bachina, Ankit Gangwal, Aaryan Ajay Sharma, Charu Sharma",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04805"" target=""_blank"">2406.04805</a>",,2025-12-03 22:39:25
The Price of Implicit Bias in Adversarially Robust Generalization,"Nikolaos Tsilivis, Natalie Frank, Nathan Srebro, Julia Kempe",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04981"" target=""_blank"">2406.04981</a>",,2025-12-03 22:39:25
Nonlinear Transformations Against Unlearnable Datasets,"Thushari Hapuarachchi, Jing Lin, Kaiqi Xiong, Mohamed Rahouti, Gitte Ost",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02883"" target=""_blank"">2406.02883</a>",,2025-12-03 22:39:25
"Inference Attacks: A Taxonomy, Survey, and Promising Directions","Feng Wu, Lei Cui, Shaowen Yao, Shui Yu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02027"" target=""_blank"">2406.02027</a>",,2025-12-03 22:39:25
The Crystal Ball Hypothesis in diffusion models: Anticipating object positions from initial noise,"Yuanhao Ban, Ruochen Wang, Tianyi Zhou, Boqing Gong, Cho-Jui Hsieh, Minhao Cheng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01970"" target=""_blank"">2406.01970</a>",,2025-12-03 22:39:25
Can Dense Connectivity Benefit Outlier Detection? An Odyssey with NAS,"Hao Fu, Tunhou Zhang, Hai Li, Yiran Chen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01975"" target=""_blank"">2406.01975</a>",,2025-12-03 22:39:25
Constraint-based Adversarial Example Synthesis,"Fang Yu, Ya-Yu Chi, Yu-Fang Chen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01219"" target=""_blank"">2406.01219</a>",,2025-12-03 22:39:25
SVASTIN: Sparse Video Adversarial Attack via Spatio-Temporal Invertible Neural Networks,"Yi Pan, Jun-Jie Huang, Zihan Chen, Wentao Zhao, Ziyue Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01894"" target=""_blank"">2406.01894</a>","<a href=""https://github.com/Brittany-Chen/SVASTIN"" target=""_blank"">Brittany-Chen</a>",2025-12-03 22:39:25
Reproducibility Study on Adversarial Attacks Against Robust Transformer Trackers,"Fatemeh Nourilenjan Nokabadi, Jean-François Lalonde, Christian Gagné",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01765"" target=""_blank"">2406.01765</a>","<a href=""https://github.com/fatemehN/ReproducibilityStudy"" target=""_blank"">fatemehN</a>",2025-12-03 22:39:25
CR-UTP: Certified Robustness against Universal Text Perturbations on Large Language Models,"Qian Lou, Xin Liang, Jiaqi Xue, Yancheng Zhang, Rui Xie, Mengxin Zheng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01873"" target=""_blank"">2406.01873</a>","<a href=""https://github.com/UCFML-Research/CR-UTP"" target=""_blank"">UCFML-Research</a>",2025-12-03 22:39:25
Are AI-Generated Text Detectors Robust to Adversarial Perturbations? (80%),"Guanhua Huang, Yuchen Zhang, Zhe Li, Yongjian You, Mingze Wang, Zhouwang Yang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01179"" target=""_blank"">2406.01179</a>","<a href=""https://github.com/CarlanLark/Robust-AIGC-Detector"" target=""_blank"">CarlanLark</a>",2025-12-03 22:39:25
Model for Peanuts: Hijacking ML Models without Training Access is Possible,"Mahmoud Ghorbel, Halima Bouzidi, Ioan Marius Bilasco, Ihsen Alouani",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01708"" target=""_blank"">2406.01708</a>",,2025-12-03 22:39:25
SLANT: Spurious Logo ANalysis Toolkit,"Maan Qraitem, Piotr Teterwak, Kate Saenko, Bryan A. Plummer",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01449"" target=""_blank"">2406.01449</a>",,2025-12-03 22:39:25
MedFuzz: Exploring the Robustness of Large Language Models in Medical Question Answering,"Robert Osazuwa Ness, Katie Matton, Hayden Helm, Sheng Zhang, Junaid Bajwa, Carey E. Priebe, Eric Horvitz",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.06573"" target=""_blank"">2406.06573</a>",,2025-12-03 22:39:25
From Feature Visualization to Visual Circuits: Effect of Adversarial Model Manipulation,"Geraldin Nanfack, Michael Eickenberg, Eugene Belilovsky",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01365"" target=""_blank"">2406.01365</a>",,2025-12-03 22:39:25
A Game-Theoretic Approach to Privacy-Utility Tradeoff in Sharing Genomic Summary Statistics,"Tao Zhang, Rajagopal Venkatesaramani, Rajat K. De, Bradley A. Malin, Yevgeniy Vorobeychik",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01811"" target=""_blank"">2406.01811</a>",,2025-12-03 22:39:25
Poisoning Attacks and Defenses in Recommender Systems: A Survey,"Zongwei Wang, Junliang Yu, Min Gao, Wei Yuan, Guanhua Ye, Shazia Sadiq, Hongzhi Yin",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01022"" target=""_blank"">2406.01022</a>",,2025-12-03 22:39:25
Unelicitable Backdoors in Language Models via Cryptographic Transformer Circuits,"Andis Draguns, Andrew Gritsevskiy, Sumeet Ramesh Motwani, Charlie Rogers-Smith, Jeffrey Ladish, Witt Christian Schroeder de",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02619"" target=""_blank"">2406.02619</a>",,2025-12-03 22:39:25
PRICE: A Pretrained Model for Cross-Database Cardinality Estimation,"Tianjing Zeng, Junwei Lan, Jiahong Ma, Wenqing Wei, Rong Zhu, Pengfei Li, Bolin Ding, Defu Lian, Zhewei Wei, Jingren Zhou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.01027"" target=""_blank"">2406.01027</a>","<a href=""https://github.com/StCarmen/PRICE"" target=""_blank"">StCarmen</a>",2025-12-03 22:39:25
Improving Accuracy-robustness Trade-off via Pixel Reweighted Adversarial Training,"Jiacheng Zhang, Feng Liu, Dawei Zhou, Jingfeng Zhang, Tongliang Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.00685"" target=""_blank"">2406.00685</a>",,2025-12-03 22:39:25
Assessing the Adversarial Security of Perceptual Hashing Algorithms,"Jordan Madden, Moxanki Bhavsar, Lhamo Dorje, Xiaohua Li",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.00918"" target=""_blank"">2406.00918</a>",,2025-12-03 22:39:25
A Novel Defense Against Poisoning Attacks on Federated Learning: LayerCAM Augmented with Autoencoder,"Jingjing Zheng, Xin Yuan, Kai Li, Wei Ni, Eduardo Tovar, Jon Crowcroft",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02605"" target=""_blank"">2406.02605</a>","<a href=""https://github.com/jjzgeeks/LayerCAM-AE"" target=""_blank"">jjzgeeks</a>",2025-12-03 22:39:25
An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records,"Joakim Edin, Maria Maistro, Lars Maaløe, Lasse Borgholt, Jakob D. Havtorn, Tuukka Ruotsalo",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08958"" target=""_blank"">2406.08958</a>",,2025-12-03 22:39:25
Invisible Backdoor Attacks on Diffusion Models,"Sen Li, Junchi Ma, Minhao Cheng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.00816"" target=""_blank"">2406.00816</a>","<a href=""https://github.com/invisibleTriggerDiffusion/invisible_triggers_for_diffusion"" target=""_blank"">invisibleTriggerDiffusion</a>",2025-12-03 22:39:25
Robust Knowledge Distillation Based on Feature Variance Against Backdoored Teacher Model,"Jinyin Chen, Xiaoming Zhao, Haibin Zheng, Xiao Li, Sheng Xiang, Haifeng Guo",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03409"" target=""_blank"">2406.03409</a>",,2025-12-03 22:39:25
Exploring Vulnerabilities and Protections in Large Language Models: A Survey,"Frank Weizhen Liu, Chenhui Hu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.00240"" target=""_blank"">2406.00240</a>",,2025-12-03 22:39:25
StyDeSty: Min-Max Stylization and Destylization for Single Domain Generalization,"Songhua Liu, Xin Jin, Xingyi Yang, Jingwen Ye, Xinchao Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.00275"" target=""_blank"">2406.00275</a>","<a href=""https://github.com/Huage001/StyDeSty"" target=""_blank"">Huage001</a>",2025-12-03 22:39:25
Deep Learning Approaches for Detecting Adversarial Cyberbullying and Hate Speech in Social Networks,"Sylvia Worlali Azumah, Nelly Elsayed, Zag ElSayed, Murat Ozer, Guardia Amanda La",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17793"" target=""_blank"">2406.17793</a>",,2025-12-03 22:39:25
Fully Exploiting Every Real Sample: SuperPixel Sample Gradient Model Stealing,"Yunlong Zhao, Xiaoheng Deng, Yijing Liu, Xinjun Pei, Jiazhi Xia, Wei Chen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18540"" target=""_blank"">2406.18540</a>","<a href=""https://github.com/zyl123456aB/SPSG_attack"" target=""_blank"">zyl123456aB</a>",2025-12-03 22:39:25
Large Language Models as Carriers of Hidden Messages,"Jakub Hoscilowicz, Pawel Popiolek, Jan Rudkowski, Jedrzej Bieniasz, Artur Janicki",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02481"" target=""_blank"">2406.02481</a>",,2025-12-03 22:39:25
Verifying the Generalization of Deep Learning to Out-of-Distribution Domains,"Guy Amir, Osher Maayan, Tom Zelazny, Guy Katz, Michael Schapira",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02024"" target=""_blank"">2406.02024</a>",,2025-12-03 22:39:25
A Risk Estimation Study of Native Code Vulnerabilities in Android Applications,"Silvia Lucia Sanna, Diego Soi, Davide Maiorca, Giorgio Fumera, Giorgio Giacinto",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02011"" target=""_blank"">2406.02011</a>",,2025-12-03 22:39:25
DifAttack++: Query-Efficient Black-Box Adversarial Attack via Hierarchical Disentangled Feature Space in Cross-Domain,"Jun Liu, Jiantao Zhou, Jiandian Zeng, Jinyu Tian, Zheng Li",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03017"" target=""_blank"">2406.03017</a>","<a href=""https://github.com/csjunjun/DifAttack"" target=""_blank"">csjunjun</a>",2025-12-03 22:39:25
Contextual fusion enhances robustness to image blurring,"Shruti Joshi, Aiswarya Akumalla, Seth Haney, Maxim Bazhenov",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.05120"" target=""_blank"">2406.05120</a>",,2025-12-03 22:39:25
LLM Whisperer: An Inconspicuous Attack to Bias LLM Responses,"Weiran Lin, Anna Gerchanovsky, Omer Akgul, Lujo Bauer, Matt Fredrikson, Zifan Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04755"" target=""_blank"">2406.04755</a>",,2025-12-03 22:39:25
Batch-in-Batch: a new adversarial training framework for initial perturbation and sample selection,"Yinting School of Mathematics and Statistics, and Key Lab NAA--MOE, Central China Normal University Wu, Pai School of Mathematics and Computer Science, Jianghan University Peng, Bo Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, and School of Cyber Science and Engineering, Wuhan University Cai, Le School of Mathematics and Statistics, and Key Lab NAA--MOE, Central China Normal University Li, .",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04070"" target=""_blank"">2406.04070</a>",,2025-12-03 22:39:25
Talos: A More Effective and Efficient Adversarial Defense for GNN Models Based on the Global Homophily of Graphs,"Duanyu Li, Huijun Wu, Min Xie, Xugang Wu, Zhenwei Wu, Wenzhe Zhang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03833"" target=""_blank"">2406.03833</a>",,2025-12-03 22:39:25
Robust Deep Reinforcement Learning against Adversarial Behavior Manipulation,"Shojiro Yamabe, Kazuto Fukuchi, Jun Sakuma",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03862"" target=""_blank"">2406.03862</a>",,2025-12-03 22:39:25
AutoJailbreak: Exploring Jailbreak Attacks and Defenses through a Dependency Lens,"Lin Lu, Hai Yan, Zenghui Yuan, Jiawen Shi, Wenqi Wei, Pin-Yu Chen, Pan Zhou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03805"" target=""_blank"">2406.03805</a>",,2025-12-03 22:39:25
Neural Codec-based Adversarial Sample Detection for Speaker Verification,"Xuanjun Chen, Jiawei Du, Haibin Wu, Jyh-Shing Roger Jang, Hung-yi Lee",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04582"" target=""_blank"">2406.04582</a>",,2025-12-03 22:39:25
Interpreting the Second-Order Effects of Neurons in CLIP,"Yossi Gandelsman, Alexei A. Efros, Jacob Steinhardt",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04341"" target=""_blank"">2406.04341</a>",,2025-12-03 22:39:25
Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt,"Zonghao Ying, Aishan Liu, Tianyuan Zhang, Zhengmin Yu, Siyuan Liang, Xianglong Liu, Dacheng Tao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.04031"" target=""_blank"">2406.04031</a>",,2025-12-03 22:39:25
Memorization in deep learning: A survey,"Jiaheng Wei, Yanjun Zhang, Leo Yu Zhang, Ming Ding, Chao Chen, Kok-Leong Ong, Jun Zhang, Yang Xiang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03880"" target=""_blank"">2406.03880</a>",,2025-12-03 22:39:25
VQUNet: Vector Quantization U-Net for Defending Adversarial Atacks by Regularizing Unwanted Noise,"Zhixun He, Mukesh Singhal",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03117"" target=""_blank"">2406.03117</a>",,2025-12-03 22:39:25
ZeroPur: Succinct Training-Free Adversarial Purification,"Erhu Liu, Zonglin Yang, Bo Liu, Bin Xiao, Xiuli Bi",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03143"" target=""_blank"">2406.03143</a>",,2025-12-03 22:39:25
Defending Large Language Models Against Attacks With Residual Stream Activation Analysis,"Amelia Kawasaki, Andrew Davis, Houssam Abbas",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03230"" target=""_blank"">2406.03230</a>",,2025-12-03 22:39:25
PuFace: Defending against Facial Cloaking Attacks for Facial Recognition Models,Jing Wen,arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02253"" target=""_blank"">2406.02253</a>",,2025-12-03 22:39:25
Graph Neural Network Explanations are Fragile,"Jiate Li, Meng Pang, Yun Dong, Jinyuan Jia, Binghui Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03193"" target=""_blank"">2406.03193</a>",,2025-12-03 22:39:25
A Geometric View of Data Complexity: Efficient Local Intrinsic Dimension Estimation with Diffusion Models,"Hamidreza Kamkari, Brendan Leigh Ross, Rasa Hosseinzadeh, Jesse C. Cresswell, Gabriel Loaiza-Ganem",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03537"" target=""_blank"">2406.03537</a>",,2025-12-03 22:39:25
Principles of Designing Robust Remote Face Anti-Spoofing Systems,"Xiang Xu, Tianchen Zhao, Zheng Zhang, Zhihua Li, Jon Wu, Alessandro Achille, Mani Srivastava",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03684"" target=""_blank"">2406.03684</a>",,2025-12-03 22:39:25
Mutual Information Guided Backdoor Mitigation for Pre-trained Encoders,"Tingxu Han, Weisong Sun, Ziqi Ding, Chunrong Fang, Hanwei Qian, Jiaxun Li, Zhenyu Chen, Xiangyu Zhang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03508"" target=""_blank"">2406.03508</a>",,2025-12-03 22:39:25
JIGMARK: A Black-Box Approach for Enhancing Image Watermarks against Diffusion Model Edits,"Minzhou Pan, Yi Zeng, Xue Lin, Ning Yu, Cho-Jui Hsieh, Peter Henderson, Ruoxi Jia",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03720"" target=""_blank"">2406.03720</a>",,2025-12-03 22:39:25
Are Your Models Still Fair? Fairness Attacks on Graph Neural Networks via Node Injections,"Zihan Luo, Hong Huang, Yongkang Zhou, Jiping Zhang, Nuo Chen, Hai Jin",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03052"" target=""_blank"">2406.03052</a>","<a href=""https://github.com/CGCL-codes/NIFA"" target=""_blank"">CGCL-codes</a>",2025-12-03 22:39:25
Enhancing the Resilience of Graph Neural Networks to Topological Perturbations in Sparse Graphs,"Shuqi He, Jun Zhuang, Ding Wang, Luyao Peng, Jun Song",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03097"" target=""_blank"">2406.03097</a>",,2025-12-03 22:39:25
Reconstructing training data from document understanding models,"Jérémie Dentan, Arnaud Paran, Aymen Shabou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.03182"" target=""_blank"">2406.03182</a>",,2025-12-03 22:39:25
FREA: Feasibility-Guided Generation of Safety-Critical Scenarios with Reasonable Adversariality,"Keyu Chen, Yuheng Lei, Hao Cheng, Haoran Wu, Wenchao Sun, Sifa Zheng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02983"" target=""_blank"">2406.02983</a>",,2025-12-03 22:39:25
Advancing Generalized Transfer Attack with Initialization Derived Bilevel Optimization and Dynamic Sequence Truncation,"Yaohua Liu, Jiaxin Gao, Xuan Liu, Xianghao Jiao, Xin Fan, Risheng Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02064"" target=""_blank"">2406.02064</a>","<a href=""https://github.com/callous-youth/BETAK"" target=""_blank"">callous-youth</a>",2025-12-03 22:39:25
Effects of Exponential Gaussian Distribution on (Double Sampling) Randomized Smoothing,"Youwei Shu, Xi Xiao, Derui Wang, Yuxin Cao, Siji Chen, Jason Xue, Linyi Li, Bo Li",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02309"" target=""_blank"">2406.02309</a>",,2025-12-03 22:39:25
QROA: A Black-Box Query-Response Optimization Attack on LLMs,"Hussein LaMME Jawad, Nicolas J. -B. LaMME BRUNEL",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.02044"" target=""_blank"">2406.02044</a>",,2025-12-03 22:39:25
Large-Scale Evaluation of Open-Set Image Classification Techniques,"Halil Bisgin, Andres Palechor, Mike Suter, Manuel Günther",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09112"" target=""_blank"">2406.09112</a>",,2025-12-03 22:39:25
Graph Transductive Defense: a Two-Stage Defense for Graph Membership Inference Attacks,"Peizhi Niu, Chao Pan, Siheng Chen, Olgica Milenkovic",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.07917"" target=""_blank"">2406.07917</a>",,2025-12-03 22:39:25
Validation of human benchmark models for Automated Driving System approval: How competent and careful are they really? (1%),"Pierluigi Olleja, Gustav Markkula, Jonas Bärgman",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09493"" target=""_blank"">2406.09493</a>",,2025-12-03 22:39:25
AGSOA:Graph Neural Network Targeted Attack Based on Average Gradient and Structure Optimization,"Yang Chen, Bin Zhou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13228"" target=""_blank"">2406.13228</a>",,2025-12-03 22:39:25
Machine Unlearning Fails to Remove Data Poisoning Attacks,"Martin Pawelczyk, Jimmy Z. Di, Yiwei Lu, Gautam Kamath, Ayush Sekhari, Seth Neel",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17216"" target=""_blank"">2406.17216</a>",,2025-12-03 22:39:25
Towards unlocking the mystery of adversarial fragility of neural networks,"Jingchao Gao, Raghu Mudumbai, Xiaodong Wu, Jirong Yi, Catherine Xu, Hui Xie, Weiyu Xu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16200"" target=""_blank"">2406.16200</a>",,2025-12-03 22:39:25
CBPF: Filtering Poisoned Data Based on Composite Backdoor Attack,"Hanfeng Xia, Haibo Hong, Ruili Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16125"" target=""_blank"">2406.16125</a>",,2025-12-03 22:39:25
Investigating the Influence of Prompt-Specific Shortcuts in AI Generated Text Detection,"Choonghyun Park, Hyuhng Joon Kim, Junyeob Kim, Youna Kim, Taeuk Kim, Hyunsoo Cho, Hwiyeol Jo, Sang-goo Lee, Kang Min Yoo",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16275"" target=""_blank"">2406.16275</a>","<a href=""https://github.com/zxcvvxcz/FAILOpt"" target=""_blank"">zxcvvxcz</a>",2025-12-03 22:39:25
On Instabilities of Unsupervised Denoising Diffusion Models in Magnetic Resonance Imaging Reconstruction,"Tianyu Han, Sven Nebelung, Firas Khader, Jakob Nikolas Kather, Daniel Truhn",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16983"" target=""_blank"">2406.16983</a>",,2025-12-03 22:39:25
Understanding and Diagnosing Deep Reinforcement Learning,Ezgi Korkmaz,arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16979"" target=""_blank"">2406.16979</a>",,2025-12-03 22:39:25
The Effect of Similarity Measures on Accurate Stability Estimates for Local Surrogate Models in Text-based Explainable AI,"Christopher Burger, Charles Walter, Thai Le",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15839"" target=""_blank"">2406.15839</a>",,2025-12-03 22:39:25
Federated Adversarial Learning for Robust Autonomous Landing Runway Detection,"Yi Li, Plamen Angelov, Zhengxin Yu, Alvaro Lopez Pellicer, Neeraj Suri",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15925"" target=""_blank"">2406.15925</a>",,2025-12-03 22:39:25
Privacy Implications of Explainable AI in Data-Driven Systems,Fatima Ezzeddine,arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15789"" target=""_blank"">2406.15789</a>",,2025-12-03 22:39:25
ECLIPSE: Expunging Clean-label Indiscriminate Poisons via Sparse Diffusion Purification,"Xianlong Wang, Shengshan Hu, Yechao Zhang, Ziqi Zhou, Leo Yu Zhang, Peng Xu, Wei Wan, Hai Jin",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15093"" target=""_blank"">2406.15093</a>","<a href=""https://github.com/CGCL-codes/ECLIPSE"" target=""_blank"">CGCL-codes</a>",2025-12-03 22:39:25
Deciphering the Definition of Adversarial Robustness for post-hoc OOD Detectors,"Peter Lorenz, Mario Fernandez, Jens Müller, Ullrich Köthe",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15104"" target=""_blank"">2406.15104</a>",,2025-12-03 22:39:25
DataFreeShield: Defending Adversarial Attacks without Training Data,"Hyeyoon Lee, Kanghyun Choi, Dain Kwon, Sunjong Park, Mayoore Selvarasa Jaiswal, Noseong Park, Jonghyun Choi, Jinho Lee",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15635"" target=""_blank"">2406.15635</a>",,2025-12-03 22:39:25
Large Language Models for Link Stealing Attacks Against Graph Neural Networks,"Faqian Guan, Tianqing Zhu, Hui Sun, Wanlei Zhou, Philip S. Yu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16963"" target=""_blank"">2406.16963</a>",,2025-12-03 22:39:25
MOUNTAINEER: Topology-Driven Visual Analytics for Comparing Local Explanations,"Parikshit Solunke, Vitoria Guardieiro, Joao Rulff, Peter Xenopoulos, Gromit Yeuk-Yin Chan, Brian Barr, Luis Gustavo Nonato, Claudio Silva",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15613"" target=""_blank"">2406.15613</a>",,2025-12-03 22:39:25
Enhancing robustness of data-driven SHM models: adversarial training with circle loss,"Xiangli Yang, Xijie Deng, Hanwei Zhang, Yang Zou, Jianxi Yang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14232"" target=""_blank"">2406.14232</a>",,2025-12-03 22:39:25
Exploring Layerwise Adversarial Robustness Through the Lens of t-SNE,"Inês Valentim, Nuno Antunes, Nuno Lourenço",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14073"" target=""_blank"">2406.14073</a>",,2025-12-03 22:39:25
Defending Against Sophisticated Poisoning Attacks with RL-based Aggregation in Federated Learning,"Yujing Wang, Hainan Zhang, Sijia Wen, Wangjie Qiu, Binghui Guo",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14217"" target=""_blank"">2406.14217</a>",,2025-12-03 22:39:25
Jailbreaking as a Reward Misspecification Problem,"Zhihui Xie, Jiahui Gao, Lei Li, Zhenguo Li, Qi Liu, Lingpeng Kong",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14393"" target=""_blank"">2406.14393</a>",,2025-12-03 22:39:25
Uniform Convergence of Adversarially Robust Classifiers,"Rachel Morris, Ryan Murray",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14682"" target=""_blank"">2406.14682</a>",,2025-12-03 22:39:25
Prompt Injection Attacks in Defended Systems,"Daniil Khomsky, Narek Maloyan, Bulat Nutfullin",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14048"" target=""_blank"">2406.14048</a>",,2025-12-03 22:39:25
MEAT: Median-Ensemble Adversarial Training for Improving Robustness and Generalization,"Zhaozhe Hu, Jia-Li Yin, Bin Chen, Luojun Lin, Bo-Hao Chen, Ximeng Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14259"" target=""_blank"">2406.14259</a>",,2025-12-03 22:39:25
Countering adversarial perturbations in graphs using error correcting codes,Saif Eddin Jabari,arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14245"" target=""_blank"">2406.14245</a>",,2025-12-03 22:39:25
Steering Without Side Effects: Improving Post-Deployment Control of Language Models,"Asa Cooper Stickland, Alexander Lyzhov, Jacob Pfau, Salsabila Mahdi, Samuel R. Bowman",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.15518"" target=""_blank"">2406.15518</a>","<a href=""https://github.com/AsaCooperStickland/kl-then-steer"" target=""_blank"">AsaCooperStickland</a>",2025-12-03 22:39:25
Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective,"Yuchen Wen, Keping Bi, Wei Chen, Jiafeng Guo, Xueqi Cheng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14023"" target=""_blank"">2406.14023</a>",,2025-12-03 22:39:25
PoseBench: Benchmarking the Robustness of Pose Estimation Models under Corruptions,"Sihan Ma, Jing Zhang, Qiong Cao, Dacheng Tao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14367"" target=""_blank"">2406.14367</a>","<a href=""https://xymsh.github.io/PoseBench"" target=""_blank"">xymsh.github.io</a>",2025-12-03 22:39:25
Can you trust your explanations? A robustness test for feature attribution methods,"Ilaria Vascotto, Alex Rodriguez, Alessandro Bonaita, Luca Bortolussi",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14349"" target=""_blank"">2406.14349</a>",,2025-12-03 22:39:25
SeCTIS: A Framework to Secure CTI Sharing,"Dincy R. Arikkat, Mert Cihangiroglu, Mauro Conti, Rafidha Rehiman K. A., Serena Nicolazzo, Antonino Nocera, Vinod P",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.14102"" target=""_blank"">2406.14102</a>",,2025-12-03 22:39:25
From Perfect to Noisy World Simulation: Customizable Embodied Multi-modal Perturbations for SLAM Robustness Benchmarking,"Xiaohao Xu, Tianyi Zhang, Sibo Wang, Xiang Li, Yongqi Chen, Ye Li, Bhiksha Raj, Matthew Johnson-Roberson, Xiaonan Huang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16850"" target=""_blank"">2406.16850</a>","<a href=""https://github.com/Xiaohao-Xu/SLAM-under-Perturbation"" target=""_blank"">Xiaohao-Xu</a>",2025-12-03 22:39:25
BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models,"Yi Zeng, Weiyu Sun, Tran Ngoc Huynh, Dawn Song, Bo Li, Ruoxi Jia",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17092"" target=""_blank"">2406.17092</a>",,2025-12-03 22:39:25
Improving robustness to corruptions with multiplicative weight perturbations,"Trung Trinh, Markus Heinonen, Luigi Acerbi, Samuel Kaski",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16540"" target=""_blank"">2406.16540</a>",,2025-12-03 22:39:25
Detecting Brittle Decisions for Free: Leveraging Margin Consistency in Deep Robust Classifiers,"Jonas Ngnawé, Sabyasachi Sahoo, Yann Pequignot, Frédéric Precioso, Christian Gagné",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18451"" target=""_blank"">2406.18451</a>",,2025-12-03 22:39:25
Deceptive Diffusion: Generating Synthetic Adversarial Examples,"Lucas Beerens, Catherine F. Higham, Desmond J. Higham",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19807"" target=""_blank"">2406.19807</a>",,2025-12-03 22:39:25
Emotion Loss Attacking: Adversarial Attack Perception for Skeleton based on Multi-dimensional Features,"Feng Liu, Qing Xu, Qijian Zheng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19815"" target=""_blank"">2406.19815</a>",,2025-12-03 22:39:25
Steering cooperation: Adversarial attacks on prisoner's dilemma in complex networks,Kazuhiro Takemoto,arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19692"" target=""_blank"">2406.19692</a>",,2025-12-03 22:39:25
Opening the Black Box: predicting the trainability of deep neural networks with reconstruction entropy,"Yanick Thurn, Ro Jefferson, Johanna Erdmenger",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12916"" target=""_blank"">2406.12916</a>",,2025-12-03 22:39:25
Backdoor Attack in Prompt-Based Continual Learning,"Trang Nguyen, Anh Tran, Nhat Ho",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19753"" target=""_blank"">2406.19753</a>",,2025-12-03 22:39:25
Virtual Context: Enhancing Jailbreak Attacks with Special Token Injection,"Yuqi Zhou, Lin Lu, Hanchi Sun, Pan Zhou, Lichao Sun",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19845"" target=""_blank"">2406.19845</a>",,2025-12-03 22:39:25
GRACE: Graph-Regularized Attentive Convolutional Entanglement with Laplacian Smoothing for Robust DeepFake Video Detection,"Chih-Chung Hsu, Shao-Ning Chen, Mei-Hsuan Wu, Yi-Fang Wang, Chia-Ming Lee, Yi-Shiuan Chou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19941"" target=""_blank"">2406.19941</a>","<a href=""https://github.com/ming053l/GRACE"" target=""_blank"">ming053l</a>",2025-12-03 22:39:25
Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems,"Zheng Fang, Tao Wang, Lingchen Zhao, Shenyi Zhang, Bowen Li, Yunjie Ge, Qi Li, Chao Shen, Qian Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19311"" target=""_blank"">2406.19311</a>",,2025-12-03 22:39:25
Data-Driven Lipschitz Continuity: A Cost-Effective Approach to Improve Adversarial Robustness,"Erh-Chung Chen, Pin-Yu Chen, I-Hsin Chung, Che-Rung Lee",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19622"" target=""_blank"">2406.19622</a>",,2025-12-03 22:39:25
Investigating and Defending Shortcut Learning in Personalized Diffusion Models,"Yixin Liu, Ruoxi Chen, Lichao Sun",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18944"" target=""_blank"">2406.18944</a>","<a href=""https://github.com/liuyixin-louis/DiffShortcut"" target=""_blank"">liuyixin-louis</a>",2025-12-03 22:39:25
Data Poisoning Attacks to Locally Differentially Private Frequent Itemset Mining Protocols,"Wei Tong, Haoyu Chen, Jiacheng Niu, Sheng Zhong",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19466"" target=""_blank"">2406.19466</a>",,2025-12-03 22:39:25
Context Matters: An Empirical Study of the Impact of Contextual Information in Temporal Question Answering Systems,"Dan Schumacher, Fatemeh Haji, Tara Grey, Niharika Bandlamudi, Nupoor Karnik, Gagana Uday Kumar, Jason Cho-Yu Chiang, Paul Rad, Nishant Vishwamitra, Anthony Rios",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19538"" target=""_blank"">2406.19538</a>",,2025-12-03 22:39:25
Revisiting Backdoor Attacks against Large Vision-Language Models,"Siyuan Liang, Jiawei Liang, Tianyu Pang, Chao Du, Aishan Liu, Ee-Chien Chang, Xiaochun Cao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18844"" target=""_blank"">2406.18844</a>",,2025-12-03 22:39:25
Automated Adversarial Discovery for Safety Classifiers,"Yash Kumar Lal, Preethi Lahoti, Aradhana Sinha, Yao Qin, Ananth Balashankar",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17104"" target=""_blank"">2406.17104</a>",,2025-12-03 22:39:25
Breaking the Barrier: Enhanced Utility and Robustness in Smoothed DRL Agents,"Chung-En Sun, Sicun Gao, Tsui-Wei Weng",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18062"" target=""_blank"">2406.18062</a>",,2025-12-03 22:39:25
Poisoned LangChain: Jailbreak LLMs by LangChain,"Ziqiu Wang, Jun Liu, Shengkai Zhang, Yang Yang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18122"" target=""_blank"">2406.18122</a>",,2025-12-03 22:39:25
WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models,"Liwei Jiang, Kavel Rao, Seungju Han, Allyson Ettinger, Faeze Brahman, Sachin Kumar, Niloofar Mireshghallah, Ximing Lu, Maarten Sap, Yejin Choi, Nouha Dziri",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18510"" target=""_blank"">2406.18510</a>",,2025-12-03 22:39:25
Adversarial Search Engine Optimization for Large Language Models,"Fredrik Nestaas, Edoardo Debenedetti, Florian Tramèr",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.18382"" target=""_blank"">2406.18382</a>",,2025-12-03 22:39:25
CuDA2: An approach for Incorporating Traitor Agents into Cooperative Multi-Agent Systems,"Zhen Chen, Yong Liao, Youpeng Zhao, Zipeng Dai, Jian Zhao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17425"" target=""_blank"">2406.17425</a>",,2025-12-03 22:39:25
Diffusion-based Adversarial Purification for Intrusion Detection,"Mohamed Amine Merzouk, Erwan Beurier, Reda Yaich, Nora Boulahia-Cuppens, Frédéric Cuppens",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17606"" target=""_blank"">2406.17606</a>",,2025-12-03 22:39:25
Semantic Deep Hiding for Robust Unlearnable Examples,"Ruohan Meng, Chenyu Yi, Yi Yu, Siyuan Yang, Bingquan Shen, Alex C. Kot",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17349"" target=""_blank"">2406.17349</a>",,2025-12-03 22:39:25
Treatment of Statistical Estimation Problems in Randomized Smoothing for Adversarial Robustness,Vaclav Voracek,arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17830"" target=""_blank"">2406.17830</a>",,2025-12-03 22:39:25
Robustly Optimized Deep Feature Decoupling Network for Fatty Liver Diseases Detection,"Peng Huang, Shu Hu, Bo Peng, Jiashu Zhang, Xi Wu, Xin Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.17338"" target=""_blank"">2406.17338</a>","<a href=""https://github.com/HP-ML/MICCAI2024"" target=""_blank"">HP-ML</a>",2025-12-03 22:39:25
Evaluating the Robustness of Deep-Learning Algorithm-Selection Models by Evolving Adversarial Instances,"Emma Hart, Quentin Renau, Kevin Sim, Mohamad Alissa",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16609"" target=""_blank"">2406.16609</a>",,2025-12-03 22:39:25
"UNICAD: A Unified Approach for Attack Detection, Noise Reduction and Novel Class Identification","Alvaro Lopez Pellicer, Kittipos Giatgong, Yi Li, Neeraj Suri, Plamen Angelov",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16501"" target=""_blank"">2406.16501</a>",,2025-12-03 22:39:25
ADVSCORE: A Metric for the Evaluation and Creation of Adversarial Benchmarks,"Yoo Yeon Sung, Eve Fleisig, Ishani Mondal, Jordan Lee Boyd-Graber",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.16342"" target=""_blank"">2406.16342</a>",,2025-12-03 22:39:25
GraphMU: Repairing Robustness of Graph Neural Networks via Machine Unlearning,"Tao Wu, Xinwen Cao, Chao Wang, Shaojie Qiao, Xingping Xian, Lin Yuan, Canyixing Cui, Yanbing Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13499"" target=""_blank"">2406.13499</a>",,2025-12-03 22:39:25
IDT: Dual-Task Adversarial Attacks for Privacy Protection,"Pedro Faustini, Shakila Mahjabin Tonni, Annabelle McIver, Qiongkai Xu, Mark Dras",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19642"" target=""_blank"">2406.19642</a>",,2025-12-03 22:39:25
Understanding the Robustness of Graph Neural Networks against Adversarial Attacks,"Tao Wu, Canyixing Cui, Xingping Xian, Shaojie Qiao, Chao Wang, Lin Yuan, Shui Yu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13920"" target=""_blank"">2406.13920</a>","<a href=""https://github.com/star4455/GraphRE"" target=""_blank"">star4455</a>",2025-12-03 22:39:25
BadSampler: Harnessing the Power of Catastrophic Forgetting to Poison Byzantine-robust Federated Learning,"Yi Liu, Cong Wang, Xingliang Yuan",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12222"" target=""_blank"">2406.12222</a>",,2025-12-03 22:39:25
Do Parameters Reveal More than Loss for Membership Inference? (1%),"Anshuman Suri, Xiao Zhang, David Evans",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11544"" target=""_blank"">2406.11544</a>",,2025-12-03 22:39:25
Adversaries With Incentives: A Strategic Alternative to Adversarial Robustness,"Maayan Ehrenberg, Roy Ganz, Nir Rosenfeld",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11458"" target=""_blank"">2406.11458</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness via Decoupled Visual Representation Masking,"Decheng Liu, Tao Chen, Chunlei Peng, Nannan Wang, Ruimin Hu, Xinbo Gao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10933"" target=""_blank"">2406.10933</a>","<a href=""https://github.com/chenboluo/Adversarial-defense"" target=""_blank"">chenboluo</a>",2025-12-03 22:39:25
Imperceptible Face Forgery Attack via Adversarial Semantic Mask,"Decheng Liu, Qixuan Su, Chunlei Peng, Nannan Wang, Xinbo Gao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10887"" target=""_blank"">2406.10887</a>","<a href=""https://github.com/clawerO-O/ASMA"" target=""_blank"">clawerO-O</a>",2025-12-03 22:39:25
KGPA: Robustness Evaluation for Large Language Models via Cross-Domain Knowledge Graphs,"Aihua Waseda University Pei, Zehua Waseda University Yang, Shunan Waseda University Zhu, Ruoxi Southeast University Cheng, Ju Southeast University Jia, Lina Wuhan University Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10802"" target=""_blank"">2406.10802</a>",,2025-12-03 22:39:25
NBA: defensive distillation for backdoor removal via neural behavior alignment,"Zonghao Ying, Bin Wu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10846"" target=""_blank"">2406.10846</a>",,2025-12-03 22:39:25
RWKU: Benchmarking Real-World Knowledge Unlearning for Large Language Models,"Zhuoran Jin, Pengfei Cao, Chenhao Wang, Zhitao He, Hongbang Yuan, Jiachun Li, Yubo Chen, Kang Liu, Jun Zhao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10890"" target=""_blank"">2406.10890</a>","<a href=""http://rwku-bench.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
ChatBug: A Common Vulnerability of Aligned LLMs Induced by Chat Templates,"Fengqing Jiang, Zhangchen Xu, Luyao Niu, Bill Yuchen Lin, Radha Poovendran",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12935"" target=""_blank"">2406.12935</a>",,2025-12-03 22:39:25
Imperceptible Rhythm Backdoor Attacks: Exploring Rhythm Transformation for Embedding Undetectable Vulnerabilities on Speech Recognition,"Wenhan Yao, Jiangkun Yang, Yongqiang He, Jia Liu, Weiping Wen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10932"" target=""_blank"">2406.10932</a>",,2025-12-03 22:39:25
RUPBench: Benchmarking Reasoning Under Perturbations for Robustness Evaluation in Large Language Models,"Yuqing Wang, Yun Zhao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11020"" target=""_blank"">2406.11020</a>",,2025-12-03 22:39:25
Robust Image Classification in the Presence of Out-of-Distribution and Adversarial Samples Using Attractors in Neural Networks,"Nasrin Alipour, Seyyed Ali SeyyedSalehi",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10579"" target=""_blank"">2406.10579</a>",,2025-12-03 22:39:25
Emerging Safety Attack and Defense in Federated Instruction Tuning of Large Language Models,"Rui Ye, Jingyi Chai, Xiangrui Liu, Yaodong Yang, Yanfeng Wang, Siheng Chen",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10630"" target=""_blank"">2406.10630</a>",,2025-12-03 22:39:25
Enhancing Anomaly Detection Generalization through Knowledge Exposure: The Dual Effects of Augmentation,"Mohammad Akhavan Anvari, Rojina Kashefi, Vahid Reza Khazaie, Mohammad Khalooei, Mohammad Sabokrou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10617"" target=""_blank"">2406.10617</a>",,2025-12-03 22:39:25
Over-parameterization and Adversarial Robustness in Neural Networks: An Overview and Empirical Analysis,"Zhang Chen, Luca Demetrio, Srishti Gupta, Xiaoyi Feng, Zhaoqiang Xia, Antonio Emanuele Cinà, Maura Pintor, Luca Oneto, Ambra Demontis, Battista Biggio, Fabio Roli",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10090"" target=""_blank"">2406.10090</a>",,2025-12-03 22:39:25
Adaptive Randomized Smoothing: Certified Adversarial Robustness for Multi-Step Defences,"Saiyue Lyu, Shadab Shaikh, Frederick Shpilevskiy, Evan Shelhamer, Mathias Lécuyer",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10427"" target=""_blank"">2406.10427</a>","<a href=""https://github.com/ubc-systopia/adaptive-randomized-smoothing"" target=""_blank"">ubc-systopia</a>",2025-12-03 22:39:25
Robustness-Inspired Defense Against Backdoor Attacks on Graph Neural Networks,"Zhiwei Zhang, Minhua Lin, Junjie Xu, Zongyu Wu, Enyan Dai, Suhang Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09836"" target=""_blank"">2406.09836</a>",,2025-12-03 22:39:25
Automated Design of Linear Bounding Functions for Sigmoidal Nonlinearities in Neural Networks,"Matthias König, Xiyue Zhang, Holger H. Hoos, Marta Kwiatkowska, Rijn Jan N. van",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10154"" target=""_blank"">2406.10154</a>",,2025-12-03 22:39:25
Beyond Slow Signs in High-fidelity Model Extraction,"Hanna Foerster, Robert Mullins, Ilia Shumailov, Jamie Hayes",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10011"" target=""_blank"">2406.10011</a>",,2025-12-03 22:39:25
Byzantine-Robust Decentralized Federated Learning,"Minghong Fang, Zifan Zhang, Hairi, Prashant Khanduri, Jia Liu, Songtao Lu, Yuchen Liu, Neil Gong",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10416"" target=""_blank"">2406.10416</a>",,2025-12-03 22:39:25
Self-supervised Monocular Depth Estimation Based on Hierarchical Feature-Guided Diffusion,"Runze Liu, Dongchen Zhu, Guanghui Zhang, Lei Wang, Jiamao Li",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09782"" target=""_blank"">2406.09782</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness via Feature Pattern Consistency Constraint,"Jiacong Hu, Jingwen Ye, Zunlei Feng, Jiazhen Yang, Shunyu Liu, Xiaotian Yu, Lingxiang Jia, Mingli Song",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.08829"" target=""_blank"">2406.08829</a>",,2025-12-03 22:39:25
Watch the Watcher! Backdoor Attacks on Security-Enhancing Diffusion Models,"Changjiang Li, Ren Pang, Bochuan Cao, Jinghui Chen, Fenglong Ma, Shouling Ji, Ting Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09669"" target=""_blank"">2406.09669</a>",,2025-12-03 22:39:25
MirrorCheck: Efficient Adversarial Defense for Vision-Language Models,"Samar Fares, Klea Ziu, Toluwani Aremu, Nikita Durasov, Martin Takáč, Pascal Fua, Karthik Nandakumar, Ivan Laptev",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09250"" target=""_blank"">2406.09250</a>",,2025-12-03 22:39:25
Towards Evaluating the Robustness of Visual State Space Models,"Hashmat Shadab Malik, Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar, Fahad Shahbaz Khan, Salman Khan",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09407"" target=""_blank"">2406.09407</a>","<a href=""https://github.com/HashmatShadab/MambaRobustness"" target=""_blank"">HashmatShadab</a>",2025-12-03 22:39:25
Steganalysis on Digital Watermarking: Is Your Defense Truly Impervious? (4%),"Pei Yang, Hai Ci, Yiren Song, Mike Zheng Shou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09026"" target=""_blank"">2406.09026</a>",,2025-12-03 22:39:25
Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs,"Zhao Xu, Fan Liu, Hao Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.09324"" target=""_blank"">2406.09324</a>","<a href=""https://github.com/usail-hkust/Bag_of_Tricks_for_LLM_Jailbreaking"" target=""_blank"">usail-hkust</a>",2025-12-03 22:39:25
AgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents,"Edoardo Debenedetti, Jie Zhang, Mislav Balunović, Luca Beurer-Kellner, Marc Fischer, Florian Tramèr",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13352"" target=""_blank"">2406.13352</a>","<a href=""https://github.com/ethz-spylab/agentdojo"" target=""_blank"">ethz-spylab</a>",2025-12-03 22:39:25
SoK: A Literature and Engineering Review of Regular Expression Denial of Service,"Masudul Hasan Masud Bhuiyan, Berk Çakar, Ethan H Burmane, James C Davis, Cristian-Alexandru Staicu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11618"" target=""_blank"">2406.11618</a>",,2025-12-03 22:39:25
E-SAGE: Explainability-based Defense Against Backdoor Attacks on Graph Neural Networks,"Dingqiang Yuan, Xiaohua Xu, Lei Yu, Tongchang Han, Rongchang Li, Meng Han",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.10655"" target=""_blank"">2406.10655</a>",,2025-12-03 22:39:25
Evading AI-Generated Content Detectors using Homoglyphs,"Aldan Creo, Shushanta Pudasaini",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11239"" target=""_blank"">2406.11239</a>",,2025-12-03 22:39:25
DLP: towards active defense against backdoor attacks with decoupled learning process,"Zonghao Ying, Bin Wu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13098"" target=""_blank"">2406.13098</a>",,2025-12-03 22:39:25
Textual Unlearning Gives a False Sense of Unlearning,"Jiacheng Du, Zhibo Wang, Kui Ren",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13348"" target=""_blank"">2406.13348</a>",,2025-12-03 22:39:25
DPO: Dual-Perturbation Optimization for Test-time Adaptation in 3D Object Detection,"Zhuoxiao Chen, Zixin Wang, Sen Wang, Zi Huang, Yadan Luo",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13891"" target=""_blank"">2406.13891</a>",,2025-12-03 22:39:25
ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations,"Yunze Xiao, Yujia Hu, Kenny Tsu Wei Choo, Roy Ka-wei Lee",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12223"" target=""_blank"">2406.12223</a>",,2025-12-03 22:39:25
Enhancing Cross-Prompt Transferability in Vision-Language Models through Contextual Injection of Target Tokens,"Xikang Yang, Xuehai Tang, Fuqing Zhu, Jizhong Han, Songlin Hu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13294"" target=""_blank"">2406.13294</a>",,2025-12-03 22:39:25
ModSec-Learn: Boosting ModSecurity with Machine Learning,"Christian Scano, Giuseppe Floris, Biagio Montaruli, Luca Demetrio, Andrea Valenza, Luca Compagna, Davide Ariu, Luca Piras, Davide Balzarotti, Battista Biggio",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13547"" target=""_blank"">2406.13547</a>","<a href=""https://github.com/pralab/modsec-learn"" target=""_blank"">pralab</a>",2025-12-03 22:39:25
RobGC: Towards Robust Graph Condensation,"Xinyi Gao, Hongzhi Yin, Tong Chen, Guanhua Ye, Wentao Zhang, Bin Cui",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13200"" target=""_blank"">2406.13200</a>",,2025-12-03 22:39:25
Saliency Attention and Semantic Similarity-Driven Adversarial Perturbation,"Hetvi Waghela, Jaydip Sen, Sneha Rakshit",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.19413"" target=""_blank"">2406.19413</a>",,2025-12-03 22:39:25
NoiSec: Harnessing Noise for Security against Adversarial and Backdoor Attacks,"Md Hasan Shahriar, Ning Wang, Y. Thomas Hou, Wenjing Lou",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13073"" target=""_blank"">2406.13073</a>",,2025-12-03 22:39:25
MaskPure: Improving Defense Against Text Adversaries with Stochastic Purification,"Harrison Gietz, Jugal Kalita",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13066"" target=""_blank"">2406.13066</a>",,2025-12-03 22:39:25
"Towards Trustworthy Unsupervised Domain Adaptation: A Representation Learning Perspective for Enhancing Robustness, Discrimination, and Generalization","Jia-Li Yin, Haoyuan Zheng, Ximeng Liu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13180"" target=""_blank"">2406.13180</a>",,2025-12-03 22:39:25
Adversarial Attacks on Large Language Models in Medicine,"Yifan Yang, Qiao Jin, Furong Huang, Zhiyong Lu",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12259"" target=""_blank"">2406.12259</a>",,2025-12-03 22:39:25
Can Go AIs be adversarially robust? (62%),"Tom Tseng, Euan McLean, Kellin Pelrine, Tony T. Wang, Adam Gleave",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12843"" target=""_blank"">2406.12843</a>",,2025-12-03 22:39:25
Adversarial Attacks on Multimodal Agents,"Chen Henry Wu, Jing Yu Koh, Ruslan Salakhutdinov, Daniel Fried, Aditi Raghunathan",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12814"" target=""_blank"">2406.12814</a>","<a href=""https://github.com/ChenWu98/agent-attack"" target=""_blank"">ChenWu98</a>",2025-12-03 22:39:25
Large-Scale Dataset Pruning in Adversarial Training through Data Importance Extrapolation,"Björn Nieth, Thomas Altstidl, Leo Schwinn, Björn Eskofier",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.13283"" target=""_blank"">2406.13283</a>",,2025-12-03 22:39:25
The Power of LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions,"Stefan Sylvius Wagner, Maike Behrendt, Marc Ziegele, Stefan Harmeling",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12480"" target=""_blank"">2406.12480</a>",,2025-12-03 22:39:25
Harmonizing Feature Maps: A Graph Convolutional Approach for Enhancing Adversarial Robustness,"Kejia Zhang, Juanjuan Weng, Junwei Wu, Guoqing Yang, Shaozi Li, Zhiming Luo",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11576"" target=""_blank"">2406.11576</a>",,2025-12-03 22:39:25
FullCert: Deterministic End-to-End Certification for Training and Inference of Neural Networks,"Tobias Lorenz, Marta Kwiatkowska, Mario Fritz",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11522"" target=""_blank"">2406.11522</a>",,2025-12-03 22:39:25
Adversarial Perturbations Cannot Reliably Protect Artists From Generative AI,"Robert Hönig, Javier Rando, Nicholas Carlini, Florian Tramèr",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12027"" target=""_blank"">2406.12027</a>",,2025-12-03 22:39:25
Obfuscating IoT Device Scanning Activity via Adversarial Example Generation,"Haocong Li, Yaxin Zhang, Long Cheng, Wenjia Niu, Haining Wang, Qiang Li",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11515"" target=""_blank"">2406.11515</a>",,2025-12-03 22:39:25
PRePair: Pointwise Reasoning Enhance Pairwise Evaluating for Robust Instruction-Following Assessments,"Hawon Jeong, ChaeHun Park, Jimin Hong, Jaegul Choo",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12319"" target=""_blank"">2406.12319</a>",,2025-12-03 22:39:25
Stealth edits for provably fixing or attacking large language models,"Oliver J. Sutton, Qinghua Zhou, Wei Wang, Desmond J. Higham, Alexander N. Gorban, Alexander Bastounis, Ivan Y. Tyukin",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12670"" target=""_blank"">2406.12670</a>","<a href=""https://github.com/qinghua-zhou/stealth-edits"" target=""_blank"">qinghua-zhou</a>",2025-12-03 22:39:25
CleanGen: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models,"Yuetai Li, Zhangchen Xu, Fengqing Jiang, Luyao Niu, Dinuka Sahabandu, Bhaskar Ramasubramanian, Radha Poovendran",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12257"" target=""_blank"">2406.12257</a>",,2025-12-03 22:39:25
SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation,"Xiaoze Liu, Ting Sun, Tianyang Xu, Feijie Wu, Cunxiang Wang, Xiaoqian Wang, Jing Gao",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12975"" target=""_blank"">2406.12975</a>","<a href=""https://github.com/xz-liu/SHIELD"" target=""_blank"">xz-liu</a>",2025-12-03 22:39:25
Attack and Defense of Deep Learning Models in the Field of Web Attack Detection,"Lijia Shi, Shihao Dong",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.12605"" target=""_blank"">2406.12605</a>",,2025-12-03 22:39:25
A First Physical-World Trajectory Prediction Attack via LiDAR-induced Deceptions in Autonomous Driving,"Yang Lou, Yi Zhu, Qun Song, Rui Tan, Chunming Qiao, Wei-Bin Lee, Jianping Wang",arXiv,2024-06,"<a href=""http://arxiv.org/abs/2406.11707"" target=""_blank"">2406.11707</a>",,2025-12-03 22:39:25
Certifying Robustness of Graph Convolutional Networks for Node Perturbation with Polyhedra Abstract Interpretation,"Boqi Chen, Kristóf Marussy, Oszkár Semeráth, Gunter Mussbacher, Dániel Varró",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08645"" target=""_blank"">2405.08645</a>",,2025-12-03 22:39:25
Achieving Resolution-Agnostic DNN-based Image Watermarking:A Novel Perspective of Implicit Neural Representation,"Yuchen Wang, Xingyu Zhu, Guanhui Ye, Shiyao Zhang, Xuetao Wei",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08340"" target=""_blank"">2405.08340</a>",,2025-12-03 22:39:25
Pointwise Lipschitz Continuous Graph Algorithms via Proximal Gradient Analysis,"Quanquan C. Liu, Grigoris Velegkas, Yuichi Yoshida, Felix Zhou",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08938"" target=""_blank"">2405.08938</a>",,2025-12-03 22:39:25
The RoboDrive Challenge: Drive Anytime Anywhere in Any Condition,"Lingdong Kong, Shaoyuan Xie, Hanjiang Hu, Yaru Niu, Wei Tsang Ooi, Benoit R. Cottereau, Lai Xing Ng, Yuexin Ma, Wenwei Zhang, Liang Pan, Kai Chen, Ziwei Liu, Weichao Qiu, Wei Zhang, Xu Cao, Hao Lu, Ying-Cong Chen, Caixin Kang, Xinning Zhou, Chengyang Ying, Wentao Shang, Xingxing Wei, Yinpeng Dong, Bo Yang, Shengyin Jiang, Zeliang Ma, Dengyi Ji, Haiwen Li, Xingliang Huang, Yu Tian, Genghua Kou, Fan Jia, Yingfei Liu, Tiancai Wang, Ying Li, Xiaoshuai Hao, Yifan Yang, Hui Zhang, Mengchuan Wei, Yi Zhou, Haimei Zhao, Jing Zhang, Jinke Li, Xiao He, Xiaoqiang Cheng, Bingyang Zhang, Lirong Zhao, Dianlei Ding, Fangsheng Liu, Yixiang Yan, Hongming Wang, Nanfei Ye, Lun Luo, Yubo Tian, Yiwei Zuo, Zhe Cao, Yi Ren, Yunfan Li, Wenjie Liu, Xun Wu, Yifan Mao, Ming Li, Jian Liu, Jiayang Liu, Zihan Qin, Cunxi Chu, Jialei Xu, Wenbo Zhao, Junjun Jiang, Xianming Liu, Ziyan Wang, Chiwei Li, Shilong Li, Chendong Yuan, Songyue Yang, Wentao Liu, Peng Chen, Bin Zhou, Yubo Wang, Chi Zhang, Jianhang Sun, Hai Chen, Xiao Yang, Lizhong Wang, Dongyi Fu, Yongchun Lin, Huitong Yang, Haoang Li, Yadan Luo, Xianjing Cheng, Yong Xu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08816"" target=""_blank"">2405.08816</a>",,2025-12-03 22:39:25
The Pitfalls and Promise of Conformal Inference Under Adversarial Attacks,"Ziquan Liu, Yufei Cui, Yan Yan, Yi Xu, Xiangyang Ji, Xue Liu, Antoni B. Chan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08886"" target=""_blank"">2405.08886</a>",,2025-12-03 22:39:25
Properties that allow or prohibit transferability of adversarial attacks among quantized networks,"Abhishek Shrestha, Jürgen Großmann",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09598"" target=""_blank"">2405.09598</a>",,2025-12-03 22:39:25
SpeechGuard: Exploring the Adversarial Robustness of Multimodal Large Language Models,"Raghuveer Peri, Sai Muralidhar Jayanthi, Srikanth Ronanki, Anshu Bhatia, Karel Mundnich, Saket Dingliwal, Nilaksh Das, Zejiang Hou, Goeric Huybrechts, Srikanth Vishnubhotla, Daniel Garcia-Romero, Sundararajan Srinivasan, Kyu J Han, Katrin Kirchhoff",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08317"" target=""_blank"">2405.08317</a>",,2025-12-03 22:39:25
Optimizing Sensor Network Design for Multiple Coverage,"Lukas Taus, Yen-Hsi Richard Tsai",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09096"" target=""_blank"">2405.09096</a>",,2025-12-03 22:39:25
Themis: Automatic and Efficient Deep Learning System Testing with Strong Fault Detection Capability,"Tsz On Li, Dong Huang, Xiaofei Xie, Heming Cui",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09314"" target=""_blank"">2405.09314</a>",,2025-12-03 22:39:25
"Dealing Doubt: Unveiling Threat Models in Gradient Inversion Attacks under Federated Learning, A Survey and Taxonomy","Yichuan Shi, Olivera Kotevska, Viktor Reshniak, Abhishek Singh, Ramesh Raskar",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10376"" target=""_blank"">2405.10376</a>",,2025-12-03 22:39:25
Cross-Input Certified Training for Universal Perturbations,"Changming Xu, Gagandeep Singh",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09176"" target=""_blank"">2405.09176</a>",,2025-12-03 22:39:25
Towards Evaluating the Robustness of Automatic Speech Recognition Systems via Audio Style Transfer,"Weifei Jin, Yuxin Cao, Junjie Su, Qi Shen, Kai Ye, Derui Wang, Jie Hao, Ziyao Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09470"" target=""_blank"">2405.09470</a>",,2025-12-03 22:39:25
Neural Collapse Meets Differential Privacy: Curious Behaviors of NoisyGD with Near-perfect Representation Learning,"Chendi Wang, Yuqing Zhu, Weijie J. Su, Yu-Xiang Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08920"" target=""_blank"">2405.08920</a>",,2025-12-03 22:39:25
IBD-PSC: Input-level Backdoor Detection via Parameter-oriented Scaling Consistency,"Linshan Hou, Ruili Feng, Zhongyun Hua, Wei Luo, Leo Yu Zhang, Yiming Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09786"" target=""_blank"">2405.09786</a>",,2025-12-03 22:39:25
Improving Transferable Targeted Adversarial Attack via Normalized Logit Calibration and Truncated Feature Mixing,"Juanjuan Weng, Zhiming Luo, Shaozi Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06340"" target=""_blank"">2405.06340</a>",,2025-12-03 22:39:25
UnMarker: A Universal Attack on Defensive Watermarking,"Andre Kassis, Urs Hengartner",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08363"" target=""_blank"">2405.08363</a>",,2025-12-03 22:39:25
RS-Reg: Probabilistic and Robust Certified Regression Through Randomized Smoothing,"Aref Miri Rekavandi, Olga Ohrimenko, Benjamin I. P. Rubinstein",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.08892"" target=""_blank"">2405.08892</a>","<a href=""https://github.com/arekavandi/Certified_Robust_Regression"" target=""_blank"">arekavandi</a>",2025-12-03 22:39:25
Environmental Matching Attack Against Unmanned Aerial Vehicles Object Detection,"Dehong Kong, Siyuan Liang, Wenqi Ren",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.07595"" target=""_blank"">2405.07595</a>",,2025-12-03 22:39:25
CrossCert: A Cross-Checking Detection Approach to Patch Robustness Certification for Deep Learning Models,"Qilin Zhou, Zhengyuan Wei, Haipeng Wang, Bo Jiang, W. K. Chan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.07668"" target=""_blank"">2405.07668</a>",,2025-12-03 22:39:25
RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors,"Liam Dugan, Alyssa Hwang, Filip Trhlik, Josh Magnus Ludan, Andrew Zhu, Hainiu Xu, Daphne Ippolito, Chris Callison-Burch",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.07940"" target=""_blank"">2405.07940</a>",,2025-12-03 22:39:25
GLiRA: Black-Box Membership Inference Attack via Knowledge Distillation,"Andrey V. Galichin, Mikhail Pautov, Alexey Zhavoronkin, Oleg Y. Rogov, Ivan Oseledets",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.07562"" target=""_blank"">2405.07562</a>",,2025-12-03 22:39:25
BB-Patch: BlackBox Adversarial Patch-Attack using Zeroth-Order Optimization,"Satyadwyoom Kumar, Saurabh Gupta, Arun Balaji Buduru",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06049"" target=""_blank"">2405.06049</a>",,2025-12-03 22:39:25
Backdoor Removal for Generative Large Language Models,"Haoran Li, Yulin Chen, Zihao Zheng, Qi Hu, Chunkit Chan, Heshan Liu, Yangqiu Song",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.07667"" target=""_blank"">2405.07667</a>",,2025-12-03 22:39:25
Stealthy Imitation: Reward-guided Environment-free Policy Stealing,"Zhixiong Zhuang, Maria-Irina Nicolae, Mario Fritz",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.07004"" target=""_blank"">2405.07004</a>",,2025-12-03 22:39:25
Disttack: Graph Adversarial Attacks Toward Distributed GNN Training,"Yuxiang Zhang, Xin Liu, Meng Wu, Wei Yan, Mingyu Yan, Xiaochun Ye, Dongrui Fan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06247"" target=""_blank"">2405.06247</a>",,2025-12-03 22:39:25
Exploring the Interplay of Interpretability and Robustness in Deep Neural Networks: A Saliency-guided Approach,"Amira Guesmi, Nishant Suresh Aswani, Muhammad Shafique",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06278"" target=""_blank"">2405.06278</a>",,2025-12-03 22:39:25
Evaluating Adversarial Robustness in the Spatial Frequency Domain,"Keng-Hsin Liao, Chin-Yuan Yeh, Hsi-Wen Chen, Ming-Syan Chen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06345"" target=""_blank"">2405.06345</a>",,2025-12-03 22:39:25
Certified $\ell_2$ Attribution Robustness via Uniformly Smoothed Attributions,"Fan Wang, Adams Wai-Kin Kong",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06361"" target=""_blank"">2405.06361</a>",,2025-12-03 22:39:25
PUMA: margin-based data pruning,"Javier Maroto, Pascal Frossard",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06298"" target=""_blank"">2405.06298</a>",,2025-12-03 22:39:25
Solving the enigma: Enhancing faithfulness and comprehensibility in explanations of deep networks,"Michail Mamalakis, Antonios Mamalakis, Ingrid Agartz, Lynn Egeland Mørch-Johnsen, Graham Murray, John Suckling, Pietro Lio",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10008"" target=""_blank"">2405.10008</a>",,2025-12-03 22:39:25
Manifold Integrated Gradients: Riemannian Geometry for Feature Attribution,"Eslam Zaher, Maciej Trzaskowski, Quan Nguyen, Fred Roosta",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09800"" target=""_blank"">2405.09800</a>",,2025-12-03 22:39:25
An Invisible Backdoor Attack Based On Semantic Feature,Yangming Chen,arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11551"" target=""_blank"">2405.11551</a>",,2025-12-03 22:39:25
Relational DNN Verification With Cross Executional Bound Refinement,"Debangshu Banerjee, Gagandeep Singh",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10143"" target=""_blank"">2405.10143</a>",,2025-12-03 22:39:25
Box-Free Model Watermarks Are Prone to Black-Box Removal Attacks,"Haonan An, Guang Hua, Zhiping Lin, Yuguang Fang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09863"" target=""_blank"">2405.09863</a>",,2025-12-03 22:39:25
Robust Deep Reinforcement Learning with Adaptive Adversarial Perturbations in Action Space,"Qianmei Liu, Yufei Kuang, Jie Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11982"" target=""_blank"">2405.11982</a>","<a href=""https://github.com/Lqm00/A2P-SAC"" target=""_blank"">Lqm00</a>",2025-12-03 22:39:25
EGAN: Evolutional GAN for Ransomware Evasion,"Daniel Commey, Benjamin Appiah, Bill K. Frimpong, Isaac Osei, Ebenezer N. A. Hammond, Garth V. Crosby",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12266"" target=""_blank"">2405.12266</a>",,2025-12-03 22:39:25
Rethinking Robustness Assessment: Adversarial Attacks on Learning-based Quadrupedal Locomotion Controllers,"Fan Shi, Chong Zhang, Takahiro Miki, Joonho Lee, Marco Hutter, Stelian Coros",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12424"" target=""_blank"">2405.12424</a>",,2025-12-03 22:39:25
Adversarially Diversified Rehearsal Memory (ADRM): Mitigating Memory Overfitting Challenge in Continual Learning,"Hikmat Khan, Ghulam Rasool, Nidhal Carla Bouaynaya",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11829"" target=""_blank"">2405.11829</a>","<a href=""https://github.com/hikmatkhan/ADRM"" target=""_blank"">hikmatkhan</a>",2025-12-03 22:39:25
Efficient Model-Stealing Attacks Against Inductive Graph Neural Networks,"Marcin Podhajski, Jan Dubiński, Franziska Boenisch, Adam Dziedzic, Agnieszka Pregowska, Tomasz Michalak",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12295"" target=""_blank"">2405.12295</a>",,2025-12-03 22:39:25
DispaRisk: Auditing Fairness Through Usable Information,"Jonathan Vasquez, Carlotta Domeniconi, Huzefa Rangwala",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12372"" target=""_blank"">2405.12372</a>","<a href=""https://github.com/jovasque156/disparisk"" target=""_blank"">jovasque156</a>",2025-12-03 22:39:25
Adaptive Batch Normalization Networks for Adversarial Robustness,"Shao-Yuan Lo, Vishal M. Patel",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11708"" target=""_blank"">2405.11708</a>",,2025-12-03 22:39:25
Poisoning-based Backdoor Attacks for Arbitrary Target Label with Positive Triggers,"Binxiao Huang, Jason Chun Lok, Chang Liu, Ngai Wong",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05573"" target=""_blank"">2405.05573</a>",,2025-12-03 22:39:25
Certified Robust Accuracy of Neural Networks Are Bounded due to Bayes Errors,"Ruihan Zhang, Jun Sun",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11547"" target=""_blank"">2405.11547</a>",,2025-12-03 22:39:25
A GAN-Based Data Poisoning Attack Against Federated Learning Systems and Its Countermeasure,"Wei Sun, Bo Gao, Ke Xiong, Yuwei Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11440"" target=""_blank"">2405.11440</a>","<a href=""https://github.com/SSssWEIssSS/VagueGAN-Data-Poisoning-Attack-and-Its-Countermeasure"" target=""_blank"">SSssWEIssSS</a>",2025-12-03 22:39:25
SEEP: Training Dynamics Grounds Latent Representation Search for Mitigating Backdoor Poisoning Attacks,"Xuanli He, Qiongkai Xu, Jun Wang, Benjamin I. P. Rubinstein, Trevor Cohn",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11575"" target=""_blank"">2405.11575</a>",,2025-12-03 22:39:25
Fed-Credit: Robust Federated Learning with Credibility Management,"Jiayan Chen, Zhirong Qian, Tianhui Meng, Xitong Gao, Tian Wang, Weijia Jia",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11758"" target=""_blank"">2405.11758</a>",,2025-12-03 22:39:25
BOSC: A Backdoor-based Framework for Open Set Synthetic Image Attribution,"Jun Wang, Benedetta Tondi, Mauro Barni",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11491"" target=""_blank"">2405.11491</a>",,2025-12-03 22:39:25
Towards Robust Policy: Enhancing Offline Reinforcement Learning with Adversarial Attacks and Defenses,"Thanh Nguyen, Tung M. Luu, Tri Ton, Chang D. Yoo",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11206"" target=""_blank"">2405.11206</a>",,2025-12-03 22:39:25
Trustworthy Actionable Perturbations,"Jesse Friedbaum, Sudarshan Adiga, Ravi Tandon",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11195"" target=""_blank"">2405.11195</a>",,2025-12-03 22:39:25
UPAM: Unified Prompt Attack in Text-to-Image Generation Models Against Both Textual Filters and Visual Checkers,"Duo Peng, Qiuhong Ke, Jun Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11336"" target=""_blank"">2405.11336</a>",,2025-12-03 22:39:25
BadActs: A Universal Backdoor Defense in the Activation Space,"Biao Yi, Sishuo Chen, Yiming Li, Tong Li, Baolei Zhang, Zheli Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11227"" target=""_blank"">2405.11227</a>",,2025-12-03 22:39:25
On Robust Reinforcement Learning with Lipschitz-Bounded Policy Networks,"Nicholas H. Barbara, Ruigang Wang, Ian R. Manchester",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11432"" target=""_blank"">2405.11432</a>",,2025-12-03 22:39:25
Diffusion Model Driven Test-Time Image Adaptation for Robust Skin Lesion Classification,"Ming Hu, Siyuan Yan, Peng Xia, Feilong Tang, Wenxue Li, Peibo Duan, Lin Zhang, Zongyuan Ge",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11289"" target=""_blank"">2405.11289</a>","<a href=""https://github.com/minghu0830/Skin-TTA_Diffusion"" target=""_blank"">minghu0830</a>",2025-12-03 22:39:25
RoBERTa-Augmented Synthesis for Detecting Malicious API Requests,"Udi Aharon, Revital Marbel, Ran Dubin, Amit Dvir, Chen Hajaj",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11258"" target=""_blank"">2405.11258</a>","<a href=""https://github.com/ArielCyber/GAN-API"" target=""_blank"">ArielCyber</a>",2025-12-03 22:39:25
Revisiting the Robust Generalization of Adversarial Prompt Tuning,"Fan Yang, Mingxuan Xia, Sangzhou Xia, Chicheng Ma, Hui Hui",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11154"" target=""_blank"">2405.11154</a>",,2025-12-03 22:39:25
Safeguarding Vision-Language Models Against Patched Visual Prompt Injectors,"Jiachen Sun, Changsheng Wang, Jiongxiao Wang, Yiwei Zhang, Chaowei Xiao",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10529"" target=""_blank"">2405.10529</a>",,2025-12-03 22:39:25
Rethinking Graph Backdoor Attacks: A Distribution-Preserving Perspective,"Zhiwei Zhang, Minhua Lin, Enyan Dai, Suhang Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10757"" target=""_blank"">2405.10757</a>",,2025-12-03 22:39:25
Not All Prompts Are Secure: A Switchable Backdoor Attack Against Pre-trained Vision Transformers,"Sheng Yang, Jiawang Bai, Kuofeng Gao, Yong Yang, Yiming Li, Shu-tao Xia",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10612"" target=""_blank"">2405.10612</a>","<a href=""https://github.com/20000yshust/SWARM"" target=""_blank"">20000yshust</a>",2025-12-03 22:39:25
Boosting Few-Pixel Robustness Verification via Covering Verification Designs,"Yuval Shapira, Naor Wiesel, Shahar Shabelman, Dana Drachsler-Cohen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10924"" target=""_blank"">2405.10924</a>",,2025-12-03 22:39:25
DiffAM: Diffusion-based Adversarial Makeup Transfer for Facial Privacy Protection,"Yuhao Sun, Lingyun Yu, Hongtao Xie, Jiaming Li, Yongdong Zhang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09882"" target=""_blank"">2405.09882</a>","<a href=""https://github.com/HansSunY/DiffAM"" target=""_blank"">HansSunY</a>",2025-12-03 22:39:25
Infrared Adversarial Car Stickers,"Xiaopei Zhu, Yuqiu Liu, Zhanhao Hu, Jianmin Li, Xiaolin Hu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09924"" target=""_blank"">2405.09924</a>",,2025-12-03 22:39:25
Adversarial Robustness for Visual Grounding of Multimodal Large Language Models,"Kuofeng Gao, Yang Bai, Jiawang Bai, Yong Yang, Shu-Tao Xia",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09981"" target=""_blank"">2405.09981</a>",,2025-12-03 22:39:25
Adversarial Robustness Guarantees for Quantum Classifiers,"Neil Dowling, Maxwell T. West, Angus Southwell, Azar C. Nakhl, Martin Sevior, Muhammad Usman, Kavan Modi",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10360"" target=""_blank"">2405.10360</a>",,2025-12-03 22:39:25
Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models,"Vyas Raina, Rao Ma, Charles McGhee, Kate Knill, Mark Gales",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06134"" target=""_blank"">2405.06134</a>",,2025-12-03 22:39:25
Why is SAM Robust to Label Noise? (1%),"Christina Baek, Zico Kolter, Aditi Raghunathan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03676"" target=""_blank"">2405.03676</a>",,2025-12-03 22:39:25
Link Stealing Attacks Against Inductive Graph Neural Networks,"Yixin Wu, Xinlei He, Pascal Berrang, Mathias Humbert, Michael Backes, Neil Zhenqiang Gong, Yang Zhang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05784"" target=""_blank"">2405.05784</a>",,2025-12-03 22:39:25
Updating Windows Malware Detectors: Balancing Robustness and Regression against Adversarial EXEmples,"Matous Kozak, Luca Demetrio, Dmitrijs Trizna, Fabio Roli",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.02646"" target=""_blank"">2405.02646</a>",,2025-12-03 22:39:25
UniDEC : Unified Dual Encoder and Classifier Training for Extreme Multi-Label Classification,"Siddhant Kharbanda, Devaansh Gupta, Gururaj K, Pankaj Malhotra, Amit Singh, Cho-Jui Hsieh, Rohit Babbar",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03714"" target=""_blank"">2405.03714</a>","<a href=""https://github.com/the-catalyst/UniDEC"" target=""_blank"">the-catalyst</a>",2025-12-03 22:39:25
From Attack to Defense: Insights into Deep Learning Security Measures in Black-Box Settings,"Firuz Juraev, Mohammed Abuhamad, Eric Chan-Tin, George K. Thiruvathukal, Tamer Abuhmed",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01963"" target=""_blank"">2405.01963</a>",,2025-12-03 22:39:25
ProFLingo: A Fingerprinting-based Copyright Protection Scheme for Large Language Models,"Heng Jin, Chaoyu Zhang, Shanghao Shi, Wenjing Lou, Y. Thomas Hou",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.02466"" target=""_blank"">2405.02466</a>","<a href=""https://github.com/hengvt/ProFLingo_arXiv"" target=""_blank"">hengvt</a>",2025-12-03 22:39:25
Impact of Architectural Modifications on Deep Learning Adversarial Robustness,"Firuz Juraev, Mohammed Abuhamad, Simon S. Woo, George K Thiruvathukal, Tamer Abuhmed",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01934"" target=""_blank"">2405.01934</a>",,2025-12-03 22:39:25
ModelShield: Adaptive and Robust Watermark against Model Extraction Attack,"Kaiyi Pang, Tao Qi, Chuhan Wu, Minhao Bai, Minghu Jiang, Yongfeng Huang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.02365"" target=""_blank"">2405.02365</a>",,2025-12-03 22:39:25
Robust Explainable Recommendation,"Sairamvinay Vijayaraghavan, Prasant Mohapatra",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01855"" target=""_blank"">2405.01855</a>",,2025-12-03 22:39:25
Adversarial Botometer: Adversarial Analysis for Social Bot Detection,"Shaghayegh Najari, Davood Rafiee, Mostafa Salehi, Reza Farahbakhsh",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.02016"" target=""_blank"">2405.02016</a>",,2025-12-03 22:39:25
Position Paper: Beyond Robustness Against Single Attack Types,"Sihui Dai, Chong Xiang, Tong Wu, Prateek Mittal",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01349"" target=""_blank"">2405.01349</a>",,2025-12-03 22:39:25
Explainability Guided Adversarial Evasion Attacks on Malware Detectors,"Kshitiz Aryal, Maanak Gupta, Mahmoud Abdelsalam, Moustafa Saleh",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01728"" target=""_blank"">2405.01728</a>",,2025-12-03 22:39:25
Purify Unlearnable Examples via Rate-Constrained Variational Autoencoders,"Yi Yu, Yufei Wang, Song Xia, Wenhan Yang, Shijian Lu, Yap-Peng Tan, Alex C. Kot",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01460"" target=""_blank"">2405.01460</a>","<a href=""https://github.com/yuyi-sd/D-VAE"" target=""_blank"">yuyi-sd</a>",2025-12-03 22:39:25
Poisoning Attacks on Federated Learning for Autonomous Driving,"Sonakshi Garg, Hugo Jönsson, Gustav Kalander, Axel Nilsson, Bhhaanu Pirange, Viktor Valadi, Johan Östman",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01073"" target=""_blank"">2405.01073</a>",,2025-12-03 22:39:25
Adversarial Attacks on Reinforcement Learning Agents for Command and Control,"Ahaan Dabholkar, James Z. Hare, Mark Mittrick, John Richardson, Nicholas Waytowich, Priya Narayanan, Saurabh Bagchi",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01693"" target=""_blank"">2405.01693</a>",,2025-12-03 22:39:25
Boosting Jailbreak Attack with Momentum,"Yihao Zhang, Zeming Wei",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01229"" target=""_blank"">2405.01229</a>","<a href=""https://github.com/weizeming/momentum-attack-llm"" target=""_blank"">weizeming</a>",2025-12-03 22:39:25
Uniformly Stable Algorithms for Adversarial Training and Beyond,"Jiancong Xiao, Jiawei Zhang, Zhi-Quan Luo, Asuman Ozdaglar",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01817"" target=""_blank"">2405.01817</a>",,2025-12-03 22:39:25
ATTAXONOMY: Unpacking Differential Privacy Guarantees Against Practical Adversaries,"Rachel Cummings, Shlomi Hod, Jayshree Sarathy, Marika Swanberg",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01716"" target=""_blank"">2405.01716</a>",,2025-12-03 22:39:25
Certified Adversarial Robustness of Machine Learning-based Malware Detectors via (De)Randomized Smoothing,"Daniel Gibert, Luca Demetrio, Giulio Zizzo, Quan Le, Jordi Planes, Battista Biggio",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00392"" target=""_blank"">2405.00392</a>",,2025-12-03 22:39:25
JNI Global References Are Still Vulnerable: Attacks and Defenses,"Yi He, Yuan Zhou, Yacong Gu, Purui Su, Qi Li, Yajin Zhou, Yong Jiang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00526"" target=""_blank"">2405.00526</a>",,2025-12-03 22:39:25
Robustness of graph embedding methods for community detection,"Zhi-Feng Wei, Pablo Moriano, Ramakrishnan Kannan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00636"" target=""_blank"">2405.00636</a>",,2025-12-03 22:39:25
Gameplay Filters: Robust Zero-Shot Safety through Adversarial Imagination,"Duy P. Nguyen, Kai-Chieh Hsu, Wenhao Yu, Jie Tan, Jaime F. Fisac",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00846"" target=""_blank"">2405.00846</a>",,2025-12-03 22:39:25
Exploiting Positional Bias for Query-Agnostic Generative Content in Search,"Andrew Parry, Sean MacAvaney, Debasis Ganguly",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00469"" target=""_blank"">2405.00469</a>",,2025-12-03 22:39:25
ASAM: Boosting Segment Anything Model with Adversarial Tuning,"Bo Li, Haoke Xiao, Lv Tang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00256"" target=""_blank"">2405.00256</a>","<a href=""https://asam2024.github.io/"" target=""_blank"">asam2024.github.io</a>",2025-12-03 22:39:25
Adversarial Attacks and Defense for Conversation Entailment Task,"Zhenning Yang, Ryan Krawec, Liang-Yuan Wu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00289"" target=""_blank"">2405.00289</a>",,2025-12-03 22:39:25
VeriFence: Lightweight and Precise Spectre Defenses for Untrusted Linux Kernel Extensions,"Luis Gerhorst, Henriette Herzog, Peter Wägemann, Maximilian Ott, Rüdiger Kapitza, Timo Hönig",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00078"" target=""_blank"">2405.00078</a>",,2025-12-03 22:39:25
Learnable Linguistic Watermarks for Tracing Model Extraction Attacks on Large Language Models,"Minhao Bai, Kaiyi Pang, Yongfeng Huang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01509"" target=""_blank"">2405.01509</a>",,2025-12-03 22:39:25
CodeFort: Robust Training for Code Generation Models,"Yuhao Zhang, Shiqi Wang, Haifeng Qian, Zijian Wang, Mingyue Shang, Linbo Liu, Sanjay Krishna Gouda, Baishakhi Ray, Murali Krishna Ramanathan, Xiaofei Ma, Anoop Deoras",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01567"" target=""_blank"">2405.01567</a>",,2025-12-03 22:39:25
DiffuseMix: Label-Preserving Data Augmentation with Diffusion Models,"Khawar Islam, Muhammad Zaigham Zaheer, Arif Mahmood, Karthik Nandakumar",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14881"" target=""_blank"">2405.14881</a>","<a href=""https://diffusemix.github.io/"" target=""_blank"">diffusemix.github.io</a>",2025-12-03 22:39:25
Mask-based Invisible Backdoor Attacks on Object Detection,Shin Jeong Jin,arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.09550"" target=""_blank"">2405.09550</a>",,2025-12-03 22:39:25
A Constraint-Enforcing Reward for Adversarial Attacks on Text Classifiers,"Tom Roth, Inigo Jauregi Unanue, Alsharif Abuadbba, Massimo Piccardi",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.11904"" target=""_blank"">2405.11904</a>",,2025-12-03 22:39:25
Exploring Biologically Inspired Mechanisms of Adversarial Robustness,"Konstantin Holzhausen, Mia Merlid, Håkon Olav Torvik, Anders Malthe-Sørenssen, Mikkel Elle Lepperød",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.00679"" target=""_blank"">2405.00679</a>",,2025-12-03 22:39:25
Assessing Adversarial Robustness of Large Language Models: An Empirical Study,"Zeyu Yang, Zhao Meng, Xiaochen Zheng, Roger Wattenhofer",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.02764"" target=""_blank"">2405.02764</a>",,2025-12-03 22:39:25
Probing Human Visual Robustness with Neurally-Guided Deep Neural Networks,"Zhenan Shao, Linjian Ma, Yiqing Zhou, Yibo Jacky Zhang, Sanmi Koyejo, Bo Li, Diane M. Beck",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.02564"" target=""_blank"">2405.02564</a>",,2025-12-03 22:39:25
Hard Work Does Not Always Pay Off: Poisoning Attacks on Neural Architecture Search,"Zachary Coalson, Huazheng Wang, Qingyun Wu, Sanghyun Hong",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06073"" target=""_blank"">2405.06073</a>",,2025-12-03 22:39:25
Explainable Malware Detection with Tailored Logic Explained Networks,"Peter Anthony, Francesco Giannini, Michelangelo Diligenti, Martin Homola, Marco Gori, Stefan Balogh, Jan Mojzis",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03009"" target=""_blank"">2405.03009</a>",,2025-12-03 22:39:25
Concealing Backdoor Model Updates in Federated Learning by Trigger-Optimized Data Poisoning,"Yujie Zhang, Neil Gong, Michael K. Reiter",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06206"" target=""_blank"">2405.06206</a>",,2025-12-03 22:39:25
Towards Robust Physical-world Backdoor Attacks on Lane Detection,"Xinwei Zhang, Aishan Liu, Tianyuan Zhang, Siyuan Liang, Xianglong Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05553"" target=""_blank"">2405.05553</a>",,2025-12-03 22:39:25
Model Inversion Robustness: Can Transfer Learning Help? (45%),"Sy-Tuyen Ho, Koh Jun Hao, Keshigeyan Chandrasegaran, Ngoc-Bao Nguyen, Ngai-Man Cheung",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05588"" target=""_blank"">2405.05588</a>","<a href=""https://hosytuyen.github.io/projects/TL-DMI"" target=""_blank"">projects</a>",2025-12-03 22:39:25
Chain of Attack: a Semantic-Driven Contextual Multi-Turn attacker for LLM,"Xikang Yang, Xuehai Tang, Songlin Hu, Jizhong Han",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05610"" target=""_blank"">2405.05610</a>",,2025-12-03 22:39:25
Demystifying Behavior-Based Malware Detection at Endpoints,"Yigitcan Kaya, Yizheng Chen, Shoumik Saha, Fabio Pierazzi, Lorenzo Cavallaro, David Wagner, Tudor Dumitras",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.06124"" target=""_blank"">2405.06124</a>",,2025-12-03 22:39:25
Universal Adversarial Perturbations for Vision-Language Pre-trained Models,"Peng-Fei Zhang, Zi Huang, Guangdong Bai",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05524"" target=""_blank"">2405.05524</a>",,2025-12-03 22:39:25
Adversarial Threats to Automatic Modulation Open Set Recognition in Wireless Networks,"Yandie Yang, Sicheng Zhang, Kuixian Li, Qiao Tian, Yun Lin",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05022"" target=""_blank"">2405.05022</a>",,2025-12-03 22:39:25
Untargeted Adversarial Attack on Knowledge Graph Embeddings,"Tianzhe Zhao, Jiaoyan Chen, Yanchi Ru, Qika Lin, Yuxia Geng, Jun Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.10970"" target=""_blank"">2405.10970</a>",,2025-12-03 22:39:25
Towards Efficient Training and Evaluation of Robust Models against $l_0$ Bounded Adversarial Perturbations,"Xuyang Zhong, Yixiao Huang, Chen Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05075"" target=""_blank"">2405.05075</a>","<a href=""https://github.com/CityU-MLO/sPGD"" target=""_blank"">CityU-MLO</a>",2025-12-03 22:39:25
Towards Accurate and Robust Architectures via Neural Architecture Search,"Yuwei Ou, Yuqi Feng, Yanan Sun",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.05502"" target=""_blank"">2405.05502</a>",,2025-12-03 22:39:25
Explanation as a Watermark: Towards Harmless and Multi-bit Model Ownership Verification via Watermarking Feature Attribution,"Shuo Shao, Yiming Li, Hongwei Yao, Yiling He, Zhan Qin, Kui Ren",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.04825"" target=""_blank"">2405.04825</a>",,2025-12-03 22:39:25
Revisiting character-level adversarial attacks,"Elias Abad Rocamora, Yongtao Wu, Fanghui Liu, Grigorios G. Chrysos, Volkan Cevher",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.04346"" target=""_blank"">2405.04346</a>","<a href=""https://github.com/LIONS-EPFL/Charmer"" target=""_blank"">LIONS-EPFL</a>",2025-12-03 22:39:25
Explainability-Informed Targeted Malware Misclassification,"Quincy Card, Kshitiz Aryal, Maanak Gupta",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.04010"" target=""_blank"">2405.04010</a>",,2025-12-03 22:39:25
Effective and Robust Adversarial Training against Data and Label Corruptions,"Peng-Fei Zhang, Zi Huang, Xin-Shun Xu, Guangdong Bai",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.04191"" target=""_blank"">2405.04191</a>",,2025-12-03 22:39:25
Going Proactive and Explanatory Against Malware Concept Drift,"Yiling He, Junchi Lei, Zhan Qin, Kui Ren",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.04095"" target=""_blank"">2405.04095</a>",,2025-12-03 22:39:25
Verified Neural Compressed Sensing,"Rudy Bunel, Krishnamurthy Dvijotham, M. Pawan Kumar, Palma Alessandro De, Robert Stanforth",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.04260"" target=""_blank"">2405.04260</a>",,2025-12-03 22:39:25
Exploring Frequencies via Feature Mixing and Meta-Learning for Improving Adversarial Transferability,"Juanjuan Weng, Zhiming Luo, Shaozi Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03193"" target=""_blank"">2405.03193</a>","<a href=""https://github.com/WJJLL/MetaSSA"" target=""_blank"">WJJLL</a>",2025-12-03 22:39:25
Cutting through buggy adversarial example defenses: fixing 1 line of code breaks Sabre,Nicholas Carlini,arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03672"" target=""_blank"">2405.03672</a>",,2025-12-03 22:39:25
On Adversarial Examples for Text Classification by Perturbing Latent Representations,"Korn Sooksatra, Bikram Khanal, Pablo Rivas",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03789"" target=""_blank"">2405.03789</a>",,2025-12-03 22:39:25
Is ReLU Adversarially Robust? (98%),"Korn Sooksatra, Greg Hamerly, Pablo Rivas",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03777"" target=""_blank"">2405.03777</a>",,2025-12-03 22:39:25
Enhancing O-RAN Security: Evasion Attacks and Robust Defenses for Graph Reinforcement Learning-based Connection Management,"Ravikumar Balakrishnan, Marius Arvinte, Nageen Himayat, Hosein Nikopour, Hassnaa Moustafa",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03891"" target=""_blank"">2405.03891</a>",,2025-12-03 22:39:25
BadFusion: 2D-Oriented Backdoor Attacks against 3D Object Detection,"Saket S. Chaturvedi, Lan Zhang, Wenbin Zhang, Pan He, Xiaoyong Yuan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03884"" target=""_blank"">2405.03884</a>",,2025-12-03 22:39:25
Provably Unlearnable Data Examples,"Derui Wang, Minhui Xue, Bo Li, Seyit Camtepe, Liming Zhu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03316"" target=""_blank"">2405.03316</a>",,2025-12-03 22:39:25
DarkFed: A Data-Free Backdoor Attack in Federated Learning,"Minghui Li, Wei Wan, Yuxuan Ning, Shengshan Hu, Lulu Xue, Leo Yu Zhang, Yichen Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03299"" target=""_blank"">2405.03299</a>",,2025-12-03 22:39:25
UnsafeBench: Benchmarking Image Safety Classifiers on Real-World and AI-Generated Images,"Yiting Qu, Xinyue Shen, Yixin Wu, Michael Backes, Savvas Zannettou, Yang Zhang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03486"" target=""_blank"">2405.03486</a>",,2025-12-03 22:39:25
Detecting Android Malware: From Neural Embeddings to Hands-On Validation with BERTroid,"Meryam Chaieb, Mostafa Anouar Ghorab, Mohamed Aymen Saied",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03620"" target=""_blank"">2405.03620</a>",,2025-12-03 22:39:25
LaserEscape: Detecting and Mitigating Optical Probing Attacks,"Saleh Khalaj Monfared, Kyle Mitard, Andrew Cannon, Domenic Forte, Shahin Tajik",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03632"" target=""_blank"">2405.03632</a>",,2025-12-03 22:39:25
Defense against Joint Poison and Evasion Attacks: A Case Study of DERMS,"Zain ul Abdeen, Padmaksha Roy, Ahmad Al-Tawaha, Rouxi Jia, Laura Freeman, Peter Beling, Chen-Ching Liu, Alberto Sangiovanni-Vincentelli, Ming Jin",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.02989"" target=""_blank"">2405.02989</a>",,2025-12-03 22:39:25
To Each (Textual Sequence) Its Own: Improving Memorized-Data Unlearning in Large Language Models,"George-Octavian Barbulescu, Peter Triantafillou",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.03097"" target=""_blank"">2405.03097</a>",,2025-12-03 22:39:25
GAN-GRID: A Novel Generative Attack on Smart Grid Stability Prediction,"Emad Efatinasab, Alessandro Brighente, Mirco Rampazzo, Nahal Azadi, Mauro Conti",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12076"" target=""_blank"">2405.12076</a>",,2025-12-03 22:39:25
A Novel Approach to Guard from Adversarial Attacks using Stable Diffusion,"Trinath Sai Subhash Reddy Pittala, Uma Maheswara Rao Meleti, Geethakrishna Puligundla",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.01838"" target=""_blank"">2405.01838</a>",,2025-12-03 22:39:25
Tiny Refinements Elicit Resilience: Toward Efficient Prefix-Model Against LLM Red-Teaming,"Jiaxu Liu, Xiangyu Yin, Sihao Wu, Jianhong Wang, Meng Fang, Xinping Yi, Xiaowei Huang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12604"" target=""_blank"">2405.12604</a>",,2025-12-03 22:39:25
AutoBreach: Universal and Adaptive Jailbreaking with Efficient Wordplay-Guided Optimization,"Jiawei Chen, Xiao Yang, Zhengwei Fang, Yu Tian, Yinpeng Dong, Zhaoxia Yin, Hang Su",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19668"" target=""_blank"">2405.19668</a>",,2025-12-03 22:39:25
ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning,"Ruchika Chavhan, Da Li, Timothy Hospedales",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19237"" target=""_blank"">2405.19237</a>",,2025-12-03 22:39:25
Resurrecting Old Classes with New Data for Exemplar-Free Continual Learning,"Dipam Goswami, Albin Soutif--Cormerais, Yuyang Liu, Sandesh Kamath, Bartłomiej Twardowski, de Weijer Joost van",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19074"" target=""_blank"">2405.19074</a>","<a href=""https://github.com/dipamgoswami/ADC"" target=""_blank"">dipamgoswami</a>",2025-12-03 22:39:25
Node Injection Attack Based on Label Propagation Against Graph Neural Network,"Peican Zhu, Zechen Pan, Keke Tang, Xiaodong Cui, Jinhuan Wang, Qi Xuan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18824"" target=""_blank"">2405.18824</a>",,2025-12-03 22:39:25
Genshin: General Shield for Natural Language Processing with Large Language Models,"Xiao Peng, Tao Liu, Ying Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18741"" target=""_blank"">2405.18741</a>",,2025-12-03 22:39:25
Confronting the Reproducibility Crisis: A Case Study of Challenges in Cybersecurity AI,"Richard H. Moulton, Gary A. McCully, John D. Hastings",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18753"" target=""_blank"">2405.18753</a>",,2025-12-03 22:39:25
Enhancing Security and Privacy in Federated Learning using Update Digests and Voting-Based Defense,"Wenjie Li, Kai Fan, Jingyuan Zhang, Hui Li, Wei Yang Bryan Lim, Qiang Yang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18802"" target=""_blank"">2405.18802</a>",,2025-12-03 22:39:25
Gone but Not Forgotten: Improved Benchmarks for Machine Unlearning,"Keltin Grimes, Collin Abidi, Cole Frank, Shannon Gallagher",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19211"" target=""_blank"">2405.19211</a>",,2025-12-03 22:39:25
MemControl: Mitigating Memorization in Diffusion Models via Automated Parameter Selection,"Raman Dutt, Ondrej Bohdal, Pedro Sanchez, Sotirios A. Tsaftaris, Timothy Hospedales",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19458"" target=""_blank"">2405.19458</a>","<a href=""https://github.com/Raman1121/Diffusion_Memorization_HPO"" target=""_blank"">Raman1121</a>",2025-12-03 22:39:25
Towards Unified Robustness Against Both Backdoor and Adversarial Attacks,"Zhenxing Niu, Yuyao Sun, Qiguang Miao, Rong Jin, Gang Hua",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17929"" target=""_blank"">2405.17929</a>",,2025-12-03 22:39:25
Improved Generation of Adversarial Examples Against Safety-aligned LLMs,"Qizhang Li, Yiwen Guo, Wangmeng Zuo, Hao Chen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20778"" target=""_blank"">2405.20778</a>","<a href=""https://github.com/qizhangli/Gradient-based-Jailbreak-Attacks"" target=""_blank"">qizhangli</a>",2025-12-03 22:39:25
PureGen: Universal Data Purification for Train-Time Poison Defense via Generative Model Dynamics,"Sunay Bhat, Jeffrey Jiang, Omead Pooladzandi, Alexander Branch, Gregory Pottie",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18627"" target=""_blank"">2405.18627</a>",,2025-12-03 22:39:25
PureEBM: Universal Poison Purification via Mid-Run Dynamics of Energy-Based Models,"Omead Pooladzandi, Jeffrey Jiang, Sunay Bhat, Gregory Pottie",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19376"" target=""_blank"">2405.19376</a>",,2025-12-03 22:39:25
White-box Multimodal Jailbreaks Against Large Vision-Language Models,"Ruofan Wang, Xingjun Ma, Hanxu Zhou, Chuanjun Ji, Guangnan Ye, Yu-Gang Jiang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17894"" target=""_blank"">2405.17894</a>",,2025-12-03 22:39:25
Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing,"Wei Zhao, Zhe Li, Yige Li, Ye Zhang, Jun Sun",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18166"" target=""_blank"">2405.18166</a>","<a href=""https://github.com/ledllm/ledllm"" target=""_blank"">ledllm</a>",2025-12-03 22:39:25
Wavelet-Based Image Tokenizer for Vision Transformers,"Zhenhai Zhu, Radu Soricut",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18616"" target=""_blank"">2405.18616</a>",,2025-12-03 22:39:25
Cross-Context Backdoor Attacks against Graph Prompt Learning,"Xiaoting Lyu, Yufei Han, Wei Wang, Hangwei Qian, Ivor Tsang, Xiangliang Zhang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17984"" target=""_blank"">2405.17984</a>",,2025-12-03 22:39:25
BlueSWAT: A Lightweight State-Aware Security Framework for Bluetooth Low Energy,"Xijia Che, Yi He, Xuewei Feng, Kun Sun, Ke Xu, Qi Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17987"" target=""_blank"">2405.17987</a>",,2025-12-03 22:39:25
Watermarking Counterfactual Explanations,"Hangzhi Guo, Firdaus Ahmed Choudhury, Tinghua Chen, Amulya Yadav",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18671"" target=""_blank"">2405.18671</a>",,2025-12-03 22:39:25
Black-Box Detection of Language Model Watermarks,"Thibaud Gloaguen, Nikola Jovanović, Robin Staab, Martin Vechev",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20777"" target=""_blank"">2405.20777</a>",,2025-12-03 22:39:25
Adversarial Attacks on Both Face Recognition and Face Anti-spoofing Models,"Fengfan Zhou, Qianyu Zhou, Hefei Ling, Xuequan Lu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16940"" target=""_blank"">2405.16940</a>",,2025-12-03 22:39:25
The Uncanny Valley: Exploring Adversarial Robustness from a Flatness Perspective,"Nils Philipp Walter, Linara Adilova, Jilles Vreeken, Michael Kamp",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16918"" target=""_blank"">2405.16918</a>",,2025-12-03 22:39:25
Exploiting the Layered Intrinsic Dimensionality of Deep Models for Practical Adversarial Training,"Enes Altinisik, Safa Messaoud, Husrev Taha Sencar, Hassan Sajjad, Sanjay Chawla",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17130"" target=""_blank"">2405.17130</a>",,2025-12-03 22:39:25
Spectral regularization for adversarially-robust representation learning,"Sheng Yang, Jacob A. Zavatone-Veth, Cengiz Pehlevan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17181"" target=""_blank"">2405.17181</a>",,2025-12-03 22:39:25
TIMA: Text-Image Mutual Awareness for Balancing Zero-Shot Adversarial Robustness and Generalization Ability,"Fengji Ma, Li Liu, Hei Victor Cheng",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17678"" target=""_blank"">2405.17678</a>",,2025-12-03 22:39:25
OSLO: One-Shot Label-Only Membership Inference Attacks,"Yuefeng Peng, Jaechul Roh, Subhransu Maji, Amir Houmansadr",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16978"" target=""_blank"">2405.16978</a>",,2025-12-03 22:39:25
Verifying Properties of Binary Neural Networks Using Sparse Polynomial Optimization,"Jianting Yang, Srećko Ðurašinović, Jean-Bernard Lasserre, Victor Magron, Jun Zhao",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17049"" target=""_blank"">2405.17049</a>",,2025-12-03 22:39:25
Rethinking Pruning for Backdoor Mitigation: An Optimization Perspective,"Nan Li, Haiyang Yu, Ping Yi",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17746"" target=""_blank"">2405.17746</a>",,2025-12-03 22:39:25
Navigating the Safety Landscape: Measuring Risks in Finetuning Large Language Models,"ShengYun Peng, Pin-Yu Chen, Matthew Hull, Duen Horng Chau",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17374"" target=""_blank"">2405.17374</a>","<a href=""https://github.com/ShengYun-Peng/llm-landscape"" target=""_blank"">ShengYun-Peng</a>",2025-12-03 22:39:25
Can We Trust Embodied Agents? Exploring Backdoor Attacks against Embodied LLM-based Decision-Making Systems,"Ruochen Jiao, Shaoyuan Xie, Justin Yue, Takami Sato, Lixu Wang, Yixuan Wang, Qi Alfred Chen, Qi Zhu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20774"" target=""_blank"">2405.20774</a>",,2025-12-03 22:39:25
EntProp: High Entropy Propagation for Improving Accuracy and Robustness,Shohei Enomoto,arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18931"" target=""_blank"">2405.18931</a>",,2025-12-03 22:39:25
AI Risk Management Should Incorporate Both Safety and Security,"Xiangyu Qi, Yangsibo Huang, Yi Zeng, Edoardo Debenedetti, Jonas Geiping, Luxi He, Kaixuan Huang, Udari Madhushani, Vikash Sehwag, Weijia Shi, Boyi Wei, Tinghao Xie, Danqi Chen, Pin-Yu Chen, Jeffrey Ding, Ruoxi Jia, Jiaqi Ma, Arvind Narayanan, Weijie J Su, Mengdi Wang, Chaowei Xiao, Bo Li, Dawn Song, Peter Henderson, Prateek Mittal",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19524"" target=""_blank"">2405.19524</a>",,2025-12-03 22:39:25
Magnitude-based Neuron Pruning for Backdoor Defens,"Nan Li, Haoyu Jiang, Ping Yi",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17750"" target=""_blank"">2405.17750</a>",,2025-12-03 22:39:25
Verifiably Robust Conformal Prediction,"Linus Jeary, Tom Kuipers, Mehran Hosseini, Nicola Paoletti",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18942"" target=""_blank"">2405.18942</a>",,2025-12-03 22:39:25
Enhancing Jailbreak Attack Against Large Language Models through Silent Tokens,"Jiahao Yu, Haozheng Luo, Jerry Yao-Chieh Hu, Wenbo Guo, Han Liu, Xinyu Xing",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20653"" target=""_blank"">2405.20653</a>",,2025-12-03 22:39:25
Investigating and unmasking feature-level vulnerabilities of CNNs to adversarial perturbations,"Davide Coppola, Hwee Kuan Lee",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20672"" target=""_blank"">2405.20672</a>",,2025-12-03 22:39:25
Robust Stable Spiking Neural Networks,"Jianhao Ding, Zhiyu Pan, Yujia Liu, Zhaofei Yu, Tiejun Huang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20694"" target=""_blank"">2405.20694</a>",,2025-12-03 22:39:25
Dullahan: Stealthy Backdoor Attack against Without-Label-Sharing Split Learning,"Yuwen Pu, Zhuoyuan Ding, Jiahao Chen, Chunyi Zhou, Qingming Li, Chunqiang Hu, Shouling Ji",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12751"" target=""_blank"">2405.12751</a>",,2025-12-03 22:39:25
Improved Techniques for Optimization-Based Jailbreaking on Large Language Models,"Xiaojun Jia, Tianyu Pang, Chao Du, Yihao Huang, Jindong Gu, Yang Liu, Xiaochun Cao, Min Lin",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.21018"" target=""_blank"">2405.21018</a>","<a href=""https://github.com/jiaxiaojunQAQ/I-GCG"" target=""_blank"">jiaxiaojunQAQ</a>",2025-12-03 22:39:25
ACE: A Model Poisoning Attack on Contribution Evaluation Methods in Federated Learning,"Zhangchen Xu, Fengqing Jiang, Luyao Niu, Jinyuan Jia, Bo Li, Radha Poovendran",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20975"" target=""_blank"">2405.20975</a>",,2025-12-03 22:39:25
Neural Network Verification with Branch-and-Bound for General Nonlinearities,"Zhouxing Shi, Qirui Jin, Zico Kolter, Suman Jana, Cho-Jui Hsieh, Huan Zhang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.21063"" target=""_blank"">2405.21063</a>",,2025-12-03 22:39:25
Query Provenance Analysis: Efficient and Robust Defense against Query-based Black-box Attacks,"Shaofei Li, Ziqi Zhang, Haomin Jia, Ding Li, Yao Guo, Xiangqun Chen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20641"" target=""_blank"">2405.20641</a>",,2025-12-03 22:39:25
GANcrop: A Contrastive Defense Against Backdoor Attacks in Federated Learning,"Xiaoyun Gan, Shanyu Gan, Taizhi Su, Peng Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20727"" target=""_blank"">2405.20727</a>",,2025-12-03 22:39:25
Locking Machine Learning Models into Hardware,"Eleanor Clifford, Adhithya Saravanan, Harry Langford, Cheng Zhang, Yiren Zhao, Robert Mullins, Ilia Shumailov, Jamie Hayes",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20990"" target=""_blank"">2405.20990</a>",,2025-12-03 22:39:25
Disrupting Diffusion: Token-Level Attention Erasure Attack against Diffusion-based Customization,"Yisu Liu, Jinyang An, Wanqian Zhang, Dayan Wu, Jingzi Gu, Zheng Lin, Weiping Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20584"" target=""_blank"">2405.20584</a>",,2025-12-03 22:39:25
HOLMES: to Detect Adversarial Examples with Multiple Detectors,Jing Wen,arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19956"" target=""_blank"">2405.19956</a>",,2025-12-03 22:39:25
Typography Leads Semantic Diversifying: Amplifying Adversarial Transferability across Multimodal Large Language Models,"Hao Cheng, Erjia Xiao, Jiayan Yang, Jiahang Cao, Qiang Zhang, Le Yang, Jize Zhang, Kaidi Xu, Jindong Gu, Renjing Xu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20090"" target=""_blank"">2405.20090</a>",,2025-12-03 22:39:25
Exploring the Robustness of Decision-Level Through Adversarial Attacks on LLM-Based Embodied Models,"Shuyuan Liu, Jiawei Chen, Shouwei Ruan, Hang Su, Zhaoxia Yin",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19802"" target=""_blank"">2405.19802</a>",,2025-12-03 22:39:25
Phantom: General Trigger Attacks on Retrieval Augmented Language Generation,"Harsh Chaudhari, Giorgio Severi, John Abascal, Matthew Jagielski, Christopher A. Choquette-Choo, Milad Nasr, Cristina Nita-Rotaru, Alina Oprea",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20485"" target=""_blank"">2405.20485</a>",,2025-12-03 22:39:25
SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents,"Ethan Rathbun, Christopher Amato, Alina Oprea",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20539"" target=""_blank"">2405.20539</a>",,2025-12-03 22:39:25
BAN: Detecting Backdoors Activated by Adversarial Neuron Noise,"Xiaoyun Xu, Zhuoran Liu, Stefanos Koffas, Shujian Yu, Stjepan Picek",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19928"" target=""_blank"">2405.19928</a>",,2025-12-03 22:39:25
Is My Data in Your Retrieval Database? Membership Inference Attacks Against Retrieval Augmented Generation,"Maya Anderson, Guy Amit, Abigail Goldsteen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20446"" target=""_blank"">2405.20446</a>",,2025-12-03 22:39:25
Defensive Prompt Patch: A Robust and Interpretable Defense of LLMs against Jailbreak Attacks,"Chen Xiong, Xiangyu Qi, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20099"" target=""_blank"">2405.20099</a>",,2025-12-03 22:39:25
Large Language Model Watermark Stealing With Mixed Integer Programming,"Zhaoxi Zhang, Xiaomei Zhang, Yanjun Zhang, Leo Yu Zhang, Chao Chen, Shengshan Hu, Asif Gill, Shirui Pan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19677"" target=""_blank"">2405.19677</a>",,2025-12-03 22:39:25
DiffPhysBA: Diffusion-based Physical Backdoor Attack against Person Re-Identification in Real-World,"Wenli Sun, Xinyang Jiang, Dongsheng Li, Cairong Zhao",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19990"" target=""_blank"">2405.19990</a>",,2025-12-03 22:39:25
Unveiling and Mitigating Backdoor Vulnerabilities based on Unlearning Weight Changes and Backdoor Activeness,"Weilin Lin, Li Liu, Shaokui Wei, Jianze Li, Hui Xiong",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20291"" target=""_blank"">2405.20291</a>",,2025-12-03 22:39:25
Certifying Global Robustness for Deep Neural Networks,"You Li, Guannan Zhao, Shuyu Kong, Yunqi He, Hai Zhou",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20556"" target=""_blank"">2405.20556</a>",,2025-12-03 22:39:25
Breaking Indistinguishability with Transfer Learning: A First Look at SPECK32/64 Lightweight Block Ciphers,"Jimmy Dani, Kalyan Nakka, Nitesh Saxena",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19683"" target=""_blank"">2405.19683</a>",,2025-12-03 22:39:25
Reconstruction Attacks on Machine Unlearning: Simple Models are Vulnerable,"Martin Bertran, Shuai Tang, Michael Kearns, Jamie Morgenstern, Aaron Roth, Zhiwei Steven Wu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20272"" target=""_blank"">2405.20272</a>",,2025-12-03 22:39:25
Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior,"Shuyu Cheng, Yibo Miao, Yinpeng Dong, Xiao Yang, Xiao-Shan Gao, Jun Zhu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19098"" target=""_blank"">2405.19098</a>","<a href=""https://github.com/yibo-miao/PBO-Attack"" target=""_blank"">yibo-miao</a>",2025-12-03 22:39:25
Leveraging Many-To-Many Relationships for Defending Against Visual-Language Adversarial Attacks,"Futa Waseda, Antonio Tejero-de-Pablos",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.18770"" target=""_blank"">2405.18770</a>",,2025-12-03 22:39:25
Diffusion Policy Attacker: Crafting Adversarial Attacks for Diffusion-based Policies,"Yipu Chen, Haotian Xue, Yongxin Chen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19424"" target=""_blank"">2405.19424</a>",,2025-12-03 22:39:25
Evaluating the Effectiveness and Robustness of Visual Similarity-based Phishing Detection Models,"Fujiao Ji, Kiho Lee, Hyungjoon Koo, Wenhao You, Euijin Choo, Hyoungshick Kim, Doowon Kim",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19598"" target=""_blank"">2405.19598</a>",,2025-12-03 22:39:25
LabObf: A Label Protection Scheme for Vertical Federated Learning Through Label Obfuscation,"Ying He, Mingyang Niu, Jingyu Hua, Yunlong Mao, Xu Huang, Chen Li, Sheng Zhong",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17042"" target=""_blank"">2405.17042</a>",,2025-12-03 22:39:25
Enhancing Adversarial Robustness in SNNs with Sparse Gradients,"Yujia Liu, Tong Bu, Jianhao Ding, Zecheng Hao, Tiejun Huang, Zhaofei Yu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20355"" target=""_blank"">2405.20355</a>",,2025-12-03 22:39:25
Medical MLLM is Vulnerable: Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models,"Xijie Huang, Xinyuan Wang, Hantao Zhang, Yinghao Zhu, Jiawen Xi, Jingkun An, Hao Wang, Hao Liang, Chengwei Pan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20775"" target=""_blank"">2405.20775</a>","<a href=""https://github.com/dirtycomputer/O2M_attack"" target=""_blank"">dirtycomputer</a>",2025-12-03 22:39:25
"Eidos: Efficient, Imperceptible Adversarial 3D Point Clouds","Hanwei Zhang, Luo Cheng, Qisong He, Wei Huang, Renjue Li, Ronan Sicre, Xiaowei Huang, Holger Hermanns, Lijun Zhang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14210"" target=""_blank"">2405.14210</a>",,2025-12-03 22:39:25
A New Formulation for Zeroth-Order Optimization of Adversarial EXEmples in Malware Detection,"Marco Rando, Luca Demetrio, Lorenzo Rosasco, Fabio Roli",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14519"" target=""_blank"">2405.14519</a>",,2025-12-03 22:39:25
SLIFER: Investigating Performance and Robustness of Malware Detection Pipelines,"Andrea Ponte, Dmitrijs Trizna, Luca Demetrio, Battista Biggio, Ivan Tesfai Ogbu, Fabio Roli",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14478"" target=""_blank"">2405.14478</a>",,2025-12-03 22:39:25
Generating camera failures as a class of physics-based adversarial examples,"Manav Prabhakar, Jwalandhar Girnar, Arpan Kusari",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15033"" target=""_blank"">2405.15033</a>",,2025-12-03 22:39:25
TrojanForge: Generating Adversarial Hardware Trojan Examples with Reinforcement Learning,"Amin Sarihi, Peter Jamieson, Ahmad Patooghy, Abdel-Hameed A. Badawy",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15184"" target=""_blank"">2405.15184</a>",,2025-12-03 22:39:25
Towards Transferable Attacks Against Vision-LLMs in Autonomous Driving with Typography,"Nhat Chung, Sensen Gao, Tuan-Anh Vu, Jie Zhang, Aishan Liu, Yun Lin, Jin Song Dong, Qing Guo",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14169"" target=""_blank"">2405.14169</a>",,2025-12-03 22:39:25
How Does Bayes Error Limit Probabilistic Robust Accuracy,"Ruihan Zhang, Jun Sun",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14923"" target=""_blank"">2405.14923</a>",,2025-12-03 22:39:25
Universal Robustness via Median Randomized Smoothing for Real-World Super-Resolution,"Zakariya Chaouai, Mohamed Tamaazousti",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14934"" target=""_blank"">2405.14934</a>",,2025-12-03 22:39:25
Invisible Backdoor Attack against Self-supervised Learning,"Hanrong Zhang, Zhenting Wang, Boheng Li, Fulin Lin, Tingxu Han, Mingyu Jin, Chenlu Zhan, Mengnan Du, Hongwei Wang, Shiqing Ma",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14672"" target=""_blank"">2405.14672</a>","<a href=""https://github.com/Zhang-Henry/INACTIVE"" target=""_blank"">Zhang-Henry</a>",2025-12-03 22:39:25
Unveiling the Achilles' Heel of NLG Evaluators: A Unified Adversarial Framework Driven by Large Language Models,"Yiming Chen, Chen Zhang, Danqing Luo, Luis Fernando D'Haro, Robby T. Tan, Haizhou Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14646"" target=""_blank"">2405.14646</a>",,2025-12-03 22:39:25
AdjointDEIS: Efficient Gradients for Diffusion Models,"Zander W. Blasingame, Chen Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15020"" target=""_blank"">2405.15020</a>","<a href=""https://zblasingame.github.io/AdjointDEIS/"" target=""_blank"">AdjointDEIS</a>",2025-12-03 22:39:25
What Variables Affect Out-of-Distribution Generalization in Pretrained Models? (9%),"Md Yousuf Harun, Kyungbok Lee, Jhair Gallardo, Giri Krishnan, Christopher Kanan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15018"" target=""_blank"">2405.15018</a>",,2025-12-03 22:39:25
Tighter Privacy Auditing of DP-SGD in the Hidden State Threat Model,"Tudor Cebere, Aurélien Bellet, Nicolas Papernot",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14457"" target=""_blank"">2405.14457</a>",,2025-12-03 22:39:25
RFLPA: A Robust Federated Learning Framework against Poisoning Attacks with Secure Aggregation,"Peihua Mai, Ran Yan, Yan Pang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15182"" target=""_blank"">2405.15182</a>",,2025-12-03 22:39:25
Are You Copying My Prompt? Protecting the Copyright of Vision Prompt for VPaaS via Watermark,"Huali Ren, Anli Yan, Chong-zhi Gao, Hongyang Yan, Zhenxin Zhang, Jin Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15161"" target=""_blank"">2405.15161</a>",,2025-12-03 22:39:25
Adaptive Gradient Clipping for Robust Federated Learning,"Youssef Allouah, Rachid Guerraoui, Nirupam Gupta, Ahmed Jellouli, Geovani Rizk, John Stephan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14432"" target=""_blank"">2405.14432</a>",,2025-12-03 22:39:25
Learning to Transform Dynamically for Better Adversarial Transferability,"Rongyi Zhu, Zeliang Zhang, Susan Liang, Zhuo Liu, Chenliang Xu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14077"" target=""_blank"">2405.14077</a>","<a href=""https://github.com/RongyiZhu/L2T"" target=""_blank"">RongyiZhu</a>",2025-12-03 22:39:25
Adversarial Training of Two-Layer Polynomial and ReLU Activation Networks via Convex Optimization,"Daniel Kuelbs, Sanjay Lall, Mert Pilanci",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14033"" target=""_blank"">2405.14033</a>",,2025-12-03 22:39:25
Towards Certification of Uncertainty Calibration under Adversarial Attacks,"Cornelius Emde, Francesco Pinto, Thomas Lukasiewicz, Philip H. S. Torr, Adel Bibi",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.13922"" target=""_blank"">2405.13922</a>",,2025-12-03 22:39:25
LookHere: Vision Transformers with Directed Attention Generalize and Extrapolate,"Anthony Fuller, Daniel G. Kyrollos, Yousef Yassin, James R. Green",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.13985"" target=""_blank"">2405.13985</a>",,2025-12-03 22:39:25
Remote Keylogging Attacks in Multi-user VR Applications,"Zihao Su, Kunlin Cai, Reuben Beeler, Lukas Dresel, Allan Garcia, Ilya Grishchenko, Yuan Tian, Christopher Kruegel, Giovanni Vigna",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14036"" target=""_blank"">2405.14036</a>",,2025-12-03 22:39:25
Nearly Tight Black-Box Auditing of Differentially Private Machine Learning,"Meenatchi Sundaram Muthu Selva Annamalai, Cristofaro Emiliano De",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14106"" target=""_blank"">2405.14106</a>","<a href=""https://github.com/spalabucr/bb-audit-dpsgd"" target=""_blank"">spalabucr</a>",2025-12-03 22:39:25
Mellivora Capensis: A Backdoor-Free Training Framework on the Poisoned Dataset without Auxiliary Data,"Yuwen Pu, Jiahao Chen, Chunyi Zhou, Zhou Feng, Qingming Li, Chunqiang Hu, Shouling Ji",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12719"" target=""_blank"">2405.12719</a>",,2025-12-03 22:39:25
Adversarial Training via Adaptive Knowledge Amalgamation of an Ensemble of Teachers,"Shayan Mohajer Hamidi, Linfeng Ye",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.13324"" target=""_blank"">2405.13324</a>",,2025-12-03 22:39:25
Rethinking the Vulnerabilities of Face Recognition Systems:From a Practical Perspective,"Jiahao Chen, Zhiqiang Shen, Yuwen Pu, Chunyi Zhou, Shouling Ji",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12786"" target=""_blank"">2405.12786</a>",,2025-12-03 22:39:25
EmInspector: Combating Backdoor Attacks in Federated Self-Supervised Learning Through Embedding Inspection,"Yuwen Qian, Shuchi Wu, Kang Wei, Ming Ding, Di Xiao, Tao Xiang, Chuan Ma, Song Guo",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.13080"" target=""_blank"">2405.13080</a>","<a href=""https://github.com/ShuchiWu/EmInspector"" target=""_blank"">ShuchiWu</a>",2025-12-03 22:39:25
Nearest is Not Dearest: Towards Practical Defense against Quantization-conditioned Backdoor Attacks,"Boheng Li, Yishuo Cai, Haowei Li, Feng Xue, Zhifeng Li, Yiming Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12725"" target=""_blank"">2405.12725</a>","<a href=""https://github.com/AntigoneRandy/QuantBackdoor_EFRAP"" target=""_blank"">AntigoneRandy</a>",2025-12-03 22:39:25
Fully Randomized Pointers,"Gregory J. Duck, Sai Dhawal Phaye, Roland H. C. Yap, Trevor E. Carlson",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.12513"" target=""_blank"">2405.12513</a>",,2025-12-03 22:39:25
Pruning for Robust Concept Erasing in Diffusion Models,"Tianyun Yang, Juan Cao, Chang Xu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16534"" target=""_blank"">2405.16534</a>",,2025-12-03 22:39:25
A novel reliability attack of Physical Unclonable Functions,"Gaoxiang Li, Yu Zhuang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.13147"" target=""_blank"">2405.13147</a>",,2025-12-03 22:39:25
Certified Robustness against Sparse Adversarial Perturbations via Data Localization,"Ambar Pal, René Vidal, Jeremias Sulam",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14176"" target=""_blank"">2405.14176</a>",,2025-12-03 22:39:25
WordGame: Efficient & Effective LLM Jailbreak via Simultaneous Obfuscation in Query and Response,"Tianrong Zhang, Bochuan Cao, Yuanpu Cao, Lu Lin, Prasenjit Mitra, Jinghui Chen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.14023"" target=""_blank"">2405.14023</a>",,2025-12-03 22:39:25
"Revisit, Extend, and Enhance Hessian-Free Influence Functions","Ziao Yang, Han Yue, Jian Chen, Hongfu Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.17490"" target=""_blank"">2405.17490</a>",,2025-12-03 22:39:25
Noisy Data Meets Privacy: Training Local Models with Post-Processed Remote Queries,"Kexin Li, Aastha Mehta, David Lie",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16361"" target=""_blank"">2405.16361</a>",,2025-12-03 22:39:25
Enhancing Adversarial Transferability Through Neighborhood Conditional Sampling,"Chunlin Qiu, Yiheng Duan, Lingchen Zhao, Qian Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16181"" target=""_blank"">2405.16181</a>",,2025-12-03 22:39:25
Breaking the False Sense of Security in Backdoor Defense through Re-Activation Attack,"Mingli Zhu, Siyuan Liang, Baoyuan Wu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16134"" target=""_blank"">2405.16134</a>",,2025-12-03 22:39:25
Detecting Adversarial Data via Perturbation Forgery,"Qian Wang, Chen Li, Yuchen Luo, Hefei Ling, Ping Li, Jiazhong Chen, Shijuan Huang, Ning Yu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16226"" target=""_blank"">2405.16226</a>",,2025-12-03 22:39:25
Automatic Jailbreaking of the Text-to-Image Generative AI Systems,"Minseon Kim, Hyomin Lee, Boqing Gong, Huishuai Zhang, Sung Ju Hwang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16567"" target=""_blank"">2405.16567</a>",,2025-12-03 22:39:25
R,"Changhoon Kim, Kyle Min, Yezhou Yang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16341"" target=""_blank"">2405.16341</a>",,2025-12-03 22:39:25
Uncertainty Measurement of Deep Learning System based on the Convex Hull of Training Sets,"Hyekyoung Hwang, Jitae Shin",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16082"" target=""_blank"">2405.16082</a>",,2025-12-03 22:39:25
"Partial train and isolate, mitigate backdoor attack","Yong Li, Han Gao",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16488"" target=""_blank"">2405.16488</a>",,2025-12-03 22:39:25
Layer-Aware Analysis of Catastrophic Overfitting: Revealing the Pseudo-Robust Shortcut Dependency,"Runqi Lin, Chaojian Yu, Bo Han, Hang Su, Tongliang Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16262"" target=""_blank"">2405.16262</a>",,2025-12-03 22:39:25
Mitigating Backdoor Attack by Injecting Proactive Defensive Backdoor,"Shaokui Wei, Hongyuan Zha, Baoyuan Wu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16112"" target=""_blank"">2405.16112</a>",,2025-12-03 22:39:25
Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Image Character,"Siyuan Ma, Weidi Luo, Yu Wang, Xiaogeng Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20773"" target=""_blank"">2405.20773</a>",,2025-12-03 22:39:25
Intruding with Words: Towards Understanding Graph Injection Attacks at the Text Level,"Runlin Lei, Yuwei Hu, Yuchen Ren, Zhewei Wei",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16405"" target=""_blank"">2405.16405</a>",,2025-12-03 22:39:25
AuthNet: Neural Network with Integrated Authentication Logic,"Yuling Cai, Fan Xiang, Guozhu Meng, Yinzhi Cao, Kai Chen",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15426"" target=""_blank"">2405.15426</a>",,2025-12-03 22:39:25
TrojFM: Resource-efficient Backdoor Attacks against Very Large Foundation Models,"Yuzhou. Nie, Yanting. Wang, Jinyuan. Jia, Lucia Michael J. De, Nathaniel D. Bastian, Wenbo. Guo, Dawn. Song",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16783"" target=""_blank"">2405.16783</a>",,2025-12-03 22:39:25
Robust Message Embedding via Attention Flow-Based Steganography,"Huayuan Ye, Shenzhuo Zhang, Shiqi Jiang, Jing Liao, Shuhang Gu, Dejun Zheng, Changbo Wang, Chenhui Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16414"" target=""_blank"">2405.16414</a>",,2025-12-03 22:39:25
No Two Devils Alike: Unveiling Distinct Mechanisms of Fine-tuning Attacks,"Chak Tou Leong, Yi Cheng, Kaishuai Xu, Jian Wang, Hanlin Wang, Wenjie Li",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16229"" target=""_blank"">2405.16229</a>",,2025-12-03 22:39:25
Robust width: A lightweight and certifiable adversarial defense,"Jonathan Peck, Bart Goossens",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15971"" target=""_blank"">2405.15971</a>","<a href=""https://github.com/peck94/robust-width-defense"" target=""_blank"">peck94</a>",2025-12-03 22:39:25
Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models,"Yimeng Zhang, Xin Chen, Jinghan Jia, Yihua Zhang, Chongyu Fan, Jiancheng Liu, Mingyi Hong, Ke Ding, Sijia Liu",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15234"" target=""_blank"">2405.15234</a>","<a href=""https://github.com/OPTML-Group/AdvUnlearn"" target=""_blank"">OPTML-Group</a>",2025-12-03 22:39:25
BadGD: A unified data-centric framework to identify gradient descent vulnerabilities,"Chi-Hua Wang, Guang Cheng",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15979"" target=""_blank"">2405.15979</a>",,2025-12-03 22:39:25
Certifiably Robust RAG against Retrieval Corruption,"Chong Xiang, Tong Wu, Zexuan Zhong, David Wagner, Danqi Chen, Prateek Mittal",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15556"" target=""_blank"">2405.15556</a>",,2025-12-03 22:39:25
Can Implicit Bias Imply Adversarial Robustness? (11%),"Hancheng Min, René Vidal",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15942"" target=""_blank"">2405.15942</a>",,2025-12-03 22:39:25
HiddenSpeaker: Generate Imperceptible Unlearnable Audios for Speaker Verification System,"Zhisheng Zhang, Pengyang Huang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15655"" target=""_blank"">2405.15655</a>",,2025-12-03 22:39:25
Large Language Model Sentinel: LLM Agent for Adversarial Purification,"Guang Lin, Toshihisa Tanaka, Qibin Zhao",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.20770"" target=""_blank"">2405.20770</a>",,2025-12-03 22:39:25
Robustifying Safety-Aligned Large Language Models through Clean Data Curation,"Xiaoqun Liu, Jiacheng Liang, Muchao Ye, Zhaohan Xi",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.19358"" target=""_blank"">2405.19358</a>",,2025-12-03 22:39:25
BDetCLIP: Multimodal Prompting Contrastive Test-Time Backdoor Detection,"Yuwei Niu, Shuo He, Qi Wei, Zongyu Wu, Feng Liu, Lei Feng",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15269"" target=""_blank"">2405.15269</a>",,2025-12-03 22:39:25
Rethinking Independent Cross-Entropy Loss For Graph-Structured Data,"Rui Miao, Kaixiong Zhou, Yili Wang, Ninghao Liu, Ying Wang, Xin Wang",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15564"" target=""_blank"">2405.15564</a>",,2025-12-03 22:39:25
Efficient Adversarial Training in LLMs with Continuous Attacks,"Sophie Xhonneux, Alessandro Sordoni, Stephan Günnemann, Gauthier Gidel, Leo Schwinn",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15589"" target=""_blank"">2405.15589</a>",,2025-12-03 22:39:25
Certifying Adapters: Enabling and Enhancing the Certification of Classifier Adversarial Robustness,"Jieren Deng, Hanbin Hong, Aaron Palmer, Xin Zhou, Jinbo Bi, Kaleel Mahmood, Yuan Hong, Derek Aguiar",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.16036"" target=""_blank"">2405.16036</a>",,2025-12-03 22:39:25
Evaluating and Safeguarding the Adversarial Robustness of Retrieval-Based In-Context Learning,"Simon Yu, Jie He, Pasquale Minervini, Jeff Z. Pan",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15984"" target=""_blank"">2405.15984</a>","<a href=""https://github.com/simonucl/adv-retreival-icl"" target=""_blank"">simonucl</a>",2025-12-03 22:39:25
Adversarial Attacks on Hidden Tasks in Multi-Task Learning,"Yu Zhe, Rei Nagaike, Daiki Nishiyama, Kazuto Fukuchi, Jun Sakuma",arXiv,2024-05,"<a href=""http://arxiv.org/abs/2405.15244"" target=""_blank"">2405.15244</a>",,2025-12-03 22:39:25
Towards Robust Domain Generation Algorithm Classification,"Arthur Drichel, Marc Meyer, Ulrike Meyer",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06236"" target=""_blank"">2404.06236</a>",,2025-12-03 22:39:25
SafeGen: Mitigating Unsafe Content Generation in Text-to-Image Models,"Xinfeng Li, Yuchen Yang, Jiangyi Deng, Chen Yan, Yanjiao Chen, Xiaoyu Ji, Wenyuan Xu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06666"" target=""_blank"">2404.06666</a>",,2025-12-03 22:39:25
Sandwich attack: Multi-language Mixture Adaptive Attack on LLMs,"Bibek Upadhayay, Vahid Behzadan",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.07242"" target=""_blank"">2404.07242</a>",,2025-12-03 22:39:25
"Aggressive or Imperceptible, or Both: Network Pruning Assisted Hybrid Byzantines in Federated Learning","Emre Ozfatura, Kerem Ozfatura, Alptekin Kupcu, Deniz Gunduz",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06230"" target=""_blank"">2404.06230</a>",,2025-12-03 22:39:25
How to Craft Backdoors with Unlabeled Data Alone? (1%),"Yifei Wang, Wenhan Ma, Yisen Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06694"" target=""_blank"">2404.06694</a>","<a href=""https://github.com/PKU-ML/nlb"" target=""_blank"">PKU-ML</a>",2025-12-03 22:39:25
Certified PEFTSmoothing: Parameter-Efficient Fine-Tuning with Randomized Smoothing,"Chengyan Fu, Wenjie Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05350"" target=""_blank"">2404.05350</a>",,2025-12-03 22:39:25
LRR: Language-Driven Resamplable Continuous Representation against Adversarial Tracking Attacks,"Jianlang Chen, Xuhong Ren, Qing Guo, Felix Juefei-Xu, Di Lin, Wei Feng, Lei Ma, Jianjun Zhao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06247"" target=""_blank"">2404.06247</a>",,2025-12-03 22:39:25
David and Goliath: An Empirical Evaluation of Attacks and Defenses for QNNs at the Deep Edge,"Miguel Costa, Sandro Pinto",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05688"" target=""_blank"">2404.05688</a>",,2025-12-03 22:39:25
BruSLeAttack: A Query-Efficient Score-Based Black-Box Sparse Adversarial Attack,"Viet Quoc Vo, Ehsan Abbasnejad, Damith C. Ranasinghe",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05311"" target=""_blank"">2404.05311</a>",,2025-12-03 22:39:25
Case Study: Neural Network Malware Detection Verification for Feature and Image Datasets,"Preston K. Robinette, Diego Manzanas Lopez, Serena Serbinowska, Kevin Leach, Taylor T. Johnson",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05703"" target=""_blank"">2404.05703</a>",,2025-12-03 22:39:25
SemEval-2024 Task 2: Safe Biomedical Natural Language Inference for Clinical Trials,"Mael Jullien, Marco Valentino, André Freitas",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04963"" target=""_blank"">2404.04963</a>",,2025-12-03 22:39:25
Out-of-Distribution Data: An Acquaintance of Adversarial Examples -- A Survey,"Naveen Karunanayake, Ravin Gunawardena, Suranga Seneviratne, Sanjay Chawla",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05219"" target=""_blank"">2404.05219</a>",,2025-12-03 22:39:25
Quantum Adversarial Learning for Kernel Methods,"Giuseppe Montalbano, Leonardo Banchi",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05824"" target=""_blank"">2404.05824</a>",,2025-12-03 22:39:25
Investigating the Impact of Quantization on Adversarial Robustness,"Qun Li, Yuan Meng, Chen Tang, Jiacheng Jiang, Zhi Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05639"" target=""_blank"">2404.05639</a>",,2025-12-03 22:39:25
SoK: On Gradient Leakage in Federated Learning,"Jiacheng Du, Jiahui Hu, Zhibo Wang, Peng Sun, Neil Zhenqiang Gong, Kui Ren, Chun Chen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05403"" target=""_blank"">2404.05403</a>",,2025-12-03 22:39:25
SphereHead: Stable 3D Full-head Synthesis with Spherical Tri-plane Representation,"Heyuan Li, Ce Chen, Tianhao Shi, Yuda Qiu, Sizhe An, Guanying Chen, Xiaoguang Han",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05680"" target=""_blank"">2404.05680</a>","<a href=""https://lhyfst.github.io/spherehead"" target=""_blank"">lhyfst.github.io</a>",2025-12-03 22:39:25
Semantic Stealth: Adversarial Text Attacks on NLP Using Several Methods,"Roopkatha Dey, Aivy Debnath, Sayak Kumar Dutta, Kaustav Ghosh, Arijit Mitra, Arghya Roy Chowdhury, Jaydip Sen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05159"" target=""_blank"">2404.05159</a>",,2025-12-03 22:39:25
Enabling Privacy-Preserving Cyber Threat Detection with Federated Learning,"Yu Bi, Yekai Li, Xuan Feng, Xianghang Mi",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05130"" target=""_blank"">2404.05130</a>",,2025-12-03 22:39:25
How much reliable is ChatGPT's prediction on Information Extraction under Input Perturbations? (5%),"Ishani Mondal, Abhilasha Sancheti",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.05088"" target=""_blank"">2404.05088</a>",,2025-12-03 22:39:25
Towards Building a Robust Toxicity Predictor,"Dmitriy Bespalov, Sourav Bhabesh, Yi Xiang, Liutong Zhou, Yanjun Qi",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08690"" target=""_blank"">2404.08690</a>",,2025-12-03 22:39:25
CANEDERLI: On The Impact of Adversarial Training and Transferability on CAN Intrusion Detection Systems,"Francesco Marchiori, Mauro Conti",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04648"" target=""_blank"">2404.04648</a>",,2025-12-03 22:39:25
Learning Minimal NAP Specifications for Neural Network Verification,"Chuqin Geng, Zhaoyue Wang, Haolin Ye, Saifei Liao, Xujie Si",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04662"" target=""_blank"">2404.04662</a>",,2025-12-03 22:39:25
Data Poisoning Attacks on Off-Policy Policy Evaluation Methods,"Elita Lobo, Harvineet Singh, Marek Petrik, Cynthia Rudin, Himabindu Lakkaraju",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04714"" target=""_blank"">2404.04714</a>",,2025-12-03 22:39:25
Goal-guided Generative Prompt Injection Attack on Large Language Models,"Chong Zhang, Mingyu Jin, Qinkai Yu, Chengzhi Liu, Haochen Xue, Xiaobo Jin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.07234"" target=""_blank"">2404.07234</a>",,2025-12-03 22:39:25
On adversarial training and the 1 Nearest Neighbor classifier,"Amir Hagai, Yair Weiss",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06313"" target=""_blank"">2404.06313</a>","<a href=""https://github.com/amirhagai/On-Adversarial-Training-And-The-1-Nearest-Neighbor-Classifier"" target=""_blank"">amirhagai</a>",2025-12-03 22:39:25
Persistent Classification: A New Approach to Stability of Data and Adversarial Examples,"Brian Bell, Michael Geyer, David Glickenstein, Keaton Hamm, Carlos Scheidegger, Amanda Fernandez, Juston Moore",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08069"" target=""_blank"">2404.08069</a>",,2025-12-03 22:39:25
TrajPRed: Trajectory Prediction with Region-based Relation Learning,"Chen Zhou, Ghassan AlRegib, Armin Parchami, Kunjan Singh",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06971"" target=""_blank"">2404.06971</a>",,2025-12-03 22:39:25
Simpler becomes Harder: Do LLMs Exhibit a Coherent Behavior on Simplified Corpora? (2%),"Miriam Anschütz, Edoardo Mosca, Georg Groh",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06838"" target=""_blank"">2404.06838</a>",,2025-12-03 22:39:25
FaceCat: Enhancing Face Recognition Security with a Unified Generative Model Framework,"Jiawei Chen, Xiao Yang, Yinpeng Dong, Hang Su, Jianteng Peng, Zhaoxia Yin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09193"" target=""_blank"">2404.09193</a>",,2025-12-03 22:39:25
Stability and Generalization in Free Adversarial Training,"Xiwei Cheng, Kexin Fu, Farzan Farnia",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08980"" target=""_blank"">2404.08980</a>","<a href=""https://github.com/Xiwei-Cheng/Stability_FreeAT"" target=""_blank"">Xiwei-Cheng</a>",2025-12-03 22:39:25
Exploiting Sequence Number Leakage: TCP Hijacking in NAT-Enabled Wi-Fi Networks,"Yuxiang Yang, Xuewei Feng, Qi Li, Kun Sun, Ziqiang Wang, Ke Xu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04601"" target=""_blank"">2404.04601</a>",,2025-12-03 22:39:25
Proof-of-Learning with Incentive Security,"Zishuo Zhao, Zhixuan Fang, Xuechao Wang, Xi Chen, Yuan Zhou",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09005"" target=""_blank"">2404.09005</a>",,2025-12-03 22:39:25
PASA: Attack Agnostic Unsupervised Adversarial Detection using Prediction & Attribution Sensitivity Analysis,"Dipkamal Bhusal, Md Tanvirul Alam, Monish K. Veerabhadran, Michael Clifford, Sara Rampazzi, Nidhi Rastogi",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10789"" target=""_blank"">2404.10789</a>",,2025-12-03 22:39:25
Counterfactual Explanations for Face Forgery Detection via Adversarial Removal of Artifacts,"Yang Li, Songlin Yang, Wei Wang, Ziwen He, Bo Peng, Jing Dong",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08341"" target=""_blank"">2404.08341</a>",,2025-12-03 22:39:25
Struggle with Adversarial Defense? Try Diffusion,"Yujie Li, Yanbin Wang, Haitao Xu, Bin Liu, Jianguo Sun, Zhenhao Guo, Wenrui Ma",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08273"" target=""_blank"">2404.08273</a>",,2025-12-03 22:39:25
Multimodal Attack Detection for Action Recognition Models,"Furkan Mumcu, Yasin Yilmaz",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10790"" target=""_blank"">2404.10790</a>",,2025-12-03 22:39:25
A Survey of Neural Network Robustness Assessment in Image Recognition,"Jie Wang, Jun Ai, Minyan Lu, Haoran Su, Dan Yu, Yutao Zhang, Junda Zhu, Jingyu Liu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08285"" target=""_blank"">2404.08285</a>",,2025-12-03 22:39:25
Practical Region-level Attack against Segment Anything Models,"Yifan Shen, Zhengyuan Li, Gang Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08255"" target=""_blank"">2404.08255</a>",,2025-12-03 22:39:25
FCert: Certifiably Robust Few-Shot Classification in the Era of Foundation Models,"Yanting Wang, Wei Zou, Jinyuan Jia",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08631"" target=""_blank"">2404.08631</a>",,2025-12-03 22:39:25
Mitigating Cascading Effects in Large Adversarial Graph Environments,"James D. Cunningham, Conrad S. Tucker",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14418"" target=""_blank"">2404.14418</a>",,2025-12-03 22:39:25
On the Robustness of Language Guidance for Low-Level Vision Tasks: Findings from Depth Estimation,"Agneet Chatterjee, Tejas Gokhale, Chitta Baral, Yezhou Yang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08540"" target=""_blank"">2404.08540</a>",,2025-12-03 22:39:25
Empowering Malware Detection Efficiency within Processing-in-Memory Architecture,"Sreenitha Kasarapu, Sathwika Bavikadi, Sai Manoj Pudukotai Dinakarrao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08818"" target=""_blank"">2404.08818</a>",,2025-12-03 22:39:25
Eliminating Catastrophic Overfitting Via Abnormal Adversarial Examples Regularization,"Runqi Lin, Chaojian Yu, Tongliang Liu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08154"" target=""_blank"">2404.08154</a>",,2025-12-03 22:39:25
Backdoor Contrastive Learning via Bi-level Trigger Optimization,"Weiyu Sun, Xinyu Zhang, Hao Lu, Yingcong Chen, Ting Wang, Jinghui Chen, Lu Lin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.07863"" target=""_blank"">2404.07863</a>","<a href=""https://github.com/SWY666/SSL-backdoor-BLTO"" target=""_blank"">SWY666</a>",2025-12-03 22:39:25
Adversarial Robustness of Distilled and Pruned Deep Learning-based Wireless Classifiers,"Nayan Moni Baishya, B. R. Manoj",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15344"" target=""_blank"">2404.15344</a>",,2025-12-03 22:39:25
AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs,"Zeyi Liao, Huan Sun",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.07921"" target=""_blank"">2404.07921</a>",,2025-12-03 22:39:25
LeapFrog: The Rowhammer Instruction Skip Attack,"Andrew Adiletta, M. Caner Tol, Kemal Derya, Berk Sunar, Saad Islam",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.07878"" target=""_blank"">2404.07878</a>",,2025-12-03 22:39:25
"Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies","Zichao Li, Cihang Xie, Ekin Dogus Cubuk",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.08197"" target=""_blank"">2404.08197</a>",,2025-12-03 22:39:25
Logit Calibration and Feature Contrast for Robust Federated Learning on Non-IID Data,"Yu Qiao, Chaoning Zhang, Apurba Adhikary, Choong Seon Hong",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06776"" target=""_blank"">2404.06776</a>",,2025-12-03 22:39:25
Lost in Translation: Modern Neural Networks Still Struggle With Small Realistic Image Transformations,"Ofir Shifman, Yair Weiss",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.07153"" target=""_blank"">2404.07153</a>",,2025-12-03 22:39:25
Adversarial purification for no-reference image-quality metrics: applicability study and new methods,"Aleksandr Gushchin, Anna Chistyakova, Vladislav Minashkin, Anastasia Antsiferova, Dmitriy Vatolin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.06957"" target=""_blank"">2404.06957</a>",,2025-12-03 22:39:25
Structured Gradient-based Interpretations via Norm-Regularized Adversarial Training,"Shizhan Gong, Qi Dou, Farzan Farnia",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04647"" target=""_blank"">2404.04647</a>",,2025-12-03 22:39:25
The Double-Edged Sword of Input Perturbations to Robust Accurate Fairness,"Xuran Li, Peng Wu, Yanting Chen, Xingjun Ma, Zhen Zhang, Kaixiang Dong",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01356"" target=""_blank"">2404.01356</a>",,2025-12-03 22:39:25
"Evaluating Adversarial Robustness: A Comparison Of FGSM, Carlini-Wagner Attacks, And The Role of Distillation as Defense Mechanism","Trilokesh Ranjan Sarkar, Nilanjan Das, Pralay Sankar Maitra, Bijoy Some, Ritwik Saha, Orijita Adhikary, Bishal Bose, Jaydip Sen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04245"" target=""_blank"">2404.04245</a>",,2025-12-03 22:39:25
Exploring Backdoor Vulnerabilities of Chat Models,"Yunzhuo Hao, Wenkai Yang, Yankai Lin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02406"" target=""_blank"">2404.02406</a>",,2025-12-03 22:39:25
Multi-granular Adversarial Attacks against Black-box Neural Ranking Models,"Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Rijke Maarten de, Yixing Fan, Xueqi Cheng",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01574"" target=""_blank"">2404.01574</a>",,2025-12-03 22:39:25
BadPart: Unified Black-box Adversarial Patch Attacks against Pixel-wise Regression Tasks,"Zhiyuan Cheng, Zhaoyi Liu, Tengda Guo, Shiwei Feng, Dongfang Liu, Mingjie Tang, Xiangyu Zhang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00924"" target=""_blank"">2404.00924</a>",,2025-12-03 22:39:25
UFID: A Unified Framework for Input-level Backdoor Detection on Diffusion Models,"Zihan Guan, Mengxuan Hu, Sheng Li, Anil Vullikanti",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01101"" target=""_blank"">2404.01101</a>","<a href=""https://github.com/GuanZihan/official_UFID"" target=""_blank"">GuanZihan</a>",2025-12-03 22:39:25
Poisoning Decentralized Collaborative Recommender System and Its Countermeasures,"Ruiqi Zheng, Liang Qu, Tong Chen, Kai Zheng, Yuhui Shi, Hongzhi Yin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01177"" target=""_blank"">2404.01177</a>",,2025-12-03 22:39:25
Can Biases in ImageNet Models Explain Generalization? (10%),"Paul Gavrikov, Janis Keuper",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01509"" target=""_blank"">2404.01509</a>","<a href=""https://github.com/paulgavrikov/biases_vs_generalization"" target=""_blank"">paulgavrikov</a>",2025-12-03 22:39:25
Privacy Backdoors: Enhancing Membership Inference through Poisoning Pre-trained Models,"Yuxin Wen, Leo Marchyok, Sanghyun Hong, Jonas Geiping, Tom Goldstein, Nicholas Carlini",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01231"" target=""_blank"">2404.01231</a>",,2025-12-03 22:39:25
An incremental hybrid adaptive network-based IDS in Software Defined Networks to detect stealth attacks,Abdullah H Alqahtani,arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01109"" target=""_blank"">2404.01109</a>",,2025-12-03 22:39:25
PID Control-Based Self-Healing to Improve the Robustness of Large Language Models,"Zhuotong Chen, Zihu Wang, Yifan Yang, Qianxiao Li, Zheng Zhang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00828"" target=""_blank"">2404.00828</a>","<a href=""https://github.com/zhuotongchen/PID-Control-Based-Self-Healing-to-Improve-the-Robustness-of-Large-Language-Models"" target=""_blank"">zhuotongchen</a>",2025-12-03 22:39:25
Machine Learning Robustness: A Primer,"Houssem Ben Braiek, Foutse Khomh",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00897"" target=""_blank"">2404.00897</a>",,2025-12-03 22:39:25
STBA: Towards Evaluating the Robustness of DNNs for Query-Limited Black-box Scenario,"Renyang Liu, Kwok-Yan Lam, Wei Zhou, Sixing Wu, Jun Zhao, Dongting Hu, Mingming Gong",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00362"" target=""_blank"">2404.00362</a>",,2025-12-03 22:39:25
Embodied Active Defense: Leveraging Recurrent Feedback to Counter Adversarial Patches,"Lingxuan Wu, Xiao Yang, Yinpeng Dong, Liuwei Xie, Hang Su, Jun Zhu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00540"" target=""_blank"">2404.00540</a>",,2025-12-03 22:39:25
Shortcuts Arising from Contrast: Effective and Covert Clean-Label Attacks in Prompt-Based Learning,"Xiaopeng Xie, Ming Yan, Xiwen Zhou, Chenlong Zhao, Suli Wang, Yong Zhang, Joey Tianyi Zhou",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00461"" target=""_blank"">2404.00461</a>",,2025-12-03 22:39:25
TG-NAS: Generalizable Zero-Cost Proxies with Operator Description Embedding and Graph Learning for Efficient Neural Architecture Search,"Ye Qiao, Jingcheng Li, Haocheng Xu, Sitao Huang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00271"" target=""_blank"">2404.00271</a>",,2025-12-03 22:39:25
On Inherent Adversarial Robustness of Active Vision Systems,"Amitangshu Mukherjee, Timur Ibrayev, Kaushik Roy",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00185"" target=""_blank"">2404.00185</a>",,2025-12-03 22:39:25
Deepfake Sentry: Harnessing Ensemble Intelligence for Resilient Detection and Generalisation,"Liviu-Daniel University ""Politehnica"" of Bucharest, Romania Ştefan, Dan-Cristian University ""Politehnica"" of Bucharest, Romania Stanciu, Mihai University ""Politehnica"" of Bucharest, Romania Dogariu, Mihai Gabriel University ""Politehnica"" of Bucharest, Romania Constantin, Andrei Cosmin University ""Politehnica"" of Bucharest, Romania Jitaru, Bogdan University ""Politehnica"" of Bucharest, Romania Ionescu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00114"" target=""_blank"">2404.00114</a>",,2025-12-03 22:39:25
GDA: Generalized Diffusion for Robust Test-time Adaptation,"Yun-Yun Tsai, Fu-Chen Chen, Albert Y. C. Chen, Junfeng Yang, Che-Chun Su, Min Sun, Cheng-Hao Kuo",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00095"" target=""_blank"">2404.00095</a>",,2025-12-03 22:39:25
Efficient Data-Free Model Stealing with Label Diversity,"Yiyong Liu, Rui Wen, Michael Backes, Yang Zhang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00108"" target=""_blank"">2404.00108</a>",,2025-12-03 22:39:25
State-of-the-Art Approaches to Enhancing Privacy Preservation of Machine Learning Datasets: A Survey,Chaoyu Zhang,arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16847"" target=""_blank"">2404.16847</a>",,2025-12-03 22:39:25
A Backdoor Approach with Inverted Labels Using Dirty Label-Flipping Attacks,Orson Mengara,arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00076"" target=""_blank"">2404.00076</a>",,2025-12-03 22:39:25
JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models,"Patrick Chao, Edoardo Debenedetti, Alexander Robey, Maksym Andriushchenko, Francesco Croce, Vikash Sehwag, Edgar Dobriban, Nicolas Flammarion, George J. Pappas, Florian Tramer, Hamed Hassani, Eric Wong",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01318"" target=""_blank"">2404.01318</a>","<a href=""https://github.com/JailbreakBench/jailbreakbench"" target=""_blank"">JailbreakBench</a>",2025-12-03 22:39:25
EdgeLeakage: Membership Information Leakage in Distributed Edge Intelligence Systems,"Kongyang Chen, Yi Lin, Hui Luo, Bing Mi, Yatie Xiao, Chao Ma, Jorge Sá Silva",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16851"" target=""_blank"">2404.16851</a>",,2025-12-03 22:39:25
Watermark-embedded Adversarial Examples for Copyright Protection against Diffusion Models,"Peifei Zhu, Tsubasa Takahashi, Hirokatsu Kataoka",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09401"" target=""_blank"">2404.09401</a>",,2025-12-03 22:39:25
A novel interface for adversarial trivia question-writing,Jason Liu,arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.00011"" target=""_blank"">2404.00011</a>",,2025-12-03 22:39:25
CAPE: CAM as a Probabilistic Ensemble for Enhanced DNN Interpretation,"Townim Faisal Chowdhury, Kewen Liao, Vu Minh Hieu Phan, Minh-Son To, Yutong Xie, Kevin Hung, David Ross, Anton van den Hengel, Johan W. Verjans, Zhibin Liao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02388"" target=""_blank"">2404.02388</a>","<a href=""https://github.com/AIML-MED/CAPE"" target=""_blank"">AIML-MED</a>",2025-12-03 22:39:25
Designing a Photonic Physically Unclonable Function Having Resilience to Machine Learning Attacks,"Elena R. Henderson, Jessie M. Henderson, Hiva Shahoei, William V. Oxford, Eric C. Larson, Duncan L. MacFarlane, Mitchell A. Thornton",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02440"" target=""_blank"">2404.02440</a>",,2025-12-03 22:39:25
Reliable Feature Selection for Adversarially Robust Cyber-Attack Detection,"João Vitorino, Miguel Silva, Eva Maia, Isabel Praça",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04188"" target=""_blank"">2404.04188</a>",,2025-12-03 22:39:25
Towards Robust 3D Pose Transfer with Adversarial Learning,"Haoyu Chen, Hao Tang, Ehsan Adeli, Guoying Zhao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02242"" target=""_blank"">2404.02242</a>",,2025-12-03 22:39:25
Compositional Estimation of Lipschitz Constants for Deep Neural Networks,"Yuezhu Xu, S. Sivaranjani",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04375"" target=""_blank"">2404.04375</a>",,2025-12-03 22:39:25
Precision Guided Approach to Mitigate Data Poisoning Attacks in Federated Learning,"K Naveen Kumar, C Krishna Mohan, Aravind Machiry",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.04139"" target=""_blank"">2404.04139</a>",,2025-12-03 22:39:25
Meta Invariance Defense Towards Generalizable Robustness to Unknown Adversarial Attacks,"Lei Zhang, Yuhang Zhou, Yi Yang, Xinbo Gao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.03340"" target=""_blank"">2404.03340</a>",,2025-12-03 22:39:25
FACTUAL: A Novel Framework for Contrastive Learning Based Robust SAR Image Classification,"Xu Wang, Tian Ye, Rajgopal Kannan, Viktor Prasanna",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.03225"" target=""_blank"">2404.03225</a>",,2025-12-03 22:39:25
Learn What You Want to Unlearn: Unlearning Inversion Attacks against Machine Unlearning,"Hongsheng Hu, Shuo Wang, Tian Dong, Minhui Xue",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.03233"" target=""_blank"">2404.03233</a>",,2025-12-03 22:39:25
Knowledge Distillation-Based Model Extraction Attack using GAN-based Private Counterfactual Explanations,"Fatima Ezzeddine, Omran Ayoub, Silvia Giordano",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.03348"" target=""_blank"">2404.03348</a>",,2025-12-03 22:39:25
Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak Attacks? (2%),"Shuo Chen, Zhen Han, Bailan He, Zifeng Ding, Wenqian Yu, Philip Torr, Volker Tresp, Jindong Gu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.03411"" target=""_blank"">2404.03411</a>","<a href=""https://github.com/chenxshuo/RedTeamingGPT4V"" target=""_blank"">chenxshuo</a>",2025-12-03 22:39:25
Adversarial Attacks and Dimensionality in Text Classifiers,"Nandish Chattopadhyay, Atreya Goswami, Anupam Chattopadhyay",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02660"" target=""_blank"">2404.02660</a>",,2025-12-03 22:39:25
Unsegment Anything by Simulating Deformation,"Jiahao Lu, Xingyi Yang, Xinchao Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02585"" target=""_blank"">2404.02585</a>","<a href=""https://github.com/jiahaolu97/anything-unsegmentable"" target=""_blank"">jiahaolu97</a>",2025-12-03 22:39:25
"""Are Adversarial Phishing Webpages a Threat in Reality?"" Understanding the Users' Perception of Adversarial Webpages","Ying Yuan, Qingying Hao, Giovanni Apruzzese, Mauro Conti, Gang Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02832"" target=""_blank"">2404.02832</a>",,2025-12-03 22:39:25
JailBreakV-28K: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks,"Weidi Luo, Siyuan Ma, Xiaogeng Liu, Xiaoyu Guo, Chaowei Xiao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.03027"" target=""_blank"">2404.03027</a>",,2025-12-03 22:39:25
Learn to Disguise: Avoid Refusal Responses in LLM's Defense via a Multi-agent Attacker-Disguiser Game,"Qianqiao Xu, Zhiliang Tian, Hongyan Wu, Zhen Huang, Yiping Song, Feng Liu, Dongsheng Li",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02532"" target=""_blank"">2404.02532</a>",,2025-12-03 22:39:25
A Unified Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability,"Jie Zhu, Jirong Zha, Ding Li, Leye Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02462"" target=""_blank"">2404.02462</a>","<a href=""https://github.com/JiePKU/PartCrop"" target=""_blank"">JiePKU</a>",2025-12-03 22:39:25
Steganographic Passport: An Owner and User Verifiable Credential for Deep Model IP Protection Without Retraining,"Qi Cui, Ruohan Meng, Chaohui Xu, Chip-Hong Chang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02889"" target=""_blank"">2404.02889</a>",,2025-12-03 22:39:25
Humanizing Machine-Generated Content: Evading AI-Text Detection through Adversarial Attack,"Ying Zhou, Ben He, Le Sun",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01907"" target=""_blank"">2404.01907</a>",,2025-12-03 22:39:25
Patch Synthesis for Property Repair of Deep Neural Networks,"Zhiming Chi, Jianan Ma, Pengfei Yang, Cheng-Chao Huang, Renjue Li, Xiaowei Huang, Lijun Zhang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01642"" target=""_blank"">2404.01642</a>",,2025-12-03 22:39:25
Jailbreaking Prompt Attack: A Controllable Adversarial Attack against Diffusion Models,"Jiachen Ma, Anda Cao, Zhiqing Xiao, Yijiang Li, Jie Zhang, Chao Ye, Junbo Zhao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02928"" target=""_blank"">2404.02928</a>",,2025-12-03 22:39:25
One Noise to Rule Them All: Multi-View Adversarial Attacks with Universal Perturbation,"Mehmet Ergezer, Phat Duong, Christian Green, Tommy Nguyen, Abdurrahman Zeybey",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02287"" target=""_blank"">2404.02287</a>","<a href=""https://github.com/memoatwit/UniversalPerturbation"" target=""_blank"">memoatwit</a>",2025-12-03 22:39:25
Defense without Forgetting: Continual Adversarial Defense with Anisotropic & Isotropic Pseudo Replay,"Yuhang Zhou, Zhongyun Hua",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.01828"" target=""_blank"">2404.01828</a>",,2025-12-03 22:39:25
Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks,"Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02151"" target=""_blank"">2404.02151</a>","<a href=""https://github.com/tml-epfl/llm-adaptive-attacks"" target=""_blank"">tml-epfl</a>",2025-12-03 22:39:25
READ: Improving Relation Extraction from an ADversarial Perspective,"Dawei Li, William Hogan, Jingbo Shang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02931"" target=""_blank"">2404.02931</a>","<a href=""https://github.com/David-Li0406/READ"" target=""_blank"">David-Li0406</a>",2025-12-03 22:39:25
Two Heads are Better than One: Nested PoE for Robust Defense Against Multi-Backdoors,"Victoria Graf, Qin Liu, Muhao Chen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02356"" target=""_blank"">2404.02356</a>",,2025-12-03 22:39:25
Red-Teaming Segment Anything Model,"Krzysztof Jankowski, Bartlomiej Sobieski, Mateusz Kwiatkowski, Jakub Szulc, Michal Janik, Hubert Baniecki, Przemyslaw Biecek",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.02067"" target=""_blank"">2404.02067</a>",,2025-12-03 22:39:25
Adversarial Robustness Limits via Scaling-Law and Human-Alignment Studies,"Brian R. Bartoldson, James Diffenderfer, Konstantinos Parasyris, Bhavya Kailkhura",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09349"" target=""_blank"">2404.09349</a>",,2025-12-03 22:39:25
Towards Robust and Interpretable EMG-based Hand Gesture Recognition using Deep Metric Meta Learning,"Simon Tam, Shriram Tallam Puranam Raghu, Étienne Buteau, Erik Scheme, Mounir Boukadoum, Alexandre Campeau-Lecours, Benoit Gosselin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15360"" target=""_blank"">2404.15360</a>",,2025-12-03 22:39:25
Counteracting Concept Drift by Learning with Future Malware Predictions,"Branislav Bosansky, Lada Hospodkova, Michal Najman, Maria Rigaki, Elnaz Babayeva, Viliam Lisy",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09352"" target=""_blank"">2404.09352</a>",,2025-12-03 22:39:25
An Empirical Study of Aegis,"Daniel Saragih, Paridhi Goel, Tejas Balaji, Alyssa Li",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15784"" target=""_blank"">2404.15784</a>",,2025-12-03 22:39:25
Adversarial Reweighting with $\alpha$-Power Maximization for Domain Adaptation,"Xiang Gu, Xi Yu, Yan Yang, Jian Sun, Zongben Xu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17275"" target=""_blank"">2404.17275</a>",,2025-12-03 22:39:25
Changing the Training Data Distribution to Reduce Simplicity Bias Improves In-distribution Generalization,"Dang Nguyen, Paymon Haddad, Eric Gan, Baharan Mirzasoleiman",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17768"" target=""_blank"">2404.17768</a>",,2025-12-03 22:39:25
Generating Minimalist Adversarial Perturbations to Test Object-Detection Models: An Adaptive Multi-Metric Evolutionary Search Approach,"Cristopher McIntyre-Garcia, Adrien Heymans, Beril Borali, Won-Sook Lee, Shiva Nejati",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17020"" target=""_blank"">2404.17020</a>",,2025-12-03 22:39:25
PAD: Patch-Agnostic Defense against Adversarial Patch Attacks,"Lihua Jing, Rui Wang, Wenqi Ren, Xin Dong, Cong Zou",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16452"" target=""_blank"">2404.16452</a>","<a href=""https://github.com/Lihua-Jing/PAD"" target=""_blank"">Lihua-Jing</a>",2025-12-03 22:39:25
Robust and Efficient Adversarial Defense in SNNs via Image Purification and Joint Detection,"Weiran Chen, Qi Xu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17092"" target=""_blank"">2404.17092</a>",,2025-12-03 22:39:25
Don't Say No: Jailbreaking LLM by Suppressing Refusal,"Yukai Zhou, Zhijie Huang, Feiyang Lu, Zhan Qin, Wenjie Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16369"" target=""_blank"">2404.16369</a>",,2025-12-03 22:39:25
A Self-Organizing Clustering System for Unsupervised Distribution Shift Detection,"Sebastián Basterrech, Line Clemmensen, Gerardo Rubino",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16656"" target=""_blank"">2404.16656</a>",,2025-12-03 22:39:25
Energy-Latency Manipulation of Multi-modal Large Language Models via Verbose Samples,"Kuofeng Gao, Jindong Gu, Yang Bai, Shu-Tao Xia, Philip Torr, Wei Liu, Zhifeng Li",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16557"" target=""_blank"">2404.16557</a>",,2025-12-03 22:39:25
Talking Nonsense: Probing Large Language Models' Understanding of Adversarial Gibberish Inputs,"Valeriia Cherepanova, James Zou",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17120"" target=""_blank"">2404.17120</a>",,2025-12-03 22:39:25
Steal Now and Attack Later: Evaluating Robustness of Object Detection against Black-box Adversarial Attacks,"Erh-Chung Chen, Pin-Yu Chen, I-Hsin Chung, Che-Rung Lee",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15881"" target=""_blank"">2404.15881</a>",,2025-12-03 22:39:25
An Analysis of Recent Advances in Deepfake Image Detection in an Evolving Threat Landscape,"Sifat Muhammad Abdullah, Aravind Cheruvu, Shravya Kanchi, Taejoong Chung, Peng Gao, Murtuza Jadliwala, Bimal Viswanath",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16212"" target=""_blank"">2404.16212</a>",,2025-12-03 22:39:25
A General Black-box Adversarial Attack on Graph-based Fake News Detectors,"Peican Zhu, Zechen Pan, Yang Liu, Jiwei Tian, Keke Tang, Zhen Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15744"" target=""_blank"">2404.15744</a>",,2025-12-03 22:39:25
Evaluations of Machine Learning Privacy Defenses are Misleading,"Michael Aerni, Jie Zhang, Florian Tramèr",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17399"" target=""_blank"">2404.17399</a>",,2025-12-03 22:39:25
A Comparative Analysis of Adversarial Robustness for Quantum and Classical Machine Learning Models,"Maximilian Wendlinger, Kilian Tscharke, Pascal Debus",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16154"" target=""_blank"">2404.16154</a>",,2025-12-03 22:39:25
MISLEAD: Manipulating Importance of Selected features for Learning Epsilon in Evasion Attack Deception,"Vidit Khazanchi, Pavan Kulkarni, Yuvaraj Govindarajulu, Manojkumar Parmar",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15656"" target=""_blank"">2404.15656</a>",,2025-12-03 22:39:25
Investigating the prompt leakage effect and black-box defenses for multi-turn LLM interactions,"Divyansh Agarwal, Alexander R. Fabbri, Philippe Laban, Ben Risher, Shafiq Joty, Caiming Xiong, Chien-Sheng Wu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16251"" target=""_blank"">2404.16251</a>",,2025-12-03 22:39:25
Investigating Adversarial Trigger Transfer in Large Language Models,"Nicholas Meade, Arkil Patel, Siva Reddy",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16020"" target=""_blank"">2404.16020</a>",,2025-12-03 22:39:25
CLAD: Robust Audio Deepfake Detection Against Manipulation Attacks with Contrastive Learning,"Haolin Wu, Jing Chen, Ruiying Du, Cong Wu, Kun He, Xingcan Shang, Hao Ren, Guowen Xu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15854"" target=""_blank"">2404.15854</a>","<a href=""https://github.com/CLAD23/CLAD"" target=""_blank"">CLAD23</a>",2025-12-03 22:39:25
Security Analysis of WiFi-based Sensing Systems: Threats from Perturbation Attacks,"Hangcheng Cao, Wenbin Huang, Guowen Xu, Xianhao Chen, Ziyang He, Jingyang Hu, Hongbo Jiang, Yuguang Fang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15587"" target=""_blank"">2404.15587</a>",,2025-12-03 22:39:25
Manipulating Recommender Systems: A Survey of Poisoning Attacks and Countermeasures,"Thanh Toan Nguyen, Quoc Viet Hung Nguyen, Thanh Tam Nguyen, Thanh Trung Huynh, Thanh Thi Nguyen, Matthias Weidlich, Hongzhi Yin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14942"" target=""_blank"">2404.14942</a>","<a href=""https://github.com/tamlhp/awesome-recsys-poisoning"" target=""_blank"">tamlhp</a>",2025-12-03 22:39:25
Perturbing Attention Gives You More Bang for the Buck: Subtle Imaging Perturbations That Efficiently Fool Customized Diffusion Models,"Jingyao Xu, Yuetong Lu, Yandong Li, Siyang Lu, Dongdong Wang, Xiang Wei",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15081"" target=""_blank"">2404.15081</a>",,2025-12-03 22:39:25
Talk Too Much: Poisoning Large Language Models under Token Limit,"Jiaming He, Wenbo Jiang, Guanyu Hou, Wenshu Fan, Rui Zhang, Hongwei Li",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14795"" target=""_blank"">2404.14795</a>",,2025-12-03 22:39:25
Leverage Variational Graph Representation For Model Poisoning on Federated Learning,"Kai Li, Xin Yuan, Jingjing Zheng, Wei Ni, Falko Dressler, Abbas Jamalipour",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15042"" target=""_blank"">2404.15042</a>",,2025-12-03 22:39:25
Formal Verification of Graph Convolutional Networks with Uncertain Node Features and Uncertain Graph Structure,"Tobias Ladner, Michael Eichelbeck, Matthias Althoff",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15065"" target=""_blank"">2404.15065</a>",,2025-12-03 22:39:25
Enhancing Privacy and Security of Autonomous UAV Navigation,"Vatsal Aggarwal, Arjun Ramesh Kaushik, Charanjit Jutla, Nalini Ratha",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17225"" target=""_blank"">2404.17225</a>",,2025-12-03 22:39:25
Human-Imperceptible Retrieval Poisoning Attacks in LLM-Powered Applications,"Quan Zhang, Binqi Zeng, Chijin Zhou, Gwihwan Go, Heyuan Shi, Yu Jiang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17196"" target=""_blank"">2404.17196</a>",,2025-12-03 22:39:25
Graph Machine Learning in the Era of Large Language Models (LLMs),"Wenqi Fan, Shijie Wang, Jiani Huang, Zhikai Chen, Yu Song, Wenzhuo Tang, Haitao Mao, Hui Liu, Xiaorui Liu, Dawei Yin, Qing Li",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14928"" target=""_blank"">2404.14928</a>",,2025-12-03 22:39:25
Double Backdoored: Converting Code Large Language Model Backdoors to Traditional Malware via Adversarial Instruction Tuning Attacks,"Md Imran Hossen, Sai Venkatesh Chilukoti, Liqun Shan, Sheng Chen, Yinzhi Cao, Xiali Hei",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.18567"" target=""_blank"">2404.18567</a>",,2025-12-03 22:39:25
Adversarial Consistency and the Uniqueness of the Adversarial Bayes Classifier,Natalie S. Frank,arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17358"" target=""_blank"">2404.17358</a>",,2025-12-03 22:39:25
Revisiting the Adversarial Robustness of Vision Language Models: a Multimodal Perspective,"Wanqi Zhou, Shuanghao Bai, Qibin Zhao, Badong Chen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19287"" target=""_blank"">2404.19287</a>",,2025-12-03 22:39:25
Probing Unlearned Diffusion Models: A Transferable Adversarial Attack Perspective,"Xiaoxuan Han, Songlin Yang, Wei Wang, Yang Li, Jing Dong",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19382"" target=""_blank"">2404.19382</a>",,2025-12-03 22:39:25
AttackBench: Evaluating Gradient-based Attacks for Adversarial Examples,"Antonio Emanuele Cinà, Jérôme Rony, Maura Pintor, Luca Demetrio, Ambra Demontis, Battista Biggio, Ismail Ben Ayed, Fabio Roli",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19460"" target=""_blank"">2404.19460</a>",,2025-12-03 22:39:25
Provably Robust Conformal Prediction with Improved Efficiency,"Ge Yan, Yaniv Romano, Tsui-Wei Weng",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19651"" target=""_blank"">2404.19651</a>","<a href=""https://github.com/Trustworthy-ML-Lab/Provably-Robust-Conformal-Prediction"" target=""_blank"">Trustworthy-ML-Lab</a>",2025-12-03 22:39:25
Consistency and Uncertainty: Identifying Unreliable Responses From Black-Box Vision-Language Models for Selective Visual Question Answering,"Zaid Khan, Yun Fu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10193"" target=""_blank"">2404.10193</a>",,2025-12-03 22:39:25
Transferring Troubles: Cross-Lingual Transferability of Backdoor Attacks in LLMs with Instruction Tuning,"Xuanli He, Jun Wang, Qiongkai Xu, Pasquale Minervini, Pontus Stenetorp, Benjamin I. P. Rubinstein, Trevor Cohn",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19597"" target=""_blank"">2404.19597</a>",,2025-12-03 22:39:25
Let's Focus: Focused Backdoor Attack against Federated Transfer Learning,"Marco Arazzi, Stefanos Koffas, Antonino Nocera, Stjepan Picek",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19420"" target=""_blank"">2404.19420</a>",,2025-12-03 22:39:25
URVFL: Undetectable Data Reconstruction Attack on Vertical Federated Learning,"Duanyi Yao, Songze Li, Xueluan Gong, Sizai Hou, Gaoning Pan",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19582"" target=""_blank"">2404.19582</a>","<a href=""https://github.com/duanyiyao/URVFL"" target=""_blank"">duanyiyao</a>",2025-12-03 22:39:25
Physical Backdoor: Towards Temperature-based Backdoor Attacks in the Physical World,"Wen Yin, Jian Lou, Pan Zhou, Yulai Xie, Dan Feng, Yuhua Sun, Tailai Zhang, Lichao Sun",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19417"" target=""_blank"">2404.19417</a>",,2025-12-03 22:39:25
A Systematic Evaluation of Adversarial Attacks against Speech Emotion Recognition Models,"Nicolas Facchinetti, Federico Simonetta, Stavros Ntalampiras",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.18514"" target=""_blank"">2404.18514</a>",,2025-12-03 22:39:25
Certification of Speaker Recognition Models to Additive Perturbations,"Dmitrii Korzh, Elvir Karimov, Mikhail Pautov, Oleg Y. Rogov, Ivan Oseledets",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.18791"" target=""_blank"">2404.18791</a>",,2025-12-03 22:39:25
Adversarial Examples: Generation Proposal in the Context of Facial Recognition Systems,"Marina Fuster, Ignacio Vidaurreta",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17760"" target=""_blank"">2404.17760</a>",,2025-12-03 22:39:25
Espresso: Robust Concept Filtering in Text-to-Image Models,"Anudeep Das, Vasisht Duddu, Rui Zhang, N. Asokan",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19227"" target=""_blank"">2404.19227</a>",,2025-12-03 22:39:25
Why You Should Not Trust Interpretations in Machine Learning: Adversarial Attacks on Partial Dependence Plots,"Xi Xin, Giles Hooker, Fei Huang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.18702"" target=""_blank"">2404.18702</a>",,2025-12-03 22:39:25
"Machine Learning for Windows Malware Detection and Classification: Methods, Challenges and Ongoing Research",Daniel Gibert,arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.18541"" target=""_blank"">2404.18541</a>",,2025-12-03 22:39:25
Towards Quantitative Evaluation of Explainable AI Methods for Deepfake Detection,"Konstantinos Tsigos, Evlampios Apostolidis, Spyridon Baxevanakis, Symeon Papadopoulos, Vasileios Mezaris",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.18649"" target=""_blank"">2404.18649</a>",,2025-12-03 22:39:25
Harmonic Machine Learning Models are Robust,"Nicholas S. Kersting, Yi Li, Aman Mohanty, Oyindamola Obisesan, Raphael Okochu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.18825"" target=""_blank"">2404.18825</a>",,2025-12-03 22:39:25
Enhancing IoT Security: A Novel Feature Engineering Approach for ML-Based Intrusion Detection Systems,"Afsaneh Mahanipour, Hana Khamfroush",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19114"" target=""_blank"">2404.19114</a>",,2025-12-03 22:39:25
Towards Robust Recommendation: A Review and an Adversarial Robustness Evaluation Library,"Lei Cheng, Xiaowen Huang, Jitao Sang, Jian Yu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17844"" target=""_blank"">2404.17844</a>","<a href=""https://github.com/chengleileilei/ShillingREC"" target=""_blank"">chengleileilei</a>",2025-12-03 22:39:25
Privacy-Preserving Aggregation for Decentralized Learning with Byzantine-Robustness,"Ali Reza Ghavamipour, Benjamin Zi Hao Zhao, Oguzhan Ersoy, Fatih Turkmen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17970"" target=""_blank"">2404.17970</a>",,2025-12-03 22:39:25
Bounding the Expected Robustness of Graph Neural Networks Subject to Node Feature Attacks,"Yassine Abbahaddou, Sofiane Ennadir, Johannes F. Lutzeyer, Michalis Vazirgiannis, Henrik Boström",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17947"" target=""_blank"">2404.17947</a>","<a href=""https://github.com/Sennadir/GCORN"" target=""_blank"">Sennadir</a>",2025-12-03 22:39:25
Are Watermarks Bugs for Deepfake Detectors? Rethinking Proactive Forensics,"Xiaoshuai Wu, Xin Liao, Bo Ou, Yuling Liu, Zheng Qin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.17867"" target=""_blank"">2404.17867</a>",,2025-12-03 22:39:25
Attacking Bayes: On the Adversarial Robustness of Bayesian Neural Networks,"Yunzhen Feng, Tim G. J. Rudner, Nikolaos Tsilivis, Julia Kempe",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19640"" target=""_blank"">2404.19640</a>",,2025-12-03 22:39:25
Does It Make Sense to Explain a Black Box With Another Black Box? (1%),"Julien Delaunay, Luis Galárraga, Christine Largouët",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14943"" target=""_blank"">2404.14943</a>",,2025-12-03 22:39:25
Causal Perception Inspired Representation Learning for Trustworthy Image Quality Assessment,"Lei Wang, Desen Yuan",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.19567"" target=""_blank"">2404.19567</a>",,2025-12-03 22:39:25
Towards Understanding the Robustness of Diffusion-Based Purification: A Stochastic Perspective,"Yiming Liu, Kezhao Liu, Yao Xiao, Ziyi Dong, Xiaogang Xu, Pengxu Wei, Liang Lin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14309"" target=""_blank"">2404.14309</a>",,2025-12-03 22:39:25
Model-Based Counterfactual Explanations Incorporating Feature Space Attributes for Tabular Data,"Yuta Sumiya, Hayaru shouno",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13224"" target=""_blank"">2404.13224</a>","<a href=""https://github.com/sumugit/FastDCFlow"" target=""_blank"">sumugit</a>",2025-12-03 22:39:25
"Fortify the Guardian, Not the Treasure: Resilient Adversarial Detectors","Raz Lapid, Almog Dubin, Moshe Sipper",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12120"" target=""_blank"">2404.12120</a>",,2025-12-03 22:39:25
Advancing the Robustness of Large Language Models through Self-Denoised Smoothing,"Jiabao Ji, Bairu Hou, Zhen Zhang, Guanhua Zhang, Wenqi Fan, Qing Li, Yang Zhang, Gaowen Liu, Sijia Liu, Shiyu Chang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12274"" target=""_blank"">2404.12274</a>","<a href=""https://github.com/UCSB-NLP-Chang/SelfDenoise"" target=""_blank"">UCSB-NLP-Chang</a>",2025-12-03 22:39:25
SA-Attack: Speed-adaptive stealthy adversarial attack on trajectory prediction,"Huilin Yin, Jiaxiang Li, Pengju Zhen, Jun Yan",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12612"" target=""_blank"">2404.12612</a>","<a href=""https://github.com/eclipse-bot/SA-Attack"" target=""_blank"">eclipse-bot</a>",2025-12-03 22:39:25
Enhance Robustness of Language Models Against Variation Attack through Graph Integration,"Zi Xiong, Lizhi Qing, Yangyang Kang, Jiawei Liu, Hongsong Li, Changlong Sun, Xiaozhong Liu, Wei Lu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12014"" target=""_blank"">2404.12014</a>",,2025-12-03 22:39:25
Uncovering Safety Risks of Large Language Models through Concept Activation Vector,"Zhihao Xu, Ruixuan Huang, Changyu Chen, Shuai Wang, Xiting Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12038"" target=""_blank"">2404.12038</a>",,2025-12-03 22:39:25
Proteus: Preserving Model Confidentiality during Graph Optimizations,"Yubo Gao, Maryam Haghifam, Christina Giannoula, Renbo Tu, Gennady Pekhimenko, Nandita Vijaykumar",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12512"" target=""_blank"">2404.12512</a>",,2025-12-03 22:39:25
Omniview-Tuning: Boosting Viewpoint Invariance of Vision-Language Pre-training Models,"Shouwei Ruan, Yinpeng Dong, Hanqing Liu, Yao Huang, Hang Su, Xingxing Wei",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12139"" target=""_blank"">2404.12139</a>",,2025-12-03 22:39:25
"Is There No Such Thing as a Bad Question? H4R: HalluciBot For Ratiocination, Rewriting, Ranking, and Routing","William Watson, Nicole Cho, Nishan Srishankar",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12535"" target=""_blank"">2404.12535</a>",,2025-12-03 22:39:25
GenFighter: A Generative and Evolutive Textual Attack Removal,"Md Athikul Islam, Edoardo Serra, Sushil Jajodia",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.11538"" target=""_blank"">2404.11538</a>",,2025-12-03 22:39:25
Utilizing Adversarial Examples for Bias Mitigation and Accuracy Enhancement,"Pushkar Shukla, Dhruv Srikanth, Lee Cohen, Matthew Turk",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.11819"" target=""_blank"">2404.11819</a>",,2025-12-03 22:39:25
Exploring DNN Robustness Against Adversarial Attacks Using Approximate Multipliers,"Mohammad Javad Askarizadeh, Ebrahim Farahmand, Jorge Castro-Godinez, Ali Mahani, Laura Cabrera-Quiros, Carlos Salazar-Garcia",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.11665"" target=""_blank"">2404.11665</a>",,2025-12-03 22:39:25
Exploring the Transferability of Visual Prompting for Multimodal Large Language Models,"Yichi Zhang, Yinpeng Dong, Siyuan Zhang, Tianzan Min, Hang Su, Jun Zhu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.11207"" target=""_blank"">2404.11207</a>",,2025-12-03 22:39:25
Toward Understanding the Disagreement Problem in Neural Network Feature Attribution,"Niklas Koenen, Marvin N. Wright",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.11330"" target=""_blank"">2404.11330</a>",,2025-12-03 22:39:25
Detector Collapse: Backdooring Object Detection to Catastrophic Overload or Blindness,"Hangtao Zhang, Shengshan Hu, Yichen Wang, Leo Yu Zhang, Ziqi Zhou, Xianlong Wang, Yanjun Zhang, Chao Chen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.11357"" target=""_blank"">2404.11357</a>",,2025-12-03 22:39:25
Efficiently Adversarial Examples Generation for Visual-Language Models under Targeted Transfer Scenarios using Diffusion Models,"Qi Guo, Shanmin Pang, Xiaojun Jia, Qing Guo",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10335"" target=""_blank"">2404.10335</a>",,2025-12-03 22:39:25
Adversarial Identity Injection for Semantic Face Image Synthesis,"Giuseppe Tarollo, Tomaso Fontanini, Claudio Ferrari, Guido Borghi, Andrea Prati",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10408"" target=""_blank"">2404.10408</a>",,2025-12-03 22:39:25
Ti-Patch: Tiled Physical Adversarial Patch for no-reference video quality metrics,"Victoria Leonenkova, Ekaterina Shumitskaya, Anastasia Antsiferova, Dmitriy Vatolin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09961"" target=""_blank"">2404.09961</a>",,2025-12-03 22:39:25
Robust Noisy Label Learning via Two-Stream Sample Distillation,"Sihan Bai, Sanping Zhou, Zheng Qin, Le Wang, Nanning Zheng",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10499"" target=""_blank"">2404.10499</a>",,2025-12-03 22:39:25
Improving Weakly-Supervised Object Localization Using Adversarial Erasing and Pseudo Label,"Byeongkeun Kang, Sinhae Cha, Yeejin Lee",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09475"" target=""_blank"">2404.09475</a>",,2025-12-03 22:39:25
Black-box Adversarial Transferability: An Empirical Study in Cybersecurity Perspective,"Khushnaseeb Roshan, Aasim Zafar",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10796"" target=""_blank"">2404.10796</a>",,2025-12-03 22:39:25
Enhancing Code Vulnerability Detection via Vulnerability-Preserving Data Augmentation,"Shangqing Liu, Wei Ma, Jian Wang, Xiaofei Xie, Ruitao Feng, Yang Liu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.09599"" target=""_blank"">2404.09599</a>",,2025-12-03 22:39:25
Towards a Novel Perspective on Adversarial Examples Driven by Frequency,"Zhun Zhang, Yi Zeng, Qihe Liu, Shijie Zhou",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.10202"" target=""_blank"">2404.10202</a>",,2025-12-03 22:39:25
Double Privacy Guard: Robust Traceable Adversarial Watermarking against Face Recognition,"Yunming Zhang, Dengpan Ye, Sipeng Shen, Caiyun Xie, Ziyi Liu, Jiacheng Deng, Long Tang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14693"" target=""_blank"">2404.14693</a>",,2025-12-03 22:39:25
LSP Framework: A Compensatory Model for Defeating Trigger Reverse Engineering via Label Smoothing Poisoning,"Beichen Li, Yuanfang Guo, Heqi Peng, Yangxi Li, Yunhong Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12852"" target=""_blank"">2404.12852</a>",,2025-12-03 22:39:25
The Victim and The Beneficiary: Exploiting a Poisoned Model to Train a Clean Model on Poisoned Data,"Zixuan Zhu, Rui Wang, Cong Zou, Lihua Jing",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.11265"" target=""_blank"">2404.11265</a>","<a href=""https://github.com/Zixuan-Zhu/VaB"" target=""_blank"">Zixuan-Zhu</a>",2025-12-03 22:39:25
MLSD-GAN -- Generating Strong High Quality Face Morphing Attacks using Latent Semantic Disentanglement,"Aravinda Reddy PN, Raghavendra Ramachandra, Krothapalli Sreenivasa Rao, Pabitra Mitra",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12679"" target=""_blank"">2404.12679</a>",,2025-12-03 22:39:25
Fermi-Bose Machine,"Mingshan Xie, Yuchen Wang, Haiping Huang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13631"" target=""_blank"">2404.13631</a>",,2025-12-03 22:39:25
Audio Anti-Spoofing Detection: A Survey,"Menglu Li, Yasaman Ahmadiadli, Xiao-Ping Zhang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13914"" target=""_blank"">2404.13914</a>",,2025-12-03 22:39:25
Explicit Lipschitz Value Estimation Enhances Policy Robustness Against Perturbation,"Xulin Chen, Ruipeng Liu, Garrett E. Katz",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13879"" target=""_blank"">2404.13879</a>",,2025-12-03 22:39:25
Dual Model Replacement:invisible Multi-target Backdoor Attack based on Federal Learning,"Rong Wang, Guichen Zhou, Mingjun Gao, Yunpeng Xiao",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13946"" target=""_blank"">2404.13946</a>",,2025-12-03 22:39:25
Protecting Your LLMs with Information Bottleneck,"Zichuan Liu, Zefan Wang, Linjie Xu, Jinyu Wang, Lei Song, Tianchun Wang, Chunlin Chen, Wei Cheng, Jiang Bian",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13968"" target=""_blank"">2404.13968</a>",,2025-12-03 22:39:25
Physical Backdoor Attack can Jeopardize Driving with Vision-Large-Language Models,"Zhenyang Ni, Rui Ye, Yuxi Wei, Zhen Xiang, Yanfeng Wang, Siheng Chen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12916"" target=""_blank"">2404.12916</a>",,2025-12-03 22:39:25
Competition Report: Finding Universal Jailbreak Backdoors in Aligned LLMs,"Javier Rando, Francesco Croce, Kryštof Mitka, Stepan Shabalin, Maksym Andriushchenko, Nicolas Flammarion, Florian Tramèr",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14461"" target=""_blank"">2404.14461</a>",,2025-12-03 22:39:25
Deep Learning as Ricci Flow,"Anthony Baptista, Alessandro Barp, Tapabrata Chakraborti, Chris Harbron, Ben D. MacArthur, Christopher R. S. Banerji",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14265"" target=""_blank"">2404.14265</a>",,2025-12-03 22:39:25
Hyp-OC: Hyperbolic One Class Classification for Face Anti-Spoofing,"Kartik Narayan, Vishal M. Patel",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14406"" target=""_blank"">2404.14406</a>",,2025-12-03 22:39:25
Poisoning Attacks on Federated Learning-based Wireless Traffic Prediction,"Zifan Zhang, Minghong Fang, Jiayuan Huang, Yuchen Liu",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14389"" target=""_blank"">2404.14389</a>",,2025-12-03 22:39:25
Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations,"Sukmin Cho, Soyeong Jeong, Jeongyeon Seo, Taeho Hwang, Jong C. Park",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13948"" target=""_blank"">2404.13948</a>",,2025-12-03 22:39:25
Attack on Scene Flow using Point Clouds,"Haniyeh Ehsani Oskouie, Mohammad-Shahram Moin, Shohreh Kasaei",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13621"" target=""_blank"">2404.13621</a>","<a href=""https://github.com/aheldis/Attack-on-Scene-Flow-using-Point-Clouds"" target=""_blank"">aheldis</a>",2025-12-03 22:39:25
CloudFort: Enhancing Robustness of 3D Point Cloud Classification Against Backdoor Attacks via Spatial Partitioning and Ensemble Prediction,"Wenhao Lan, Yijun Yang, Haihua Shen, Shan Li",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.14042"" target=""_blank"">2404.14042</a>",,2025-12-03 22:39:25
Robust EEG-based Emotion Recognition Using an Inception and Two-sided Perturbation Model,"Shadi Sartipi, Mujdat Cetin",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.15373"" target=""_blank"">2404.15373</a>",,2025-12-03 22:39:25
Reliable Model Watermarking: Defending Against Theft without Compromising on Evasion,"Hongyu Zhu, Sichu Liang, Wentao Hu, Fangqi Li, Ju Jia, Shilin Wang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13518"" target=""_blank"">2404.13518</a>",,2025-12-03 22:39:25
A Clean-graph Backdoor Attack against Graph Convolutional Networks with Poisoned Label Only,"Jiazhu Dai, Haoyu Sun",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12704"" target=""_blank"">2404.12704</a>",,2025-12-03 22:39:25
AED-PADA:Improving Generalizability of Adversarial Example Detection via Principal Adversarial Domain Adaptation,"Heqi Peng, Yunhong Wang, Ruijie Yang, Beichen Li, Rui Wang, Yuanfang Guo",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12635"" target=""_blank"">2404.12635</a>",,2025-12-03 22:39:25
How Real Is Real? A Human Evaluation Framework for Unrestricted Adversarial Examples,"Dren Fazlija, Arkadij Orlov, Johanna Schrader, Monty-Maximilian Zühlke, Michael Rohs, Daniel Kudenko",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.12653"" target=""_blank"">2404.12653</a>",,2025-12-03 22:39:25
Backdoor Attacks and Defenses on Semantic-Symbol Reconstruction in Semantic Communications,"Yuan Zhou, Rose Qingyang Hu, Yi Qian",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13279"" target=""_blank"">2404.13279</a>",,2025-12-03 22:39:25
AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs,"Anselm Paulus, Arman Zharmagambetov, Chuan Guo, Brandon Amos, Yuandong Tian",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.16873"" target=""_blank"">2404.16873</a>",,2025-12-03 22:39:25
Beyond Score Changes: Adversarial Attack on No-Reference Image Quality Assessment from Two Perspectives,"Chenxi Yang, Yujia Liu, Dingquan Li, Yan Zhong, Tingting Jiang",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13277"" target=""_blank"">2404.13277</a>",,2025-12-03 22:39:25
Pixel is a Barrier: Diffusion Models Are More Adversarially Robust Than We Think,"Haotian Xue, Yongxin Chen",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13320"" target=""_blank"">2404.13320</a>","<a href=""https://github.com/xavihart/PDM-Pure"" target=""_blank"">xavihart</a>",2025-12-03 22:39:25
Trojan Detection in Large Language Models: Insights from The Trojan Detection Challenge,"Narek Maloyan, Ekansh Verma, Bulat Nutfullin, Bislan Ashinov",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13660"" target=""_blank"">2404.13660</a>",,2025-12-03 22:39:25
Swap It Like Its Hot: Segmentation-based spoof attacks on eye-tracking images,"Anish S. Narkar, Brendan David-John",arXiv,2024-04,"<a href=""http://arxiv.org/abs/2404.13827"" target=""_blank"">2404.13827</a>",,2025-12-03 22:39:25
PeerAiD: Improving Adversarial Distillation from a Specialized Peer Tutor,"Jaewon Jung, Hongsun Jang, Jaeyong Song, Jinho Lee",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06668"" target=""_blank"">2403.06668</a>","<a href=""https://github.com/jaewonalive/PeerAiD"" target=""_blank"">jaewonalive</a>",2025-12-03 22:39:25
Dynamic Perturbation-Adaptive Adversarial Training on Medical Image Classification,"Shuai Li, Xiaoguang Ma, Shancheng Jiang, Lu Meng",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06798"" target=""_blank"">2403.06798</a>",,2025-12-03 22:39:25
Disentangling Policy from Offline Task Representation Learning via Adversarial Data Augmentation,"Chengxing Jia, Fuxiang Zhang, Yi-Chen Li, Chen-Xiao Gao, Xu-Hui Liu, Lei Yuan, Zongzhang Zhang, Yang Yu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07261"" target=""_blank"">2403.07261</a>",,2025-12-03 22:39:25
Intra-Section Code Cave Injection for Adversarial Evasion Attacks on Windows PE Malware File,"Kshitiz Aryal, Maanak Gupta, Mahmoud Abdelsalam, Moustafa Saleh",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06428"" target=""_blank"">2403.06428</a>",,2025-12-03 22:39:25
epsilon-Mesh Attack: A Surface-based Adversarial Point Cloud Attack for Facial Expression Recognition,"Batuhan Cengiz, Mert Gulsen, Yusuf H. Sahin, Gozde Unal",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06661"" target=""_blank"">2403.06661</a>","<a href=""https://github.com/batuceng/e-mesh-attack"" target=""_blank"">batuceng</a>",2025-12-03 22:39:25
PCLD: Point Cloud Layerwise Diffusion for Adversarial Purification,"Mert Gulsen, Batuhan Cengiz, Yusuf H. Sahin, Gozde Unal",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06698"" target=""_blank"">2403.06698</a>","<a href=""https://github.com/batuceng/diffusion-layer-robustness-pc"" target=""_blank"">batuceng</a>",2025-12-03 22:39:25
Overcoming the Paradox of Certified Training with Gaussian Smoothing,"Stefan Balauca, Mark Niklas Müller, Yuhao Mao, Maximilian Baader, Marc Fischer, Martin Vechev",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07095"" target=""_blank"">2403.07095</a>",,2025-12-03 22:39:25
Real is not True: Backdoor Attacks Against Deepfake Detection,"Hong Sun, Ziqiang Li, Lei Liu, Bin Li",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06610"" target=""_blank"">2403.06610</a>",,2025-12-03 22:39:25
Stealing Part of a Production Language Model,"Nicholas Carlini, Daniel Paleka, Krishnamurthy Dj Dvijotham, Thomas Steinke, Jonathan Hayase, A. Feder Cooper, Katherine Lee, Matthew Jagielski, Milad Nasr, Arthur Conmy, Eric Wallace, David Rolnick, Florian Tramèr",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06634"" target=""_blank"">2403.06634</a>",,2025-12-03 22:39:25
"Improving deep learning with prior knowledge and cognitive models: A survey on enhancing explainability, adversarial robustness and zero-shot learning","Fuseinin Mumuni, Alhassan Mumuni",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07078"" target=""_blank"">2403.07078</a>",,2025-12-03 22:39:25
IOI: Invisible One-Iteration Adversarial Attack on No-Reference Image- and Video-Quality Metrics,"Ekaterina Shumitskaya, Anastasia Antsiferova, Dmitriy Vatolin",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05955"" target=""_blank"">2403.05955</a>",,2025-12-03 22:39:25
AS-FIBA: Adaptive Selective Frequency-Injection for Backdoor Attack on Deep Face Restoration,"Zhenbo Song, Wenhao Gao, Zhenyuan Zhang, Jianfeng Lu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06430"" target=""_blank"">2403.06430</a>",,2025-12-03 22:39:25
Towards the Uncharted: Density-Descending Feature Perturbation for Semi-supervised Semantic Segmentation,"Xiaoyang Wang, Huihui Bai, Limin Yu, Yao Zhao, Jimin Xiao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06462"" target=""_blank"">2403.06462</a>","<a href=""https://github.com/Gavinwxy/DDFP"" target=""_blank"">Gavinwxy</a>",2025-12-03 22:39:25
DNNShield: Embedding Identifiers for Deep Neural Network Ownership Verification,"Jasper Stang, Torsten Krauß, Alexandra Dmitrienko",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06581"" target=""_blank"">2403.06581</a>",,2025-12-03 22:39:25
Impact of Noisy Supervision in Foundation Model Learning,"Hao Chen, Zihan Wang, Ran Tao, Hongxin Wei, Xing Xie, Masashi Sugiyama, Bhiksha Raj, Jindong Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06869"" target=""_blank"">2403.06869</a>",,2025-12-03 22:39:25
Transformers Learn Low Sensitivity Functions: Investigations and Implications,"Bhavya Vasudeva, Deqing Fu, Tianyi Zhou, Elliott Kau, Youqi Huang, Vatsal Sharan",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06925"" target=""_blank"">2403.06925</a>","<a href=""https://github.com/estija/sensitivity"" target=""_blank"">estija</a>",2025-12-03 22:39:25
A Zero Trust Framework for Realization and Defense Against Generative AI Attacks in Power Grid,"Md. Shirajum Munir, Sravanthi Proddatoori, Manjushree Muralidhara, Walid Saad, Zhu Han, Sachin Shetty",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06388"" target=""_blank"">2403.06388</a>",,2025-12-03 22:39:25
Hard-label based Small Query Black-box Adversarial Attack,"Jeonghwan Park, Paul Miller, Niall McLaughlin",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.06014"" target=""_blank"">2403.06014</a>",,2025-12-03 22:39:25
iBA: Backdoor Attack on 3D Point Cloud via Reconstructing Itself,"Yuhao Bian, Shengjing Tian, Xiuping Liu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05847"" target=""_blank"">2403.05847</a>",,2025-12-03 22:39:25
Attacking Transformers with Feature Diversity Adversarial Perturbation,"Chenxing Gao, Hang Zhou, Junqing Yu, YuTeng Ye, Jiale Cai, Junle Wang, Wei Yang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07942"" target=""_blank"">2403.07942</a>",,2025-12-03 22:39:25
Hide in Thicket: Generating Imperceptible and Rational Adversarial Perturbations on 3D Point Clouds,"Tianrui Lou, Xiaojun Jia, Jindong Gu, Li Liu, Siyuan Liang, Bangyan He, Xiaochun Cao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05247"" target=""_blank"">2403.05247</a>","<a href=""https://github.com/TRLou/HiT-ADV"" target=""_blank"">TRLou</a>",2025-12-03 22:39:25
Duwak: Dual Watermarks in Large Language Models,"Chaoyi Zhu, Jeroen Galjaard, Pin-Yu Chen, Lydia Y. Chen",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13000"" target=""_blank"">2403.13000</a>",,2025-12-03 22:39:25
Visual Privacy Auditing with Diffusion Models,"Kristian Schwethelm, Johannes Kaiser, Moritz Knolle, Daniel Rueckert, Georgios Kaissis, Alexander Ziller",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07588"" target=""_blank"">2403.07588</a>",,2025-12-03 22:39:25
Adversarial Fine-tuning of Compressed Neural Networks for Joint Improvement of Robustness and Efficiency,"Hallgrimur Thorsteinsson, Valdemar J Henriksen, Tong Chen, Raghavendra Selvan",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09441"" target=""_blank"">2403.09441</a>",,2025-12-03 22:39:25
Towards a Framework for Deep Learning Certification in Safety-Critical Applications Using Inherently Safe Design and Run-Time Error Detection,Romeo Valentin,arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14678"" target=""_blank"">2403.14678</a>",,2025-12-03 22:39:25
PreCurious: How Innocent Pre-Trained Language Models Turn into Privacy Traps,"Ruixuan Liu, Tianhao Wang, Yang Cao, Li Xiong",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09562"" target=""_blank"">2403.09562</a>",,2025-12-03 22:39:25
NLP Verification: Towards a General Methodology for Certifying Robustness,"Marco Casadio, Tanvi Dinkar, Ekaterina Komendantskaya, Luca Arnaboldi, Matthew L. Daggitt, Omri Isac, Guy Katz, Verena Rieser, Oliver Lemon",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10144"" target=""_blank"">2403.10144</a>",,2025-12-03 22:39:25
Robust Influence-based Training Methods for Noisy Brain MRI,"Minh-Hao Van, Alycia N. Carey, Xintao Wu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10698"" target=""_blank"">2403.10698</a>",,2025-12-03 22:39:25
An Image Is Worth 1000 Lies: Adversarial Transferability across Prompts on Vision-Language Models,"Haochen Luo, Jindong Gu, Fengyuan Liu, Philip Torr",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09766"" target=""_blank"">2403.09766</a>","<a href=""https://github.com/Haochen-Luo/CroPA"" target=""_blank"">Haochen-Luo</a>",2025-12-03 22:39:25
Counter-Samples: A Stateless Strategy to Neutralize Black Box Adversarial Attacks,"Roey Bokobza, Yisroel Mirsky",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10562"" target=""_blank"">2403.10562</a>",,2025-12-03 22:39:25
Exploring the Adversarial Frontier: Quantifying Robustness via Adversarial Hypervolume,"Ping Guo, Cheng Gong, Xi Lin, Zhiyuan Yang, Qingfu Zhang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05100"" target=""_blank"">2403.05100</a>",,2025-12-03 22:39:25
Soften to Defend: Towards Adversarial Robustness via Self-Guided Label Refinement,"Daiwei Yu, Zhuorong Li, Lina Wei, Canghong Jin, Yun Zhang, Sixian Chan",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09101"" target=""_blank"">2403.09101</a>",,2025-12-03 22:39:25
Robust Subgraph Learning by Monitoring Early Training Representations,"Sepideh Neshatfar, Salimeh Yasaei Sekeh",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09901"" target=""_blank"">2403.09901</a>",,2025-12-03 22:39:25
LDPRecover: Recovering Frequencies from Poisoning Attacks against Local Differential Privacy,"Xinyue Sun, Qingqing Ye, Haibo Hu, Jiawei Duan, Tianyu Wo, Jie Xu, Renyu Yang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09351"" target=""_blank"">2403.09351</a>",,2025-12-03 22:39:25
AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting,"Yu Wang, Xiaogeng Liu, Yu Li, Muhao Chen, Chaowei Xiao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09513"" target=""_blank"">2403.09513</a>","<a href=""https://github.com/rain305f/AdaShield"" target=""_blank"">rain305f</a>",2025-12-03 22:39:25
Towards White Box Deep Learning,Maciej Satkiewicz,arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09863"" target=""_blank"">2403.09863</a>","<a href=""https://github.com/314-Foundation/white-box-nn"" target=""_blank"">314-Foundation</a>",2025-12-03 22:39:25
Symbiotic Game and Foundation Models for Cyber Deception Operations in Strategic Cyber Warfare,"Tao Li, Quanyan Zhu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10570"" target=""_blank"">2403.10570</a>",,2025-12-03 22:39:25
AVIBench: Towards Evaluating the Robustness of Large Vision-Language Model on Adversarial Visual-Instructions,"Hao Zhang, Wenqi Shao, Hong Liu, Yongqiang Ma, Ping Luo, Yu Qiao, Kaipeng Zhang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09346"" target=""_blank"">2403.09346</a>",,2025-12-03 22:39:25
Backdoor Attack with Mode Mixture Latent Modification,"Hongwei Zhang, Xiaoyin Xu, Dongsheng An, Xianfeng Gu, Min Zhang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07463"" target=""_blank"">2403.07463</a>",,2025-12-03 22:39:25
Optimistic Verifiable Training by Controlling Hardware Nondeterminism,"Megha Srivastava, Simran Arora, Dan Boneh",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09603"" target=""_blank"">2403.09603</a>","<a href=""https://github.com/meghabyte/verifiable-training"" target=""_blank"">meghabyte</a>",2025-12-03 22:39:25
Medical Unlearnable Examples: Securing Medical Data from Unauthorized Traning via Sparsity-Aware Local Masking,"Weixiang Sun, Yixin Liu, Zhiling Yan, Kaidi Xu, Lichao Sun",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10573"" target=""_blank"">2403.10573</a>",,2025-12-03 22:39:25
ADEdgeDrop: Adversarial Edge Dropping for Robust Graph Neural Networks,"Zhaoliang Chen, Zhihao Wu, Ylli Sadikaj, Claudia Plant, Hong-Ning Dai, Shiping Wang, Yiu-Ming Cheung, Wenzhong Guo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.09171"" target=""_blank"">2403.09171</a>",,2025-12-03 22:39:25
Attack Deterministic Conditional Image Generative Models for Diverse and Controllable Generation,"Tianyi Chu, Wei Xing, Jiafu Chen, Zhizhong Wang, Jiakai Sun, Lei Zhao, Haibo Chen, Huaizhong Lin",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.08294"" target=""_blank"">2403.08294</a>",,2025-12-03 22:39:25
Fast Inference of Removal-Based Node Influence,"Weikai Li, Zhiping Xiao, Xiao Luo, Yizhou Sun",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.08333"" target=""_blank"">2403.08333</a>","<a href=""https://github.com/weikai-li/NORA"" target=""_blank"">weikai-li</a>",2025-12-03 22:39:25
Tastle: Distract Large Language Models for Automatic Jailbreak Attack,"Zeguan Xiao, Yan Yang, Guanhua Chen, Yun Chen",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.08424"" target=""_blank"">2403.08424</a>",,2025-12-03 22:39:25
Adaptive Hybrid Masking Strategy for Privacy-Preserving Face Recognition Against Model Inversion Attack,"Yinggui Wang, Yuanqing Huang, Jianshu Li, Le Yang, Kai Song, Lei Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10558"" target=""_blank"">2403.10558</a>",,2025-12-03 22:39:25
"RAF-GI: Towards Robust, Accurate and Fast-Convergent Gradient Inversion Attack in Federated Learning","Can Liu, Jin Wang, Dongyang Yu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.08383"" target=""_blank"">2403.08383</a>",,2025-12-03 22:39:25
Verifix: Post-Training Correction to Improve Label Noise Robustness with Verified Samples,"Sangamesh Kodge, Deepak Ravikumar, Gobinda Saha, Kaushik Roy",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.08618"" target=""_blank"">2403.08618</a>",,2025-12-03 22:39:25
Versatile Defense Against Adversarial Attacks on Image Recognition,"Haibo Zhang, Zhihua Yao, Kouichi Sakurai",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.08170"" target=""_blank"">2403.08170</a>",,2025-12-03 22:39:25
Towards Model Extraction Attacks in GAN-Based Image Translation via Domain Shift Mitigation,"Di Mi, Yanjun Zhang, Leo Yu Zhang, Shengshan Hu, Qi Zhong, Haizhuan Yuan, Shirui Pan",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07673"" target=""_blank"">2403.07673</a>",,2025-12-03 22:39:25
Gemini 1,"Team Gemini, Petko Georgiev, Ving Ian Lei, Ryan Burnell, Libin Bai, Anmol Gulati, Garrett Tanzer, Damien Vincent, Zhufeng Pan, Shibo Wang, Soroosh Mariooryad, Yifan Ding, Xinyang Geng, Fred Alcober, Roy Frostig, Mark Omernick, Lexi Walker, Cosmin Paduraru, Christina Sorokin, Andrea Tacchetti, Colin Gaffney, Samira Daruki, Olcan Sercinoglu, Zach Gleicher, Juliette Love, Paul Voigtlaender, Rohan Jain, Gabriela Surita, Kareem Mohamed, Rory Blevins, Junwhan Ahn, Tao Zhu, Kornraphop Kawintiranon, Orhan Firat, Yiming Gu, Yujing Zhang, Matthew Rahtz, Manaal Faruqui, Natalie Clay, Justin Gilmer, JD Co-Reyes, Ivo Penchev, Rui Zhu, Nobuyuki Morioka, Kevin Hui, Krishna Haridasan, Victor Campos, Mahdis Mahdieh, Mandy Guo, Samer Hassan, Kevin Kilgour, Arpi Vezer, Heng-Tze Cheng, Liedekerke Raoul de, Siddharth Goyal, Paul Barham, DJ Strouse, Seb Noury, Jonas Adler, Mukund Sundararajan, Sharad Vikram, Dmitry Lepikhin, Michela Paganini, Xavier Garcia, Fan Yang, Dasha Valter, Maja Trebacz, Kiran Vodrahalli, Chulayuth Asawaroengchai, Roman Ring, Norbert Kalb, Livio Baldini Soares, Siddhartha Brahma, David Steiner, Tianhe Yu, Fabian Mentzer, Antoine He, Lucas Gonzalez, Bibo Xu, Raphael Lopez Kaufman, Laurent El Shafey, Junhyuk Oh, Tom Hennigan, George van den Driessche, Seth Odoom, Mario Lucic, Becca Roelofs, Sid Lall, Amit Marathe, Betty Chan, Santiago Ontanon, Luheng He, Denis Teplyashin, Jonathan Lai, Phil Crone, Bogdan Damoc, Lewis Ho, Sebastian Riedel, Karel Lenc, Chih-Kuan Yeh, Aakanksha Chowdhery, Yang Xu, Mehran Kazemi, Ehsan Amid, Anastasia Petrushkina, Kevin Swersky, Ali Khodaei, Gowoon Chen, Chris Larkin, Mario Pinto, Geng Yan, Adria Puigdomenech Badia, Piyush Patil, Steven Hansen, Dave Orr, Sebastien M. R. Arnold, Jordan Grimstad, Andrew Dai, Sholto Douglas, Rishika Sinha, Vikas Yadav, Xi Chen, Elena Gribovskaya, Jacob Austin, Jeffrey Zhao, Kaushal Patel, Paul Komarek, Sophia Austin, Sebastian Borgeaud, Linda Friso, Abhimanyu Goyal, Ben Caine, Kris Cao, Da-Woon Chung, Matthew Lamm, Gabe Barth-Maron, Thais Kagohara, Kate Olszewska, Mia Chen, Kaushik Shivakumar, Rishabh Agarwal, Harshal Godhia, Ravi Rajwar, Javier Snaider, Xerxes Dotiwalla, Yuan Liu, Aditya Barua, Victor Ungureanu, Yuan Zhang, Bat-Orgil Batsaikhan, Mateo Wirth, James Qin, Ivo Danihelka, Tulsee Doshi, Martin Chadwick, Jilin Chen, Sanil Jain, Quoc Le, Arjun Kar, Madhu Gurumurthy, Cheng Li, Ruoxin Sang, Fangyu Liu, Lampros Lamprou, Rich Munoz, Nathan Lintz, Harsh Mehta, Heidi Howard, Malcolm Reynolds, Lora Aroyo, Quan Wang, Lorenzo Blanco, Albin Cassirer, Jordan Griffith, Dipanjan Das, Stephan Lee, Jakub Sygnowski, Zach Fisher, James Besley, Richard Powell, Zafarali Ahmed, Dominik Paulus, David Reitter, Zalan Borsos, Rishabh Joshi, Aedan Pope, Steven Hand, Vittorio Selo, Vihan Jain, Nikhil Sethi, Megha Goel, Takaki Makino, Rhys May, Zhen Yang, Johan Schalkwyk, Christina Butterfield, Anja Hauth, Alex Goldin, Will Hawkins, Evan Senter, Sergey Brin, Oliver Woodman, Marvin Ritter, Eric Noland, Minh Giang, Vijay Bolina, Lisa Lee, Tim Blyth, Ian Mackinnon, Machel Reid, Obaid Sarvana, David Silver, Alexander Chen, Lily Wang, Loren Maggiore, Oscar Chang, Nithya Attaluri, Gregory Thornton, Chung-Cheng Chiu, Oskar Bunyan, Nir Levine, Timothy Chung, Evgenii Eltyshev, Xiance Si, Timothy Lillicrap, Demetra Brady, Vaibhav Aggarwal, Boxi Wu, Yuanzhong Xu, Ross McIlroy, Kartikeya Badola, Paramjit Sandhu, Erica Moreira, Wojciech Stokowiec, Ross Hemsley, Dong Li, Alex Tudor, Pranav Shyam, Elahe Rahimtoroghi, Salem Haykal, Pablo Sprechmann, Xiang Zhou, Diana Mincu, Yujia Li, Ravi Addanki, Kalpesh Krishna, Xiao Wu, Alexandre Frechette, Matan Eyal, Allan Dafoe, Dave Lacey, Jay Whang, Thi Avrahami, Ye Zhang, Emanuel Taropa, Hanzhao Lin, Daniel Toyama, Eliza Rutherford, Motoki Sano, HyunJeong Choe, Alex Tomala, Chalence Safranek-Shrader, Nora Kassner, Mantas Pajarskas, Matt Harvey, Sean Sechrist, Meire Fortunato, Christina Lyu, Gamaleldin Elsayed, Chenkai Kuang, James Lottes, Eric Chu, Chao Jia, Chih-Wei Chen, Peter Humphreys, Kate Baumli, Connie Tao, Rajkumar Samuel, Cicero Nogueira dos Santos, Anders Andreassen, Nemanja Rakićević, Dominik Grewe, Aviral Kumar, Stephanie Winkler, Jonathan Caton, Andrew Brock, Sid Dalmia, Hannah Sheahan, Iain Barr, Yingjie Miao, Paul Natsev, Jacob Devlin, Feryal Behbahani, Flavien Prost, Yanhua Sun, Artiom Myaskovsky, Thanumalayan Sankaranarayana Pillai, Dan Hurt, Angeliki Lazaridou, Xi Xiong, Ce Zheng, Fabio Pardo, Xiaowei Li, Dan Horgan, Joe Stanton, Moran Ambar, Fei Xia, Alejandro Lince, Mingqiu Wang, Basil Mustafa, Albert Webson, Hyo Lee, Rohan Anil, Martin Wicke, Timothy Dozat, Abhishek Sinha, Enrique Piqueras, Elahe Dabir, Shyam Upadhyay, Anudhyan Boral, Lisa Anne Hendricks, Corey Fry, Josip Djolonga, Yi Su, Jake Walker, Jane Labanowski, Ronny Huang, Vedant Misra, Jeremy Chen, RJ Skerry-Ryan, Avi Singh, Shruti Rijhwani, Dian Yu, Alex Castro-Ros, Beer Changpinyo, Romina Datta, Sumit Bagri, Arnar Mar Hrafnkelsson, Marcello Maggioni, Daniel Zheng, Yury Sulsky, Shaobo Hou, Tom Le Paine, Antoine Yang, Jason Riesa, Dominika Rogozinska, Dror Marcus, Dalia El Badawy, Qiao Zhang, Luyu Wang, Helen Miller, Jeremy Greer, Lars Lowe Sjos, Azade Nova, Heiga Zen, Rahma Chaabouni, Mihaela Rosca, Jiepu Jiang, Charlie Chen, Ruibo Liu, Tara Sainath, Maxim Krikun, Alex Polozov, Jean-Baptiste Lespiau, Josh Newlan, Zeyncep Cankara, Soo Kwak, Yunhan Xu, Phil Chen, Andy Coenen, Clemens Meyer, Katerina Tsihlas, Ada Ma, Juraj Gottweis, Jinwei Xing, Chenjie Gu, Jin Miao, Christian Frank, Zeynep Cankara, Sanjay Ganapathy, Ishita Dasgupta, Steph Hughes-Fitt, Heng Chen, David Reid, Keran Rong, Hongmin Fan, Amersfoort Joost van, Vincent Zhuang, Aaron Cohen, Shixiang Shane Gu, Anhad Mohananey, Anastasija Ilic, Taylor Tobin, John Wieting, Anna Bortsova, Phoebe Thacker, Emma Wang, Emily Caveness, Justin Chiu, Eren Sezener, Alex Kaskasoli, Steven Baker, Katie Millican, Mohamed Elhawaty, Kostas Aisopos, Carl Lebsack, Nathan Byrd, Hanjun Dai, Wenhao Jia, Matthew Wiethoff, Elnaz Davoodi, Albert Weston, Lakshman Yagati, Arun Ahuja, Isabel Gao, Golan Pundak, Susan Zhang, Michael Azzam, Khe Chai Sim, Sergi Caelles, James Keeling, Abhanshu Sharma, Andy Swing, YaGuang Li, Chenxi Liu, Carrie Grimes Bostock, Yamini Bansal, Zachary Nado, Ankesh Anand, Josh Lipschultz, Abhijit Karmarkar, Lev Proleev, Abe Ittycheriah, Soheil Hassas Yeganeh, George Polovets, Aleksandra Faust, Jiao Sun, Alban Rrustemi, Pen Li, Rakesh Shivanna, Jeremiah Liu, Chris Welty, Federico Lebron, Anirudh Baddepudi, Sebastian Krause, Emilio Parisotto, Radu Soricut, Zheng Xu, Dawn Bloxwich, Melvin Johnson, Behnam Neyshabur, Justin Mao-Jones, Renshen Wang, Vinay Ramasesh, Zaheer Abbas, Arthur Guez, Constant Segal, Duc Dung Nguyen, James Svensson, Le Hou, Sarah York, Kieran Milan, Sophie Bridgers, Wiktor Gworek, Marco Tagliasacchi, James Lee-Thorp, Michael Chang, Alexey Guseynov, Ale Jakse Hartman, Michael Kwong, Ruizhe Zhao, Sheleem Kashem, Elizabeth Cole, Antoine Miech, Richard Tanburn, Mary Phuong, Filip Pavetic, Sebastien Cevey, Ramona Comanescu, Richard Ives, Sherry Yang, Cosmo Du, Bo Li, Zizhao Zhang, Mariko Iinuma, Clara Huiyi Hu, Aurko Roy, Shaan Bijwadia, Zhenkai Zhu, Danilo Martins, Rachel Saputro, Anita Gergely, Steven Zheng, Dawei Jia, Ioannis Antonoglou, Adam Sadovsky, Shane Gu, Yingying Bi, Alek Andreev, Sina Samangooei, Mina Khan, Tomas Kocisky, Angelos Filos, Chintu Kumar, Colton Bishop, Adams Yu, Sarah Hodkinson, Sid Mittal, Premal Shah, Alexandre Moufarek, Yong Cheng, Adam Bloniarz, Jaehoon Lee, Pedram Pejman, Paul Michel, Stephen Spencer, Vladimir Feinberg, Xuehan Xiong, Nikolay Savinov, Charlotte Smith, Siamak Shakeri, Dustin Tran, Mary Chesus, Bernd Bohnet, George Tucker, Glehn Tamara von, Carrie Muir, Yiran Mao, Hideto Kazawa, Ambrose Slone, Kedar Soparkar, Disha Shrivastava, James Cobon-Kerr, Michael Sharman, Jay Pavagadhi, Carlos Araya, Karolis Misiunas, Nimesh Ghelani, Michael Laskin, David Barker, Qiujia Li, Anton Briukhov, Neil Houlsby, Mia Glaese, Balaji Lakshminarayanan, Nathan Schucher, Yunhao Tang, Eli Collins, Hyeontaek Lim, Fangxiaoyu Feng, Adria Recasens, Guangda Lai, Alberto Magni, Cao Nicola De, Aditya Siddhant, Zoe Ashwood, Jordi Orbay, Mostafa Dehghani, Jenny Brennan, Yifan He, Kelvin Xu, Yang Gao, Carl Saroufim, James Molloy, Xinyi Wu, Seb Arnold, Solomon Chang, Julian Schrittwieser, Elena Buchatskaya, Soroush Radpour, Martin Polacek, Skye Giordano, Ankur Bapna, Simon Tokumine, Vincent Hellendoorn, Thibault Sottiaux, Sarah Cogan, Aliaksei Severyn, Mohammad Saleh, Shantanu Thakoor, Laurent Shefey, Siyuan Qiao, Meenu Gaba, Shuo-yiin Chang, Craig Swanson, Biao Zhang, Benjamin Lee, Paul Kishan Rubenstein, Gan Song, Tom Kwiatkowski, Anna Koop, Ajay Kannan, David Kao, Parker Schuh, Axel Stjerngren, Golnaz Ghiasi, Gena Gibson, Luke Vilnis, Ye Yuan, Felipe Tiengo Ferreira, Aishwarya Kamath, Ted Klimenko, Ken Franko, Kefan Xiao, Indro Bhattacharya, Miteyan Patel, Rui Wang, Alex Morris, Robin Strudel, Vivek Sharma, Peter Choy, Sayed Hadi Hashemi, Jessica Landon, Mara Finkelstein, Priya Jhakra, Justin Frye, Megan Barnes, Matthew Mauger, Dennis Daun, Khuslen Baatarsukh, Matthew Tung, Wael Farhan, Henryk Michalewski, Fabio Viola, Felix de Chaumont Quitry, Charline Le Lan, Tom Hudson, Qingze Wang, Felix Fischer, Ivy Zheng, Elspeth White, Anca Dragan, Jean-baptiste Alayrac, Eric Ni, Alexander Pritzel, Adam Iwanicki, Michael Isard, Anna Bulanova, Lukas Zilka, Ethan Dyer, Devendra Sachan, Srivatsan Srinivasan, Hannah Muckenhirn, Honglong Cai, Amol Mandhane, Mukarram Tariq, Jack W. Rae, Gary Wang, Kareem Ayoub, Nicholas FitzGerald, Yao Zhao, Woohyun Han, Chris Alberti, Dan Garrette, Kashyap Krishnakumar, Mai Gimenez, Anselm Levskaya, Daniel Sohn, Josip Matak, Inaki Iturrate, Michael B. Chang, Jackie Xiang, Yuan Cao, Nishant Ranka, Geoff Brown, Adrian Hutter, Vahab Mirrokni, Nanxin Chen, Kaisheng Yao, Zoltan Egyed, Francois Galilee, Tyler Liechty, Praveen Kallakuri, Evan Palmer, Sanjay Ghemawat, Jasmine Liu, David Tao, Chloe Thornton, Tim Green, Mimi Jasarevic, Sharon Lin, Victor Cotruta, Yi-Xuan Tan, Noah Fiedel, Hongkun Yu, Ed Chi, Alexander Neitz, Jens Heitkaemper, Anu Sinha, Denny Zhou, Yi Sun, Charbel Kaed, Brice Hulse, Swaroop Mishra, Maria Georgaki, Sneha Kudugunta, Clement Farabet, Izhak Shafran, Daniel Vlasic, Anton Tsitsulin, Rajagopal Ananthanarayanan, Alen Carin, Guolong Su, Pei Sun, Shashank V, Gabriel Carvajal, Josef Broder, Iulia Comsa, Alena Repina, William Wong, Warren Weilun Chen, Peter Hawkins, Egor Filonov, Lucia Loher, Christoph Hirnschall, Weiyi Wang, Jingchen Ye, Andrea Burns, Hardie Cate, Diana Gage Wright, Federico Piccinini, Lei Zhang, Chu-Cheng Lin, Ionel Gog, Yana Kulizhskaya, Ashwin Sreevatsa, Shuang Song, Luis C. Cobo, Anand Iyer, Chetan Tekur, Guillermo Garrido, Zhuyun Xiao, Rupert Kemp, Huaixiu Steven Zheng, Hui Li, Ananth Agarwal, Christel Ngani, Kati Goshvadi, Rebeca Santamaria-Fernandez, Wojciech Fica, Xinyun Chen, Chris Gorgolewski, Sean Sun, Roopal Garg, Xinyu Ye, S. M. Ali Eslami, Nan Hua, Jon Simon, Pratik Joshi, Yelin Kim, Ian Tenney, Sahitya Potluri, Lam Nguyen Thiet, Quan Yuan, Florian Luisier, Alexandra Chronopoulou, Salvatore Scellato, Praveen Srinivasan, Minmin Chen, Vinod Koverkathu, Valentin Dalibard, Yaming Xu, Brennan Saeta, Keith Anderson, Thibault Sellam, Nick Fernando, Fantine Huot, Junehyuk Jung, Mani Varadarajan, Michael Quinn, Amit Raul, Maigo Le, Ruslan Habalov, Jon Clark, Komal Jalan, Kalesha Bullard, Achintya Singhal, Thang Luong, Boyu Wang, Sujeevan Rajayogam, Julian Eisenschlos, Johnson Jia, Daniel Finchelstein, Alex Yakubovich, Daniel Balle, Michael Fink, Sameer Agarwal, Jing Li, Dj Dvijotham, Shalini Pal, Kai Kang, Jaclyn Konzelmann, Jennifer Beattie, Olivier Dousse, Diane Wu, Remi Crocker, Chen Elkind, Siddhartha Reddy Jonnalagadda, Jong Lee, Dan Holtmann-Rice, Krystal Kallarackal, Rosanne Liu, Denis Vnukov, Neera Vats, Luca Invernizzi, Mohsen Jafari, Huanjie Zhou, Lilly Taylor, Jennifer Prendki, Marcus Wu, Tom Eccles, Tianqi Liu, Kavya Kopparapu, Francoise Beaufays, Christof Angermueller, Andreea Marzoca, Shourya Sarcar, Hilal Dib, Jeff Stanway, Frank Perbet, Nejc Trdin, Rachel Sterneck, Andrey Khorlin, Dinghua Li, Xihui Wu, Sonam Goenka, David Madras, Sasha Goldshtein, Willi Gierke, Tong Zhou, Yaxin Liu, Yannie Liang, Anais White, Yunjie Li, Shreya Singh, Sanaz Bahargam, Mark Epstein, Sujoy Basu, Li Lao, Adnan Ozturel, Carl Crous, Alex Zhai, Han Lu, Zora Tung, Neeraj Gaur, Alanna Walton, Lucas Dixon, Ming Zhang, Amir Globerson, Grant Uy, Andrew Bolt, Olivia Wiles, Milad Nasr, Ilia Shumailov, Marco Selvi, Francesco Piccinno, Ricardo Aguilar, Sara McCarthy, Misha Khalman, Mrinal Shukla, Vlado Galic, John Carpenter, Kevin Villela, Haibin Zhang, Harry Richardson, James Martens, Matko Bosnjak, Shreyas Rammohan Belle, Jeff Seibert, Mahmoud Alnahlawi, Brian McWilliams, Sankalp Singh, Annie Louis, Wen Ding, Dan Popovici, Lenin Simicich, Laura Knight, Pulkit Mehta, Nishesh Gupta, Chongyang Shi, Saaber Fatehi, Jovana Mitrovic, Alex Grills, Joseph Pagadora, Dessie Petrova, Danielle Eisenbud, Zhishuai Zhang, Damion Yates, Bhavishya Mittal, Nilesh Tripuraneni, Yannis Assael, Thomas Brovelli, Prateek Jain, Mihajlo Velimirovic, Canfer Akbulut, Jiaqi Mu, Wolfgang Macherey, Ravin Kumar, Jun Xu, Haroon Qureshi, Gheorghe Comanici, Jeremy Wiesner, Zhitao Gong, Anton Ruddock, Matthias Bauer, Nick Felt, Anirudh GP, Anurag Arnab, Dustin Zelle, Jonas Rothfuss, Bill Rosgen, Ashish Shenoy, Bryan Seybold, Xinjian Li, Jayaram Mudigonda, Goker Erdogan, Jiawei Xia, Jiri Simsa, Andrea Michi, Yi Yao, Christopher Yew, Steven Kan, Isaac Caswell, Carey Radebaugh, Andre Elisseeff, Pedro Valenzuela, Kay McKinney, Kim Paterson, Albert Cui, Eri Latorre-Chimoto, Solomon Kim, William Zeng, Ken Durden, Priya Ponnapalli, Tiberiu Sosea, Christopher A. Choquette-Choo, James Manyika, Brona Robenek, Harsha Vashisht, Sebastien Pereira, Hoi Lam, Marko Velic, Denese Owusu-Afriyie, Katherine Lee, Tolga Bolukbasi, Alicia Parrish, Shawn Lu, Jane Park, Balaji Venkatraman, Alice Talbert, Lambert Rosique, Yuchung Cheng, Andrei Sozanschi, Adam Paszke, Praveen Kumar, Jessica Austin, Lu Li, Khalid Salama, Wooyeol Kim, Nandita Dukkipati, Anthony Baryshnikov, Christos Kaplanis, XiangHai Sheng, Yuri Chervonyi, Caglar Unlu, Diego de Las Casas, Harry Askham, Kathryn Tunyasuvunakool, Felix Gimeno, Siim Poder, Chester Kwak, Matt Miecnikowski, Vahab Mirrokni, Alek Dimitriev, Aaron Parisi, Dangyi Liu, Tomy Tsai, Toby Shevlane, Christina Kouridi, Drew Garmon, Adrian Goedeckemeyer, Adam R. Brown, Anitha Vijayakumar, Ali Elqursh, Sadegh Jazayeri, Jin Huang, Sara Mc Carthy, Jay Hoover, Lucy Kim, Sandeep Kumar, Wei Chen, Courtney Biles, Garrett Bingham, Evan Rosen, Lisa Wang, Qijun Tan, David Engel, Francesco Pongetti, Cesare Dario de, Dongseong Hwang, Lily Yu, Jennifer Pullman, Srini Narayanan, Kyle Levin, Siddharth Gopal, Megan Li, Asaf Aharoni, Trieu Trinh, Jessica Lo, Norman Casagrande, Roopali Vij, Loic Matthey, Bramandia Ramadhana, Austin Matthews, CJ Carey, Matthew Johnson, Kremena Goranova, Rohin Shah, Shereen Ashraf, Kingshuk Dasgupta, Rasmus Larsen, Yicheng Wang, Manish Reddy Vuyyuru, Chong Jiang, Joana Ijazi, Kazuki Osawa, Celine Smith, Ramya Sree Boppana, Taylan Bilal, Yuma Koizumi, Ying Xu, Yasemin Altun, Nir Shabat, Ben Bariach, Alex Korchemniy, Kiam Choo, Olaf Ronneberger, Chimezie Iwuanyanwu, Shubin Zhao, David Soergel, Cho-Jui Hsieh, Irene Cai, Shariq Iqbal, Martin Sundermeyer, Zhe Chen, Elie Bursztein, Chaitanya Malaviya, Fadi Biadsy, Prakash Shroff, Inderjit Dhillon, Tejasi Latkar, Chris Dyer, Hannah Forbes, Massimo Nicosia, Vitaly Nikolaev, Somer Greene, Marin Georgiev, Pidong Wang, Nina Martin, Hanie Sedghi, John Zhang, Praseem Banzal, Doug Fritz, Vikram Rao, Xuezhi Wang, Jiageng Zhang, Viorica Patraucean, Dayou Du, Igor Mordatch, Ivan Jurin, Lewis Liu, Ayush Dubey, Abhi Mohan, Janek Nowakowski, Vlad-Doru Ion, Nan Wei, Reiko Tojo, Maria Abi Raad, Drew A. Hudson, Vaishakh Keshava, Shubham Agrawal, Kevin Ramirez, Zhichun Wu, Hoang Nguyen, Ji Liu, Madhavi Sewak, Bryce Petrini, DongHyun Choi, Ivan Philips, Ziyue Wang, Ioana Bica, Ankush Garg, Jarek Wilkiewicz, Priyanka Agrawal, Xiaowei Li, Danhao Guo, Emily Xue, Naseer Shaik, Andrew Leach, Sadh MNM Khan, Julia Wiesinger, Sammy Jerome, Abhishek Chakladar, Alek Wenjiao Wang, Tina Ornduff, Folake Abu, Alireza Ghaffarkhah, Marcus Wainwright, Mario Cortes, Frederick Liu, Joshua Maynez, Slav Petrov, Yonghui Wu, Demis Hassabis, Koray Kavukcuoglu, Jeffrey Dean, Oriol Vinyals",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05530"" target=""_blank"">2403.05530</a>",,2025-12-03 22:39:25
Uplift Modeling for Target User Attacks on Recommender Systems,"Wenjie Wang, Changsheng Wang, Fuli Feng, Wentao Shi, Daizong Ding, Tat-Seng Chua",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02692"" target=""_blank"">2403.02692</a>",,2025-12-03 22:39:25
Prepared for the Worst: A Learning-Based Adversarial Attack for Resilience Analysis of the ICP Algorithm,"Ziyu Zhang, Johann Laconte, Daniil Lisus, Timothy D. Barfoot",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05666"" target=""_blank"">2403.05666</a>",,2025-12-03 22:39:25
One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models,"Lin Li, Haoyan Guan, Jianing Qiu, Michael Spratling",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01849"" target=""_blank"">2403.01849</a>","<a href=""https://github.com/TreeLLi/APT"" target=""_blank"">TreeLLi</a>",2025-12-03 22:39:25
COMMIT: Certifying Robustness of Multi-Sensor Fusion Systems against Semantic Attacks,"Zijian Huang, Wenda Chu, Linyi Li, Chejian Xu, Bo Li",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02329"" target=""_blank"">2403.02329</a>",,2025-12-03 22:39:25
Inf2Guard: An Information-Theoretic Framework for Learning Privacy-Preserving Representations against Inference Attacks,"Sayedeh Leila Noorbakhsh, Binghui Zhang, Yuan Hong, Binghui Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02116"" target=""_blank"">2403.02116</a>",,2025-12-03 22:39:25
BSDP: Brain-inspired Streaming Dual-level Perturbations for Online Open World Object Detection,"Yu Chen, Liyan Ma, Liping Jing, Jian Yu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02637"" target=""_blank"">2403.02637</a>",,2025-12-03 22:39:25
Mirage: Defense against CrossPath Attacks in Software Defined Networks,"Shariq Murtuza, Krishna Asawa",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02172"" target=""_blank"">2403.02172</a>",,2025-12-03 22:39:25
Bayesian Uncertainty Estimation by Hamiltonian Monte Carlo: Applications to Cardiac MRI Segmentation,"Yidong Zhao, Joao Tourais, Iain Pierce, Christian Nitsche, Thomas A. Treibel, Sebastian Weingärtner, Artur M. Schweidtmann, Qian Tao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02311"" target=""_blank"">2403.02311</a>",,2025-12-03 22:39:25
GuardT2I: Defending Text-to-Image Models from Adversarial Prompts,"Yijun Yang, Ruiyuan Gao, Xiao Yang, Jianyuan Zhong, Qiang Xu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01446"" target=""_blank"">2403.01446</a>","<a href=""https://github.com/cure-lab/GuardT2I"" target=""_blank"">cure-lab</a>",2025-12-03 22:39:25
SAR-AE-SFP: SAR Imagery Adversarial Example in Real Physics domain with Target Scattering Feature Parameters,"Jiahao Cui, Jiale Duan, Binyan Luo, Hang Cao, Wang Guo, Haifeng Li",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01210"" target=""_blank"">2403.01210</a>",,2025-12-03 22:39:25
Inexact Unlearning Needs More Careful Evaluations to Avoid a False Sense of Privacy,"Jamie Hayes, Ilia Shumailov, Eleni Triantafillou, Amr Khalifa, Nicolas Papernot",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01218"" target=""_blank"">2403.01218</a>",,2025-12-03 22:39:25
Breaking Down the Defenses: A Comparative Survey of Attacks on Large Language Models,"Arijit Ghosh Chowdhury, Md Mofijul Islam, Vaibhav Kumar, Faysal Hossain Shezan, Vaibhav Kumar, Vinija Jain, Aman Chadha",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04786"" target=""_blank"">2403.04786</a>",,2025-12-03 22:39:25
AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks,"Yifan Zeng, Yiran Wu, Xiao Zhang, Huazheng Wang, Qingyun Wu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04783"" target=""_blank"">2403.04783</a>","<a href=""https://github.com/XHMY/AutoDefense"" target=""_blank"">XHMY</a>",2025-12-03 22:39:25
Adversarial Testing for Visual Grounding via Image-Aware Property Reduction,"Zhiyuan Chang, Mingyang Li, Junjie Wang, Cheng Li, Boyu Wu, Fanjiang Xu, Qing Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01118"" target=""_blank"">2403.01118</a>",,2025-12-03 22:39:25
Query Recovery from Easy to Hard: Jigsaw Attack against SSE,"Hao Nie, Wei Wang, Peng Xu, Xianglong Zhang, Laurence T. Yang, Kaitai Liang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01155"" target=""_blank"">2403.01155</a>",,2025-12-03 22:39:25
Accelerating Greedy Coordinate Gradient via Probe Sampling,"Yiran Zhao, Wenyue Zheng, Tianle Cai, Xuan Long Do, Kenji Kawaguchi, Anirudh Goyal, Michael Shieh",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01251"" target=""_blank"">2403.01251</a>",,2025-12-03 22:39:25
Robust Deep Reinforcement Learning Through Adversarial Attacks and Training : A Survey,"Lucas Schott, Josephine Delas, Hatem Hajri, Elies Gherbi, Reda Yaich, Nora Boulahia-Cuppens, Frederic Cuppens, Sylvain Lamprier",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.00420"" target=""_blank"">2403.00420</a>",,2025-12-03 22:39:25
Resilience of Entropy Model in Distributed Neural Networks,"Milin Zhang, Mohammad Abdi, Shahriar Rifat, Francesco Restuccia",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.00942"" target=""_blank"">2403.00942</a>",,2025-12-03 22:39:25
Attacking Delay-based PUFs with Minimal Adversary Model,"Hongming Fei, Owen Millwood, Prosanta Gope, Jack Miskelly, Biplab Sikdar",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.00464"" target=""_blank"">2403.00464</a>",,2025-12-03 22:39:25
On Robustness and Generalization of ML-Based Congestion Predictors to Valid and Imperceptible Perturbations,"Chester Holtz, Yucheng Wang, Chung-Kuan Cheng, Bill Lin",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.00103"" target=""_blank"">2403.00103</a>",,2025-12-03 22:39:25
Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes,"Xiaomeng Hu, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.00867"" target=""_blank"">2403.00867</a>",,2025-12-03 22:39:25
Evaluating Robustness of Generative Search Engine on Adversarial Factual Questions,"Xuming Hu, Xiaochuan Li, Junzhe Chen, Yinghui Li, Yangning Li, Xiaoguang Li, Yasheng Wang, Qun Liu, Lijie Wen, Philip S. Yu, Zhijiang Guo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12077"" target=""_blank"">2403.12077</a>",,2025-12-03 22:39:25
Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models,"Zachary Horvitz, Jingru Chen, Rahul Aditya, Harshvardhan Srivastava, Robert West, Zhou Yu, Kathleen McKeown",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.00794"" target=""_blank"">2403.00794</a>",,2025-12-03 22:39:25
Adversarial Nibbler: An Open Red-Teaming Method for Identifying Diverse Harms in Text-to-Image Generation,"Jessica Quaye, Alicia Parrish, Oana Inel, Charvi Rastogi, Hannah Rose Kirk, Minsuk Kahng, Liemt Erin van, Max Bartolo, Jess Tsang, Justin White, Nathan Clement, Rafael Mosquera, Juan Ciro, Vijay Janapa Reddi, Lora Aroyo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12075"" target=""_blank"">2403.12075</a>",,2025-12-03 22:39:25
Adversarially Robust Deepfake Detection via Adversarial Feature Similarity Learning,Sarwar Khan,arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.08806"" target=""_blank"">2403.08806</a>",,2025-12-03 22:39:25
Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A Pilot Study,"Chenguang Wang, Ruoxi Jia, Xin Liu, Dawn Song",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10499"" target=""_blank"">2403.10499</a>",,2025-12-03 22:39:25
Improving the Robustness of Object Detection and Classification AI models against Adversarial Patch Attacks,"Roie Kazoom, Raz Birman, Ofer Hadar",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12988"" target=""_blank"">2403.12988</a>",,2025-12-03 22:39:25
Robustness Bounds on the Successful Adversarial Examples: Theory and Practice,"Hiroaki Maeshima, Akira Otsuka",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.01896"" target=""_blank"">2403.01896</a>",,2025-12-03 22:39:25
Adversarial Sparse Teacher: Defense Against Distillation-Based Model Stealing Attacks Using Adversarial Examples,"Eda Yilmaz, Hacer Yalim Keles",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05181"" target=""_blank"">2403.05181</a>",,2025-12-03 22:39:25
XAI-Based Detection of Adversarial Attacks on Deepfake Detectors,"Ben Pinhasov, Raz Lapid, Rony Ohayon, Moshe Sipper, Yehudit Aperstein",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02955"" target=""_blank"">2403.02955</a>",,2025-12-03 22:39:25
EVD4UAV: An Altitude-Sensitive Benchmark to Evade Vehicle Detection in UAV,"Huiming Sun, Jiacheng Guo, Zibo Meng, Tianyun Zhang, Jianwu Fang, Yuewei Lin, Hongkai Yu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05422"" target=""_blank"">2403.05422</a>",,2025-12-03 22:39:25
The Impact of Quantization on the Robustness of Transformer-based Text Classifiers,"Seyed Parsa Neshaei, Yasaman Boreshban, Gholamreza Ghassem-Sani, Seyed Abolghasem Mirroshandel",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05365"" target=""_blank"">2403.05365</a>",,2025-12-03 22:39:25
Speech Robust Bench: A Robustness Benchmark For Speech Recognition,"Muhammad A. Shah, David Solans Noguero, Mikko A. Heikkila, Bhiksha Raj, Nicolas Kourtellis",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.07937"" target=""_blank"">2403.07937</a>",,2025-12-03 22:39:25
Defending Against Unforeseen Failure Modes with Latent Adversarial Training,"Stephen Casper, Lennart Schulze, Oam Patel, Dylan Hadfield-Menell",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.05030"" target=""_blank"">2403.05030</a>",,2025-12-03 22:39:25
Fooling Neural Networks for Motion Forecasting via Adversarial Attacks,"Edgar Medina, Leyong Loh",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04954"" target=""_blank"">2403.04954</a>",,2025-12-03 22:39:25
Automatic and Universal Prompt Injection Attacks against Large Language Models,"Xiaogeng Liu, Zhiyuan Yu, Yizhe Zhang, Ning Zhang, Chaowei Xiao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04957"" target=""_blank"">2403.04957</a>",,2025-12-03 22:39:25
ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes,"Hashmat Shadab Malik, Muhammad Huzaifa, Muzammal Naseer, Salman Khan, Fahad Shahbaz Khan",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04701"" target=""_blank"">2403.04701</a>","<a href=""https://github.com/Muhammad-Huzaifaa/ObjectCompose"" target=""_blank"">Muhammad-Huzaifaa</a>",2025-12-03 22:39:25
Cell reprogramming design by transfer learning of functional transcriptional networks,"Thomas P. Wytock, Adilson E. Motter",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04837"" target=""_blank"">2403.04837</a>",,2025-12-03 22:39:25
Towards Robustness Analysis of E-Commerce Ranking System,"Ningfei Wang, Yupin Huang, Han Cheng, Jiri Gesi, Xiaojie Wang, Vivek Mittal",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04257"" target=""_blank"">2403.04257</a>",,2025-12-03 22:39:25
Adversarial Infrared Geometry: Using Geometry to Perform Adversarial Attack against Infrared Pedestrian Detectors,Kalibinuer Tiliwalidi,arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.03674"" target=""_blank"">2403.03674</a>",,2025-12-03 22:39:25
Improving Adversarial Training using Vulnerability-Aware Perturbation Budget,"Olukorede Fakorede, Modeste Atsague, Jin Tian",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04070"" target=""_blank"">2403.04070</a>",,2025-12-03 22:39:25
Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability,"Rajdeep Haldar, Yue Xing, Qifan Song",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.03967"" target=""_blank"">2403.03967</a>",,2025-12-03 22:39:25
Belief-Enriched Pessimistic Q-Learning against Adversarial State Perturbations,"Xiaolin Sun, Zizhan Zheng",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.04050"" target=""_blank"">2403.04050</a>","<a href=""https://github.com/SliencerX/Belief-enriched-robust-Q-learning"" target=""_blank"">SliencerX</a>",2025-12-03 22:39:25
On the Effectiveness of Distillation in Mitigating Backdoors in Pre-trained Encoder,"Tingxu Han, Shenghan Huang, Ziqi Ding, Weisong Sun, Yebo Feng, Chunrong Fang, Jun Li, Hanwei Qian, Cong Wu, Quanjun Zhang, Yang Liu, Zhenyu Chen",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.03846"" target=""_blank"">2403.03846</a>",,2025-12-03 22:39:25
Verified Training for Counterfactual Explanation Robustness under Data Shift,"Anna P. Meyer, Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.03773"" target=""_blank"">2403.03773</a>",,2025-12-03 22:39:25
Towards Robust Federated Learning via Logits Calibration on Non-IID Data,"Yu Qiao, Apurba Adhikary, Chaoning Zhang, Choong Seon Hong",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02803"" target=""_blank"">2403.02803</a>",,2025-12-03 22:39:25
Mitigating Label Flipping Attacks in Malicious URL Detectors Using Ensemble Trees,"Ehsan Nowroozi, Nada Jadalla, Samaneh Ghelichkhani, Alireza Jolfaei",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02995"" target=""_blank"">2403.02995</a>",,2025-12-03 22:39:25
Minimum Topology Attacks for Graph Neural Networks,"Mengmei Zhang, Xiao Wang, Chuan Shi, Lingjuan Lyu, Tianchi Yang, Junping Du",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02723"" target=""_blank"">2403.02723</a>",,2025-12-03 22:39:25
Federated Learning Under Attack: Exposing Vulnerabilities through Data Poisoning Attacks in Computer Networks,"Ehsan Nowroozi, Imran Haider, Rahim Taheri, Mauro Conti",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02983"" target=""_blank"">2403.02983</a>",,2025-12-03 22:39:25
A general approach to enhance the survivability of backdoor attacks by decision path coupling,"Yufei Zhao, Dingji Wang, Bihuan Chen, Ziqian Chen, Xin Peng",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02950"" target=""_blank"">2403.02950</a>",,2025-12-03 22:39:25
Robust Federated Learning Mitigates Client-side Training Data Distribution Inference Attacks,"Yichang Xu, Ming Yin, Minghong Fang, Neil Zhenqiang Gong",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.03149"" target=""_blank"">2403.03149</a>",,2025-12-03 22:39:25
FLGuard: Byzantine-Robust Federated Learning via Ensemble of Contrastive Models,"Younghan Lee, Yungi Cho, Woorim Han, Ho Bae, Yunheung Paek",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02846"" target=""_blank"">2403.02846</a>","<a href=""https://github.com/201younghanlee/FLGuard"" target=""_blank"">201younghanlee</a>",2025-12-03 22:39:25
InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents,"Qiusi Zhan, Zhixiang Liang, Zifan Ying, Daniel Kang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.02691"" target=""_blank"">2403.02691</a>","<a href=""https://github.com/uiuc-kang-lab/InjecAgent"" target=""_blank"">uiuc-kang-lab</a>",2025-12-03 22:39:25
Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency,"Soumyadeep Pal, Yuguang Yao, Ren Wang, Bingquan Shen, Sijia Liu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10717"" target=""_blank"">2403.10717</a>","<a href=""https://github.com/OPTML-Group/BackdoorMSPC"" target=""_blank"">OPTML-Group</a>",2025-12-03 22:39:25
"Not Just Change the Labels, Learn the Features: Watermarking Deep Neural Networks with Multi-View Data","Yuxuan Li, Sarthak Kumar Maharana, Yunhui Guo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10663"" target=""_blank"">2403.10663</a>",,2025-12-03 22:39:25
DataCook: Crafting Anti-Adversarial Examples for Healthcare Data Copyright Protection,"Sihan Shang, Jiancheng Yang, Zhenglong Sun, Pascal Fua",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.17755"" target=""_blank"">2403.17755</a>","<a href=""https://github.com/MedMNIST/DataCook"" target=""_blank"">MedMNIST</a>",2025-12-03 22:39:25
Ensemble Adversarial Defense via Integration of Multiple Dispersed Low Curvature Models,"Kaikang Zhao, Xi Chen, Wei Huang, Liuxin Ding, Xianglong Kong, Fan Zhang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16405"" target=""_blank"">2403.16405</a>",,2025-12-03 22:39:25
Leak and Learn: An Attacker's Cookbook to Train Using Leaked Data from Federated Learning,"Joshua C. Zhao, Ahaan Dabholkar, Atul Sharma, Saurabh Bagchi",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18144"" target=""_blank"">2403.18144</a>",,2025-12-03 22:39:25
Exploring LLMs as a Source of Targeted Synthetic Textual Data to Minimize High Confidence Misclassifications,"Philip Lippmann, Matthijs Spaan, Jie Yang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.17860"" target=""_blank"">2403.17860</a>",,2025-12-03 22:39:25
$\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on Prompt-based Language Models,"Yue Xu, Wenjie Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16432"" target=""_blank"">2403.16432</a>","<a href=""https://github.com/SavannahXu79/LinkPrompt"" target=""_blank"">SavannahXu79</a>",2025-12-03 22:39:25
Physical 3D Adversarial Attacks against Monocular Depth Estimation in Autonomous Driving,"Junhao Zheng, Chenhao Lin, Jiahao Sun, Zhengyu Zhao, Qian Li, Chao Shen",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.17301"" target=""_blank"">2403.17301</a>",,2025-12-03 22:39:25
The Anatomy of Adversarial Attacks: Concept-based XAI Dissection,"Georgii Mikriukov, Gesina Schwalbe, Franz Motzkus, Korinna Bade",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16782"" target=""_blank"">2403.16782</a>",,2025-12-03 22:39:25
DeepKnowledge: Generalisation-Driven Deep Learning Testing,"Sondess Missaoui, Simos Gerasimou, Nikolaos Matragkas",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16768"" target=""_blank"">2403.16768</a>",,2025-12-03 22:39:25
Revealing Vulnerabilities of Neural Networks in Parameter Learning and Defense Against Explanation-Aware Backdoors,"Md Abdul Kadir, GowthamKrishna Addluri, Daniel Sonntag",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16569"" target=""_blank"">2403.16569</a>",,2025-12-03 22:39:25
LOTUS: Evasive and Resilient Backdoor Attacks through Sub-Partitioning,"Siyuan Cheng, Guanhong Tao, Yingqi Liu, Guangyu Shen, Shengwei An, Shiwei Feng, Xiangzhe Xu, Kaiyuan Zhang, Shiqing Ma, Xiangyu Zhang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.17188"" target=""_blank"">2403.17188</a>","<a href=""https://github.com/Megum1/LOTUS"" target=""_blank"">Megum1</a>",2025-12-03 22:39:25
Model-less Is the Best Model: Generating Pure Code Implementations to Replace On-Device DL Models,"Mingyi Zhou, Xiang Gao, Pei Liu, John Grundy, Chunyang Chen, Xiao Chen, Li Li",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16479"" target=""_blank"">2403.16479</a>",,2025-12-03 22:39:25
Subspace Defense: Discarding Adversarial Perturbations by Learning a Subspace for Clean Signals,"Rui Zheng, Yuhao Zhou, Zhiheng Xi, Tao Gui, Qi Zhang, Xuanjing Huang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16176"" target=""_blank"">2403.16176</a>",,2025-12-03 22:39:25
Robust Diffusion Models for Adversarial Purification,"Guang Lin, Zerui Tao, Jianhai Zhang, Toshihisa Tanaka, Qibin Zhao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16067"" target=""_blank"">2403.16067</a>",,2025-12-03 22:39:25
Unlearning Backdoor Threats: Enhancing Backdoor Defense in Multimodal Contrastive Learning via Local Token Unlearning,"Siyuan Liang, Kuanrong Liu, Jiajun Gong, Jiawei Liang, Yuan Xun, Ee-Chien Chang, Xiaochun Cao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16257"" target=""_blank"">2403.16257</a>",,2025-12-03 22:39:25
Reversible Jump Attack to Textual Classifiers with Modification Reduction,"Mingze Ni, Zhensu Sun, Wei Liu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14731"" target=""_blank"">2403.14731</a>",,2025-12-03 22:39:25
Rumor Detection with a novel graph neural network approach,"Tianrui Liu, Qi Cai, Changxin Xu, Bo Hong, Fanghao Ni, Yuxin Qiao, Tsungwei Yang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16206"" target=""_blank"">2403.16206</a>",,2025-12-03 22:39:25
Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion,"Hossein Souri, Arpit Bansal, Hamid Kazemi, Liam Fowl, Aniruddha Saha, Jonas Geiping, Andrew Gordon Wilson, Rama Chellappa, Tom Goldstein, Micah Goldblum",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16365"" target=""_blank"">2403.16365</a>","<a href=""https://github.com/hsouri/GDP"" target=""_blank"">hsouri</a>",2025-12-03 22:39:25
A General and Efficient Federated Split Learning with Pre-trained Image Transformers for Heterogeneous Data,"Yifan Shi, Yuhui Zhang, Ziyue Huang, Xiaofeng Yang, Li Shen, Wei Chen, Xueqian Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.16050"" target=""_blank"">2403.16050</a>",,2025-12-03 22:39:25
Towards Adversarial Robustness And Backdoor Mitigation in SSL,"Aryan Satpathy, Nilaksh Singh, Dhruva Rajwade, Somesh Kumar",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15918"" target=""_blank"">2403.15918</a>",,2025-12-03 22:39:25
Adversarial Defense Teacher for Cross-Domain Object Detection under Poor Visibility Conditions,"Kaiwen Wang, Yinzhe Shen, Martin Lauer",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15786"" target=""_blank"">2403.15786</a>",,2025-12-03 22:39:25
Robust optimization for adversarial learning with finite sample complexity guarantees,"André Bertolace, Konstatinos Gatsis, Kostas Margellos",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15207"" target=""_blank"">2403.15207</a>",,2025-12-03 22:39:25
A Transfer Attack to Image Watermarks,"Yuepeng Hu, Zhengyuan Jiang, Moyang Guo, Neil Gong",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15365"" target=""_blank"">2403.15365</a>",,2025-12-03 22:39:25
From Hardware Fingerprint to Access Token: Enhancing the Authentication on IoT Devices,"Yue Xiao, Yi He, Xiaoli Zhang, Qian Wang, Renjie Xie, Kun Sun, Ke Xu, Qi Li",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15271"" target=""_blank"">2403.15271</a>",,2025-12-03 22:39:25
Clean-image Backdoor Attacks,"Dazhong Rong, Guoyao Yu, Shuheng Shen, Xinyi Fu, Peng Qian, Jianhai Chen, Qinming He, Xing Fu, Weiqiang Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15010"" target=""_blank"">2403.15010</a>",,2025-12-03 22:39:25
Forward Learning for Gradient-based Black-box Saliency Map Generation,"Zeliang Zhang, Mingqian Feng, Jinyang Jiang, Rongyi Zhu, Yijie Peng, Chenliang Xu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15603"" target=""_blank"">2403.15603</a>",,2025-12-03 22:39:25
Diffusion Attack: Leveraging Stable Diffusion for Naturalistic Image Attacking,"Qianyu Guo, Jiaming Fu, Yawen Lu, Dongming Gan",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14778"" target=""_blank"">2403.14778</a>",,2025-12-03 22:39:25
Targeted Visualization of the Backbone of Encoder LLMs,"Isaac Roberts, Alexander Schulz, Luca Hermes, Barbara Hammer",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18872"" target=""_blank"">2403.18872</a>",,2025-12-03 22:39:25
Optimization-based Prompt Injection Attack to LLM-as-a-Judge,"Jiawen Shi, Zenghui Yuan, Yinuo Liu, Yue Huang, Pan Zhou, Lichao Sun, Neil Zhenqiang Gong",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.17710"" target=""_blank"">2403.17710</a>",,2025-12-03 22:39:25
Boosting Adversarial Training via Fisher-Rao Norm-based Regularization,"Xiangyu Yin, Wenjie Ruan",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.17520"" target=""_blank"">2403.17520</a>","<a href=""https://github.com/TrustAI/LOAT"" target=""_blank"">TrustAI</a>",2025-12-03 22:39:25
FaultGuard: A Generative Approach to Resilient Fault Prediction in Smart Electrical Grids,"Emad Efatinasab, Francesco Marchiori, Alessandro Brighente, Mirco Rampazzo, Mauro Conti",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.17494"" target=""_blank"">2403.17494</a>",,2025-12-03 22:39:25
Towards Understanding Dual BN In Hybrid Adversarial Training,"Chenshuang Zhang, Chaoning Zhang, Kang Zhang, Axi Niu, Junmo Kim, In So Kweon",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19150"" target=""_blank"">2403.19150</a>",,2025-12-03 22:39:25
Benchmarking the Robustness of Temporal Action Detection Models Against Temporal Corruptions,"Runhao Zeng, Xiaoyong Chen, Jiaming Liang, Huisi Wu, Guangzhong Cao, Yong Guo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.20254"" target=""_blank"">2403.20254</a>","<a href=""https://github.com/Alvin-Zeng/temporal-robustness-benchmark"" target=""_blank"">Alvin-Zeng</a>",2025-12-03 22:39:25
"Improving Adversarial Data Collection by Supporting Annotators: Lessons from GAHD, a German Hate Speech Dataset","Janis Goldzycher, Paul Röttger, Gerold Schneider",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19559"" target=""_blank"">2403.19559</a>","<a href=""https://github.com/jagol/gahd"" target=""_blank"">jagol</a>",2025-12-03 22:39:25
Leveraging Expert Input for Robust and Explainable AI-Assisted Lung Cancer Detection in Chest X-rays,"Amy Rafferty, Rishi Ramaesh, Ajitha Rajan",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19444"" target=""_blank"">2403.19444</a>",,2025-12-03 22:39:25
Securing Federated Learning with Control-Flow Attestation: A Novel Framework for Enhanced Integrity and Resilience against Adversarial Attacks,Zahir Alsulaimawi,arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10005"" target=""_blank"">2403.10005</a>",,2025-12-03 22:39:25
On the Robustness of LDP Protocols for Numerical Attributes under Data Poisoning Attacks,"Xiaoguang Li, Zitao Li, Ninghui Li, Wenhai Sun",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19510"" target=""_blank"">2403.19510</a>",,2025-12-03 22:39:25
Cross-Lingual Transfer Robustness to Lower-Resource Languages on Adversarial Datasets,"Shadi Manafi, Nikhil Krishnaswamy",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.20056"" target=""_blank"">2403.20056</a>",,2025-12-03 22:39:25
MedBN: Robust Test-Time Adaptation against Malicious Test Samples,"Hyejin Park, Jeongyeon Hwang, Sunung Mun, Sangdon Park, Jungseul Ok",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19326"" target=""_blank"">2403.19326</a>",,2025-12-03 22:39:25
Imperceptible Protection against Style Imitation from Diffusion Models,"Namhyuk Ahn, Wonhyuk Ahn, KiYoon Yoo, Daesik Kim, Seung-Hun Nam",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19254"" target=""_blank"">2403.19254</a>",,2025-12-03 22:39:25
Uncertainty-Aware SAR ATR: Defending Against Adversarial Attacks via Bayesian Neural Networks,"Tian Ye, Rajgopal Kannan, Viktor Prasanna, Carl Busart",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18318"" target=""_blank"">2403.18318</a>",,2025-12-03 22:39:25
CosalPure: Learning Concept from Group Images for Robust Co-Saliency Detection,"Jiayi Zhu, Qing Guo, Felix Juefei-Xu, Yihao Huang, Yang Liu, Geguang Pu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18554"" target=""_blank"">2403.18554</a>",,2025-12-03 22:39:25
MMCert: Provable Defense against Adversarial Attacks to Multi-modal Models,"Yanting Wang, Hongye Fu, Wei Zou, Jinyuan Jia",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19080"" target=""_blank"">2403.19080</a>",,2025-12-03 22:39:25
Bayesian Learned Models Can Detect Adversarial Malware For Free,"Bao Gia Doan, Dang Quang Nguyen, Paul Montague, Tamas Abraham, Vel Olivier De, Seyit Camtepe, Salil S. Kanhere, Ehsan Abbasnejad, Damith C. Ranasinghe",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18309"" target=""_blank"">2403.18309</a>",,2025-12-03 22:39:25
MisGUIDE : Defense Against Data-Free Deep Learning Model Extraction,"Mahendra Gurve, Sankar Behera, Satyadev Ahlawat, Yamuna Prasad",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18580"" target=""_blank"">2403.18580</a>",,2025-12-03 22:39:25
Towards Sustainable SecureML: Quantifying Carbon Footprint of Adversarial Machine Learning,"Syed Mhamudul Hasan, Abdur R. Shahid, Ahmed Imteaj",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.19009"" target=""_blank"">2403.19009</a>",,2025-12-03 22:39:25
Deep Learning for Robust and Explainable Models in Computer Vision,Mohammadreza Amirian,arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18674"" target=""_blank"">2403.18674</a>",,2025-12-03 22:39:25
SemRoDe: Macro Adversarial Training to Learn Representations That are Robust to Word-Level Attacks,"Brian Formento, Wenjie Feng, Chuan Sheng Foo, Luu Anh Tuan, See-Kiong Ng",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18423"" target=""_blank"">2403.18423</a>",,2025-12-03 22:39:25
Vulnerability Detection with Code Language Models: How Far Are We? (26%),"Yangruibo Ding, Yanjun Fu, Omniyyah Ibrahim, Chawin Sitawarin, Xinyun Chen, Basel Alomair, David Wagner, Baishakhi Ray, Yizheng Chen",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18624"" target=""_blank"">2403.18624</a>",,2025-12-03 22:39:25
Spikewhisper: Temporal Spike Backdoor Attacks on Federated Neuromorphic Learning over Low-power Devices,"Hanqing Fu, Gaolei Li, Jun Wu, Jianhua Li, Xi Lin, Kai Zhou, Yuchen Liu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18607"" target=""_blank"">2403.18607</a>",,2025-12-03 22:39:25
"Robustness and Visual Explanation for Black Box Image, Video, and ECG Signal Classification with Reinforcement Learning","Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad Mousavi, Vineet Gundecha, Avisek Naug, Sahand Ghorbanpour",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18985"" target=""_blank"">2403.18985</a>",,2025-12-03 22:39:25
The Impact of Uniform Inputs on Activation Sparsity and Energy-Latency Attacks in Computer Vision,"Andreas Müller, Erwin Quiring",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18587"" target=""_blank"">2403.18587</a>",,2025-12-03 22:39:25
Fact Checking Beyond Training Set,"Payam Karisani, Heng Ji",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18671"" target=""_blank"">2403.18671</a>",,2025-12-03 22:39:25
BAM: Box Abstraction Monitors for Real-time OoD Detection in Object Detection,"Changshun Wu, Weicheng He, Chih-Hong Cheng, Xiaowei Huang, Saddek Bensalem",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.18373"" target=""_blank"">2403.18373</a>",,2025-12-03 22:39:25
Few-Shot Adversarial Prompt Learning on Vision-Language Models,"Yiwei Zhou, Xiaobo Xia, Zhiwei Lin, Bo Han, Tongliang Liu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14774"" target=""_blank"">2403.14774</a>",,2025-12-03 22:39:25
The Impact of Prompts on Zero-Shot Detection of AI-Generated Text,"Kaito Taguchi, Yujie Gu, Kouichi Sakurai",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.20127"" target=""_blank"">2403.20127</a>","<a href=""https://github.com/kaito25atugich/Detector"" target=""_blank"">kaito25atugich</a>",2025-12-03 22:39:25
Improving Robustness to Model Inversion Attacks via Sparse Coding Architectures,"Sayanton V. Dibbo, Adam Breuer, Juston Moore, Michael Teti",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14772"" target=""_blank"">2403.14772</a>",,2025-12-03 22:39:25
CBR - Boosting Adaptive Classification By Retrieval of Encrypted Network Traffic with Out-of-distribution,"Amir Lukach, Ran Dubin, Amit Dvir, Chen Hajaj",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11206"" target=""_blank"">2403.11206</a>",,2025-12-03 22:39:25
Electioneering the Network: Dynamic Multi-Step Adversarial Attacks for Community Canvassing,"Saurabh Sharma, Ambuj SIngh",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12399"" target=""_blank"">2403.12399</a>","<a href=""https://github.com/saurabhsharma1993/mac"" target=""_blank"">saurabhsharma1993</a>",2025-12-03 22:39:25
Advancing Time Series Classification with Multimodal Language Modeling,"Mingyue Cheng, Yiheng Chen, Qi Liu, Zhiding Liu, Yucong Luo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12371"" target=""_blank"">2403.12371</a>",,2025-12-03 22:39:25
Low-Cost Privacy-Preserving Decentralized Learning,"Sayan Biswas, Davide Frey, Romaric Gaudel, Anne-Marie Kermarrec, Dimitri Lerévérend, Rafael Pires, Rishi Sharma, François Taïani",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11795"" target=""_blank"">2403.11795</a>",,2025-12-03 22:39:25
Defense Against Adversarial Attacks on No-Reference Image Quality Models with Gradient Norm Regularization,"Yujia Liu, Chenxi Yang, Dingquan Li, Jianhao Ding, Tingting Jiang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11397"" target=""_blank"">2403.11397</a>",,2025-12-03 22:39:25
A Modified Word Saliency-Based Adversarial Attack on Text Classification Models,"Hetvi Waghela, Sneha Rakshit, Jaydip Sen",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11297"" target=""_blank"">2403.11297</a>",,2025-12-03 22:39:25
Robust Overfitting Does Matter: Test-Time Adversarial Purification With FGSM,"Linyu Tang, Lei Zhang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11448"" target=""_blank"">2403.11448</a>",,2025-12-03 22:39:25
Forging the Forger: An Attempt to Improve Authorship Verification via Data Augmentation,"Silvia Corbara, Alejandro Moreo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11265"" target=""_blank"">2403.11265</a>",,2025-12-03 22:39:25
RobustSentEmbed: Robust Sentence Embeddings Using Adversarial Self-Supervised Contrastive Learning,"Javad Rafiei Asl, Prajwal Panzade, Eduardo Blanco, Daniel Takabi, Zhipeng Cai",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11082"" target=""_blank"">2403.11082</a>",,2025-12-03 22:39:25
COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits,"Mintong Kang, Nezihe Merve Gürel, Linyi Li, Bo Li",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11348"" target=""_blank"">2403.11348</a>",,2025-12-03 22:39:25
A Dual-Tier Adaptive One-Class Classification IDS for Emerging Cyberthreats,"Md. Ashraf Uddin, Sunil Aryal, Mohamed Reda Bouadjenek, Muna Al-Hawawreh, Md. Alamin Talukder",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13010"" target=""_blank"">2403.13010</a>",,2025-12-03 22:39:25
Hierarchical Classification for Intrusion Detection System: Effective Design and Empirical Analysis,"Md. Ashraf Uddin, Sunil Aryal, Mohamed Reda Bouadjenek, Muna Al-Hawawreh, Md. Alamin Talukder",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13013"" target=""_blank"">2403.13013</a>",,2025-12-03 22:39:25
Pencil: Private and Extensible Collaborative Learning without the Non-Colluding Assumption,"Xuanqi Liu, Zhuotao Liu, Qi Li, Ke Xu, Mingwei Xu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11166"" target=""_blank"">2403.11166</a>",,2025-12-03 22:39:25
Impart: An Imperceptible and Effective Label-Specific Backdoor Attack,"Jingke Zhao, Zan Wang, Yongwei Wang, Lanjun Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13017"" target=""_blank"">2403.13017</a>",,2025-12-03 22:39:25
Securely Fine-tuning Pre-trained Encoders Against Adversarial Examples,"Ziqi Zhou, Minghui Li, Wei Liu, Shengshan Hu, Yechao Zhang, Wei Wan, Lulu Xue, Leo Yu Zhang, Dezhong Yang, Hai Jin",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10801"" target=""_blank"">2403.10801</a>",,2025-12-03 22:39:25
Understanding Robustness of Visual State Space Models for Image Classification,"Chengbin Du, Yanxi Li, Chang Xu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10935"" target=""_blank"">2403.10935</a>",,2025-12-03 22:39:25
Improving Adversarial Transferability of Visual-Language Pre-training Models through Collaborative Multimodal Interaction,"Jiyuan Fu, Zhaoyu Chen, Kaixun Jiang, Haijing Guo, Jiafeng Wang, Shuyong Gao, Wenqiang Zhang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10883"" target=""_blank"">2403.10883</a>",,2025-12-03 22:39:25
Edge Private Graph Neural Networks with Singular Value Perturbation,"Tingting Tang, Yue Niu, Salman Avestimehr, Murali Annavaram",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10995"" target=""_blank"">2403.10995</a>",,2025-12-03 22:39:25
Benchmarking Adversarial Robustness of Image Shadow Removal with Shadow-adaptive Attacks,"Chong Wang, Yi Yu, Lanqing Guo, Bihan Wen",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10076"" target=""_blank"">2403.10076</a>",,2025-12-03 22:39:25
Towards Non-Adversarial Algorithmic Recourse,"Tobias Leemann, Martin Pawelczyk, Bardh Prenkaj, Gjergji Kasneci",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10330"" target=""_blank"">2403.10330</a>",,2025-12-03 22:39:25
Adversary-Robust Graph-Based Learning of WSIs,"Saba Heidari Gheshlaghi, Milan Aryal, Nasim Yahyasoltani, Masoud Ganji",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14489"" target=""_blank"">2403.14489</a>",,2025-12-03 22:39:25
Introducing Adaptive Continuous Adversarial Training (ACAT) to Enhance ML Robustness,"Mohamed elShehaby, Aditya Kotha, Ashraf Matrawy",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10461"" target=""_blank"">2403.10461</a>",,2025-12-03 22:39:25
Revisiting Adversarial Training under Long-Tailed Distributions,"Xinli Yue, Ningping Mou, Qian Wang, Lingchen Zhao",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10073"" target=""_blank"">2403.10073</a>","<a href=""https://github.com/NISPLab/AT-BSL"" target=""_blank"">NISPLab</a>",2025-12-03 22:39:25
Towards Adversarially Robust Dataset Distillation by Curvature Regularization,"Eric Xue, Yijiang Li, Haoyang Liu, Peiran Wang, Yifan Shen, Haohan Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10045"" target=""_blank"">2403.10045</a>",,2025-12-03 22:39:25
Interactive Trimming against Evasive Online Data Manipulation Attacks: A Game-Theoretic Approach,"Yue Fu, Qingqing Ye, Rong Du, Haibo Hu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10313"" target=""_blank"">2403.10313</a>",,2025-12-03 22:39:25
SSAP: A Shape-Sensitive Adversarial Patch for Comprehensive Disruption of Monocular Depth Estimation in Autonomous Navigation Applications,"Amira Guesmi, Muhammad Abdullah Hanif, Ihsen Alouani, Bassem Ouni, Muhammad Shafique",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11515"" target=""_blank"">2403.11515</a>",,2025-12-03 22:39:25
Time-Frequency Jointed Imperceptible Adversarial Attack to Brainprint Recognition with Deep Learning Models,"Hangjie Yi, Yuhang Ming, Dongjun Liu, Wanzeng Kong",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.10021"" target=""_blank"">2403.10021</a>",,2025-12-03 22:39:25
Problem space structural adversarial attacks for Network Intrusion Detection Systems based on Graph Neural Networks,"Andrea Venturi, Dario Stabili, Mirco Marchetti",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11830"" target=""_blank"">2403.11830</a>",,2025-12-03 22:39:25
"Threats, Attacks, and Defenses in Machine Unlearning: A Survey","Ziyao Liu, Huanyi Ye, Chen Chen, Kwok-Yan Lam",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13682"" target=""_blank"">2403.13682</a>",,2025-12-03 22:39:25
FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based LLMs,"Jinmin Li, Kuofeng Gao, Yang Bai, Jingyun Zhang, Shu-tao Xia, Yisen Wang",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13507"" target=""_blank"">2403.13507</a>","<a href=""https://github.com/THU-Kingmin/FMM-Attack"" target=""_blank"">THU-Kingmin</a>",2025-12-03 22:39:25
Certified Human Trajectory Prediction,"Mohammadhossein Bahari, Saeed Saadatnejad, Amirhossein Askari Farsangi, Seyed-Mohsen Moosavi-Dezfooli, Alexandre Alahi",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13778"" target=""_blank"">2403.13778</a>","<a href=""https://s-attack.github.io/"" target=""_blank"">s-attack.github.io</a>",2025-12-03 22:39:25
Invisible Backdoor Attack Through Singular Value Decomposition,"Wenmin Chen, Xiaowei Xu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13018"" target=""_blank"">2403.13018</a>",,2025-12-03 22:39:25
Capsule Neural Networks as Noise Stabilizer for Time Series Data,"Soyeon Kim, Jihyeon Seong, Hyunkyung Han, Jaesik Choi",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13867"" target=""_blank"">2403.13867</a>",,2025-12-03 22:39:25
DD-RobustBench: An Adversarial Robustness Benchmark for Dataset Distillation,"Yifan Wu, Jiawei Du, Ping Liu, Yuewei Lin, Wenqing Cheng, Wei Xu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13322"" target=""_blank"">2403.13322</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defenses in Automated Control Systems: A Comprehensive Benchmark,"Vitaliy Pozdnyakov, Aleksandr Kovalenko, Ilya Makarov, Mikhail Drobyshevskiy, Kirill Lukyanov",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13502"" target=""_blank"">2403.13502</a>",,2025-12-03 22:39:25
Have You Poisoned My Data? Defending Neural Networks against Data Poisoning,"Gaspari Fabio De, Dorjan Hitaj, Luigi V. Mancini",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13523"" target=""_blank"">2403.13523</a>",,2025-12-03 22:39:25
Defending Against Indirect Prompt Injection Attacks With Spotlighting,"Keegan Hines, Gary Lopez, Matthew Hall, Federico Zarfati, Yonatan Zunger, Emre Kiciman",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14720"" target=""_blank"">2403.14720</a>",,2025-12-03 22:39:25
Don't be a Fool: Pooling Strategies in Offensive Language Detection from User-Intended Adversarial Attacks,"Seunguk Yu, Juhwan Choi, Youngbin Kim",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.15467"" target=""_blank"">2403.15467</a>",,2025-12-03 22:39:25
BadEdit: Backdooring large language models by model editing,"Yanzhou Li, Tianlin Li, Kangjie Chen, Jian Zhang, Shangqing Liu, Wenhan Wang, Tianwei Zhang, Yang Liu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13355"" target=""_blank"">2403.13355</a>",,2025-12-03 22:39:25
Teacher-Student Training for Debiasing: General Permutation Debiasing for Large Language Models,"Adian Liusie, Yassir Fathullah, Mark J. F. Gales",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13590"" target=""_blank"">2403.13590</a>",,2025-12-03 22:39:25
Safeguarding Medical Image Segmentation Datasets against Unauthorized Training via Contour- and Texture-Aware Perturbations,"Xun Lin, Yi Yu, Song Xia, Jue Jiang, Haoran Wang, Zitong Yu, Yizhong Liu, Ying Fu, Shuai Wang, Wenzhong Tang, Alex Kot",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.14250"" target=""_blank"">2403.14250</a>",,2025-12-03 22:39:25
As Firm As Their Foundations: Can open-sourced foundation models be used to create adversarial examples for downstream tasks? (99%),"Anjun Hu, Jindong Gu, Francesco Pinto, Konstantinos Kamnitsas, Philip Torr",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12693"" target=""_blank"">2403.12693</a>",,2025-12-03 22:39:25
Boosting Transferability in Vision-Language Attacks via Diversification along the Intersection Region of Adversarial Trajectory,"Sensen Gao, Xiaojun Jia, Xuhong Ren, Ivor Tsang, Qing Guo",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12445"" target=""_blank"">2403.12445</a>",,2025-12-03 22:39:25
Certified Robustness to Clean-Label Poisoning Using Diffusion Denoising,"Sanghyun Hong, Nicholas Carlini, Alexey Kurakin",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11981"" target=""_blank"">2403.11981</a>",,2025-12-03 22:39:25
LocalStyleFool: Regional Video Style Transfer Attack Using Segment Anything Model,"Yuxin Cao, Jinghao Li, Xi Xiao, Derui Wang, Minhui Xue, Hao Ge, Wei Liu, Guangwu Hu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11656"" target=""_blank"">2403.11656</a>",,2025-12-03 22:39:25
"SSCAE -- Semantic, Syntactic, and Context-aware natural language Adversarial Examples generator","Javad Rafiei Asl, Mohammad H. Rafiei, Manar Alohaly, Daniel Takabi",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.11833"" target=""_blank"">2403.11833</a>",,2025-12-03 22:39:25
Discover and Mitigate Multiple Biased Subgroups in Image Classifiers,"Zeliang Zhang, Mingqian Feng, Zhiheng Li, Chenliang Xu",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12777"" target=""_blank"">2403.12777</a>","<a href=""https://github.com/ZhangAIPI/DIM"" target=""_blank"">ZhangAIPI</a>",2025-12-03 22:39:25
"Robust NAS under adversarial training: benchmark, theory, and beyond","Yongtao Wu, Fanghui Liu, Carl-Johann Simon-Gabriel, Grigorios G Chrysos, Volkan Cevher",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13134"" target=""_blank"">2403.13134</a>",,2025-12-03 22:39:25
RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content,"Zhuowen Yuan, Zidi Xiong, Yi Zeng, Ning Yu, Ruoxi Jia, Dawn Song, Bo Li",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13031"" target=""_blank"">2403.13031</a>",,2025-12-03 22:39:25
Resilience in Online Federated Learning: Mitigating Model-Poisoning Attacks via Partial Sharing,"Ehsan Lari, Reza Arablouei, Vinay Chakravarthi Gogineni, Stefan Werner",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13108"" target=""_blank"">2403.13108</a>",,2025-12-03 22:39:25
Marlin: Knowledge-Driven Analysis of Provenance Graphs for Efficient and Robust Detection of Cyber Attacks,"Zhenyuan Li, Yangyang Wei, Xiangmin Shen, Lingzhi Wang, Yan Chen, Haitao Xu, Shouling Ji, Fan Zhang, Liang Hou, Wenmao Liu, Xuhong Zhang, Jianwei Ying",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.12541"" target=""_blank"">2403.12541</a>",,2025-12-03 22:39:25
ADAPT to Robustify Prompt Tuning Vision Transformers,"Masih Eskandar, Tooba Imtiaz, Zifeng Wang, Jennifer Dy",arXiv,2024-03,"<a href=""http://arxiv.org/abs/2403.13196"" target=""_blank"">2403.13196</a>",,2025-12-03 22:39:25
Accuracy of TextFooler black box adversarial attacks on 01 loss sign activation neural network ensemble,"Yunzhe Xue, Usman Roshan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07347"" target=""_blank"">2402.07347</a>","<a href=""https://github.com/zero-one-loss/wordcnn01"" target=""_blank"">zero-one-loss</a>",2025-12-03 22:39:25
Whispers in the Machine: Confidentiality in LLM-integrated Systems,"Jonathan Evertz, Merlin Chlosta, Lea Schönherr, Thorsten Eisenhofer",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06922"" target=""_blank"">2402.06922</a>",,2025-12-03 22:39:25
Architectural Neural Backdoors from First Principles,"Harry Langford, Ilia Shumailov, Yiren Zhao, Robert Mullins, Nicolas Papernot",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06957"" target=""_blank"">2402.06957</a>",,2025-12-03 22:39:25
A Random Ensemble of Encrypted Vision Transformers for Adversarially Robust Defense,"Ryota Iijima, Sayaka Shiota, Hitoshi Kiya",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07183"" target=""_blank"">2402.07183</a>",,2025-12-03 22:39:25
Anomaly Unveiled: Securing Image Classification against Adversarial Patch Attacks,"Nandish Chattopadhyay, Amira Guesmi, Muhammad Shafique",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06249"" target=""_blank"">2402.06249</a>",,2025-12-03 22:39:25
Pixel Sentence Representation Learning,"Chenghao Xiao, Zhuoxu Huang, Danlu Chen, G Thomas Hudson, Yizhi Li, Haoran Duan, Chenghua Lin, Jie Fu, Jungong Han, Noura Al Moubayed",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08183"" target=""_blank"">2402.08183</a>","<a href=""https://github.com/gowitheflow-1998/Pixel-Linguist"" target=""_blank"">gowitheflow-1998</a>",2025-12-03 22:39:25
The SkipSponge Attack: Sponge Weight Poisoning of Deep Neural Networks,"Jona te Lintelo, Stefanos Koffas, Stjepan Picek",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06357"" target=""_blank"">2402.06357</a>",,2025-12-03 22:39:25
Fight Back Against Jailbreaking via Prompt Adversarial Tuning,"Yichuan Mo, Yuji Wang, Zeming Wei, Yisen Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06255"" target=""_blank"">2402.06255</a>","<a href=""https://github.com/PKU-ML/PAT"" target=""_blank"">PKU-ML</a>",2025-12-03 22:39:25
RAMP: Boosting Adversarial Robustness Against Multiple $l_p$ Perturbations,"Enyi Jiang, Gagandeep Singh",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06827"" target=""_blank"">2402.06827</a>",,2025-12-03 22:39:25
Do Membership Inference Attacks Work on Large Language Models? (1%),"Michael Duan, Anshuman Suri, Niloofar Mireshghallah, Sewon Min, Weijia Shi, Luke Zettlemoyer, Yulia Tsvetkov, Yejin Choi, David Evans, Hannaneh Hajishirzi",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07841"" target=""_blank"">2402.07841</a>",,2025-12-03 22:39:25
System-level Analysis of Adversarial Attacks and Defenses on Intelligence in O-RAN based Cellular Networks,"Azuka Chiejina, Brian Kim, Kaushik Chowhdury, Vijay K. Shah",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06846"" target=""_blank"">2402.06846</a>",,2025-12-03 22:39:25
TETRIS: Towards Exploring the Robustness of Interactive Segmentation,"Andrey Moskalenko, Vlad Shakhuro, Anna Vorontsova, Anton Konushin, Anton Antonov, Alexander Krapukhin, Denis Shepelev, Konstantin Soshin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06132"" target=""_blank"">2402.06132</a>",,2025-12-03 22:39:25
Corruption Robust Offline Reinforcement Learning with Human Feedback,"Debmalya Mandal, Andi Nika, Parameswaran Kamalaruban, Adish Singla, Goran Radanović",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06734"" target=""_blank"">2402.06734</a>",,2025-12-03 22:39:25
Quantifying and Enhancing Multi-modal Robustness with Modality Preference,"Zequn Yang, Yake Wei, Ce Liang, Di Hu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06244"" target=""_blank"">2402.06244</a>",,2025-12-03 22:39:25
StruQ: Defending Against Prompt Injection with Structured Queries,"Sizhe Chen, Julien Piet, Chawin Sitawarin, David Wagner",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06363"" target=""_blank"">2402.06363</a>","<a href=""https://github.com/Sizhe-Chen/PromptInjectionDefense"" target=""_blank"">Sizhe-Chen</a>",2025-12-03 22:39:25
"FedMIA: An Effective Membership Inference Attack Exploiting ""All for One"" Principle in Federated Learning","Gongxi Zhu, Donghao Li, Hanlin Gu, Yuan Yao, Lixin Fan, Yuxing Han",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06289"" target=""_blank"">2402.06289</a>","<a href=""https://github.com/Liar-Mask/FedMIA"" target=""_blank"">Liar-Mask</a>",2025-12-03 22:39:25
Blockchain Bribing Attacks and the Efficacy of Counterincentives,"Dimitris Karakostas, Aggelos Kiayias, Thomas Zacharias",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06352"" target=""_blank"">2402.06352</a>",,2025-12-03 22:39:25
For Better or For Worse? Learning Minimum Variance Features With Label Augmentation,"Muthu Chidambaram, Rong Ge",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06855"" target=""_blank"">2402.06855</a>",,2025-12-03 22:39:25
JailbreakRadar: Comprehensive Assessment of Jailbreak Attacks Against LLMs,"Junjie Chu, Yugeng Liu, Ziqing Yang, Xinyue Shen, Michael Backes, Yang Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05668"" target=""_blank"">2402.05668</a>",,2025-12-03 22:39:25
Investigating White-Box Attacks for On-Device Models,"Mingyi Zhou, Xiang Gao, Jing Wu, Kui Liu, Hailong Sun, Li Li",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05493"" target=""_blank"">2402.05493</a>",,2025-12-03 22:39:25
Local Centrality Minimization with Quality Guarantees,"Atsushi Miyauchi, Lorenzo Severini, Francesco Bonchi",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07718"" target=""_blank"">2402.07718</a>",,2025-12-03 22:39:25
Linearizing Models for Efficient yet Robust Private Inference,"Sreetama Sarkar, Souvik Kundu, Peter A. Beerel",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05521"" target=""_blank"">2402.05521</a>",,2025-12-03 22:39:25
A High Dimensional Statistical Model for Adversarial Training: Geometry and Trade-Offs,"Kasimir Tanner, Matteo Vilucchio, Bruno Loureiro, Florent Krzakala",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05674"" target=""_blank"">2402.05674</a>",,2025-12-03 22:39:25
FedAA: A Reinforcement Learning Perspective on Adaptive Aggregation for Fair and Robust Federated Learning,"Jialuo He, Wei Chen, Xiaojin Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05541"" target=""_blank"">2402.05541</a>","<a href=""https://github.com/Gp1g/FedAA"" target=""_blank"">Gp1g</a>",2025-12-03 22:39:25
Adversarial Robustness Through Artifact Design,"Tsufit Shua, Liron David, Mahmood Sharif",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.04660"" target=""_blank"">2402.04660</a>",,2025-12-03 22:39:25
Breaking Free: How to Hack Safety Guardrails in Black-Box Diffusion Models! (98%),"Shashank Kotyan, Po-Yuan Mao, Pin-Yu Chen, Danilo Vasconcellos Vargas",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.04699"" target=""_blank"">2402.04699</a>","<a href=""https://shashankkotyan.github.io/EvoSeed"" target=""_blank"">shashankkotyan.github.io</a>",2025-12-03 22:39:25
Analyzing Adversarial Inputs in Deep Reinforcement Learning,"Davide Corsi, Guy Amir, Guy Katz, Alessandro Farinelli",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05284"" target=""_blank"">2402.05284</a>",,2025-12-03 22:39:25
NeuralSentinel: Safeguarding Neural Network Reliability and Trustworthiness,"Xabier Echeberria-Barrio, Mikel Gorricho, Selene Valencia, Francesco Zola",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07506"" target=""_blank"">2402.07506</a>",,2025-12-03 22:39:25
Understanding Deep Learning defenses Against Adversarial Examples Through Visualizations for Dynamic Risk Assessment,"Xabier Echeberria-Barrio, Amaia Gil-Lerchundi, Jon Egana-Zubia, Raul Orduna-Urrutia",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07496"" target=""_blank"">2402.07496</a>",,2025-12-03 22:39:25
Game of Trojans: Adaptive Adversaries Against Output-based Trojaned-Model Detectors,"Dinuka Sahabandu, Xiaojun Xu, Arezoo Rajabi, Luyao Niu, Bhaskar Ramasubramanian, Bo Li, Radha Poovendran",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08695"" target=""_blank"">2402.08695</a>",,2025-12-03 22:39:25
Enhancing Robustness of Indoor Robotic Navigation with Free-Space Segmentation Models Against Adversarial Attacks,"Qiyuan An, Christos Sevastopoulos, Fillia Makedon",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08763"" target=""_blank"">2402.08763</a>",,2025-12-03 22:39:25
Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications,"Boyi Wei, Kaixuan Huang, Yangsibo Huang, Tinghao Xie, Xiangyu Qi, Mengzhou Xia, Prateek Mittal, Mengdi Wang, Peter Henderson",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.05162"" target=""_blank"">2402.05162</a>",,2025-12-03 22:39:25
Review-Incorporated Model-Agnostic Profile Injection Attacks on Recommender Systems,"Shiyi Yang, Lina Yao, Chen Wang, Xiwei Xu, Liming Zhu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09023"" target=""_blank"">2402.09023</a>",,2025-12-03 22:39:25
Attacking Large Language Models with Projected Gradient Descent,"Simon Geisler, Tom Wollschläger, M. H. I. Abdalla, Johannes Gasteiger, Stephan Günnemann",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09154"" target=""_blank"">2402.09154</a>",,2025-12-03 22:39:25
Detecting Adversarial Spectrum Attacks via Distance to Decision Boundary Statistics,"Wenwei Zhao, Xiaowen Li, Shangqing Zhao, Jie Xu, Yao Liu, Zhuo Lu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08986"" target=""_blank"">2402.08986</a>",,2025-12-03 22:39:25
SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding,"Zhangchen Xu, Fengqing Jiang, Luyao Niu, Jinyuan Jia, Bill Yuchen Lin, Radha Poovendran",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08983"" target=""_blank"">2402.08983</a>",,2025-12-03 22:39:25
Reward Poisoning Attack Against Offline Reinforcement Learning,"Yinglun Xu, Rohan Gumaste, Gagandeep Singh",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09695"" target=""_blank"">2402.09695</a>",,2025-12-03 22:39:25
"Rapid Adoption, Hidden Risks: The Dual Impact of Large Language Model Customization","Rui Zhang, Hongwei Li, Rui Wen, Wenbo Jiang, Yuan Zhang, Michael Backes, Yun Shen, Yang Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09179"" target=""_blank"">2402.09179</a>",,2025-12-03 22:39:25
Ten Words Only Still Help: Improving Black-Box AI-Generated Text Detection via Proxy-Guided Efficient Re-Sampling,"Yuhui Shi, Qiang Sheng, Juan Cao, Hao Mi, Beizhe Hu, Danding Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09199"" target=""_blank"">2402.09199</a>",,2025-12-03 22:39:25
Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks,"Yixin Cheng, Markos Georgopoulos, Volkan Cevher, Grigorios G. Chrysos",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09177"" target=""_blank"">2402.09177</a>",,2025-12-03 22:39:25
Towards Robust Model-Based Reinforcement Learning Against Adversarial Corruption,"Chenlu Ye, Jiafan He, Quanquan Gu, Tong Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08991"" target=""_blank"">2402.08991</a>",,2025-12-03 22:39:25
Immediate generalisation in humans but a generalisation lag in deep neural networks$\unicode{x2014}$evidence for representational divergence? (1%),"Lukas S. Huber, Fred W. Mast, Felix A. Wichmann",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09303"" target=""_blank"">2402.09303</a>",,2025-12-03 22:39:25
Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues,"Zhiyuan Chang, Mingyang Li, Yi Liu, Junjie Wang, Qing Wang, Yang Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09091"" target=""_blank"">2402.09091</a>",,2025-12-03 22:39:25
Faster Repeated Evasion Attacks in Tree Ensembles,"Lorenzo Cascioli, Laurens Devos, Ondřej Kuželka, Jesse Davis",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08586"" target=""_blank"">2402.08586</a>",,2025-12-03 22:39:25
Generating Universal Adversarial Perturbations for Quantum Classifiers,"Gautham Anil, Vishnu Vinod, Apurva Narayan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08648"" target=""_blank"">2402.08648</a>",,2025-12-03 22:39:25
Data Reconstruction Attacks and Defenses: A Systematic Evaluation,"Sheng Liu, Zihan Wang, Yuxiao Chen, Qi Lei",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09478"" target=""_blank"">2402.09478</a>",,2025-12-03 22:39:25
Accelerated Smoothing: A Scalable Approach to Randomized Smoothing,"Devansh Bhardwaj, Kshitiz Kaushik, Sarthak Gupta",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07498"" target=""_blank"">2402.07498</a>",,2025-12-03 22:39:25
COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability,"Xingang Guo, Fangxu Yu, Huan Zhang, Lianhui Qin, Bin Hu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08679"" target=""_blank"">2402.08679</a>","<a href=""https://github.com/Yu-Fangxu/COLD-Attack"" target=""_blank"">Yu-Fangxu</a>",2025-12-03 22:39:25
Test-Time Backdoor Attacks on Multimodal Large Language Models,"Dong Lu, Tianyu Pang, Chao Du, Qian Liu, Xianjun Yang, Min Lin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08577"" target=""_blank"">2402.08577</a>","<a href=""https://sail-sg.github.io/AnyDoor/"" target=""_blank"">AnyDoor</a>",2025-12-03 22:39:25
Adversarially Robust Feature Learning for Breast Cancer Diagnosis,"Degan Hao, Dooman Arefan, Margarita Zuley, Wendie Berg, Shandong Wu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08768"" target=""_blank"">2402.08768</a>",,2025-12-03 22:39:25
Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast,"Xiangming Gu, Xiaosen Zheng, Tianyu Pang, Chao Du, Qian Liu, Ye Wang, Jing Jiang, Min Lin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08567"" target=""_blank"">2402.08567</a>","<a href=""https://sail-sg.github.io/Agent-Smith/"" target=""_blank"">Agent-Smith</a>",2025-12-03 22:39:25
Adaptive Hierarchical Certification for Segmentation using Randomized Smoothing,"Alaa Anani, Tobias Lorenz, Bernt Schiele, Mario Fritz",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08400"" target=""_blank"">2402.08400</a>","<a href=""https://github.com/AlaaAnani/adaptive-certify"" target=""_blank"">AlaaAnani</a>",2025-12-03 22:39:25
Feature Attribution with Necessity and Sufficiency via Dual-stage Perturbation Test for Causal Explanation,"Xuexin Chen, Ruichu Cai, Zhengting Huang, Yuxuan Zhu, Julien Horwood, Zhifeng Hao, Zijian Li, Jose Miguel Hernandez-Lobato",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08845"" target=""_blank"">2402.08845</a>",,2025-12-03 22:39:25
Topological safeguard for evasion attack interpreting the neural networks' behavior,"Xabier Echeberria-Barrio, Amaia Gil-Lerchundi, Iñigo Mendialdua, Raul Orduna-Urrutia",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07480"" target=""_blank"">2402.07480</a>",,2025-12-03 22:39:25
PoisonedRAG: Knowledge Corruption Attacks to Retrieval-Augmented Generation of Large Language Models,"Wei Zou, Runpeng Geng, Binghui Wang, Jinyuan Jia",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07867"" target=""_blank"">2402.07867</a>",,2025-12-03 22:39:25
Privacy-Preserving Gaze Data Streaming in Immersive Interactive Virtual Reality: Robustness and User Experience,"Ethan Wilson, Azim Ibragimov, Michael J. Proulx, Sai Deep Tetali, Kevin Butler, Eakta Jain",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07687"" target=""_blank"">2402.07687</a>",,2025-12-03 22:39:25
OrderBkd: Textual backdoor attack through repositioning,"Irina Alekseevskaia, Konstantin Arkhipenko",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07689"" target=""_blank"">2402.07689</a>","<a href=""https://github.com/alekseevskaia/OrderBkd"" target=""_blank"">alekseevskaia</a>",2025-12-03 22:39:25
Tighter Bounds on the Information Bottleneck with Application to Deep Learning,"Nir Weingarten, Zohar Yakhini, Moshe Butman, Ran Gilad-Bachrach",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.07639"" target=""_blank"">2402.07639</a>",,2025-12-03 22:39:25
Multi-Attribute Vision Transformers are Efficient and Robust Learners,"Hanan Gani, Nada Saadi, Noor Hussein, Karthik Nandakumar",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08070"" target=""_blank"">2402.08070</a>",,2025-12-03 22:39:25
Customizable Perturbation Synthesis for Robust SLAM Benchmarking,"Xiaohao Xu, Tianyi Zhang, Sibo Wang, Xiang Li, Yongqi Chen, Ye Li, Bhiksha Raj, Matthew Johnson-Roberson, Xiaonan Huang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08125"" target=""_blank"">2402.08125</a>","<a href=""https://github.com/Xiaohao-Xu/SLAM-under-Perturbation/"" target=""_blank"">SLAM-under-Perturbation</a>",2025-12-03 22:39:25
THE COLOSSEUM: A Benchmark for Evaluating Generalization for Robotic Manipulation,"Wilbert Pumacay, Ishika Singh, Jiafei Duan, Ranjay Krishna, Jesse Thomason, Dieter Fox",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.08191"" target=""_blank"">2402.08191</a>","<a href=""https://robot-colosseum.github.io/"" target=""_blank"">robot-colosseum.github.io</a>",2025-12-03 22:39:25
Universal Prompt Optimizer for Safe Text-to-Image Generation,"Zongyu Wu, Hongcheng Gao, Yueze Wang, Xiang Zhang, Suhang Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10882"" target=""_blank"">2402.10882</a>",,2025-12-03 22:39:25
What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement,"Xisen Jin, Xiang Ren",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01865"" target=""_blank"">2402.01865</a>",,2025-12-03 22:39:25
Boosting Adversarial Transferability across Model Genus by Deformation-Constrained Warping,"Qinliang Lin, Cheng Luo, Zenghao Niu, Xilin He, Weicheng Xie, Yuanbo Hou, Linlin Shen, Siyang Song",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03951"" target=""_blank"">2402.03951</a>","<a href=""https://github.com/LinQinLiang/DeCoWA"" target=""_blank"">LinQinLiang</a>",2025-12-03 22:39:25
Invisible Finger: Practical Electromagnetic Interference Attack on Touchscreen-based Electronic Devices,"Haoqi Shan, Boyi Zhang, Zihao Zhan, Dean Sullivan, Shuo Wang, Yier Jin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02227"" target=""_blank"">2402.02227</a>",,2025-12-03 22:39:25
Data Poisoning for In-context Learning,"Pengfei He, Han Xu, Yue Xing, Hui Liu, Makoto Yamada, Jiliang Tang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02160"" target=""_blank"">2402.02160</a>",,2025-12-03 22:39:25
HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack on Text,"Han Liu, Zhi Xu, Xiaotong Zhang, Feng Zhang, Fenglong Ma, Hongyang Chen, Hong Yu, Xianchao Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01806"" target=""_blank"">2402.01806</a>",,2025-12-03 22:39:25
$\sigma$-zero: Gradient-based Optimization of $\ell_0$-norm Adversarial Examples,"Antonio Emanuele Cinà, Francesco Villani, Maura Pintor, Lea Schönherr, Battista Biggio, Marcello Pelillo",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01879"" target=""_blank"">2402.01879</a>",,2025-12-03 22:39:25
STAA-Net: A Sparse and Transferable Adversarial Attack for Speech Emotion Recognition,"Yi Chang, Zhao Ren, Zixing Zhang, Xin Jing, Kun Qian, Xi Shao, Bin Hu, Tanja Schultz, Björn W. Schuller",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01227"" target=""_blank"">2402.01227</a>",,2025-12-03 22:39:25
Delving into Decision-based Black-box Attacks on Semantic Segmentation,"Zhaoyu Chen, Zhengyang Shan, Jingwen Chang, Kaixun Jiang, Dingkang Yang, Yiting Cheng, Wenqiang Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01220"" target=""_blank"">2402.01220</a>",,2025-12-03 22:39:25
Enhanced Urban Region Profiling with Adversarial Self-Supervised Learning for Robust Forecasting and Security,"Weiliang Chen, Qianqian Ren, Yong Liu, Jianguo Sun",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01163"" target=""_blank"">2402.01163</a>",,2025-12-03 22:39:25
SignSGD with Federated Defense: Harnessing Adversarial Attacks through Gradient Sign Decoding,"Chanho Park, Namyoon Lee",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01340"" target=""_blank"">2402.01340</a>",,2025-12-03 22:39:25
Unlearnable Examples For Time Series,"Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, James Bailey",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02028"" target=""_blank"">2402.02028</a>",,2025-12-03 22:39:25
Preference Poisoning Attacks on Reward Model Learning,"Junlin Wu, Jiongxiao Wang, Chaowei Xiao, Chenguang Wang, Ning Zhang, Yevgeniy Vorobeychik",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01920"" target=""_blank"">2402.01920</a>",,2025-12-03 22:39:25
Privacy-Preserving Distributed Learning for Residential Short-Term Load Forecasting,"Yi Dong, Yingjie Wang, Mariana Gama, Mustafa A. Mustafa, Geert Deconinck, Xiaowei Huang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01546"" target=""_blank"">2402.01546</a>",,2025-12-03 22:39:25
S2malloc: Statistically Secure Allocator for Use-After-Free Protection And More,"Ruizhe Wang, Meng Xu, N. Asokan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01894"" target=""_blank"">2402.01894</a>",,2025-12-03 22:39:25
Cheating Suffix: Targeted Attack to Text-To-Image Diffusion Models with Multi-Modal Priors,"Dingcheng Yang, Yang Bai, Xiaojun Jia, Yang Liu, Xiaochun Cao, Wenjian Yu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01369"" target=""_blank"">2402.01369</a>","<a href=""https://github.com/ydc123/MMP-Attack"" target=""_blank"">ydc123</a>",2025-12-03 22:39:25
Fundamental Challenges in Cybersecurity and a Philosophy of Vulnerability-Guided Hardening,Marcel Böhme,arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01944"" target=""_blank"">2402.01944</a>",,2025-12-03 22:39:25
PAL: Proxy-Guided Black-Box Attack on Large Language Models,"Chawin Sitawarin, Norman Mu, David Wagner, Alexandre Araujo",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09674"" target=""_blank"">2402.09674</a>","<a href=""https://github.com/chawins/pal"" target=""_blank"">chawins</a>",2025-12-03 22:39:25
Benchmarking Transferable Adversarial Attacks,"Zhibo Jin, Jiayu Zhang, Zhiyu Zhu, Huaming Chen",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00418"" target=""_blank"">2402.00418</a>","<a href=""https://github.com/KxPlaug/TAA-Bench"" target=""_blank"">KxPlaug</a>",2025-12-03 22:39:25
Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated Student Essay Detection,"Xinlin Peng, Ying Zhou, Ben He, Le Sun, Yingfei Sun",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00412"" target=""_blank"">2402.00412</a>",,2025-12-03 22:39:25
Double-Dip: Thwarting Label-Only Membership Inference Attacks with Transfer Learning and Randomization,"Arezoo Rajabi, Reeya Pimple, Aiswarya Janardhanan, Surudhi Asokraj, Bhaskar Ramasubramanian, Radha Poovendran",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01114"" target=""_blank"">2402.01114</a>",,2025-12-03 22:39:25
Vision-LLMs Can Fool Themselves with Self-Generated Typographic Attacks,"Maan Qraitem, Nazia Tasnim, Piotr Teterwak, Kate Saenko, Bryan A. Plummer",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00626"" target=""_blank"">2402.00626</a>","<a href=""https://github.com/mqraitem/Self-Gen-Typo-Attack"" target=""_blank"">mqraitem</a>",2025-12-03 22:39:25
Approximating Optimal Morphing Attacks using Template Inversion,"Laurent Colbois, Hatef Otroshi Shahreza, Sébastien Marcel",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00695"" target=""_blank"">2402.00695</a>",,2025-12-03 22:39:25
"Trustworthy Distributed AI Systems: Robustness, Privacy, and Governance","Wenqi Wei, Ling Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01096"" target=""_blank"">2402.01096</a>",,2025-12-03 22:39:25
Vaccine: Perturbation-aware Alignment for Large Language Models against Harmful Fine-tuning Attack,"Tiansheng Huang, Sihao Hu, Ling Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01109"" target=""_blank"">2402.01109</a>","<a href=""https://github.com/git-disl/Vaccine"" target=""_blank"">git-disl</a>",2025-12-03 22:39:25
algoXSSF: Detection and analysis of cross-site request forgery (XSRF) and cross-site scripting (XSS) attacks via Machine learning algorithms,"Naresh Kshetri, Dilip Kumar, James Hutson, Navneet Kaur, Omar Faruq Osama",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01012"" target=""_blank"">2402.01012</a>",,2025-12-03 22:39:25
Adversarial Quantum Machine Learning: An Information-Theoretic Generalization Analysis,"Petros Georgiou, Sharu Theresa Jose, Osvaldo Simeone",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00176"" target=""_blank"">2402.00176</a>",,2025-12-03 22:39:25
Invariance-powered Trustworthy Defense via Remove Then Restore,"Xiaowei Fu, Yuhang Zhou, Lina Ma, Lei Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00304"" target=""_blank"">2402.00304</a>",,2025-12-03 22:39:25
BrainLeaks: On the Privacy-Preserving Properties of Neuromorphic Architectures against Model Inversion Attacks,"Hamed Poursiami, Ihsen Alouani, Maryam Parsa",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00906"" target=""_blank"">2402.00906</a>",,2025-12-03 22:39:25
SpecFormer: Guarding Vision Transformer Robustness via Maximum Singular Value Penalization,"Xixu Hu, Runkai Zheng, Jindong Wang, Cheuk Hang Leung, Qi Wu, Xing Xie",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03317"" target=""_blank"">2402.03317</a>","<a href=""https://github.com/microsoft/robustlearn"" target=""_blank"">microsoft</a>",2025-12-03 22:39:25
Security and Privacy Challenges of Large Language Models: A Survey,"Badhan Chandra Das, M. Hadi Amini, Yanzhao Wu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00888"" target=""_blank"">2402.00888</a>",,2025-12-03 22:39:25
Robustness Assessment of a Runway Object Classifier for Safe Aircraft Taxiing,"Yizhak Elboher, Raya Elsaleh, Omri Isac, Mélanie Ducoffe, Audrey Galametz, Guillaume Povéda, Ryma Boumazouza, Noémie Cohen, Guy Katz",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.00035"" target=""_blank"">2402.00035</a>",,2025-12-03 22:39:25
Fluent dreaming for language models,"T. Ben Confirm Labs Thompson, Zygimantas Confirm Labs Straznickas, Michael Confirm Labs Sklar",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.01702"" target=""_blank"">2402.01702</a>","<a href=""https://github.com/Confirm-Solutions/dreamy"" target=""_blank"">Confirm-Solutions</a>",2025-12-03 22:39:25
Safety Fine-Tuning at (Almost) No Cost: A Baseline for Vision Large Language Models,"Yongshuo Zong, Ondrej Bohdal, Tingyang Yu, Yongxin Yang, Timothy Hospedales",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02207"" target=""_blank"">2402.02207</a>","<a href=""https://github.com/ys-zong/VLGuard"" target=""_blank"">ys-zong</a>",2025-12-03 22:39:25
Towards Optimal Adversarial Robust Q-learning with Bellman Infinity-error,"Haoran Li, Zicheng Zhang, Wang Luo, Congying Han, Yudong Hu, Tiande Guo, Shichen Liao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02165"" target=""_blank"">2402.02165</a>",,2025-12-03 22:39:25
SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent Reinforcement Learning Systems,"Oubo Ma, Yuwen Pu, Linkang Du, Yang Dai, Ruo Wang, Xiaolei Liu, Yingcai Wu, Shouling Ji",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03741"" target=""_blank"">2402.03741</a>",,2025-12-03 22:39:25
CEPA: Consensus Embedded Perturbation for Agnostic Detection and Inversion of Backdoors,"Guangmingmei Yang, Xi Li, Hang Wang, David J. Miller, George Kesidis",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02034"" target=""_blank"">2402.02034</a>",,2025-12-03 22:39:25
PAC-Bayesian Adversarially Robust Generalization Bounds for Graph Neural Network,"Tan Sun, Junhong Lin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.04038"" target=""_blank"">2402.04038</a>",,2025-12-03 22:39:25
Enhance DNN Adversarial Robustness and Efficiency via Injecting Noise to Non-Essential Neurons,"Zhenyu Liu, Garrett Gagnon, Swagath Venkataramani, Liu Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.04325"" target=""_blank"">2402.04325</a>",,2025-12-03 22:39:25
BotSSCL: Social Bot Detection with Self-Supervised Contrastive Learning,"Mohammad Majid Akhtar, Navid Shadman Bhuiyan, Rahat Masood, Muhammad Ikram, Salil S. Kanhere",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03740"" target=""_blank"">2402.03740</a>",,2025-12-03 22:39:25
Privacy Leakage on DNNs: A Survey of Model Inversion Attacks and Defenses,"Hao Fang, Yixiang Qiu, Hongyao Yu, Wenbo Yu, Jiawei Kong, Baoli Chong, Bin Chen, Xuan Wang, Shu-Tao Xia, Ke Xu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.04013"" target=""_blank"">2402.04013</a>",,2025-12-03 22:39:25
Studying Vulnerable Code Entities in R,"Zixiao Zhao, Millon Madhur Das, Fatemeh H. Fard",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.04421"" target=""_blank"">2402.04421</a>",,2025-12-03 22:39:25
DeMarking: A Defense for Network Flow Watermarking in Real-Time,"Yali Yuan, Jian Ge, Guang Cheng",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03760"" target=""_blank"">2402.03760</a>",,2025-12-03 22:39:25
HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal,"Mantas Mazeika, Long Phan, Xuwang Yin, Andy Zou, Zifan Wang, Norman Mu, Elham Sakhaee, Nathaniel Li, Steven Basart, Bo Li, David Forsyth, Dan Hendrycks",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.04249"" target=""_blank"">2402.04249</a>","<a href=""https://github.com/centerforaisafety/HarmBench"" target=""_blank"">centerforaisafety</a>",2025-12-03 22:39:25
A Generative Approach to Surrogate-based Black-box Attacks,"Raha Moraffah, Huan Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02732"" target=""_blank"">2402.02732</a>",,2025-12-03 22:39:25
Transcending Adversarial Perturbations: Manifold-Aided Adversarial Examples with Legitimate Semantics,"Shuai Li, Xiaoyu Jiang, Xiaoguang Ma",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03095"" target=""_blank"">2402.03095</a>","<a href=""https://github.com/shuaili1027/MAELS"" target=""_blank"">shuaili1027</a>",2025-12-03 22:39:25
Arabic Synonym BERT-based Adversarial Examples for Text Classification,"Norah Alshahrani, Saied Alshahrani, Esma Wali, Jeanna Matthews",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03477"" target=""_blank"">2402.03477</a>",,2025-12-03 22:39:25
Generalization Properties of Adversarial Training for $\ell_0$-Bounded Adversarial Attacks,"Payam Delgosha, Hamed Hassani, Ramtin Pedarsani",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03576"" target=""_blank"">2402.03576</a>",,2025-12-03 22:39:25
FoolSDEdit: Deceptively Steering Your Edits Towards Targeted Attribute-aware Distribution,"Qi Zhou, Dongxia Wang, Tianlin Li, Zhihong Xu, Yang Liu, Kui Ren, Wenhai Wang, Qing Guo",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03705"" target=""_blank"">2402.03705</a>",,2025-12-03 22:39:25
Time-Distributed Backdoor Attacks on Federated Spiking Learning,"Gorka Abad, Stjepan Picek, Aitor Urbieta",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02886"" target=""_blank"">2402.02886</a>",,2025-12-03 22:39:25
Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language Models,"Yuancheng Xu, Jiarui Yao, Manli Shu, Yanchao Sun, Zichu Wu, Ning Yu, Tom Goldstein, Furong Huang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06659"" target=""_blank"">2402.06659</a>","<a href=""https://github.com/umd-huang-lab/VLM-Poisoning"" target=""_blank"">umd-huang-lab</a>",2025-12-03 22:39:25
Partially Recentralization Softmax Loss for Vision-Language Models Robustness,"Hao Wang, Xin Zhang, Jinzhe Jiang, Yaqian Zhao, Chen Li",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03627"" target=""_blank"">2402.03627</a>",,2025-12-03 22:39:25
Organic or Diffused: Can We Distinguish Human Art from AI-generated Images? (31%),"Anna Yoo Jeong Ha, Josephine Passananti, Ronik Bhaskar, Shawn Shan, Reid Southen, Haitao Zheng, Ben Y. Zhao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03214"" target=""_blank"">2402.03214</a>",,2025-12-03 22:39:25
DisDet: Exploring Detectability of Backdoor Attack on Diffusion Models,"Yang Sui, Huy Phan, Jinqi Xiao, Tianfang Zhang, Zijie Tang, Cong Shi, Yan Wang, Yingying Chen, Bo Yuan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02739"" target=""_blank"">2402.02739</a>",,2025-12-03 22:39:25
FINEST: Stabilizing Recommendations by Rank-Preserving Fine-Tuning,"Sejoon Oh, Berk Ustun, Julian McAuley, Srijan Kumar",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.03481"" target=""_blank"">2402.03481</a>",,2025-12-03 22:39:25
PROSAC: Provably Safe Certification for Machine Learning Models under Adversarial Attacks,"Ziquan Liu, Zhuo Zhi, Ilija Bogunovic, Carsten Gerner-Beuerle, Miguel Rodrigues",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02629"" target=""_blank"">2402.02629</a>",,2025-12-03 22:39:25
Adversarial Text Purification: A Large Language Model Approach for Defense,"Raha Moraffah, Shubh Khandelwal, Amrita Bhattacharjee, Huan Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.06655"" target=""_blank"">2402.06655</a>",,2025-12-03 22:39:25
DeSparsify: Adversarial Attack Against Token Sparsification Mechanisms in Vision Transformers,"Oryan Yehezkel, Alon Zolfi, Amit Baras, Yuval Elovici, Asaf Shabtai",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02554"" target=""_blank"">2402.02554</a>",,2025-12-03 22:39:25
Exploiting Class Probabilities for Black-box Sentence-level Attacks,"Raha Moraffah, Huan Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02695"" target=""_blank"">2402.02695</a>",,2025-12-03 22:39:25
Evading Deep Learning-Based Malware Detectors via Obfuscation: A Deep Reinforcement Learning Approach,"Brian Etter, James Lee Hu, Mohammedreza Ebrahimi, Weifeng Li, Xin Li, Hsinchun Chen",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02600"" target=""_blank"">2402.02600</a>",,2025-12-03 22:39:25
Adversarial Data Augmentation for Robust Speaker Verification,"Zhenyu Zhou, Junhui Chen, Namin Wang, Lantian Li, Dong Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02699"" target=""_blank"">2402.02699</a>",,2025-12-03 22:39:25
Contrasting Adversarial Perturbations: The Space of Harmless Perturbations,"Lu Chen, Shaofeng Li, Benhao Huang, Fan Yang, Zheng Li, Jie Li, Yuan Luo",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02095"" target=""_blank"">2402.02095</a>",,2025-12-03 22:39:25
Evaluating the Robustness of Off-Road Autonomous Driving Segmentation against Adversarial Attacks: A Dataset-Centric analysis,"Pankaj Deoli, Rohit Kumar, Axel Vierling, Karsten Berns",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02154"" target=""_blank"">2402.02154</a>","<a href=""https://github.com/rohtkumar/adversarial_attacks_"" target=""_blank"">rohtkumar</a>",2025-12-03 22:39:25
Your Diffusion Model is Secretly a Certifiably Robust Classifier,"Huanran Chen, Yinpeng Dong, Shitong Shao, Zhongkai Hao, Xiao Yang, Hang Su, Jun Zhu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02316"" target=""_blank"">2402.02316</a>",,2025-12-03 22:39:25
MixedNUTS: Training-Free Accuracy-Robustness Balance via Nonlinearly Mixed Classifiers,"Yatong Bai, Mo Zhou, Vishal M. Patel, Somayeh Sojoudi",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02263"" target=""_blank"">2402.02263</a>",,2025-12-03 22:39:25
Analyzing Sentiment Polarity Reduction in News Presentation through Contextual Perturbation and Large Language Models,"Alapan Kuila, Somnath Jena, Sudeshna Sarkar, Partha Pratim Chakrabarti",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.02145"" target=""_blank"">2402.02145</a>",,2025-12-03 22:39:25
Only My Model On My Data: A Privacy Preserving Approach Protecting one Model and Deceiving Unauthorized Black-Box Models,"Weiheng Chai, Brian Testa, Huantao Ren, Asif Salekin, Senem Velipasalar",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09316"" target=""_blank"">2402.09316</a>",,2025-12-03 22:39:25
Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning,"Shuai Zhao, Leilei Gan, Luu Anh Tuan, Jie Fu, Lingjuan Lyu, Meihuizi Jia, Jinming Wen",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12168"" target=""_blank"">2402.12168</a>",,2025-12-03 22:39:25
Exploring the Adversarial Capabilities of Large Language Models,"Lukas Struppek, Minh Hieu Le, Dominik Hintersdorf, Kristian Kersting",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09132"" target=""_blank"">2402.09132</a>",,2025-12-03 22:39:25
Edge Detectors Can Make Deep Convolutional Neural Networks More Robust,"Jin Ding, Jie-Chao Zhao, Yong-Zhi Sun, Ping Tan, Jia-Wei Wang, Ji-En Ma, You-Tong Fang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16479"" target=""_blank"">2402.16479</a>",,2025-12-03 22:39:25
Defending LLMs against Jailbreaking Attacks via Backtranslation,"Yihan Wang, Zhouxing Shi, Andrew Bai, Cho-Jui Hsieh",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16459"" target=""_blank"">2402.16459</a>",,2025-12-03 22:39:25
Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts,"Mikayel Samvelyan, Sharath Chandra Raparthy, Andrei Lupu, Eric Hambro, Aram H. Markosyan, Manish Bhatt, Yuning Mao, Minqi Jiang, Jack Parker-Holder, Jakob Foerster, Tim Rocktäschel, Roberta Raileanu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16822"" target=""_blank"">2402.16822</a>",,2025-12-03 22:39:25
Pandora's White-Box: Precise Training Data Detection and Extraction in Large Language Models,"Jeffrey G. Wang, Jason Wang, Marvin Li, Seth Neel",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17012"" target=""_blank"">2402.17012</a>",,2025-12-03 22:39:25
WIPI: A New Web Threat for LLM-Driven Web Agents,"Fangzhou Wu, Shutong Wu, Yulong Cao, Chaowei Xiao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16965"" target=""_blank"">2402.16965</a>",,2025-12-03 22:39:25
RoCoIns: Enhancing Robustness of Large Language Models through Code-Style Instructions,"Yuansen Zhang, Xiao Wang, Zhiheng Xi, Han Xia, Tao Gui, Qi Zhang, Xuanjing Huang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16431"" target=""_blank"">2402.16431</a>",,2025-12-03 22:39:25
An Innovative Information Theory-based Approach to Tackle and Enhance The Transparency in Phishing Detection,"Van Nguyen, Tingmin Wu, Xingliang Yuan, Marthie Grobler, Surya Nepal, Carsten Rudolph",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17092"" target=""_blank"">2402.17092</a>",,2025-12-03 22:39:25
From Noise to Clarity: Unraveling the Adversarial Suffix of Large Language Model Attacks via Translation of Text Embeddings,"Hao Wang, Hao Li, Minlie Huang, Lei Sha",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16006"" target=""_blank"">2402.16006</a>",,2025-12-03 22:39:25
An Adversarial Robustness Benchmark for Enterprise Network Intrusion Detection,"João Vitorino, Miguel Silva, Eva Maia, Isabel Praça",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16912"" target=""_blank"">2402.16912</a>",,2025-12-03 22:39:25
Defending Large Language Models against Jailbreak Attacks via Semantic Smoothing,"Jiabao Ji, Bairu Hou, Alexander Robey, George J. Pappas, Hamed Hassani, Yang Zhang, Eric Wong, Shiyu Chang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16192"" target=""_blank"">2402.16192</a>","<a href=""https://github.com/UCSB-NLP-Chang/SemanticSmooth"" target=""_blank"">UCSB-NLP-Chang</a>",2025-12-03 22:39:25
Adversarial-Robust Transfer Learning for Medical Imaging via Domain Assimilation,"Xiaohui Chen, Tie Luo",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16005"" target=""_blank"">2402.16005</a>",,2025-12-03 22:39:25
How Secure Are Large Language Models (LLMs) for Navigation in Urban Environments? (98%),"Congcong Wen, Jiazhao Liang, Shuaihang Yuan, Hao Huang, Geeta Chandra Raju Bethala, Yu-Shen Liu, Mengyu Wang, Anthony Tzes, Yi Fang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09546"" target=""_blank"">2402.09546</a>",,2025-12-03 22:39:25
m2mKD: Module-to-Module Knowledge Distillation for Modular Transformers,"Ka Man Lo, Yiming Liang, Wenyu Du, Yuantao Fan, Zili Wang, Wenhao Huang, Lei Ma, Jie Fu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16918"" target=""_blank"">2402.16918</a>","<a href=""https://github.com/kamanphoebe/m2mKD"" target=""_blank"">kamanphoebe</a>",2025-12-03 22:39:25
PRP: Propagating Universal Perturbations to Attack Large Language Model Guard-Rails,"Neal Mangaokar, Ashish Hooda, Jihye Choi, Shreyas Chandrashekaran, Kassem Fawaz, Somesh Jha, Atul Prakash",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15911"" target=""_blank"">2402.15911</a>",,2025-12-03 22:39:25
LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner: A Vision Paper,"Daoyuan Wu, Shuai Wang, Yang Liu, Ning Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15727"" target=""_blank"">2402.15727</a>",,2025-12-03 22:39:25
RAUCA: A Novel Physical Adversarial Attack on Vehicle Detectors via Robust and Accurate Camouflage Generation,"Jiawei Zhou, Linye Lyu, Daojing He, Yu Li",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15853"" target=""_blank"">2402.15853</a>",,2025-12-03 22:39:25
Towards Robust Image Stitching: An Adaptive Resistance Learning against Compatible Attacks,"Zhiying Jiang, Xingyuan Li, Jinyuan Liu, Xin Fan, Risheng Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15959"" target=""_blank"">2402.15959</a>","<a href=""https://github.com/Jzy2017/TRIS"" target=""_blank"">Jzy2017</a>",2025-12-03 22:39:25
Optimal Zero-Shot Detector for Multi-Armed Attacks,"Federica Granese, Marco Romanelli, Pablo Piantanida",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15808"" target=""_blank"">2402.15808</a>",,2025-12-03 22:39:25
Sparse MeZO: Less Parameters for Better Performance in Zeroth-Order LLM Fine-Tuning,"Yong Liu, Zirui Zhu, Chaoyu Gong, Minhao Cheng, Cho-Jui Hsieh, Yang You",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15751"" target=""_blank"">2402.15751</a>",,2025-12-03 22:39:25
Distilling Adversarial Robustness Using Heterogeneous Teachers,"Jieren Deng, Aaron Palmer, Rigel Mahmood, Ethan Rathbun, Jinbo Bi, Kaleel Mahmood, Derek Aguiar",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15586"" target=""_blank"">2402.15586</a>",,2025-12-03 22:39:25
Fast Adversarial Attacks on Language Models In One GPU Minute,"Vinu Sankar Sadasivan, Shoumik Saha, Gaurang Sriramanan, Priyatham Kattakinda, Atoosa Chegini, Soheil Feizi",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15570"" target=""_blank"">2402.15570</a>","<a href=""https://github.com/vinusankars/BEAST"" target=""_blank"">vinusankars</a>",2025-12-03 22:39:25
A Robust Defense against Adversarial Attacks on Deep Learning-based Malware Detectors via (De)Randomized Smoothing,"Daniel Gibert, Giulio Zizzo, Quan Le, Jordi Planes",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15267"" target=""_blank"">2402.15267</a>",,2025-12-03 22:39:25
ProTIP: Probabilistic Robustness Verification on Text-to-Image Diffusion Models against Stochastic Perturbation,"Yi Zhang, Yun Tang, Wenjie Ruan, Xiaowei Huang, Siddartha Khastgir, Paul Jennings, Xingyu Zhao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15429"" target=""_blank"">2402.15429</a>",,2025-12-03 22:39:25
On the Duality Between Sharpness-Aware Minimization and Adversarial Training,"Yihao Zhang, Hangzhou He, Jingyu Zhu, Huanran Chen, Yifei Wang, Zeming Wei",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15152"" target=""_blank"">2402.15152</a>","<a href=""https://github.com/weizeming/SAM_AT"" target=""_blank"">weizeming</a>",2025-12-03 22:39:25
Low-Frequency Black-Box Backdoor Attack via Evolutionary Algorithm,"Yanqi Qiao, Dazhuang Liu, Rui Wang, Kaitai Liang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15653"" target=""_blank"">2402.15653</a>",,2025-12-03 22:39:25
Deep Networks Always Grok and Here is Why,"Ahmed Imtiaz Humayun, Randall Balestriero, Richard Baraniuk",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15555"" target=""_blank"">2402.15555</a>",,2025-12-03 22:39:25
BSPA: Exploring Black-box Stealthy Prompt Attacks against Image Generators,"Yu Tian, Xiao Yang, Yinpeng Dong, Heming Yang, Hang Su, Jun Zhu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15218"" target=""_blank"">2402.15218</a>",,2025-12-03 22:39:25
Reinforcement Learning-Based Approaches for Enhancing Security and Resilience in Smart Control: A Survey on Attack and Defense Methods,Zheyu Zhang,arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15617"" target=""_blank"">2402.15617</a>",,2025-12-03 22:39:25
Break the Breakout: Reinventing LM Defense Against Jailbreak Attacks with Self-Refinement,"Heegyu Kim, Sehyun Yuk, Hyunsouk Cho",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15180"" target=""_blank"">2402.15180</a>",,2025-12-03 22:39:25
Prime+Retouch: When Cache is Locked and Leaked,"Jaehyuk Lee, Fan Sang, Taesoo Kim",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15425"" target=""_blank"">2402.15425</a>",,2025-12-03 22:39:25
Investigating Deep Watermark Security: An Adversarial Transferability Perspective,"Biqing Qi, Junqi Gao, Yiang Luo, Jianxing Liu, Ligang Wu, Bowen Zhou",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16397"" target=""_blank"">2402.16397</a>",,2025-12-03 22:39:25
Unveiling Vulnerability of Self-Attention,"Khai Jiet Liong, Hongqiu Wu, Hai Zhao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16470"" target=""_blank"">2402.16470</a>",,2025-12-03 22:39:25
SoK: Analyzing Adversarial Examples: A Framework to Study Adversary Knowledge,"Lucas Fenaux, Florian Kerschbaum",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14937"" target=""_blank"">2402.14937</a>",,2025-12-03 22:39:25
Adversarial Perturbations of Physical Signals,"Robert L. Bassett, Dellen Austin Van, Anthony P. Austin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17104"" target=""_blank"">2402.17104</a>",,2025-12-03 22:39:25
Unraveling Adversarial Examples against Speaker Identification -- Techniques for Attack Detection and Victim Model Classification,"Sonal Joshi, Thomas Thebaud, Jesús Villalba, Najim Dehak",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19355"" target=""_blank"">2402.19355</a>",,2025-12-03 22:39:25
How to Train your Antivirus: RL-based Hardening through the Problem-Space,"Jacopo Cortellazzi, Ilias Tsingenopoulos, Branislav Bošanský, Simone Aonzo, Davy Preuveneers, Wouter Joosen, Fabio Pierazzi, Lorenzo Cavallaro",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19027"" target=""_blank"">2402.19027</a>",,2025-12-03 22:39:25
Pointing out the Shortcomings of Relation Extraction Models with Semantically Motivated Adversarials,"Gennaro Nolano, Moritz Blum, Basil Ell, Philipp Cimiano",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19076"" target=""_blank"">2402.19076</a>",,2025-12-03 22:39:25
Assessing Visually-Continuous Corruption Robustness of Neural Networks Relative to Human Performance,"Huakun Shen, Boyue Caroline Hu, Krzysztof Czarnecki, Lina Marsso, Marsha Chechik",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19401"" target=""_blank"">2402.19401</a>",,2025-12-03 22:39:25
Verification of Neural Networks' Global Robustness,"Anan Kabaha, Dana Drachsler-Cohen",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19322"" target=""_blank"">2402.19322</a>",,2025-12-03 22:39:25
SynGhost: Imperceptible and Universal Task-agnostic Backdoor Attack in Pre-trained Language Models,"Pengzhou Cheng, Wei Du, Zongru Wu, Fengwei Zhang, Libo Chen, Gongshen Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18945"" target=""_blank"">2402.18945</a>",,2025-12-03 22:39:25
PRSA: Prompt Stealing Attacks against Real-World Prompt Services,"Yong Yang, Changjiang Li, Qingming Li, Oubo Ma, Haoyu Wang, Zonghui Wang, Yandong Gao, Wenzhi Chen, Shouling Ji",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19200"" target=""_blank"">2402.19200</a>",,2025-12-03 22:39:25
Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge,"Ansh Arora, Xuanli He, Maximilian Mozes, Srinibas Swain, Mark Dras, Qiongkai Xu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19334"" target=""_blank"">2402.19334</a>",,2025-12-03 22:39:25
Unveiling Typographic Deceptions: Insights of the Typographic Vulnerability in Large Vision-Language Model,"Hao Cheng, Erjia Xiao, Jindong Gu, Le Yang, Jinhao Duan, Jize Zhang, Jiahang Cao, Kaidi Xu, Renjing Xu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.19150"" target=""_blank"">2402.19150</a>","<a href=""https://github.com/ChaduCheng/TypoDeceptions"" target=""_blank"">ChaduCheng</a>",2025-12-03 22:39:25
"Enhancing the ""Immunity"" of Mixture-of-Experts Networks for Adversarial Defense","Qiao Han, yong huang, xinling Guo, Yiteng Zhai, Yu Qin, Yao Yang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18787"" target=""_blank"">2402.18787</a>",,2025-12-03 22:39:25
MPAT: Building Robust Deep Neural Networks against Textual Adversarial Attacks,"Fangyuan Zhang, Huichi Zhou, Shuangjiao Li, Hongtao Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18792"" target=""_blank"">2402.18792</a>",,2025-12-03 22:39:25
Catastrophic Overfitting: A Potential Blessing in Disguise,"Mengnan Zhao, Lihe Zhang, Yuqiu Kong, Baocai Yin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18211"" target=""_blank"">2402.18211</a>",,2025-12-03 22:39:25
Living-off-The-Land Reverse-Shell Detection by Informed Data Augmentation,"Dmitrijs Trizna, Luca Demetrio, Battista Biggio, Fabio Roli",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18329"" target=""_blank"">2402.18329</a>",,2025-12-03 22:39:25
A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems,"Fangzhou Wu, Ning Zhang, Somesh Jha, Patrick McDaniel, Chaowei Xiao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18649"" target=""_blank"">2402.18649</a>","<a href=""https://fzwark.github.io/LLM-System-Attack-Demo/"" target=""_blank"">LLM-System-Attack-Demo</a>",2025-12-03 22:39:25
Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction,"Tong Liu, Yingjie Zhang, Zhe Zhao, Yinpeng Dong, Guozhu Meng, Kai Chen",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18104"" target=""_blank"">2402.18104</a>",,2025-12-03 22:39:25
Out-of-Distribution Detection using Neural Activation Prior,"Weilin Wan, Weizhong Zhang, Cheng Jin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18162"" target=""_blank"">2402.18162</a>",,2025-12-03 22:39:25
Robustness-Congruent Adversarial Training for Secure Machine Learning Model Updates,"Daniele Angioni, Luca Demetrio, Maura Pintor, Luca Oneto, Davide Anguita, Battista Biggio, Fabio Roli",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17390"" target=""_blank"">2402.17390</a>",,2025-12-03 22:39:25
Extreme Miscalibration and the Illusion of Adversarial Robustness,"Vyas Raina, Samson Tan, Volkan Cevher, Aditya Rawal, Sheng Zha, George Karypis",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17509"" target=""_blank"">2402.17509</a>",,2025-12-03 22:39:25
Black-box Adversarial Attacks Against Image Quality Assessment Models,"Yu Ran, Ao-Xiang Zhang, Mingjie Li, Weixuan Tang, Yuan-Gen Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17533"" target=""_blank"">2402.17533</a>",,2025-12-03 22:39:25
Enhancing Tracking Robustness with Auxiliary Adversarial Defense Networks,"Zhewei Wu, Ruilong Yu, Qihe Liu, Shuying Cheng, Shilin Qiu, Shijie Zhou",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17976"" target=""_blank"">2402.17976</a>",,2025-12-03 22:39:25
LLM-Resistant Math Word Problem Generation via Adversarial Attacks,"Roy Xie, Chengxuan Huang, Junlin Wang, Bhuwan Dhingra",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17916"" target=""_blank"">2402.17916</a>",,2025-12-03 22:39:25
Breaking the Black-Box: Confidence-Guided Model Inversion Attack for Distribution Shift,"Xinhao Liu, Yingzhao Jiang, Zetao Lin",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18027"" target=""_blank"">2402.18027</a>",,2025-12-03 22:39:25
Model X-ray:Detecting Backdoored Models via Decision Boundary,"Yanghao Su, Jie Zhang, Ting Xu, Tianwei Zhang, Weiming Zhang, Nenghai Yu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17465"" target=""_blank"">2402.17465</a>",,2025-12-03 22:39:25
Towards Fairness-Aware Adversarial Learning,"Yanghao Zhang, Tianle Zhang, Ronghui Mu, Xiaowei Huang, Wenjie Ruan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17729"" target=""_blank"">2402.17729</a>",,2025-12-03 22:39:25
Time-Restricted Double-Spending Attack on PoW-based Blockchains,"Yiming Jiang, Jiangfan Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17223"" target=""_blank"">2402.17223</a>",,2025-12-03 22:39:25
Improving the JPEG-resistance of Adversarial Attacks on Face Recognition by Interpolation Smoothing,"Kefu Guo, Fengfan Zhou, Hefei Ling, Ping Li, Hui Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16586"" target=""_blank"">2402.16586</a>",,2025-12-03 22:39:25
Improving behavior based authentication against adversarial attack using XAI,"Dong Qin, George Amariucai, Daji Qiao, Yong Guan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16430"" target=""_blank"">2402.16430</a>",,2025-12-03 22:39:25
Adversarial example soups: averaging multiple adversarial examples improves transferability without increasing additional generation time,"Bo Yang, Hengwei Zhang, Chenwei Li, Jindong Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.18370"" target=""_blank"">2402.18370</a>",,2025-12-03 22:39:25
A Curious Case of Remarkable Resilience to Gradient Attacks via Fully Convolutional and Differentiable Front End with a Skip Connection,"Leonid Boytsov, Ameya Joshi, Filipe Condessa",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.17018"" target=""_blank"">2402.17018</a>",,2025-12-03 22:39:25
TREC: APT Tactic / Technique Recognition via Few-Shot Provenance Subgraph Learning,"Mingqi Lv, HongZhe Gao, Xuebo Qiu, Tieming Chen, Tiantian Zhu, Jinyin Chen, Shouling Ji",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.15147"" target=""_blank"">2402.15147</a>",,2025-12-03 22:39:25
DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM Jailbreakers,"Xirui Li, Ruochen Wang, Minhao Cheng, Tianyi Zhou, Cho-Jui Hsieh",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.16914"" target=""_blank"">2402.16914</a>",,2025-12-03 22:39:25
Rethinking Invariance Regularization in Adversarial Training to Improve Robustness-Accuracy Trade-off,"Futa Waseda, Ching-Chun Chang, Isao Echizen",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14648"" target=""_blank"">2402.14648</a>",,2025-12-03 22:39:25
VoltSchemer: Use Voltage Noise to Manipulate Your Wireless Charger,"Zihao Zhan, Yirui Yang, Haoqi Shan, Hanqiu Wang, Yier Jin, Shuo Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11423"" target=""_blank"">2402.11423</a>",,2025-12-03 22:39:25
Amplifying Training Data Exposure through Fine-Tuning with Pseudo-Labeled Memberships,"Myung Gyo Oh, Hong Eun Ahn, Leo Hyun Park, Taekyoung Kwon",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12189"" target=""_blank"">2402.12189</a>",,2025-12-03 22:39:25
Privacy-Preserving Low-Rank Adaptation for Latent Diffusion Models,"Zihao Luo, Xilie Xu, Feng Liu, Yun Sing Koh, Di Wang, Jingfeng Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11989"" target=""_blank"">2402.11989</a>","<a href=""https://github.com/WilliamLUO0/StablePrivateLoRA"" target=""_blank"">WilliamLUO0</a>",2025-12-03 22:39:25
A Curious Case of Searching for the Correlation between Training Data and Adversarial Robustness of Transformer Textual Models,"Cuong Dang, Dung D. Le, Thai Le",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11469"" target=""_blank"">2402.11469</a>","<a href=""https://github.com/CaptainCuong/RobustText_ACL2024"" target=""_blank"">CaptainCuong</a>",2025-12-03 22:39:25
Evaluating Adversarial Robustness of Low dose CT Recovery,"Kanchana Vaishnavi Gandikota, Paramanand Chandramouli, Hannah Droege, Michael Moeller",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11557"" target=""_blank"">2402.11557</a>",,2025-12-03 22:39:25
Evaluating Efficacy of Model Stealing Attacks and Defenses on Quantum Neural Networks,"Satwik Kundu, Debarshi Kundu, Swaroop Ghosh",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11687"" target=""_blank"">2402.11687</a>",,2025-12-03 22:39:25
The Effectiveness of Random Forgetting for Robust Generalization,"Vijaya Raghavan T Ramkumar, Bahram Zonooz, Elahe Arani",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11733"" target=""_blank"">2402.11733</a>",,2025-12-03 22:39:25
Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection,"Jiawei Liang, Siyuan Liang, Aishan Liu, Xiaojun Jia, Junhao Kuang, Xiaochun Cao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11473"" target=""_blank"">2402.11473</a>","<a href=""https://github.com/JWLiang007/PFF"" target=""_blank"">JWLiang007</a>",2025-12-03 22:39:25
Poisoning Federated Recommender Systems with Fake Users,"Ming Yin, Yichang Xu, Minghong Fang, Neil Zhenqiang Gong",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11637"" target=""_blank"">2402.11637</a>",,2025-12-03 22:39:25
SPML: A DSL for Defending Language Models Against Prompt Attacks,"Reshabh K Sharma, Vinayak Gupta, Dan Grossman",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11755"" target=""_blank"">2402.11755</a>","<a href=""https://prompt-compiler.github.io/SPML/"" target=""_blank"">SPML</a>",2025-12-03 22:39:25
Teacher as a Lenient Expert: Teacher-Agnostic Data-Free Knowledge Distillation,"Hyunjune Shin, Dong-Wan Choi",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12406"" target=""_blank"">2402.12406</a>",,2025-12-03 22:39:25
Maintaining Adversarial Robustness in Continuous Learning,"Xiaolei Ru, Xiaowei Cao, Zijia Liu, Jack Murdoch Moore, Xin-Ya Zhang, Xia Zhu, Wenjia Wei, Gang Yan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11196"" target=""_blank"">2402.11196</a>",,2025-12-03 22:39:25
Be Persistent: Towards a Unified Solution for Mitigating Shortcuts in Deep Learning,"Hadi M. Dolatabadi, Sarah M. Erfani, Christopher Leckie",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11237"" target=""_blank"">2402.11237</a>",,2025-12-03 22:39:25
Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents,"Wenkai Yang, Xiaohan Bi, Yankai Lin, Sishuo Chen, Jie Zhou, Xu Sun",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11208"" target=""_blank"">2402.11208</a>",,2025-12-03 22:39:25
DART: A Principled Approach to Adversarially Robust Unsupervised Domain Adaptation,"Yunjuan Wang, Hussein Hazimeh, Natalia Ponomareva, Alexey Kurakin, Ibrahim Hammoud, Raman Arora",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11120"" target=""_blank"">2402.11120</a>",,2025-12-03 22:39:25
Robust CLIP: Unsupervised Adversarial Fine-Tuning of Vision Embeddings for Robust Large Vision-Language Models,"Christian Schlarmann, Naman Deep Singh, Francesco Croce, Matthias Hein",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12336"" target=""_blank"">2402.12336</a>","<a href=""https://github.com/chs20/RobustVLM"" target=""_blank"">chs20</a>",2025-12-03 22:39:25
Theoretical Understanding of Learning from Adversarial Perturbations,"Soichiro Kumano, Hiroshi Kera, Toshihiko Yamasaki",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10470"" target=""_blank"">2402.10470</a>","<a href=""https://github.com/s-kumano/learning-from-adversarial-perturbations"" target=""_blank"">s-kumano</a>",2025-12-03 22:39:25
Assessing biomedical knowledge robustness in large language models by query-efficient sampling attacks,"R. Patrick Xian, Alex J. Lee, Satvik Lolla, Vincent Wang, Qiming Cui, Russell Ro, Reza Abbasi-Asl",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10527"" target=""_blank"">2402.10527</a>",,2025-12-03 22:39:25
Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning Meets Adversarial Images,"Zefeng Wang, Zhen Han, Shuo Chen, Fan Xue, Zifeng Ding, Xun Xiao, Volker Tresp, Philip Torr, Jindong Gu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14899"" target=""_blank"">2402.14899</a>",,2025-12-03 22:39:25
The AI Security Pyramid of Pain,"Chris M. Ward, Josh Harguess, Julia Tao, Daniel Christman, Paul Spicer, Mike Tan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11082"" target=""_blank"">2402.11082</a>",,2025-12-03 22:39:25
AIM: Automated Input Set Minimization for Metamorphic Security Testing,"Nazanin Bayati Chaleshtari, Yoann Marquer, Fabrizio Pastore, Lionel C. Briand",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10773"" target=""_blank"">2402.10773</a>",,2025-12-03 22:39:25
ToBlend: Token-Level Blending With an Ensemble of LLMs to Attack AI-Generated Text Detection,"Fan Huang, Haewoon Kwak, Jisun An",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11167"" target=""_blank"">2402.11167</a>",,2025-12-03 22:39:25
Camouflage is all you need: Evaluating and Enhancing Language Model Robustness Against Camouflage Adversarial Attacks,"Álvaro Huertas-García, Alejandro Martín, Javier Huertas-Tato, David Camacho",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.09874"" target=""_blank"">2402.09874</a>",,2025-12-03 22:39:25
On the Safety Concerns of Deploying LLMs/VLMs in Robotics: Highlighting the Risks and Vulnerabilities,"Xiyang Wu, Ruiqi Xian, Tianrui Guan, Jing Liang, Souradip Chakraborty, Fuxiao Liu, Brian Sadler, Dinesh Manocha, Amrit Singh Bedi",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10340"" target=""_blank"">2402.10340</a>",,2025-12-03 22:39:25
Backdoor Attack against One-Class Sequential Anomaly Detection Models,"He Cheng, Shuhan Yuan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10283"" target=""_blank"">2402.10283</a>",,2025-12-03 22:39:25
A Trembling House of Cards? Mapping Adversarial Attacks against Language Agents,"Lingbo Mo, Zeyi Liao, Boyuan Zheng, Yu Su, Chaowei Xiao, Huan Sun",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10196"" target=""_blank"">2402.10196</a>",,2025-12-03 22:39:25
FedRDF: A Robust and Dynamic Aggregation Function against Poisoning Attacks in Federated Learning,"Enrique Mármol Campos, Aurora González Vidal, José Luis Hernández Ramos, Antonio Skarmeta",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10082"" target=""_blank"">2402.10082</a>",,2025-12-03 22:39:25
Some Targets Are Harder to Identify than Others: Quantifying the Target-dependent Membership Leakage,"Achraf Azize, Debabrota Basu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10065"" target=""_blank"">2402.10065</a>",,2025-12-03 22:39:25
Quantum-Inspired Analysis of Neural Network Vulnerabilities: The Role of Conjugate Variables in System Attacks,"Jun-Jie Zhang, Deyu Meng",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.10983"" target=""_blank"">2402.10983</a>",,2025-12-03 22:39:25
Robustness and Exploration of Variational and Machine Learning Approaches to Inverse Problems: An Overview,"Alexander Auras, Kanchana Vaishnavi Gandikota, Hannah Droege, Michael Moeller",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12072"" target=""_blank"">2402.12072</a>",,2025-12-03 22:39:25
VQAttack: Transferable Adversarial Attacks on Visual Question Answering via Pre-trained Models,"Ziyi Yin, Muchao Ye, Tianrong Zhang, Jiaqi Wang, Han Liu, Jinghui Chen, Ting Wang, Fenglong Ma",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11083"" target=""_blank"">2402.11083</a>",,2025-12-03 22:39:25
Self-Guided Robust Graph Structure Refinement,"Yeonjun In, Kanghoon Yoon, Kibum Kim, Kijung Shin, Chanyoung Park",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11837"" target=""_blank"">2402.11837</a>","<a href=""https://github.com/yeonjun-in/torch-SG-GSR"" target=""_blank"">yeonjun-in</a>",2025-12-03 22:39:25
Round Trip Translation Defence against Large Language Model Jailbreaking Attacks,"Canaan Yung, Hadi Mohaghegh Dolatabadi, Sarah Erfani, Christopher Leckie",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13517"" target=""_blank"">2402.13517</a>","<a href=""https://github.com/Cancanxxx/Round_Trip_Translation_Defence"" target=""_blank"">Cancanxxx</a>",2025-12-03 22:39:25
AttackGNN: Red-Teaming GNNs in Hardware Security Using Reinforcement Learning,"Vasudev Gohil, Satwik Patnaik, Dileep Kalathil, Jeyavijayan Rajendran",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13946"" target=""_blank"">2402.13946</a>",,2025-12-03 22:39:25
A Simple and Yet Fairly Effective Defense for Graph Neural Networks,"Sofiane Ennadir, Yassine Abbahaddou, Johannes F. Lutzeyer, Michalis Vazirgiannis, Henrik Boström",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13987"" target=""_blank"">2402.13987</a>","<a href=""https://github.com/Sennadir/NoisyGNN"" target=""_blank"">Sennadir</a>",2025-12-03 22:39:25
Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment,"Jiongxiao Wang, Jiazhao Li, Yiquan Li, Xiangyu Qi, Junjie Hu, Yixuan Li, Patrick McDaniel, Muhao Chen, Bo Li, Chaowei Xiao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14968"" target=""_blank"">2402.14968</a>",,2025-12-03 22:39:25
Noise-BERT: A Unified Perturbation-Robust Framework with Noise Alignment Pre-training for Noisy Slot Filling Task,"Jinxu Zhao, Guanting Dong, Yueyan Qiu, Tingfeng Hui, Xiaoshuai Song, Daichi Guo, Weiran Xu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14494"" target=""_blank"">2402.14494</a>",,2025-12-03 22:39:25
Adversarial Purification and Fine-tuning for Robust UDC Image Restoration,"Zhenbo Song, Zhenyuan Zhang, Kaihao Zhang, Wenhan Luo, Zhaoxin Fan, Jianfeng Lu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13629"" target=""_blank"">2402.13629</a>",,2025-12-03 22:39:25
Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment,"Vyas Raina, Adian Liusie, Mark Gales",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14016"" target=""_blank"">2402.14016</a>",,2025-12-03 22:39:25
Flexible Physical Camouflage Generation Based on a Differential Approach,"Yang Li, Wenyi Tan, Chenxing Zhao, Shuangju Zhou, Xinkai Liang, Quan Pan",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13575"" target=""_blank"">2402.13575</a>",,2025-12-03 22:39:25
VL-Trojan: Multimodal Instruction Backdoor Attacks against Autoregressive Visual Language Models,"Jiawei Liang, Siyuan Liang, Man Luo, Aishan Liu, Dongchen Han, Ee-Chien Chang, Xiaochun Cao",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13851"" target=""_blank"">2402.13851</a>",,2025-12-03 22:39:25
Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs,"Xiaoxia Li, Siyuan Liang, Jiyi Zhang, Han Fang, Aishan Liu, Ee-Chien Chang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14872"" target=""_blank"">2402.14872</a>",,2025-12-03 22:39:25
Coercing LLMs to do and reveal (almost) anything,"Jonas Geiping, Alex Stein, Manli Shu, Khalid Saifullah, Yuxin Wen, Tom Goldstein",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14020"" target=""_blank"">2402.14020</a>",,2025-12-03 22:39:25
T-Stitch: Accelerating Sampling in Pre-Trained Diffusion Models with Trajectory Stitching,"Zizheng Pan, Bohan Zhuang, De-An Huang, Weili Nie, Zhiding Yu, Chaowei Xiao, Jianfei Cai, Anima Anandkumar",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14167"" target=""_blank"">2402.14167</a>","<a href=""https://github.com/NVlabs/T-Stitch"" target=""_blank"">NVlabs</a>",2025-12-03 22:39:25
QuanTest: Entanglement-Guided Testing of Quantum Neural Network Systems,"Jinjing Shi, Zimeng Xiao, Heyuan Shi, Yu Jiang, Xuelong Li",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12950"" target=""_blank"">2402.12950</a>",,2025-12-03 22:39:25
Defending Jailbreak Prompts via In-Context Adversarial Game,"Yujun Zhou, Yufei Han, Haomin Zhuang, Taicheng Guo, Kehan Guo, Zhenwen Liang, Hongyan Bao, Xiangliang Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13148"" target=""_blank"">2402.13148</a>",,2025-12-03 22:39:25
Robustness of Deep Neural Networks for Micro-Doppler Radar Classification,"Mikolaj Czerkawski, Carmine Clemente, Craig MichieCraig Michie, Christos Tachtatzis",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13651"" target=""_blank"">2402.13651</a>",,2025-12-03 22:39:25
Investigating the Impact of Model Instability on Explanations and Uncertainty,"Sara Vera Marjanović, Isabelle Augenstein, Christina Lioma",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13006"" target=""_blank"">2402.13006</a>",,2025-12-03 22:39:25
AICAttack: Adversarial Image Captioning Attack with Attention-Based Optimization,"Jiyao Li, Mingze Ni, Yifei Dong, Tianqing Zhu, Wei Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11940"" target=""_blank"">2402.11940</a>",,2025-12-03 22:39:25
A Comprehensive Study of Jailbreak Attack versus Defense for Large Language Models,"Zihao Xu, Yi Liu, Gelei Deng, Yuekang Li, Stjepan Picek",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13457"" target=""_blank"">2402.13457</a>",,2025-12-03 22:39:25
Stealing the Invisible: Unveiling Pre-Trained CNN Models through Adversarial Examples and Timing Side-Channels,"Shubhi Shukla, Manaar Alam, Pabitra Mitra, Debdeep Mukhopadhyay",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.11953"" target=""_blank"">2402.11953</a>",,2025-12-03 22:39:25
Attacks on Node Attributes in Graph Neural Networks,"Ying Xu, Michael Lanier, Anindya Sarkar, Yevgeniy Vorobeychik",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12426"" target=""_blank"">2402.12426</a>",,2025-12-03 22:39:25
Indiscriminate Data Poisoning Attacks on Pre-trained Feature Extractors,"Yiwei Lu, Matthew Y. R. Yang, Gautam Kamath, Yaoliang Yu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12626"" target=""_blank"">2402.12626</a>",,2025-12-03 22:39:25
An Adversarial Approach to Evaluating the Robustness of Event Identification Models,"Obai Bahwal, Oliver Kosut, Lalitha Sankar",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12338"" target=""_blank"">2402.12338</a>",,2025-12-03 22:39:25
Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies,"Xiangyu Liu, Chenghao Deng, Yanchao Sun, Yongyuan Liang, Furong Huang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12673"" target=""_blank"">2402.12673</a>",,2025-12-03 22:39:25
Adversarial Feature Alignment: Balancing Robustness and Accuracy in Deep Learning via Adversarial Training,"Leo Hyun Park, Jaeuk Kim, Myung Gyo Oh, Jaewoo Park, Taekyoung Kwon",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12187"" target=""_blank"">2402.12187</a>",,2025-12-03 22:39:25
Query-Based Adversarial Prompt Generation,"Jonathan Hayase, Ema Borevkovic, Nicholas Carlini, Florian Tramèr, Milad Nasr",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.12329"" target=""_blank"">2402.12329</a>",,2025-12-03 22:39:25
RITFIS: Robust input testing framework for LLMs-based intelligent software,"Mingxuan Xiao, Yan Xiao, Hai Dong, Shunhui Ji, Pengcheng Zhang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13518"" target=""_blank"">2402.13518</a>",,2025-12-03 22:39:25
The Wolf Within: Covert Injection of Malice into MLLM Societies via an MLLM Operative,"Zhen Tan, Chengshuai Zhao, Raha Moraffah, Yifan Li, Yu Kong, Tianlong Chen, Huan Liu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.14859"" target=""_blank"">2402.14859</a>",,2025-12-03 22:39:25
Stealthy Adversarial Attacks on Stochastic Multi-Armed Bandits,"Zhiwei Wang, Huazheng Wang, Hongning Wang",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13487"" target=""_blank"">2402.13487</a>",,2025-12-03 22:39:25
Learning to Poison Large Language Models During Instruction Tuning,"Yao Qiang, Xiangyu Zhou, Saleh Zare Zade, Mohammad Amin Roshani, Douglas Zytko, Dongxiao Zhu",arXiv,2024-02,"<a href=""http://arxiv.org/abs/2402.13459"" target=""_blank"">2402.13459</a>",,2025-12-03 22:39:25
Can We Trust the Unlabeled Target Data? Towards Backdoor Attack and Defense on Model Adaptation,"Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06030"" target=""_blank"">2401.06030</a>",,2025-12-03 22:39:25
CoLafier: Collaborative Noisy Label Purifier With Local Intrinsic Dimensionality Guidance,"Dongyu Zhang, Ruofan Hu, Elke Rundensteiner",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05458"" target=""_blank"">2401.05458</a>","<a href=""https://github.com/zdy93/CoLafier"" target=""_blank"">zdy93</a>",2025-12-03 22:39:25
Manipulating Feature Visualizations with Gradient Slingshots,"Dilyara Bareeva, Marina M. -C. Höhne, Alexander Warnecke, Lukas Pirch, Klaus-Robert Müller, Konrad Rieck, Kirill Bykov",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06122"" target=""_blank"">2401.06122</a>",,2025-12-03 22:39:25
Combating Adversarial Attacks with Multi-Agent Debate,"Steffi Chern, Zhen Fan, Andy Liu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05998"" target=""_blank"">2401.05998</a>",,2025-12-03 22:39:25
Exploring Vulnerabilities of No-Reference Image Quality Assessment Models: A Query-Based Black-Box Method,"Chenxi Yang, Yujia Liu, Dingquan Li, Tingting Jiang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05217"" target=""_blank"">2401.05217</a>",,2025-12-03 22:39:25
TrustLLM: Trustworthiness in Large Language Models,"Lichao Sun, Yue Huang, Haoran Wang, Siyuan Wu, Qihui Zhang, Chujie Gao, Yixin Huang, Wenhan Lyu, Yixuan Zhang, Xiner Li, Zhengliang Liu, Yixin Liu, Yijue Wang, Zhikun Zhang, Bhavya Kailkhura, Caiming Xiong, Chaowei Xiao, Chunyuan Li, Eric Xing, Furong Huang, Hao Liu, Heng Ji, Hongyi Wang, Huan Zhang, Huaxiu Yao, Manolis Kellis, Marinka Zitnik, Meng Jiang, Mohit Bansal, James Zou, Jian Pei, Jian Liu, Jianfeng Gao, Jiawei Han, Jieyu Zhao, Jiliang Tang, Jindong Wang, John Mitchell, Kai Shu, Kaidi Xu, Kai-Wei Chang, Lifang He, Lifu Huang, Michael Backes, Neil Zhenqiang Gong, Philip S. Yu, Pin-Yu Chen, Quanquan Gu, Ran Xu, Rex Ying, Shuiwang Ji, Suman Jana, Tianlong Chen, Tianming Liu, Tianyi Zhou, Willian Wang, Xiang Li, Xiangliang Zhang, Xiao Wang, Xing Xie, Xun Chen, Xuyu Wang, Yan Liu, Yanfang Ye, Yinzhi Cao, Yong Chen, Yue Zhao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05561"" target=""_blank"">2401.05561</a>",,2025-12-03 22:39:25
SENet: Visual Detection of Online Social Engineering Attack Campaigns,"Irfan Ozen, Karthika Subramani, Phani Vadrevu, Roberto Perdisci",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05569"" target=""_blank"">2401.05569</a>",,2025-12-03 22:39:25
Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training,"Evan Hubinger, Carson Denison, Jesse Mu, Mike Lambert, Meg Tong, Monte MacDiarmid, Tamera Lanham, Daniel M. Ziegler, Tim Maxwell, Newton Cheng, Adam Jermyn, Amanda Askell, Ansh Radhakrishnan, Cem Anil, David Duvenaud, Deep Ganguli, Fazl Barez, Jack Clark, Kamal Ndousse, Kshitij Sachan, Michael Sellitto, Mrinank Sharma, Nova DasSarma, Roger Grosse, Shauna Kravec, Yuntao Bai, Zachary Witten, Marina Favaro, Jan Brauner, Holden Karnofsky, Paul Christiano, Samuel R. Bowman, Logan Graham, Jared Kaplan, Sören Mindermann, Ryan Greenblatt, Buck Shlegeris, Nicholas Schiefer, Ethan Perez",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05566"" target=""_blank"">2401.05566</a>",,2025-12-03 22:39:25
Pre-trained Model Guided Fine-Tuning for Zero-Shot Adversarial Robustness,"Sibo Wang, Jie Zhang, Zheng Yuan, Shiguang Shan",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04350"" target=""_blank"">2401.04350</a>","<a href=""https://github.com/serendipity1122/Pre-trained-Model-Guided-Fine-Tuning-for-Zero-Shot-Adversarial-Robustness"" target=""_blank"">serendipity1122</a>",2025-12-03 22:39:25
Brave: Byzantine-Resilient and Privacy-Preserving Peer-to-Peer Federated Learning,"Zhangchen Xu, Fengqing Jiang, Luyao Niu, Jinyuan Jia, Radha Poovendran",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05562"" target=""_blank"">2401.05562</a>",,2025-12-03 22:39:25
FBSDetector: Fake Base Station and Multi Step Attack Detection in Cellular Networks using Machine Learning,"Kazi Samin Mubasshir, Imtiaz Karim, Elisa Bertino",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04958"" target=""_blank"">2401.04958</a>",,2025-12-03 22:39:25
Revisiting Adversarial Training at Scale,"Zeyu Wang, Xianhang Li, Hongru Zhu, Cihang Xie",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04727"" target=""_blank"">2401.04727</a>","<a href=""https://github.com/UCSC-VLAA/AdvXL"" target=""_blank"">UCSC-VLAA</a>",2025-12-03 22:39:25
SoK: Facial Deepfake Detectors,"Binh M. Le, Jiwon Kim, Shahroz Tariq, Kristen Moore, Alsharif Abuadbba, Simon S. Woo",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04364"" target=""_blank"">2401.04364</a>",,2025-12-03 22:39:25
Advancing Ante-Hoc Explainable Models through Generative Adversarial Networks,"Tanmay Garg, Deepika Vemuri, Vineeth N Balasubramanian",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04647"" target=""_blank"">2401.04647</a>",,2025-12-03 22:39:25
Coupling Graph Neural Networks with Fractional Order Continuous Dynamics: A Robustness Study,"Qiyu Kang, Kai Zhao, Yang Song, Yihang Xie, Yanan Zhao, Sijie Wang, Rui She, Wee Peng Tay",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04331"" target=""_blank"">2401.04331</a>",,2025-12-03 22:39:25
Logits Poisoning Attack in Federated Distillation,"Yuhan Tang, Zhiyuan Wu, Bo Gao, Tian Wen, Yuwei Wang, Sheng Sun",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.03685"" target=""_blank"">2401.03685</a>",,2025-12-03 22:39:25
Attack-Resilient Image Watermarking Using Stable Diffusion,"Lijun Zhang, Xiao Liu, Antoni Viros Martin, Cindy Xiong Bearfield, Yuriy Brun, Hui Guan",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04247"" target=""_blank"">2401.04247</a>","<a href=""https://github.com/zhanglijun95/ZoDiac"" target=""_blank"">zhanglijun95</a>",2025-12-03 22:39:25
Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks,"Shuai Zhao, Meihuizi Jia, Luu Anh Tuan, Jinming Wen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05949"" target=""_blank"">2401.05949</a>",,2025-12-03 22:39:25
Revisiting Jailbreaking for Large Language Models: A Representation Engineering Perspective,"Tianlong Li, Zhenghua Wang, Wenhao Liu, Muling Wu, Shihan Dou, Changze Lv, Xiaohua Wang, Xiaoqing Zheng, Xuanjing Huang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06824"" target=""_blank"">2401.06824</a>",,2025-12-03 22:39:25
Robustness Against Adversarial Attacks via Learning Confined Adversarial Polytopes,"Shayan Mohajer Hamidi, Linfeng Ye",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.07991"" target=""_blank"">2401.07991</a>",,2025-12-03 22:39:25
GE-AdvGAN: Improving the transferability of adversarial samples by gradient editing-based adversarial generative model,"Zhiyu Zhu, Huaming Chen, Xinyi Wang, Jiayu Zhang, Zhibo Jin, Kim-Kwang Raymond Choo, Jun Shen, Dong Yuan",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06031"" target=""_blank"">2401.06031</a>","<a href=""https://github.com/LMBTough/GE-advGAN"" target=""_blank"">LMBTough</a>",2025-12-03 22:39:25
Intention Analysis Makes LLMs A Good Jailbreak Defender,"Yuqi Zhang, Liang Ding, Lefei Zhang, Dacheng Tao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06561"" target=""_blank"">2401.06561</a>","<a href=""https://github.com/alphadl/SafeLLM_with_IntentionAnalysis"" target=""_blank"">alphadl</a>",2025-12-03 22:39:25
Bag of Tricks to Boost Adversarial Transferability,"Zeliang Zhang, Rongyi Zhu, Wei Yao, Xiaosen Wang, Chenliang Xu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08734"" target=""_blank"">2401.08734</a>",,2025-12-03 22:39:25
A Generative Adversarial Attack for Multilingual Text Classifiers,"Tom Roth, Inigo Jauregi Unanue, Alsharif Abuadbba, Massimo Piccardi",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08255"" target=""_blank"">2401.08255</a>",,2025-12-03 22:39:25
PPR: Enhancing Dodging Attacks while Maintaining Impersonation Attacks on Face Recognition Systems,"Fengfan Zhou, Heifei Ling",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08903"" target=""_blank"">2401.08903</a>",,2025-12-03 22:39:25
Robust Localization of Key Fob Using Channel Impulse Response of Ultra Wide Band Sensors for Keyless Entry Systems,"Abhiram Kolli, Filippo Casamassima, Horst Possegger, Horst Bischof",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08863"" target=""_blank"">2401.08863</a>",,2025-12-03 22:39:25
The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images,"Nicholas Konz, Maciej A. Mazurowski",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08865"" target=""_blank"">2401.08865</a>","<a href=""https://github.com/mazurowski-lab/intrinsic-properties"" target=""_blank"">mazurowski-lab</a>",2025-12-03 22:39:25
RandOhm: Mitigating Impedance Side-channel Attacks using Randomized Circuit Configurations,"Saleh Khalaj Monfared, Domenic Forte, Shahin Tajik",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08925"" target=""_blank"">2401.08925</a>",,2025-12-03 22:39:25
Towards Efficient and Certified Recovery from Poisoning Attacks in Federated Learning,"Yu Jiang, Jiyuan Shen, Ziyao Liu, Chee Wei Tan, Kwok-Yan Lam",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08216"" target=""_blank"">2401.08216</a>",,2025-12-03 22:39:25
IPR-NeRF: Ownership Verification meets Neural Radiance Field,"Win Kent Ong, Kam Woh Ng, Chee Seng Chan, Yi Zhe Song, Tao Xiang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09495"" target=""_blank"">2401.09495</a>",,2025-12-03 22:39:25
IoTWarden: A Deep Reinforcement Learning Based Real-time Defense System to Mitigate Trigger-action IoT Attacks,"Md Morshed Department of Software and Information Systems, University of North Carolina at Charlotte, Charlotte, USA Alam, Israt Department of Computer Science, University of Memphis, Memphis, USA Jahan, Weichao Department of Software and Information Systems, University of North Carolina at Charlotte, Charlotte, USA Wang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08141"" target=""_blank"">2401.08141</a>",,2025-12-03 22:39:25
Invisible Reflections: Leveraging Infrared Laser Reflections to Target Traffic Sign Perception,"Takami Sato, Sri Hrushikesh Varma Bhupathiraju, Michael Clifford, Takeshi Sugawara, Qi Alfred Chen, Sara Rampazzi",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.03582"" target=""_blank"">2401.03582</a>",,2025-12-03 22:39:25
Authorship Obfuscation in Multilingual Machine-Generated Text Detection,"Dominik Macko, Robert Moro, Adaku Uchendu, Ivan Srba, Jason Samuel Lucas, Michiharu Yamashita, Nafis Irtiza Tripto, Dongwon Lee, Jakub Simko, Maria Bielikova",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.07867"" target=""_blank"">2401.07867</a>",,2025-12-03 22:39:25
LookAhead: Preventing DeFi Attacks via Unveiling Adversarial Contracts,"Shoupeng Ren, Lipeng He, Tianyu Tu, Di Wu, Jian Liu, Kui Ren, Chun Chen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.07261"" target=""_blank"">2401.07261</a>",,2025-12-03 22:39:25
Crafter: Facial Feature Crafting against Inversion-based Identity Theft on Deep Models,"Shiming Wang, Zhe Ji, Liyao Xiang, Hao Zhang, Xinbing Wang, Chenghu Zhou, Bo Li",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.07205"" target=""_blank"">2401.07205</a>",,2025-12-03 22:39:25
Exploring Adversarial Attacks against Latent Diffusion Model from the Perspective of Adversarial Transferability,"Junxi Chen, Junhao Dong, Xiaohua Xie",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.07087"" target=""_blank"">2401.07087</a>",,2025-12-03 22:39:25
Left-right Discrepancy for Adversarial Attack on Stereo Networks,"Pengfei Wang, Xiaofei Hui, Beijia Lu, Nimrod Lilith, Jun Liu, Sameer Alam",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.07188"" target=""_blank"">2401.07188</a>",,2025-12-03 22:39:25
Adversarial Examples are Misaligned in Diffusion Model Manifolds,"Peter Lorenz, Ricard Durall, Janis Keuper",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06637"" target=""_blank"">2401.06637</a>",,2025-12-03 22:39:25
How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs,"Yi Zeng, Hongpeng Lin, Jingwen Zhang, Diyi Yang, Ruoxi Jia, Weiyan Shi",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06373"" target=""_blank"">2401.06373</a>",,2025-12-03 22:39:25
Enhancing Consistency and Mitigating Bias: A Data Replay Approach for Incremental Learning,"Chenyang Wang, Junjun Jiang, Xingyu Hu, Xianming Liu, Xiangyang Ji",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06548"" target=""_blank"">2401.06548</a>",,2025-12-03 22:39:25
An Analytical Framework for Modeling and Synthesizing Malicious Attacks on ACC Vehicles,Shian Wang,arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.06916"" target=""_blank"">2401.06916</a>",,2025-12-03 22:39:25
Dense Hopfield Networks in the Teacher-Student Setting,"Robin Thériault, Daniele Tantari",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.04191"" target=""_blank"">2401.04191</a>",,2025-12-03 22:39:25
"Caught in the Quicksand of Reasoning, Far from AGI Summit: Evaluating LLMs' Mathematical and Coding Competency through Ontology-guided Interventions","Pengfei Hong, Deepanway Ghosal, Navonil Majumder, Somak Aditya, Rada Mihalcea, Soujanya Poria",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09395"" target=""_blank"">2401.09395</a>","<a href=""https://github.com/declare-lab/llm_robustness"" target=""_blank"">declare-lab</a>",2025-12-03 22:39:25
Data-Driven Subsampling in the Presence of an Adversarial Actor,"Abu Shafin Mohammad Mahdee Jameel, Ahmed P. Mohamed, Jinho Yi, Aly El Gamal, Akshay Malhotra",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.03488"" target=""_blank"">2401.03488</a>",,2025-12-03 22:39:25
Does Few-shot Learning Suffer from Backdoor Attacks? (98%),"Xinwei Liu, Xiaojun Jia, Jindong Gu, Yuan Xun, Siyuan Liang, Xiaochun Cao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01377"" target=""_blank"">2401.01377</a>",,2025-12-03 22:39:25
Dual Teacher Knowledge Distillation with Domain Alignment for Face Anti-spoofing,"Zhe Kong, Wentian Zhang, Tao Wang, Kaihao Zhang, Yuexiang Li, Xiaoying Tang, Wenhan Luo",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01102"" target=""_blank"">2401.01102</a>",,2025-12-03 22:39:25
Unveiling the Stealthy Threat: Analyzing Slow Drift GPS Spoofing Attacks for Autonomous Vehicles in Urban Environments and Enabling the Resilience,"Sagar Dasgupta, Abdullah Ahmed, Mizanur Rahman, Thejesh N. Bandi",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01394"" target=""_blank"">2401.01394</a>",,2025-12-03 22:39:25
Imperio: Language-Guided Backdoor Attacks for Arbitrary Model Control,"Ka-Ho Chow, Wenqi Wei, Lei Yu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01085"" target=""_blank"">2401.01085</a>",,2025-12-03 22:39:25
Will 6G be Semantic Communications? Opportunities and Challenges from Task Oriented and Secure Communications to Integrated Sensing,"Yalin E. Sagduyu, Tugba Erpek, Aylin Yener, Sennur Ulukus",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01531"" target=""_blank"">2401.01531</a>",,2025-12-03 22:39:25
"Safety and Performance, Why Not Both? Bi-Objective Optimized Model Compression against Heterogeneous Attacks Toward AI Software Deployment","Jie Zhu, Leye Wang, Xiao Han, Anmin Liu, Tao Xie",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00996"" target=""_blank"">2401.00996</a>",,2025-12-03 22:39:25
Detection and Defense Against Prominent Attacks on Preconditioned LLM-Integrated Virtual Assistants,"Chun Fai Chan, Daniel Wankit Yip, Aysan Esmradi",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00994"" target=""_blank"">2401.00994</a>",,2025-12-03 22:39:25
A Novel Evaluation Framework for Assessing Resilience Against Prompt Injection Attacks in Large Language Models,"Daniel Wankit Yip, Aysan Esmradi, Chun Fai Chan",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00991"" target=""_blank"">2401.00991</a>",,2025-12-03 22:39:25
AR-GAN: Generative Adversarial Network-Based Defense Method Against Adversarial Attacks on the Traffic Sign Classification System of Autonomous Vehicles,"M Sabbir Salek, Abdullah Al Mamun, Mashrur Chowdhury",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14232"" target=""_blank"">2401.14232</a>",,2025-12-03 22:39:25
Is It Possible to Backdoor Face Forgery Detection with Natural Triggers? (68%),"Xiaoxuan Han, Songlin Yang, Wei Wang, Ziwen He, Jing Dong",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00414"" target=""_blank"">2401.00414</a>",,2025-12-03 22:39:25
Enhancing Generalization of Invisible Facial Privacy Cloak via Gradient Accumulation,"Xuannan Liu, Yaoyao Zhong, Weihong Deng, Hongzhi Shi, Xingchen Cui, Yunfeng Yin, Dongchao Wen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01575"" target=""_blank"">2401.01575</a>",,2025-12-03 22:39:25
Explainability-Driven Leaf Disease Classification using Adversarial Training and Knowledge Distillation,"Sebastian-Vasile Echim, Iulian-Marius Tăiatu, Dumitru-Clementin Cercel, Florin Pop",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00334"" target=""_blank"">2401.00334</a>",,2025-12-03 22:39:25
CamPro: Camera-based Anti-Facial Recognition,"Wenjun Zhu, Yuan Sun, Jiani Liu, Yushi Cheng, Xiaoyu Ji, Wenyuan Xu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00151"" target=""_blank"">2401.00151</a>",,2025-12-03 22:39:25
TPatch: A Triggered Physical Adversarial Patch,"Wenjun Zhu, Xiaoyu Ji, Yushi Cheng, Shibo Zhang, Wenyuan Xu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00148"" target=""_blank"">2401.00148</a>",,2025-12-03 22:39:25
A clean-label graph backdoor attack method in node classification task,"Xiaogang Xing, Ming Xu, Yujing Bai, Dongdong Yang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00163"" target=""_blank"">2401.00163</a>",,2025-12-03 22:39:25
SSL-OTA: Unveiling Backdoor Threats in Self-Supervised Learning for Object Detection,"Qiannan Wang, Changchun Yin, Lu Zhou, Liming Fang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.00137"" target=""_blank"">2401.00137</a>",,2025-12-03 22:39:25
Resilient Path Planning for UAVs in Data Collection under Adversarial Attacks,"Xueyuan Wang, M. Cenk Gursoy",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08634"" target=""_blank"">2401.08634</a>",,2025-12-03 22:39:25
STR-Cert: Robustness Certification for Deep Text Recognition on Deep Learning Pipelines and Vision Transformers,"Daqian Shao, Lukas Fesser, Marta Kwiatkowska",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05338"" target=""_blank"">2401.05338</a>",,2025-12-03 22:39:25
Reputation-Based Federated Learning Defense to Mitigate Threats in EEG Signal Classification,"Zhibo Zhang, Pengfei Li, Ahmed Y. Al Hammadi, Fusen Guo, Ernesto Damiani, Chan Yeob Yeun",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01896"" target=""_blank"">2401.01896</a>",,2025-12-03 22:39:25
JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example,"Benedetta Tondi, Wei Guo, Mauro Barni",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01199"" target=""_blank"">2401.01199</a>",,2025-12-03 22:39:25
Integrated Cyber-Physical Resiliency for Power Grids under IoT-Enabled Dynamic Botnet Attacks,"Yuhan Zhao, Juntao Chen, Quanyan Zhu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01963"" target=""_blank"">2401.01963</a>",,2025-12-03 22:39:25
ROIC-DM: Robust Text Inference and Classification via Diffusion Model,"Shilong Yuan, Wei Yuan, Hongzhi Yin, Tieke He",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.03514"" target=""_blank"">2401.03514</a>",,2025-12-03 22:39:25
Vulnerabilities Unveiled: Adversarially Attacking a Multimodal Vision Langauge Model for Pathology Imaging,"Jai Prakash Veerla, Poojitha Thota, Partha Sai Guttikonda, Shirin Nilizadeh, Jacob M. Luber",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02565"" target=""_blank"">2401.02565</a>",,2025-12-03 22:39:25
Data-Dependent Stability Analysis of Adversarial Training,"Yihan Wang, Shuang Liu, Xiao-Shan Gao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.03156"" target=""_blank"">2401.03156</a>",,2025-12-03 22:39:25
End-to-End Anti-Backdoor Learning on Images and Time Series,"Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, Yige Li, James Bailey",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.03215"" target=""_blank"">2401.03215</a>",,2025-12-03 22:39:25
Transferable Learned Image Compression-Resistant Adversarial Perturbations,"Yang Sui, Zhuohang Li, Ding Ding, Xiang Pan, Xiaozhong Xu, Shan Liu, Zhenzhong Chen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.03115"" target=""_blank"">2401.03115</a>",,2025-12-03 22:39:25
Enhancing targeted transferability via feature space fine-tuning,"Hui Zeng, Biwei Chen, Anjie Peng",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02727"" target=""_blank"">2401.02727</a>",,2025-12-03 22:39:25
Calibration Attack: A Framework For Adversarial Attacks Targeting Calibration,"Stephen Obadinma, Xiaodan Zhu, Hongyu Guo",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02718"" target=""_blank"">2401.02718</a>",,2025-12-03 22:39:25
A backdoor attack against link prediction tasks with graph neural networks,"Jiazhu Dai, Haoyu Sun",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02663"" target=""_blank"">2401.02663</a>",,2025-12-03 22:39:25
TEN-GUARD: Tensor Decomposition for Backdoor Attack Detection in Deep Neural Networks,"Khondoker Murad Hossain, Tim Oates",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.05432"" target=""_blank"">2401.05432</a>",,2025-12-03 22:39:25
MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance,"Renjie Pi, Tianyang Han, Yueqi Xie, Rui Pan, Qing Lian, Hanze Dong, Jipeng Zhang, Tong Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02906"" target=""_blank"">2401.02906</a>",,2025-12-03 22:39:25
A Random Ensemble of Encrypted models for Enhancing Robustness against Adversarial Examples,"Ryota Iijima, Sayaka Shiota, Hitoshi Kiya",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02633"" target=""_blank"">2401.02633</a>",,2025-12-03 22:39:25
FullLoRA-AT: Efficiently Boosting the Robustness of Pretrained Vision Transformers,"Zheng Yuan, Jie Zhang, Shiguang Shan",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01752"" target=""_blank"">2401.01752</a>",,2025-12-03 22:39:25
AdvSQLi: Generating Adversarial SQL Injections against Real-world WAF-as-a-service,"Zhenqing Qu, Xiang Ling, Ting Wang, Xiang Chen, Shouling Ji, Chunming Wu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02615"" target=""_blank"">2401.02615</a>",,2025-12-03 22:39:25
Evasive Hardware Trojan through Adversarial Power Trace,"Behnam Omidi, Khaled N. Khasawneh, Ihsen Alouani",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02342"" target=""_blank"">2401.02342</a>",,2025-12-03 22:39:25
Object-oriented backdoor attack against image captioning,"Meiling Li, Nan Zhong, Xinpeng Zhang, Zhenxing Qian, Sheng Li",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02600"" target=""_blank"">2401.02600</a>",,2025-12-03 22:39:25
DEM: A Method for Certifying Deep Neural Network Classifier Outputs in Aerospace,"Guy Katz, Natan Levy, Idan Refaeli, Raz Yerushalmi",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02283"" target=""_blank"">2401.02283</a>",,2025-12-03 22:39:25
Secure Control of Connected and Automated Vehicles Using Trust-Aware Robust Event-Triggered Control Barrier Functions,"H M Sabbir Ahmad, Ehsan Sabouni, Akua Dickson, Wei Xiao, Christos G. Cassandras, Wenchao Li",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02306"" target=""_blank"">2401.02306</a>",,2025-12-03 22:39:25
A Survey Analyzing Generalization in Deep Reinforcement Learning,Ezgi Korkmaz,arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02349"" target=""_blank"">2401.02349</a>",,2025-12-03 22:39:25
Towards Robust Semantic Segmentation against Patch-based Attack via Attention Refinement,"Zheng Yuan, Jie Zhang, Yude Wang, Shiguang Shan, Xilin Chen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.01750"" target=""_blank"">2401.01750</a>",,2025-12-03 22:39:25
Spy-Watermark: Robust Invisible Watermarking for Backdoor Attack,"Ruofei Wang, Renjie Wan, Zongyu Guo, Qing Guo, Rui Huang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.02031"" target=""_blank"">2401.02031</a>",,2025-12-03 22:39:25
Revealing Vulnerabilities in Stable Diffusion via Targeted Attacks,"Chenyu Zhang, Lanjun Wang, Anan Liu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08725"" target=""_blank"">2401.08725</a>","<a href=""https://github.com/datar001/Revealing-Vulnerabilities-in-Stable-Diffusion-via-Targeted-Attacks"" target=""_blank"">datar001</a>",2025-12-03 22:39:25
Boosting the Transferability of Adversarial Examples via Local Mixup and Adaptive Step Size,"Junlin Liu, Xinchen Lyu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.13205"" target=""_blank"">2401.13205</a>",,2025-12-03 22:39:25
Attack and Reset for Unlearning: Exploiting Adversarial Noise toward Machine Unlearning through Parameter Re-initialization,"Yoonhwa Jung, Ikhyun Cho, Shun-Hsiang Hsu, Julia Hockenmaier",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08998"" target=""_blank"">2401.08998</a>",,2025-12-03 22:39:25
Securing Recommender System via Cooperative Training,"Qingyang Wang, Chenwang Wu, Defu Lian, Enhong Chen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12700"" target=""_blank"">2401.12700</a>",,2025-12-03 22:39:25
L-AutoDA: Leveraging Large Language Models for Automated Decision-based Adversarial Attacks,"Ping Guo, Fei Liu, Xi Lin, Qingchuan Zhao, Qingfu Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15335"" target=""_blank"">2401.15335</a>",,2025-12-03 22:39:25
Set-Based Training for Neural Network Verification,"Lukas Koller, Tobias Ladner, Matthias Althoff",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14961"" target=""_blank"">2401.14961</a>",,2025-12-03 22:39:25
Mitigating Feature Gap for Adversarial Robustness by Feature Disentanglement,"Nuoyan Zhou, Dawei Zhou, Decheng Liu, Xinbo Gao, Nannan Wang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14707"" target=""_blank"">2401.14707</a>",,2025-12-03 22:39:25
"Multi-Trigger Backdoor Attacks: More Triggers, More Threats","Yige Li, Xingjun Ma, Jiabo He, Hanxun Huang, Yu-Gang Jiang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15295"" target=""_blank"">2401.15295</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defenses in 6G Network-Assisted IoT Systems,"Bui Duc Son, Nguyen Tien Hoa, Chien Trinh Van, Waqas Khalid, Mohamed Amine Ferrag, Wan Choi, Merouane Debbah",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14780"" target=""_blank"">2401.14780</a>",,2025-12-03 22:39:25
Conserve-Update-Revise to Cure Generalization and Robustness Trade-off in Adversarial Training,"Shruthi Gowda, Bahram Zonooz, Elahe Arani",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14948"" target=""_blank"">2401.14948</a>",,2025-12-03 22:39:25
Asymptotic Behavior of Adversarial Training Estimator under $\ell_\infty$-Perturbation,"Yiling Xie, Xiaoming Huo",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15262"" target=""_blank"">2401.15262</a>",,2025-12-03 22:39:25
Better Representations via Adversarial Training in Pre-Training: A Theoretical Perspective,"Yue Xing, Xiaofeng Lin, Qifan Song, Yi Xu, Belinda Zeng, Guang Cheng",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15248"" target=""_blank"">2401.15248</a>",,2025-12-03 22:39:25
MEA-Defender: A Robust Watermark against Model Extraction Attack,"Peizhuo Lv, Hualong Ma, Kai Chen, Jiachen Zhou, Shengzhi Zhang, Ruigang Liang, Shenchen Zhu, Pan Li, Yingjun Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15239"" target=""_blank"">2401.15239</a>",,2025-12-03 22:39:25
BackdoorBench: A Comprehensive Benchmark and Analysis of Backdoor Learning,"Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Mingli Zhu, Ruotong Wang, Li Liu, Chao Shen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15002"" target=""_blank"">2401.15002</a>",,2025-12-03 22:39:25
Sparse and Transferable Universal Singular Vectors Attack,"Kseniia Kuvshinova, Olga Tsymboi, Ivan Oseledets",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14031"" target=""_blank"">2401.14031</a>",,2025-12-03 22:39:25
Friendly Attacks to Improve Channel Coding Reliability,"Anastasiia Kurmukova, Deniz Gunduz",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14184"" target=""_blank"">2401.14184</a>",,2025-12-03 22:39:25
Semantic Sensitivities and Inconsistent Predictions: Measuring the Fragility of NLI Models,"Erik Arakelyan, Zhaoqi Liu, Isabelle Augenstein",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14440"" target=""_blank"">2401.14440</a>",,2025-12-03 22:39:25
The Risk of Federated Learning to Skew Fine-Tuning Features and Underperform Out-of-Distribution Robustness,"Mengyao Du, Miao Zhang, Yuwen Pu, Kai Xu, Shouling Ji, Quanjun Yin",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14027"" target=""_blank"">2401.14027</a>",,2025-12-03 22:39:25
Novel Quadratic Constraints for Extending LipSDP beyond Slope-Restricted Activations,"Patricia Pauli, Aaron Havens, Alexandre Araujo, Siddharth Garg, Farshad Khorrami, Frank Allgöwer, Bin Hu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14033"" target=""_blank"">2401.14033</a>",,2025-12-03 22:39:25
Physical Trajectory Inference Attack and Defense in Decentralized POI Recommendation,"Jing Long, Tong Chen, Guanhua Ye, Kai Zheng, Nguyen Quoc Viet Hung, Hongzhi Yin",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.14583"" target=""_blank"">2401.14583</a>",,2025-12-03 22:39:25
A Training Rate and Survival Heuristic for Inference and Robustness Evaluation (TRASHFIRE),"Charles Meyers, Mohammad Reza Saleh Sedghpour, Tommy Löfstedt, Erik Elmroth",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.13751"" target=""_blank"">2401.13751</a>",,2025-12-03 22:39:25
Can overfitted deep neural networks in adversarial training generalize? -- An approximation viewpoint,"Zhongjie Shi, Fanghui Liu, Yuan Cao, Johan A. K. Suykens",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.13624"" target=""_blank"">2401.13624</a>",,2025-12-03 22:39:25
WPDA: Frequency-based Backdoor Attack with Wavelet Packet Decomposition,"Zhengyao Song, Yongqiang Li, Danni Yuan, Li Liu, Shaokui Wei, Baoyuan Wu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.13578"" target=""_blank"">2401.13578</a>",,2025-12-03 22:39:25
Model Supply Chain Poisoning: Backdooring Pre-trained Models via Embedding Indistinguishability,"Hao Wang, Shangwei Guo, Jialing He, Hangcheng Liu, Tianwei Zhang, Tao Xiang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15883"" target=""_blank"">2401.15883</a>","<a href=""https://github.com/haowang-cqu/TransTroj"" target=""_blank"">haowang-cqu</a>",2025-12-03 22:39:25
Addressing Noise and Efficiency Issues in Graph-Based Machine Learning Models From the Perspective of Adversarial Attack,Yongyu Wang,arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15615"" target=""_blank"">2401.15615</a>",,2025-12-03 22:39:25
GPS: Graph Contrastive Learning via Multi-scale Augmented Views from Adversarial Pooling,"Wei Ju, Yiyang Gu, Zhengyang Mao, Ziyue Qiao, Yifang Qin, Xiao Luo, Hui Xiong, Ming Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.16011"" target=""_blank"">2401.16011</a>",,2025-12-03 22:39:25
AdvGPS: Adversarial GPS for Multi-Agent Perception Attack,"Jinlong Li, Baolu Li, Xinyu Liu, Jianwu Fang, Felix Juefei-Xu, Qing Guo, Hongkai Yu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17499"" target=""_blank"">2401.17499</a>",,2025-12-03 22:39:25
Manipulating Predictions over Discrete Inputs in Machine Teaching,"Xiaodong Wu, Yufei Han, Hayssam Dahrouj, Jianbing Ni, Zhenwen Liang, Xiangliang Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17865"" target=""_blank"">2401.17865</a>",,2025-12-03 22:39:25
LoRec: Large Language Model for Robust Sequential Recommendation against Poisoning Attacks,"Kaike Zhang, Qi Cao, Yunfan Wu, Fei Sun, Huawei Shen, Xueqi Cheng",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17723"" target=""_blank"">2401.17723</a>",,2025-12-03 22:39:25
Logit Poisoning Attack in Distillation-based Federated Learning and its Countermeasures,"Yonghao Yu, Shunan Zhu, Jinglu Hu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17746"" target=""_blank"">2401.17746</a>",,2025-12-03 22:39:25
Ambush from All Sides: Understanding Security Threats in Open-Source Software CI/CD Pipelines,"Ziyue Pan, Wenbo Shen, Xingkai Wang, Yutian Yang, Rui Chang, Yao Liu, Chengwei Liu, Yang Liu, Kui Ren",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17606"" target=""_blank"">2401.17606</a>",,2025-12-03 22:39:25
An Optimal Transport Approach for Computing Adversarial Training Lower Bounds in Multiclass Classification,"Nicolas Garcia Trillos, Matt Jacobs, Jakwang Kim, Matthew Werenski",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09191"" target=""_blank"">2401.09191</a>",,2025-12-03 22:39:25
Single Word Change is All You Need: Designing Attacks and Defenses for Text Classifiers,"Lei Xu, Sarah Alnegheimish, Laure Berti-Equille, Alfredo Cuesta-Infante, Kalyan Veeramachaneni",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17196"" target=""_blank"">2401.17196</a>",,2025-12-03 22:39:25
Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks,"Andy Zhou, Bo Li, Haohan Wang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17263"" target=""_blank"">2401.17263</a>",,2025-12-03 22:39:25
Towards Assessing the Synthetic-to-Measured Adversarial Vulnerability of SAR ATR,"Bowen Peng, Bo Peng, Jingyuan Xia, Tianpeng Liu, Yongxiang Liu, Li Liu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17038"" target=""_blank"">2401.17038</a>","<a href=""https://github.com/scenarri/S2M-TEA"" target=""_blank"">scenarri</a>",2025-12-03 22:39:25
Game-Theoretic Unlearnable Example Generator,"Shuang Liu, Yihan Wang, Xiao-Shan Gao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17523"" target=""_blank"">2401.17523</a>","<a href=""https://github.com/hong-xian/gue"" target=""_blank"">hong-xian</a>",2025-12-03 22:39:25
Revisiting Gradient Pruning: A Dual Realization for Defending against Gradient Attacks,"Lulu Xue, Shengshan Hu, Ruizhi Zhao, Leo Yu Zhang, Shengqing Hu, Lichao Sun, Dezhong Yao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.16687"" target=""_blank"">2401.16687</a>",,2025-12-03 22:39:25
Camouflage Adversarial Attacks on Multiple Agent Systems,"Ziqing Lu, Guanlin Liu, Lifeng Lai, Weiyu Xu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17405"" target=""_blank"">2401.17405</a>",,2025-12-03 22:39:25
Weak-to-Strong Jailbreaking on Large Language Models,"Xuandong Zhao, Xianjun Yang, Tianyu Pang, Chao Du, Lei Li, Yu-Xiang Wang, William Yang Wang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17256"" target=""_blank"">2401.17256</a>","<a href=""https://github.com/XuandongZhao/weak-to-strong"" target=""_blank"">XuandongZhao</a>",2025-12-03 22:39:25
A Proactive and Dual Prevention Mechanism against Illegal Song Covers empowered by Singing Voice Conversion,"Guangke Chen, Yedi Zhang, Fu Song, Ting Wang, Xiaoning Du, Yang Liu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17133"" target=""_blank"">2401.17133</a>",,2025-12-03 22:39:25
Improving QA Model Performance with Cartographic Inoculation,"Allen UT Austin Chen, Okan UT Austin Tanrikulu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17498"" target=""_blank"">2401.17498</a>",,2025-12-03 22:39:25
Towards Visual Syntactical Understanding,"Sayeed Shafayet Chowdhury, Soumyadeep Chandra, Kaushik Roy",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.17497"" target=""_blank"">2401.17497</a>",,2025-12-03 22:39:25
Provably Robust Multi-bit Watermarking for AI-generated Text via Error Correction Code,"Wenjie Qu, Dong Yin, Zixin He, Wei Zou, Tianyang Tao, Jinyuan Jia, Jiaheng Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.16820"" target=""_blank"">2401.16820</a>",,2025-12-03 22:39:25
LESSON: Multi-Label Adversarial False Data Injection Attack for Deep Learning Locational Detection,"Jiwei Tian, Chao Shen, Buhong Wang, Xiaofang Xia, Meng Zhang, Chenhao Lin, Qian Li",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.16001"" target=""_blank"">2401.16001</a>",,2025-12-03 22:39:25
Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization,"Guang Lin, Chao Li, Jianhai Zhang, Toshihisa Tanaka, Qibin Zhao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.16352"" target=""_blank"">2401.16352</a>",,2025-12-03 22:39:25
Exploring Adversarial Threat Models in Cyber Physical Battery Systems,"Shanthan Kumar Padisala, Shashank Dhananjay Vyas, Satadru Dey",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.13801"" target=""_blank"">2401.13801</a>",,2025-12-03 22:39:25
Transparency Attacks: How Imperceptible Image Layers Can Fool AI Perception,"Forrest McKee, David Noever",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.15817"" target=""_blank"">2401.15817</a>",,2025-12-03 22:39:25
MITS-GAN: Safeguarding Medical Imaging from Tampering with Generative Adversarial Networks,"Giovanni Pasqualino, Luca Guarnera, Alessandro Ortis, Sebastiano Battiato",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09624"" target=""_blank"">2401.09624</a>",,2025-12-03 22:39:25
Differentially Private and Adversarially Robust Machine Learning: An Empirical Evaluation,"Janvi Thakkar, Giulio Zizzo, Sergio Maffeis",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10405"" target=""_blank"">2401.10405</a>",,2025-12-03 22:39:25
The Surprising Harmfulness of Benign Overfitting for Adversarial Robustness,"Yifan Hao, Tong Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12236"" target=""_blank"">2401.12236</a>",,2025-12-03 22:39:25
FIMBA: Evaluating the Robustness of AI in Genomics via Feature Importance Adversarial Attacks,"Heorhii Skovorodnikov, Hoda Alkhzaimi",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10657"" target=""_blank"">2401.10657</a>",,2025-12-03 22:39:25
Adversarial Robustness of Link Sign Prediction in Signed Graphs,"Jialong Zhou, Xing Ai, Yuni Lai, Tomasz Michalak, Gaolei Li, Jianhua Li, Kai Zhou",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10590"" target=""_blank"">2401.10590</a>",,2025-12-03 22:39:25
BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models,"Zhen Xiang, Fengqing Jiang, Zidi Xiong, Bhaskar Ramasubramanian, Radha Poovendran, Bo Li",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12242"" target=""_blank"">2401.12242</a>",,2025-12-03 22:39:25
Image Safeguarding: Reasoning with Conditional Vision Language Model and Obfuscating Unsafe Content Counterfactually,"Mazal Bethany, Brandon Wherry, Nishant Vishwamitra, Peyman Najafirad",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11035"" target=""_blank"">2401.11035</a>","<a href=""https://github.com/SecureAIAutonomyLab/ConditionalVLM"" target=""_blank"">SecureAIAutonomyLab</a>",2025-12-03 22:39:25
HGAttack: Transferable Heterogeneous Graph Adversarial Attack,"He Zhao, Zhiwei Zeng, Yongwei Wang, Deheng Ye, Chunyan Miao",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09945"" target=""_blank"">2401.09945</a>",,2025-12-03 22:39:25
Hijacking Attacks against Neural Networks by Analyzing Training Data,"Yunjie Ge, Qian Wang, Huayang Huang, Qi Li, Cong Wang, Chao Shen, Lingchen Zhao, Peipei Jiang, Zheng Fang, Shenyi Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09740"" target=""_blank"">2401.09740</a>",,2025-12-03 22:39:25
Adapters Mixup: Mixing Parameter-Efficient Adapters to Enhance the Adversarial Robustness of Fine-tuned Pre-trained Text Classifiers,"Tuc Nguyen, Thai Le",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10111"" target=""_blank"">2401.10111</a>",,2025-12-03 22:39:25
Investigating Training Strategies and Model Robustness of Low-Rank Adaptation for Language Modeling in Speech Recognition,"Yu Yu, Chao-Han Huck Yang, Tuan Dinh, Sungho Ryu, Jari Kolehmainen, Roger Ren, Denis Filimonov, Prashanth G. Shivakumar, Ankur Gandhe, Ariya Rastow, Jia Xu, Ivan Bulyko, Andreas Stolcke",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10447"" target=""_blank"">2401.10447</a>",,2025-12-03 22:39:25
PuriDefense: Randomized Local Implicit Adversarial Purification for Defending Black-box Query-based Attacks,"Ping Guo, Zhiyuan Yang, Xi Lin, Qingchuan Zhao, Qingfu Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10586"" target=""_blank"">2401.10586</a>",,2025-12-03 22:39:25
Power in Numbers: Robust reading comprehension by finetuning with four adversarial sentences per example,Ariel Marcus,arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10091"" target=""_blank"">2401.10091</a>",,2025-12-03 22:39:25
Cross-Modality Perturbation Synergy Attack for Person Re-identification,"Yunpeng Gong, Zhun Zhong, Yansong Qu, Zhiming Luo, Rongrong Ji, Min Jiang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10090"" target=""_blank"">2401.10090</a>","<a href=""https://github.com/finger-monkey/cmps__attack"" target=""_blank"">finger-monkey</a>",2025-12-03 22:39:25
Vulnerabilities of Foundation Model Integrated Federated Learning Under Adversarial Threats,"Chen Wu, Xi Li, Jiaqi Wang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10375"" target=""_blank"">2401.10375</a>",,2025-12-03 22:39:25
Lateral Phishing With Large Language Models: A Large Organization Comparative Study,"Mazal Bethany, Athanasios Galiopoulos, Emet Bethany, Mohammad Bahrami Karkevandi, Nicole Beebe, Nishant Vishwamitra, Peyman Najafirad",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09727"" target=""_blank"">2401.09727</a>",,2025-12-03 22:39:25
Large Language Models are Efficient Learners of Noise-Robust Speech Recognition,"Yuchen Hu, Chen Chen, Chao-Han Huck Yang, Ruizhe Li, Chao Zhang, Pin-Yu Chen, EnSiong Chng",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10446"" target=""_blank"">2401.10446</a>",,2025-12-03 22:39:25
Towards Scalable and Robust Model Versioning,"Wenxin Ding, Arjun Nitin Bhagoji, Ben Y. Zhao, Haitao Zheng",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09574"" target=""_blank"">2401.09574</a>",,2025-12-03 22:39:25
Artwork Protection Against Neural Style Transfer Using Locally Adaptive Adversarial Color Attack,"Zhongliang Guo, Junhao Dong, Yifei Qian, Kaixuan Wang, Weiye Li, Ziheng Guo, Yuheng Wang, Yanli Li, Ognjen Arandjelović, Lei Fang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.09673"" target=""_blank"">2401.09673</a>",,2025-12-03 22:39:25
Compositional Generative Inverse Design,"Tailin Wu, Takashi Maruyama, Long Wei, Tao Zhang, Yilun Du, Gianluca Iaccarino, Jure Leskovec",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.13171"" target=""_blank"">2401.13171</a>","<a href=""https://github.com/AI4Science-WestlakeU/cindm"" target=""_blank"">AI4Science-WestlakeU</a>",2025-12-03 22:39:25
Explainable and Transferable Adversarial Attack for ML-Based Network Intrusion Detectors,"Hangsheng Zhang, Dongqi Han, Yinlong Liu, Zhiliang Wang, Jiyan Sun, Shangyuan Zhuang, Jiqiang Liu, Jinsong Dong",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10691"" target=""_blank"">2401.10691</a>",,2025-12-03 22:39:25
Hacking Predictors Means Hacking Cars: Using Sensitivity Analysis to Identify Trajectory Prediction Vulnerabilities for Autonomous Driving Security,"Marsalis Gibson, David Babazadeh, Claire Tomlin, Shankar Sastry",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.10313"" target=""_blank"">2401.10313</a>",,2025-12-03 22:39:25
ToDA: Target-oriented Diffusion Attacker against Recommendation System,"Xiaohao Liu, Zhulin Tao, Ting Jiang, He Chang, Yunshan Ma, Xianglin Huang, Xiang Wang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12578"" target=""_blank"">2401.12578</a>",,2025-12-03 22:39:25
Robustness to distribution shifts of compressed networks for edge devices,"Lulan Shen, Ali Edalati, Brett Meyer, Warren Gross, James J. Clark",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12014"" target=""_blank"">2401.12014</a>",,2025-12-03 22:39:25
AdCorDA: Classifier Refinement via Adversarial Correction and Domain Adaptation,"Lulan Shen, Ali Edalati, Brett Meyer, Warren Gross, James J. Clark",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.13212"" target=""_blank"">2401.13212</a>",,2025-12-03 22:39:25
Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images,"Kuofeng Gao, Yang Bai, Jindong Gu, Shu-Tao Xia, Philip Torr, Zhifeng Li, Wei Liu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11170"" target=""_blank"">2401.11170</a>","<a href=""https://github.com/KuofengGao/Verbose_Images"" target=""_blank"">KuofengGao</a>",2025-12-03 22:39:25
DAFA: Distance-Aware Fair Adversarial Training,"Hyungyu Lee, Saehyung Lee, Hyemi Jang, Junsung Park, Ho Bae, Sungroh Yoon",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12532"" target=""_blank"">2401.12532</a>",,2025-12-03 22:39:25
The twin peaks of learning neural networks,"Elizaveta Demyanenko, Christoph Feinauer, Enrico M. Malatesta, Luca Saglietti",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12610"" target=""_blank"">2401.12610</a>",,2025-12-03 22:39:25
Fast Adversarial Training against Textual Adversarial Attacks,"Yichen Yang, Xin Liu, Kun He",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12461"" target=""_blank"">2401.12461</a>",,2025-12-03 22:39:25
A Training-Free Defense Framework for Robust Learned Image Compression,"Myungseo Song, Jinyoung Choi, Bohyung Han",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11902"" target=""_blank"">2401.11902</a>",,2025-12-03 22:39:25
Adversarial speech for voice privacy protection from Personalized Speech generation,"Shihao Chen, Liping Chen, Jie Zhang, KongAik Lee, Zhenhua Ling, Lirong Dai",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11857"" target=""_blank"">2401.11857</a>","<a href=""https://voiceprivacy.github.io/Adeversarial-Speech-with-YourTTS"" target=""_blank"">voiceprivacy.github.io</a>",2025-12-03 22:39:25
NEUROSEC: FPGA-Based Neuromorphic Audio Security,"Murat Isik, Hiruna Vishwamith, Yusuf Sur, Kayode Inadagbo, I. Can Dikmen",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12055"" target=""_blank"">2401.12055</a>",,2025-12-03 22:39:25
Unraveling Attacks in Machine Learning-based IoT Ecosystems: A Survey and the Open Libraries Behind Them,"Chao Liu, Boxi Chen, Wei Shao, Chris Zhang, Kelvin Wong, Yi Zhang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11723"" target=""_blank"">2401.11723</a>",,2025-12-03 22:39:25
A GAN-based data poisoning framework against anomaly detection in vertical federated learning,"Xiaolin Chen, Daoguang Zan, Wei Li, Bei Guan, Yongji Wang",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.08984"" target=""_blank"">2401.08984</a>",,2025-12-03 22:39:25
Finding a Needle in the Adversarial Haystack: A Targeted Paraphrasing Approach For Uncovering Edge Cases with Minimal Distribution Distortion,"Aly M. Kassem, Sherif Saad",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11373"" target=""_blank"">2401.11373</a>",,2025-12-03 22:39:25
Out-of-Distribution Detection & Applications With Ablated Learned Temperature Energy,"Will LeVine, Benjamin Pikus, Jacob Phillips, Berk Norman, Fernando Amat Gil, Sean Hendryx",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12129"" target=""_blank"">2401.12129</a>",,2025-12-03 22:39:25
How Robust Are Energy-Based Models Trained With Equilibrium Propagation? (99%),"Siddharth Mansingh, Michal Kucer, Garrett Kenyon, Juston Moore, Michael Teti",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11543"" target=""_blank"">2401.11543</a>",,2025-12-03 22:39:25
Analyzing the Quality Attributes of AI Vision Models in Open Repositories Under Adversarial Attacks,"Zerui Wang, Yan Liu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12261"" target=""_blank"">2401.12261</a>",,2025-12-03 22:39:25
Efficient local linearity regularization to overcome catastrophic overfitting,"Elias Abad Rocamora, Fanghui Liu, Grigorios G. Chrysos, Pablo M. Olmos, Volkan Cevher",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11618"" target=""_blank"">2401.11618</a>","<a href=""https://github.com/LIONS-EPFL/ELLE"" target=""_blank"">LIONS-EPFL</a>",2025-12-03 22:39:25
Susceptibility of Adversarial Attack on Medical Image Segmentation Models,"Zhongxuan Wang, Leo Xu",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11224"" target=""_blank"">2401.11224</a>","<a href=""https://github.com/ZhongxuanWang/adv_attk"" target=""_blank"">ZhongxuanWang</a>",2025-12-03 22:39:25
Text Embedding Inversion Security for Multilingual Language Models,"Yiyi Chen, Heather Lent, Johannes Bjerva",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.12192"" target=""_blank"">2401.12192</a>",,2025-12-03 22:39:25
CARE: Ensemble Adversarial Robustness Evaluation Against Adaptive Attackers for Security Applications,"Hangsheng Zhang, Jiqiang Liu, Jinsong Dong",arXiv,2024-01,"<a href=""http://arxiv.org/abs/2401.11126"" target=""_blank"">2401.11126</a>",,2025-12-03 22:39:25
Poisoning $\times$ Evasion: Symbiotic Adversarial Robustness for Graph Neural Networks,"Ege Erdogan, Simon Geisler, Stephan Günnemann",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.05502"" target=""_blank"">2312.05502</a>",,2025-12-03 22:39:25
Initialization Matters for Adversarial Transfer Learning,"Andong Hua, Jindong Gu, Zhiyu Xue, Nicholas Carlini, Eric Wong, Yao Qin",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.05716"" target=""_blank"">2312.05716</a>","<a href=""https://github.com/DongXzz/RoLI"" target=""_blank"">DongXzz</a>",2025-12-03 22:39:25
Dynamic Adversarial Attacks on Autonomous Driving Systems,"Amirhosein Chahe, Chenan Wang, Abhishek Jeyapratap, Kaidi Xu, Lifeng Zhou",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06701"" target=""_blank"">2312.06701</a>",,2025-12-03 22:39:25
Improving Adversarial Robust Fairness via Anti-Bias Soft Label Distillation,"Shiji Zhao, Ranjie Duan, Xizhe Wang, Xingxing Wei",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.05508"" target=""_blank"">2312.05508</a>",,2025-12-03 22:39:25
Robust Graph Neural Network based on Graph Denoising,"Victor M. Tenorio, Samuel Rey, Antonio G. Marques",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06557"" target=""_blank"">2312.06557</a>",,2025-12-03 22:39:25
METAL: Metamorphic Testing Framework for Analyzing Large-Language Model Qualities,"Sangwon Hyun, Mingyu Guo, M. Ali Babar",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06056"" target=""_blank"">2312.06056</a>",,2025-12-03 22:39:25
An Ambiguity Measure for Recognizing the Unknowns in Deep Learning,Roozbeh Yousefzadeh,arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06077"" target=""_blank"">2312.06077</a>",,2025-12-03 22:39:25
SA-Attack: Improving Adversarial Transferability of Vision-Language Pre-training Models via Self-Augmentation,"Bangyan He, Xiaojun Jia, Siyuan Liang, Tianrui Lou, Yang Liu, Xiaochun Cao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04913"" target=""_blank"">2312.04913</a>",,2025-12-03 22:39:25
A Practical Survey on Emerging Threats from AI-driven Voice Attacks: How Vulnerable are Commercial Voice Control Systems? (76%),"Yuanda Wang, Qiben Yan, Nikolay Ivanov, Xun Chen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06010"" target=""_blank"">2312.06010</a>",,2025-12-03 22:39:25
Data-Free Hard-Label Robustness Stealing Attack,"Xiaojian Yuan, Kejiang Chen, Wen Huang, Jie Zhang, Weiming Zhang, Nenghai Yu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.05924"" target=""_blank"">2312.05924</a>","<a href=""https://github.com/LetheSec/DFHL-RS-Attack"" target=""_blank"">LetheSec</a>",2025-12-03 22:39:25
HC-Ref: Hierarchical Constrained Refinement for Robust Adversarial Training of GNNs,"Xiaobing Pei, Haoran Yang, Gang Shen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04879"" target=""_blank"">2312.04879</a>",,2025-12-03 22:39:25
Annotation-Free Group Robustness via Loss-Based Resampling,"Mahdi Ghaznavi, Hesam Asadollahzadeh, HamidReza Yaghoubi Araghi, Fahimeh Hosseini Noohdani, Mohammad Hossein Rohban, Mahdieh Soleymani Baghshah",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04893"" target=""_blank"">2312.04893</a>",,2025-12-03 22:39:25
MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness,"Xiaoyun Xu, Shujian Yu, Jingzheng Wu, Stjepan Picek",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04960"" target=""_blank"">2312.04960</a>","<a href=""https://github.com/xiaoyunxxy/MIMIR"" target=""_blank"">xiaoyunxxy</a>",2025-12-03 22:39:25
BELT: Old-School Backdoor Attacks can Evade the State-of-the-Art Defense with Backdoor Exclusivity Lifting,"Huming Qiu, Junjie Sun, Mi Zhang, Xudong Pan, Min Yang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04902"" target=""_blank"">2312.04902</a>",,2025-12-03 22:39:25
An adversarial attack approach for eXplainable AI evaluation on deepfake detection models,"Balachandar Gowrisankar, Vrizlynn L. L. Thing",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06627"" target=""_blank"">2312.06627</a>",,2025-12-03 22:39:25
A Red Teaming Framework for Securing AI in Maritime Autonomous Systems,"Mathew J. Walter, Aaron Barrett, Kimberly Tam",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11500"" target=""_blank"">2312.11500</a>",,2025-12-03 22:39:25
HuRef: HUman-REadable Fingerprint for Large Language Models,"Boyi Zeng, Lizheng Wang, Yuncong Hu, Yi Xu, Chenghu Zhou, Xinbing Wang, Yu Yu, Zhouhan Lin",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04828"" target=""_blank"">2312.04828</a>","<a href=""https://github.com/LUMIA-Group/HuRef"" target=""_blank"">LUMIA-Group</a>",2025-12-03 22:39:25
Topology-Based Reconstruction Prevention for Decentralised Learning,"Florine W. Delft University of Technology, the Netherlands and Dekker, Zekeriya Delft University of Technology, the Netherlands and Erkin, Mauro Università di Padova, Italy Delft University of Technology, the Netherlands and Conti",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.05248"" target=""_blank"">2312.05248</a>",,2025-12-03 22:39:25
MimicDiffusion: Purifying Adversarial Perturbation via Mimicking Clean Diffusion Model,"Kaiyu Song, Hanjiang Lai",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04802"" target=""_blank"">2312.04802</a>",,2025-12-03 22:39:25
OT-Attack: Enhancing Adversarial Transferability of Vision-Language Models via Optimal Transport Optimization,"Dongchen Han, Xiaojun Jia, Yang Bai, Jindong Gu, Yang Liu, Xiaochun Cao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04403"" target=""_blank"">2312.04403</a>",,2025-12-03 22:39:25
FreqFed: A Frequency Analysis-Based Approach for Mitigating Poisoning Attacks in Federated Learning,"Hossein Fereidooni, Alessandro Pegoraro, Phillip Rieger, Alexandra Dmitrienko, Ahmad-Reza Sadeghi",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04432"" target=""_blank"">2312.04432</a>",,2025-12-03 22:39:25
Forcing Generative Models to Degenerate Ones: The Power of Data Poisoning Attacks,"Shuli Jiang, Swanand Ravindra Kadhe, Yi Zhou, Ling Cai, Nathalie Baracaldo",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04748"" target=""_blank"">2312.04748</a>",,2025-12-03 22:39:25
DeceptPrompt: Exploiting LLM-driven Code Generation via Adversarial Natural Language Instructions,"Fangzhou Wu, Xiaogeng Liu, Chaowei Xiao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04730"" target=""_blank"">2312.04730</a>",,2025-12-03 22:39:25
DTA: Distribution Transform-based Attack for Query-Limited Scenario,"Renyang Liu, Wei Zhou, Xin Jin, Song Gao, Yuanyu Wang, Ruxin Wang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07245"" target=""_blank"">2312.07245</a>",,2025-12-03 22:39:25
Adversarial Camera Patch: An Effective and Robust Physical-World Attack on Object Detectors,Kalibinuer Tiliwalidi,arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06163"" target=""_blank"">2312.06163</a>",,2025-12-03 22:39:25
Promoting Counterfactual Robustness through Diversity,"Francesco Leofante, Nico Potyka",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06564"" target=""_blank"">2312.06564</a>",,2025-12-03 22:39:25
Defense Against Adversarial Attacks using Convolutional Auto-Encoders,Shreyasi Mandal,arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03520"" target=""_blank"">2312.03520</a>",,2025-12-03 22:39:25
May the Noise be with you: Adversarial Training without Adversarial Examples,"Ayoub Arous, Andres F Lopez-Lopera, Nael Abu-Ghazaleh, Ihsen Alouani",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08877"" target=""_blank"">2312.08877</a>",,2025-12-03 22:39:25
QuadAttack: A Quadratic Programming Approach to Ordered Top-K Attacks,"Thomas Paniagua, Ryan Grainger, Tianfu Wu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11510"" target=""_blank"">2312.11510</a>",,2025-12-03 22:39:25
Attacking the Loop: Adversarial Attacks on Graph-based Loop Closure Detection,"Jonathan J. Y. Kim, Martin Urschler, Patricia J. Riddle, Jorg S. Wicker",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06991"" target=""_blank"">2312.06991</a>",,2025-12-03 22:39:25
ReRoGCRL: Representation-based Robustness in Goal-Conditioned Reinforcement Learning,"Xiangyu Yin, Sihao Wu, Jiaxu Liu, Meng Fang, Xingyu Zhao, Xiaowei Huang, Wenjie Ruan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07392"" target=""_blank"">2312.07392</a>","<a href=""https://github.com/TrustAI/ReRoGCRL"" target=""_blank"">TrustAI</a>",2025-12-03 22:39:25
Robust MRI Reconstruction by Smoothed Unrolling (SMUG),"Shijun Liang, Van Hoang Minh Nguyen, Jinghan Jia, Ismail Alkhouri, Sijia Liu, Saiprasad Ravishankar",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07784"" target=""_blank"">2312.07784</a>",,2025-12-03 22:39:25
"Cost Aware Untargeted Poisoning Attack against Graph Neural Networks,","Yuwei Han, Yuni Lai, Yulin Zhu, Kai Zhou",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07158"" target=""_blank"">2312.07158</a>",,2025-12-03 22:39:25
EdgePruner: Poisoned Edge Pruning in Graph Contrastive Learning,"Hiroya Kato, Kento Hasegawa, Seira Hidano, Kazuhide Fukushima",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07022"" target=""_blank"">2312.07022</a>",,2025-12-03 22:39:25
Causality Analysis for Evaluating the Security of Large Language Models,"Wei Zhao, Zhe Li, Jun Sun",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07876"" target=""_blank"">2312.07876</a>",,2025-12-03 22:39:25
SimAC: A Simple Anti-Customization Method for Protecting Face Privacy against Text-to-Image Synthesis of Diffusion Models,"Feifei Wang, Zhentao Tan, Tianyi Wei, Yue Wu, Qidong Huang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07865"" target=""_blank"">2312.07865</a>","<a href=""https://github.com/somuchtome/SimAC"" target=""_blank"">somuchtome</a>",2025-12-03 22:39:25
Divide-and-Conquer Attack: Harnessing the Power of LLM to Bypass Safety Filters of Text-to-Image Models,"Yimo Deng, Huangxun Chen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07130"" target=""_blank"">2312.07130</a>","<a href=""https://github.com/researchcode001/Divide-and-Conquer-Attack"" target=""_blank"">researchcode001</a>",2025-12-03 22:39:25
Eroding Trust In Aerial Imagery: Comprehensive Analysis and Evaluation Of Adversarial Attacks In Geospatial Systems,"Michael Lanier, Aayush Dhakal, Zhexiao Xiong, Arthur Li, Nathan Jacobs, Yevgeniy Vorobeychik",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07389"" target=""_blank"">2312.07389</a>",,2025-12-03 22:39:25
Securing Graph Neural Networks in MLaaS: A Comprehensive Realization of Query-based Integrity Verification,"Bang Wu, Xingliang Yuan, Shuo Wang, Qi Li, Minhui Xue, Shirui Pan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07870"" target=""_blank"">2312.07870</a>",,2025-12-03 22:39:25
Majority is Not Required: A Rational Analysis of the Private Double-Spend Attack from a Sub-Majority Adversary,"Yanni Georghiades, Rajesh Mishra, Karl Kreder, Sriram Vishwanath",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07709"" target=""_blank"">2312.07709</a>",,2025-12-03 22:39:25
Rethinking Model Inversion Attacks With Patch-Wise Reconstruction,"Jonggyu Jang, Hyeonsu Lyu, Hyun Jong Yang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07040"" target=""_blank"">2312.07040</a>",,2025-12-03 22:39:25
MalPurifier: Enhancing Android Malware Detection with Adversarial Purification against Evasion Attacks,"Yuyang Zhou, Guang Cheng, Zongyao Chen, Shui Yu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06423"" target=""_blank"">2312.06423</a>",,2025-12-03 22:39:25
Towards Transferable Adversarial Attacks with Centralized Perturbation,"Shangbo Wu, Yu-an Tan, Yajie Wang, Ruinan Ma, Wencong Ma, Yuanzhang Li",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06199"" target=""_blank"">2312.06199</a>",,2025-12-03 22:39:25
Sparse but Strong: Crafting Adversarially Robust Graph Lottery Tickets,"Subhajit Dutta Chowdhury, Zhiyu Ni, Qingyuan Peng, Souvik Kundu, Pierluigi Nuzzo",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06568"" target=""_blank"">2312.06568</a>",,2025-12-03 22:39:25
Reward Certification for Policy Smoothed Reinforcement Learning,"Ronghui Mu, Leandro Soriano Marcolino, Tianle Zhang, Yanghao Zhang, Xiaowei Huang, Wenjie Ruan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06436"" target=""_blank"">2312.06436</a>",,2025-12-03 22:39:25
Activation Gradient based Poisoned Sample Detection Against Backdoor Attacks,"Danni Yuan, Shaokui Wei, Mingda Zhang, Li Liu, Baoyuan Wu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06230"" target=""_blank"">2312.06230</a>","<a href=""https://github.com/SCLBD/bdzoo2/blob/dev/detection_pretrain/agpd.py"" target=""_blank"">detection_pretrain</a>",2025-12-03 22:39:25
Poisoned ChatGPT Finds Work for Idle Hands: Exploring Developers' Coding Practices with Insecure Suggestions from Poisoned AI Models,"Sanghak Oh, Kiho Lee, Seonhye Park, Doowon Kim, Hyoungshick Kim",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.06227"" target=""_blank"">2312.06227</a>",,2025-12-03 22:39:25
Defense against ML-based Power Side-channel Attacks on DNN Accelerators with Adversarial Attacks,"Xiaobei Yan, Chip Hong Chang, Tianwei Zhang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04035"" target=""_blank"">2312.04035</a>",,2025-12-03 22:39:25
Fool the Hydra: Adversarial Attacks against Multi-view Object Detection Systems,"Bilel Tarchoun, Quazi Mishkatul Alam, Nael Abu-Ghazaleh, Ihsen Alouani",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00173"" target=""_blank"">2312.00173</a>",,2025-12-03 22:39:25
Node-aware Bi-smoothing: Certified Robustness against Graph Injection Attacks,"Yuni Lai, Yulin Zhu, Bailin Pan, Kai Zhou",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03979"" target=""_blank"">2312.03979</a>",,2025-12-03 22:39:25
The Philosopher's Stone: Trojaning Plugins of Large Language Models,"Tian Dong, Minhui Xue, Guoxing Chen, Rayne Holland, Yan Meng, Shaofeng Li, Zhen Liu, Haojin Zhu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00374"" target=""_blank"">2312.00374</a>",,2025-12-03 22:39:25
Evaluating the Security of Satellite Systems,"Roy Peled, Eran Aizikovich, Edan Habler, Yuval Elovici, Asaf Shabtai",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01330"" target=""_blank"">2312.01330</a>",,2025-12-03 22:39:25
Exploring Adversarial Robustness of LiDAR-Camera Fusion Model in Autonomous Driving,"Bo Yang, Xiaoyu Ji, Xiaoyu Ji, Xiaoyu Ji, Xiaoyu Ji",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01468"" target=""_blank"">2312.01468</a>",,2025-12-03 22:39:25
Towards Sample-specific Backdoor Attack with Clean Labels via Attribute Trigger,"Yiming Li, Mingyan Zhu, Junfeng Guo, Tao Wei, Shu-Tao Xia, Zhan Qin",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04584"" target=""_blank"">2312.04584</a>",,2025-12-03 22:39:25
TranSegPGD: Improving Transferability of Adversarial Examples on Semantic Segmentation,"Xiaojun Jia, Jindong Gu, Yihao Huang, Simeng Qin, Qing Guo, Yang Liu, Xiaochun Cao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02207"" target=""_blank"">2312.02207</a>",,2025-12-03 22:39:25
Rethinking PGD Attack: Is Sign Function Necessary? (98%),"Junjie Yang, Tianlong Chen, Xuxi Chen, Zhangyang Wang, Yingbin Liang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01260"" target=""_blank"">2312.01260</a>","<a href=""https://github.com/JunjieYang97/RGD"" target=""_blank"">JunjieYang97</a>",2025-12-03 22:39:25
PROFL: A Privacy-Preserving Federated Learning Method with Stringent Defense Against Poisoning Attacks,"Yisheng Zhong, Li-Ping Wang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01045"" target=""_blank"">2312.01045</a>",,2025-12-03 22:39:25
Mendata: A Framework to Purify Manipulated Training Data,"Zonghao Huang, Neil Gong, Michael K. Reiter",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01281"" target=""_blank"">2312.01281</a>",,2025-12-03 22:39:25
TransURL: Improving malicious URL detection with multi-layer Transformer encoding and multi-scale pyramid features,"Ruitong Liu, Yanbin Wang, Zhenhao Guo, Haitao Xu, Zhan Qin, Wenrui Ma, Fan Zhang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00508"" target=""_blank"">2312.00508</a>","<a href=""https://github.com/Vul-det/TransURL/"" target=""_blank"">TransURL</a>",2025-12-03 22:39:25
Survey of Security Issues in Memristor-based Machine Learning Accelerators for RF Analysis,"William Lillis, Max Cohen Hoffing, Wayne Burleson",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00942"" target=""_blank"">2312.00942</a>",,2025-12-03 22:39:25
Deep Generative Attacks and Countermeasures for Data-Driven Offline Signature Verification,"An Ngo, MinhPhuong Cao, Rajesh Kumar",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00987"" target=""_blank"">2312.00987</a>",,2025-12-03 22:39:25
"Temperature Balancing, Layer-wise Weight Analysis, and Neural Network Training","Yefan Zhou, Tianyu Pang, Keqin Liu, Charles H. Martin, Michael W. Mahoney, Yaoqing Yang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00359"" target=""_blank"">2312.00359</a>",,2025-12-03 22:39:25
RoAST: Robustifying Language Models via Adversarial Perturbation with Selective Training,"Jaehyung Kim, Yuning Mao, Rui Hou, Hanchao Yu, Davis Liang, Pascale Fung, Qifan Wang, Fuli Feng, Lifu Huang, Madian Khabsa",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.04032"" target=""_blank"">2312.04032</a>",,2025-12-03 22:39:25
Crystal: Enhancing Blockchain Mining Transparency with Quorum Certificate,"Jianyu Niu, Fangyu Gai, Runchao Han, Ren Zhang, Yinqian Zhang, Chen Feng",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00741"" target=""_blank"">2312.00741</a>",,2025-12-03 22:39:25
Improving the Robustness of Quantized Deep Neural Networks to White-Box Attacks using Stochastic Quantization and Information-Theoretic Ensemble Training,"Saurabh Farkya, Aswin Raghavan, Avi Ziskind",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00105"" target=""_blank"">2312.00105</a>",,2025-12-03 22:39:25
Universal Backdoor Attacks,"Benjamin Schneider, Nils Lukas, Florian Kerschbaum",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00157"" target=""_blank"">2312.00157</a>",,2025-12-03 22:39:25
Radio Signal Classification by Adversarially Robust Quantum Machine Learning,"Yanqiu Wu, Eromanga Adermann, Chandra Thapa, Seyit Camtepe, Hajime Suzuki, Muhammad Usman",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07821"" target=""_blank"">2312.07821</a>",,2025-12-03 22:39:25
Optimal Attack and Defense for Reinforcement Learning,"Jeremy McMahan, Young Wu, Xiaojin Zhu, Qiaomin Xie",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00198"" target=""_blank"">2312.00198</a>",,2025-12-03 22:39:25
Can Protective Perturbation Safeguard Personal Data from Being Exploited by Stable Diffusion? (74%),"Zhengyue Zhao, Jinhao Duan, Kaidi Xu, Chenan Wang, Rui Zhangp Zidong Dup Qi Guo, Xing Hu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00084"" target=""_blank"">2312.00084</a>",,2025-12-03 22:39:25
Mark My Words: Analyzing and Evaluating Language Model Watermarks,"Julien Piet, Chawin Sitawarin, Vivian Fang, Norman Mu, David Wagner",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00273"" target=""_blank"">2312.00273</a>","<a href=""https://github.com/wagner-group/MarkMyWords"" target=""_blank"">wagner-group</a>",2025-12-03 22:39:25
Elijah: Eliminating Backdoors Injected in Diffusion Models via Distribution Shift,"Shengwei An, Sheng-Yen Chou, Kaiyuan Zhang, Qiuling Xu, Guanhong Tao, Guangyu Shen, Siyuan Cheng, Shiqing Ma, Pin-Yu Chen, Tsung-Yi Ho, Xiangyu Zhang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00050"" target=""_blank"">2312.00050</a>",,2025-12-03 22:39:25
Presentation Attack Detection using Convolutional Neural Networks and Local Binary Patterns,"Justin Spencer, Deborah Lawrence, Prosenjit Chatterjee, Kaushik Roy, Albert Esterline, Jung-Hee Kim",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00041"" target=""_blank"">2312.00041</a>",,2025-12-03 22:39:25
Bergeron: Combating Adversarial Attacks through a Conscience-Based Alignment Framework,"Matthew Pisano, Peter Ly, Abraham Sanders, Bingsheng Yao, Dakuo Wang, Tomek Strzalkowski, Mei Si",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.00029"" target=""_blank"">2312.00029</a>",,2025-12-03 22:39:25
OCGEC: One-class Graph Embedding Classification for DNN Backdoor Detection,"Haoyu Jiang, Haiyang Yu, Nan Li, Ping Yi",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01585"" target=""_blank"">2312.01585</a>","<a href=""https://github.com/jhy549/OCGEC"" target=""_blank"">jhy549</a>",2025-12-03 22:39:25
QuantAttack: Exploiting Dynamic Quantization to Attack Vision Transformers,"Amit Baras, Alon Zolfi, Yuval Elovici, Asaf Shabtai",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02220"" target=""_blank"">2312.02220</a>",,2025-12-03 22:39:25
Rejuvenating image-GPT as Strong Visual Representation Learners,"Sucheng Ren, Zeyu Wang, Hongru Zhu, Junfei Xiao, Alan Yuille, Cihang Xie",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02147"" target=""_blank"">2312.02147</a>","<a href=""https://github.com/OliverRensu/D-iGPT"" target=""_blank"">OliverRensu</a>",2025-12-03 22:39:25
Auto DP-SGD: Dual Improvements of Privacy and Accuracy via Automatic Clipping Threshold and Noise Multiplier Estimation,"Sai Venkatesh Chilukoti, Md Imran Hossen, Liqun Shan, Vijay Srinivas Tida, Xiai Hei",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02400"" target=""_blank"">2312.02400</a>",,2025-12-03 22:39:25
Detecting Voice Cloning Attacks via Timbre Watermarking,"Chang Liu, Jie Zhang, Tianwei Zhang, Xi Yang, Weiming Zhang, Nenghai Yu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03410"" target=""_blank"">2312.03410</a>","<a href=""https://timbrewatermarking.github.io/samples"" target=""_blank"">timbrewatermarking.github.io</a>",2025-12-03 22:39:25
Synthesizing Physical Backdoor Datasets: An Automated Framework Leveraging Deep Generative Models,"Sze Jue Yang, Chinh D. La, Quang H. Nguyen, Eugene Bagdasaryan, Kok-Seng Wong, Anh Tuan Tran, Chee Seng Chan, Khoa D. Doan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03419"" target=""_blank"">2312.03419</a>",,2025-12-03 22:39:25
Dr,"Matteo Gioele Collu, Tom Janssen-Groesbeek, Stefanos Koffas, Mauro Conti, Stjepan Picek",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03853"" target=""_blank"">2312.03853</a>",,2025-12-03 22:39:25
MICRO: Model-Based Offline Reinforcement Learning with a Conservative Bellman Operator,"Xiao-Yin Liu, Xiao-Hu Zhou, Guo-Tao Li, Hao Li, Mei-Jiang Gui, Tian-Yu Xiang, De-Xing Huang, Zeng-Guang Hou",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03991"" target=""_blank"">2312.03991</a>",,2025-12-03 22:39:25
Generating Visually Realistic Adversarial Patch,"Xiaosen Wang, Kunyu Wang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03030"" target=""_blank"">2312.03030</a>",,2025-12-03 22:39:25
A Simple Framework to Enhance the Adversarial Robustness of Deep Learning-based Intrusion Detection System,"Xinwei Yuan, Shu Han, Wei Huang, Hongliang Ye, Xianglong Kong, Fan Zhang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03245"" target=""_blank"">2312.03245</a>",,2025-12-03 22:39:25
Realistic Scatterer Based Adversarial Attacks on SAR Image Classifiers,"Tian Ye, Rajgopal Kannan, Viktor Prasanna, Carl Busart, Lance Kaplan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02912"" target=""_blank"">2312.02912</a>",,2025-12-03 22:39:25
ScAR: Scaling Adversarial Robustness for LiDAR Object Detection,"Xiaohu Lu, Hayder Radha",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03085"" target=""_blank"">2312.03085</a>","<a href=""https://github.com/xiaohulugo/ScAR-IROS2023"" target=""_blank"">xiaohulugo</a>",2025-12-03 22:39:25
Class Incremental Learning for Adversarial Robustness,"Seungju Cho, Hongsin Lee, Changick Kim",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03289"" target=""_blank"">2312.03289</a>",,2025-12-03 22:39:25
"Provable Adversarial Robustness for Group Equivariant Tasks: Graphs, Point Clouds, Molecules, and More","Jan Schuchardt, Yan Scholten, Stephan Günnemann",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02708"" target=""_blank"">2312.02708</a>",,2025-12-03 22:39:25
On the Robustness of Large Multimodal Models Against Image Adversarial Attacks,"Xuanimng Cui, Alejandro Aparcedo, Young Kyun Jang, Ser-Nam Lim",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03777"" target=""_blank"">2312.03777</a>",,2025-12-03 22:39:25
Scaling Laws for Adversarial Attacks on Language Model Activations,Stanislav Fort,arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02780"" target=""_blank"">2312.02780</a>",,2025-12-03 22:39:25
Indirect Gradient Matching for Adversarial Robust Distillation,"Hongsin Lee, Seungju Cho, Changick Kim",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03286"" target=""_blank"">2312.03286</a>",,2025-12-03 22:39:25
Robust Backdoor Detection for Deep Learning via Topological Evolution Dynamics,"Xiaoxing Mo, Yechao Zhang, Leo Yu Zhang, Wei Luo, Nan Sun, Shengshan Hu, Shang Gao, Yang Xiang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02673"" target=""_blank"">2312.02673</a>",,2025-12-03 22:39:25
Prompt Optimization via Adversarial In-Context Learning,"Xuan Long Do, Yiran Zhao, Hannah Brown, Yuxi Xie, James Xu Zhao, Nancy F. Chen, Kenji Kawaguchi, Michael Qizhe Xie, Junxian He",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02614"" target=""_blank"">2312.02614</a>",,2025-12-03 22:39:25
Privacy-Preserving Task-Oriented Semantic Communications Against Model Inversion Attacks,"Yanhu Wang, Shuaishuai Guo, Yiqin Deng, Haixia Zhang, Yuguang Fang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.03252"" target=""_blank"">2312.03252</a>",,2025-12-03 22:39:25
Machine Vision Therapy: Multimodal Large Language Models Can Enhance Visual Robustness via Denoising In-Context Learning,"Zhuo Huang, Chang Liu, Yinpeng Dong, Hang Su, Shibao Zheng, Tongliang Liu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02546"" target=""_blank"">2312.02546</a>","<a href=""https://github.com/tmllab/Machine_Vision_Therapy"" target=""_blank"">tmllab</a>",2025-12-03 22:39:25
Adversarial Medical Image with Hierarchical Feature Hiding,"Qingsong Yao, Zecheng He, Yuexiang Li, Yi Lin, Kai Ma, Yefeng Zheng, S. Kevin Zhou",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01679"" target=""_blank"">2312.01679</a>",,2025-12-03 22:39:25
InstructTA: Instruction-Tuned Targeted Attack for Large Vision-Language Models,"Xunguang Wang, Zhenlan Ji, Pingchuan Ma, Zongjie Li, Shuai Wang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01886"" target=""_blank"">2312.01886</a>","<a href=""https://github.com/xunguangwang/InstructTA"" target=""_blank"">xunguangwang</a>",2025-12-03 22:39:25
Singular Regularization with Information Bottleneck Improves Model's Adversarial Robustness,"Guanlin Li, Naishan Zheng, Man Zhou, Jie Zhang, Tianwei Zhang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.02237"" target=""_blank"">2312.02237</a>",,2025-12-03 22:39:25
Two-stage optimized unified adversarial patch for attacking visible-infrared cross-modal detectors in the physical world,"Chengyin Hu, Weiwen Shi",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.01789"" target=""_blank"">2312.01789</a>",,2025-12-03 22:39:25
SSTA: Salient Spatially Transformed Attack,"Renyang Liu, Wei Zhou, Sixin Wu, Jun Zhao, Kwok-Yan Lam",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07258"" target=""_blank"">2312.07258</a>",,2025-12-03 22:39:25
Focus on Hiders: Exploring Hidden Threats for Enhancing Adversarial Training,"Qian Li, Yuxiao Hu, Yinpeng Dong, Dongxiao Zhang, Yuntian Chen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07067"" target=""_blank"">2312.07067</a>",,2025-12-03 22:39:25
Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models,"Jiang Zhang, Qiong Wu, Yiming Xu, Cheng Cao, Zheng Du, Konstantinos Psounis",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08303"" target=""_blank"">2312.08303</a>",,2025-12-03 22:39:25
I-CEE: Tailoring Explanations of Image Classifications Models to User Expertise,"Yao Rong, Peizhu Qian, Vaibhav Unhelkar, Enkelejda Kasneci",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12102"" target=""_blank"">2312.12102</a>",,2025-12-03 22:39:25
Understanding the Regularity of Self-Attention with Optimal Transport,"Valérie Castin, Pierre Ablin, Gabriel Peyré",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14820"" target=""_blank"">2312.14820</a>",,2025-12-03 22:39:25
Attacking Byzantine Robust Aggregation in High Dimensions,"Sarthak Choudhary, Aashish Kolluri, Prateek Saxena",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14461"" target=""_blank"">2312.14461</a>",,2025-12-03 22:39:25
SODA: Protecting Proprietary Information in On-Device Machine Learning Models,"Akanksha Atrey, Ritwik Sinha, Saayan Mitra, Prashant Shenoy",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15036"" target=""_blank"">2312.15036</a>",,2025-12-03 22:39:25
Adaptive Domain Inference Attack,"Yuechun Gu, Keke Chen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15088"" target=""_blank"">2312.15088</a>",,2025-12-03 22:39:25
Energy-based learning algorithms for analog computing: a comparative study,"Benjamin Scellier, Maxence Ernoult, Jack Kendall, Suhas Kumar",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15103"" target=""_blank"">2312.15103</a>",,2025-12-03 22:39:25
AutoAugment Input Transformation for Highly Transferable Targeted Attacks,"Haobo Lu, Xin Liu, Kun He",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14218"" target=""_blank"">2312.14218</a>",,2025-12-03 22:39:25
Where and How to Attack? A Causality-Inspired Recipe for Generating Counterfactual Adversarial Examples,"Ruichu Cai, Yuxuan Zhu, Jie Qiao, Zefeng Liang, Furui Liu, Zhifeng Hao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.13628"" target=""_blank"">2312.13628</a>",,2025-12-03 22:39:25
Elevating Defenses: Bridging Adversarial Training and Watermarking for Model Resilience,"Janvi Thakkar, Giulio Zizzo, Sergio Maffeis",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14260"" target=""_blank"">2312.14260</a>",,2025-12-03 22:39:25
Adversarial Infrared Curves: An Attack on Infrared Pedestrian Detectors in the Physical World,"Chengyin Hu, Weiwen Shi",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14217"" target=""_blank"">2312.14217</a>",,2025-12-03 22:39:25
Exploiting Novel GPT-4 APIs,"Kellin Pelrine, Mohammad Taufeeque, Michał Zając, Euan McLean, Adam Gleave",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14302"" target=""_blank"">2312.14302</a>",,2025-12-03 22:39:25
Mutual-modality Adversarial Attack with Semantic Perturbation,"Jingwen Ye, Ruonan Yu, Songhua Liu, Xinchao Wang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12768"" target=""_blank"">2312.12768</a>",,2025-12-03 22:39:25
LRS: Enhancing Adversarial Transferability through Lipschitz Regularized Surrogate,"Tao Wu, Tie Luo, Donald C. Wunsch",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.13118"" target=""_blank"">2312.13118</a>","<a href=""https://github.com/TrustAIoT/LRS"" target=""_blank"">TrustAIoT</a>",2025-12-03 22:39:25
Adversarial Markov Games: On Adaptive Decision-Based Attacks and Defenses,"Ilias Tsingenopoulos, Vera Rimmer, Davy Preuveneers, Fabio Pierazzi, Lorenzo Cavallaro, Wouter Joosen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.13435"" target=""_blank"">2312.13435</a>",,2025-12-03 22:39:25
Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models,"Jingwei Yi, Yueqi Xie, Bin Zhu, Emre Kiciman, Guangzhong Sun, Xing Xie, Fangzhao Wu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14197"" target=""_blank"">2312.14197</a>",,2025-12-03 22:39:25
PGN: A perturbation generation network against deep reinforcement learning,"Xiangjuan Li, Feifan Li, Yang Li, Quan Pan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12904"" target=""_blank"">2312.12904</a>",,2025-12-03 22:39:25
ARBiBench: Benchmarking Adversarial Robustness of Binarized Neural Networks,"Peng Zhao, Jiehua Zhang, Bowen Peng, Longguang Wang, YingMei Wei, Yu Liu, Li Liu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.13575"" target=""_blank"">2312.13575</a>",,2025-12-03 22:39:25
Scaling Compute Is Not All You Need for Adversarial Robustness,"Edoardo Debenedetti, Zishen Wan, Maksym Andriushchenko, Vikash Sehwag, Kshitij Bhardwaj, Bhavya Kailkhura",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.13131"" target=""_blank"">2312.13131</a>",,2025-12-03 22:39:25
Doubly Perturbed Task Free Continual Learning,"Byung Hyun Lee, Min-hwan Oh, Se Young Chun",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.13027"" target=""_blank"">2312.13027</a>",,2025-12-03 22:39:25
Interactive Visualization of Time-Varying Flow Fields Using Particle Tracing Neural Networks,"Mengjiao Han, Jixian Li, Sudhanshu Sane, Shubham Gupta, Bei Wang, Steve Petruzza, Chris R. Johnson",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14973"" target=""_blank"">2312.14973</a>",,2025-12-03 22:39:25
Rethinking Randomized Smoothing from the Perspective of Scalability,"Anupriya Kumari, Devansh Bhardwaj, Sukrit Jindal",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12608"" target=""_blank"">2312.12608</a>",,2025-12-03 22:39:25
SkyMask: Attack-agnostic Robust Federated Learning with Fine-grained Learnable Masks,"Peishen Yan, Hao Wang, Tao Song, Yang Hua, Ruhui Ma, Ningxin Hu, Mohammad R. Haghighat, Haibing Guan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12484"" target=""_blank"">2312.12484</a>","<a href=""https://github.com/KoalaYan/SkyMask"" target=""_blank"">KoalaYan</a>",2025-12-03 22:39:25
Progressive Poisoned Data Isolation for Training-time Backdoor Defense,"Yiming Chen, Haiwei Wu, Jiantao Zhou",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12724"" target=""_blank"">2312.12724</a>",,2025-12-03 22:39:25
Adversarial AutoMixup,"Huafeng Qin, Xin Jin, Yun Jiang, Mounim A. El-Yacoubi, Xinbo Gao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11954"" target=""_blank"">2312.11954</a>",,2025-12-03 22:39:25
Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks,"Haz Sameen Shahgir, Xianghao Kong, Greg Ver Steeg, Yue Dong",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14440"" target=""_blank"">2312.14440</a>",,2025-12-03 22:39:25
MEAOD: Model Extraction Attack against Object Detectors,"Zeyu Li, Chenghui Shi, Yuwen Pu, Xuhong Zhang, Yu Li, Jinbao Li, Shouling Ji",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.14677"" target=""_blank"">2312.14677</a>",,2025-12-03 22:39:25
TVE: Learning Meta-attribution for Transferable Vision Explainer,"Guanchu Wang, Yu-Neng Chuang, Fan Yang, Mengnan Du, Chia-Yuan Chang, Shaochen Zhong, Zirui Liu, Zhaozhuo Xu, Kaixiong Zhou, Xuanting Cai, Xia Hu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15359"" target=""_blank"">2312.15359</a>",,2025-12-03 22:39:25
Securing NextG Systems against Poisoning Attacks on Federated Learning: A Game-Theoretic Solution,"Yalin E. Sagduyu, Tugba Erpek, Yi Shi",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.17164"" target=""_blank"">2312.17164</a>",,2025-12-03 22:39:25
Collapse-Aware Triplet Decoupling for Adversarially Robust Image Retrieval,"Qiwei Tian, Chenhao Lin, Zhengyu Zhao, Qian Li, Chao Shen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07364"" target=""_blank"">2312.07364</a>","<a href=""https://github.com/michaeltian108/CA-TRIDE"" target=""_blank"">michaeltian108</a>",2025-12-03 22:39:25
Jatmo: Prompt Injection Defense by Task-Specific Finetuning,"Julien Piet, Maha Alrashed, Chawin Sitawarin, Sizhe Chen, Zeming Wei, Elizabeth Sun, Basel Alomair, David Wagner",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.17673"" target=""_blank"">2312.17673</a>","<a href=""https://github.com/wagner-group/prompt-injection-defense"" target=""_blank"">wagner-group</a>",2025-12-03 22:39:25
Towards Faithful Explanations for Text Classification with Robustness Improvement and Explanation Guided Training,"Dongfang Li, Baotian Hu, Qingcai Chen, Shan He",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.17591"" target=""_blank"">2312.17591</a>",,2025-12-03 22:39:25
Adversarial Attacks on Image Classification Models: Analysis and Defense,"Jaydip Sen, Abhiraj Sen, Ananda Chatterjee",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16880"" target=""_blank"">2312.16880</a>",,2025-12-03 22:39:25
Attack Tree Analysis for Adversarial Evasion Attacks,"Yuki Yamaguchi, Toshiaki Aoki",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16957"" target=""_blank"">2312.16957</a>",,2025-12-03 22:39:25
BlackboxBench: A Comprehensive Benchmark of Black-box Adversarial Attacks,"Meixi Zheng, Xuanchen Yan, Zihao Zhu, Hongrui Chen, Baoyuan Wu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16979"" target=""_blank"">2312.16979</a>","<a href=""https://blackboxbenchmark.github.io/"" target=""_blank"">blackboxbenchmark.github.io</a>",2025-12-03 22:39:25
Can you See me? On the Visibility of NOPs against Android Malware Detectors,"Diego Soi, Davide Maiorca, Giorgio Giacinto, Harel Berger",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.17356"" target=""_blank"">2312.17356</a>",,2025-12-03 22:39:25
MVPatch: More Vivid Patch for Adversarial Camouflaged Attacks on Object Detectors in the Physical World,"Zheng Zhou, Hongbo Zhao, Ju Liu, Qiaosheng Zhang, Liwei Geng, Shuchang Lyu, Wenquan Feng",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.17431"" target=""_blank"">2312.17431</a>",,2025-12-03 22:39:25
Efficient Representation of the Activation Space in Deep Neural Networks,"Tanya Akumu, Celia Cintas, Girmaw Abebe Tadesse, Adebayo Oshingbesan, Skyler Speakman, Edward III McFowland",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08143"" target=""_blank"">2312.08143</a>",,2025-12-03 22:39:25
DOEPatch: Dynamically Optimized Ensemble Model for Adversarial Patches Generation,"Wenyi Tan, Yang Li, Chenxing Zhao, Zhunga Liu, Quan Pan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16907"" target=""_blank"">2312.16907</a>",,2025-12-03 22:39:25
Timeliness: A New Design Metric and a New Attack Surface,"Priyanka Kaswan, Sennur Ulukus",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.17220"" target=""_blank"">2312.17220</a>",,2025-12-03 22:39:25
Pre-trained Trojan Attacks for Visual Recognition,"Aishan Liu, Xinwei Zhang, Yisong Xiao, Yuguang Zhou, Siyuan Liang, Jiakai Wang, Xianglong Liu, Xiaochun Cao, Dacheng Tao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15172"" target=""_blank"">2312.15172</a>",,2025-12-03 22:39:25
Adversarial Attacks on LoRa Device Identification and Rogue Signal Detection with Deep Learning,"Yalin E. Sagduyu, Tugba Erpek",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16715"" target=""_blank"">2312.16715</a>",,2025-12-03 22:39:25
Domain Generalization with Vital Phase Augmentation,"Ingyun Lee, Wooju Lee, Hyun Myung",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16451"" target=""_blank"">2312.16451</a>","<a href=""https://github.com/excitedkid/vipaug"" target=""_blank"">excitedkid</a>",2025-12-03 22:39:25
From text to multimodal: a survey of adversarial example generation in question answering systems,"Gulsum Yigit, Mehmet Fatih Amasyali",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16156"" target=""_blank"">2312.16156</a>",,2025-12-03 22:39:25
Natural Adversarial Patch Generation Method Based on Latent Diffusion Model,"Xianyi Chen, Fazhan Liu, Dong Jiang, Kai Yan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16401"" target=""_blank"">2312.16401</a>",,2025-12-03 22:39:25
Robust Survival Analysis with Adversarial Regularization,"Michael Potter, Stefano Maxenti, Michael Everett",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16019"" target=""_blank"">2312.16019</a>","<a href=""https://github.com/mlpotter/SAWAR"" target=""_blank"">mlpotter</a>",2025-12-03 22:39:25
Universal Pyramid Adversarial Training for Improved ViT Performance,"Ping-yeh Chiang, Yipin Zhou, Omid Poursaeed, Satya Narayan Shukla, Ashish Shah, Tom Goldstein, Ser-Nam Lim",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.16339"" target=""_blank"">2312.16339</a>",,2025-12-03 22:39:25
GanFinger: GAN-Based Fingerprint Generation for Deep Neural Network Ownership Verification,"Huali Ren, Anli Yan, Xiaojun Ren, Pei-Gen Ye, Chong-zhi Gao, Zhili Zhou, Jin Li",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15617"" target=""_blank"">2312.15617</a>",,2025-12-03 22:39:25
Adversarial Item Promotion on Visually-Aware Recommender Systems by Guided Diffusion,"Lijian Chen, Wei Yuan, Tong Chen, Guanhua Ye, Quoc Viet Hung Nguyen, Hongzhi Yin",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15826"" target=""_blank"">2312.15826</a>",,2025-12-03 22:39:25
Punctuation Matters! Stealthy Backdoor Attack for Language Models,"Xuan Sheng, Zhicheng Li, Zhaoyang Han, Xiangmao Chang, Piji Li",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15867"" target=""_blank"">2312.15867</a>",,2025-12-03 22:39:25
Adversarial Data Poisoning for Fake News Detection: How to Make a Model Misclassify a Target News without Modifying It,"Federico Siciliano, Luca Maiano, Lorenzo Papa, Federica Baccin, Irene Amerini, Fabrizio Silvestri",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.15228"" target=""_blank"">2312.15228</a>",,2025-12-03 22:39:25
Shaping Up SHAP: Enhancing Stability through Layer-Wise Neighbor Selection,"Gwladys Kelodjou, Laurence Rozé, Véronique Masson, Luis Galárraga, Romaric Gaudel, Maurice Tchuente, Alexandre Termier",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.12115"" target=""_blank"">2312.12115</a>",,2025-12-03 22:39:25
Explainability-Based Adversarial Attack on Graphs Through Edge Perturbation,"Dibaloke Chanda, Saba Heidari Gheshlaghi, Nasim Yahya Soltani",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.17301"" target=""_blank"">2312.17301</a>",,2025-12-03 22:39:25
Gemini: A Family of Highly Capable Multimodal Models,"Team Gemini, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M. Dai, Anja Hauth, Katie Millican, David Silver, Slav Petrov, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser, Amelia Glaese, Jilin Chen, Emily Pitler, Timothy Lillicrap, Angeliki Lazaridou, Orhan Firat, James Molloy, Michael Isard, Paul R. Barham, Tom Hennigan, Benjamin Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, Ryan Doherty, Eli Collins, Clemens Meyer, Eliza Rutherford, Erica Moreira, Kareem Ayoub, Megha Goel, George Tucker, Enrique Piqueras, Maxim Krikun, Iain Barr, Nikolay Savinov, Ivo Danihelka, Becca Roelofs, Anaïs White, Anders Andreassen, Glehn Tamara von, Lakshman Yagati, Mehran Kazemi, Lucas Gonzalez, Misha Khalman, Jakub Sygnowski, Alexandre Frechette, Charlotte Smith, Laura Culp, Lev Proleev, Yi Luan, Xi Chen, James Lottes, Nathan Schucher, Federico Lebron, Alban Rrustemi, Natalie Clay, Phil Crone, Tomas Kocisky, Jeffrey Zhao, Bartek Perz, Dian Yu, Heidi Howard, Adam Bloniarz, Jack W. Rae, Han Lu, Laurent Sifre, Marcello Maggioni, Fred Alcober, Dan Garrette, Megan Barnes, Shantanu Thakoor, Jacob Austin, Gabriel Barth-Maron, William Wong, Rishabh Joshi, Rahma Chaabouni, Deeni Fatiha, Arun Ahuja, Ruibo Liu, Yunxuan Li, Sarah Cogan, Jeremy Chen, Chao Jia, Chenjie Gu, Qiao Zhang, Jordan Grimstad, Ale Jakse Hartman, Martin Chadwick, Gaurav Singh Tomar, Xavier Garcia, Evan Senter, Emanuel Taropa, Thanumalayan Sankaranarayana Pillai, Jacob Devlin, Michael Laskin, Diego de Las Casas, Dasha Valter, Connie Tao, Lorenzo Blanco, Adrià Puigdomènech Badia, David Reitter, Mianna Chen, Jenny Brennan, Clara Rivera, Sergey Brin, Shariq Iqbal, Gabriela Surita, Jane Labanowski, Abhi Rao, Stephanie Winkler, Emilio Parisotto, Yiming Gu, Kate Olszewska, Yujing Zhang, Ravi Addanki, Antoine Miech, Annie Louis, Laurent El Shafey, Denis Teplyashin, Geoff Brown, Elliot Catt, Nithya Attaluri, Jan Balaguer, Jackie Xiang, Pidong Wang, Zoe Ashwood, Anton Briukhov, Albert Webson, Sanjay Ganapathy, Smit Sanghavi, Ajay Kannan, Ming-Wei Chang, Axel Stjerngren, Josip Djolonga, Yuting Sun, Ankur Bapna, Matthew Aitchison, Pedram Pejman, Henryk Michalewski, Tianhe Yu, Cindy Wang, Juliette Love, Junwhan Ahn, Dawn Bloxwich, Kehang Han, Peter Humphreys, Thibault Sellam, James Bradbury, Varun Godbole, Sina Samangooei, Bogdan Damoc, Alex Kaskasoli, Sébastien M. R. Arnold, Vijay Vasudevan, Shubham Agrawal, Jason Riesa, Dmitry Lepikhin, Richard Tanburn, Srivatsan Srinivasan, Hyeontaek Lim, Sarah Hodkinson, Pranav Shyam, Johan Ferret, Steven Hand, Ankush Garg, Tom Le Paine, Jian Li, Yujia Li, Minh Giang, Alexander Neitz, Zaheer Abbas, Sarah York, Machel Reid, Elizabeth Cole, Aakanksha Chowdhery, Dipanjan Das, Dominika Rogozińska, Vitaly Nikolaev, Pablo Sprechmann, Zachary Nado, Lukas Zilka, Flavien Prost, Luheng He, Marianne Monteiro, Gaurav Mishra, Chris Welty, Josh Newlan, Dawei Jia, Miltiadis Allamanis, Clara Huiyi Hu, Liedekerke Raoul de, Justin Gilmer, Carl Saroufim, Shruti Rijhwani, Shaobo Hou, Disha Shrivastava, Anirudh Baddepudi, Alex Goldin, Adnan Ozturel, Albin Cassirer, Yunhan Xu, Daniel Sohn, Devendra Sachan, Reinald Kim Amplayo, Craig Swanson, Dessie Petrova, Shashi Narayan, Arthur Guez, Siddhartha Brahma, Jessica Landon, Miteyan Patel, Ruizhe Zhao, Kevin Villela, Luyu Wang, Wenhao Jia, Matthew Rahtz, Mai Giménez, Legg Yeung, Hanzhao Lin, James Keeling, Petko Georgiev, Diana Mincu, Boxi Wu, Salem Haykal, Rachel Saputro, Kiran Vodrahalli, James Qin, Zeynep Cankara, Abhanshu Sharma, Nick Fernando, Will Hawkins, Behnam Neyshabur, Solomon Kim, Adrian Hutter, Priyanka Agrawal, Alex Castro-Ros, George van den Driessche, Tao Wang, Fan Yang, Shuo-yiin Chang, Paul Komarek, Ross McIlroy, Mario Lučić, Guodong Zhang, Wael Farhan, Michael Sharman, Paul Natsev, Paul Michel, Yong Cheng, Yamini Bansal, Siyuan Qiao, Kris Cao, Siamak Shakeri, Christina Butterfield, Justin Chung, Paul Kishan Rubenstein, Shivani Agrawal, Arthur Mensch, Kedar Soparkar, Karel Lenc, Timothy Chung, Aedan Pope, Loren Maggiore, Jackie Kay, Priya Jhakra, Shibo Wang, Joshua Maynez, Mary Phuong, Taylor Tobin, Andrea Tacchetti, Maja Trebacz, Kevin Robinson, Yash Katariya, Sebastian Riedel, Paige Bailey, Kefan Xiao, Nimesh Ghelani, Lora Aroyo, Ambrose Slone, Neil Houlsby, Xuehan Xiong, Zhen Yang, Elena Gribovskaya, Jonas Adler, Mateo Wirth, Lisa Lee, Music Li, Thais Kagohara, Jay Pavagadhi, Sophie Bridgers, Anna Bortsova, Sanjay Ghemawat, Zafarali Ahmed, Tianqi Liu, Richard Powell, Vijay Bolina, Mariko Iinuma, Polina Zablotskaia, James Besley, Da-Woon Chung, Timothy Dozat, Ramona Comanescu, Xiance Si, Jeremy Greer, Guolong Su, Martin Polacek, Raphaël Lopez Kaufman, Simon Tokumine, Hexiang Hu, Elena Buchatskaya, Yingjie Miao, Mohamed Elhawaty, Aditya Siddhant, Nenad Tomasev, Jinwei Xing, Christina Greer, Helen Miller, Shereen Ashraf, Aurko Roy, Zizhao Zhang, Ada Ma, Angelos Filos, Milos Besta, Rory Blevins, Ted Klimenko, Chih-Kuan Yeh, Soravit Changpinyo, Jiaqi Mu, Oscar Chang, Mantas Pajarskas, Carrie Muir, Vered Cohen, Charline Le Lan, Krishna Haridasan, Amit Marathe, Steven Hansen, Sholto Douglas, Rajkumar Samuel, Mingqiu Wang, Sophia Austin, Chang Lan, Jiepu Jiang, Justin Chiu, Jaime Alonso Lorenzo, Lars Lowe Sjösund, Sébastien Cevey, Zach Gleicher, Thi Avrahami, Anudhyan Boral, Hansa Srinivasan, Vittorio Selo, Rhys May, Konstantinos Aisopos, Léonard Hussenot, Livio Baldini Soares, Kate Baumli, Michael B. Chang, Adrià Recasens, Ben Caine, Alexander Pritzel, Filip Pavetic, Fabio Pardo, Anita Gergely, Justin Frye, Vinay Ramasesh, Dan Horgan, Kartikeya Badola, Nora Kassner, Subhrajit Roy, Ethan Dyer, Víctor Campos, Alex Tomala, Yunhao Tang, Dalia El Badawy, Elspeth White, Basil Mustafa, Oran Lang, Abhishek Jindal, Sharad Vikram, Zhitao Gong, Sergi Caelles, Ross Hemsley, Gregory Thornton, Fangxiaoyu Feng, Wojciech Stokowiec, Ce Zheng, Phoebe Thacker, Çağlar Ünlü, Zhishuai Zhang, Mohammad Saleh, James Svensson, Max Bileschi, Piyush Patil, Ankesh Anand, Roman Ring, Katerina Tsihlas, Arpi Vezer, Marco Selvi, Toby Shevlane, Mikel Rodriguez, Tom Kwiatkowski, Samira Daruki, Keran Rong, Allan Dafoe, Nicholas FitzGerald, Keren Gu-Lemberg, Mina Khan, Lisa Anne Hendricks, Marie Pellat, Vladimir Feinberg, James Cobon-Kerr, Tara Sainath, Maribeth Rauh, Sayed Hadi Hashemi, Richard Ives, Yana Hasson, YaGuang Li, Eric Noland, Yuan Cao, Nathan Byrd, Le Hou, Qingze Wang, Thibault Sottiaux, Michela Paganini, Jean-Baptiste Lespiau, Alexandre Moufarek, Samer Hassan, Kaushik Shivakumar, Amersfoort Joost van, Amol Mandhane, Pratik Joshi, Anirudh Goyal, Matthew Tung, Andrew Brock, Hannah Sheahan, Vedant Misra, Cheng Li, Nemanja Rakićević, Mostafa Dehghani, Fangyu Liu, Sid Mittal, Junhyuk Oh, Seb Noury, Eren Sezener, Fantine Huot, Matthew Lamm, Cao Nicola De, Charlie Chen, Gamaleldin Elsayed, Ed Chi, Mahdis Mahdieh, Ian Tenney, Nan Hua, Ivan Petrychenko, Patrick Kane, Dylan Scandinaro, Rishub Jain, Jonathan Uesato, Romina Datta, Adam Sadovsky, Oskar Bunyan, Dominik Rabiej, Shimu Wu, John Zhang, Gautam Vasudevan, Edouard Leurent, Mahmoud Alnahlawi, Ionut Georgescu, Nan Wei, Ivy Zheng, Betty Chan, Pam G Rabinovitch, Piotr Stanczyk, Ye Zhang, David Steiner, Subhajit Naskar, Michael Azzam, Matthew Johnson, Adam Paszke, Chung-Cheng Chiu, Jaume Sanchez Elias, Afroz Mohiuddin, Faizan Muhammad, Jin Miao, Andrew Lee, Nino Vieillard, Sahitya Potluri, Jane Park, Elnaz Davoodi, Jiageng Zhang, Jeff Stanway, Drew Garmon, Abhijit Karmarkar, Zhe Dong, Jong Lee, Aviral Kumar, Luowei Zhou, Jonathan Evens, William Isaac, Zhe Chen, Johnson Jia, Anselm Levskaya, Zhenkai Zhu, Chris Gorgolewski, Peter Grabowski, Yu Mao, Alberto Magni, Kaisheng Yao, Javier Snaider, Norman Casagrande, Paul Suganthan, Evan Palmer, Geoffrey Irving, Edward Loper, Manaal Faruqui, Isha Arkatkar, Nanxin Chen, Izhak Shafran, Michael Fink, Alfonso Castaño, Irene Giannoumis, Wooyeol Kim, Mikołaj Rybiński, Ashwin Sreevatsa, Jennifer Prendki, David Soergel, Adrian Goedeckemeyer, Willi Gierke, Mohsen Jafari, Meenu Gaba, Jeremy Wiesner, Diana Gage Wright, Yawen Wei, Harsha Vashisht, Yana Kulizhskaya, Jay Hoover, Maigo Le, Lu Li, Chimezie Iwuanyanwu, Lu Liu, Kevin Ramirez, Andrey Khorlin, Albert Cui, Tian LIN, Marin Georgiev, Marcus Wu, Ricardo Aguilar, Keith Pallo, Abhishek Chakladar, Alena Repina, Xihui Wu, der Weide Tom van, Priya Ponnapalli, Caroline Kaplan, Jiri Simsa, Shuangfeng Li, Olivier Dousse, Fan Yang, Jeff Piper, Nathan Ie, Minnie Lui, Rama Pasumarthi, Nathan Lintz, Anitha Vijayakumar, Lam Nguyen Thiet, Daniel Andor, Pedro Valenzuela, Cosmin Paduraru, Daiyi Peng, Katherine Lee, Shuyuan Zhang, Somer Greene, Duc Dung Nguyen, Paula Kurylowicz, Sarmishta Velury, Sebastian Krause, Cassidy Hardin, Lucas Dixon, Lili Janzer, Kiam Choo, Ziqiang Feng, Biao Zhang, Achintya Singhal, Tejasi Latkar, Mingyang Zhang, Quoc Le, Elena Allica Abellan, Dayou Du, Dan McKinnon, Natasha Antropova, Tolga Bolukbasi, Orgad Keller, David Reid, Daniel Finchelstein, Maria Abi Raad, Remi Crocker, Peter Hawkins, Robert Dadashi, Colin Gaffney, Sid Lall, Ken Franko, Egor Filonov, Anna Bulanova, Rémi Leblond, Vikas Yadav, Shirley Chung, Harry Askham, Luis C. Cobo, Kelvin Xu, Felix Fischer, Jun Xu, Christina Sorokin, Chris Alberti, Chu-Cheng Lin, Colin Evans, Hao Zhou, Alek Dimitriev, Hannah Forbes, Dylan Banarse, Zora Tung, Jeremiah Liu, Mark Omernick, Colton Bishop, Chintu Kumar, Rachel Sterneck, Ryan Foley, Rohan Jain, Swaroop Mishra, Jiawei Xia, Taylor Bos, Geoffrey Cideron, Ehsan Amid, Francesco Piccinno, Xingyu Wang, Praseem Banzal, Petru Gurita, Hila Noga, Premal Shah, Daniel J. Mankowitz, Alex Polozov, Nate Kushman, Victoria Krakovna, Sasha Brown, MohammadHossein Bateni, Dennis Duan, Vlad Firoiu, Meghana Thotakuri, Tom Natan, Anhad Mohananey, Matthieu Geist, Sidharth Mudgal, Sertan Girgin, Hui Li, Jiayu Ye, Ofir Roval, Reiko Tojo, Michael Kwong, James Lee-Thorp, Christopher Yew, Quan Yuan, Sumit Bagri, Danila Sinopalnikov, Sabela Ramos, John Mellor, Abhishek Sharma, Aliaksei Severyn, Jonathan Lai, Kathy Wu, Heng-Tze Cheng, David Miller, Nicolas Sonnerat, Denis Vnukov, Rory Greig, Jennifer Beattie, Emily Caveness, Libin Bai, Julian Eisenschlos, Alex Korchemniy, Tomy Tsai, Mimi Jasarevic, Weize Kong, Phuong Dao, Zeyu Zheng, Frederick Liu, Fan Yang, Rui Zhu, Mark Geller, Tian Huey Teh, Jason Sanmiya, Evgeny Gladchenko, Nejc Trdin, Andrei Sozanschi, Daniel Toyama, Evan Rosen, Sasan Tavakkol, Linting Xue, Chen Elkind, Oliver Woodman, John Carpenter, George Papamakarios, Rupert Kemp, Sushant Kafle, Tanya Grunina, Rishika Sinha, Alice Talbert, Abhimanyu Goyal, Diane Wu, Denese Owusu-Afriyie, Cosmo Du, Chloe Thornton, Jordi Pont-Tuset, Pradyumna Narayana, Jing Li, Sabaer Fatehi, John Wieting, Omar Ajmeri, Benigno Uria, Tao Zhu, Yeongil Ko, Laura Knight, Amélie Héliou, Ning Niu, Shane Gu, Chenxi Pang, Dustin Tran, Yeqing Li, Nir Levine, Ariel Stolovich, Norbert Kalb, Rebeca Santamaria-Fernandez, Sonam Goenka, Wenny Yustalim, Robin Strudel, Ali Elqursh, Balaji Lakshminarayanan, Charlie Deck, Shyam Upadhyay, Hyo Lee, Mike Dusenberry, Zonglin Li, Xuezhi Wang, Kyle Levin, Raphael Hoffmann, Dan Holtmann-Rice, Olivier Bachem, Summer Yue, Sho Arora, Eric Malmi, Daniil Mirylenka, Qijun Tan, Christy Koh, Soheil Hassas Yeganeh, Siim Põder, Steven Zheng, Francesco Pongetti, Mukarram Tariq, Yanhua Sun, Lucian Ionita, Mojtaba Seyedhosseini, Pouya Tafti, Ragha Kotikalapudi, Zhiyu Liu, Anmol Gulati, Jasmine Liu, Xinyu Ye, Bart Chrzaszcz, Lily Wang, Nikhil Sethi, Tianrun Li, Ben Brown, Shreya Singh, Wei Fan, Aaron Parisi, Joe Stanton, Chenkai Kuang, Vinod Koverkathu, Christopher A. Choquette-Choo, Yunjie Li, TJ Lu, Abe Ittycheriah, Prakash Shroff, Pei Sun, Mani Varadarajan, Sanaz Bahargam, Rob Willoughby, David Gaddy, Ishita Dasgupta, Guillaume Desjardins, Marco Cornero, Brona Robenek, Bhavishya Mittal, Ben Albrecht, Ashish Shenoy, Fedor Moiseev, Henrik Jacobsson, Alireza Ghaffarkhah, Morgane Rivière, Alanna Walton, Clément Crepy, Alicia Parrish, Yuan Liu, Zongwei Zhou, Clement Farabet, Carey Radebaugh, Praveen Srinivasan, der Salm Claudia van, Andreas Fidjeland, Salvatore Scellato, Eri Latorre-Chimoto, Hanna Klimczak-Plucińska, David Bridson, Cesare Dario de, Tom Hudson, Piermaria Mendolicchio, Lexi Walker, Alex Morris, Ivo Penchev, Matthew Mauger, Alexey Guseynov, Alison Reid, Seth Odoom, Lucia Loher, Victor Cotruta, Madhavi Yenugula, Dominik Grewe, Anastasia Petrushkina, Tom Duerig, Antonio Sanchez, Steve Yadlowsky, Amy Shen, Amir Globerson, Adam Kurzrok, Lynette Webb, Sahil Dua, Dong Li, Preethi Lahoti, Surya Bhupatiraju, Dan Hurt, Haroon Qureshi, Ananth Agarwal, Tomer Shani, Matan Eyal, Anuj Khare, Shreyas Rammohan Belle, Lei Wang, Chetan Tekur, Mihir Sanjay Kale, Jinliang Wei, Ruoxin Sang, Brennan Saeta, Tyler Liechty, Yi Sun, Yao Zhao, Stephan Lee, Pandu Nayak, Doug Fritz, Manish Reddy Vuyyuru, John Aslanides, Nidhi Vyas, Martin Wicke, Xiao Ma, Taylan Bilal, Evgenii Eltyshev, Daniel Balle, Nina Martin, Hardie Cate, James Manyika, Keyvan Amiri, Yelin Kim, Xi Xiong, Kai Kang, Florian Luisier, Nilesh Tripuraneni, David Madras, Mandy Guo, Austin Waters, Oliver Wang, Joshua Ainslie, Jason Baldridge, Han Zhang, Garima Pruthi, Jakob Bauer, Feng Yang, Riham Mansour, Jason Gelman, Yang Xu, George Polovets, Ji Liu, Honglong Cai, Warren Chen, XiangHai Sheng, Emily Xue, Sherjil Ozair, Adams Yu, Christof Angermueller, Xiaowei Li, Weiren Wang, Julia Wiesinger, Emmanouil Koukoumidis, Yuan Tian, Anand Iyer, Madhu Gurumurthy, Mark Goldenson, Parashar Shah, MK Blake, Hongkun Yu, Anthony Urbanowicz, Jennimaria Palomaki, Chrisantha Fernando, Kevin Brooks, Ken Durden, Harsh Mehta, Nikola Momchev, Elahe Rahimtoroghi, Maria Georgaki, Amit Raul, Sebastian Ruder, Morgan Redshaw, Jinhyuk Lee, Komal Jalan, Dinghua Li, Ginger Perng, Blake Hechtman, Parker Schuh, Milad Nasr, Mia Chen, Kieran Milan, Vladimir Mikulik, Trevor Strohman, Juliana Franco, Tim Green, Demis Hassabis, Koray Kavukcuoglu, Jeffrey Dean, Oriol Vinyals",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11805"" target=""_blank"">2312.11805</a>",,2025-12-03 22:39:25
DRAM-Locker: A General-Purpose DRAM Protection Mechanism against Adversarial DNN Weight Attacks,"Ranyang Zhou, Sabbir Ahmed, Arman Roohi, Adnan Siraj Rakin, Shaahin Angizi",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09027"" target=""_blank"">2312.09027</a>",,2025-12-03 22:39:25
VNN: Verification-Friendly Neural Networks with Hard Robustness Guarantees,"Anahita Baninajjar, Ahmed Rezine, Amir Aminifar",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09748"" target=""_blank"">2312.09748</a>",,2025-12-03 22:39:25
Silent Guardian: Protecting Text from Malicious Exploitation by Large Language Models,"Jiawei Zhao, Kejiang Chen, Xiaojian Yuan, Yuang Qi, Weiming Zhang, Nenghai Yu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09669"" target=""_blank"">2312.09669</a>",,2025-12-03 22:39:25
AVA: Inconspicuous Attribute Variation-based Adversarial Attack bypassing DeepFake Detection,"Xiangtao Meng, Li Wang, Shanqing Guo, Lei Ju, Qingchuan Zhao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08675"" target=""_blank"">2312.08675</a>",,2025-12-03 22:39:25
Continual Adversarial Defense,"Qian Wang, Yaoyao Liu, Hefei Ling, Yingwei Li, Qihao Liu, Ping Li, Jiazhong Chen, Alan Yuille, Ning Yu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09481"" target=""_blank"">2312.09481</a>",,2025-12-03 22:39:25
SlowTrack: Increasing the Latency of Camera-based Perception in Autonomous Driving Using Adversarial Examples,"Chen Ma, Ningfei Wang, Qi Alfred Chen, Chao Shen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09520"" target=""_blank"">2312.09520</a>",,2025-12-03 22:39:25
On the Difficulty of Defending Contrastive Learning against Backdoor Attacks,"Changjiang Li, Ren Pang, Bochuan Cao, Zhaohan Xi, Jinghui Chen, Shouling Ji, Ting Wang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09057"" target=""_blank"">2312.09057</a>",,2025-12-03 22:39:25
Detection and Defense of Unlearnable Examples,"Yifan Zhu, Lijia Yu, Xiao-Shan Gao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08898"" target=""_blank"">2312.08898</a>",,2025-12-03 22:39:25
Improve Robustness of Reinforcement Learning against Observation Perturbations via $l_\infty$ Lipschitz Policy Networks,"Buqing Nie, Jingtian Ji, Yangqing Fu, Yue Gao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08751"" target=""_blank"">2312.08751</a>",,2025-12-03 22:39:25
Adv-Diffusion: Imperceptible Adversarial Face Identity Attack via Latent Diffusion Model,"Decheng Liu, Xijun Wang, Chunlei Peng, Nannan Wang, Ruiming Hu, Xinbo Gao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11285"" target=""_blank"">2312.11285</a>","<a href=""https://github.com/kopper-xdu/Adv-Diffusion"" target=""_blank"">kopper-xdu</a>",2025-12-03 22:39:25
"Data and Model Poisoning Backdoor Attacks on Wireless Federated Learning, and the Defense Mechanisms: A Comprehensive Survey","Yichen Wan, Youyang Qu, Wei Ni, Yong Xiang, Longxiang Gao, Ekram Hossain",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08667"" target=""_blank"">2312.08667</a>",,2025-12-03 22:39:25
No-Skim: Towards Efficiency Robustness Evaluation on Skimming-based Language Models,"Shengyao Zhang, Mi Zhang, Xudong Pan, Min Yang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09494"" target=""_blank"">2312.09494</a>",,2025-12-03 22:39:25
Closing the Gap: Achieving Better Accuracy-Robustness Tradeoffs Against Query-Based Attacks,"Pascal Zimmer, Sébastien Andreina, Giorgia Azzurra Marson, Ghassan Karame",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10132"" target=""_blank"">2312.10132</a>",,2025-12-03 22:39:25
Forbidden Facts: An Investigation of Competing Objectives in Llama-2,"Tony T. Wang, Miles Wang, Kaivalya Hariharan, Nir Shavit",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08793"" target=""_blank"">2312.08793</a>","<a href=""https://forbiddenfacts.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Coevolutionary Algorithm for Building Robust Decision Trees under Minimax Regret,"Adam Żychowski, Andrew Perrault, Jacek Mańdziuk",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09078"" target=""_blank"">2312.09078</a>",,2025-12-03 22:39:25
Exploring Transferability for Randomized Smoothing,"Kai Qiu, Huishuai Zhang, Zhirong Wu, Stephen Lin",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09020"" target=""_blank"">2312.09020</a>",,2025-12-03 22:39:25
Erasing Self-Supervised Learning Backdoor by Cluster Activation Masking,"Shengsheng Qian, Dizhan Xue, Yifei Wang, Shengjie Zhang, Huaiwen Zhang, Changsheng Xu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07955"" target=""_blank"">2312.07955</a>",,2025-12-03 22:39:25
Split-Ensemble: Efficient OOD-aware Ensemble via Task and Model Splitting,"Anthony Chen, Huanrui Yang, Yulu Gan, Denis A Gudovskiy, Zhen Dong, Haofan Wang, Tomoyuki Okuno, Yohei Nakata, Shanghang Zhang, Kurt Keutzer",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09148"" target=""_blank"">2312.09148</a>","<a href=""https://antonioo-c.github.io/projects/split-ensemble"" target=""_blank"">projects</a>",2025-12-03 22:39:25
Defenses in Adversarial Machine Learning: A Survey,"Baoyuan Wu, Shaokui Wei, Mingli Zhu, Meixi Zheng, Zihao Zhu, Mingda Zhang, Hongrui Chen, Danni Yuan, Li Liu, Qingshan Liu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08890"" target=""_blank"">2312.08890</a>",,2025-12-03 22:39:25
Robust Few-Shot Named Entity Recognition with Boundary Discrimination and Correlation Purification,"Xiaojun Xue, Chunxia Zhang, Tianxiang Xu, Zhendong Niu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07961"" target=""_blank"">2312.07961</a>",,2025-12-03 22:39:25
Universal Adversarial Framework to Improve Adversarial Robustness for Diabetic Retinopathy Detection,"Samrat Mukherjee, Dibyanayan Bandyopadhyay, Baban Gain, Asif Ekbal",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08193"" target=""_blank"">2312.08193</a>",,2025-12-03 22:39:25
Scalable Ensemble-based Detection Method against Adversarial Attacks for speaker verification,"Haibin Wu, Heng-Cheng Kuo, Yu Tsao, Hung-yi Lee",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08622"" target=""_blank"">2312.08622</a>",,2025-12-03 22:39:25
Accelerating the Global Aggregation of Local Explanations,"Alon Mor, Yonatan Belinkov, Benny Kimelfeld",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.07991"" target=""_blank"">2312.07991</a>",,2025-12-03 22:39:25
"Fragility, Robustness and Antifragility in Deep Learning","Chandresh Pravin, Ivan Martino, Giuseppe Nicosia, Varun Ojha",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09821"" target=""_blank"">2312.09821</a>",,2025-12-03 22:39:25
Adversarial Robustness on Image Classification with $k$-means,"Rollin Omari, Junae Kim, Paul Montague",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09533"" target=""_blank"">2312.09533</a>",,2025-12-03 22:39:25
FlowMur: A Stealthy and Practical Audio Backdoor Attack with Limited Knowledge,"Jiahe Lan, Jie Wang, Baochen Yan, Zheng Yan, Elisa Bertino",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09665"" target=""_blank"">2312.09665</a>",,2025-12-03 22:39:25
Robust Node Representation Learning via Graph Variational Diffusion Networks,"Jun Zhuang, Mohammad Al Hasan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10903"" target=""_blank"">2312.10903</a>",,2025-12-03 22:39:25
The Ultimate Combo: Boosting Adversarial Example Transferability by Composing Data Augmentations,"Zebin Yun, Achi-Or Weingarten, Eyal Ronen, Mahmood Sharif",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11309"" target=""_blank"">2312.11309</a>",,2025-12-03 22:39:25
DataElixir: Purifying Poisoned Dataset to Mitigate Backdoor Attacks via Diffusion Models,"Jiachen Zhou, Peizhuo Lv, Yibing Lan, Guozhu Meng, Kai Chen, Hualong Ma",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11057"" target=""_blank"">2312.11057</a>",,2025-12-03 22:39:25
A Malware Classification Survey on Adversarial Attacks and Defences,"Mahesh Datta Sai Ponnuru, Likhitha Amasala, Tanu Sree Bhimavarapu, Guna Chaitanya Garikipati",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09636"" target=""_blank"">2312.09636</a>",,2025-12-03 22:39:25
Model Stealing Attack against Recommender System,"Zhihao Zhu, Rui Fan, Chenwang Wu, Yi Yang, Defu Lian, Enhong Chen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11571"" target=""_blank"">2312.11571</a>",,2025-12-03 22:39:25
"Model Stealing Attack against Graph Classification with Authenticity, Uncertainty and Diversity","Zhihao Zhu, Chenwang Wu, Rui Fan, Yi Yang, Defu Lian, Enhong Chen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10943"" target=""_blank"">2312.10943</a>",,2025-12-03 22:39:25
MISA: Unveiling the Vulnerabilities in Split Federated Learning,"Wei Wan, Yuxuan Ning, Shengshan Hu, Lulu Xue, Minghui Li, Leo Yu Zhang, Hai Jin",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11026"" target=""_blank"">2312.11026</a>",,2025-12-03 22:39:25
"A Survey of Side-Channel Attacks in Context of Cache -- Taxonomies, Analysis and Mitigation","Ankit Pulkit, Smita Naval, Vijay Laxmi",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11094"" target=""_blank"">2312.11094</a>",,2025-12-03 22:39:25
UltraClean: A Simple Framework to Train Robust Neural Networks against Backdoor Attacks,"Bingyin Zhao, Yingjie Lao",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10657"" target=""_blank"">2312.10657</a>","<a href=""https://github.com/bxz9200/UltraClean"" target=""_blank"">bxz9200</a>",2025-12-03 22:39:25
The Pros and Cons of Adversarial Robustness,"Yacine Izza, Joao Marques-Silva",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10911"" target=""_blank"">2312.10911</a>",,2025-12-03 22:39:25
A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection,"Xiaoyu Zhang, Cen Zhang, Tianlin Li, Yihao Huang, Xiaojun Jia, Xiaofei Xie, Yang Liu, Chao Shen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10766"" target=""_blank"">2312.10766</a>",,2025-12-03 22:39:25
"A Comprehensive Survey of Attack Techniques, Implementation, and Mitigation Strategies in Large Language Models","Aysan Esmradi, Daniel Wankit Yip, Chun Fai Chan",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10982"" target=""_blank"">2312.10982</a>",,2025-12-03 22:39:25
A Study on Transferability of Deep Learning Models for Network Intrusion Detection,"Shreya Ghosh, Abu Shafin Mohammad Mahdee Jameel, Aly El Gamal",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.11550"" target=""_blank"">2312.11550</a>","<a href=""https://github.com/ghosh64/transferability"" target=""_blank"">ghosh64</a>",2025-12-03 22:39:25
Transformers in Unsupervised Structure-from-Motion,"Hemang Chawla, Arnav Varma, Elahe Arani, Bahram Zonooz",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10529"" target=""_blank"">2312.10529</a>",,2025-12-03 22:39:25
Towards Transferable Targeted 3D Adversarial Attack in the Physical World,"Yao Huang, Yinpeng Dong, Shouwei Ruan, Xiao Yang, Hang Su, Xingxing Wei",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09558"" target=""_blank"">2312.09558</a>",,2025-12-03 22:39:25
Embodied Adversarial Attack: A Dynamic Robust Physical Attack in Autonomous Driving,"Yitong Sun, Yao Huang, Xingxing Wei",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09554"" target=""_blank"">2312.09554</a>",,2025-12-03 22:39:25
LogoStyleFool: Vitiating Video Recognition Systems via Logo Style Transfer,"Yuxin Cao, Ziyu Zhao, Xi Xiao, Derui Wang, Minhui Xue, Jin Lu",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.09935"" target=""_blank"">2312.09935</a>",,2025-12-03 22:39:25
TrojFSP: Trojan Insertion in Few-shot Prompt Tuning,"Mengxin Zheng, Jiaqi Xue, Xun Chen, YanShan Wang, Qian Lou, Lei Jiang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10467"" target=""_blank"">2312.10467</a>",,2025-12-03 22:39:25
Towards Inductive Robustness: Distilling and Fostering Wave-induced Resonance in Transductive GCNs Against Graph Adversarial Attacks,"Ao Liu, Wenshan Li, Tao Li, Beibei Li, Hanyuan Huang, Pan Zhou",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.08651"" target=""_blank"">2312.08651</a>",,2025-12-03 22:39:25
TrojFair: Trojan Fairness Attacks,"Mengxin Zheng, Jiaqi Xue, Yi Sheng, Lei Yang, Qian Lou, Lei Jiang",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10508"" target=""_blank"">2312.10508</a>",,2025-12-03 22:39:25
SAME: Sample Reconstruction Against Model Extraction Attacks,"Yi Xie, Jie Zhang, Shiqian Zhao, Tianwei Zhang, Xiaofeng Chen",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10578"" target=""_blank"">2312.10578</a>","<a href=""https://github.com/xythink/SAME"" target=""_blank"">xythink</a>",2025-12-03 22:39:25
Perturbation-Invariant Adversarial Training for Neural Ranking Models: Improving the Effectiveness-Robustness Trade-Off,"Yu-An Liu, Ruqing Zhang, Mingkun Zhang, Wei Chen, Rijke Maarten de, Jiafeng Guo, Xueqi Cheng",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10329"" target=""_blank"">2312.10329</a>",,2025-12-03 22:39:25
Rethinking Robustness of Model Attributions,"Sandesh Kamath, Sankalp Mittal, Amit Deshpande, Vineeth N Balasubramanian",arXiv,2023-12,"<a href=""http://arxiv.org/abs/2312.10534"" target=""_blank"">2312.10534</a>","<a href=""https://github.com/ksandeshk/LENS"" target=""_blank"">ksandeshk</a>",2025-12-03 22:39:25
Robust Text Classification: Analyzing Prototype-Based Networks,"Zhivar Sourati, Darshan Deshpande, Filip Ilievski, Kiril Gashteovski, Sascha Saralajew",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06647"" target=""_blank"">2311.06647</a>",,2025-12-03 22:39:25
An Extensive Study on Adversarial Attack against Pre-trained Models of Code,"Xiaohu Du, Ming Wen, Zichao Wei, Shangwen Wang, Hai Jin",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07553"" target=""_blank"">2311.07553</a>",,2025-12-03 22:39:25
Multi-agent Attacks for Black-box Social Recommendations,"Wenqi Fan, Shijie Wang, Xiao-yong Wei, Xiaowei Mei, Shanru Lin, Qing Li",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07127"" target=""_blank"">2311.07127</a>",,2025-12-03 22:39:25
On the Robustness of Neural Collapse and the Neural Collapse of Robustness,"Jingtong Su, Ya Shi Zhang, Nikolaos Tsilivis, Julia Kempe",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07444"" target=""_blank"">2311.07444</a>","<a href=""https://github.com/JingtongSu/robust_neural_collapse"" target=""_blank"">JingtongSu</a>",2025-12-03 22:39:25
Tabdoor: Backdoor Vulnerabilities in Transformer-based Neural Networks for Tabular Data,"Bart Pleiter, Behrad Tajalli, Stefanos Koffas, Gorka Abad, Jing Xu, Martha Larson, Stjepan Picek",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07550"" target=""_blank"">2311.07550</a>",,2025-12-03 22:39:25
Learning Globally Optimized Language Structure via Adversarial Training,Xuwang Yin,arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06771"" target=""_blank"">2311.06771</a>",,2025-12-03 22:39:25
Resilient Graph Neural Networks: A Coupled Dynamical Systems Approach,"Moshe Eliasof, Davide Murari, Ferdia Sherry, Carola-Bibiane Schönlieb",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06942"" target=""_blank"">2311.06942</a>",,2025-12-03 22:39:25
Analytical Verification of Deep Neural Network Performance for Time-Synchronized Distribution System State Estimation,"Behrouz Azimian, Shiva Moshtagh, Anamitra Pal, Shanshan Ma",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06973"" target=""_blank"">2311.06973</a>",,2025-12-03 22:39:25
DialMAT: Dialogue-Enabled Transformer with Moment-Based Adversarial Training,"Kanta Kaneda, Ryosuke Korekata, Yuiga Wada, Shunya Nagashima, Motonari Kambara, Yui Iioka, Haruka Matsuo, Yuto Imai, Takayuki Nishimura, Komei Sugiura",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06855"" target=""_blank"">2311.06855</a>",,2025-12-03 22:39:25
Robust Adversarial Attacks Detection for Deep Learning based Relative Pose Estimation for Space Rendezvous,"Ziwei Wang, Nabil Aouf, Jose Pizarro, Christophe Honvault",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05992"" target=""_blank"">2311.05992</a>",,2025-12-03 22:39:25
Scale-MIA: A Scalable Model Inversion Attack against Secure Federated Learning via Latent Space Reconstruction,"Shanghao Shi, Ning Wang, Yang Xiao, Chaoyu Zhang, Yi Shi, Y. Thomas Hou, Wenjing Lou",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05808"" target=""_blank"">2311.05808</a>",,2025-12-03 22:39:25
Fight Fire with Fire: Combating Adversarial Patch Attacks using Pattern-randomized Defensive Patches,"Jianan Feng, Jiachun Li, Changqing Miao, Jianjun Huang, Wei You, Wenchang Shi, Bin Liang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06122"" target=""_blank"">2311.06122</a>",,2025-12-03 22:39:25
Transferability Bound Theory: Exploring Relationship between Adversarial Transferability and Flatness,"Mingyuan Fan, Xiaodan Li, Cen Chen, Wenmeng Zhou, Yaliang Li",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06423"" target=""_blank"">2311.06423</a>","<a href=""https://github.com/fmy266/TPA>"" target=""_blank"">fmy266</a>",2025-12-03 22:39:25
FigStep: Jailbreaking Large Vision-language Models via Typographic Visual Prompts,"Yichen Gong, Delong Ran, Jinyuan Liu, Conglei Wang, Tianshuo Cong, Anyu Wang, Sisi Duan, Xiaoyun Wang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05608"" target=""_blank"">2311.05608</a>",,2025-12-03 22:39:25
CALLOC: Curriculum Adversarial Learning for Secure and Robust Indoor Localization,"Danish Gufran, Sudeep Pasricha",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06361"" target=""_blank"">2311.06361</a>",,2025-12-03 22:39:25
RLHFPoison: Reward Poisoning Attack for Reinforcement Learning with Human Feedback in Large Language Models,"Jiongxiao Wang, Junlin Wu, Muhao Chen, Yevgeniy Vorobeychik, Chaowei Xiao",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09641"" target=""_blank"">2311.09641</a>",,2025-12-03 22:39:25
Practical Membership Inference Attacks against Fine-tuned Large Language Models via Self-prompt Calibration,"Wenjie Fu, Huandong Wang, Chen Gao, Guanghua Liu, Yong Li, Tao Jiang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.06062"" target=""_blank"">2311.06062</a>",,2025-12-03 22:39:25
ABIGX: A Unified Framework for eXplainable Fault Detection and Classification,"Yue Zhuo, Jinchuan Qian, Zhihuan Song, Zhiqiang Ge",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05316"" target=""_blank"">2311.05316</a>",,2025-12-03 22:39:25
Honest Score Client Selection Scheme: Preventing Federated Learning Label Flipping Attacks in Non-IID Scenarios,"Yanli Li, Huaming Chen, Wei Bao, Zhengmeng Xu, Dong Yuan",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05826"" target=""_blank"">2311.05826</a>",,2025-12-03 22:39:25
Resilient and constrained consensus against adversarial attacks: A distributed MPC framework,"Henglai Wei, Kunwu Zhang, Hui Zhang, Yang Shi",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05935"" target=""_blank"">2311.05935</a>",,2025-12-03 22:39:25
Identifying the Truth of Global Model: A Generic Solution to Defend Against Byzantine and Backdoor Attacks in Federated Learning (full version),"Sheldon C. Ebron, Meiying Zhang, Kan Yang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.10248"" target=""_blank"">2311.10248</a>",,2025-12-03 22:39:25
Parrot-Trained Adversarial Examples: Pushing the Practicality of Black-Box Audio Attacks against Speaker Recognition Models,"Rui Duan, Zhe Qu, Leah Ding, Yao Liu, Zhuo Lu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07780"" target=""_blank"">2311.07780</a>",,2025-12-03 22:39:25
Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization,"Zhexin Zhang, Junxiao Yang, Pei Ke, Fei Mi, Hongning Wang, Minlie Huang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09096"" target=""_blank"">2311.09096</a>","<a href=""https://github.com/thu-coai/JailbreakDefense_GoalPriority"" target=""_blank"">thu-coai</a>",2025-12-03 22:39:25
Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities,"Avishree Khare, Saikat Dutta, Ziyang Li, Alaia Solko-Breslin, Rajeev Alur, Mayur Naik",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16169"" target=""_blank"">2311.16169</a>",,2025-12-03 22:39:25
Constrained Adaptive Attacks: Realistic Evaluation of Adversarial Examples and Robust Training of Deep Neural Networks for Tabular Data,"Thibault Simonetto, Salah Ghamizi, Antoine Desjardins, Maxime Cordy, Yves Le Traon",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.04503"" target=""_blank"">2311.04503</a>",,2025-12-03 22:39:25
Towards more Practical Threat Models in Artificial Intelligence Security,"Kathrin Grosse, Lukas Bieringer, Tarek Richard Besold, Alexandre Alahi",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09994"" target=""_blank"">2311.09994</a>",,2025-12-03 22:39:25
You Cannot Escape Me: Detecting Evasions of SIEM Rules in Enterprise Networks,"Rafael Uetz, Marco Herzog, Louis Hackländer, Simon Schwarz, Martin Henze",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.10197"" target=""_blank"">2311.10197</a>",,2025-12-03 22:39:25
Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts,"Yuanwei Wu, Xiang Li, Yixin Liu, Pan Zhou, Lichao Sun",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09127"" target=""_blank"">2311.09127</a>",,2025-12-03 22:39:25
Backdoor Activation Attack: Attack Large Language Models using Activation Steering for Safety-Alignment,"Haoran Wang, Kai Shu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09433"" target=""_blank"">2311.09433</a>","<a href=""https://github.com/wang2226/Backdoor-Activation-Attack"" target=""_blank"">wang2226</a>",2025-12-03 22:39:25
Fast Certification of Vision-Language Models Using Incremental Randomized Smoothing,"A K Iowa State University Nirala, A New York University Joshi, C New York University Hegde, S Iowa State University Sarkar",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09024"" target=""_blank"">2311.09024</a>",,2025-12-03 22:39:25
Adversarially Robust Spiking Neural Networks Through Conversion,"Ozan Özdenizci, Robert Legenstein",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09266"" target=""_blank"">2311.09266</a>",,2025-12-03 22:39:25
How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities,"Lingbo Mo, Boshi Wang, Muhao Chen, Huan Sun",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09447"" target=""_blank"">2311.09447</a>",,2025-12-03 22:39:25
Privacy Threats in Stable Diffusion Models,"Thomas Cilloni, Charles Fleming, Charles Walter",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09355"" target=""_blank"">2311.09355</a>",,2025-12-03 22:39:25
Adversarial Purification for Data-Driven Power System Event Classifiers with Diffusion Models,"Yuanbin Cheng, Koji Yamashita, Jim Follum, Nanpeng Yu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07110"" target=""_blank"">2311.07110</a>",,2025-12-03 22:39:25
MirrorNet: A TEE-Friendly Framework for Secure On-device DNN Inference,"Ziyu Liu, Yukui Luo, Shijin Duan, Tong Zhou, Xiaolin Xu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09489"" target=""_blank"">2311.09489</a>",,2025-12-03 22:39:25
JAB: Joint Adversarial Prompting and Belief Augmentation,"Ninareh Mehrabi, Palash Goyal, Anil Ramakrishna, Jwala Dhamala, Shalini Ghosh, Richard Zemel, Kai-Wei Chang, Aram Galstyan, Rahul Gupta",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09473"" target=""_blank"">2311.09473</a>",,2025-12-03 22:39:25
Beyond Detection: Unveiling Fairness Vulnerabilities in Abusive Language Models,"Yueqing Liang, Lu Cheng, Ali Payani, Kai Shu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09428"" target=""_blank"">2311.09428</a>",,2025-12-03 22:39:25
Towards Improving Robustness Against Common Corruptions in Object Detectors Using Adversarial Contrastive Learning,"Shashank Kotyan, Danilo Vasconcellos Vargas",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07928"" target=""_blank"">2311.07928</a>",,2025-12-03 22:39:25
Physical Adversarial Examples for Multi-Camera Systems,"Ana Răduţoiu, Jan-Philipp Schulze, Philip Sperl, Konstantin Böttinger",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.08539"" target=""_blank"">2311.08539</a>",,2025-12-03 22:39:25
DALA: A Distribution-Aware LoRA-Based Adversarial Attack against Language Models,"Yibo Wang, Xiangjue Dong, James Caverlee, Philip S. Yu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.08598"" target=""_blank"">2311.08598</a>",,2025-12-03 22:39:25
On The Relationship Between Universal Adversarial Attacks And Sparse Representations,"Dana Weitzner, Raja Giryes",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.08265"" target=""_blank"">2311.08265</a>","<a href=""https://github.com/danawr/adversarial_attacks_and_sparse_representations"" target=""_blank"">danawr</a>",2025-12-03 22:39:25
A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily,"Peng Ding, Jun Kuang, Dan Ma, Xuezhi Cao, Yunsen Xian, Jiajun Chen, Shujian Huang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.08268"" target=""_blank"">2311.08268</a>","<a href=""https://github.com/NJUNLP/ReNeLLM"" target=""_blank"">NJUNLP</a>",2025-12-03 22:39:25
Evaluating Concurrent Robustness of Language Models Across Diverse Challenge Sets,"Vatsal Gupta, Pranshu Pandya, Tushar Kataria, Vivek Gupta, Dan Roth",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.08662"" target=""_blank"">2311.08662</a>",,2025-12-03 22:39:25
FireMatch: A Semi-Supervised Video Fire Detection Network Based on Consistency and Distribution Alignment,"Qinghua Lin, Zuoyong Li, Kun Zeng, Haoyi Fan, Wei Li, Xiaoguang Zhou",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05168"" target=""_blank"">2311.05168</a>",,2025-12-03 22:39:25
Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game,"Sam Toyer, Olivia Watkins, Ethan Adrian Mendes, Justin Svegliato, Luke Bailey, Tiffany Wang, Isaac Ong, Karim Elmaaroufi, Pieter Abbeel, Trevor Darrell, Alan Ritter, Stuart Russell",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01011"" target=""_blank"">2311.01011</a>",,2025-12-03 22:39:25
Army of Thieves: Enhancing Black-Box Model Extraction via Ensemble based sample selection,"Akshit Jindal, Vikram Goyal, Saket Anand, Chetan Arora",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.04588"" target=""_blank"">2311.04588</a>",,2025-12-03 22:39:25
Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks,"Yichen Huang, Timothy Baldwin",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00508"" target=""_blank"">2311.00508</a>",,2025-12-03 22:39:25
Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula,"Aryaman Reddi, Maximilian Tölle, Jan Peters, Georgia Chalvatzaki, Carlo D'Eramo",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01642"" target=""_blank"">2311.01642</a>",,2025-12-03 22:39:25
Sequential Subset Matching for Dataset Distillation,"Jiawei Du, Qin Shi, Joey Tianyi Zhou",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01570"" target=""_blank"">2311.01570</a>","<a href=""https://github.com/shqii1j/seqmatch"" target=""_blank"">shqii1j</a>",2025-12-03 22:39:25
E(2) Equivariant Neural Networks for Robust Galaxy Morphology Classification,"Sneh Pandya, Purvik Patel, Franc O, Jonathan Blazek",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01500"" target=""_blank"">2311.01500</a>","<a href=""https://github.com/snehjp2/GCNNMorphology"" target=""_blank"">snehjp2</a>",2025-12-03 22:39:25
Robust Identity Perceptual Watermark Against Deepfake Face Swapping,"Tianyi Wang, Mengxiao Huang, Harry Cheng, Bin Ma, Yinglong Wang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01357"" target=""_blank"">2311.01357</a>",,2025-12-03 22:39:25
NEO-KD: Knowledge-Distillation-Based Adversarial Training for Robust Multi-Exit Neural Networks,"Seokil Ham, Jungwuk Park, Dong-Jun Han, Jaekyun Moon",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00428"" target=""_blank"">2311.00428</a>",,2025-12-03 22:39:25
Adversarial Examples in the Physical World: A Survey,"Jiakai Wang, Donghua Wang, Jin Hu, Siyang Wu, Tingsong Jiang, Wen Yao, Aishan Liu, Xianglong Liu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01473"" target=""_blank"">2311.01473</a>",,2025-12-03 22:39:25
Optimal Cost Constrained Adversarial Attacks For Multiple Agent Systems,"Ziqing Lu, Guanlin Liu, Lifeng Cai, Weiyu Xu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00859"" target=""_blank"">2311.00859</a>",,2025-12-03 22:39:25
Improving Robustness for Vision Transformer with a Simple Dynamic Scanning Augmentation,"Shashank Kotyan, Danilo Vasconcellos Vargas",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00441"" target=""_blank"">2311.00441</a>",,2025-12-03 22:39:25
MIST: Defending Against Membership Inference Attacks Through Membership-Invariant Subspace Training,"Jiacheng Li, Ninghui Li, Bruno Ribeiro",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00919"" target=""_blank"">2311.00919</a>",,2025-12-03 22:39:25
Open-Set Face Recognition with Maximal Entropy and Objectosphere Loss,"Rafael Henrique Vareto, Yu Linghu, Terrance E. Boult, William Robson Schwartz, Manuel Günther",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00400"" target=""_blank"">2311.00400</a>",,2025-12-03 22:39:25
Distilling Out-of-Distribution Robustness from Vision-Language Foundation Models,"Andy Zhou, Jindong Wang, Yu-Xiong Wang, Haohan Wang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01441"" target=""_blank"">2311.01441</a>",,2025-12-03 22:39:25
Robust Safety Classifier for Large Language Models: Adversarial Prompt Shield,"Jinhwa Kim, Ali Derakhshan, Ian G. Harris",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00172"" target=""_blank"">2311.00172</a>",,2025-12-03 22:39:25
Magmaw: Modality-Agnostic Adversarial Attacks on Machine Learning-Based Wireless Communication Systems,"Jung-Woo Chang, Ke Sun, Nasimeh Heydaribeni, Seira Hidano, Xinyu Zhang, Farinaz Koushanfar",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.00207"" target=""_blank"">2311.00207</a>",,2025-12-03 22:39:25
DiffAttack: Evasion Attacks Against Diffusion-Based Adversarial Purification,"Mintong Kang, Dawn Song, Bo Li",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16124"" target=""_blank"">2311.16124</a>",,2025-12-03 22:39:25
Unscrambling the Rectification of Adversarial Attacks Transferability across Computer Networks,"Ehsan Nowroozi, Samaneh Ghelichkhani, Imran Haider, Ali Dehghantanha",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.03373"" target=""_blank"">2311.03373</a>",,2025-12-03 22:39:25
Adversarial sample generation and training using geometric masks for accurate and resilient license plate character recognition,"Bishal Shrestha, Griwan Khakurel, Kritika Simkhada, Badri Adhikari",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12857"" target=""_blank"">2311.12857</a>",,2025-12-03 22:39:25
RAEDiff: Denoising Diffusion Probabilistic Models Based Reversible Adversarial Examples Self-Generation and Self-Recovery,"Fan Xing, Xiaoyi Zhou, Xuefeng Fan, Zhuo Tian, Yan Zhao",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12858"" target=""_blank"">2311.12858</a>",,2025-12-03 22:39:25
Imperceptible CMOS camera dazzle for adversarial attacks on deep neural networks,"Zvi Stein, Adrian Stern",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16118"" target=""_blank"">2311.16118</a>",,2025-12-03 22:39:25
Can We Trust the Similarity Measurement in Federated Learning? (15%),"Zhilin Wang, Qin Hu, Xukai Zou",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.03369"" target=""_blank"">2311.03369</a>",,2025-12-03 22:39:25
Toward effective protection against diffusion based mimicry through score distillation,"Haotian Xue, Chumeng Liang, Xiaoyu Wu, Yongxin Chen",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12832"" target=""_blank"">2311.12832</a>","<a href=""https://github.com/xavihart/Diff-Protect"" target=""_blank"">xavihart</a>",2025-12-03 22:39:25
Assist Is Just as Important as the Goal: Image Resurfacing to Aid Model's Robust Prediction,"Abhijith Sharma, Phil Munz, Apurva Narayan",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01563"" target=""_blank"">2311.01563</a>",,2025-12-03 22:39:25
Universal Perturbation-based Secret Key-Controlled Data Hiding,"Donghua Wang, Wen Yao, Tingsong Jiang, Xiaoqian Chen",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01696"" target=""_blank"">2311.01696</a>",,2025-12-03 22:39:25
"Frontier Language Models are not Robust to Adversarial Arithmetic, or ""What do I need to say so you agree 2+2=5? (61%)","C. Daniel Freeman, Laura Culp, Aaron Parisi, Maxwell L Bileschi, Gamaleldin F Elsayed, Alex Rizkowsky, Isabelle Simpson, Alex Alemi, Azade Nova, Ben Adlam, Bernd Bohnet, Gaurav Mishra, Hanie Sedghi, Igor Mordatch, Izzeddin Gur, Jaehoon Lee, JD Co-Reyes, Jeffrey Pennington, Kelvin Xu, Kevin Swersky, Kshiteej Mahajan, Lechao Xiao, Rosanne Liu, Simon Kornblith, Noah Constant, Peter J. Liu, Roman Novak, Yundi Qian, Noah Fiedel, Jascha Sohl-Dickstein",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.07587"" target=""_blank"">2311.07587</a>",,2025-12-03 22:39:25
Measuring Adversarial Datasets,"Yuanchen Bai, Raoyi Huang, Vijay Viswanathan, Tzu-Sheng Kuo, Tongshuang Wu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.03566"" target=""_blank"">2311.03566</a>",,2025-12-03 22:39:25
SCAAT: Improving Neural Network Interpretability via Saliency Constrained Adaptive Adversarial Training,"Rui Xu, Wenkang Qin, Peixiang Huang, Haowang, Lin Luo",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05143"" target=""_blank"">2311.05143</a>",,2025-12-03 22:39:25
Familiarity-Based Open-Set Recognition Under Adversarial Attacks,"Philip Enevoldsen, Christian Gundersen, Nico Lang, Serge Belongie, Christian Igel",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05006"" target=""_blank"">2311.05006</a>",,2025-12-03 22:39:25
Domain Adaptive Object Detection via Balancing Between Self-Training and Adversarial Learning,"Muhammad Akhtar Munir, Muhammad Haris Khan, M. Saquib Sarfraz, Mohsen Ali",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.04815"" target=""_blank"">2311.04815</a>",,2025-12-03 22:39:25
Counter-Empirical Attacking based on Adversarial Reinforcement Learning for Time-Relevant Scoring System,"Xiangguo Sun, Hong Cheng, Hang Dong, Bo Qiao, Si Qin, Qingwei Lin",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.05144"" target=""_blank"">2311.05144</a>",,2025-12-03 22:39:25
Unveiling Safety Vulnerabilities of Large Language Models,"George Kour, Marcel Zalmanovici, Naama Zwerdling, Esther Goldbraich, Ora Nova Fandina, Ateret Anaby-Tavor, Orna Raz, Eitan Farchi",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.04124"" target=""_blank"">2311.04124</a>",,2025-12-03 22:39:25
When Fairness Meets Privacy: Exploring Privacy Threats in Fair Binary Classifiers through Membership Inference Attacks,"Huan Tian, Guangsheng Zhang, Bo Liu, Tianqing Zhu, Ming Ding, Wanlei Zhou",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.03865"" target=""_blank"">2311.03865</a>",,2025-12-03 22:39:25
Identifying and Mitigating Vulnerabilities in LLM-Integrated Applications,"Fengqing Jiang, Zhangchen Xu, Luyao Niu, Boxin Wang, Jinyuan Jia, Bo Li, Radha Poovendran",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16153"" target=""_blank"">2311.16153</a>",,2025-12-03 22:39:25
SoK: Security Below the OS -- A Security Analysis of UEFI,"Priyanka Prakash Surve, Oleg Brodt, Mark Yampolskiy, Yuval Elovici, Asaf Shabtai",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.03809"" target=""_blank"">2311.03809</a>",,2025-12-03 22:39:25
Do LLMs exhibit human-like response biases? A case study in survey design,"Lindia Tjuatja, Valerie Chen, Sherry Tongshuang Wu, Ameet Talwalkar, Graham Neubig",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.04076"" target=""_blank"">2311.04076</a>","<a href=""https://github.com/lindiatjuatja/BiasMonkey"" target=""_blank"">lindiatjuatja</a>",2025-12-03 22:39:25
Can LLMs Follow Simple Rules? (68%),"Norman Mu, Sarah Chen, Zifan Wang, Sizhe Chen, David Karamardian, Lulwa Aljeraisy, Basel Alomair, Dan Hendrycks, David Wagner",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.04235"" target=""_blank"">2311.04235</a>",,2025-12-03 22:39:25
On the Lipschitz constant of random neural networks,"Paul Geuchen, Thomas Heindl, Dominik Stöger, Felix Voigtlaender",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01356"" target=""_blank"">2311.01356</a>",,2025-12-03 22:39:25
Preserving Privacy in GANs Against Membership Inference Attack,"Mohammadhadi Shateri, Francisco Messina, Fabrice Labeau, Pablo Piantanida",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.03172"" target=""_blank"">2311.03172</a>",,2025-12-03 22:39:25
Cal-DETR: Calibrated Detection Transformer,"Muhammad Akhtar Munir, Salman Khan, Muhammad Haris Khan, Mohsen Ali, Fahad Shahbaz Khan",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.03570"" target=""_blank"">2311.03570</a>","<a href=""https://github.com/akhtarvision/cal-detr"" target=""_blank"">akhtarvision</a>",2025-12-03 22:39:25
Understanding Deep Representation Learning via Layerwise Feature Compression and Discrimination,"Peng Wang, Xiao Li, Can Yaras, Zhihui Zhu, Laura Balzano, Wei Hu, Qing Qu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.02960"" target=""_blank"">2311.02960</a>","<a href=""https://github.com/Heimine/PNC_DLN"" target=""_blank"">Heimine</a>",2025-12-03 22:39:25
Certified Defense on the Fairness of Graph Neural Networks,"Yushun Dong, Binchi Zhang, Hanghang Tong, Jundong Li",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.02757"" target=""_blank"">2311.02757</a>","<a href=""https://github.com/yushundong/ELEGANT"" target=""_blank"">yushundong</a>",2025-12-03 22:39:25
From Trojan Horses to Castle Walls: Unveiling Bilateral Data Poisoning Effects in Diffusion Models,"Zhuoshi Pan, Yuguang Yao, Gaowen Liu, Bingquan Shen, H. Vicky Zhao, Ramana Rao Kompella, Sijia Liu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.02373"" target=""_blank"">2311.02373</a>",,2025-12-03 22:39:25
Efficient Black-Box Adversarial Attacks on Neural Text Detectors,"Vitalii Fishchuk, Daniel Braun",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01873"" target=""_blank"">2311.01873</a>",,2025-12-03 22:39:25
The Alignment Problem in Context,Raphaël Millière,arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.02147"" target=""_blank"">2311.02147</a>",,2025-12-03 22:39:25
Adversary ML Resilience in Autonomous Driving Through Human Centered Perception Mechanisms,Aakriti Shah,arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01478"" target=""_blank"">2311.01478</a>",,2025-12-03 22:39:25
"Towards Evaluating Transfer-based Attacks Systematically, Practically, and Fairly","Qizhang Li, Yiwen Guo, Wangmeng Zuo, Hao Chen",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.01323"" target=""_blank"">2311.01323</a>","<a href=""https://github.com/qizhangli/TA-Bench"" target=""_blank"">qizhangli</a>",2025-12-03 22:39:25
Towards Improving Robustness Against Common Corruptions using Mixture of Class Specific Experts,"Shashank Kotyan, Danilo Vasconcellos Vargas",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.10177"" target=""_blank"">2311.10177</a>",,2025-12-03 22:39:25
The Perception-Robustness Tradeoff in Deterministic Image Restoration,"Guy Ohayon, Tomer Michaeli, Michael Elad",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09253"" target=""_blank"">2311.09253</a>",,2025-12-03 22:39:25
Cognitive Overload: Jailbreaking Large Language Models with Overloaded Logical Thinking,"Nan Xu, Fei Wang, Ben Zhou, Bang Zheng Li, Chaowei Xiao, Muhao Chen",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09827"" target=""_blank"">2311.09827</a>",,2025-12-03 22:39:25
Confidence Is All You Need for MI Attacks,"Abhishek Sinha, Himanshi Tibrewal, Mansi Gupta, Nikhar Waghela, Shivank Garg",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15373"" target=""_blank"">2311.15373</a>",,2025-12-03 22:39:25
RADAP: A Robust and Adaptive Defense Against Diverse Adversarial Patches on Face Recognition,"Xiaoliang Liu, Furao Shen, Jian Zhao, Changhai Nie",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17339"" target=""_blank"">2311.17339</a>",,2025-12-03 22:39:25
"1-Lipschitz Layers Compared: Memory, Speed, and Certifiable Robustness","Bernd Prach, Fabio Brau, Giorgio Buttazzo, Christoph H. Lampert",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16833"" target=""_blank"">2311.16833</a>","<a href=""https://github.com/berndprach/1LipschitzLayersCompared"" target=""_blank"">berndprach</a>",2025-12-03 22:39:25
Scalable Extraction of Training Data from (Production) Language Models,"Milad Nasr, Nicholas Carlini, Jonathan Hayase, Matthew Jagielski, A. Feder Cooper, Daphne Ippolito, Christopher A. Choquette-Choo, Eric Wallace, Florian Tramèr, Katherine Lee",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17035"" target=""_blank"">2311.17035</a>",,2025-12-03 22:39:25
Cooperative Abnormal Node Detection with Adversary Resistance,"Yingying Huangfu, Tian Bai",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16661"" target=""_blank"">2311.16661</a>",,2025-12-03 22:39:25
On robust overfitting: adversarial training induced distribution matters,"Runzhi Tian, Yongyi Mao",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16526"" target=""_blank"">2311.16526</a>",,2025-12-03 22:39:25
Understanding the (Extra-)Ordinary: Validating Deep Model Decisions with Prototypical Concept-based Explanations,"Maximilian Dreyer, Reduan Achtibat, Wojciech Samek, Sebastian Lapuschkin",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16681"" target=""_blank"">2311.16681</a>","<a href=""https://github.com/maxdreyer/pcx"" target=""_blank"">maxdreyer</a>",2025-12-03 22:39:25
Shadows Don't Lie and Lines Can't Bend! Generative Models don't know Projective Geometry,"Ayush Sarkar, Hanlin Mai, Amitabh Mahapatra, Svetlana Lazebnik, D. A. Forsyth, Anand Bhattad",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17138"" target=""_blank"">2311.17138</a>",,2025-12-03 22:39:25
Enhancing Cyber-Resilience in Integrated Energy System Scheduling with Demand Response Using Deep Reinforcement Learning,"Yang Li, Wenjie Ma, Yuanzheng Li, Sen Li, Zhe Chen, Mohammad Shahidehpor",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17941"" target=""_blank"">2311.17941</a>",,2025-12-03 22:39:25
RetouchUAA: Unconstrained Adversarial Attack via Image Retouching,"Mengda Xie, Yiling He, Meie Fang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16478"" target=""_blank"">2311.16478</a>",,2025-12-03 22:39:25
Adversaral Doodles: Interpretable and Human-drawable Attacks Provide Describable Insights,"Ryoya Nara, Yusuke Matsui",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15994"" target=""_blank"">2311.15994</a>",,2025-12-03 22:39:25
Rethinking Mixup for Improving the Adversarial Transferability,"Xiaosen Wang, Zeyuan Yin",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17087"" target=""_blank"">2311.17087</a>",,2025-12-03 22:39:25
Instruct2Attack: Language-Guided Semantic Adversarial Attacks,"Jiang Liu, Chen Wei, Yuxiang Guo, Heng Yu, Alan Yuille, Soheil Feizi, Chun Pong Lau, Rama Chellappa",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15551"" target=""_blank"">2311.15551</a>",,2025-12-03 22:39:25
CLAP: Isolating Content from Style through Contrastive Learning with Augmented Prompts,"Yichao Cai, Yuhang Liu, Zhen Zhang, Javen Qinfeng Shi",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16445"" target=""_blank"">2311.16445</a>",,2025-12-03 22:39:25
A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective,"Xianghua Xie, Chen Hu, Hanchi Ren, Jingjing Deng",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16065"" target=""_blank"">2311.16065</a>",,2025-12-03 22:39:25
Threshold Breaker: Can Counter-Based RowHammer Prevention Mechanisms Truly Safeguard DRAM? (31%),"Ranyang Zhou, Jacqueline Liu, Sabbir Ahmed, Nakul Kochar, Adnan Siraj Rakin, Shaahin Angizi",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16460"" target=""_blank"">2311.16460</a>",,2025-12-03 22:39:25
Distributed Attacks over Federated Reinforcement Learning-enabled Cell Sleep Control,"Han Zhang, Hao Zhou, Medhat Elsayed, Majid Bavand, Raimundas Gaigalas, Yigit Ozcan, Melike Erol-Kantarci",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15894"" target=""_blank"">2311.15894</a>",,2025-12-03 22:39:25
"""Do Users fall for Real Adversarial Phishing?"" Investigating the Human response to Evasive Webpages","Ajka Draganovic, Savino Dambra, Javier Aldana Iuit, Kevin Roundy, Giovanni Apruzzese",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16383"" target=""_blank"">2311.16383</a>",,2025-12-03 22:39:25
How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for Vision LLMs,"Haoqin Tu, Chenhang Cui, Zijun Wang, Yiyang Zhou, Bingchen Zhao, Junlin Han, Wangchunshu Zhou, Huaxiu Yao, Cihang Xie",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16101"" target=""_blank"">2311.16101</a>","<a href=""https://github.com/UCSC-VLAA/vllm-safety-benchmark"" target=""_blank"">UCSC-VLAA</a>",2025-12-03 22:39:25
Microarchitectural Security of AWS Firecracker VMM for Serverless Cloud Platforms,"Zane Worcester Polytechnic Institute Weissman, Thore University of Lübeck Tiemann, Thomas University of Lübeck Eisenbarth, Berk Worcester Polytechnic Institute Sunar",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15999"" target=""_blank"">2311.15999</a>",,2025-12-03 22:39:25
Adversarial Purification of Information Masking,"Sitong Liu, Zhichao Lian, Shuangquan Zhang, Liang Xiao",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15339"" target=""_blank"">2311.15339</a>","<a href=""https://github.com/NoWindButRain/IMPure"" target=""_blank"">NoWindButRain</a>",2025-12-03 22:39:25
Having Second Thoughts? Let's hear it,"Jung H. Lee, Sujith Vijayan",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15356"" target=""_blank"">2311.15356</a>",,2025-12-03 22:39:25
Efficient Key-Based Adversarial Defense for ImageNet by Using Pre-trained Model,"AprilPyone MaungMaung, Isao Echizen, Hitoshi Kiya",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16577"" target=""_blank"">2311.16577</a>",,2025-12-03 22:39:25
NeRFTAP: Enhancing Transferability of Adversarial Patches on Face Recognition using Neural Radiance Fields,"Xiaoliang Liu, Furao Shen, Feng Han, Jian Zhao, Changhai Nie",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17332"" target=""_blank"">2311.17332</a>",,2025-12-03 22:39:25
Vulnerability Analysis of Transformer-based Optical Character Recognition to Adversarial Attacks,"Lucas Beerens, Desmond J. Higham",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17128"" target=""_blank"">2311.17128</a>",,2025-12-03 22:39:25
Adversarial Robust Memory-Based Continual Learner,"Xiaoyue Mi, Fan Tang, Zonghan Yang, Danding Wang, Juan Cao, Peng Li, Yang Liu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17608"" target=""_blank"">2311.17608</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defenses for Wireless Signal Classifiers using CDI-aware GANs,"Sujata Sinha, Alkan Soysal",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.18820"" target=""_blank"">2311.18820</a>",,2025-12-03 22:39:25
Test-time Backdoor Mitigation for Black-Box Large Language Models with Defensive Demonstrations,"Wenjie Mo, Jiashu Xu, Qin Liu, Jiongxiao Wang, Jun Yan, Hadi Askari, Chaowei Xiao, Muhao Chen",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09763"" target=""_blank"">2311.09763</a>",,2025-12-03 22:39:25
Corrupting Convolution-based Unlearnable Datasets with Pixel-based Image Transformations,"Xianlong Wang, Shengshan Hu, Minghui Li, Zhifei Yu, Ziqi Zhou, Leo Yu Zhang, Hai Jin",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.18403"" target=""_blank"">2311.18403</a>",,2025-12-03 22:39:25
Improving Adversarial Transferability via Model Alignment,"Avery Ma, Amir-massoud Farahmand, Yangchen Pan, Philip Torr, Jindong Gu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.18495"" target=""_blank"">2311.18495</a>",,2025-12-03 22:39:25
Data-Agnostic Model Poisoning against Federated Learning: A Graph Autoencoder Approach,"Kai Li, Jingjing Zheng, Xin Yuan, Wei Ni, Ozgur B. Akan, H. Vincent Poor",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.18498"" target=""_blank"">2311.18498</a>",,2025-12-03 22:39:25
Improving the Robustness of Transformer-based Large Language Models with Dynamic Attention,"Lujia Shen, Yuwen Pu, Shouling Ji, Changjiang Li, Xuhong Zhang, Chunpeng Ge, Ting Wang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17400"" target=""_blank"">2311.17400</a>",,2025-12-03 22:39:25
Group-wise Sparse and Explainable Adversarial Attacks,"Shpresim Sadiku, Moritz Wagner, Sebastian Pokutta",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17434"" target=""_blank"">2311.17434</a>",,2025-12-03 22:39:25
Quantum Neural Networks under Depolarization Noise: Exploring White-Box Attacks and Defenses,"David Winderl, Nicola Franco, Jeanette Miriam Lorenz",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17458"" target=""_blank"">2311.17458</a>",,2025-12-03 22:39:25
On the Adversarial Robustness of Graph Contrastive Learning Methods,"Filippo Guerranti, Zinuo Yi, Anna Starovoit, Rafiq Kamel, Simon Geisler, Stephan Günnemann",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17853"" target=""_blank"">2311.17853</a>",,2025-12-03 22:39:25
Improving Faithfulness for Vision Transformers,"Lijie Hu, Yixin Liu, Ninghao Liu, Mengdi Huai, Lichao Sun, Di Wang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17983"" target=""_blank"">2311.17983</a>",,2025-12-03 22:39:25
Unveiling the Implicit Toxicity in Large Language Models,"Jiaxin Wen, Pei Ke, Hao Sun, Zhexin Zhang, Chengfei Li, Jinfeng Bai, Minlie Huang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17391"" target=""_blank"">2311.17391</a>","<a href=""https://github.com/thu-coai/Implicit-Toxicity"" target=""_blank"">thu-coai</a>",2025-12-03 22:39:25
TARGET: Template-Transferable Backdoor Attack Against Prompt-based NLP Models via GPT4,"Zihao Tan, Qingliang Chen, Yongjian Huang, Chen Liang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17429"" target=""_blank"">2311.17429</a>",,2025-12-03 22:39:25
Topology-Preserving Adversarial Training,"Xiaoyue Mi, Fan Tang, Yepeng Weng, Danding Wang, Juan Cao, Sheng Tang, Peng Li, Yang Liu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17607"" target=""_blank"">2311.17607</a>",,2025-12-03 22:39:25
Query-Relevant Images Jailbreak Large Multi-Modal Models,"Xin Liu, Yichen Zhu, Yunshi Lan, Chao Yang, Yu Qiao",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17600"" target=""_blank"">2311.17600</a>","<a href=""https://github.com/isXinLiu/MM-SafetyBench"" target=""_blank"">isXinLiu</a>",2025-12-03 22:39:25
Analyzing and Explaining Image Classifiers via Diffusion Guidance,"Maximilian Augustin, Yannic Neuhaus, Matthias Hein",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17833"" target=""_blank"">2311.17833</a>",,2025-12-03 22:39:25
Poisoning Attacks Against Contrastive Recommender Systems,"Zongwei Wang, Junliang Yu, Min Gao, Hongzhi Yin, Bin Cui, Shazia Sadiq",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.18244"" target=""_blank"">2311.18244</a>",,2025-12-03 22:39:25
SenTest: Evaluating Robustness of Sentence Encoders,"Tanmay Chavan, Shantanu Patankar, Aditya Kane, Omkar Gokhale, Geetanjali Kale, Raviraj Joshi",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17722"" target=""_blank"">2311.17722</a>",,2025-12-03 22:39:25
Critical Influence of Overparameterization on Sharpness-aware Minimization,"Sungbin Shin, Dongyeop Lee, Maksym Andriushchenko, Namhoon Lee",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17539"" target=""_blank"">2311.17539</a>",,2025-12-03 22:39:25
Meta Co-Training: Two Views are Better than One,"Jay C. Rothenberger, Dimitrios I. Diochnos",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.18083"" target=""_blank"">2311.18083</a>",,2025-12-03 22:39:25
CLIPC8: Face liveness detection algorithm based on image-text pairs and contrastive learning,"Xu Liu, Shu Zhou, Yurong Song, Wenzhe Luo, Xin Zhang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.17583"" target=""_blank"">2311.17583</a>",,2025-12-03 22:39:25
BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP,"Jiawang Bai, Kuofeng Gao, Shaobo Min, Shu-Tao Xia, Zhifeng Li, Wei Liu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16194"" target=""_blank"">2311.16194</a>",,2025-12-03 22:39:25
BAGEL: Backdoor Attacks against Federated Contrastive Learning,"Yao Huang, Kongyang Chen, Jiannong Cao, Jiaxing Shen, Shaowei Wang, Yun Peng, Weilong Peng, Kechao Cai",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.16113"" target=""_blank"">2311.16113</a>",,2025-12-03 22:39:25
Mixing Classifiers to Alleviate the Accuracy-Robustness Trade-Off,"Yatong Bai, Brendon G. Anderson, Somayeh Sojoudi",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.15165"" target=""_blank"">2311.15165</a>",,2025-12-03 22:39:25
Improving Adversarial Transferability by Stable Diffusion,"Jiayang Liu, Siyu Zhu, Siyuan Liang, Jie Zhang, Han Fang, Weiming Zhang, Ee-Chien Chang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11017"" target=""_blank"">2311.11017</a>",,2025-12-03 22:39:25
AdvGen: Physical Adversarial Attack on Face Presentation Attack Detection Systems,"Sai Amrit Patnaik, Shivali Chansoriya, Anil K. Jain, Anoop M. Namboodiri",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11753"" target=""_blank"">2311.11753</a>",,2025-12-03 22:39:25
Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI Systems,"Guangjing Wang, Ce Zhou, Yuanda Wang, Bocheng Chen, Hanqing Guo, Qiben Yan",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11796"" target=""_blank"">2311.11796</a>",,2025-12-03 22:39:25
Understanding Variation in Subpopulation Susceptibility to Poisoning Attacks,"Evan Rose, Fnu Suya, David Evans",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11544"" target=""_blank"">2311.11544</a>","<a href=""https://uvasrg.github.io/visualizing-poisoning"" target=""_blank"">uvasrg.github.io</a>",2025-12-03 22:39:25
Training robust and generalizable quantum models,"Julian Berberich, Daniel Fink, Daniel Pranjić, Christian Tutschku, Christian Holm",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11871"" target=""_blank"">2311.11871</a>",,2025-12-03 22:39:25
BrainWash: A Poisoning Attack to Forget in Continual Learning,"Ali Abbasi, Parsa Nooralinejad, Hamed Pirsiavash, Soheil Kolouri",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11995"" target=""_blank"">2311.11995</a>",,2025-12-03 22:39:25
Adversarial Prompt Tuning for Vision-Language Models,"Jiaming Zhang, Xingjun Ma, Xin Wang, Lingyu Qiu, Jiaqi Wang, Yu-Gang Jiang, Jitao Sang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11261"" target=""_blank"">2311.11261</a>",,2025-12-03 22:39:25
Token-Level Adversarial Prompt Detection Based on Perplexity Measures and Contextual Information,"Zhengmian Hu, Gang Wu, Saayan Mitra, Ruiyi Zhang, Tong Sun, Heng Huang, Viswanathan Swaminathan",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11509"" target=""_blank"">2311.11509</a>",,2025-12-03 22:39:25
BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning,"Siyuan Liang, Mingli Zhu, Aishan Liu, Baoyuan Wu, Xiaochun Cao, Ee-Chien Chang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12075"" target=""_blank"">2311.12075</a>",,2025-12-03 22:39:25
EditShield: Protecting Unauthorized Image Editing by Instruction-guided Diffusion Models,"Ruoxi Chen, Haibo Jin, Jinyin Chen, Lichao Sun",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12066"" target=""_blank"">2311.12066</a>",,2025-12-03 22:39:25
Breaking Boundaries: Balancing Performance and Robustness in Deep Wireless Traffic Forecasting,"Romain Ilbert, Thai V. Hoang, Zonghua Zhang, Themis Palpanas",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09790"" target=""_blank"">2311.09790</a>",,2025-12-03 22:39:25
DefensiveDR: Defending against Adversarial Patches using Dimensionality Reduction,"Nandish Chattopadhyay, Amira Guesmi, Muhammad Abdullah Hanif, Bassem Ouni, Muhammad Shafique",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12211"" target=""_blank"">2311.12211</a>",,2025-12-03 22:39:25
PACOL: Poisoning Attacks Against Continual Learners,"Huayu Li, Gregory Ditzler",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.10919"" target=""_blank"">2311.10919</a>",,2025-12-03 22:39:25
Two-Factor Authentication Approach Based on Behavior Patterns for Defeating Puppet Attacks,"Wenhao Wang, Guyue Li, Zhiming Chu, Haobo Li, Daniele Faccio",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.10389"" target=""_blank"">2311.10389</a>",,2025-12-03 22:39:25
Breaking Temporal Consistency: Generating Video Universal Adversarial Perturbations Using Image Models,"Hee-Seon Kim, Minji Son, Minbeom Kim, Myung-Joon Kwon, Changick Kim",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.10366"" target=""_blank"">2311.10366</a>",,2025-12-03 22:39:25
"Robust Network Slicing: Multi-Agent Policies, Adversarial Attacks, and Defensive Strategies","Feng Wang, M. Cenk Gursoy, Senem Velipasalar",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11206"" target=""_blank"">2311.11206</a>",,2025-12-03 22:39:25
Effective Backdoor Mitigation Depends on the Pre-training Objective,"Sahil Verma, Gantavya Bhatt, Avi Schwarzschild, Soumye Singhal, Arnav Mohanty Das, Chirag Shah, John P Dickerson, Jeff Bilmes",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.14948"" target=""_blank"">2311.14948</a>",,2025-12-03 22:39:25
An Information-theoretic Security Analysis of Honeyword,"Pengcheng Su, Haibo Cheng, Wenting Li, Ping Wang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.10960"" target=""_blank"">2311.10960</a>",,2025-12-03 22:39:25
Attention-Based Real-Time Defenses for Physical Adversarial Attacks in Vision Applications,"Giulio Rossolini, Alessandro Biondi, Giorgio Buttazzo",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11191"" target=""_blank"">2311.11191</a>",,2025-12-03 22:39:25
Hijacking Large Language Models via Adversarial In-Context Learning,"Yao Qiang, Xiangyu Zhou, Dongxiao Zhu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.09948"" target=""_blank"">2311.09948</a>",,2025-12-03 22:39:25
TextGuard: Provable Defense against Backdoor Attacks on Text Classification,"Hengzhi Pei, Jinyuan Jia, Wenbo Guo, Bo Li, Dawn Song",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11225"" target=""_blank"">2311.11225</a>","<a href=""https://github.com/AI-secure/TextGuard"" target=""_blank"">AI-secure</a>",2025-12-03 22:39:25
Generating Valid and Natural Adversarial Examples with Large Language Models,"Zimu Wang, Wei Wang, Qi Chen, Qiufeng Wang, Anh Nguyen",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.11861"" target=""_blank"">2311.11861</a>",,2025-12-03 22:39:25
Boost Adversarial Transferability by Uniform Scale and Mix Mask Method,"Tao Wang, Zijian Ying, Qianmu Li, zhichao Lian",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12051"" target=""_blank"">2311.12051</a>",,2025-12-03 22:39:25
ODDR: Outlier Detection & Dimension Reduction Based Defense Against Adversarial Patches,"Nandish Chattopadhyay, Amira Guesmi, Muhammad Abdullah Hanif, Bassem Ouni, Muhammad Shafique",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12084"" target=""_blank"">2311.12084</a>",,2025-12-03 22:39:25
Trainwreck: A damaging adversarial attack on image classifiers,Jan Zahálka,arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.14772"" target=""_blank"">2311.14772</a>","<a href=""https://github.com/JanZahalka/trainwreck"" target=""_blank"">JanZahalka</a>",2025-12-03 22:39:25
Adversarial defense based on distribution transfer,"Jiahao Chen, Diqun Yan, Li Dong",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13841"" target=""_blank"">2311.13841</a>",,2025-12-03 22:39:25
Robust and Interpretable COVID-19 Diagnosis on Chest X-ray Images using Adversarial Training,"Karina Yang, Alexis Bennett, Dominique Duncan",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.14227"" target=""_blank"">2311.14227</a>",,2025-12-03 22:39:25
Iris Presentation Attack: Assessing the Impact of Combining Vanadium Dioxide Films with Artificial Eyes,"Darshika Jauhari, Renu Sharma, Cunjian Chen, Nelson Sepulveda, Arun Ross",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12773"" target=""_blank"">2311.12773</a>",,2025-12-03 22:39:25
"A Survey of Adversarial CAPTCHAs on its History, Classification and Generation","Zisheng Xu, Qiao Yan, F. Richard Yu, Victor C. M. Leung",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13233"" target=""_blank"">2311.13233</a>",,2025-12-03 22:39:25
Segment (Almost) Nothing: Prompt-Agnostic Adversarial Attacks on Segmentation Models,"Francesco Croce, Matthias Hein",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.14450"" target=""_blank"">2311.14450</a>",,2025-12-03 22:39:25
Transfer Attacks and Defenses for Large Language Models on Coding Tasks,"Chi Zhang, Zifan Wang, Ravi Mangal, Matt Fredrikson, Limin Jia, Corina Pasareanu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13445"" target=""_blank"">2311.13445</a>",,2025-12-03 22:39:25
Universal Jailbreak Backdoors from Poisoned Human Feedback,"Javier Rando, Florian Tramèr",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.14455"" target=""_blank"">2311.14455</a>",,2025-12-03 22:39:25
Panda or not Panda? Understanding Adversarial Attacks with Interactive Visualization,"Yuzhe You, Jarvis Tse, Jian Zhao",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13656"" target=""_blank"">2311.13656</a>",,2025-12-03 22:39:25
Hard Label Black Box Node Injection Attack on Graph Neural Networks,"Yu Zhou, Zihao Dong, Guofeng Zhang, Jingchen Tang",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13244"" target=""_blank"">2311.13244</a>",,2025-12-03 22:39:25
When Side-Channel Attacks Break the Black-Box Property of Embedded Artificial Intelligence,"Benoit Coqueret, Mathieu Carbone, Olivier Sentieys, Gabriel Zaid",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.14005"" target=""_blank"">2311.14005</a>",,2025-12-03 22:39:25
Security and Privacy Challenges in Deep Learning Models,Gopichandh Golla,arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13744"" target=""_blank"">2311.13744</a>",,2025-12-03 22:39:25
A Somewhat Robust Image Watermark against Diffusion-based Editing Models,"Mingtian Tan, Tianhao Wang, Somesh Jha",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13713"" target=""_blank"">2311.13713</a>","<a href=""https://github.com/BennyTMT/RIW"" target=""_blank"">BennyTMT</a>",2025-12-03 22:39:25
OASIS: Offsetting Active Reconstruction Attacks in Federated Learning,"Tre' R. Jeter, Truc Nguyen, Raed Alharbi, My T. Thai",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13739"" target=""_blank"">2311.13739</a>",,2025-12-03 22:39:25
Unified Classification and Rejection: A One-versus-All Framework,"Zhen Cheng, Xu-Yao Zhang, Cheng-Lin Liu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13355"" target=""_blank"">2311.13355</a>",,2025-12-03 22:39:25
SD-NAE: Generating Natural Adversarial Examples with Stable Diffusion,"Yueqian Lin, Jingyang Zhang, Yiran Chen, Hai Li",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12981"" target=""_blank"">2311.12981</a>","<a href=""https://github.com/linyueqian/SD-NAE"" target=""_blank"">linyueqian</a>",2025-12-03 22:39:25
Toward Robust Imperceptible Perturbation against Unauthorized Text-to-image Diffusion-based Synthesis,"Yixin Liu, Chenrui Fan, Yutong Dai, Xun Chen, Pan Zhou, Lichao Sun",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13127"" target=""_blank"">2311.13127</a>","<a href=""https://github.com/liuyixin-louis/MetaCloak"" target=""_blank"">liuyixin-louis</a>",2025-12-03 22:39:25
Stable Unlearnable Example: Enhancing the Robustness of Unlearnable Examples via Stable Error-Minimizing Noise,"Yixin Liu, Kaidi Xu, Xun Chen, Lichao Sun",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.13091"" target=""_blank"">2311.13091</a>","<a href=""https://github.com/liuyixin-louis/Stable-Unlearnable-Example"" target=""_blank"">liuyixin-louis</a>",2025-12-03 22:39:25
Robust Graph Neural Networks via Unbiased Aggregation,"Ruiqi Feng, Zhichao Hou, Tyler Derr, Xiaorui Liu",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.14934"" target=""_blank"">2311.14934</a>",,2025-12-03 22:39:25
Attacking Motion Planners Using Adversarial Perception Errors,"Jonathan Sadeghi, Nicholas A. Lord, John Redford, Romain Mueller",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12722"" target=""_blank"">2311.12722</a>",,2025-12-03 22:39:25
Attention Deficit is Ordered! Fooling Deformable Vision Transformers with Collaborative Adversarial Patches,"Quazi Mishkatul Alam, Bilel Tarchoun, Ihsen Alouani, Nael Abu-Ghazaleh",arXiv,2023-11,"<a href=""http://arxiv.org/abs/2311.12914"" target=""_blank"">2311.12914</a>",,2025-12-03 22:39:25
Adversarial Robustness in Graph Neural Networks: A Hamiltonian Approach,"Kai Zhao, Qiyu Kang, Yang Song, Rui She, Sijie Wang, Wee Peng Tay",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06396"" target=""_blank"">2310.06396</a>","<a href=""https://github.com/zknus/NeurIPS-2023-HANG-Robustness"" target=""_blank"">zknus</a>",2025-12-03 22:39:25
Investigating the Adversarial Robustness of Density Estimation Using the Probability Flow ODE,"Marius Arvinte, Cory Cornelius, Jason Martin, Nageen Himayat",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07084"" target=""_blank"">2310.07084</a>",,2025-12-03 22:39:25
PAC-Bayesian Spectrally-Normalized Bounds for Adversarially Robust Generalization,"Jiancong Xiao, Ruoyu Sun, Zhi- Quan Luo",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06182"" target=""_blank"">2310.06182</a>",,2025-12-03 22:39:25
Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations,"Zeming Wei, Yifei Wang, Yisen Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06387"" target=""_blank"">2310.06387</a>",,2025-12-03 22:39:25
GraphCloak: Safeguarding Task-specific Knowledge within Graph-structured Data from Unauthorized Exploitation,"Yixin Liu, Chenrui Fan, Xun Chen, Pan Zhou, Lichao Sun",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07100"" target=""_blank"">2310.07100</a>",,2025-12-03 22:39:25
FTFT: efficient and robust Fine-Tuning by transFerring Training dynamics,"Yupei Du, Albert Gatt, Dong Nguyen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06588"" target=""_blank"">2310.06588</a>",,2025-12-03 22:39:25
Latent Diffusion Counterfactual Explanations,"Karim Farid, Simon Schrodi, Max Argus, Thomas Brox",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06668"" target=""_blank"">2310.06668</a>",,2025-12-03 22:39:25
Comparing the Robustness of Modern No-Reference Image- and Video-Quality Metrics to Adversarial Attacks,"Anastasia Antsiferova, Khaled Abud, Aleksandr Gushchin, Ekaterina Shumitskaya, Sergey Lavrushkin, Dmitriy Vatolin",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06958"" target=""_blank"">2310.06958</a>",,2025-12-03 22:39:25
No Privacy Left Outside: On the (In-)Security of TEE-Shielded DNN Partition for On-Device ML,"Ziqi Zhang, Chen Gong, Yifeng Cai, Yuanyuan Yuan, Bingyan Liu, Ding Li, Yao Guo, Xiangqun Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07152"" target=""_blank"">2310.07152</a>",,2025-12-03 22:39:25
"Adversarial optimization leads to over-optimistic security-constrained dispatch, but sampling can help","Charles Dawson, Chuchu Fan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06956"" target=""_blank"">2310.06956</a>",,2025-12-03 22:39:25
AdvSV: An Over-the-Air Adversarial Attack Dataset for Speaker Verification,"Li Wang, Jiaqi Li, Yuhao Luo, Jiahao Zheng, Lei Wang, Hao Li, Ke Xu, Chengfang Fang, Jie Shi, Zhizheng Wu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05369"" target=""_blank"">2310.05369</a>",,2025-12-03 22:39:25
Domain Watermark: Effective and Harmless Dataset Copyright Protection is Closed at Hand,"Junfeng Guo, Yiming Li, Lixu Wang, Shu-Tao Xia, Heng Huang, Cong Liu, Bo Li",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14942"" target=""_blank"">2310.14942</a>","<a href=""https://github.com/JunfengGo/Domain-Watermark"" target=""_blank"">JunfengGo</a>",2025-12-03 22:39:25
Theoretical Analysis of Robust Overfitting for Wide DNNs: An NTK Approach,"Shaopeng Fu, Di Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06112"" target=""_blank"">2310.06112</a>","<a href=""https://github.com/fshp971/adv-ntk"" target=""_blank"">fshp971</a>",2025-12-03 22:39:25
Exploring adversarial attacks in federated learning for medical imaging,"Erfan Darzi, Florian Dubost, N. M. Sijtsema, Ooijen P. M. A van",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06227"" target=""_blank"">2310.06227</a>",,2025-12-03 22:39:25
GReAT: A Graph Regularized Adversarial Training Method,"Samet Bayram, Kenneth Barner",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05336"" target=""_blank"">2310.05336</a>",,2025-12-03 22:39:25
An Initial Investigation of Neural Replay Simulator for Over-the-Air Adversarial Perturbations to Automatic Speaker Verification,"Jiaqi Li, Li Wang, Liumeng Xue, Lei Wang, Zhizheng Wu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05354"" target=""_blank"">2310.05354</a>",,2025-12-03 22:39:25
Transferable Availability Poisoning Attacks,"Yiyong Liu, Michael Backes, Xiao Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05141"" target=""_blank"">2310.05141</a>",,2025-12-03 22:39:25
BRAINTEASER: Lateral Thinking Puzzles for Large Language Models,"Yifan Jiang, Filip Ilievski, Kaixin Ma, Zhivar Sourati",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05057"" target=""_blank"">2310.05057</a>",,2025-12-03 22:39:25
Stealthy Backdoor Attack via Confidence-driven Sampling,"Pengfei He, Yue Xing, Han Xu, Jie Ren, Yingqian Cui, Shenglai Zeng, Jiliang Tang, Makoto Yamada, Mohammad Sabokrou",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05263"" target=""_blank"">2310.05263</a>",,2025-12-03 22:39:25
Adversarial Attacks on Combinatorial Multi-Armed Bandits,"Rishab Balasubramanian, Jiawei Li, Prasad Tadepalli, Huazheng Wang, Qingyun Wu, Haoyu Zhao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05308"" target=""_blank"">2310.05308</a>",,2025-12-03 22:39:25
Improving Adversarial Attacks on Latent Diffusion Model,"Boyang Zheng, Chumeng Liang, Xiaoyu Wu, Yan Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04687"" target=""_blank"">2310.04687</a>",,2025-12-03 22:39:25
IPMix: Label-Preserving Data Augmentation Method for Training Robust Classifiers,"Zhenglin Huang, Xiaoan Bao, Na Zhang, Qingqi Zhang, Xiaomei Tu, Biao Wu, Xi Yang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04780"" target=""_blank"">2310.04780</a>",,2025-12-03 22:39:25
Test-Time Adaptation Induces Stronger Accuracy and Agreement-on-the-Line,"Eungyeup Kim, Mingjie Sun, Christina Baek, Aditi Raghunathan, J. Zico Kolter",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04941"" target=""_blank"">2310.04941</a>",,2025-12-03 22:39:25
A Geometrical Approach to Evaluate the Adversarial Robustness of Deep Neural Networks,"Yang Wang, Bo Dong, Ke Xu, Haiyin Piao, Yufei Ding, Baocai Yin, Xin Yang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06468"" target=""_blank"">2310.06468</a>",,2025-12-03 22:39:25
Assessing Robustness via Score-Based Adversarial Image Generation,"Marcel Kollovieh, Lukas Gosch, Marten Lienen, Yan Scholten, Leo Schwinn, Stephan Günnemann",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04285"" target=""_blank"">2310.04285</a>",,2025-12-03 22:39:25
My Brother Helps Me: Node Injection Based Adversarial Attack on Social Bot Detection,"Lanjun Wang, Xinran Qiao, Yanwei Xie, Weizhi Nie, Yongdong Zhang, Anan Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07159"" target=""_blank"">2310.07159</a>",,2025-12-03 22:39:25
Bucks for Buckets (B4B): Active Defenses Against Stealing Encoders,"Jan Dubiński, Stanisław Pawlak, Franziska Boenisch, Tomasz Trzciński, Adam Dziedzic",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08571"" target=""_blank"">2310.08571</a>",,2025-12-03 22:39:25
Deep Reinforcement Learning for Autonomous Cyber Defence: A Survey,"Gregory Palmer, Chris Parry, Daniel J. B. Harrold, Chris Willis",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07745"" target=""_blank"">2310.07745</a>",,2025-12-03 22:39:25
Fed-Safe: Securing Federated Learning in Healthcare Against Adversarial Attacks,"Erfan Darzi, Nanna M. Sijtsema, Ooijen P. M. A van",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08681"" target=""_blank"">2310.08681</a>",,2025-12-03 22:39:25
Evading Detection Actively: Toward Anti-Forensics against Forgery Localization,"Long Zhuo, Shenghai Luo, Shunquan Tan, Han Chen, Bin Li, Jiwu Huang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10036"" target=""_blank"">2310.10036</a>",,2025-12-03 22:39:25
Explore the Effect of Data Selection on Poison Efficiency in Backdoor Attacks,"Ziqiang Li, Pengfei Xia, Hong Sun, Yueqi Zeng, Wei Zhang, Bin Li",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09744"" target=""_blank"">2310.09744</a>",,2025-12-03 22:39:25
Ring-A-Bell! How Reliable are Concept Removal Methods for Diffusion Models? (9%),"Yu-Lin Tsai, Chia-Yi Hsu, Chulin Xie, Chih-Hsun Lin, Jia-You Chen, Bo Li, Pin-Yu Chen, Chia-Mu Yu, Chun-Ying Huang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10012"" target=""_blank"">2310.10012</a>","<a href=""https://github.com/chiayi-hsu/Ring-A-Bell"" target=""_blank"">chiayi-hsu</a>",2025-12-03 22:39:25
VFLAIR: A Research Library and Benchmark for Vertical Federated Learning,"Tianyuan Zou, Zixuan Gu, Yu He, Hideaki Takahashi, Yang Liu, Ya-Qin Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09827"" target=""_blank"">2310.09827</a>","<a href=""https://github.com/FLAIR-THU/VFLAIR"" target=""_blank"">FLAIR-THU</a>",2025-12-03 22:39:25
BufferSearch: Generating Black-Box Adversarial Texts With Lower Queries,"Wenjie Lv, Zhen Wang, Yitao Zheng, Zhehua Zhong, Qi Xuan, Tianyi Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09652"" target=""_blank"">2310.09652</a>",,2025-12-03 22:39:25
Is Certifying $\ell_p$ Robustness Still Worthwhile? (99%),"Ravi Mangal, Klas Leino, Zifan Wang, Kai Hu, Weicheng Yu, Corina Pasareanu, Anupam Datta, Matt Fredrikson",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09361"" target=""_blank"">2310.09361</a>",,2025-12-03 22:39:25
User Inference Attacks on Large Language Models,"Nikhil Kandpal, Krishna Pillutla, Alina Oprea, Peter Kairouz, Christopher A. Choquette-Choo, Zheng Xu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09266"" target=""_blank"">2310.09266</a>",,2025-12-03 22:39:25
"On the Over-Memorization During Natural, Robust and Catastrophic Overfitting","Runqi Lin, Chaojian Yu, Bo Han, Tongliang Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08847"" target=""_blank"">2310.08847</a>",,2025-12-03 22:39:25
Samples on Thin Ice: Re-Evaluating Adversarial Pruning of Neural Networks,"Giorgio Piras, Maura Pintor, Ambra Demontis, Battista Biggio",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08073"" target=""_blank"">2310.08073</a>",,2025-12-03 22:39:25
Concealed Electronic Countermeasures of Radar Signal with Adversarial Examples,"Ruinan Ma, Canjie Zhu, Mingfeng Lu, Yunjie Li, Yu-an Tan, Ruibin Zhang, Ran Tao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08292"" target=""_blank"">2310.08292</a>",,2025-12-03 22:39:25
Provably Cost-Sensitive Adversarial Defense via Randomized Smoothing,"Yuan Xin, Dingfan Chen, Michael Backes, Xiao Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08732"" target=""_blank"">2310.08732</a>",,2025-12-03 22:39:25
Attacks Meet Interpretability (AmI) Evaluation and Findings,"Qian Ma, Ziping Ye, Shagufta Mehnaz",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08808"" target=""_blank"">2310.08808</a>",,2025-12-03 22:39:25
Improving Fast Minimum-Norm Attacks with Hyperparameter Optimization,"Giuseppe Floris, Raffaele Mura, Luca Scionis, Giorgio Piras, Maura Pintor, Ambra Demontis, Battista Biggio",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08177"" target=""_blank"">2310.08177</a>","<a href=""https://github.com/pralab/HO-FMN"" target=""_blank"">pralab</a>",2025-12-03 22:39:25
Generating Less Certain Adversarial Examples Improves Robust Generalization,"Minxing Zhang, Michael Backes, Xiao Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04539"" target=""_blank"">2310.04539</a>",,2025-12-03 22:39:25
Towards Causal Deep Learning for Vulnerability Detection,"Md Mahbubur Rahman, Ira Ceka, Chengzhi Mao, Saikat Chakraborty, Baishakhi Ray, Wei Le",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07958"" target=""_blank"">2310.07958</a>",,2025-12-03 22:39:25
Sentinel: An Aggregation Function to Secure Decentralized Federated Learning,"Chao Feng, Alberto Huertas Celdran, Janosch Baltensperger, Enrique Tomas Matınez Bertran, Gerome Bovet, Burkhard Stiller",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08097"" target=""_blank"">2310.08097</a>",,2025-12-03 22:39:25
Defending Our Privacy With Backdoors,"Dominik Hintersdorf, Lukas Struppek, Daniel Neider, Kristian Kersting",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08320"" target=""_blank"">2310.08320</a>",,2025-12-03 22:39:25
Polynomial Time Cryptanalytic Extraction of Neural Network Models,"Adi Shamir, Isaac Canales-Martinez, Anna Hambitzer, Jorge Chavez-Saab, Francisco Rodrigez-Henriquez, Nitin Satpute",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08708"" target=""_blank"">2310.08708</a>",,2025-12-03 22:39:25
Latent Point Collapse on a Low Dimensional Embedding in Deep Neural Network Classifiers,"Luigi Sbailò, Luca Ghiringhelli",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08224"" target=""_blank"">2310.08224</a>",,2025-12-03 22:39:25
SEE-OoD: Supervised Exploration For Enhanced Out-of-Distribution Detection,"Xiaoyang Song, Wenbo Sun, Maher Nouiehed, Raed Al Kontar, Judy Jin",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08040"" target=""_blank"">2310.08040</a>",,2025-12-03 22:39:25
XAI Benchmark for Visual Explanation,"Yifei Zhang, Siyi Gu, James Song, Bo Pan, Liang Zhao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08537"" target=""_blank"">2310.08537</a>","<a href=""https://xaidataset.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Jailbreaking Black Box Large Language Models in Twenty Queries,"Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani, George J. Pappas, Eric Wong",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08419"" target=""_blank"">2310.08419</a>",,2025-12-03 22:39:25
Voyager: MTD-Based Aggregation Protocol for Mitigating Poisoning Attacks on DFL,"Chao Feng, Alberto Huertas Celdran, Michael Vuong, Gerome Bovet, Burkhard Stiller",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08739"" target=""_blank"">2310.08739</a>",,2025-12-03 22:39:25
Boosting Black-box Attack to Deep Neural Networks with Conditional Diffusion Models,"Renyang Liu, Wei Zhou, Tianwei Zhang, Kangjie Chen, Jun Zhao, Kwok-Yan Lam",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07492"" target=""_blank"">2310.07492</a>",,2025-12-03 22:39:25
Promoting Robustness of Randomized Smoothing: Two Cost-Effective Approaches,"Linbo Liu, Trong Nghia Hoang, Lam M. Nguyen, Tsui-Wei Weng",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07780"" target=""_blank"">2310.07780</a>",,2025-12-03 22:39:25
An Adversarial Example for Direct Logit Attribution: Memory Management in GELU-4L,"Jett Janiak, Can Rager, James Dao, Yeu-Tong Lau",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07325"" target=""_blank"">2310.07325</a>",,2025-12-03 22:39:25
Prompt Backdoors in Visual Prompt Learning,"Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07632"" target=""_blank"">2310.07632</a>",,2025-12-03 22:39:25
Why Train More? Effective and Efficient Membership Inference via Memorization,"Jihye Choi, Shruti Tople, Varun Chandrasekaran, Somesh Jha",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08015"" target=""_blank"">2310.08015</a>",,2025-12-03 22:39:25
VLATTACK: Multimodal Adversarial Attacks on Vision-Language Tasks via Pre-trained Models,"Ziyi Yin, Muchao Ye, Tianrong Zhang, Tianyu Du, Jinguo Zhu, Han Liu, Jinghui Chen, Ting Wang, Fenglong Ma",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04655"" target=""_blank"">2310.04655</a>","<a href=""https://github.com/ericyinyzy/VLAttack"" target=""_blank"">ericyinyzy</a>",2025-12-03 22:39:25
DeepZero: Scaling up Zeroth-Order Optimization for Deep Model Training,"Aochuan Chen, Yimeng Zhang, Jinghan Jia, James Diffenderfer, Jiancheng Liu, Konstantinos Parasyris, Yihua Zhang, Zheng Zhang, Bhavya Kailkhura, Sijia Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02025"" target=""_blank"">2310.02025</a>",,2025-12-03 22:39:25
Kick Bad Guys Out! Conditionally Activated Anomaly Detection in Federated Learning with Zero-Knowledge Proof Verification,"Shanshan Han, Wenxuan Wu, Baturalp Buyukates, Weizhao Jin, Qifan Zhang, Yuhang Yao, Salman Avestimehr, Chaoyang He",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04055"" target=""_blank"">2310.04055</a>",,2025-12-03 22:39:25
OMG-ATTACK: Self-Supervised On-Manifold Generation of Transferable Evasion Attacks,"Ofir Bar Tal, Adi Haviv, Amit H. Bermano",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03707"" target=""_blank"">2310.03707</a>",,2025-12-03 22:39:25
A Survey of Robustness and Safety of 2D and 3D Deep Learning Models Against Adversarial Attacks,"Yanjie Li, Bin Xie, Songtao Guo, Yuanyuan Yang, Bin Xiao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00633"" target=""_blank"">2310.00633</a>",,2025-12-03 22:39:25
Counterfactual Image Generation for adversarially robust and interpretable Classifiers,"Rafael Bischof, Florian Scheidegger, Michael A. Kraus, A. Cristiano I. Malossi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00761"" target=""_blank"">2310.00761</a>",,2025-12-03 22:39:25
Understanding Adversarial Transferability in Federated Learning,"Yijiang Li, Ying Gao, Haohan Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00616"" target=""_blank"">2310.00616</a>",,2025-12-03 22:39:25
On the Onset of Robust Overfitting in Adversarial Training,"Chaojian Yu, Xiaolong Shi, Jun Yu, Bo Han, Tongliang Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00607"" target=""_blank"">2310.00607</a>",,2025-12-03 22:39:25
GhostEncoder: Stealthy Backdoor Attacks with Dynamic Triggers to Pre-trained Encoders in Self-supervised Learning,"Qiannan Wang, Changchun Yin, Zhe Liu, Liming Fang, Run Wang, Chenhao Lin",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00626"" target=""_blank"">2310.00626</a>",,2025-12-03 22:39:25
Fewer is More: Trojan Attacks on Parameter-Efficient Fine-Tuning,"Lauren Hong, Ting Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00648"" target=""_blank"">2310.00648</a>",,2025-12-03 22:39:25
Can Pre-trained Networks Detect Familiar Out-of-Distribution Data? (1%),"Atsuyuki Miyai, Qing Yu, Go Irie, Kiyoharu Aizawa",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00847"" target=""_blank"">2310.00847</a>","<a href=""https://github.com/AtsuMiyai/PT-OOD"" target=""_blank"">AtsuMiyai</a>",2025-12-03 22:39:25
How well does LLM generate security tests? (1%),"Ying Daphne Zhang, Wenjia Daphne Song, Zhengjie Daphne Ji, Daphne Danfeng, Yao, Na Meng",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00710"" target=""_blank"">2310.00710</a>",,2025-12-03 22:39:25
Understanding the Robustness of Randomized Feature Defense Against Query-Based Adversarial Attacks,"Quang H. Nguyen, Yingjie Lao, Tung Pham, Kok-Seng Wong, Khoa D. Doan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00567"" target=""_blank"">2310.00567</a>",,2025-12-03 22:39:25
Human-Producible Adversarial Examples,"David Khachaturov, Yue Gao, Ilia Shumailov, Robert Mullins, Ross Anderson, Kassem Fawaz",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00438"" target=""_blank"">2310.00438</a>",,2025-12-03 22:39:25
Black-box Attacks on Image Activity Prediction and its Natural Language Explanations,"Alina Elena Baia, Valentina Poggioni, Andrea Cavallaro",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00503"" target=""_blank"">2310.00503</a>",,2025-12-03 22:39:25
Horizontal Class Backdoor to Deep Learning,"Hua Ma, Shang Wang, Yansong Gao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00542"" target=""_blank"">2310.00542</a>",,2025-12-03 22:39:25
Refutation of Shapley Values for XAI -- Additional Evidence,"Xuanxiang Huang, Joao Marques-Silva",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00416"" target=""_blank"">2310.00416</a>",,2025-12-03 22:39:25
Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks,"Mehrdad Saberi, Vinu Sankar Sadasivan, Keivan Rezaei, Aounon Kumar, Atoosa Chegini, Wenxiao Wang, Soheil Feizi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00076"" target=""_blank"">2310.00076</a>",,2025-12-03 22:39:25
State Machine Frameworks for Website Fingerprinting Defenses: Maybe Not,Ethan Witwer,arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10789"" target=""_blank"">2310.10789</a>",,2025-12-03 22:39:25
Certified Robustness via Dynamic Margin Maximization and Improved Lipschitz Regularization,"Mahyar Fazlyab, Taha Entesari, Aniket Roy, Rama Chellappa",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00116"" target=""_blank"">2310.00116</a>",,2025-12-03 22:39:25
A Survey of Graph Unlearning,"Anwar Said, Yuying Zhao, Tyler Derr, Mudassir Shabbir, Waseem Abbas, Xenofon Koutsoukos",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02164"" target=""_blank"">2310.02164</a>",,2025-12-03 22:39:25
Adversarial Explainability: Utilizing Explainable Machine Learning in Bypassing IoT Botnet Detection Systems,"Mohammed M. Alani, Atefeh Mashatan, Ali Miri",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00070"" target=""_blank"">2310.00070</a>",,2025-12-03 22:39:25
Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models: A Pilot Study,"Myeongseob Ko, Ming Jin, Chenguang Wang, Ruoxi Jia",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00108"" target=""_blank"">2310.00108</a>","<a href=""https://github.com/ruoxi-jia-group/CLIP-MIA"" target=""_blank"">ruoxi-jia-group</a>",2025-12-03 22:39:25
Source Inference Attacks: Beyond Membership Inference Attacks in Federated Learning,"Hongsheng Hu, Xuyun Zhang, Zoran Salcic, Lichao Sun, Kim-Kwang Raymond Choo, Gillian Dobbie",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.00222"" target=""_blank"">2310.00222</a>",,2025-12-03 22:39:25
Warfare:Breaking the Watermark Protection of AI-Generated Content,"Guanlin Li, Yifei Chen, Jie Zhang, Jiwei Li, Shangwei Guo, Tianwei Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07726"" target=""_blank"">2310.07726</a>",,2025-12-03 22:39:25
Genetic Algorithm-Based Dynamic Backdoor Attack on Federated Learning-Based Network Traffic Classification,"Mahmoud Nazzal, Nura Aljaafari, Ahmed Sawalmeh, Abdallah Khreishah, Muhammad Anan, Abdulelah Algosaibi, Mohammed Alnaeem, Adel Aldalbahi, Abdulaziz Alhumam, Conrado P. Vizcarra, Shadan Alhamed",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06855"" target=""_blank"">2310.06855</a>",,2025-12-03 22:39:25
Robust and Efficient Interference Neural Networks for Defending Against Adversarial Attacks in ImageNet,"Yunuo Xiong, Shujuan Liu, Hongwei Xiong",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05947"" target=""_blank"">2310.05947</a>",,2025-12-03 22:39:25
Benchmarking Local Robustness of High-Accuracy Binary Neural Networks for Enhanced Traffic Sign Recognition,"Andreea Postovan, Mădălina Eraşcu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03033"" target=""_blank"">2310.03033</a>","<a href=""https://github.com/ChristopherBrix/vnncomp2023_benchmarks/tree/main/benchmarks/traffic_signs_recognition"" target=""_blank"">benchmarks</a>",2025-12-03 22:39:25
RobustEdge: Low Power Adversarial Detection for Cloud-Edge Systems,"Abhishek Moitra, Abhiroop Bhattacharjee, Youngeun Kim, Priyadarshini Panda",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.06845"" target=""_blank"">2310.06845</a>",,2025-12-03 22:39:25
VeriDIP: Verifying Ownership of Deep Neural Networks through Privacy Leakage Fingerprints,"Aoting Hu, Zhigang Lu, Renjie Xie, Minhui Xue",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10656"" target=""_blank"">2310.10656</a>",,2025-12-03 22:39:25
Nebula: Self-Attention for Dynamic Malware Analysis,"Dmitrijs Trizna, Luca Demetrio, Battista Biggio, Fabio Roli",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10664"" target=""_blank"">2310.10664</a>",,2025-12-03 22:39:25
Extreme Image Transformations Facilitate Robust Latent Object Representations,"Girik Malik, Dakarai Crowder, Ennio Mingolla",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.07725"" target=""_blank"">2310.07725</a>",,2025-12-03 22:39:25
Exploiting Machine Unlearning for Backdoor Attacks in Deep Learning System,"Peixin Zhang, Jun Sun, Mingtian Tan, Xinyu Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10659"" target=""_blank"">2310.10659</a>",,2025-12-03 22:39:25
Fool Your (Vision and) Language Model With Embarrassingly Simple Permutations,"Yongshuo Zong, Tingyang Yu, Bingchen Zhao, Ruchika Chavhan, Timothy Hospedales",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01651"" target=""_blank"">2310.01651</a>","<a href=""https://github.com/ys-zong/FoolyourVLLMs"" target=""_blank"">ys-zong</a>",2025-12-03 22:39:25
Gotcha! This Model Uses My Code! Evaluating Membership Leakage Risks in Code Models,"Zhou Yang, Zhipeng Zhao, Chenyu Wang, Jieke Shi, Dongsum Kim, Donggyun Han, David Lo",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01166"" target=""_blank"">2310.01166</a>",,2025-12-03 22:39:25
LoFT: Local Proxy Fine-tuning For Improving Transferability Of Adversarial Attacks Against Large Language Model,"Muhammad Ahmed Shah, Roshan Sharma, Hira Dhamyal, Raphael Olivier, Ankit Shah, Joseph Konan, Dareen Alharthi, Hazim T Bukhari, Massa Baali, Soham Deshmukh, Michael Kuhlmann, Bhiksha Raj, Rita Singh",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04445"" target=""_blank"">2310.04445</a>",,2025-12-03 22:39:25
Raze to the Ground: Query-Efficient Adversarial HTML Attacks on Machine-Learning Phishing Webpage Detectors,"Biagio Montaruli, Luca Demetrio, Maura Pintor, Luca Compagna, Davide Balzarotti, Battista Biggio",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03166"" target=""_blank"">2310.03166</a>",,2025-12-03 22:39:25
Untargeted White-box Adversarial Attack with Heuristic Defence Methods in Real-time Deep Learning based Network Intrusion Detection System,"Khushnaseeb Roshan, Aasim Zafar, Sheikh Burhan Ul Haque",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03334"" target=""_blank"">2310.03334</a>",,2025-12-03 22:39:25
Enhancing Robust Representation in Adversarial Training: Alignment and Exclusion Criteria,"Nuoyan Zhou, Nannan Wang, Decheng Liu, Dawei Zhou, Xinbo Gao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03358"" target=""_blank"">2310.03358</a>",,2025-12-03 22:39:25
An Integrated Algorithm for Robust and Imperceptible Audio Adversarial Examples,"Armin Ettenhofer, Jan-Philipp Schulze, Karla Pizzi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03349"" target=""_blank"">2310.03349</a>",,2025-12-03 22:39:25
Adversarial Machine Learning for Social Good: Reframing the Adversary as an Ally,"Shawqi Al-Maliki, Adnan Qayyum, Hassan Ali, Mohamed Abdallah, Junaid Qadir, Dinh Thai Hoang, Dusit Niyato, Ala Al-Fuqaha",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03614"" target=""_blank"">2310.03614</a>",,2025-12-03 22:39:25
SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks,"Alexander Robey, Eric Wong, Hamed Hassani, George J. Pappas",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03684"" target=""_blank"">2310.03684</a>","<a href=""https://github.com/arobey1/smooth-llm"" target=""_blank"">arobey1</a>",2025-12-03 22:39:25
Better Safe than Sorry: Pre-training CLIP against Targeted Data Poisoning and Backdoor Attacks,"Wenhan Yang, Jingdong Gao, Baharan Mirzasoleiman",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.05862"" target=""_blank"">2310.05862</a>",,2025-12-03 22:39:25
Targeted Adversarial Attacks on Generalizable Neural Radiance Fields,"Andras Horvath, Csaba M. Jozsa",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03578"" target=""_blank"">2310.03578</a>",,2025-12-03 22:39:25
Certification of Deep Learning Models for Medical Image Segmentation,"Othmane Laousy, Alexandre Araujo, Guillaume Chassagnon, Nikos Paragios, Marie-Pierre Revel, Maria Vakalopoulou",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03664"" target=""_blank"">2310.03664</a>",,2025-12-03 22:39:25
Certifiably Robust Graph Contrastive Learning,"Minhua Lin, Teng Xiao, Enyan Dai, Xiang Zhang, Suhang Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03312"" target=""_blank"">2310.03312</a>","<a href=""https://github.com/ventr1c/RES-GCL"" target=""_blank"">ventr1c</a>",2025-12-03 22:39:25
Towards Robust and Generalizable Training: An Empirical Study of Noisy Slot Filling for Input Perturbations,"Jiachi Liu, Liwen Wang, Guanting Dong, Xiaoshuai Song, Zechen Wang, Zhengyang Wang, Shanglin Lei, Jinzheng Zhao, Keqing He, Bo Xiao, Weiran Xu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03518"" target=""_blank"">2310.03518</a>","<a href=""https://github.com/dongguanting/Noise-SF"" target=""_blank"">dongguanting</a>",2025-12-03 22:39:25
Optimizing Key-Selection for Face-based One-Time Biometrics via Morphing,"Daile Osorio-Roig, Mahdi Ghafourian, Christian Rathgeb, Ruben Vera-Rodriguez, Christoph Busch, Julian Fierrez",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02997"" target=""_blank"">2310.02997</a>",,2025-12-03 22:39:25
Misusing Tools in Large Language Models With Visual Adversarial Examples,"Xiaohan Fu, Zihan Wang, Shuheng Li, Rajesh K. Gupta, Niloofar Mireshghallah, Taylor Berg-Kirkpatrick, Earlence Fernandes",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03185"" target=""_blank"">2310.03185</a>",,2025-12-03 22:39:25
Burning the Adversarial Bridges: Robust Windows Malware Detection Against Binary-level Mutations,"Ahmed Abusnaina, Yizhen Wang, Sunpreet Arora, Ke Wang, Mihai Christodorescu, David Mohaisen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03285"" target=""_blank"">2310.03285</a>",,2025-12-03 22:39:25
Shielding the Unseen: Privacy Protection through Poisoning NeRF with Spatial Deformation,"Yihan Wu, Brandon Y. Feng, Heng Huang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.03125"" target=""_blank"">2310.03125</a>",,2025-12-03 22:39:25
Adversarial Client Detection via Non-parametric Subspace Monitoring in the Internet of Federated Things,"Xianjian Xie, Xiaochen Xian, Dan Li, Andi Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01537"" target=""_blank"">2310.01537</a>",,2025-12-03 22:39:25
Splitting the Difference on Adversarial Training,"Matan Levi, Aryeh Kontorovich",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02480"" target=""_blank"">2310.02480</a>",,2025-12-03 22:39:25
AFLOW: Developing Adversarial Examples under Extremely Noise-limited Settings,"Renyang Liu, Jinhong Zhang, Haoran Li, Jin Zhang, Yuanyu Wang, Wei Zhou",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09795"" target=""_blank"">2310.09795</a>",,2025-12-03 22:39:25
SlowFormer: Universal Adversarial Patch for Attack on Compute and Energy Efficiency of Inference Efficient Vision Transformers,"KL Navaneet, Soroush Abbasi Koohpayegani, Essam Sleiman, Hamed Pirsiavash",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02544"" target=""_blank"">2310.02544</a>",,2025-12-03 22:39:25
Towards Stable Backdoor Purification through Feature Shift Tuning,"Rui Min, Zeyu Qin, Li Shen, Minhao Cheng",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01875"" target=""_blank"">2310.01875</a>","<a href=""https://github.com/AISafety-HKUST/stable_backdoor_purification"" target=""_blank"">AISafety-HKUST</a>",2025-12-03 22:39:25
Jailbreaker in Jail: Moving Target Defense for Large Language Models,"Bocheng Chen, Advait Paliwal, Qiben Yan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02417"" target=""_blank"">2310.02417</a>",,2025-12-03 22:39:25
AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models,"Xiaogeng Liu, Nan Xu, Muhao Chen, Chaowei Xiao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.04451"" target=""_blank"">2310.04451</a>",,2025-12-03 22:39:25
Beyond Labeling Oracles: What does it mean to steal ML models? (47%),"Avital Shafran, Ilia Shumailov, Murat A. Erdogdu, Nicolas Papernot",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01959"" target=""_blank"">2310.01959</a>",,2025-12-03 22:39:25
A Recipe for Improved Certifiable Robustness,"Kai Hu, Klas Leino, Zifan Wang, Matt Fredrikson",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02513"" target=""_blank"">2310.02513</a>","<a href=""https://github.com/hukkai/liresnet"" target=""_blank"">hukkai</a>",2025-12-03 22:39:25
Exploring Model Learning Heterogeneity for Boosting Ensemble Robustness,"Yanzhao Wu, Ka-Ho Chow, Wenqi Wei, Ling Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02237"" target=""_blank"">2310.02237</a>",,2025-12-03 22:39:25
FLEDGE: Ledger-based Federated Learning Resilient to Inference and Backdoor Attacks,"Jorge Castillo, Phillip Rieger, Hossein Fereidooni, Qian Chen, Ahmad Sadeghi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.02113"" target=""_blank"">2310.02113</a>",,2025-12-03 22:39:25
AutoLoRa: A Parameter-Free Automated Robust Fine-Tuning Framework,"Xilie Xu, Jingfeng Zhang, Mohan Kankanhalli",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01818"" target=""_blank"">2310.01818</a>",,2025-12-03 22:39:25
Fooling the Textual Fooler via Randomizing Latent Representations,"Duy C. Hoang, Quang H. Nguyen, Saurav Manchanda, MinLong Peng, Kok-Seng Wong, Khoa D. Doan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01452"" target=""_blank"">2310.01452</a>",,2025-12-03 22:39:25
"LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples","Jia-Yu Yao, Kun-Peng Ning, Zhen-Hui Liu, Mu-Nan Ning, Li Yuan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.01469"" target=""_blank"">2310.01469</a>",,2025-12-03 22:39:25
Black-box Targeted Adversarial Attack on Segment Anything (SAM),"Sheng Zheng, Chaoning Zhang, Xinhong Hao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10010"" target=""_blank"">2310.10010</a>",,2025-12-03 22:39:25
Investigating the Robustness and Properties of Detection Transformers (DETR) Toward Difficult Images,"Zhao Ning Zou, Yuhang Zhang, Robert Wijaya",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.08772"" target=""_blank"">2310.08772</a>",,2025-12-03 22:39:25
SCME: A Self-Contrastive Method for Data-free and Query-Limited Model Extraction Attack,"Renyang Liu, Jinhong Zhang, Kwok-Yan Lam, Jun Zhao, Wei Zhou",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09792"" target=""_blank"">2310.09792</a>",,2025-12-03 22:39:25
Wide Flat Minimum Watermarking for Robust Ownership Verification of GANs,"Jianwei Fei, Zhihua Xia, Benedetta Tondi, Mauro Barni",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16919"" target=""_blank"">2310.16919</a>",,2025-12-03 22:39:25
A Survey on Transferability of Adversarial Examples across Deep Neural Networks,"Jindong Gu, Xiaojun Jia, Jorge Pau de, Wenqain Yu, Xinwei Liu, Avery Ma, Yuan Xun, Anjun Hu, Ashkan Khakzar, Zhijiang Li, Xiaochun Cao, Philip Torr",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17626"" target=""_blank"">2310.17626</a>",,2025-12-03 22:39:25
Defending Against Transfer Attacks From Public Models,"Chawin Sitawarin, Jaewon Chang, David Huang, Wesson Altoyan, David Wagner",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17645"" target=""_blank"">2310.17645</a>","<a href=""https://github.com/wagner-group/pubdef"" target=""_blank"">wagner-group</a>",2025-12-03 22:39:25
Uncertainty-weighted Loss Functions for Improved Adversarial Attacks on Semantic Segmentation,"Kira Maag, Asja Fischer",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17436"" target=""_blank"">2310.17436</a>",,2025-12-03 22:39:25
Detection Defenses: An Empty Promise against Adversarial Patch Attacks on Optical Flow,"Erik Scheurer, Jenny Schmalfuss, Alexander Lis, Andrés Bruhn",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17403"" target=""_blank"">2310.17403</a>","<a href=""https://github.com/cv-stuttgart/DetectionDefenses"" target=""_blank"">cv-stuttgart</a>",2025-12-03 22:39:25
CBD: A Certified Backdoor Detector Based on Local Dominant Probability,"Zhen Xiang, Zidi Xiong, Bo Li",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17498"" target=""_blank"">2310.17498</a>",,2025-12-03 22:39:25
SoK: Pitfalls in Evaluating Black-Box Attacks,"Fnu Suya, Anshuman Suri, Tingwei Zhang, Jingtao Hong, Yuan Tian, David Evans",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17534"" target=""_blank"">2310.17534</a>",,2025-12-03 22:39:25
Instability of computer vision models is a necessary result of the task itself,"Oliver Turnbull, George Cevora",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17559"" target=""_blank"">2310.17559</a>",,2025-12-03 22:39:25
PAC-tuning:Fine-tuning Pretrained Language Models with PAC-driven Perturbed Gradient Descent,"Guangliang Liu, Zhiyu Xue, Xitong Zhang, Kristen Marie Johnson, Rongrong Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17588"" target=""_blank"">2310.17588</a>",,2025-12-03 22:39:25
A minimax optimal control approach for robust neural ODEs,"Cristina Cipriani, Alessandro Scagliotti, Tobias Wöhrer",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17584"" target=""_blank"">2310.17584</a>",,2025-12-03 22:39:25
"Break it, Imitate it, Fix it: Robustness by Generating Human-Like Attacks","Aradhana Sinha, Ananth Balashankar, Ahmad Beirami, Thi Avrahami, Jilin Chen, Alex Beutel",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16955"" target=""_blank"">2310.16955</a>",,2025-12-03 22:39:25
"Trust, but Verify: Robust Image Segmentation using Deep Learning","Fahim Ahmed Zaman, Xiaodong Wu, Weiyu Xu, Milan Sonka, Raghuraman Mudumbai",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16999"" target=""_blank"">2310.16999</a>",,2025-12-03 22:39:25
"Dual Defense: Adversarial, Traceable, and Invisible Robust Watermarking against Face Swapping","Yunming Zhang, Dengpan Ye, Caiyun Xie, Long Tang, Chuanxi Chen, Ziyi Liu, Jiacheng Deng",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16540"" target=""_blank"">2310.16540</a>",,2025-12-03 22:39:25
On the Proactive Generation of Unsafe Images From Text-To-Image Models Using Benign Prompts,"Yixin Wu, Ning Yu, Michael Backes, Yun Shen, Yang Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16613"" target=""_blank"">2310.16613</a>",,2025-12-03 22:39:25
Multi-scale Diffusion Denoised Smoothing,"Jongheon Jeong, Jinwoo Shin",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16779"" target=""_blank"">2310.16779</a>",,2025-12-03 22:39:25
Elevating Code-mixed Text Handling through Auditory Information of Words,"Mamta, Zishan Ahmad, Asif Ekbal",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18155"" target=""_blank"">2310.18155</a>","<a href=""https://github.com/20118/DefenseWithPhonetics"" target=""_blank"">20118</a>",2025-12-03 22:39:25
SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous Manipulation,"Qianxu Wang, Haotong Zhang, Congyue Deng, Yang You, Hao Dong, Yixin Zhu, Leonidas Guibas",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16838"" target=""_blank"">2310.16838</a>",,2025-12-03 22:39:25
Defense Against Model Extraction Attacks on Recommender Systems,"Sixiao Zhang, Hongzhi Yin, Hongxu Chen, Cheng Long",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16335"" target=""_blank"">2310.16335</a>",,2025-12-03 22:39:25
Segue: Side-information Guided Generative Unlearnable Examples for Facial Privacy Protection in Real World,"Zhiling Zhang, Jie Zhang, Kui Zhang, Wenbo Zhou, Weiming Zhang, Nenghai Yu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16061"" target=""_blank"">2310.16061</a>",,2025-12-03 22:39:25
Hierarchical Randomized Smoothing,"Yan Scholten, Jan Schuchardt, Aleksandar Bojchevski, Stephan Günnemann",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16221"" target=""_blank"">2310.16221</a>",,2025-12-03 22:39:25
Improving Robustness and Reliability in Medical Image Classification with Latent-Guided Diffusion and Nested-Ensembles,"Xing Shen, Hengguan Huang, Brennan Nichyporuk, Tal Arbel",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15952"" target=""_blank"">2310.15952</a>",,2025-12-03 22:39:25
Momentum Gradient-based Untargeted Attack on Hypergraph Neural Networks,"Yang Chen, Stjepan Picek, Zhonglin Ye, Zhaoyang Wang, Haixing Zhao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15656"" target=""_blank"">2310.15656</a>",,2025-12-03 22:39:25
Corrupting Neuron Explanations of Deep Visual Features,"Divyansh Srivastava, Tuomas Oikarinen, Tsui-Wei Weng",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16332"" target=""_blank"">2310.16332</a>",,2025-12-03 22:39:25
Guiding LLM to Fool Itself: Automatically Manipulating Machine Reading Comprehension Shortcut Triggers,"Mosh Levy, Shauli Ravfogel, Yoav Goldberg",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18360"" target=""_blank"">2310.18360</a>",,2025-12-03 22:39:25
A Survey on Detection of LLMs-Generated Content,"Xianjun Yang, Liangming Pan, Xuandong Zhao, Haifeng Chen, Linda Petzold, William Yang Wang, Wei Cheng",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15654"" target=""_blank"">2310.15654</a>","<a href=""https://github.com/Xianjun-Yang/Awesome_papers_on_LLMs_detection"" target=""_blank"">Xianjun-Yang</a>",2025-12-03 22:39:25
White-box Compiler Fuzzing Empowered by Large Language Models,"Chenyuan Yang, Yinlin Deng, Runyu Lu, Jiayi Yao, Jiawei Liu, Reyhaneh Jabbarvand, Lingming Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15991"" target=""_blank"">2310.15991</a>",,2025-12-03 22:39:25
Enhancing Large Language Models for Secure Code Generation: A Dataset-driven Study on Vulnerability Mitigation,"Jiexin Wang, Liuwen Cao, Xitong Luo, Zhiping Zhou, Jiayuan Xie, Adam Jatowt, Yi Cai",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.16263"" target=""_blank"">2310.16263</a>",,2025-12-03 22:39:25
Semantic-Aware Adversarial Training for Reliable Deep Hashing Retrieval,"Xu Yuan, Zheng Zhang, Xunguang Wang, Lin Wu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14637"" target=""_blank"">2310.14637</a>","<a href=""https://github.com/xandery-geek/SAAT"" target=""_blank"">xandery-geek</a>",2025-12-03 22:39:25
F$^2$AT: Feature-Focusing Adversarial Training via Disentanglement of Natural and Perturbed Patterns,"Yaguan Qian, Chenyu Zhao, Zhaoquan Gu, Bin Wang, Shouling Ji, Wei Wang, Boyang Zhou, Pan Zhou",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14561"" target=""_blank"">2310.14561</a>",,2025-12-03 22:39:25
Understanding Parameter Saliency via Extreme Value Theory,"Shuo Wang, Issei Sato",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.17951"" target=""_blank"">2310.17951</a>",,2025-12-03 22:39:25
LipSim: A Provably Robust Perceptual Similarity Metric,"Sara Ghazanfari, Alexandre Araujo, Prashanth Krishnamurthy, Farshad Khorrami, Siddharth Garg",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18274"" target=""_blank"">2310.18274</a>","<a href=""https://github.com/SaraGhazanfari/LipSim"" target=""_blank"">SaraGhazanfari</a>",2025-12-03 22:39:25
Fast Propagation is Better: Accelerating Single-Step Adversarial Training via Sampling Subnetworks,"Xiaojun Jia, Jianshu Li, Jindong Gu, Yang Bai, Xiaochun Cao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15444"" target=""_blank"">2310.15444</a>","<a href=""https://github.com/jiaxiaojunQAQ/FP-Better"" target=""_blank"">jiaxiaojunQAQ</a>",2025-12-03 22:39:25
Blacksmith: Fast Adversarial Training of Vision Transformers via a Mixture of Single-step and Multi-step Methods,"Mahdi Salmani, Alireza Dehghanpour Farashah, Mohammad Azizmalayeri, Mahdi Amiri, Navid Eslami, Mohammad Taghi Manzuri, Mohammad Hossein Rohban",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18975"" target=""_blank"">2310.18975</a>",,2025-12-03 22:39:25
Amoeba: Circumventing ML-supported Network Censorship via Adversarial Reinforcement Learning,"Haoyu Liu, Alec F. Diallo, Paul Patras",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.20469"" target=""_blank"">2310.20469</a>",,2025-12-03 22:39:25
LFAA: Crafting Transferable Targeted Adversarial Examples with Low-Frequency Perturbations,"Kunyu Wang, Juluan Shi, Wenxuan Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.20175"" target=""_blank"">2310.20175</a>",,2025-12-03 22:39:25
Is Robustness Transferable across Languages in Multilingual Neural Machine Translation? (26%),"Leiyu Pan, Supryadi, Deyi Xiong",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.20162"" target=""_blank"">2310.20162</a>",,2025-12-03 22:39:25
Dynamic Batch Norm Statistics Update for Natural Robustness,"Shahbaz Rezaei, Mohammad Sadegh Norouzzadeh",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.20649"" target=""_blank"">2310.20649</a>",,2025-12-03 22:39:25
In Search of Lost Online Test-time Adaptation: A Survey,"Zixin Wang, Yadan Luo, Liang Zheng, Zhuoxiao Chen, Sen Wang, Zi Huang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.20199"" target=""_blank"">2310.20199</a>","<a href=""https://github.com/Jo-wang/OTTA_ViT_survey"" target=""_blank"">Jo-wang</a>",2025-12-03 22:39:25
Label-Only Model Inversion Attacks via Knowledge Transfer,"Ngoc-Bao Nguyen, Keshigeyan Chandrasegaran, Milad Abdollahzadeh, Ngai-Man Cheung",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19342"" target=""_blank"">2310.19342</a>","<a href=""https://ngoc-nguyen-0.github.io/lokt/"" target=""_blank"">lokt</a>",2025-12-03 22:39:25
Exploring Geometry of Blind Spots in Vision Models,"Sriram Balasubramanian, Gaurang Sriramanan, Vinu Sankar Sadasivan, Soheil Feizi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19889"" target=""_blank"">2310.19889</a>","<a href=""https://github.com/SriramB-98/blindspots-neurips-sub"" target=""_blank"">SriramB-98</a>",2025-12-03 22:39:25
Adversarial Attacks and Defenses in Large Language Models: Old and New Threats,"Leo Schwinn, David Dobre, Stephan Günnemann, Gauthier Gidel",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19737"" target=""_blank"">2310.19737</a>",,2025-12-03 22:39:25
Generated Distributions Are All You Need for Membership Inference Attacks Against Generative Models,"Minxing Zhang, Ning Yu, Rui Wen, Michael Backes, Yang Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19410"" target=""_blank"">2310.19410</a>",,2025-12-03 22:39:25
"Causal Fair Metric: Bridging Causality, Individual Fairness, and Adversarial Robustness","Ahmad-Reza Ehyaei, Golnoosh Farnadi, Samira Samadi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19391"" target=""_blank"">2310.19391</a>",,2025-12-03 22:39:25
Differentially Private Reward Estimation with Preference Feedback,"Sayak Ray Chowdhury, Xingyu Zhou, Nagarajan Natarajan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19733"" target=""_blank"">2310.19733</a>",,2025-12-03 22:39:25
Asymmetric Diffusion Based Channel-Adaptive Secure Wireless Semantic Communications,"Xintian Ren, Jun Wu, Hansong Xu, Qianqian Pan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19439"" target=""_blank"">2310.19439</a>",,2025-12-03 22:39:25
Privacy-Preserving Federated Learning over Vertically and Horizontally Partitioned Data for Financial Anomaly Detection,"Swanand Ravindra Kadhe, Heiko Ludwig, Nathalie Baracaldo, Alan King, Yi Zhou, Keith Houck, Ambrish Rawat, Mark Purcell, Naoise Holohan, Mikio Takeuchi, Ryo Kawahara, Nir Drucker, Hayim Shaul, Eyal Kushnir, Omri Soceanu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19304"" target=""_blank"">2310.19304</a>",,2025-12-03 22:39:25
Boosting Decision-Based Black-Box Adversarial Attack with Gradient Priors,"Han Liu, Xingshuo Huang, Xiaotong Zhang, Qimai Li, Fenglong Ma, Wei Wang, Hongyang Chen, Hong Yu, Xianchao Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19038"" target=""_blank"">2310.19038</a>",,2025-12-03 22:39:25
Understanding and Improving Ensemble Adversarial Defense,"Yian Deng, Tingting Mu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18477"" target=""_blank"">2310.18477</a>",,2025-12-03 22:39:25
BERT Lost Patience Won't Be Robust to Adversarial Slowdown,"Zachary Coalson, Gabriel Ritter, Rakesh Bobba, Sanghyun Hong",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19152"" target=""_blank"">2310.19152</a>","<a href=""https://github.com/ztcoalson/WAFFLE"" target=""_blank"">ztcoalson</a>",2025-12-03 22:39:25
Adversarial Examples Are Not Real Features,"Ang Li, Yifei Wang, Yiwen Guo, Yisen Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18936"" target=""_blank"">2310.18936</a>","<a href=""https://github.com/PKU-ML/AdvNotRealFeatures"" target=""_blank"">PKU-ML</a>",2025-12-03 22:39:25
IMPRESS: Evaluating the Resilience of Imperceptible Perturbations Against Unauthorized Data Usage in Diffusion-Based Generative AI,"Bochuan Cao, Changjiang Li, Ting Wang, Jinyuan Jia, Bo Li, Jinghui Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19248"" target=""_blank"">2310.19248</a>",,2025-12-03 22:39:25
Poisoning Retrieval Corpora by Injecting Adversarial Passages,"Zexuan Zhong, Ziqing Huang, Alexander Wettig, Danqi Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19156"" target=""_blank"">2310.19156</a>",,2025-12-03 22:39:25
Label Poisoning is All You Need,"Rishi D. Jha, Jonathan Hayase, Sewoong Oh",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18933"" target=""_blank"">2310.18933</a>",,2025-12-03 22:39:25
Towards Deep Learning Models Resistant to Transfer-based Adversarial Attacks via Data-centric Robust Learning,"Yulong Yang, Chenhao Lin, Xiang Ji, Qiwei Tian, Qian Li, Hongshan Yang, Zhibo Wang, Chao Shen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.09891"" target=""_blank"">2310.09891</a>",,2025-12-03 22:39:25
Path Analysis for Effective Fault Localization in Deep Neural Networks,"Soroush Hashemifar, Saeed Parsa, Akram Kalaee",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18987"" target=""_blank"">2310.18987</a>",,2025-12-03 22:39:25
"From Chatbots to PhishBots? -- Preventing Phishing scams created using ChatGPT, Google Bard and Claude","Sayak Saha Roy, Poojitha Thota, Krishna Vamsi Naragam, Shirin Nilizadeh",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19181"" target=""_blank"">2310.19181</a>",,2025-12-03 22:39:25
Assessing and Improving Syntactic Adversarial Robustness of Pre-trained Models for Code Translation,"Guang Yang, Yu Zhou, Xiangyu Zhang, Xiang Chen, Tingting Han, Taolue Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18587"" target=""_blank"">2310.18587</a>",,2025-12-03 22:39:25
Benchmark Generation Framework with Customizable Distortions for Image Classifier Robustness,"Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad Mousavi, Zachariah Carmichael, Vineet Gundecha, Sahand Ghorbanpour, Ricardo Luna, Gutierrez Antonio Guillen, Avisek Naug",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18626"" target=""_blank"">2310.18626</a>",,2025-12-03 22:39:25
Purify++: Improving Diffusion-Purification with Advanced Diffusion Models and Control of Randomness,"Boya Zhang, Weijian Luo, Zhihua Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18762"" target=""_blank"">2310.18762</a>",,2025-12-03 22:39:25
Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers,"Wencong You, Zayd Hammoudeh, Daniel Lowd",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18603"" target=""_blank"">2310.18603</a>",,2025-12-03 22:39:25
Where have you been? A Study of Privacy Risk for Point-of-Interest Recommendation,"Kunlin Cai, Jinghuai Zhang, Will Shand, Zhiqing Hong, Guang Wang, Desheng Zhang, Jianfeng Chi, Yuan Tian",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.18606"" target=""_blank"">2310.18606</a>",,2025-12-03 22:39:25
AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models,"Sicheng Zhu, Ruiyi Zhang, Bang An, Gang Wu, Joe Barrow, Zichao Wang, Furong Huang, Ani Nenkova, Tong Sun",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15140"" target=""_blank"">2310.15140</a>",,2025-12-03 22:39:25
Robustifying Language Models with Test-Time Adaptation,"Noah Thomas McDermott, Junfeng Yang, Chengzhi Mao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.19177"" target=""_blank"">2310.19177</a>",,2025-12-03 22:39:25
On the Detection of Image-Scaling Attacks in Machine Learning,"Erwin Quiring, Andreas Müller, Konrad Rieck",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15085"" target=""_blank"">2310.15085</a>",,2025-12-03 22:39:25
Generalizability of CNN Architectures for Face Morph Presentation Attack,"Sherko R. HmaSalah, Aras Asaad",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11105"" target=""_blank"">2310.11105</a>",,2025-12-03 22:39:25
IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks,"Yue Cao, Tianlin Li, Xiaofeng Cao, Ivor Tsang, Yang Liu, Qing Guo",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11890"" target=""_blank"">2310.11890</a>",,2025-12-03 22:39:25
Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class Manipulation Using DeepFool Algorithm,"S. M. Fazle Rabby Labib, Joyanta Jyoti Mondal, Meem Arafat Manab, Sarfaraz Newaz, Xi Xiao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13019"" target=""_blank"">2310.13019</a>",,2025-12-03 22:39:25
Malicious Agent Detection for Robust Multi-Agent Collaborative Perception,"Yangheng Zhao, Zhen Xiang, Sheng Yin, Xianghe Pang, Siheng Chen, Yanfeng Wang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11901"" target=""_blank"">2310.11901</a>",,2025-12-03 22:39:25
Black-Box Training Data Identification in GANs via Detector Networks,"Lukman Olagoke, Salil Vadhan, Seth Neel",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12063"" target=""_blank"">2310.12063</a>",,2025-12-03 22:39:25
Adversarial Training for Physics-Informed Neural Networks,"Yao Li, Shengzhu Shi, Zhichang Guo, Boying Wu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11789"" target=""_blank"">2310.11789</a>",,2025-12-03 22:39:25
REVAMP: Automated Simulations of Adversarial Attacks on Arbitrary Objects in Realistic Scenes,"Matthew Hull, Zijie J. Wang, Duen Horng Chau",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12243"" target=""_blank"">2310.12243</a>","<a href=""https://github.com/poloclub/revamp"" target=""_blank"">poloclub</a>",2025-12-03 22:39:25
Quantifying Privacy Risks of Prompts in Visual Prompt Learning,"Yixin Wu, Rui Wen, Michael Backes, Pascal Berrang, Mathias Humbert, Yun Shen, Yang Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11970"" target=""_blank"">2310.11970</a>",,2025-12-03 22:39:25
To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images,"Yimeng Zhang, Jinghan Jia, Xin Chen, Aochuan Chen, Yihua Zhang, Jiancheng Liu, Ke Ding, Sijia Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11868"" target=""_blank"">2310.11868</a>","<a href=""https://github.com/OPTML-Group/Diffusion-MU-Attack"" target=""_blank"">OPTML-Group</a>",2025-12-03 22:39:25
CAT: Closed-loop Adversarial Training for Safe End-to-End Driving,"Linrui Zhang, Zhenghao Peng, Quanyi Li, Bolei Zhou",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12432"" target=""_blank"">2310.12432</a>","<a href=""https://metadriverse.github.io/cat"" target=""_blank"">metadriverse.github.io</a>",2025-12-03 22:39:25
PrivInfer: Privacy-Preserving Inference for Black-box Large Language Model,"Meng Tong, Kejiang Chen, Yuang Qi, Jie Zhang, Weiming Zhang, Nenghai Yu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12214"" target=""_blank"">2310.12214</a>",,2025-12-03 22:39:25
The Efficacy of Transformer-based Adversarial Attacks in Security Domains,"Kunyang Li, Kyle Domico, Jean-Charles Noirot Ferrand, Patrick McDaniel",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11597"" target=""_blank"">2310.11597</a>",,2025-12-03 22:39:25
Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning,"Taejin Kim, Jiarui Li, Shubhranshu Singh, Nikhil Madaan, Carlee Joe-Wong",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11594"" target=""_blank"">2310.11594</a>",,2025-12-03 22:39:25
WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks,"Jun Xia, Zhihao Yue, Yingbo Zhou, Zhiwei Ling, Xian Wei, Mingsong Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.11595"" target=""_blank"">2310.11595</a>",,2025-12-03 22:39:25
Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks,"Erfan Shayegani, Md Abdullah Al Mamun, Yu Fu, Pedram Zaree, Yue Dong, Nael Abu-Ghazaleh",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10844"" target=""_blank"">2310.10844</a>",,2025-12-03 22:39:25
Exploring Decision-based Black-box Attacks on Face Forgery Detection,"Zhaoyu Chen, Bo Li, Kaixun Jiang, Shuang Wu, Shouhong Ding, Wenqiang Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12017"" target=""_blank"">2310.12017</a>",,2025-12-03 22:39:25
Regularization properties of adversarially-trained linear regression,"Antônio H. Ribeiro, Dave Zachariah, Francis Bach, Thomas B. Schön",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10807"" target=""_blank"">2310.10807</a>",,2025-12-03 22:39:25
Fast Adversarial Label-Flipping Attack on Tabular Data,"Xinglong Chang, Gillian Dobbie, Jörg Wicker",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10744"" target=""_blank"">2310.10744</a>",,2025-12-03 22:39:25
A Non-monotonic Smooth Activation Function,"Koushik Biswas, Meghana Karri, Ulaş Bağcı",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10126"" target=""_blank"">2310.10126</a>",,2025-12-03 22:39:25
Quantifying Assistive Robustness Via the Natural-Adversarial Frontier,"Jerry Zhi-Yang He, Zackory Erickson, Daniel S. Brown, Anca D. Dragan",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10610"" target=""_blank"">2310.10610</a>","<a href=""https://ood-human.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Unleashing the potential of prompt engineering: a comprehensive review,"Banghao Chen, Zhaofeng Zhang, Nicolas Langrené, Shengxin Zhu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14735"" target=""_blank"">2310.14735</a>",,2025-12-03 22:39:25
A Comprehensive Study of Privacy Risks in Curriculum Learning,"Joann Qiongna Chen, Xinlei He, Zheng Li, Yang Zhang, Zhou Li",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10124"" target=""_blank"">2310.10124</a>",,2025-12-03 22:39:25
DANAA: Towards transferable attacks with double adversarial neuron attribution,"Zhibo Jin, Zhiyu Zhu, Xinyi Wang, Jiayu Zhang, Jun Shen, Huaming Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10427"" target=""_blank"">2310.10427</a>","<a href=""https://github.com/Davidjinzb/DANAA"" target=""_blank"">Davidjinzb</a>",2025-12-03 22:39:25
Demystifying Poisoning Backdoor Attacks from a Statistical Perspective,"Ganghua Wang, Xun Xian, Jayanth Srinivasa, Ashish Kundu, Xuan Bi, Mingyi Hong, Jie Ding",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10780"" target=""_blank"">2310.10780</a>",,2025-12-03 22:39:25
Prompt Packer: Deceiving LLMs through Compositional Instruction with Hidden Attacks,"Shuyu Jiang, Xingshu Chen, Rui Tang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10077"" target=""_blank"">2310.10077</a>",,2025-12-03 22:39:25
Robust Multi-Agent Reinforcement Learning via Adversarial Regularization: Theoretical Foundation and Stable Algorithms,"Alexander Bukharin, Yan Li, Yue Yu, Qingru Zhang, Zhehui Chen, Simiao Zuo, Chao Zhang, Songan Zhang, Tuo Zhao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10810"" target=""_blank"">2310.10810</a>","<a href=""https://github.com/abukharin3/ERNIE"" target=""_blank"">abukharin3</a>",2025-12-03 22:39:25
Passive Inference Attacks on Split Learning via Adversarial Regularization,"Xiaochen Zhu, Xinjian Luo, Yuncheng Wu, Yangfan Jiang, Xiaokui Xiao, Beng Chin Ooi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10483"" target=""_blank"">2310.10483</a>",,2025-12-03 22:39:25
Orthogonal Uncertainty Representation of Data Manifold for Robust Long-Tailed Learning,"Yanbiao Ma, Licheng Jiao, Fang Liu, Shuyuan Yang, Xu Liu, Lingling Li",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10090"" target=""_blank"">2310.10090</a>",,2025-12-03 22:39:25
Will the Prince Get True Love's Kiss? On the Model Sensitivity to Gender Perturbation over Fairytale Texts,"Christina Chance, Da Yin, Dakuo Wang, Kai-Wei Chang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10865"" target=""_blank"">2310.10865</a>",,2025-12-03 22:39:25
Segment Anything Meets Universal Adversarial Perturbation,"Dongshen Han, Sheng Zheng, Chaoning Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12431"" target=""_blank"">2310.12431</a>",,2025-12-03 22:39:25
On the Transferability of Learning Models for Semantic Segmentation for Remote Sensing Data,"Rongjun Qin, Guixiang Zhang, Yang Tang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.10490"" target=""_blank"">2310.10490</a>","<a href=""https://github.com/GDAOSU/Transferability-Remote-Sensing"" target=""_blank"">GDAOSU</a>",2025-12-03 22:39:25
Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models,"Jianwei Li, Qi Lei, Wei Cheng, Dongkuan Xu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13191"" target=""_blank"">2310.13191</a>",,2025-12-03 22:39:25
Adversarial Attacks on Fairness of Graph Neural Networks,"Binchi Zhang, Yushun Dong, Chen Chen, Yada Zhu, Minnan Luo, Jundong Li",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13822"" target=""_blank"">2310.13822</a>","<a href=""https://github.com/zhangbinchi/G-FairAttack"" target=""_blank"">zhangbinchi</a>",2025-12-03 22:39:25
RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions,"Lingdong Kong, Shaoyuan Xie, Hanjiang Hu, Lai Xing Ng, Benoit R. Cottereau, Wei Tsang Ooi",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15171"" target=""_blank"">2310.15171</a>",,2025-12-03 22:39:25
Attention-Enhancing Backdoor Attacks Against BERT-based Models,"Weimin Lyu, Songzhu Zheng, Lu Pang, Haibin Ling, Chao Chen",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14480"" target=""_blank"">2310.14480</a>",,2025-12-03 22:39:25
MoPe: Model Perturbation-based Privacy Attacks on Language Models,"Marvin Li, Jason Wang, Jeffrey Wang, Seth Neel",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14369"" target=""_blank"">2310.14369</a>",,2025-12-03 22:39:25
Adversarial Image Generation by Spatial Transformation in Perceptual Colorspaces,"Ayberk Aydin, Alptekin Temizel",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13950"" target=""_blank"">2310.13950</a>","<a href=""https://github.com/ayberkydn/stadv-torch"" target=""_blank"">ayberkydn</a>",2025-12-03 22:39:25
Training Image Derivatives: Increased Accuracy and Universal Robustness,Vsevolod I. Avrutskiy,arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14045"" target=""_blank"">2310.14045</a>",,2025-12-03 22:39:25
ADoPT: LiDAR Spoofing Attack Detection Based on Point-Level Temporal Consistency,"Minkyoung Cho, Yulong Cao, Zixiang Zhou, Z. Morley Mao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14504"" target=""_blank"">2310.14504</a>",,2025-12-03 22:39:25
Detecting Shared Data Manipulation in Distributed Optimization Algorithms,"Mohannad Alkhraijah, Rachel Harris, Samuel Litchfield, David Huggins, Daniel K. Molzahn",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13252"" target=""_blank"">2310.13252</a>",,2025-12-03 22:39:25
CT-GAT: Cross-Task Generative Adversarial Attack based on Transferability,"Minxuan Lv, Chengwei Dai, Kun Li, Wei Zhou, Songlin Hu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14265"" target=""_blank"">2310.14265</a>",,2025-12-03 22:39:25
Diffusion-Based Adversarial Purification for Speaker Verification,"Yibo Bai, Xiao-Lei Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14270"" target=""_blank"">2310.14270</a>",,2025-12-03 22:39:25
Calibration of Time-Series Forecasting: Detecting and Adapting Context-Driven Distribution Shift,"Mouxiang Chen, Lefei Shen, Han Fu, Zhuo Li, Jianling Sun, Chenghao Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.14838"" target=""_blank"">2310.14838</a>",,2025-12-03 22:39:25
An LLM can Fool Itself: A Prompt-Based Adversarial Attack,"Xilie Xu, Keyi Kong, Ning Liu, Lizhen Cui, Di Wang, Jingfeng Zhang, Mohan Kankanhalli",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13345"" target=""_blank"">2310.13345</a>",,2025-12-03 22:39:25
Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models,"Shawn Shan, Wenxin Ding, Josephine Passananti, Haitao Zheng, Ben Y. Zhao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13828"" target=""_blank"">2310.13828</a>",,2025-12-03 22:39:25
The Hidden Adversarial Vulnerabilities of Medical Federated Learning,"Erfan Darzi, Florian Dubost, Nanna. M. Sijtsema, Ooijen P. M. A van",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13893"" target=""_blank"">2310.13893</a>",,2025-12-03 22:39:25
Beyond Hard Samples: Robust and Effective Grammatical Error Correction with Cycle Self-Augmenting,"Zecheng Tang, Kaifeng Qi, Juntao Li, Min Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13321"" target=""_blank"">2310.13321</a>","<a href=""https://github.com/ZetangForward/CSA-GEC"" target=""_blank"">ZetangForward</a>",2025-12-03 22:39:25
Learn from the Past: A Proxy based Adversarial Defense Framework to Boost Robustness,"Yaohua Liu, Jiaxin Gao, Zhu Liu, Xianghao Jiao, Xin Fan, Risheng Liu",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12713"" target=""_blank"">2310.12713</a>",,2025-12-03 22:39:25
Recoverable Privacy-Preserving Image Classification through Noise-like Adversarial Examples,"Jun Liu, Jiantao Zhou, Jinyu Tian, Weiwei Sun",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12707"" target=""_blank"">2310.12707</a>","<a href=""https://github.com/csjunjun/RIC"" target=""_blank"">csjunjun</a>",2025-12-03 22:39:25
To grok or not to grok: Disentangling generalization and memorization on corrupted algorithmic datasets,"Darshil Doshi, Aritra Das, Tianyu He, Andrey Gromov",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13061"" target=""_blank"">2310.13061</a>",,2025-12-03 22:39:25
SecurityNet: Assessing Machine Learning Vulnerabilities on Public Models,"Boyang Zhang, Zheng Li, Ziqing Yang, Xinlei He, Michael Backes, Mario Fritz, Yang Zhang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12665"" target=""_blank"">2310.12665</a>",,2025-12-03 22:39:25
Attack Prompt Generation for Red Teaming and Defending Large Language Models,"Boyi Deng, Wenjie Wang, Fuli Feng, Yang Deng, Qifan Wang, Xiangnan He",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12505"" target=""_blank"">2310.12505</a>","<a href=""https://github.com/Aatrox103/SAP"" target=""_blank"">Aatrox103</a>",2025-12-03 22:39:25
Prompt Injection Attacks and Defenses in LLM-Integrated Applications,"Yupei Liu, Yuqi Jia, Runpeng Geng, Jinyuan Jia, Neil Zhenqiang Gong",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12815"" target=""_blank"">2310.12815</a>","<a href=""https://github.com/liu00222/Open-Prompt-Injection"" target=""_blank"">liu00222</a>",2025-12-03 22:39:25
"PatchCURE: Improving Certifiable Robustness, Model Utility, and Computation Efficiency of Adversarial Patch Defenses","Chong Xiang, Tong Wu, Sihui Dai, Jonathan Petit, Suman Jana, Prateek Mittal",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13076"" target=""_blank"">2310.13076</a>",,2025-12-03 22:39:25
OODRobustBench: benchmarking and analyzing adversarial robustness under distribution shift,"Lin Li, Yifei Wang, Chawin Sitawarin, Michael Spratling",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12793"" target=""_blank"">2310.12793</a>",,2025-12-03 22:39:25
The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks,"Xiaoyi Chen, Siyuan Tang, Rui Zhu, Shijun Yan, Lei Jin, Zihao Wang, Liya Su, Zhikun Zhang, XiaoFeng Wang, Haixu Tang",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.15469"" target=""_blank"">2310.15469</a>",,2025-12-03 22:39:25
Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks,"Xiaodong Yu, Hao Cheng, Xiaodong Liu, Dan Roth, Jianfeng Gao",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12516"" target=""_blank"">2310.12516</a>",,2025-12-03 22:39:25
FLTracer: Accurate Poisoning Attack Provenance in Federated Learning,"Xinyu Zhang, Qingyu Liu, Zhongjie Ba, Yuan Hong, Tianhang Zheng, Feng Lin, Li Lu, Kui Ren",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13424"" target=""_blank"">2310.13424</a>","<a href=""https://github.com/Eyr3/FLTracer"" target=""_blank"">Eyr3</a>",2025-12-03 22:39:25
Generating Robust Adversarial Examples against Online Social Networks (OSNs),"Jun Liu, Jiantao Zhou, Haiwei Wu, Weiwei Sun, Jinyu Tian",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.12708"" target=""_blank"">2310.12708</a>","<a href=""https://github.com/csjunjun/RobustOSNAttack"" target=""_blank"">csjunjun</a>",2025-12-03 22:39:25
Data-Free Knowledge Distillation Using Adversarially Perturbed OpenGL Shader Images,"Logan Frank, Jim Davis",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13782"" target=""_blank"">2310.13782</a>",,2025-12-03 22:39:25
VOICE-ZEUS: Impersonating Zoom's E2EE-Protected Static Media and Textual Communications via Simple Voice Manipulations,"Mashari Alatawi, Nitesh Saxena",arXiv,2023-10,"<a href=""http://arxiv.org/abs/2310.13894"" target=""_blank"">2310.13894</a>",,2025-12-03 22:39:25
Outlier Robust Adversarial Training,"Shu Hu, Zhenhuan Yang, Xin Wang, Yiming Ying, Siwei Lyu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05145"" target=""_blank"">2309.05145</a>","<a href=""https://github.com/discovershu/ORAT"" target=""_blank"">discovershu</a>",2025-12-03 22:39:25
Divergences in Color Perception between Deep Neural Networks and Humans,"Ethan O. Nadler, Elise Darragh-Ford, Bhargav Srinivasa Desikan, Christian Conaway, Mark Chu, Tasker Hull, Douglas Guilbeault",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05809"" target=""_blank"">2309.05809</a>",,2025-12-03 22:39:25
DiffDefense: Defending against Adversarial Attacks via Diffusion Models,"Hondamunige Prasanna Silva, Lorenzo Seidenari, Bimbo Alberto Del",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03702"" target=""_blank"">2309.03702</a>","<a href=""https://github.com/HondamunigePrasannaSilva/DiffDefence"" target=""_blank"">HondamunigePrasannaSilva</a>",2025-12-03 22:39:25
Catch You Everything Everywhere: Guarding Textual Inversion via Concept Watermarking,"Weitao Feng, Jiyan He, Jie Zhang, Tianwei Zhang, Wenbo Zhou, Weiming Zhang, Nenghai Yu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05940"" target=""_blank"">2309.05940</a>",,2025-12-03 22:39:25
Counterfactual Explanations via Locally-guided Sequential Algorithmic Recourse,"Edward A. Small, Jeffrey N. Clark, Christopher J. McWilliams, Kacper Sokol, Jeffrey Chan, Flora D. Salim, Raul Santos-Rodriguez",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.04211"" target=""_blank"">2309.04211</a>",,2025-12-03 22:39:25
Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs,"Wenhua Cheng, Weiwei Zhang, Haihao Shen, Yiyang Cai, Xin He, Kaokao Lv",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05516"" target=""_blank"">2309.05516</a>","<a href=""https://github.com/intel/neural-compressor"" target=""_blank"">intel</a>",2025-12-03 22:39:25
Adversarial attacks on hybrid classical-quantum Deep Learning models for Histopathological Cancer Detection,"Biswaraj Baral, Reek Majumdar, Bhavika Bhalgamiya, Taposh Dutta Roy",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06377"" target=""_blank"">2309.06377</a>",,2025-12-03 22:39:25
ARRTOC: Adversarially Robust Real-Time Optimization and Control,"Akhil Ahmed, Rio-Chanona Ehecatl Antonio del, Mehmet Mercangoz",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.04386"" target=""_blank"">2309.04386</a>",,2025-12-03 22:39:25
DAD++: Improved Data-free Test Time Adversarial Defense,"Gaurav Kumar Nayak, Inder Khatri, Shubham Randive, Ruchit Rawal, Anirban Chakraborty",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05132"" target=""_blank"">2309.05132</a>","<a href=""https://github.com/vcl-iisc/Improved-Data-free-Test-Time-Adversarial-Defense"" target=""_blank"">vcl-iisc</a>",2025-12-03 22:39:25
Machine Translation Models Stand Strong in the Face of Adversarial Attacks,"Pavel Burnyshev, Elizaveta Kostenok, Alexey Zaytsev",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06527"" target=""_blank"">2309.06527</a>",,2025-12-03 22:39:25
Secure Set-Based State Estimation for Linear Systems under Adversarial Attacks on Sensors,"M. Umar B. Niazi, Michelle S. Chong, Amr Alanwar, Karl H. Johansson",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05075"" target=""_blank"">2309.05075</a>",,2025-12-03 22:39:25
Experimental Study of Adversarial Attacks on ML-based xApps in O-RAN,"Naveen Naik Sapavath, Brian Kim, Kaushik Chowdhury, Vijay K Shah",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03844"" target=""_blank"">2309.03844</a>",,2025-12-03 22:39:25
Towards Robust Model Watermark via Reducing Parametric Vulnerability,"Guanhao Gan, Yiming Li, Dongxian Wu, Shu-Tao Xia",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.04777"" target=""_blank"">2309.04777</a>","<a href=""https://github.com/GuanhaoGan/robust-model-watermarking"" target=""_blank"">GuanhaoGan</a>",2025-12-03 22:39:25
RecAD: Towards A Unified Library for Recommender Attack and Defense,"Changsheng Wang, Jianbai Ye, Wenjie Wang, Chongming Gao, Fuli Feng, Xiangnan He",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.04884"" target=""_blank"">2309.04884</a>","<a href=""https://github.com/gusye1234/recad"" target=""_blank"">gusye1234</a>",2025-12-03 22:39:25
Exploring Robust Features for Improving Adversarial Robustness,"Hong Wang, Yuefan Deng, Shinjae Yoo, Yuewei Lin",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.04650"" target=""_blank"">2309.04650</a>",,2025-12-03 22:39:25
How adversarial attacks can disrupt seemingly stable accurate classifiers,"Oliver J. Sutton, Qinghua Zhou, Ivan Y. Tyukin, Alexander N. Gorban, Alexander Bastounis, Desmond J. Higham",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03665"" target=""_blank"">2309.03665</a>",,2025-12-03 22:39:25
"Compiled Models, Built-In Exploits: Uncovering Pervasive Bit-Flip Attack Surfaces in DNN Executables","Yanzuo The Hong Kong University of Science and Technology Chen, Zhibo The Hong Kong University of Science and Technology Liu, Yuanyuan The Hong Kong University of Science and Technology Yuan, Sihang Huawei Technologies Hu, Tianxiang Huawei Technologies Li, Shuai The Hong Kong University of Science and Technology Wang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06223"" target=""_blank"">2309.06223</a>",,2025-12-03 22:39:25
Privacy Side Channels in Machine Learning Systems,"Edoardo Debenedetti, Giorgio Severi, Nicholas Carlini, Christopher A. Choquette-Choo, Matthew Jagielski, Milad Nasr, Eric Wallace, Florian Tramèr",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05610"" target=""_blank"">2309.05610</a>",,2025-12-03 22:39:25
Adversarial Attacks Assessment of Salient Object Detection via Symbolic Learning,"Gustavo Olague, Roberto Pineda, Gerardo Ibarra-Vazquez, Matthieu Olague, Axel Martinez, Sambit Bakshi, Jonathan Vargas, Isnardo Reducindo",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05900"" target=""_blank"">2309.05900</a>",,2025-12-03 22:39:25
Semantic Adversarial Attacks via Diffusion Models,"Chenan Wang, Jinhao Duan, Chaowei Xiao, Edward Kim, Matthew Stamm, Kaidi Xu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07398"" target=""_blank"">2309.07398</a>","<a href=""https://github.com/steven202/semantic_adv_via_dm"" target=""_blank"">steven202</a>",2025-12-03 22:39:25
Hardening RGB-D Object Recognition Systems against Adversarial Patch Attacks,"Yang Zheng, Luca Demetrio, Antonio Emanuele Cinà, Xiaoyi Feng, Zhaoqiang Xia, Xiaoyue Jiang, Ambra Demontis, Battista Biggio, Fabio Roli",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07106"" target=""_blank"">2309.07106</a>",,2025-12-03 22:39:25
Mitigating Adversarial Attacks in Federated Learning with Trusted Execution Environments,"Simon Queyrut, Valerio Schiavoni, Pascal Felber",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07197"" target=""_blank"">2309.07197</a>","<a href=""https://github.com/queyrusi/Pelta"" target=""_blank"">queyrusi</a>",2025-12-03 22:39:25
"PhantomSound: Black-Box, Query-Efficient Audio Adversarial Attack via Split-Second Phoneme Injection","Hanqing Guo, Guangjing Wang, Yuanda Wang, Bocheng Chen, Qiben Yan, Li Xiao",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06960"" target=""_blank"">2309.06960</a>",,2025-12-03 22:39:25
APICom: Automatic API Completion via Prompt Learning and Adversarial Training-based Data Augmentation,"Yafeng Gu, Yiheng Shen, Xiang Chen, Shaoyu Yang, Yiling Huang, Zhixiang Cao",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07026"" target=""_blank"">2309.07026</a>",,2025-12-03 22:39:25
RAIN: Your Language Models Can Align Themselves without Finetuning,"Yuhui Li, Fangyun Wei, Jinjing Zhao, Chao Zhang, Hongyang Zhang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07124"" target=""_blank"">2309.07124</a>",,2025-12-03 22:39:25
Differentiable JPEG: The Devil is in the Details,"Christoph Reich, Biplob Debnath, Deep Patel, Srimat Chakradhar",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06978"" target=""_blank"">2309.06978</a>","<a href=""https://github.com/necla-ml/Diff-JPEG"" target=""_blank"">necla-ml</a>",2025-12-03 22:39:25
"Deep Nonparametric Convexified Filtering for Computational Photography, Image Synthesis and Adversarial Defense",Jianqiao Wangni,arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06724"" target=""_blank"">2309.06724</a>",,2025-12-03 22:39:25
MASTERKEY: Practical Backdoor Attack Against Speaker Verification Systems,"Hanqing Guo, Xun Chen, Junfeng Guo, Li Xiao, Qiben Yan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06981"" target=""_blank"">2309.06981</a>",,2025-12-03 22:39:25
Client-side Gradient Inversion Against Federated Learning from Poisoning,"Jiaheng Wei, Yanjun Zhang, Leo Yu Zhang, Chao Chen, Shirui Pan, Kok-Leong Ong, Jun Zhang, Yang Xiang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07415"" target=""_blank"">2309.07415</a>",,2025-12-03 22:39:25
Safe Reinforcement Learning with Dual Robustness,"Zeyang Li, Chuxiong Hu, Yunan Wang, Yujie Yang, Shengbo Eben Li",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06835"" target=""_blank"">2309.06835</a>",,2025-12-03 22:39:25
Using Reed-Muller Codes for Classification with Rejection and Recovery,"Daniel University of Birmingham Fentham, David University of Oxford Parker, Mark University of Birmingham Ryan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06359"" target=""_blank"">2309.06359</a>",,2025-12-03 22:39:25
Certified Robust Models with Slack Control and Large Lipschitz Constants,"Max Losch, David Stutz, Bernt Schiele, Mario Fritz",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06166"" target=""_blank"">2309.06166</a>",,2025-12-03 22:39:25
Exploring Non-additive Randomness on ViT against Query-Based Black-Box Attacks,"Jindong Gu, Fangyun Wei, Philip Torr, Han Hu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06438"" target=""_blank"">2309.06438</a>",,2025-12-03 22:39:25
Promoting Fairness in GNNs: A Characterization of Stability,"Yaning Jia, Chunhui Zhang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03648"" target=""_blank"">2309.03648</a>",,2025-12-03 22:39:25
Backdoor Attacks and Countermeasures in Natural Language Processing Models: A Comprehensive Security Review,"Pengzhou Cheng, Zongru Wu, Wei Du, Gongshen Liu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.06055"" target=""_blank"">2309.06055</a>",,2025-12-03 22:39:25
CToMP: A Cycle-task-oriented Memory Protection Scheme for Unmanned Systems,"Chengyan Ma, Ning Xi, Di Lu, Yebo Feng, Jianfeng Ma",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05978"" target=""_blank"">2309.05978</a>",,2025-12-03 22:39:25
Language Models as Black-Box Optimizers for Vision-Language Models,"Shihong Liu, Zhiqiu Lin, Samuel Yu, Ryan Lee, Tiffany Ling, Deepak Pathak, Deva Ramanan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05950"" target=""_blank"">2309.05950</a>",,2025-12-03 22:39:25
Generalized Attacks on Face Verification Systems,"Ehsan Nazari, Paula Branco, Guy-Vincent Jourdan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.05879"" target=""_blank"">2309.05879</a>",,2025-12-03 22:39:25
One-to-Multiple Clean-Label Image Camouflage (OmClic) based Backdoor Attack on Deep Learning,"Guohong Wang, Hua Ma, Yansong Gao, Alsharif Abuadbba, Zhi Zhang, Wei Kang, Said F. Al-Sarawib, Gongxuan Zhang, Derek Abbott",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.04036"" target=""_blank"">2309.04036</a>",,2025-12-03 22:39:25
Robust Recommender System: A Survey and Future Directions,"Kaike Zhang, Qi Cao, Fei Sun, Yunfan Wu, Shuchang Tao, Huawei Shen, Xueqi Cheng",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02057"" target=""_blank"">2309.02057</a>",,2025-12-03 22:39:25
Certifying LLM Safety against Adversarial Prompting,"Aounon Kumar, Chirag Agarwal, Suraj Srinivas, Aaron Jiaxun Li, Soheil Feizi, Himabindu Lakkaraju",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02705"" target=""_blank"">2309.02705</a>","<a href=""https://github.com/aounon/certified-llm-safety"" target=""_blank"">aounon</a>",2025-12-03 22:39:25
Non-Asymptotic Bounds for Adversarial Excess Risk under Misspecified Models,"Changyu Liu, Yuling Jiao, Junhui Wang, Jian Huang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00771"" target=""_blank"">2309.00771</a>",,2025-12-03 22:39:25
Robust Adversarial Defense by Tensor Factorization,"Manish Bhattarai, Mehmet Cagri Kaymak, Ryan Barron, Ben Nebgen, Kim Rasmussen, Boian Alexandrov",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01077"" target=""_blank"">2309.01077</a>",,2025-12-03 22:39:25
CARNet: Collaborative Adversarial Resilience for Robust Underwater Image Enhancement and Perception,"Zengxi Zhang, Zeru Shi, Zhiying Jiang, Jinyuan Liu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01102"" target=""_blank"">2309.01102</a>",,2025-12-03 22:39:25
Towards Certified Probabilistic Robustness with High Accuracy,"Ruihan Zhang, Peixin Zhang, Jun Sun",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00879"" target=""_blank"">2309.00879</a>",,2025-12-03 22:39:25
Timbre-reserved Adversarial Attack in Speaker Identification,"Qing Wang, Jixun Yao, Li Zhang, Pengcheng Guo, Lei Xie",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00929"" target=""_blank"">2309.00929</a>",,2025-12-03 22:39:25
Regularly Truncated M-estimators for Learning with Noisy Labels,"Xiaobo Xia, Pengqian Lu, Chen Gong, Bo Han, Jun Yu, Jun Yu, Tongliang Liu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00894"" target=""_blank"">2309.00894</a>",,2025-12-03 22:39:25
Baseline Defenses for Adversarial Attacks Against Aligned Language Models,"Neel Jain, Avi Schwarzschild, Yuxin Wen, Gowthami Somepalli, John Kirchenbauer, Ping-yeh Chiang, Micah Goldblum, Aniruddha Saha, Jonas Geiping, Tom Goldstein",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00614"" target=""_blank"">2309.00614</a>",,2025-12-03 22:39:25
M3Dsynth: A dataset of medical 3D images with AI-generated local manipulations,"Giada Zingarini, Davide Cozzolino, Riccardo Corvi, Giovanni Poggi, Luisa Verdoliva",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07973"" target=""_blank"">2309.07973</a>","<a href=""https://grip-unina.github.io/M3Dsynth/"" target=""_blank"">M3Dsynth</a>",2025-12-03 22:39:25
Curating Naturally Adversarial Datasets for Trustworthy AI in Healthcare,"Sydney Pugh, Ivan Ruchkin, Insup Lee, James Weimer",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00543"" target=""_blank"">2309.00543</a>",,2025-12-03 22:39:25
Why do universal adversarial attacks work on large language models?: Geometry might be the answer,"Varshini Subhash, Anna Bialas, Weiwei Pan, Finale Doshi-Velez",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00254"" target=""_blank"">2309.00254</a>",,2025-12-03 22:39:25
Uncertainty in AI: Evaluating Deep Neural Networks on Out-of-Distribution Images,"Jamiu Idowu, Ahmed Almasoud",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01850"" target=""_blank"">2309.01850</a>",,2025-12-03 22:39:25
RenAIssance: A Survey into AI Text-to-Image Generation in the Era of Large Model,"Fengxiang Bie, Yibo Yang, Zhongzhu Zhou, Adam Ghanem, Minjia Zhang, Zhewei Yao, Xiaoxia Wu, Connor Holmes, Pareesa Golnari, David A. Clifton, Yuxiong He, Dacheng Tao, Shuaiwen Leon Song",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00810"" target=""_blank"">2309.00810</a>",,2025-12-03 22:39:25
Learned Visual Features to Textual Explanations,"Saeid Asgari Taghanaki, Aliasghar Khani, Amir Khasahmadi, Aditya Sanghi, Karl D. D. Willis, Ali Mahdavi-Amiri",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00733"" target=""_blank"">2309.00733</a>",,2025-12-03 22:39:25
Image Hijacking: Adversarial Images can Control Generative Models at Runtime,"Luke Bailey, Euan Ong, Stuart Russell, Scott Emmons",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00236"" target=""_blank"">2309.00236</a>",,2025-12-03 22:39:25
FTA: Stealthy and Robust Backdoor Attack with Flexible Trigger on Federated Learning,"Yanqi Qiao, Congwen Chen, Rui Wang, Kaitai Liang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00127"" target=""_blank"">2309.00127</a>",,2025-12-03 22:39:25
Explainable and Trustworthy Traffic Sign Detection for Safe Autonomous Driving: An Inductive Logic Programming Approach,"Zahra University of Surrey Chaghazardi, Saber University of Surrey Fallah, Alireza University of Surrey Tamaddoni-Nezhad",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03215"" target=""_blank"">2309.03215</a>",,2025-12-03 22:39:25
AIR: Threats of Adversarial Attacks on Deep Learning-Based Information Recovery,"Jinyin Chen, Jie Ge, Shilian Zheng, Linhui Ye, Haibin Zheng, Weiguo Shen, Keqiang Yue, Xiaoniu Yang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16706"" target=""_blank"">2309.16706</a>",,2025-12-03 22:39:25
General Lipschitz: Certified Robustness Against Resolvable Semantic Transformations via Transformation-Dependent Randomized Smoothing,"Dmitrii Korzh, Mikhail Pautov, Olga Tsymboi, Ivan Oseledets",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16710"" target=""_blank"">2309.16710</a>",,2025-12-03 22:39:25
When Measures are Unreliable: Imperceptible Adversarial Perturbations toward Top-$k$ Multi-Label Learning,"Yuchen Sun, Qianqian Xu, Zitai Wang, Qingming Huang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.00007"" target=""_blank"">2309.00007</a>",,2025-12-03 22:39:25
AdvMono3D: Advanced Monocular 3D Object Detection with Depth-Aware Robust Adversarial Training,"Xingyuan Li, Jinyuan Liu, Long Ma, Xin Fan, Risheng Liu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01106"" target=""_blank"">2309.01106</a>",,2025-12-03 22:39:25
Dropout Attacks,"Andrew Yuan, Alina Oprea, Cheng Tan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01614"" target=""_blank"">2309.01614</a>",,2025-12-03 22:39:25
SWAP: Exploiting Second-Ranked Logits for Adversarial Attacks on Time Series,"Chang George Dong, Liangwei Nathan Zheng, Weitong Chen, Wei Emma Zhang, Lin Yue",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02752"" target=""_blank"">2309.02752</a>",,2025-12-03 22:39:25
Building a Winning Team: Selecting Source Model Ensembles using a Submodular Transferability Estimation Approach,"Vimal K B, Saketh Bachu, Tanmay Garg, Niveditha Lakshmi Narasimhan, Raghavan Konuru, Vineeth N Balasubramanian",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02429"" target=""_blank"">2309.02429</a>",,2025-12-03 22:39:25
Byzantine-Robust Federated Learning with Variance Reduction and Differential Privacy,"Zikai Zhang, Rui Hu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03437"" target=""_blank"">2309.03437</a>",,2025-12-03 22:39:25
J-Guard: Journalism Guided Adversarially Robust Detection of AI-generated News,"Tharindu Kumarage, Amrita Bhattacharjee, Djordje Padejski, Kristy Roschke, Dan Gillmor, Scott Ruston, Huan Liu, Joshua Garland",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03164"" target=""_blank"">2309.03164</a>",,2025-12-03 22:39:25
MIRA: Cracking Black-box Watermarking on Deep Neural Networks via Model Inversion-based Removal Attacks,"Yifan Lu, Wenxuan Li, Mi Zhang, Xudong Pan, Min Yang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03466"" target=""_blank"">2309.03466</a>",,2025-12-03 22:39:25
My Art My Choice: Adversarial Protection Against Unruly AI,"Anthony Rhodes, Ram Bhagat, Umur Aybars Ciftci, Ilke Demir",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03198"" target=""_blank"">2309.03198</a>",,2025-12-03 22:39:25
A Theoretical Explanation of Activation Sparsity through Flat Minima and Adversarial Robustness,"Ze Peng, Lei Qi, Yinghuan Shi, Yang Gao",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.03004"" target=""_blank"">2309.03004</a>",,2025-12-03 22:39:25
The Adversarial Implications of Variable-Time Inference,"Dudi Biton, Aditi Misra, Efrat Levy, Jaidip Kotak, Ron Bitton, Roei Schuster, Nicolas Papernot, Yuval Elovici, Ben Nassi",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02159"" target=""_blank"">2309.02159</a>",,2025-12-03 22:39:25
Adaptive Adversarial Training Does Not Increase Recourse Costs,"Ian Hardy, Jayanth Yetukuri, Yang Liu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02528"" target=""_blank"">2309.02528</a>",,2025-12-03 22:39:25
Black-Box Attacks against Signed Graph Analysis via Balance Poisoning,"Jialong Zhou, Yuni Lai, Jian Ren, Kai Zhou",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02396"" target=""_blank"">2309.02396</a>",,2025-12-03 22:39:25
Dual Adversarial Alignment for Realistic Support-Query Shift Few-shot Learning,"Siyang Jiang, Rui Fang, Hsi-Wen Chen, Wei Ding, Ming-Syan Chen",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.02088"" target=""_blank"">2309.02088</a>",,2025-12-03 22:39:25
Safe and Robust Watermark Injection with a Single OoD Image,"Shuyang Yu, Junyuan Hong, Haobo Zhang, Haotao Wang, Zhangyang Wang, Jiayu Zhou",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01786"" target=""_blank"">2309.01786</a>",,2025-12-03 22:39:25
Hindering Adversarial Attacks with Multiple Encrypted Patch Embeddings,"AprilPyone MaungMaung, Isao Echizen, Hitoshi Kiya",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01620"" target=""_blank"">2309.01620</a>",,2025-12-03 22:39:25
Improving Visual Quality and Transferability of Adversarial Attacks on Face Recognition Simultaneously with Adversarial Restoration,"Fengfan Zhou, Hefei Ling, Yuxuan Shi, Jiazhong Chen, Ping Li",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01582"" target=""_blank"">2309.01582</a>",,2025-12-03 22:39:25
Adv3D: Generating 3D Adversarial Examples in Driving Scenarios with NeRF,"Leheng Li, Qing Lian, Ying-Cong Chen",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01351"" target=""_blank"">2309.01351</a>","<a href=""https://len-li.github.io/adv3d-web"" target=""_blank"">len-li.github.io</a>",2025-12-03 22:39:25
Toward Defensive Letter Design,"Rentaro Kataoka, Akisato Kimura, Seiichi Uchida",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01452"" target=""_blank"">2309.01452</a>",,2025-12-03 22:39:25
MathAttack: Attacking Large Language Models Towards Math Solving Ability,"Zihao Zhou, Qiufeng Wang, Mingyu Jin, Jie Yao, Jianan Ye, Wei Liu, Wei Wang, Xiaowei Huang, Kaizhu Huang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01686"" target=""_blank"">2309.01686</a>",,2025-12-03 22:39:25
Efficient Defense Against Model Stealing Attacks on Convolutional Neural Networks,"Kacem Khaled, Mouna Dhaouadi, Magalhães Felipe Gohring de, Gabriela Nicolescu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01838"" target=""_blank"">2309.01838</a>",,2025-12-03 22:39:25
Efficient Query-Based Attack against ML-Based Android Malware Detection under Zero Knowledge Setting,"Ping He, Yifan Xia, Xuhong Zhang, Shouling Ji",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01866"" target=""_blank"">2309.01866</a>",,2025-12-03 22:39:25
EventTrojan: Manipulating Non-Intrusive Speech Quality Assessment via Imperceptible Events,"Ying Ren, Kailai Shen, Zhe Ye, Diqun Yan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01480"" target=""_blank"">2309.01480</a>",,2025-12-03 22:39:25
Turn Fake into Real: Adversarial Head Turn Attacks Against Deepfake Detection,"Weijie Wang, Zhengyu Zhao, Nicu Sebe, Bruno Lepri",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.01104"" target=""_blank"">2309.01104</a>","<a href=""https://github.com/twowwj/AdvHeaT"" target=""_blank"">twowwj</a>",2025-12-03 22:39:25
Random and Safe Cache Architecture to Defeat Cache Timing Attacks,"Guangyuan Hu, Ruby B. Lee",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16172"" target=""_blank"">2309.16172</a>",,2025-12-03 22:39:25
Physical Invisible Backdoor Based on Camera Imaging,"Yusheng Guo, Nan Zhong, Zhenxing Qian, Xinpeng Zhang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07428"" target=""_blank"">2309.07428</a>",,2025-12-03 22:39:25
Structure Invariant Transformation for better Adversarial Transferability,"Xiaosen Wang, Zeliang Zhang, Jianping Zhang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.14700"" target=""_blank"">2309.14700</a>","<a href=""https://github.com/xiaosen-wang/SIT"" target=""_blank"">xiaosen-wang</a>",2025-12-03 22:39:25
Neural Stochastic Differential Equations for Robust and Explainable Analysis of Electromagnetic Unintended Radiated Emissions,"Sumit Kumar Jha, Susmit Jha, Rickard Ewetz, Alvaro Velasquez",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15386"" target=""_blank"">2309.15386</a>",,2025-12-03 22:39:25
Collaborative Watermarking for Adversarial Speech Synthesis,"Lauri Aalto University, Finland Juvela, Xin National Institute of Informatics, Japan Wang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15224"" target=""_blank"">2309.15224</a>",,2025-12-03 22:39:25
DifAttack: Query-Efficient Black-Box Attack via Disentangled Feature Space,"Liu Jun, Zhou Jiantao, Zeng Jiandian, Jinyu Tian",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.14585"" target=""_blank"">2309.14585</a>","<a href=""https://github.com/csjunjun/DifAttack"" target=""_blank"">csjunjun</a>",2025-12-03 22:39:25
Gray-box Adversarial Attack of Deep Reinforcement Learning-based Trading Agents,"Foozhan Ataiefard, Hadi Hemmati",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.14615"" target=""_blank"">2309.14615</a>",,2025-12-03 22:39:25
SurrogatePrompt: Bypassing the Safety Filter of Text-To-Image Models via Substitution,"Zhongjie Ba, Jieming Zhong, Jiachen Lei, Peng Cheng, Qinglong Wang, Zhan Qin, Zhibo Wang, Kui Ren",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.14122"" target=""_blank"">2309.14122</a>",,2025-12-03 22:39:25
Adversarial Attacks on Video Object Segmentation with Hard Region Discovery,"Ping Li, Yu Zhang, Li Yuan, Jian Zhao, Xianghua Xu, Xiaoqin Zhang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13857"" target=""_blank"">2309.13857</a>",,2025-12-03 22:39:25
Vulnerabilities in Video Quality Assessment Models: The Challenge of Adversarial Attacks,"Ao-Xiang Zhang, Yu Ran, Weixuan Tang, Yuan-Gen Wang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13609"" target=""_blank"">2309.13609</a>","<a href=""https://github.com/GZHU-DVL/AttackVQA"" target=""_blank"">GZHU-DVL</a>",2025-12-03 22:39:25
On the Effectiveness of Adversarial Samples against Ensemble Learning-based Windows PE Malware Detectors,"Trong-Nghia To, Danh Le Kim, Do Thi Thu Hien, Nghi Hoang Khoa, Hien Do Hoang, Phan The Duy, Van-Hau Pham",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13841"" target=""_blank"">2309.13841</a>",,2025-12-03 22:39:25
Projected Randomized Smoothing for Certified Adversarial Robustness,"Samuel Pfrommer, Brendon G. Anderson, Somayeh Sojoudi",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13794"" target=""_blank"">2309.13794</a>",,2025-12-03 22:39:25
Combining Two Adversarial Attacks Against Person Re-Identification Systems,"Eduardo de O. Andrade, Igor Garcia Ballhausen Sampaio, Joris Guérin, José Viterbo",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13763"" target=""_blank"">2309.13763</a>",,2025-12-03 22:39:25
Seeing Is Not Always Believing: Invisible Collision Attack and Defence on Pre-Trained Models,"Minghang Deng, Zhong Zhang, Junming Shao",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13579"" target=""_blank"">2309.13579</a>",,2025-12-03 22:39:25
Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks,"Zhaohan Xi, Tianyu Du, Changjiang Li, Ren Pang, Shouling Ji, Jinghui Chen, Fenglong Ma, Ting Wang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13256"" target=""_blank"">2309.13256</a>",,2025-12-03 22:39:25
Moving Target Defense based Secured Network Slicing System in the O-RAN Architecture,"Mojdeh Karbalaee Motalleb, Chafika Benzaïd, Tarik Taleb, Vahid Shah-Mansouri",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13444"" target=""_blank"">2309.13444</a>",,2025-12-03 22:39:25
Detecting and Mitigating System-Level Anomalies of Vision-Based Controllers,"Aryaman Gupta, Kaustav Chakraborty, Somil Bansal",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13475"" target=""_blank"">2309.13475</a>",,2025-12-03 22:39:25
RBFormer: Improve Adversarial Robustness of Transformer by Robust Bias,"Hao Cheng, Jinhao Duan, Hui Li, Lyutianyang Zhang, Jiahang Cao, Ping Wang, Jize Zhang, Kaidi Xu, Renjing Xu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13245"" target=""_blank"">2309.13245</a>",,2025-12-03 22:39:25
"Spatial-frequency channels, shape bias, and adversarial robustness","Ajay Subramanian, Elena Sizikova, Najib J. Majaj, Denis G. Pelli",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13190"" target=""_blank"">2309.13190</a>",,2025-12-03 22:39:25
VIC-KD: Variance-Invariance-Covariance Knowledge Distillation to Make Keyword Spotting More Robust Against Adversarial Attacks,"Heitor R. Guimarães, Arthur Pimentel, Anderson Avila, Tiago H. Falk",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.12914"" target=""_blank"">2309.12914</a>",,2025-12-03 22:39:25
Understanding Deep Gradient Leakage via Inversion Influence Functions,"Haobo Zhang, Junyuan Hong, Yuyang Deng, Mehrdad Mahdavi, Jiayu Zhou",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13016"" target=""_blank"">2309.13016</a>","<a href=""https://github.com/illidanlab/inversion-influence-function"" target=""_blank"">illidanlab</a>",2025-12-03 22:39:25
Pixel-wise Smoothing for Certified Robustness against Camera Motion Perturbations,"Hanjiang Hu, Zuxin Liu, Linyi Li, Jiacheng Zhu, Ding Zhao",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13150"" target=""_blank"">2309.13150</a>",,2025-12-03 22:39:25
Privacy-preserving and Privacy-attacking Approaches for Speech and Audio -- A Survey,"Yuchen Liu, Apu Kapadia, Donald Williamson",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15087"" target=""_blank"">2309.15087</a>",,2025-12-03 22:39:25
Breaking On-Chip Communication Anonymity using Flow Correlation Attacks,"Hansika Weerasena, Prabhat Mishra",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15687"" target=""_blank"">2309.15687</a>",,2025-12-03 22:39:25
Expressive variational quantum circuits provide inherent privacy in federated learning,"Niraj Kumar, Jamie Heredge, Changhao Li, Shaltiel Eloul, Shree Hari Sureshbabu, Marco Pistoia",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13002"" target=""_blank"">2309.13002</a>",,2025-12-03 22:39:25
Generating Transferable Adversarial Simulation Scenarios for Self-Driving via Neural Rendering,"Yasasa Abeysirigoonawardena, Kevin Xie, Chuhan Chen, Salar Hosseini, Ruiting Chen, Ruiqi Wang, Florian Shkurti",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15770"" target=""_blank"">2309.15770</a>",,2025-12-03 22:39:25
On Continuity of Robust and Accurate Classifiers,"Ramin Barati, Reza Safabakhsh, Mohammad Rahmati",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.17048"" target=""_blank"">2309.17048</a>",,2025-12-03 22:39:25
Adversarial Machine Learning in Latent Representations of Neural Networks,"Milin Zhang, Mohammad Abdi, Francesco Restuccia",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.17401"" target=""_blank"">2309.17401</a>",,2025-12-03 22:39:25
Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks,"Vaidehi Patil, Peter Hase, Mohit Bansal",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.17410"" target=""_blank"">2309.17410</a>",,2025-12-03 22:39:25
Toward Robust Recommendation via Real-time Vicinal Defense,"Yichang Xu, Chenwang Wu, Defu Lian",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.17278"" target=""_blank"">2309.17278</a>",,2025-12-03 22:39:25
Investigating Human-Identifiable Features Hidden in Adversarial Perturbations,"Dennis Y. Menn, Tzu-hsun Feng, Sriram Vishwanath, Hung-yi Lee",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16878"" target=""_blank"">2309.16878</a>",,2025-12-03 22:39:25
What Matters to Enhance Traffic Rule Compliance of Imitation Learning for Automated Driving,"Hongkuan Zhou, Aifen Sui, Wei Cao, Zhenshan Bing",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07808"" target=""_blank"">2309.07808</a>","<a href=""https://hk-zh.github.io/p-csg-plus"" target=""_blank"">hk-zh.github.io</a>",2025-12-03 22:39:25
Parameter-Saving Adversarial Training: Reinforcing Multi-Perturbation Robustness via Hypernetworks,"Huihui Gong, Minjing Dong, Siqi Ma, Seyit Camtepe, Surya Nepal, Chang Xu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16207"" target=""_blank"">2309.16207</a>",,2025-12-03 22:39:25
Efficient Biologically Plausible Adversarial Training,"Matilde Tristany Farinha, Thomas Ortner, Giorgia Dellaferrera, Benjamin Grewe, Angeliki Pantazi",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.17348"" target=""_blank"">2309.17348</a>",,2025-12-03 22:39:25
Towards Poisoning Fair Representations,"Tianci Liu, Haoyu Wang, Feijie Wu, Hengtong Zhang, Pan Li, Lu Su, Jing Gao",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16487"" target=""_blank"">2309.16487</a>",,2025-12-03 22:39:25
On the Trade-offs between Adversarial Robustness and Actionable Explanations,"Satyapriya Krishna, Chirag Agarwal, Himabindu Lakkaraju",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16452"" target=""_blank"">2309.16452</a>",,2025-12-03 22:39:25
The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing,"Blaise Delattre, Alexandre Araujo, Quentin Barthélemy, Alexandre Allauzen",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16883"" target=""_blank"">2309.16883</a>",,2025-12-03 22:39:25
Post-Training Overfitting Mitigation in DNN Classifiers,"Hang Wang, David J. Miller, George Kesidis",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16827"" target=""_blank"">2309.16827</a>",,2025-12-03 22:39:25
Leveraging Optimization for Adaptive Attacks on Image Watermarks,"Nils Lukas, Abdulrahman Diaa, Lucas Fenaux, Florian Kerschbaum",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16952"" target=""_blank"">2309.16952</a>",,2025-12-03 22:39:25
Robust Offline Reinforcement Learning -- Certify the Confidence Interval,"Jiarui Yao, Simon Shaolei Du",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16631"" target=""_blank"">2309.16631</a>",,2025-12-03 22:39:25
A Primer on Bayesian Neural Networks: Review and Debates,"Julyan Arbel, Konstantinos Pitas, Mariia Vladimirova, Vincent Fortuin",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16314"" target=""_blank"">2309.16314</a>",,2025-12-03 22:39:25
On the Computational Entanglement of Distant Features in Adversarial Machine Learning,"YenLung Lai, Xingbo Dong, Zhe Jin",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15669"" target=""_blank"">2309.15669</a>",,2025-12-03 22:39:25
Adversarial Examples Might be Avoidable: The Role of Data Concentration in Adversarial Robustness,"Ambar Pal, Jeremias Sulam, René Vidal",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16096"" target=""_blank"">2309.16096</a>",,2025-12-03 22:39:25
Defending Against Physical Adversarial Patch Attacks on Infrared Human Detection,"Lukas Strack, Futa Waseda, Huy H. Nguyen, Yinqiang Zheng, Isao Echizen",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15519"" target=""_blank"">2309.15519</a>",,2025-12-03 22:39:25
Automatic Feature Fairness in Recommendation via Adversaries,"Hengchang Hu, Yiming Cao, Zhankui He, Samson Tan, Min-Yen Kan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.15418"" target=""_blank"">2309.15418</a>",,2025-12-03 22:39:25
Privacy Assessment on Reconstructed Images: Are Existing Evaluation Metrics Faithful to Human Perception? (5%),"Xiaoxiao Sun, Nidham Gazagnadou, Vivek Sharma, Lingjuan Lyu, Hongdong Li, Liang Zheng",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.13038"" target=""_blank"">2309.13038</a>",,2025-12-03 22:39:25
Distributed Resilient Control of DC Microgrids Under Generally Unbounded FDI Attacks,"Yichao Wang, Mohamadamin Rajabinezhad, Omar A. Beg, Shan Zuo",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.17301"" target=""_blank"">2309.17301</a>",,2025-12-03 22:39:25
On Data Fabrication in Collaborative Vehicular Perception: Attacks and Countermeasures,"Qingzhao Zhang, Shuowei Jin, Ruiyang Zhu, Jiachen Sun, Xumiao Zhang, Qi Alfred Chen, Z. Morley Mao",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.12955"" target=""_blank"">2309.12955</a>",,2025-12-03 22:39:25
Stealthy Physical Masked Face Recognition Attack via Adversarial Style Optimization,"Huihui Gong, Minjing Dong, Siqi Ma, Seyit Camtepe, Surya Nepal, Chang Xu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.09480"" target=""_blank"">2309.09480</a>",,2025-12-03 22:39:25
Efficient Low-Rank GNN Defense Against Structural Attacks,"Abdullah Alchihabi, Qing En, Yuhong Guo",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10136"" target=""_blank"">2309.10136</a>",,2025-12-03 22:39:25
Evaluating Adversarial Robustness with Expected Viable Performance,"Ryan McCoppin, Colin Dawson, Sean M. Kennedy, Leslie M. Blaha",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.09928"" target=""_blank"">2309.09928</a>",,2025-12-03 22:39:25
Dual Student Networks for Data-Free Model Stealing,"James Beetham, Navid Kardan, Ajmal Mian, Mubarak Shah",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10058"" target=""_blank"">2309.10058</a>",,2025-12-03 22:39:25
Securing Fixed Neural Network Steganography,"Zicong Luo, Sheng Li, Guobiao Li, Zhenxing Qian, Xinpeng Zhang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.09700"" target=""_blank"">2309.09700</a>",,2025-12-03 22:39:25
GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts,"Jiahao Yu, Xingwei Lin, Zheng Yu, Xinyu Xing",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10253"" target=""_blank"">2309.10253</a>",,2025-12-03 22:39:25
Spoofing attack augmentation: can differently-trained attack models improve generalisation? (3%),"Wanying Ge, Xin Wang, Junichi Yamagishi, Massimiliano Todisco, Nicholas Evans",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.09586"" target=""_blank"">2309.09586</a>",,2025-12-03 22:39:25
Reducing Adversarial Training Cost with Gradient Approximation,"Huihui Gong, Shuo Yang, Siqi Ma, Seyit Camtepe, Surya Nepal, Chang Xu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.09464"" target=""_blank"">2309.09464</a>",,2025-12-03 22:39:25
Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM,"Bochuan Cao, Yuanpu Cao, Lu Lin, Jinghui Chen",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.14348"" target=""_blank"">2309.14348</a>",,2025-12-03 22:39:25
Context-aware Adversarial Attack on Named Entity Recognition,"Shuguang Chen, Leonardo Neves, Thamar Solorio",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08999"" target=""_blank"">2309.08999</a>",,2025-12-03 22:39:25
Inverse classification with logistic and softmax classifiers: efficient optimization,"Miguel Á. Carreira-Perpiñán, Suryabhan Singh Hada",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08945"" target=""_blank"">2309.08945</a>",,2025-12-03 22:39:25
Robust Backdoor Attacks on Object Detection in Real World,"Yaguan Qian, Boyuan Ji, Shuke He, Shenhui Huang, Xiang Ling, Bin Wang, Wei Wang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08953"" target=""_blank"">2309.08953</a>",,2025-12-03 22:39:25
Conditional Mutual Information Constrained Deep Learning for Classification,"En-Hui Yang, Shayan Mohajer Hamidi, Linfeng Ye, Renhao Tan, Beverly Yang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.09123"" target=""_blank"">2309.09123</a>",,2025-12-03 22:39:25
Adversarial Attacks on Tables with Entity Swap,"Aneta Koleva, Martin Ringsquandl, Volker Tresp",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08650"" target=""_blank"">2309.08650</a>",,2025-12-03 22:39:25
HINT: Healthy Influential-Noise based Training to Defend against Data Poisoning Attacks,"Minh-Hao Van, Alycia N. Carey, Xintao Wu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08549"" target=""_blank"">2309.08549</a>",,2025-12-03 22:39:25
SLMIA-SR: Speaker-Level Membership Inference Attacks against Speaker Recognition Systems,"Guangke Chen, Yedi Zhang, Fu Song",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.07983"" target=""_blank"">2309.07983</a>",,2025-12-03 22:39:25
Distributionally Robust Post-hoc Classifiers under Prior Shifts,"Jiaheng Wei, Harikrishna Narasimhan, Ehsan Amid, Wen-Sheng Chu, Yang Liu, Abhishek Kumar",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08825"" target=""_blank"">2309.08825</a>","<a href=""https://github.com/weijiaheng/Drops"" target=""_blank"">weijiaheng</a>",2025-12-03 22:39:25
Unleashing the Adversarial Facet of Software Debloating,"Do-Men Su, Mohannad Alhanahnah",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08058"" target=""_blank"">2309.08058</a>",,2025-12-03 22:39:25
"A Duty to Forget, a Right to be Assured? Exposing Vulnerabilities in Machine Unlearning Services","Hongsheng Hu, Shuo Wang, Jiamin Chang, Haonan Zhong, Ruoxi Sun, Shuang Hao, Haojin Zhu, Minhui Xue",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.08230"" target=""_blank"">2309.08230</a>",,2025-12-03 22:39:25
Improving Machine Learning Robustness via Adversarial Training,"Long Dang, Thushari Hapuarachchi, Kaiqi Xiong, Jing Lin",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.12593"" target=""_blank"">2309.12593</a>",,2025-12-03 22:39:25
Transferable Adversarial Attack on Image Tampering Localization,"Yuqi Wang, Gang Cao, Zijie Lou, Haochen Zhu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10243"" target=""_blank"">2309.10243</a>",,2025-12-03 22:39:25
Frame-to-Utterance Convergence: A Spectra-Temporal Approach for Unified Spoofing Detection,"Awais Khan, Khalid Mahmood Malik, Shah Nawaz",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.09837"" target=""_blank"">2309.09837</a>",,2025-12-03 22:39:25
It's Simplex! Disaggregating Measures to Improve Certified Robustness,"Andrew C. Cullen, Paul Montague, Shijie Liu, Sarah M. Erfani, Benjamin I. P. Rubinstein",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11005"" target=""_blank"">2309.11005</a>",,2025-12-03 22:39:25
Compilation as a Defense: Enhancing DL Model Attack Robustness via Tensor Optimization,"Stefan Trawicki, William Hackett, Lewis Birch, Neeraj Suri, Peter Garraghan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.16577"" target=""_blank"">2309.16577</a>",,2025-12-03 22:39:25
On the Relationship between Skill Neurons and Robustness in Prompt Tuning,"Leon Ackermann, Xenia Ohmer",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.12263"" target=""_blank"">2309.12263</a>",,2025-12-03 22:39:25
How Robust is Google's Bard to Adversarial Image Attacks? (99%),"Yinpeng Dong, Huanran Chen, Jiawei Chen, Zhengwei Fang, Xiao Yang, Yichi Zhang, Yu Tian, Hang Su, Jun Zhu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11751"" target=""_blank"">2309.11751</a>","<a href=""https://github.com/thu-ml/Attack-Bard"" target=""_blank"">thu-ml</a>",2025-12-03 22:39:25
SPFL: A Self-purified Federated Learning Method Against Poisoning Attacks,"Zizhen Liu, Weiyang He, Chip-Hong Chang, Jing Ye, Huawei Li, Xiaowei Li",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10607"" target=""_blank"">2309.10607</a>",,2025-12-03 22:39:25
"HANS, are you clever? Clever Hans Effect Analysis of Neural Systems","Leonardo Ranaldi, Fabio Massimo Zanzotto",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.12481"" target=""_blank"">2309.12481</a>",,2025-12-03 22:39:25
PRAT: PRofiling Adversarial aTtacks,"Rahul Ambati, Naveed Akhtar, Ajmal Mian, Yogesh Singh Rawat",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11111"" target=""_blank"">2309.11111</a>",,2025-12-03 22:39:25
When to Trust AI: Advances and Challenges for Certification of Neural Networks,"Marta Kwiatkowska, Xiyue Zhang",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11196"" target=""_blank"">2309.11196</a>",,2025-12-03 22:39:25
Understanding Pose and Appearance Disentanglement in 3D Human Pose Estimation,"Krishna Kanth Nakka, Mathieu Salzmann",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11667"" target=""_blank"">2309.11667</a>",,2025-12-03 22:39:25
Fed-LSAE: Thwarting Poisoning Attacks against Federated Cyber Threat Detection System via Autoencoder-based Latent Space Inspection,"Tran Duc Luong, Vuong Minh Tien, Nguyen Huu Quyen, Do Thi Thu Hien, Phan The Duy, Van-Hau Pham",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11053"" target=""_blank"">2309.11053</a>",,2025-12-03 22:39:25
"AudioFool: Fast, Universal and synchronization-free Cross-Domain Attack on Speech Recognition","Mohamad Fakih, Rouwaida Kanj, Fadi Kurdahi, Mohammed E. Fouda",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11462"" target=""_blank"">2309.11462</a>",,2025-12-03 22:39:25
Generalized Face Forgery Detection via Adaptive Learning for Pre-trained Vision Transformer,"Anwei Luo, Rizhao Cai, Chenqi Kong, Yakun Ju, Xiangui Kang, Jiwu Huang, Alex C. Kot",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11092"" target=""_blank"">2309.11092</a>","<a href=""https://github.com/LoveSiameseCat/FAViT"" target=""_blank"">LoveSiameseCat</a>",2025-12-03 22:39:25
Language Guided Adversarial Purification,"Himanshu Singh, A V Subramanyam",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10348"" target=""_blank"">2309.10348</a>",,2025-12-03 22:39:25
Goal-Oriented Prompt Attack and Safety Evaluation for LLMs,"Chengyuan Liu, Fubang Zhao, Lizhi Qing, Yangyang Kang, Changlong Sun, Kun Kuang, Fei Wu",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11830"" target=""_blank"">2309.11830</a>","<a href=""https://github.com/liuchengyuan123/CPAD"" target=""_blank"">liuchengyuan123</a>",2025-12-03 22:39:25
What Learned Representations and Influence Functions Can Tell Us About Adversarial Examples,"Shakila Mahjabin Tonni, Mark Dras",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10916"" target=""_blank"">2309.10916</a>",,2025-12-03 22:39:25
Adversarial Attacks Against Uncertainty Quantification,"Emanuele Ledda, Daniele Angioni, Giorgio Piras, Giorgio Fumera, Battista Biggio, Fabio Roli",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10586"" target=""_blank"">2309.10586</a>",,2025-12-03 22:39:25
Model Leeching: An Extraction Attack Targeting LLMs,"Lewis Birch, William Hackett, Stefan Trawicki, Neeraj Suri, Peter Garraghan",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10544"" target=""_blank"">2309.10544</a>",,2025-12-03 22:39:25
Information Leakage from Data Updates in Machine Learning Models,"Tian Hui, Farhad Farokhi, Olga Ohrimenko",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11022"" target=""_blank"">2309.11022</a>",,2025-12-03 22:39:25
Robin: A Novel Method to Produce Robust Interpreters for Deep Learning-Based Code Classifiers,"Zhen Li, Ruqian Zhang, Deqing Zou, Ning Wang, Yating Li, Shouhuai Xu, Chen Chen, Hai Jin",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.10644"" target=""_blank"">2309.10644</a>",,2025-12-03 22:39:25
DeepTheft: Stealing DNN Model Architectures through Power Side Channel,"Yansong Gao, Huming Qiu, Zhi Zhang, Binghui Wang, Hua Ma, Alsharif Abuadbba, Minhui Xue, Anmin Fu, Surya Nepal",arXiv,2023-09,"<a href=""http://arxiv.org/abs/2309.11894"" target=""_blank"">2309.11894</a>",,2025-12-03 22:39:25
Adversarial Deep Reinforcement Learning for Cyber Security in Software Defined Networks,"Luke Borchjes, Clement Nyirenda, Louise Leenen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04909"" target=""_blank"">2308.04909</a>",,2025-12-03 22:39:25
Complex Network Effects on the Robustness of Graph Convolutional Networks,"Benjamin A. Miller, Kevin Chan, Tina Eliassi-Rad",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05498"" target=""_blank"">2308.05498</a>",,2025-12-03 22:39:25
"Critical Points ++: An Agile Point Cloud Importance Measure for Robust Classification, Adversarial Defense and Explainable AI","Meir Yossef Levi, Guy Gilboa",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05525"" target=""_blank"">2308.05525</a>",,2025-12-03 22:39:25
FLShield: A Validation Based Federated Learning Framework to Defend Against Poisoning Attacks,"Ehsanul Kabir, Zeyu Song, Md Rafi Ur Rashid, Shagufta Mehnaz",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05832"" target=""_blank"">2308.05832</a>",,2025-12-03 22:39:25
Comprehensive Analysis of Network Robustness Evaluation Based on Convolutional Neural Networks with Spatial Pyramid Pooling,"Wenjun Jiang, Tianlong Fan, Changhao Li, Chuanfu Zhang, Tao Zhang, Zong-fu Luo",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08012"" target=""_blank"">2308.08012</a>",,2025-12-03 22:39:25
Adv-Inpainting: Generating Natural and Transferable Adversarial Patch via Attention-guided Feature Fusion,"Yanjie Li, Mingxing Duan, Bin Xiao",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05320"" target=""_blank"">2308.05320</a>",,2025-12-03 22:39:25
Adversarial ModSecurity: Countering Adversarial SQL Injections with Robust Machine Learning,"Biagio Montaruli, Luca Demetrio, Andrea Valenza, Battista Biggio, Luca Compagna, Davide Balzarotti, Davide Ariu, Luca Piras",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04964"" target=""_blank"">2308.04964</a>",,2025-12-03 22:39:25
XGBD: Explanation-Guided Graph Backdoor Detection,"Zihan Guan, Mengnan Du, Ninghao Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04406"" target=""_blank"">2308.04406</a>","<a href=""https://github.com/GuanZihan/GNN_backdoor_detection"" target=""_blank"">GuanZihan</a>",2025-12-03 22:39:25
Data-Free Model Extraction Attacks in the Context of Object Detection,"Harshit Shah, Aravindhan G, Pavan Kulkarni, Yuvaraj Govidarajulu, Manojkumar Parmar",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05127"" target=""_blank"">2308.05127</a>",,2025-12-03 22:39:25
Pelta: Shielding Transformers to Mitigate Evasion Attacks in Federated Learning,"Simon Queyrut, Yérom-David Bromberg, Valerio Schiavoni",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04373"" target=""_blank"">2308.04373</a>",,2025-12-03 22:39:25
Federated Zeroth-Order Optimization using Trajectory-Informed Surrogate Gradients,"Yao Shu, Xiaoqiang Lin, Zhongxiang Dai, Bryan Kian Hsiang Low",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04077"" target=""_blank"">2308.04077</a>",,2025-12-03 22:39:25
The Model Inversion Eavesdropping Attack in Semantic Communication Systems,"Yuhao Chen, Qianqian Yang, Zhiguo Shi, Jiming Chen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04304"" target=""_blank"">2308.04304</a>",,2025-12-03 22:39:25
A Comprehensive Assessment Benchmark for Rigorously Evaluating Deep Learning Image Classifiers,Michael W. Spratling,arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04137"" target=""_blank"">2308.04137</a>",,2025-12-03 22:39:25
Improved Activation Clipping for Universal Backdoor Mitigation and Test-Time Detection,"Hang Wang, Zhen Xiang, David J. Miller, George Kesidis",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04617"" target=""_blank"">2308.04617</a>",,2025-12-03 22:39:25
Evil Operation: Breaking Speaker Recognition with PaddingBack,"Zhe Ye, Diqun Yan, Li Dong, Kailai Shen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04179"" target=""_blank"">2308.04179</a>","<a href=""https://nbufabio25.github.io/paddingback/"" target=""_blank"">paddingback</a>",2025-12-03 22:39:25
Backdoor Federated Learning by Poisoning Backdoor-Critical Layers,"Haomin Zhuang, Mingxian Yu, Hao Wang, Yang Hua, Jian Li, Xu Yuan",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04466"" target=""_blank"">2308.04466</a>",,2025-12-03 22:39:25
Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient,"Zhengzhi Lu, He Wang, Ziyi Chang, Guoan Yang, Hubert P. H. Shum",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05681"" target=""_blank"">2308.05681</a>",,2025-12-03 22:39:25
Symmetry Defense Against XGBoost Adversarial Perturbation Attacks,Blerta Lindqvist,arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05575"" target=""_blank"">2308.05575</a>",,2025-12-03 22:39:25
"LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked","Alec Helbling, Mansi Phute, Matthew Hull, Duen Horng Chau",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07308"" target=""_blank"">2308.07308</a>",,2025-12-03 22:39:25
Fast and Accurate Transferability Measurement by Evaluating Intra-class Feature Variance,"Huiwen Xu, U Kang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05986"" target=""_blank"">2308.05986</a>",,2025-12-03 22:39:25
Continual Face Forgery Detection via Historical Distribution Preserving,"Ke Sun, Shen Chen, Taiping Yao, Xiaoshuai Sun, Shouhong Ding, Rongrong Ji",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06217"" target=""_blank"">2308.06217</a>",,2025-12-03 22:39:25
White-Box Adversarial Attacks on Deep Learning-Based Radio Frequency Fingerprint Identification,"Jie Ma, Junqing Zhang, Guanxiong Shen, Alan Marshall, Chip-Hong Chang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07433"" target=""_blank"">2308.07433</a>",,2025-12-03 22:39:25
AdvCLIP: Downstream-agnostic Adversarial Examples in Multimodal Contrastive Learning,"Ziqi Zhou, Shengshan Hu, Minghui Li, Hangtao Zhang, Yechao Zhang, Hai Jin",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07026"" target=""_blank"">2308.07026</a>",,2025-12-03 22:39:25
Enhancing the Antidote: Improved Pointwise Certifications against Poisoning Attacks,"Shijie Liu, Andrew C. Cullen, Paul Montague, Sarah M. Erfani, Benjamin I. P. Rubinstein",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07553"" target=""_blank"">2308.07553</a>",,2025-12-03 22:39:25
Exploring the Physical World Adversarial Robustness of Vehicle Detection,"Wei Jiang, Tianyuan Zhang, Shuangcheng Liu, Weiyu Ji, Zichao Zhang, Gang Xiao",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03476"" target=""_blank"">2308.03476</a>",,2025-12-03 22:39:25
DISBELIEVE: Distance Between Client Models is Very Essential for Effective Local Model Poisoning Attacks,"Indu Joshi, Priyank Upadhya, Gaurav Kumar Nayak, Peter Schüffler, Nassir Navab",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07387"" target=""_blank"">2308.07387</a>",,2025-12-03 22:39:25
ACTIVE: Towards Highly Transferable 3D Physical Camouflage for Universal and Robust Vehicle Evasion,"Naufal Suryanto, Yongsu Kim, Harashta Tatimma Larasati, Hyoeun Kang, Thi-Thu-Huong Le, Yoonyoung Hong, Hunmin Yang, Se-Yoon Oh, Howon Kim",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07009"" target=""_blank"">2308.07009</a>",,2025-12-03 22:39:25
"SAM Meets Robotic Surgery: An Empirical Study on Generalization, Robustness and Adaptation","An Wang, Mobarakol Islam, Mengya Xu, Yang Zhang, Hongliang Ren",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07156"" target=""_blank"">2308.07156</a>",,2025-12-03 22:39:25
SoK: Realistic Adversarial Attacks and Defenses for Intelligent Network Intrusion Detection,"João Vitorino, Isabel Praça, Eva Maia",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06819"" target=""_blank"">2308.06819</a>",,2025-12-03 22:39:25
Understanding the robustness difference between stochastic gradient descent and adaptive gradient methods,"Avery Ma, Yangchen Pan, Amir-massoud Farahmand",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06703"" target=""_blank"">2308.06703</a>",,2025-12-03 22:39:25
"A Survey on Deep Neural Network Pruning-Taxonomy, Comparison, Analysis, and Recommendations","Hongrong Cheng, Miao Zhang, Javen Qinfeng Shi",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06767"" target=""_blank"">2308.06767</a>","<a href=""https://github.com/hrcheng1066/awesome-pruning"" target=""_blank"">hrcheng1066</a>",2025-12-03 22:39:25
Robustified ANNs Reveal Wormholes Between Human Category Percepts,"Guy Gaziv, Michael J. Lee, James J. DiCarlo",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06887"" target=""_blank"">2308.06887</a>",,2025-12-03 22:39:25
Faithful to Whom? Questioning Interpretability Measures in NLP,"Evan Crothers, Herna Viktor, Nathalie Japkowicz",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06795"" target=""_blank"">2308.06795</a>",,2025-12-03 22:39:25
Not So Robust After All: Evaluating the Robustness of Deep Neural Networks to Unseen Adversarial Attacks,"Roman Garaev, Bader Rasheed, Adil Khan",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06467"" target=""_blank"">2308.06467</a>",,2025-12-03 22:39:25
One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training,"Jianshuo Dong, Han Qiu, Yiming Li, Tianwei Zhang, Yuanjie Li, Zeqi Lai, Chao Zhang, Shu-Tao Xia",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07934"" target=""_blank"">2308.07934</a>","<a href=""https://github.com/jianshuod/TBA"" target=""_blank"">jianshuod</a>",2025-12-03 22:39:25
Enhancing Generalization of Universal Adversarial Perturbation through Gradient Aggregation,"Xuannan Liu, Yaoyao Zhong, Yuhang Zhang, Lixiong Qin, Weihong Deng",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06015"" target=""_blank"">2308.06015</a>","<a href=""https://github.com/liuxuannan/Stochastic-Gradient-Aggregation"" target=""_blank"">liuxuannan</a>",2025-12-03 22:39:25
"Physical Adversarial Attacks For Camera-based Smart Systems: Current Trends, Categorization, Applications, Research Challenges, and Future Outlook","Amira Guesmi, Muhammad Abdullah Hanif, Bassem Ouni, Muhammed Shafique",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06173"" target=""_blank"">2308.06173</a>",,2025-12-03 22:39:25
Face Encryption via Frequency-Restricted Identity-Agnostic Attacks,"Xin Dong, Rui Wang, Siyuan Liang, Aishan Liu, Lihua Jing",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.05983"" target=""_blank"">2308.05983</a>","<a href=""https://github.com/XinDong10/FRIA"" target=""_blank"">XinDong10</a>",2025-12-03 22:39:25
White-box Membership Inference Attacks against Diffusion Models,"Yan Pang, Tianhao Wang, Xuhui Kang, Mengdi Huai, Yang Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06405"" target=""_blank"">2308.06405</a>",,2025-12-03 22:39:25
Test-Time Backdoor Defense via Detecting and Repairing,"Jiyang Guan, Jian Liang, Ran He",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.06107"" target=""_blank"">2308.06107</a>",,2025-12-03 22:39:25
Fixed Inter-Neuron Covariability Induces Adversarial Robustness,"Muhammad Ahmed Shah, Bhiksha Raj",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03956"" target=""_blank"">2308.03956</a>",,2025-12-03 22:39:25
Universal Defensive Underpainting Patch: Making Your Text Invisible to Optical Character Recognition,"JiaCheng Deng, Li Dong, Jiahao Chen, Diqun Yan, Rangding Wang, Dengpan Ye, Lingchen Zhao, Jinyu Tian",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02369"" target=""_blank"">2308.02369</a>","<a href=""https://github.com/QRICKDD/UDUP"" target=""_blank"">QRICKDD</a>",2025-12-03 22:39:25
PAIF: Perception-Aware Infrared-Visible Image Fusion for Attack-Tolerant Semantic Segmentation,"Zhu Liu, Jinyuan Liu, Benzhuang Zhang, Long Ma, Xin Fan, Risheng Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03979"" target=""_blank"">2308.03979</a>","<a href=""https://github.com/LiuZhu-CV/PAIF"" target=""_blank"">LiuZhu-CV</a>",2025-12-03 22:39:25
A reading survey on adversarial machine learning: Adversarial attacks and their understanding,Shashank Kotyan,arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03363"" target=""_blank"">2308.03363</a>",,2025-12-03 22:39:25
From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application? (4%),"Rodrigo Pedro, Daniel Castro, Paulo Carreira, Nuno Santos",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01990"" target=""_blank"">2308.01990</a>",,2025-12-03 22:39:25
Inaudible Adversarial Perturbation: Manipulating the Recognition of User Speech in Real Time,"Xinfeng Li, Chen Yan, Xuancun Lu, Zihan Zeng, Xiaoyu Ji, Wenyuan Xu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01040"" target=""_blank"">2308.01040</a>",,2025-12-03 22:39:25
Isolation and Induction: Training Robust Deep Neural Networks against Model Stealing Attacks,"Jun Guo, Aishan Liu, Xingyu Zheng, Siyuan Liang, Yisong Xiao, Yichao Wu, Xianglong Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00958"" target=""_blank"">2308.00958</a>","<a href=""https://github.com/DIG-Beihang/InI-Model-Stealing-Defense"" target=""_blank"">DIG-Beihang</a>",2025-12-03 22:39:25
Mercury: An Automated Remote Side-channel Attack to Nvidia Deep Learning Accelerator,"Xiaobei Yan, Xiaoxuan Lou, Guowen Xu, Han Qiu, Shangwei Guo, Chip Hong Chang, Tianwei Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01193"" target=""_blank"">2308.01193</a>",,2025-12-03 22:39:25
TEASMA: A Practical Approach for the Test Assessment of Deep Neural Networks using Mutation Analysis,"Amin Abbasishahkoo, Mahboubeh Dadkhah, Lionel Briand, Dayi Lin",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01311"" target=""_blank"">2308.01311</a>",,2025-12-03 22:39:25
LSF-IDM: Automotive Intrusion Detection Model with Lightweight Attribution and Semantic Fusion,"Pengzhou Cheng, Lei Hua, Haobin Jiang, Mohammad Samie, Gongshen Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01237"" target=""_blank"">2308.01237</a>",,2025-12-03 22:39:25
Dynamic ensemble selection based on Deep Neural Network Uncertainty Estimation for Adversarial Robustness,"Ruoxi Qin, Linyuan Wang, Xuehui Du, Xingyuan Chen, Bin Yan",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00346"" target=""_blank"">2308.00346</a>",,2025-12-03 22:39:25
Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning,"Kaijie Zhu, Jindong Wang, Xixu Hu, Xing Xie, Ge Yang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02533"" target=""_blank"">2308.02533</a>","<a href=""https://github.com/microsoft/robustlearn"" target=""_blank"">microsoft</a>",2025-12-03 22:39:25
LimeAttack: Local Explainable Method for Textual Hard-Label Adversarial Attack,"Hai Zhu, Zhaoqing Yang, Weiwei Shang, Yuren Wu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00319"" target=""_blank"">2308.00319</a>",,2025-12-03 22:39:25
Doubly Robust Instance-Reweighted Adversarial Training,"Daouda Sow, Sen Lin, Zhangyang Wang, Yingbin Liang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00311"" target=""_blank"">2308.00311</a>",,2025-12-03 22:39:25
Training on Foveated Images Improves Robustness to Adversarial Attacks,"Muhammad A. Shah, Bhiksha Raj",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00854"" target=""_blank"">2308.00854</a>",,2025-12-03 22:39:25
Kidnapping Deep Learning-based Multirotors using Optimized Flying Adversarial Patches,"Pia Hanfeld, Khaled Wahba, Marina M. -C. Höhne, Michael Bussmann, Wolfgang Hönig",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00344"" target=""_blank"">2308.00344</a>",,2025-12-03 22:39:25
Robust Linear Regression: Phase-Transitions and Precise Tradeoffs for General Norms,"Elvis Dohmatob, Meyer Scetbon",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00556"" target=""_blank"">2308.00556</a>",,2025-12-03 22:39:25
Learning to Generate Training Datasets for Robust Semantic Segmentation,"Marwane Hariat, Olivier Laurent, Rémi Kazmierczak, Shihao Zhang, Andrei Bursuc, Angela Yao, Gianni Franchi",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02535"" target=""_blank"">2308.02535</a>","<a href=""https://github.com/ENSTA-U2IS-AI/robusta"" target=""_blank"">ENSTA-U2IS-AI</a>",2025-12-03 22:39:25
Zero-Shot Learning by Harnessing Adversarial Samples,"Zhi Chen, Pengfei Zhang, Jingjing Li, Sen Wang, Zi Huang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00313"" target=""_blank"">2308.00313</a>","<a href=""https://github.com/uqzhichen/HASZSL"" target=""_blank"">uqzhichen</a>",2025-12-03 22:39:25
A Novel Cross-Perturbation for Single Domain Generalization,"Dongjia Zhao, Lei Qi, Xiao Shi, Yinghuan Shi, Xin Geng",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00918"" target=""_blank"">2308.00918</a>",,2025-12-03 22:39:25
Robustness Over Time: Understanding Adversarial Examples' Effectiveness on Longitudinal Versions of Large Language Models,"Yugeng Liu, Tianshuo Cong, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07847"" target=""_blank"">2308.07847</a>",,2025-12-03 22:39:25
A Novel Deep Learning based Model to Defend Network Intrusion Detection System against Adversarial Attacks,"Khushnaseeb Roshan, Aasim Zafar, Shiekh Burhan Ul Haque",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00077"" target=""_blank"">2308.00077</a>",,2025-12-03 22:39:25
Adversarially Robust Neural Legal Judgement Systems,"Rohit Raj, V Susheela Devi",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.00165"" target=""_blank"">2308.00165</a>",,2025-12-03 22:39:25
ParaFuzz: An Interpretability-Driven Technique for Detecting Poisoned Samples in NLP,"Lu Yan, Zhuo Zhang, Guanhong Tao, Kaiyuan Zhang, Xuan Chen, Guangyu Shen, Xiangyu Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02122"" target=""_blank"">2308.02122</a>",,2025-12-03 22:39:25
FROD: Robust Object Detection for Free,"Muhammad, Awais, Weiming, Zhuang, Lingjuan, Lyu, Sung-Ho, Bae",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01888"" target=""_blank"">2308.01888</a>",,2025-12-03 22:39:25
AdvFAS: A robust face anti-spoofing framework against adversarial examples,"Jiawei Chen, Xiao Yang, Heng Yin, Mingzhi Ma, Bihui Chen, Jianteng Peng, Yandong Guo, Zhaoxia Yin, Hang Su",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02116"" target=""_blank"">2308.02116</a>",,2025-12-03 22:39:25
An Adaptive Model Ensemble Adversarial Attack for Boosting Adversarial Transferability,"Bin Chen, Jia-Li Yin, Shukai Chen, Bo-Hao Chen, Ximeng Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02897"" target=""_blank"">2308.02897</a>",,2025-12-03 22:39:25
A Four-Pronged Defense Against Byzantine Attacks in Federated Learning,"Wei Wan, Shengshan Hu, Minghui Li, Jianrong Lu, Longling Zhang, Leo Yu Zhang, Hai Jin",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03331"" target=""_blank"">2308.03331</a>",,2025-12-03 22:39:25
Improving Performance of Semi-Supervised Learning by Adversarial Attacks,"Dongyoon Yang, Kunwoong Kim, Yongdai Kim",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04018"" target=""_blank"">2308.04018</a>",,2025-12-03 22:39:25
Mondrian: Prompt Abstraction Attack Against Large Language Models for Cheaper API Pricing,"Wai Man Si, Michael Backes, Yang Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03558"" target=""_blank"">2308.03558</a>",,2025-12-03 22:39:25
SAAM: Stealthy Adversarial Attack on Monoculor Depth Estimation,"Amira Guesmi, Muhammad Abdullah Hanif, Bassem Ouni, Muhammad Shafique",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03108"" target=""_blank"">2308.03108</a>",,2025-12-03 22:39:25
CGBA: Curvature-aware Geometric Black-box Attack,"Md Farhamdur Reza, Ali Rahmati, Tianfu Wu, Huaiyu Dai",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03163"" target=""_blank"">2308.03163</a>","<a href=""https://github.com/Farhamdur/CGBA"" target=""_blank"">Farhamdur</a>",2025-12-03 22:39:25
APBench: A Unified Benchmark for Availability Poisoning Attacks and Defenses,"Tianrui Qin, Xitong Gao, Juanjuan Zhao, Kejiang Ye, Cheng-Zhong Xu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03258"" target=""_blank"">2308.03258</a>","<a href=""https://github.com/lafeat/apbench"" target=""_blank"">lafeat</a>",2025-12-03 22:39:25
Unsupervised Adversarial Detection without Extra Model: Training Loss Should Change,"Chien Cheng Chyou, Hung-Ting Su, Winston H. Hsu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03243"" target=""_blank"">2308.03243</a>",,2025-12-03 22:39:25
Using Overlapping Methods to Counter Adversaries in Community Detection,"Benjamin A. Miller, Kevin Chan, Tina Eliassi-Rad",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03081"" target=""_blank"">2308.03081</a>",,2025-12-03 22:39:25
An AI-Enabled Framework to Defend Ingenious MDT-based Attacks on the Emerging Zero Touch Cellular Networks,"Aneeqa Ijaz, Waseem Raza, Hasan Farooq, Marvin Manalastas, Ali Imran",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02923"" target=""_blank"">2308.02923</a>",,2025-12-03 22:39:25
URET: Universal Robustness Evaluation Toolkit (for Evasion),"Kevin Eykholt, Taesung Lee, Douglas Schales, Jiyong Jang, Ian Molloy, Masha Zorin",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01840"" target=""_blank"">2308.01840</a>",,2025-12-03 22:39:25
A Security and Usability Analysis of Local Attacks Against FIDO2,"Tarun Kumar Yadav, Kent Seamons",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02973"" target=""_blank"">2308.02973</a>",,2025-12-03 22:39:25
Approximating Positive Homogeneous Functions with Scale Invariant Neural Networks,"Stefan Bamberger, Reinhard Heckel, Felix Krahmer",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02836"" target=""_blank"">2308.02836</a>",,2025-12-03 22:39:25
Multi-attacks: Many images $+$ the same adversarial attack $\to$ many target labels,Stanislav Fort,arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.03792"" target=""_blank"">2308.03792</a>",,2025-12-03 22:39:25
RobustMQ: Benchmarking Robustness of Quantized Models,"Yisong Xiao, Aishan Liu, Tianyuan Zhang, Haotong Qin, Jinyang Guo, Xianglong Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02350"" target=""_blank"">2308.02350</a>",,2025-12-03 22:39:25
SureFED: Robust Federated Learning via Uncertainty-Aware Inward and Outward Inspection,"Nasimeh Heydaribeni, Ruisi Zhang, Tara Javidi, Cristina Nita-Rotaru, Farinaz Koushanfar",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02747"" target=""_blank"">2308.02747</a>",,2025-12-03 22:39:25
Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning Attacks,"Domenico Cotroneo, Cristina Improta, Pietro Liguori, Roberto Natella",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.04451"" target=""_blank"">2308.04451</a>",,2025-12-03 22:39:25
BlindSage: Label Inference Attacks against Node-level Vertical Federated Graph Neural Networks,"Marco Arazzi, Mauro Conti, Stefanos Koffas, Marina Krcek, Antonino Nocera, Stjepan Picek, Jing Xu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.02465"" target=""_blank"">2308.02465</a>",,2025-12-03 22:39:25
Hard Adversarial Example Mining for Improving Robust Fairness,"Chenhao Lin, Xiang Ji, Yulong Yang, Qian Li, Chao Shen, Run Wang, Liming Fang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.01823"" target=""_blank"">2308.01823</a>",,2025-12-03 22:39:25
3DHacker: Spectrum-based Decision Boundary Generation for Hard-label 3D Point Cloud Attack,"Yunbo Tao, Daizong Liu, Pan Zhou, Yulai Xie, Wei Du, Wei Hu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07546"" target=""_blank"">2308.07546</a>",,2025-12-03 22:39:25
Simple and Efficient Partial Graph Adversarial Attack: A New Perspective,"Guanghui Zhu, Mengyu Chen, Chunfeng Yuan, Yihua Huang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07834"" target=""_blank"">2308.07834</a>",,2025-12-03 22:39:25
FaceChain: A Playground for Human-centric Artificial Intelligence Generated Content,"Yang Liu, Cheng Yu, Lei Shang, Yongyi He, Ziheng Wu, Xingjun Wang, Chao Xu, Haoyu Xie, Weida Wang, Yuze Zhao, Lin Zhu, Chen Cheng, Weitao Chen, Yuan Yao, Wenmeng Zhou, Jiaqi Xu, Qiang Wang, Yingda Chen, Xuansong Xie, Baigui Sun",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14256"" target=""_blank"">2308.14256</a>","<a href=""https://github.com/modelscope/facechain"" target=""_blank"">modelscope</a>",2025-12-03 22:39:25
Designing an attack-defense game: how to increase robustness of financial transaction models via a competition,"Alexey Zaytsev, Maria Kovaleva, Alex Natekin, Evgeni Vorsin, Valerii Smirnov, Georgii Smirnov, Oleg Sidorshin, Alexander Senin, Alexander Dudin, Dmitry Berestnev",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11406"" target=""_blank"">2308.11406</a>",,2025-12-03 22:39:25
Are Existing Out-Of-Distribution Techniques Suitable for Network Intrusion Detection? (1%),"Andrea Corsini, Shanchieh Jay Yang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14376"" target=""_blank"">2308.14376</a>",,2025-12-03 22:39:25
Detecting Language Model Attacks with Perplexity,"Gabriel Alon, Michael Kamfonas",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14132"" target=""_blank"">2308.14132</a>",,2025-12-03 22:39:25
Exploring Transferability of Multimodal Adversarial Samples for Vision-Language Pre-training Models with Contrastive Learning,"Youze Wang, Wenbo Hu, Yinpeng Dong, Hanwang Zhang, Hang Su, Richang Hong",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12636"" target=""_blank"">2308.12636</a>",,2025-12-03 22:39:25
Don't Look into the Sun: Adversarial Solarization Attacks on Image Classifiers,"Paul Gavrikov, Janis Keuper",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12661"" target=""_blank"">2308.12661</a>","<a href=""https://github.com/paulgavrikov/adversarial_solarization"" target=""_blank"">paulgavrikov</a>",2025-12-03 22:39:25
Evaluating the Vulnerabilities in ML systems in terms of adversarial attacks,"John Harshith, Mantej Singh Gill, Madhan Jothimani",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12918"" target=""_blank"">2308.12918</a>",,2025-12-03 22:39:25
Fast Adversarial Training with Smooth Convergence,"Mengnan Zhao, Lihe Zhang, Yuqiu Kong, Baocai Yin",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12857"" target=""_blank"">2308.12857</a>","<a href=""https://github.com/FAT-CS/ConvergeSmooth"" target=""_blank"">FAT-CS</a>",2025-12-03 22:39:25
WavMark: Watermarking for Audio Generation,"Guangyu Chen, Yu Wu, Shujie Liu, Tao Liu, Xiaoyong Du, Furu Wei",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12770"" target=""_blank"">2308.12770</a>",,2025-12-03 22:39:25
Prediction without Preclusion: Recourse Verification with Reachable Sets,"Avni Kothari, Bogdan Kulynych, Tsui-Wei Weng, Berk Ustun",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12820"" target=""_blank"">2308.12820</a>",,2025-12-03 22:39:25
On-Manifold Projected Gradient Descent,"Aaron Mahler, Tyrus Berry, Tom Stephens, Harbir Antil, Michael Merritt, Jeanie Schreiber, Ioannis Kevrekidis",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12279"" target=""_blank"">2308.12279</a>",,2025-12-03 22:39:25
Sample Complexity of Robust Learning against Evasion Attacks,Pascale Gourdeau,arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12054"" target=""_blank"">2308.12054</a>",,2025-12-03 22:39:25
LCANets++: Robust Audio Classification using Multi-layer Neural Networks with Lateral Competition,"Sayanton V. Dibbo, Juston S. Moore, Garrett T. Kenyon, Michael A. Teti",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12882"" target=""_blank"">2308.12882</a>",,2025-12-03 22:39:25
BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection,"Tinghao Xie, Xiangyu Qi, Ping He, Yiming Li, Jiachen T. Wang, Prateek Mittal",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12439"" target=""_blank"">2308.12439</a>",,2025-12-03 22:39:25
Ensembling Uncertainty Measures to Improve Safety of Black-Box Classifiers,"Tommaso Zoppi, Andrea Ceccarelli, Andrea Bondavalli",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12065"" target=""_blank"">2308.12065</a>",,2025-12-03 22:39:25
Aparecium: Revealing Secrets from Physical Photographs,"Zhe Lei, Jie Zhang, Jingtao Li, Weiming Zhang, Nenghai Yu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12141"" target=""_blank"">2308.12141</a>",,2025-12-03 22:39:25
Multi-Instance Adversarial Attack on GNN-Based Malicious Domain Detection,"Mahmoud Nazzal, Issa Khalil, Abdallah Khreishah, NhatHai Phan, Yao Ma",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11754"" target=""_blank"">2308.11754</a>",,2025-12-03 22:39:25
SEA: Shareable and Explainable Attribution for Query-based Black-box Attacks,"Yue Gao, Ilia Shumailov, Kassem Fawaz",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11845"" target=""_blank"">2308.11845</a>",,2025-12-03 22:39:25
Does Physical Adversarial Example Really Matter to Autonomous Driving? Towards System-Level Effect of Adversarial Object Evasion Attack,"Ningfei Wang, Yunpeng Luo, Takami Sato, Kaidi Xu, Qi Alfred Chen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11894"" target=""_blank"">2308.11894</a>",,2025-12-03 22:39:25
Protect Federated Learning Against Backdoor Attacks via Data-Free Trigger Generation,"Yanxin Yang, Ming Hu, Yue Cao, Jun Xia, Yihao Huang, Yang Liu, Mingsong Chen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11333"" target=""_blank"">2308.11333</a>",,2025-12-03 22:39:25
Revisiting and Exploring Efficient Fast Adversarial Training via LAW: Lipschitz Regularization and Auto Weight Averaging,"Xiaojun Jia, Yuefeng Chen, Xiaofeng Mao, Ranjie Duan, Jindong Gu, Rong Zhang, Hui Xue, Xiaochun Cao",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11443"" target=""_blank"">2308.11443</a>",,2025-12-03 22:39:25
Rep2wav: Noise Robust text-to-speech Using self-supervised representations,"Qiushi Zhu, Yu Gu, Rilin Chen, Chao Weng, Yuchen Hu, Lirong Dai, Jie Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14553"" target=""_blank"">2308.14553</a>","<a href=""https://zqs01.github.io/rep2wav"" target=""_blank"">zqs01.github.io</a>",2025-12-03 22:39:25
ReMAV: Reward Modeling of Autonomous Vehicles for Finding Likely Failure Events,"Aizaz Sharif, Dusica Marijan",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14550"" target=""_blank"">2308.14550</a>",,2025-12-03 22:39:25
Identifying and Mitigating the Security Risks of Generative AI,"Clark Barrett, Brad Boyd, Elie Burzstein, Nicholas Carlini, Brad Chen, Jihye Choi, Amrita Roy Chowdhury, Mihai Christodorescu, Anupam Datta, Soheil Feizi, Kathleen Fisher, Tatsunori Hashimoto, Dan Hendrycks, Somesh Jha, Daniel Kang, Florian Kerschbaum, Eric Mitchell, John Mitchell, Zulfikar Ramzan, Khawaja Shams, Dawn Song, Ankur Taly, Diyi Yang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14840"" target=""_blank"">2308.14840</a>",,2025-12-03 22:39:25
Imperceptible Adversarial Attack on Deep Neural Networks from Image Boundary,"Fahad Alrasheedi, Xin Zhong",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15344"" target=""_blank"">2308.15344</a>",,2025-12-03 22:39:25
Adversarial Finetuning with Latent Representation Constraint to Mitigate Accuracy-Robustness Tradeoff,"Satoshi Suzuki, Shin'ya Yamaguchi, Shoichiro Takeda, Sekitoshi Kanai, Naoki Makishima, Atsushi Ando, Ryo Masumura",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.16454"" target=""_blank"">2308.16454</a>",,2025-12-03 22:39:25
The Power of MEME: Adversarial Malware Creation with Model-Based Reinforcement Learning,"Maria Rigaki, Sebastian Garcia",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.16562"" target=""_blank"">2308.16562</a>",,2025-12-03 22:39:25
A Review of Adversarial Attacks in Computer Vision,"Yutong Zhang, Yao Li, Yin Li, Zhichang Guo",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07673"" target=""_blank"">2308.07673</a>",,2025-12-03 22:39:25
Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack,"Sze Jue Yang, Quang Nguyen, Chee Seng Chan, Khoa D. Doan",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.16684"" target=""_blank"">2308.16684</a>",,2025-12-03 22:39:25
Fault Injection and Safe-Error Attack for Extraction of Embedded Neural Network Models,"Kevin Hector, Pierre-Alain Moellic, Mathieu Dumont, Jean-Max Dutertre",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.16703"" target=""_blank"">2308.16703</a>",,2025-12-03 22:39:25
Robust Principles: Architectural Design Principles for Adversarially Robust CNNs,"ShengYun Peng, Weilin Xu, Cory Cornelius, Matthew Hull, Kevin Li, Rahul Duggal, Mansi Phute, Jason Martin, Duen Horng Chau",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.16258"" target=""_blank"">2308.16258</a>","<a href=""https://github.com/poloclub/robust-principles"" target=""_blank"">poloclub</a>",2025-12-03 22:39:25
Adaptive Attack Detection in Text Classification: Leveraging Space Exploration Features for Text Sentiment Classification,"Atefeh Mahdavi, Neda Keivandarian, Marco Carvalho",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15663"" target=""_blank"">2308.15663</a>",,2025-12-03 22:39:25
Advancing Adversarial Robustness Through Adversarial Logit Update,"Hao Xuan, Peican Zhu, Xingyu Li",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15072"" target=""_blank"">2308.15072</a>",,2025-12-03 22:39:25
A Classification-Guided Approach for Adversarial Attacks against Neural Machine Translation,"Sahar Sadrizadeh, Ljiljana Dolamic, Pascal Frossard",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15246"" target=""_blank"">2308.15246</a>",,2025-12-03 22:39:25
DiffSmooth: Certifiably Robust Learning via Diffusion Models and Local Smoothing,"Jiawei Zhang, Zhongzhu Chen, Huan Zhang, Chaowei Xiao, Bo Li",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14333"" target=""_blank"">2308.14333</a>","<a href=""https://github.com/javyduck/DiffSmooth]"" target=""_blank"">javyduck</a>",2025-12-03 22:39:25
MDTD: A Multi Domain Trojan Detector for Deep Neural Networks,"Arezoo Rajabi, Surudhi Asokraj, Fengqing Jiang, Luyao Niu, Bhaskar Ramasubramanian, Jim Ritcey, Radha Poovendran",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15673"" target=""_blank"">2308.15673</a>",,2025-12-03 22:39:25
3D Adversarial Augmentations for Robust Out-of-Domain Predictions,"Alexander Lehner, Stefano Gasperini, Alvaro Marcos-Ramiro, Michael Schmidt, Nassir Navab, Benjamin Busam, Federico Tombari",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15479"" target=""_blank"">2308.15479</a>",,2025-12-03 22:39:25
Everything Perturbed All at Once: Enabling Differentiable Graph Attacks,"Haoran Liu, Bokun Wang, Jianling Wang, Xiangjue Dong, Tianbao Yang, James Caverlee",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15614"" target=""_blank"">2308.15614</a>",,2025-12-03 22:39:25
Intriguing Properties of Diffusion Models: An Empirical Study of the Natural Attack Capability in Text-to-Image Generative Models,"Takami Sato, Justin Yue, Nanze Chen, Ningfei Wang, Qi Alfred Chen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15692"" target=""_blank"">2308.15692</a>",,2025-12-03 22:39:25
Vulnerability of Machine Learning Approaches Applied in IoT-based Smart Grid: A Review,"Zhenyong Zhang, Mengxiang Liu, Mingyang Sun, Ruilong Deng, Peng Cheng, Dusit Niyato, Mo-Yuen Chow, Jiming Chen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15736"" target=""_blank"">2308.15736</a>",,2025-12-03 22:39:25
Can We Rely on AI? (50%),Desmond J. Higham,arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15092"" target=""_blank"">2308.15092</a>",,2025-12-03 22:39:25
Uncertainty Aware Training to Improve Deep Learning Model Calibration for Classification of Cardiac MR Images,"Tareen Dawood, Chen Chen, Baldeep S. Sidhua, Bram Ruijsink, Justin Goulda, Bradley Porter, Mark K. Elliott, Vishal Mehta, Christopher A. Rinaldi, Esther Puyol-Anton, Reza Razavi, Andrew P. King",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.15141"" target=""_blank"">2308.15141</a>",,2025-12-03 22:39:25
Adversarial Attacks on Foundational Vision Models,"Nathan Inkawhich, Gwendolyn McDonald, Ryan Luley",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.14597"" target=""_blank"">2308.14597</a>",,2025-12-03 22:39:25
Adversarial Illusions in Multi-Modal Embeddings,"Tingwei Zhang, Rishi Jha, Eugene Bagdasaryan, Vitaly Shmatikov",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11804"" target=""_blank"">2308.11804</a>",,2025-12-03 22:39:25
RemovalNet: DNN Fingerprint Removal Attacks,"Hongwei Yao, Zheng Li, Kunzhe Huang, Jian Lou, Zhan Qin, Kui Ren",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.12319"" target=""_blank"">2308.12319</a>","<a href=""https://github.com/grasses/RemovalNet"" target=""_blank"">grasses</a>",2025-12-03 22:39:25
Adversarial Training Using Feedback Loops,"Ali Haisam Muhammad Rafid, Adrian Sandu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11881"" target=""_blank"">2308.11881</a>",,2025-12-03 22:39:25
A White-Box False Positive Adversarial Attack Method on Contrastive Loss Based Offline Handwritten Signature Verification Models,"Zhongliang Guo, Weiye Li, Yifei Qian, Ognjen Arandjelović, Lei Fang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08925"" target=""_blank"">2308.08925</a>",,2025-12-03 22:39:25
Compensating Removed Frequency Components: Thwarting Voice Spectrum Reduction Attacks,"Shu Wang, Kun Sun, Qi Li",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09546"" target=""_blank"">2308.09546</a>",,2025-12-03 22:39:25
"DFB: A Data-Free, Low-Budget, and High-Efficacy Clean-Label Backdoor Attack","Binhao Ma, Jiahui Wang, Dejun Wang, Bo Meng",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09487"" target=""_blank"">2308.09487</a>",,2025-12-03 22:39:25
Backdoor Mitigation by Correcting the Distribution of Neural Activations,"Xi Li, Zhen Xiang, David J. Miller, George Kesidis",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09850"" target=""_blank"">2308.09850</a>",,2025-12-03 22:39:25
Towards Attack-tolerant Federated Learning via Critical Parameter Analysis,"Sungwon Han, Sungwon Park, Fangzhao Wu, Sundong Kim, Bin Zhu, Xing Xie, Meeyoung Cha",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09318"" target=""_blank"">2308.09318</a>",,2025-12-03 22:39:25
On Gradient-like Explanation under a Black-box Setting: When Black-box Explanations Become as Good as White-box,"Yi Cai, Gerhard Wunder",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09381"" target=""_blank"">2308.09381</a>",,2025-12-03 22:39:25
Defending Label Inference Attacks in Split Learning under Regression Setting,"Haoze Qiu, Fei Zheng, Chaochao Chen, Xiaolin Zheng",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09448"" target=""_blank"">2308.09448</a>",,2025-12-03 22:39:25
An Image is Worth a Thousand Toxic Words: A Metamorphic Testing Framework for Content Moderation Software,"Wenxuan Wang, Jingyuan Huang, Jen-tse Huang, Chang Chen, Jiazhen Gu, Pinjia He, Michael R. Lyu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09810"" target=""_blank"">2308.09810</a>",,2025-12-03 22:39:25
LEAP: Efficient and Automated Test Method for NLP Software,"Mingxuan Xiao, Yan Xiao, Hai Dong, Shunhui Ji, Pengcheng Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11284"" target=""_blank"">2308.11284</a>",,2025-12-03 22:39:25
Towards a Practical Defense against Adversarial Attacks on Deep Learning-based Malware Detectors via Randomized Smoothing,"Daniel Gibert, Giulio Zizzo, Quan Le",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08906"" target=""_blank"">2308.08906</a>",,2025-12-03 22:39:25
Causal Adversarial Perturbations for Individual Fairness and Robustness in Heterogeneous Data Spaces,"Ahmad-Reza Ehyaei, Kiarash Mohammadi, Amir-Hossein Karimi, Samira Samadi, Golnoosh Farnadi",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08938"" target=""_blank"">2308.08938</a>",,2025-12-03 22:39:25
Black-box Adversarial Attacks against Dense Retrieval Models: A Multi-view Contrastive Learning Method,"Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Rijke Maarten de, Wei Chen, Yixing Fan, Xueqi Cheng",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09861"" target=""_blank"">2308.09861</a>",,2025-12-03 22:39:25
That Doesn't Go There: Attacks on Shared State in Multi-User Augmented Reality Applications,"Carter Slocum, Yicheng Zhang, Erfan Shayegani, Pedram Zaree, Nael Abu-Ghazaleh, Jiasi Chen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09146"" target=""_blank"">2308.09146</a>",,2025-12-03 22:39:25
Evaluating the Instruction-Following Robustness of Large Language Models to Prompt Injection,"Zekun Li, Baolin Peng, Pengcheng He, Xifeng Yan",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10819"" target=""_blank"">2308.10819</a>","<a href=""https://github.com/Leezekun/Adv-Instruct-Eval"" target=""_blank"">Leezekun</a>",2025-12-03 22:39:25
Benchmarking Adversarial Robustness of Compressed Deep Learning Models,"Brijesh Vora, Kartik Patwari, Syed Mahbub Hafiz, Zubair Shafiq, Chen-Nee Chuah",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08160"" target=""_blank"">2308.08160</a>",,2025-12-03 22:39:25
Test-Time Poisoning Attacks Against Test-Time Adaptation Models,"Tianshuo Cong, Xinlei He, Yun Shen, Yang Zhang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08505"" target=""_blank"">2308.08505</a>",,2025-12-03 22:39:25
Self-Deception: Reverse Penetrating the Semantic Firewall of Large Language Models,"Zhenhua Wang, Wei Xie, Kai Chen, Baosheng Wang, Zhiwen Gui, Enze Wang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11521"" target=""_blank"">2308.11521</a>",,2025-12-03 22:39:25
Dynamic Neural Network is All You Need: Understanding the Robustness of Dynamic Mechanisms in Neural Networks,"Mirazul Haque, Wei Yang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08709"" target=""_blank"">2308.08709</a>",,2025-12-03 22:39:25
Expressivity of Graph Neural Networks Through the Lens of Adversarial Robustness,"Francesco Campi, Lukas Gosch, Tom Wollschläger, Yan Scholten, Stephan Günnemann",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.08173"" target=""_blank"">2308.08173</a>",,2025-12-03 22:39:25
SEDA: Self-Ensembling ViT with Defensive Distillation and Adversarial Training for robust Chest X-rays Classification,"Raza Imam, Ibrahim Almakky, Salma Alrashdi, Baketah Alrashdi, Mohammad Yaqub",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07874"" target=""_blank"">2308.07874</a>",,2025-12-03 22:39:25
Backpropagation Path Search On Adversarial Transferability,"Zhuoer Xu, Zhangxuan Gu, Jianping Zhang, Shiwen Cui, Changhua Meng, Weiqiang Wang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.07625"" target=""_blank"">2308.07625</a>",,2025-12-03 22:39:25
Attacking logo-based phishing website detectors with adversarial perturbations,"Jehyun Lee, Zhe Xin, Melanie Ng Pei See, Kanav Sabharwal, Giovanni Apruzzese, Dinil Mon Divakaran",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09392"" target=""_blank"">2308.09392</a>",,2025-12-03 22:39:25
Proceedings of the 2nd International Workshop on Adaptive Cyber Defense,"Marco Carvalho, Damian Marriott, Mark Bilinski, Ahmad Ridley",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09520"" target=""_blank"">2308.09520</a>",,2025-12-03 22:39:25
Robust Mixture-of-Expert Training for Convolutional Neural Networks,"Yihua Zhang, Ruisi Cai, Tianlong Chen, Guanhua Zhang, Huan Zhang, Pin-Yu Chen, Shiyu Chang, Zhangyang Wang, Sijia Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10110"" target=""_blank"">2308.10110</a>","<a href=""https://github.com/OPTML-Group/Robust-MoE-CNN"" target=""_blank"">OPTML-Group</a>",2025-12-03 22:39:25
Unlocking Accuracy and Fairness in Differentially Private Image Classification,"Leonard Berrada, Soham De, Judy Hanwen Shen, Jamie Hayes, Robert Stanforth, David Stutz, Pushmeet Kohli, Samuel L. Smith, Borja Balle",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10888"" target=""_blank"">2308.10888</a>",,2025-12-03 22:39:25
Improving the Transferability of Adversarial Examples with Arbitrary Style Transfer,"Zhijin Ge, Fanhua Shang, Hongying Liu, Yuanyuan Liu, Liang Wan, Wei Feng, Xiaosen Wang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10601"" target=""_blank"">2308.10601</a>","<a href=""https://github.com/Zhijin-Ge/STM"" target=""_blank"">Zhijin-Ge</a>",2025-12-03 22:39:25
Spear and Shield: Adversarial Attacks and Defense Methods for Model-Based Link Prediction on Continuous-Time Dynamic Graphs,"Dongjin Lee, Juho Lee, Kijung Shin",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10779"" target=""_blank"">2308.10779</a>",,2025-12-03 22:39:25
Enhancing Adversarial Attacks: The Similar Target Method,"Shuo Zhang, Ziruo Wang, Zikai Zhou, Huanran Chen",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10743"" target=""_blank"">2308.10743</a>",,2025-12-03 22:39:25
Adversarial Attacks on Code Models with Discriminative Graph Patterns,"Thanh-Dat Nguyen, Yang Zhou, Xuan Bach D. Le, Patanamon Thongtanunam, David Lo",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11161"" target=""_blank"">2308.11161</a>",,2025-12-03 22:39:25
Temporal-Distributed Backdoor Attack Against Video Based Action Recognition,"Xi Li, Songhe Wang, Ruiquan Huang, Mahanth Gowda, George Kesidis",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11070"" target=""_blank"">2308.11070</a>",,2025-12-03 22:39:25
PatchBackdoor: Backdoor Attack against Deep Neural Networks without Model Modification,"Yizhen Institute for AI Industry Research Yuan, Rui Shanghai Jiao Tong University, Shanghai, China Kong, Shenghao Wuhan University, Wuhan, China Xie, Yuanchun Institute for AI Industry Research Shanghai AI Laboratory, Shanghai, China Li, Yunxin Institute for AI Industry Research Shanghai AI Laboratory, Shanghai, China Liu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.11822"" target=""_blank"">2308.11822</a>",,2025-12-03 22:39:25
Single-User Injection for Invisible Shilling Attack against Recommender Systems,"Chengzhi Huang, Hui Li",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10467"" target=""_blank"">2308.10467</a>","<a href=""https://github.com/KDEGroup/SUI-Attack"" target=""_blank"">KDEGroup</a>",2025-12-03 22:39:25
On the Adversarial Robustness of Multi-Modal Foundation Models,"Christian Schlarmann, Matthias Hein",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10741"" target=""_blank"">2308.10741</a>",,2025-12-03 22:39:25
Measuring the Effect of Causal Disentanglement on the Adversarial Robustness of Neural Network Models,"Preben M. Ness, Dusica Marijan, Sunanda Bose",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10708"" target=""_blank"">2308.10708</a>",,2025-12-03 22:39:25
Boosting Adversarial Transferability by Block Shuffle and Rotation,"Kunyu Wang, Xuanran He, Wenxuan Wang, Xiaosen Wang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10299"" target=""_blank"">2308.10299</a>","<a href=""https://github.com/Trustworthy-AI-Group/BSR"" target=""_blank"">Trustworthy-AI-Group</a>",2025-12-03 22:39:25
Adversarial Collaborative Filtering for Free,"Huiyuan Chen, Xiaoting Li, Vivian Lai, Chin-Chia Michael Yeh, Yujie Fan, Yan Zheng, Mahashweta Das, Hao Yang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.13541"" target=""_blank"">2308.13541</a>",,2025-12-03 22:39:25
A Comparison of Adversarial Learning Techniques for Malware Detection,"Pavla Louthánová, Matouš Kozák, Martin Jureček, Mark Stamp",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.09958"" target=""_blank"">2308.09958</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness of Masked Autoencoders via Test-time Frequency-domain Prompting,"Qidong Huang, Xiaoyi Dong, Dongdong Chen, Yinpeng Chen, Lu Yuan, Gang Hua, Weiming Zhang, Nenghai Yu",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10315"" target=""_blank"">2308.10315</a>","<a href=""https://github.com/shikiw/RobustMAE"" target=""_blank"">shikiw</a>",2025-12-03 22:39:25
Efficient Joint Optimization of Layer-Adaptive Weight Pruning in Deep Neural Networks,"Kaixin Xu, Zhe Wang, Xue Geng, Jie Lin, Min Wu, Xiaoli Li, Weisi Lin",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10438"" target=""_blank"">2308.10438</a>","<a href=""https://github.com/Akimoto-Cris/RD_VIT_PRUNE"" target=""_blank"">Akimoto-Cris</a>",2025-12-03 22:39:25
A Study on Robustness and Reliability of Large Language Model Code Generation,"Li Zhong, Zilong Wang",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10335"" target=""_blank"">2308.10335</a>",,2025-12-03 22:39:25
Hiding Backdoors within Event Sequence Data via Poisoning Attacks,"Elizaveta Kovtun, Alina Ermilova, Dmitry Berestnev, Alexey Zaytsev",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10201"" target=""_blank"">2308.10201</a>",,2025-12-03 22:39:25
HoSNN: Adversarially-Robust Homeostatic Spiking Neural Networks with Adaptive Firing Thresholds,"Hejia Geng, Peng Li",arXiv,2023-08,"<a href=""http://arxiv.org/abs/2308.10373"" target=""_blank"">2308.10373</a>",,2025-12-03 22:39:25
Microbial Genetic Algorithm-based Black-box Attack against Interpretable Deep Learning Systems,"Eldor Abdukhamidov, Mohammed Abuhamad, Simon S. Woo, Eric Chan-Tin, Tamer Abuhmed",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06496"" target=""_blank"">2307.06496</a>",,2025-12-03 22:39:25
Scale Alone Does not Improve Mechanistic Interpretability in Vision Models,"Roland S. Zimmermann, Thomas Klein, Wieland Brendel",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05471"" target=""_blank"">2307.05471</a>",,2025-12-03 22:39:25
Rational Neural Network Controllers,"Matthew Newton, Antonis Papachristodoulou",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06287"" target=""_blank"">2307.06287</a>",,2025-12-03 22:39:25
Misclassification in Automated Content Analysis Causes Bias in Regression,"Nathan TeBlunthuis, Valerie Hase, Chung-Hong Chan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06483"" target=""_blank"">2307.06483</a>",,2025-12-03 22:39:25
ATWM: Defense against adversarial malware based on adversarial training,"Kun Li, Fan Zhang, Wei Guo",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05095"" target=""_blank"">2307.05095</a>",,2025-12-03 22:39:25
Membership Inference Attacks on DNNs using Adversarial Perturbations,"Hassan Ali, Adnan Qayyum, Ala Al-Fuqaha, Junaid Qadir",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05193"" target=""_blank"">2307.05193</a>",,2025-12-03 22:39:25
Random-Set Convolutional Neural Network (RS-CNN) for Epistemic Deep Learning,"Shireen Kudukkil Manchingal, Muhammad Mubashar, Kaizheng Wang, Keivan Shariatmadar, Fabio Cuzzolin",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05772"" target=""_blank"">2307.05772</a>",,2025-12-03 22:39:25
On the Vulnerability of DeepFake Detectors to Attacks Generated by Denoising Diffusion Models,"Marija Ivanovska, Vitomir Štruc",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05397"" target=""_blank"">2307.05397</a>",,2025-12-03 22:39:25
Differential Analysis of Triggers and Benign Features for Black-Box DNN Backdoor Detection,"Hao Fu, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05422"" target=""_blank"">2307.05422</a>",,2025-12-03 22:39:25
Random Position Adversarial Patch for Vision Transformers,Mingzhen Shao,arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.04066"" target=""_blank"">2307.04066</a>",,2025-12-03 22:39:25
Memorization Through the Lens of Curvature of Loss Function Around Samples,"Isha Garg, Deepak Ravikumar, Kaushik Roy",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05831"" target=""_blank"">2307.05831</a>",,2025-12-03 22:39:25
The Butterfly Effect in Artificial Intelligence Systems: Implications for AI Bias and Fairness,Emilio Ferrara,arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05842"" target=""_blank"">2307.05842</a>",,2025-12-03 22:39:25
Practical Trustworthiness Model for DNN in Dedicated 6G Application,"Anouar Nechi, Ahmed Mahmoudi, Christoph Herold, Daniel Widmer, Thomas Kürner, Mladen Berekovic, Saleh Mulhem",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.04677"" target=""_blank"">2307.04677</a>",,2025-12-03 22:39:25
Distill-SODA: Distilling Self-Supervised Vision Transformer for Source-Free Open-Set Domain Adaptation in Computational Pathology,"Guillaume Vray, Devavrat Tomar, Jean-Philippe Thiran, Behzad Bozorgtabar",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.04596"" target=""_blank"">2307.04596</a>",,2025-12-03 22:39:25
GNP Attack: Transferable Adversarial Examples via Gradient Norm Penalty,"Tao Wu, Tie Luo, Donald C. Wunsch",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.04099"" target=""_blank"">2307.04099</a>",,2025-12-03 22:39:25
Enhancing Adversarial Robustness via Score-Based Optimization,"Boya Zhang, Weijian Luo, Zhihua Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.04333"" target=""_blank"">2307.04333</a>",,2025-12-03 22:39:25
Adversarial Self-Attack Defense and Spatial-Temporal Relation Mining for Visible-Infrared Video Person Re-Identification,"Huafeng Li, Le Xu, Yafei Zhang, Dapeng Tao, Zhengtao Yu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03903"" target=""_blank"">2307.03903</a>","<a href=""https://github.com/lhf12278/xxx"" target=""_blank"">lhf12278</a>",2025-12-03 22:39:25
A Theoretical Perspective on Subnetwork Contributions to Adversarial Robustness,"Jovon Craig, Josh Andle, Theodore S. Nowak, Salimeh Yasaei Sekeh",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03803"" target=""_blank"">2307.03803</a>",,2025-12-03 22:39:25
Robust Ranking Explanations,"Chao Chen, Chenghua Guo, Guixiang Ma, Ming Zeng, Xi Zhang, Sihong Xie",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.04024"" target=""_blank"">2307.04024</a>",,2025-12-03 22:39:25
Towards Traitor Tracing in Black-and-White-Box DNN Watermarking with Tardos-based Codes,"Elena Rodriguez-Lois, Fernando Perez-Gonzalez",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06695"" target=""_blank"">2307.06695</a>",,2025-12-03 22:39:25
Single-Class Target-Specific Attack against Interpretable Deep Learning Systems,"Eldor Abdukhamidov, Mohammed Abuhamad, George K. Thiruvathukal, Hyoungshick Kim, Tamer Abuhmed",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06484"" target=""_blank"">2307.06484</a>",,2025-12-03 22:39:25
Diffusion to Confusion: Naturalistic Adversarial Patch Generation Based on Diffusion Model for Object Detector,"Shuo-Yen Lin, Ernie Chu, Che-Hsien Lin, Jun-Cheng Chen, Jia-Ching Wang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08076"" target=""_blank"">2307.08076</a>",,2025-12-03 22:39:25
Defeating Proactive Jammers Using Deep Reinforcement Learning for Resource-Constrained IoT Networks,"Abubakar Sani Ali, Shimaa Naser, Sami Muhaidat",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06796"" target=""_blank"">2307.06796</a>",,2025-12-03 22:39:25
Layer-wise Linear Mode Connectivity,"Linara Adilova, Maksym Andriushchenko, Michael Kamp, Asja Fischer, Martin Jaggi",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06966"" target=""_blank"">2307.06966</a>",,2025-12-03 22:39:25
Scalable Membership Inference Attacks via Quantile Regression,"Martin Bertran, Shuai Tang, Michael Kearns, Jamie Morgenstern, Aaron Roth, Zhiwei Steven Wu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03694"" target=""_blank"">2307.03694</a>",,2025-12-03 22:39:25
On the Robustness of Split Learning against Adversarial Attacks,"Mingyuan Fan, Cen Chen, Chengyu Wang, Wenmeng Zhou, Jun Huang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07916"" target=""_blank"">2307.07916</a>",,2025-12-03 22:39:25
Why Does Little Robustness Help? A Further Step Towards Understanding Adversarial Transferability,"Yechao Zhang, Shengshan Hu, Leo Yu Zhang, Junyu Shi, Minghui Li, Xiaogeng Liu, Wei Wan, Hai Jin",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07873"" target=""_blank"">2307.07873</a>",,2025-12-03 22:39:25
Unified Adversarial Patch for Cross-modal Attacks in the Physical World,"Xingxing Wei, Yao Huang, Yitong Sun, Jie Yu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07859"" target=""_blank"">2307.07859</a>",,2025-12-03 22:39:25
MasterKey: Automated Jailbreak Across Multiple Large Language Model Chatbots,"Gelei Deng, Yi Liu, Yuekang Li, Kailong Wang, Ying Zhang, Zefeng Li, Haoyu Wang, Tianwei Zhang, Yang Liu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08715"" target=""_blank"">2307.08715</a>",,2025-12-03 22:39:25
Vulnerability-Aware Instance Reweighting For Adversarial Training,"Olukorede Fakorede, Ashutosh Kumar Nirala, Modeste Atsague, Jin Tian",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07167"" target=""_blank"">2307.07167</a>",,2025-12-03 22:39:25
Mitigating Adversarial Vulnerability through Causal Parameter Estimation by Adversarial Double Machine Learning,"Byung-Kwan Lee, Junho Kim, Yong Man Ro",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07250"" target=""_blank"">2307.07250</a>",,2025-12-03 22:39:25
On the Sensitivity of Deep Load Disaggregation to Adversarial Attacks,"Hafsa Bousbiat, Yassine Himeur, Abbes Amira, Wathiq Mansoor",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10209"" target=""_blank"">2307.10209</a>",,2025-12-03 22:39:25
RFLA: A Stealthy Reflected Light Adversarial Attack in the Physical World,"Donghua Wang, Wen Yao, Tingsong Jiang, Chao Li, Xiaoqian Chen",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07653"" target=""_blank"">2307.07653</a>",,2025-12-03 22:39:25
Frequency Domain Adversarial Training for Robust Volumetric Medical Segmentation,"Asif Hanif, Muzammal Naseer, Salman Khan, Mubarak Shah, Fahad Shahbaz Khan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07269"" target=""_blank"">2307.07269</a>","<a href=""https://github.com/asif-hanif/vafa"" target=""_blank"">asif-hanif</a>",2025-12-03 22:39:25
Alleviating the Effect of Data Imbalance on Adversarial Training,"Guanlin Li, Guowen Xu, Tianwei Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10205"" target=""_blank"">2307.10205</a>","<a href=""https://github.com/GuanlinLee/REAT"" target=""_blank"">GuanlinLee</a>",2025-12-03 22:39:25
Structured Pruning of Neural Networks for Constraints Learning,"Matteo Cacciola, Antonio Frangioni, Andrea Lodi",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07457"" target=""_blank"">2307.07457</a>",,2025-12-03 22:39:25
Boosting Backdoor Attack with A Learnable Poisoning Sample Selection Strategy,"Zihao Zhu, Mingda Zhang, Shaokui Wei, Li Shen, Yanbo Fan, Baoyuan Wu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07328"" target=""_blank"">2307.07328</a>",,2025-12-03 22:39:25
"Erasing, Transforming, and Noising Defense Network for Occluded Person Re-Identification","Neng Dong, Liyan Zhang, Shuanglin Yan, Hao Tang, Jinhui Tang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07187"" target=""_blank"">2307.07187</a>","<a href=""https://github.com/nengdong96/ETNDNet"" target=""_blank"">nengdong96</a>",2025-12-03 22:39:25
Omnipotent Adversarial Training in the Wild,"Guanlin Li, Kangjie Chen, Yuan Xu, Han Qiu, Tianwei Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08596"" target=""_blank"">2307.08596</a>","<a href=""https://github.com/GuanlinLee/OAT"" target=""_blank"">GuanlinLee</a>",2025-12-03 22:39:25
Certified Robustness for Large Language Models with Self-Denoising,"Zhen Zhang, Guanhua Zhang, Bairu Hou, Wenqi Fan, Qing Li, Sijia Liu, Yang Zhang, Shiyu Chang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.07171"" target=""_blank"">2307.07171</a>","<a href=""https://github.com/UCSB-NLP-Chang/SelfDenoise"" target=""_blank"">UCSB-NLP-Chang</a>",2025-12-03 22:39:25
Multi-objective Evolutionary Search of Variable-length Composite Semantic Perturbations,"Jialiang Suna, Wen Yao, Tingsong Jianga, Xiaoqian Chena",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06548"" target=""_blank"">2307.06548</a>",,2025-12-03 22:39:25
MF-CLIP: Leveraging CLIP as Surrogate Models for No-box Adversarial Attacks,"Jiaming Zhang, Lingyu Qiu, Qi Yi, Yige Li, Jitao Sang, Changsheng Xu, Dit-Yan Yeung",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06608"" target=""_blank"">2307.06608</a>",,2025-12-03 22:39:25
Effective Prompt Extraction from Language Models,"Yiming Zhang, Nicholas Carlini, Daphne Ippolito",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.06865"" target=""_blank"">2307.06865</a>",,2025-12-03 22:39:25
Fooling Contrastive Language-Image Pre-trained Models with CLIPMasterPrints,"Matthias Freiberger, Peter Kun, Christian Igel, Anders Sundnes Løvlie, Sebastian Risi",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03798"" target=""_blank"">2307.03798</a>","<a href=""https://github.com/matfrei/CLIPMasterPrints"" target=""_blank"">matfrei</a>",2025-12-03 22:39:25
FedDefender: Backdoor Attack Defense in Federated Learning,"Waris Virginia Tech Gill, Ali University of Minnesota Twin Cities Anwar, Muhammad Ali Virginia Tech Gulzar",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08672"" target=""_blank"">2307.08672</a>",,2025-12-03 22:39:25
RADAR: Robust AI-Text Detection via Adversarial Learning,"Xiaomeng Hu, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03838"" target=""_blank"">2307.03838</a>",,2025-12-03 22:39:25
Generation of Time-Varying Impedance Attacks Against Haptic Shared Control Steering Systems,"Alireza Mohammadi, Hafiz Malik",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12399"" target=""_blank"">2307.12399</a>",,2025-12-03 22:39:25
Analyzing the vulnerabilities in SplitFed Learning: Assessing the robustness against Data Poisoning Attacks,"Aysha Thahsin Zahir Ismail, Raj Mani Shukla",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03197"" target=""_blank"">2307.03197</a>",,2025-12-03 22:39:25
What Distributions are Robust to Indiscriminate Poisoning Attacks for Linear Learners? (62%),"Fnu Suya, Xiao Zhang, Yuan Tian, David Evans",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01073"" target=""_blank"">2307.01073</a>",,2025-12-03 22:39:25
Adversarial Learning in Real-World Fraud Detection: Challenges and Perspectives,"Danele Lunghi, Alkis Simitsis, Olivier Caelen, Gianluca Bontempi",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01390"" target=""_blank"">2307.01390</a>",,2025-12-03 22:39:25
Understanding the Transferability of Representations via Task-Relatedness,"Akshay Mehra, Yunbei Zhang, Jihun Hamm",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00823"" target=""_blank"">2307.00823</a>",,2025-12-03 22:39:25
Enhancing the Robustness of QMIX against State-adversarial Attacks,"Weiran Guo, Guanjun Liu, Ziyuan Zhou, Ling Wang, Jiacun Wang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00907"" target=""_blank"">2307.00907</a>",,2025-12-03 22:39:25
Towards Building Self-Aware Object Detectors via Reliable Uncertainty Quantification and Calibration,"Kemal Oksuz, Tom Joy, Puneet K. Dokania",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00934"" target=""_blank"">2307.00934</a>","<a href=""https://github.com/fiveai/saod"" target=""_blank"">fiveai</a>",2025-12-03 22:39:25
Query-Efficient Decision-based Black-Box Patch Attack,"Zhaoyu Chen, Bo Li, Shuang Wu, Shouhong Ding, Wenqiang Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00477"" target=""_blank"">2307.00477</a>",,2025-12-03 22:39:25
Interpretability and Transparency-Driven Detection and Transformation of Textual Adversarial Examples (IT-DT),"Bushra Sabir, M. Ali Babar, Sharif Abuadbba",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01225"" target=""_blank"">2307.01225</a>",,2025-12-03 22:39:25
From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy,"Maanak Gupta, CharanKumar Akiri, Kshitiz Aryal, Eli Parker, Lopamudra Praharaj",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00691"" target=""_blank"">2307.00691</a>",,2025-12-03 22:39:25
CLIMAX: An exploration of Classifier-Based Contrastive Explanations,"Praharsh Nanavati, Ranjitha Prasad",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00680"" target=""_blank"">2307.00680</a>",,2025-12-03 22:39:25
Common Knowledge Learning for Generating Transferable Adversarial Examples,"Ruijie Yang, Yuanfang Guo, Junfu Wang, Jiantao Zhou, Yunhong Wang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00274"" target=""_blank"">2307.00274</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defenses on 3D Point Cloud Classification: A Survey,"Hanieh Naderi, Ivan V. Bajić",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00309"" target=""_blank"">2307.00309</a>",,2025-12-03 22:39:25
Brightness-Restricted Adversarial Attack Patch,Mingzhen Shao,arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00421"" target=""_blank"">2307.00421</a>",,2025-12-03 22:39:25
Fedward: Flexible Federated Backdoor Defense Framework with Non-IID Data,"Zekai Chen, Fuyi Wang, Zhiwei Zheng, Ximeng Liu, Yujie Lin",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00356"" target=""_blank"">2307.00356</a>",,2025-12-03 22:39:25
Minimizing Energy Consumption of Deep Learning Models by Energy-Aware Training,"Dario Lazzaro, Antonio Emanuele Cinà, Maura Pintor, Ambra Demontis, Battista Biggio, Fabio Roli, Marcello Pelillo",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00368"" target=""_blank"">2307.00368</a>",,2025-12-03 22:39:25
SysNoise: Exploring and Benchmarking Training-Deployment System Inconsistency,"Yan Wang, Yuhang Li, Ruihao Gong, Aishan Liu, Yanfei Wang, Jian Hu, Yongqiang Yao, Yunchen Zhang, Tianzi Xiao, Fengwei Yu, Xianglong Liu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00280"" target=""_blank"">2307.00280</a>","<a href=""https://modeltc.github.io/systemnoise_web"" target=""_blank"">modeltc.github.io</a>",2025-12-03 22:39:25
Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD,"Anvith Thudi, Hengrui Jia, Casey Meehan, Ilia Shumailov, Nicolas Papernot",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00310"" target=""_blank"">2307.00310</a>",,2025-12-03 22:39:25
CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data Synthesis,"Abdallah Alshantti, Damiano Varagnolo, Adil Rasheed, Aria Rahmati, Frank Westad",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00384"" target=""_blank"">2307.00384</a>",,2025-12-03 22:39:25
Hiding in Plain Sight: Differential Privacy Noise Exploitation for Evasion-resilient Localized Poisoning Attacks in Multiagent Reinforcement Learning,"Md Tamjid Hossain, Hung La",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.00268"" target=""_blank"">2307.00268</a>",,2025-12-03 22:39:25
A Dual Stealthy Backdoor: From Both Spatial and Frequency Perspectives,"Yudong Gao, Honglong Chen, Peng Sun, Junjian Li, Anqing Zhang, Zhibo Wang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10184"" target=""_blank"">2307.10184</a>",,2025-12-03 22:39:25
Pareto-Secure Machine Learning (PSML): Fingerprinting and Securing Inference Serving Systems,"Debopam Georgia Institute of Technology Sanyal, Jui-Tse Georgia Institute of Technology Hung, Manav Georgia Institute of Technology Agrawal, Prahlad Georgia Institute of Technology Jasti, Shahab University of California, Riverside Nikkhoo, Somesh University of Wisconsin-Madison Jha, Tianhao University of Virginia Wang, Sibin George Washington University Mohan, Alexey Georgia Institute of Technology Tumanov",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01292"" target=""_blank"">2307.01292</a>",,2025-12-03 22:39:25
Synthetic is all you need: removing the auxiliary data assumption for membership inference attacks against synthetic data,"Florent Guépin, Matthieu Meeus, Ana-Maria Cretu, Montjoye Yves-Alexandre de",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01701"" target=""_blank"">2307.01701</a>",,2025-12-03 22:39:25
Detecting Images Generated by Deep Diffusion Models using their Local Intrinsic Dimensionality,"Peter Lorenz, Ricard Durall, Janis Keuper",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02347"" target=""_blank"">2307.02347</a>",,2025-12-03 22:39:25
Sampling-based Fast Gradient Rescaling Method for Highly Transferable Adversarial Attacks,"Xu Han, Anmin Liu, Chenxuan Yao, Yanbo Fan, Kun He",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02828"" target=""_blank"">2307.02828</a>",,2025-12-03 22:39:25
NatLogAttack: A Framework for Attacking Natural Language Inference Models with Natural Logic,"Zi'ou Zheng, Xiaodan Zhu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02849"" target=""_blank"">2307.02849</a>",,2025-12-03 22:39:25
Quantification of Uncertainty with Adversarial Models,"Kajetan Schweighofer, Lukas Aichberger, Mykyta Ielanskyi, Günter Klambauer, Sepp Hochreiter",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03217"" target=""_blank"">2307.03217</a>",,2025-12-03 22:39:25
A Vulnerability of Attribution Methods Using Pre-Softmax Scores,"Miguel Lerma, Mirtha Lucas",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03305"" target=""_blank"">2307.03305</a>",,2025-12-03 22:39:25
Probabilistic and Semantic Descriptions of Image Manifolds and Their Applications,"Peter Tu, Zhaoyuan Yang, Richard Hartley, Zhiwei Xu, Jing Zhang, Yiwei Fu, Dylan Campbell, Jaskirat Singh, Tianyu Wang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02881"" target=""_blank"">2307.02881</a>",,2025-12-03 22:39:25
T-MARS: Improving Visual Representations by Circumventing Text Feature Learning,"Pratyush Maini, Sachin Goyal, Zachary C. Lipton, J. Zico Kolter, Aditi Raghunathan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.03132"" target=""_blank"">2307.03132</a>","<a href=""https://github.com/locuslab/T-MARS"" target=""_blank"">locuslab</a>",2025-12-03 22:39:25
Adversarial Attacks on Image Classification Models: FGSM and Patch Attacks and their Impact,"Jaydip Sen, Subhasis Dasgupta",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02055"" target=""_blank"">2307.02055</a>",,2025-12-03 22:39:25
DARE: Towards Robust Text Explanations in Biomedical and Healthcare Applications,"Adam Ivankay, Mattia Rigotti, Pascal Frossard",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02094"" target=""_blank"">2307.02094</a>",,2025-12-03 22:39:25
"GIT: Detecting Uncertainty, Out-Of-Distribution and Adversarial Samples using Gradients and Invariance Transformations","Julia Lust, Alexandru P. Condurache",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02672"" target=""_blank"">2307.02672</a>",,2025-12-03 22:39:25
Machine Learning-Based Intrusion Detection: Feature Selection versus Feature Extraction,"Vu-Duc Ngo, Tuan-Cuong Vuong, Luong Thien Van, Hung Tran",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01570"" target=""_blank"">2307.01570</a>",,2025-12-03 22:39:25
Securing Cloud FPGAs Against Power Side-Channel Attacks: A Case Study on Iterative AES,"Nithyashankari Gummidipoondi JV Jayasankaran, Hao JV Guo, Satwik JV Patnaik, JV Jeyavijayan, Rajendran, Jiang Hu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02569"" target=""_blank"">2307.02569</a>",,2025-12-03 22:39:25
On the Adversarial Robustness of Generative Autoencoders in the Latent Space,"Mingfei Lu, Badong Chen",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02202"" target=""_blank"">2307.02202</a>",,2025-12-03 22:39:25
SCAT: Robust Self-supervised Contrastive Learning via Adversarial Training for Text Classification,"Junjie Wu, Dit-Yan Yeung",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01488"" target=""_blank"">2307.01488</a>",,2025-12-03 22:39:25
LEAT: Towards Robust Deepfake Disruption in Real-World Scenarios via Latent Ensemble Attack,"Joonkyo Shim, Hyunsoo Yoon",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01520"" target=""_blank"">2307.01520</a>",,2025-12-03 22:39:25
Interpretable Computer Vision Models through Adversarial Training: Unveiling the Robustness-Interpretability Connection,Delyan Boychev,arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.02500"" target=""_blank"">2307.02500</a>",,2025-12-03 22:39:25
Overconfidence is a Dangerous Thing: Mitigating Membership Inference Attacks by Enforcing Less Confident Prediction,"Zitao Chen, Karthik Pattabiraman",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01610"" target=""_blank"">2307.01610</a>",,2025-12-03 22:39:25
Physically Realizable Natural-Looking Clothing Textures Evade Person Detectors via 3D Modeling,"Zhanhao Hu, Wenda Chu, Xiaopei Zhu, Hui Zhang, Bo Zhang, Xiaolin Hu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01778"" target=""_blank"">2307.01778</a>",,2025-12-03 22:39:25
An Analysis of Untargeted Poisoning Attack and Defense Methods for Federated Online Learning to Rank Systems,"Shuyi Wang, Guido Zuccon",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.01565"" target=""_blank"">2307.01565</a>",,2025-12-03 22:39:25
Lipschitz Continuous Algorithms for Covering Problems,"Soh Kumabe, Yuichi Yoshida",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08213"" target=""_blank"">2307.08213</a>",,2025-12-03 22:39:25
A Bayesian approach to quantifying uncertainties and improving generalizability in traffic prediction models,"Agnimitra Sengupta, Sudeepta Mondal, Adway Das, S. Ilgin Guler",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.05946"" target=""_blank"">2307.05946</a>",,2025-12-03 22:39:25
Towards Stealthy Backdoor Attacks against Speech Recognition via Elements of Sound,"Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao, Stefanos Koffas, Yiming Li",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08208"" target=""_blank"">2307.08208</a>","<a href=""https://github.com/HanboCai/BadSpeech_SoE"" target=""_blank"">HanboCai</a>",2025-12-03 22:39:25
Unified Adversarial Patch for Visible-Infrared Cross-modal Attacks in the Physical World,"Xingxing Wei, Yao Huang, Yitong Sun, Jie Yu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14682"" target=""_blank"">2307.14682</a>",,2025-12-03 22:39:25
SEV-Step: A Single-Stepping Framework for AMD-SEV,"Luca Wilke, Jan Wichelmann, Anja Rabich, Thomas Eisenbarth",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14757"" target=""_blank"">2307.14757</a>",,2025-12-03 22:39:25
"Decoding the Secrets of Machine Learning in Malware Classification: A Deep Dive into Datasets, Feature Extraction, and Model Performance","Savino Dambra, Yufei Han, Simone Aonzo, Platon Kotzias, Antonino Vitale, Juan Caballero, Davide Balzarotti, Leyla Bilge",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14657"" target=""_blank"">2307.14657</a>",,2025-12-03 22:39:25
AC-Norm: Effective Tuning for Medical Image Analysis via Affine Collaborative Normalization,"Chuyan Zhang, Yuncheng Yang, Hao Zheng, Yun Gu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15282"" target=""_blank"">2307.15282</a>","<a href=""https://github.com/EndoluminalSurgicalVision-IMR/ACNorm"" target=""_blank"">EndoluminalSurgicalVision-IMR</a>",2025-12-03 22:39:25
Enhanced Security against Adversarial Examples Using a Random Ensemble of Encrypted Vision Transformer Models,"Ryota Iijima, Miki Tanaka, Sayaka Shiota, Hitoshi Kiya",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13985"" target=""_blank"">2307.13985</a>",,2025-12-03 22:39:25
Set-level Guidance Attack: Boosting Adversarial Transferability of Vision-Language Pre-training Models,"Dong Lu, Zhiqiang Wang, Teng Wang, Weili Guan, Hongchang Gao, Feng Zheng",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14061"" target=""_blank"">2307.14061</a>",,2025-12-03 22:39:25
Defending Adversarial Patches via Joint Region Localizing and Inpainting,"Junwen Chen, Xingxing Wei",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14242"" target=""_blank"">2307.14242</a>",,2025-12-03 22:39:25
Lateral-Direction Localization Attack in High-Level Autonomous Driving: Domain-Specific Defense Opportunity via Lane Detection,"Junjie Shen, Yunpeng Luo, Ziwen Wan, Qi Alfred Chen",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14540"" target=""_blank"">2307.14540</a>",,2025-12-03 22:39:25
Plug and Pray: Exploiting off-the-shelf components of Multi-Modal Models,"Erfan Shayegani, Yue Dong, Nael Abu-Ghazaleh",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14539"" target=""_blank"">2307.14539</a>",,2025-12-03 22:39:25
Coupled-Space Attacks against Random-Walk-based Anomaly Detection,"Yuni Lai, Marcin Waniek, Liying Li, Jingwen Wu, Yulin Zhu, Tomasz P. Michalak, Talal Rahwan, Kai Zhou",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14387"" target=""_blank"">2307.14387</a>",,2025-12-03 22:39:25
FakeTracer: Proactively Defending Against Face-swap DeepFakes via Implanting Traces in Training,"Pu Sun, Honggang Qi, Yuezun Li, Siwei Lyu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14593"" target=""_blank"">2307.14593</a>",,2025-12-03 22:39:25
Open Image Content Disarm And Reconstruction,"Eli Belkind, Ran Dubin, Amit Dvir",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14057"" target=""_blank"">2307.14057</a>",,2025-12-03 22:39:25
On the unreasonable vulnerability of transformers for image restoration -- and an easy fix,"Shashank Agnihotri, Kanchana Vaishnavi Gandikota, Julia Grabinski, Paramanand Chandramouli, Margret Keuper",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13856"" target=""_blank"">2307.13856</a>",,2025-12-03 22:39:25
Imperceptible Physical Attack against Face Recognition Systems via LED Illumination Modulation,"Junbin Fang, Canjian Jiang, You Jiang, Puxi Lin, Zhaojie Chen, Yujing Sun, Siu-Ming Yiu, Zoe L. Jiang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13294"" target=""_blank"">2307.13294</a>",,2025-12-03 22:39:25
Efficient Estimation of Average-Case Robustness for Multi-Class Classification,"Tessa Han, Suraj Srinivas, Himabindu Lakkaraju",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13885"" target=""_blank"">2307.13885</a>",,2025-12-03 22:39:25
Foundational Models Defining a New Era in Vision: A Survey and Outlook,"Muhammad Awais, Muzammal Naseer, Salman Khan, Rao Muhammad Anwer, Hisham Cholakkal, Mubarak Shah, Ming-Hsuan Yang, Fahad Shahbaz Khan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13721"" target=""_blank"">2307.13721</a>","<a href=""https://github.com/awaisrauf/Awesome-CV-Foundational-Models"" target=""_blank"">awaisrauf</a>",2025-12-03 22:39:25
Why Don't You Clean Your Glasses? Perception Attacks with Dynamic Optical Perturbations,"Yi Han, Matthew Chan, Eric Wengrowski, Zhuohuan Li, Nils Ole Tippenhauer, Mani Srivastava, Saman Zonouz, Luis Garcia",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13131"" target=""_blank"">2307.13131</a>",,2025-12-03 22:39:25
Lost In Translation: Generating Adversarial Examples Robust to Round-Trip Translation,"Neel Bhandari, Pin-Yu Chen",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12520"" target=""_blank"">2307.12520</a>",,2025-12-03 22:39:25
Data-free Black-box Attack based on Diffusion Model,"Mingwen Shao, Lingzhuang Meng, Yuanjian Qiao, Lixu Zhang, Wangmeng Zuo",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12872"" target=""_blank"">2307.12872</a>",,2025-12-03 22:39:25
Adaptive Certified Training: Towards Better Accuracy-Robustness Tradeoffs,"Zhakshylyk Nurlanov, Frank R. Schmidt, Florian Bernard",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13078"" target=""_blank"">2307.13078</a>",,2025-12-03 22:39:25
NSA: Naturalistic Support Artifact to Boost Network Confidence,"Abhijith Sharma, Phil Munz, Apurva Narayan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14917"" target=""_blank"">2307.14917</a>",,2025-12-03 22:39:25
FLARE: Fingerprinting Deep Reinforcement Learning Agents using Universal Adversarial Masks,"Buse G. A. Tekgul, N. Asokan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14751"" target=""_blank"">2307.14751</a>",,2025-12-03 22:39:25
Cyber Deception against Zero-day Attacks: A Game Theoretic Approach,"Md Abu University of Texas at El Paso Sayed, Ahmed H. US Army Research Laboratory Anwar, Christopher University of Texas at El Paso Kiekintveld, Branislav Czech Technical University in Prague Bosansky, Charles US Army Research Laboratory Kamhoua",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13107"" target=""_blank"">2307.13107</a>",,2025-12-03 22:39:25
Backdoor Attacks for In-Context Learning with Language Models,"Nikhil Kandpal, Matthew Jagielski, Florian Tramèr, Nicholas Carlini",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.14692"" target=""_blank"">2307.14692</a>",,2025-12-03 22:39:25
Towards Viewpoint-Invariant Visual Recognition via Adversarial Training,"Shouwei Ruan, Yinpeng Dong, Hang Su, Jianteng Peng, Ning Chen, Xingxing Wei",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10235"" target=""_blank"">2307.10235</a>",,2025-12-03 22:39:25
Universal Adversarial Defense in Remote Sensing Based on Pre-trained Denoising Diffusion Models,"Weikang Yu, Yonghao Xu, Pedram Ghamisi",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16865"" target=""_blank"">2307.16865</a>",,2025-12-03 22:39:25
Defense of Adversarial Ranking Attack in Text Retrieval: Benchmark and Baseline via Detection,"Xuanang Chen, Ben He, Le Sun, Yingfei Sun",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16816"" target=""_blank"">2307.16816</a>",,2025-12-03 22:39:25
Text-CRS: A Generalized Certified Robustness Framework against Textual Adversarial Attacks,"Xinyu Zhang, Hanbin Hong, Yuan Hong, Peng Huang, Binghui Wang, Zhongjie Ba, Kui Ren",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16630"" target=""_blank"">2307.16630</a>",,2025-12-03 22:39:25
BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models,"Jordan Vice, Naveed Akhtar, Richard Hartley, Ajmal Mian",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16489"" target=""_blank"">2307.16489</a>","<a href=""https://github.com/JJ-Vice/BAGM"" target=""_blank"">JJ-Vice</a>",2025-12-03 22:39:25
Virtual Prompt Injection for Instruction-Tuned Large Language Models,"Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai Wang, Vijay Srinivasan, Xiang Ren, Hongxia Jin",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16888"" target=""_blank"">2307.16888</a>","<a href=""https://poison-llm.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Noisy Self-Training with Data Augmentations for Offensive and Hate Speech Detection Tasks,"João A. Leite, Carolina Scarton, Diego F. Silva",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16609"" target=""_blank"">2307.16609</a>",,2025-12-03 22:39:25
Theoretically Principled Trade-off for Stateful Defenses against Query-Based Black-Box Attacks,"Ashish Hooda, Neal Mangaokar, Ryan Feng, Kassem Fawaz, Somesh Jha, Atul Prakash",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16331"" target=""_blank"">2307.16331</a>",,2025-12-03 22:39:25
Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples,"Qiufan Ji, Lin Wang, Cong Shi, Shengshan Hu, Yingying Chen, Lichao Sun",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16361"" target=""_blank"">2307.16361</a>","<a href=""https://github.com/qiufan319/benchmark_pc_attack"" target=""_blank"">qiufan319</a>",2025-12-03 22:39:25
Probabilistically robust conformal prediction,"Subhankar Ghosh, Yuanjie Shi, Taha Belkhouja, Yan Yan, Jana Doppa, Brian Jones",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16360"" target=""_blank"">2307.16360</a>",,2025-12-03 22:39:25
On Updating Static Output Feedback Controllers Under State-Space Perturbation,"MirSaleh Bahavarnia, Ahmad F. Taha",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16178"" target=""_blank"">2307.16178</a>",,2025-12-03 22:39:25
You Can Backdoor Personalized Federated Learning,"Tiandi Ye, Cen Chen, Yinggui Wang, Xiang Li, Ming Gao",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15971"" target=""_blank"">2307.15971</a>",,2025-12-03 22:39:25
On Neural Network approximation of ideal adversarial attack and convergence of adversarial training,"Rajdeep Haldar, Qifan Song",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16099"" target=""_blank"">2307.16099</a>",,2025-12-03 22:39:25
Exposing Hidden Attackers in Industrial Control Systems using Micro-distortions,"Suman Sourav, Binbin Chen",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15926"" target=""_blank"">2307.15926</a>",,2025-12-03 22:39:25
Beating Backdoor Attack at Its Own Game,"Min Liu, Alberto Sangiovanni-Vincentelli, Xiangyu Yue",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15539"" target=""_blank"">2307.15539</a>","<a href=""https://github.com/damianliumin/non-adversarial_backdoor"" target=""_blank"">damianliumin</a>",2025-12-03 22:39:25
Adversarial training for tabular data with attack propagation,"Tiago Leon Melo, João Bravo, Marco O. P. Sampaio, Paolo Romano, Hugo Ferreira, João Tiago Ascensão, Pedro Bizarro",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15677"" target=""_blank"">2307.15677</a>",,2025-12-03 22:39:25
Improving Realistic Worst-Case Performance of NVCiM DNN Accelerators through Training with Right-Censored Gaussian Noise,"Zheyu Yan, Yifan Qin, Wujie Wen, Xiaobo Sharon Hu, Yiyu Shi",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15853"" target=""_blank"">2307.15853</a>",,2025-12-03 22:39:25
What can Discriminator do? Towards Box-free Ownership Verification of Generative Adversarial Network,"Ziheng Huang, Boheng Li, Yan Cai, Run Wang, Shangwei Guo, Liming Fang, Jing Chen, Lina Wang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15860"" target=""_blank"">2307.15860</a>","<a href=""https://github.com/AbstractTeen/gan_ownership_verification"" target=""_blank"">AbstractTeen</a>",2025-12-03 22:39:25
Universal and Transferable Adversarial Attacks on Aligned Language Models,"Andy Zou, Zifan Wang, Nicholas Carlini, Milad Nasr, J. Zico Kolter, Matt Fredrikson",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15043"" target=""_blank"">2307.15043</a>",,2025-12-03 22:39:25
An Estimator for the Sensitivity to Perturbations of Deep Neural Networks,"Naman Maheshwari, Nicholas Malaya, Scott Moe, Jaydeep P. Kulkarni, Sudhanva Gurumurthi",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12679"" target=""_blank"">2307.12679</a>",,2025-12-03 22:39:25
R-LPIPS: An Adversarially Robust Perceptual Similarity Metric,"Sara Ghazanfari, Siddharth Garg, Prashanth Krishnamurthy, Farshad Khorrami, Alexandre Araujo",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15157"" target=""_blank"">2307.15157</a>","<a href=""https://github.com/SaraGhazanfari/R-LPIPS"" target=""_blank"">SaraGhazanfari</a>",2025-12-03 22:39:25
Malware Resistant Data Protection in Hyper-connected Networks: A survey,"Jannatul Ferdous, Rafiqul Islam, Maumita Bhattacharya, Md Zahidul Islam",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13164"" target=""_blank"">2307.13164</a>",,2025-12-03 22:39:25
Improving Transferability of Adversarial Examples via Bayesian Attacks,"Qizhang Li, Yiwen Guo, Xiaochen Yang, Wangmeng Zuo, Hao Chen",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11334"" target=""_blank"">2307.11334</a>",,2025-12-03 22:39:25
PATROL: Privacy-Oriented Pruning for Collaborative Inference Against Model Inversion Attacks,"Shiwei Ding, Lan Zhang, Miao Pan, Xiaoyong Yuan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10981"" target=""_blank"">2307.10981</a>",,2025-12-03 22:39:25
A Holistic Assessment of the Reliability of Machine Learning Systems,"Anthony Corso, David Karamadian, Romeo Valentin, Mary Cooper, Mykel J. Kochenderfer",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10586"" target=""_blank"">2307.10586</a>",,2025-12-03 22:39:25
Making Pre-trained Language Models both Task-solvers and Self-calibrators,"Yangyi Chen, Xingyao Wang, Heng Ji",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11316"" target=""_blank"">2307.11316</a>","<a href=""https://github.com/Yangyi-Chen/LM-TOAST"" target=""_blank"">Yangyi-Chen</a>",2025-12-03 22:39:25
Boundary State Generation for Testing and Improvement of Autonomous Driving Systems,"Matteo Biagiola, Paolo Tonella",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10590"" target=""_blank"">2307.10590</a>",,2025-12-03 22:39:25
"A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency","Jiawei Shao, Zijian Li, Wenqiang Sun, Tailin Zhou, Yuchang Sun, Lumin Liu, Zehong Lin, Yuyi Mao, Jun Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10655"" target=""_blank"">2307.10655</a>",,2025-12-03 22:39:25
Backdoor Attack against Object Detection with Clean Annotation,"Yize Cheng, Wenbin Hu, Minhao Cheng",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10487"" target=""_blank"">2307.10487</a>",,2025-12-03 22:39:25
Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples,"Shaokui Wei, Mingda Zhang, Hongyuan Zha, Baoyuan Wu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10562"" target=""_blank"">2307.10562</a>",,2025-12-03 22:39:25
Rethinking Backdoor Attacks,"Alaa Khaddaj, Guillaume Leclerc, Aleksandar Makelov, Kristian Georgiev, Hadi Salman, Andrew Ilyas, Aleksander Madry",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10163"" target=""_blank"">2307.10163</a>",,2025-12-03 22:39:25
Towards Building More Robust Models with Frequency Bias,"Qingwen Bu, Dong Huang, Heming Cui",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.09763"" target=""_blank"">2307.09763</a>",,2025-12-03 22:39:25
CertPri: Certifiable Prioritization for Deep Neural Networks via Movement Cost in Feature Space,"Haibin Zheng, Jinyin Chen, Haibo Jin",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.09375"" target=""_blank"">2307.09375</a>",,2025-12-03 22:39:25
FedDefender: Client-Side Attack-Tolerant Federated Learning,"Sungwon Park, Sungwon Han, Fangzhao Wu, Sundong Kim, Bin Zhu, Xing Xie, Meeyoung Cha",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.09048"" target=""_blank"">2307.09048</a>",,2025-12-03 22:39:25
Can Neural Network Memorization Be Localized? (4%),"Pratyush Maini, Michael C. Mozer, Hanie Sedghi, Zachary C. Lipton, J. Zico Kolter, Chiyuan Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.09542"" target=""_blank"">2307.09542</a>",,2025-12-03 22:39:25
Adversarial Attacks on Traffic Sign Recognition: A Survey,"Svetlana Pavlitska, Nico Lambing, J. Marius Zöllner",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08278"" target=""_blank"">2307.08278</a>",,2025-12-03 22:39:25
Discretization-based ensemble model for robust learning in IoT,"Anahita Namvar, Chandra Thapa, Salil S. Kanhere",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08955"" target=""_blank"">2307.08955</a>",,2025-12-03 22:39:25
Unstoppable Attack: Label-Only Model Inversion via Conditional Diffusion Model,"Rongke Liu, Dong Wang, Yizhi Ren, Zhen Wang, Kaitian Guo, Qianqian Qin, Xiaolei Liu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08424"" target=""_blank"">2307.08424</a>",,2025-12-03 22:39:25
Runtime Stealthy Perception Attacks against DNN-based Adaptive Cruise Control Systems,"Xugui Zhou, Anqi Chen, Maxfield Kouzel, Haotian Ren, Morgan McCarty, Cristina Nita-Rotaru, Homa Alemzadeh",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08939"" target=""_blank"">2307.08939</a>",,2025-12-03 22:39:25
On the Fly Neural Style Smoothing for Risk-Averse Domain Generalization,"Akshay Mehra, Yunbei Zhang, Bhavya Kailkhura, Jihun Hamm",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.08551"" target=""_blank"">2307.08551</a>",,2025-12-03 22:39:25
A Machine Learning based Empirical Evaluation of Cyber Threat Actors High Level Attack Patterns over Low level Attack Patterns in Attributing Attacks,"Umara Noor, Sawera Shahid, Rimsha Kanwal, Zahid Rashid",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10252"" target=""_blank"">2307.10252</a>",,2025-12-03 22:39:25
Investigating the Robustness of Sequential Recommender Systems Against Training Data Perturbations,"Filippo Betello, Federico Siciliano, Pushkar Mishra, Fabrizio Silvestri",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13165"" target=""_blank"">2307.13165</a>",,2025-12-03 22:39:25
Adversarial attacks for mixtures of classifiers,"Lucas Gnecco Heredia, Benjamin Negrevergne, Yann Chevaleyre",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.10788"" target=""_blank"">2307.10788</a>",,2025-12-03 22:39:25
Improving Surrogate Model Robustness to Perturbations for Dynamical Systems Through Machine Learning and Data Assimilation,"Abhishek Ajayakumar, Soumyendu Raha",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.09762"" target=""_blank"">2307.09762</a>",,2025-12-03 22:39:25
A LLM Assisted Exploitation of AI-Guardian,Nicholas Carlini,arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.15008"" target=""_blank"">2307.15008</a>",,2025-12-03 22:39:25
Cross Contrastive Feature Perturbation for Domain Generalization,"Chenming Li, Daoan Zhang, Wenjian Huang, Jianguo Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12502"" target=""_blank"">2307.12502</a>",,2025-12-03 22:39:25
Digital Twins for Moving Target Defense Validation in AC Microgrids,"Suman Rath, Subham Sahoo, Shamik Sengupta",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13152"" target=""_blank"">2307.13152</a>",,2025-12-03 22:39:25
Mitigating Communications Threats in Decentralized Federated Learning through Moving Target Defense,"Enrique Tomás Martínez Beltrán, Pedro Miguel Sánchez Sánchez, Sergio López Bernal, Gérôme Bovet, Manuel Gil Pérez, Gregorio Martínez Pérez, Alberto Huertas Celdrán",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11730"" target=""_blank"">2307.11730</a>",,2025-12-03 22:39:25
Learning Provably Robust Estimators for Inverse Problems via Jittering,"Anselm Krainovic, Mahdi Soltanolkotabi, Reinhard Heckel",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12822"" target=""_blank"">2307.12822</a>",,2025-12-03 22:39:25
Towards Generic and Controllable Attacks Against Object Detection,"Guopeng Li, Yue Xu, Jian Ding, Gui-Song Xia",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12342"" target=""_blank"">2307.12342</a>","<a href=""https://github.com/liguopeng0923/LGP"" target=""_blank"">liguopeng0923</a>",2025-12-03 22:39:25
Downstream-agnostic Adversarial Examples,"Ziqi Zhou, Shengshan Hu, Ruizhi Zhao, Qian Wang, Leo Yu Zhang, Junhui Hou, Hai Jin",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12280"" target=""_blank"">2307.12280</a>",,2025-12-03 22:39:25
AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion Models,"Xuelong Dai, Kaisheng Liang, Bin Xiao",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12499"" target=""_blank"">2307.12499</a>",,2025-12-03 22:39:25
Gradient-Based Word Substitution for Obstinate Adversarial Examples Generation in Language Models,"Yimu Wang, Peng Shi, Hongyang Zhang",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12507"" target=""_blank"">2307.12507</a>",,2025-12-03 22:39:25
A First Look at On-device Models in iOS Apps,"Han Hu, Yujin Huang, Qiuyuan Chen, Terry Tue Zhuo, Chunyang Chen",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12328"" target=""_blank"">2307.12328</a>",,2025-12-03 22:39:25
Robust Automatic Speech Recognition via WavAugment Guided Phoneme Adversarial Training,"Gege Qi, Yuefeng Chen, Xiaofeng Mao, Xiaojun Jia, Ranjie Duan, Rong Zhang, Hui Xue",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12498"" target=""_blank"">2307.12498</a>",,2025-12-03 22:39:25
Towards Bridging the FL Performance-Explainability Trade-Off: A Trustworthy 6G RAN Slicing Use-Case,"Swastika Roy, Hatim Chergui, Christos Verikoukis",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.12903"" target=""_blank"">2307.12903</a>",,2025-12-03 22:39:25
Fast Adaptive Test-Time Defense with Robust Features,"Anurag Singh, Mahalakshmi Sabanayagam, Krikamol Muandet, Debarghya Ghoshdastidar",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11672"" target=""_blank"">2307.11672</a>",,2025-12-03 22:39:25
Unveiling Vulnerabilities in Interpretable Deep Learning Systems with Query-Efficient Black-box Attacks,"Eldor Abdukhamidov, Mohammed Abuhamad, Simon S. Woo, Eric Chan-Tin, Tamer Abuhmed",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11906"" target=""_blank"">2307.11906</a>",,2025-12-03 22:39:25
FMT: Removing Backdoor Feature Maps via Feature Map Testing in Deep Neural Networks,"Dong Huang, Qingwen Bu, Yahao Qing, Yichao Fu, Heming Cui",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11565"" target=""_blank"">2307.11565</a>",,2025-12-03 22:39:25
Improving Viewpoint Robustness for Visual Recognition via Adversarial Training,"Shouwei Ruan, Yinpeng Dong, Hang Su, Jianteng Peng, Ning Chen, Xingxing Wei",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11528"" target=""_blank"">2307.11528</a>",,2025-12-03 22:39:25
OUTFOX: LLM-generated Essay Detection through In-context Learning with Adversarially Generated Examples,"Ryuto Koike, Masahiro Kaneko, Naoaki Okazaki",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11729"" target=""_blank"">2307.11729</a>",,2025-12-03 22:39:25
Transferable Attack for Semantic Segmentation,"Mengqi He, Jing Zhang, Zhaoyuan Yang, Mingyi He, Nick Barnes, Yuchao Dai",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.16572"" target=""_blank"">2307.16572</a>","<a href=""https://github.com/anucvers/TASS"" target=""_blank"">anucvers</a>",2025-12-03 22:39:25
Backdoor Attacks against Voice Recognition Systems: A Survey,"Baochen Yan, Jiahe Lan, Zheng Yan",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.13643"" target=""_blank"">2307.13643</a>",,2025-12-03 22:39:25
HybridAugment++: Unified Frequency Spectra Perturbations for Model Robustness,"Mehmet Kerim Yucel, Ramazan Gokberk Cinbis, Pinar Duygulu",arXiv,2023-07,"<a href=""http://arxiv.org/abs/2307.11823"" target=""_blank"">2307.11823</a>",,2025-12-03 22:39:25
G$^2$uardFL: Safeguarding Federated Learning Against Backdoor Attacks through Attributed Client Graph Clustering,"Hao Yu, Chuan Ma, Meng Liu, Xinwang Liu, Zhe Liu, Ming Ding",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04984"" target=""_blank"">2306.04984</a>",,2025-12-03 22:39:25
Conservative Prediction via Data-Driven Confidence Minimization,"Caroline Choi, Fahim Tajwar, Yoonho Lee, Huaxiu Yao, Ananya Kumar, Chelsea Finn",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04974"" target=""_blank"">2306.04974</a>",,2025-12-03 22:39:25
Expanding Scope: Adapting English Adversarial Attacks to Chinese,"Hanyu Liu, Chengyuan Cai, Yanjun Qi",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04874"" target=""_blank"">2306.04874</a>",,2025-12-03 22:39:25
Extracting Cloud-based Model with Prior Knowledge,"Shiqian Zhao, Kangjie Chen, Meng Hao, Jian Zhang, Guowen Xu, Hongwei Li, Tianwei Zhang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04192"" target=""_blank"">2306.04192</a>",,2025-12-03 22:39:25
Open Set Relation Extraction via Unknown-Aware Training,"Jun Zhao, Xin Zhao, Wenyu Zhan, Qi Zhang, Tao Gui, Zhongyu Wei, Yunwen Chen, Xiang Gao, Xuanjing Huang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04950"" target=""_blank"">2306.04950</a>",,2025-12-03 22:39:25
Robust Framework for Explanation Evaluation in Time Series Classification,"Thu Trang Nguyen, Thach Le Nguyen, Georgiana Ifrim",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05501"" target=""_blank"">2306.05501</a>",,2025-12-03 22:39:25
Investigating the Effect of Misalignment on Membership Privacy in the White-box Setting,"Ana-Maria Cretu, Daniel Jones, Montjoye Yves-Alexandre de, Shruti Tople",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05093"" target=""_blank"">2306.05093</a>",,2025-12-03 22:39:25
Enhancing Robustness of AI Offensive Code Generators via Data Augmentation,"Cristina Improta, Pietro Liguori, Roberto Natella, Bojan Cukic, Domenico Cotroneo",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05079"" target=""_blank"">2306.05079</a>",,2025-12-03 22:39:25
Robustness Testing for Multi-Agent Reinforcement Learning: State Perturbations on Critical Agents,"Ziyuan Zhou, Guanjun Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06136"" target=""_blank"">2306.06136</a>",,2025-12-03 22:39:25
Optimal Transport Model Distributional Robustness,"Van-Anh Nguyen, Trung Le, Anh Tuan Bui, Thanh-Toan Do, Dinh Phung",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04178"" target=""_blank"">2306.04178</a>",,2025-12-03 22:39:25
PriSampler: Mitigating Property Inference of Diffusion Models,"Hailong Hu, Jun Pang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05208"" target=""_blank"">2306.05208</a>",,2025-12-03 22:39:25
FedMLSecurity: A Benchmark for Attacks and Defenses in Federated Learning and LLMs,"Shanshan Han, Baturalp Buyukates, Zijian Hu, Han Jin, Weizhao Jin, Lichao Sun, Xiaoyang Wang, Chulin Xie, Kai Zhang, Qifan Zhang, Yuhui Zhang, Chaoyang He, Salman Avestimehr",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04959"" target=""_blank"">2306.04959</a>",,2025-12-03 22:39:25
PromptAttack: Probing Dialogue State Trackers with Adversarial Prompts,"Xiangjue Dong, Yun He, Ziwei Zhu, James Caverlee",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04535"" target=""_blank"">2306.04535</a>",,2025-12-03 22:39:25
Divide and Repair: Using Options to Improve Performance of Imitation Learning Against Adversarial Demonstrations,Prithviraj Dasgupta,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04581"" target=""_blank"">2306.04581</a>",,2025-12-03 22:39:25
PromptRobust: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts,"Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei Ye, Yue Zhang, Neil Zhenqiang Gong, Xing Xie",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04528"" target=""_blank"">2306.04528</a>",,2025-12-03 22:39:25
A Linearly Convergent GAN Inversion-based Algorithm for Reverse Engineering of Deceptions,"Darshan Thaker, Paris Giampouras, René Vidal",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04756"" target=""_blank"">2306.04756</a>",,2025-12-03 22:39:25
Faithful Knowledge Distillation,"Tom A. Lamb, Rudy Brunel, Krishnamurthy DJ Dvijotham, M. Pawan Kumar, Philip H. S. Torr, Francisco Eiras",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04431"" target=""_blank"">2306.04431</a>",,2025-12-03 22:39:25
Can current NLI systems handle German word order? Investigating language model performance on a new German challenge set of minimal pairs,"Ines Reinig, Katja Markert",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04523"" target=""_blank"">2306.04523</a>","<a href=""https://github.com/ireinig/wogli"" target=""_blank"">ireinig</a>",2025-12-03 22:39:25
Adversarial Sample Detection Through Neural Network Transport Dynamics,"Skander Karkar, Patrick Gallinari, Alain Rakotomamonjy",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04252"" target=""_blank"">2306.04252</a>",,2025-12-03 22:39:25
Revisiting the Trade-off between Accuracy and Robustness via Weight Distribution of Filters,"Xingxing Wei, Shiji Zhao",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03430"" target=""_blank"">2306.03430</a>",,2025-12-03 22:39:25
Membership inference attack with relative decision boundary distance,"JiaCheng Xu, ChengXiang Tan",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04109"" target=""_blank"">2306.04109</a>",,2025-12-03 22:39:25
Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations,"Torsten University of Würzburg Krauß, Alexandra University of Würzburg Dmitrienko",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03600"" target=""_blank"">2306.03600</a>",,2025-12-03 22:39:25
Transferable Adversarial Robustness for Categorical Data via Universal Robust Embeddings,"Klim Kireev, Maksym Andriushchenko, Carmela Troncoso, Nicolas Flammarion",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04064"" target=""_blank"">2306.04064</a>",,2025-12-03 22:39:25
Adversarial attacks and defenses in explainable artificial intelligence: A survey,"Hubert Baniecki, Przemyslaw Biecek",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06123"" target=""_blank"">2306.06123</a>",,2025-12-03 22:39:25
Exploring Model Dynamics for Accumulative Poisoning Discovery,"Jianing Zhu, Xiawei Guo, Jiangchao Yao, Chao Du, Li He, Shuo Yuan, Tongliang Liu, Liang Wang, Bo Han",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03726"" target=""_blank"">2306.03726</a>","<a href=""https://github.com/tmlr-group/Memorization-Discrepancy"" target=""_blank"">tmlr-group</a>",2025-12-03 22:39:25
A Melting Pot of Evolution and Learning,"Moshe Sipper, Achiya Elyasaf, Tomer Halperin, Zvika Haramaty, Raz Lapid, Eyal Segal, Itai Tzruia, Snir Vitrack Tamam",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.04971"" target=""_blank"">2306.04971</a>",,2025-12-03 22:39:25
Few-shot Multi-domain Knowledge Rearming for Context-aware Defence against Advanced Persistent Threats,"Gaolei Li, Yuanyuan Zhao, Wenqi Wei, Yuchen Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07685"" target=""_blank"">2306.07685</a>",,2025-12-03 22:39:25
Generalizable Lightweight Proxy for Robust NAS against Diverse Perturbations,"Hyeonjeong Ha, Minseon Kim, Sung Ju Hwang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05031"" target=""_blank"">2306.05031</a>",,2025-12-03 22:39:25
COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in Language Models,"Zihao Tan, Qingliang Chen, Wenbin Zhu, Yongjian Huang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05659"" target=""_blank"">2306.05659</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defenses for Semantic Communication in Vehicular Metaverses,"Jiawen Kang, Jiayi He, Hongyang Du, Zehui Xiong, Zhaohui Yang, Xumin Huang, Shengli Xie",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03528"" target=""_blank"">2306.03528</a>",,2025-12-03 22:39:25
Revisiting and Advancing Adversarial Training Through A Simple Baseline,Hong Liu,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07613"" target=""_blank"">2306.07613</a>",,2025-12-03 22:39:25
Generative Watermarking Against Unauthorized Subject-Driven Image Synthesis,"Yihan Ma, Zhengyu Zhao, Xinlei He, Zheng Li, Michael Backes, Yang Zhang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07754"" target=""_blank"">2306.07754</a>",,2025-12-03 22:39:25
Privacy Inference-Empowered Stealthy Backdoor Attack on Federated Learning under Non-IID Scenarios,"Haochen Mei, Gaolei Li, Jun Wu, Longfei Zheng",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08011"" target=""_blank"">2306.08011</a>",,2025-12-03 22:39:25
Temporal Gradient Inversion Attacks with Robust Optimization,"Bowen Li, Hanlin Gu, Ruoxin Chen, Jie Li, Chentao Wu, Na Ruan, Xueming Si, Lixin Fan",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07883"" target=""_blank"">2306.07883</a>",,2025-12-03 22:39:25
When Vision Fails: Text Attacks Against ViT and OCR,"Nicholas Boucher, Jenny Blessing, Ilia Shumailov, Ross Anderson, Nicolas Papernot",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07033"" target=""_blank"">2306.07033</a>",,2025-12-03 22:39:25
AROID: Improving Adversarial Robustness Through Online Instance-Wise Data Augmentation,"Lin Li, Jianing Qiu, Michael Spratling",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07197"" target=""_blank"">2306.07197</a>","<a href=""https://github.com/TreeLLi/AROID"" target=""_blank"">TreeLLi</a>",2025-12-03 22:39:25
How robust accuracy suffers from certified training with convex relaxations,"Bartolomeis Piersilvio De, Jacob Clarysse, Amartya Sanyal, Fanny Yang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06995"" target=""_blank"">2306.06995</a>",,2025-12-03 22:39:25
Graph Agent Network: Empowering Nodes with Decentralized Communications Capabilities for Adversarial Resilience,"Ao Liu, Wenshan Li, Tao Li, Beibei Li, Guangquan Xu, Pan Zhou, Wengang Ma, Hanyuan Huang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06909"" target=""_blank"">2306.06909</a>",,2025-12-03 22:39:25
Frequency-Based Vulnerability Analysis of Deep Learning Models against Image Corruptions,"Harshitha Machiraju, Michael H. Herzog, Pascal Frossard",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07178"" target=""_blank"">2306.07178</a>",,2025-12-03 22:39:25
On the Robustness of Removal-Based Feature Attributions,"Chris Lin, Ian Covert, Su-In Lee",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07462"" target=""_blank"">2306.07462</a>",,2025-12-03 22:39:25
VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion Models,"Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06874"" target=""_blank"">2306.06874</a>",,2025-12-03 22:39:25
Securing Visually-Aware Recommender Systems: An Adversarial Image Reconstruction and Detection Framework,"Minglei Yin, Bin Liu, Neil Zhenqiang Gong, Xin Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07992"" target=""_blank"">2306.07992</a>",,2025-12-03 22:39:25
Neural Architecture Design and Robustness: A Dataset,"Steffen Jung, Jovita Lukasik, Margret Keuper",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06712"" target=""_blank"">2306.06712</a>",,2025-12-03 22:39:25
TrojLLM: A Black-box Trojan Prompt Attack on Large Language Models,"Jiaqi Xue, Mengxin Zheng, Ting Hua, Yilin Shen, Yepeng Liu, Ladislau Boloni, Qian Lou",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06815"" target=""_blank"">2306.06815</a>","<a href=""https://github.com/UCF-ML-Research/TrojLLM"" target=""_blank"">UCF-ML-Research</a>",2025-12-03 22:39:25
Boosting Adversarial Robustness using Feature Level Stochastic Smoothing,"Sravanti Addepalli, Samyak Jain, Gaurang Sriramanan, R. Venkatesh Babu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06462"" target=""_blank"">2306.06462</a>",,2025-12-03 22:39:25
NeRFool: Uncovering the Vulnerability of Generalizable Neural Radiance Fields against Adversarial Perturbations,"Yonggan Fu, Ye Yuan, Souvik Kundu, Shang Wu, Shunyao Zhang, Yingyan Celine Lin",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06359"" target=""_blank"">2306.06359</a>","<a href=""https://github.com/GATECH-EIC/NeRFool"" target=""_blank"">GATECH-EIC</a>",2025-12-03 22:39:25
The Defense of Networked Targets in General Lotto games,"Adel Aghajan, Keith Paarporn, Jason R. Marden",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06485"" target=""_blank"">2306.06485</a>",,2025-12-03 22:39:25
Detecting Adversarial Directions in Deep Reinforcement Learning to Make Robust Decisions,"Ezgi Korkmaz, Jonah Brown-Cohen",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05873"" target=""_blank"">2306.05873</a>",,2025-12-03 22:39:25
When Authentication Is Not Enough: On the Security of Behavioral-Based Driver Authentication Systems,"Emad Efatinasab, Francesco Marchiori, Denis Donadel, Alessandro Brighente, Mauro Conti",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05923"" target=""_blank"">2306.05923</a>",,2025-12-03 22:39:25
Overcoming Adversarial Attacks for Human-in-the-Loop Applications,"Ryan McCoppin, Marla Kennedy, Platon Lukyanenko, Sean Kennedy",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05952"" target=""_blank"">2306.05952</a>",,2025-12-03 22:39:25
Adversarial Evasion Attacks Practicality in Networks: Testing the Impact of Dynamic Learning,"Mohamed elShehaby, Ashraf Matrawy",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05494"" target=""_blank"">2306.05494</a>",,2025-12-03 22:39:25
Boosting Adversarial Transferability by Achieving Flat Local Maxima,"Zhijin Ge, Hongying Liu, Xiaosen Wang, Fanhua Shang, Yuanyuan Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05225"" target=""_blank"">2306.05225</a>","<a href=""https://github.com/Trustworthy-AI-Group/PGN"" target=""_blank"">Trustworthy-AI-Group</a>",2025-12-03 22:39:25
Performance-optimized deep neural networks are evolving into worse models of inferotemporal visual cortex,"Drew Linsley, Ivan F. Rodriguez, Thomas Fel, Michael Arcaro, Saloni Sharma, Margaret Livingstone, Thomas Serre",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03779"" target=""_blank"">2306.03779</a>",,2025-12-03 22:39:25
Graph-based methods coupled with specific distributional distances for adversarial attack detection,"Dwight Nwaigwe, Lucrezia Carboni, Martial Mermillod, Sophie Achard, Michel Dojat",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00042"" target=""_blank"">2306.00042</a>",,2025-12-03 22:39:25
Adversarial alignment: Breaking the trade-off between the strength of an attack and its relevance to human perception,"Drew Linsley, Pinyuan Feng, Thibaut Boissin, Alekh Karkada Ashok, Thomas Fel, Stephanie Olaiya, Thomas Serre",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03229"" target=""_blank"">2306.03229</a>",,2025-12-03 22:39:25
Does Black-box Attribute Inference Attacks on Graph Neural Networks Constitute Privacy Risk? (13%),"Iyiola E. Olatunji, Anmar Hizber, Oliver Sihlovec, Megha Khosla",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00578"" target=""_blank"">2306.00578</a>",,2025-12-03 22:39:25
Unlearnable Examples for Diffusion Models: Protect Data from Unauthorized Exploitation,"Zhengyue Zhao, Jinhao Duan, Xing Hu, Kaidi Xu, Chenan Wang, Rui Zhang, Zidong Du, Qi Guo, Yunji Chen",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01902"" target=""_blank"">2306.01902</a>",,2025-12-03 22:39:25
MutateNN: Mutation Testing of Image Recognition Models Deployed on Hardware Accelerators,"Nikolaos Louloudakis, Perry Gibson, José Cano, Ajitha Rajan",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01697"" target=""_blank"">2306.01697</a>",,2025-12-03 22:39:25
Towards Robust GAN-generated Image Detection: a Multi-view Completion Representation,"Chi Liu, Tianqing Zhu, Sheng Shen, Wanlei Zhou",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01364"" target=""_blank"">2306.01364</a>",,2025-12-03 22:39:25
Improving the generalizability and robustness of large-scale traffic signal control,"Tianyu Shi, Francois-Xavier Devailly, Denis Larocque, Laurent Charlin",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01925"" target=""_blank"">2306.01925</a>",,2025-12-03 22:39:25
Adversarial Attack Based on Prediction-Correction,"Chen Wan, Fangjun Huang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01809"" target=""_blank"">2306.01809</a>",,2025-12-03 22:39:25
Constructing Semantics-Aware Adversarial Examples with Probabilistic Perspective,"Andi Zhang, Damon Wischik",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00353"" target=""_blank"">2306.00353</a>",,2025-12-03 22:39:25
Reconstruction Distortion of Learned Image Compression with Imperceptible Perturbations,"Yang Sui, Zhuohang Li, Ding Ding, Xiang Pan, Xiaozhong Xu, Shan Liu, Zhenzhong Chen",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01125"" target=""_blank"">2306.01125</a>",,2025-12-03 22:39:25
Intriguing Properties of Text-guided Diffusion Models,"Qihao Liu, Adam Kortylewski, Yutong Bai, Song Bai, Alan Yuille",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00974"" target=""_blank"">2306.00974</a>",,2025-12-03 22:39:25
"Versatile Backdoor Attack with Visible, Semantic, Sample-Specific, and Compatible Triggers","Ruotong Wang, Hongrui Chen, Zihao Zhu, Li Liu, Baoyuan Wu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00816"" target=""_blank"">2306.00816</a>",,2025-12-03 22:39:25
Improving the Robustness of Summarization Systems with Dual Augmentation,"Xiuying Chen, Guodong Long, Chongyang Tao, Mingzhe Li, Xin Gao, Chengqi Zhang, Xiangliang Zhang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01090"" target=""_blank"">2306.01090</a>",,2025-12-03 22:39:25
Adversarial Robustness in Unsupervised Machine Learning: A Systematic Review,"Mathias Lundteigen Mohus, Jinyue Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00687"" target=""_blank"">2306.00687</a>",,2025-12-03 22:39:25
CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV Perception,"Jiachen Sun, Haizhong Zheng, Qingzhao Zhang, Atul Prakash, Z. Morley Mao, Chaowei Xiao",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00349"" target=""_blank"">2306.00349</a>",,2025-12-03 22:39:25
Evading Black-box Classifiers Without Breaking Eggs,"Edoardo Debenedetti, Nicholas Carlini, Florian Tramèr",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02895"" target=""_blank"">2306.02895</a>",,2025-12-03 22:39:25
ModelObfuscator: Obfuscating Model Information to Protect Deployed ML-based Systems,"Mingyi Zhou, Xiang Gao, Jing Wu, John Grundy, Xiao Chen, Chunyang Chen, Li Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06112"" target=""_blank"">2306.06112</a>","<a href=""https://github.com/zhoumingyi/ModelObfuscator"" target=""_blank"">zhoumingyi</a>",2025-12-03 22:39:25
Area is all you need: repeatable elements make stronger adversarial attacks,Dillon Niederhut,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07768"" target=""_blank"">2306.07768</a>",,2025-12-03 22:39:25
Adversarial-Aware Deep Learning System based on a Secondary Classical Machine Learning Verification Approach,"Mohammed Alkhowaiter, Hisham Kholidy, Mnassar Alyami, Abdulmajeed Alghamdi, Cliff Zou",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00314"" target=""_blank"">2306.00314</a>",,2025-12-03 22:39:25
Trustworthy Sensor Fusion against Inaudible Command Attacks in Advanced Driver-Assistance System,"Jiwei Guan, Lei Pan, Chen Wang, Shui Yu, Longxiang Gao, Xi Zheng",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.05358"" target=""_blank"">2306.05358</a>",,2025-12-03 22:39:25
Trainable and Explainable Simplicial Map Neural Networks,"Eduardo Paluzo-Hidalgo, Miguel A. Gutiérrez-Naranjo, Rocio Gonzalez-Diaz",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.00010"" target=""_blank"">2306.00010</a>",,2025-12-03 22:39:25
Adversarial Attack On Yolov5 For Traffic And Road Sign Detection,Sanyam Jain,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06071"" target=""_blank"">2306.06071</a>",,2025-12-03 22:39:25
Rapid Plug-in Defenders,"Kai Wu, Yujian Betterest Li, Jian Lou, Xiaoyu Zhang, Handing Wang, Jing Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01762"" target=""_blank"">2306.01762</a>",,2025-12-03 22:39:25
DeepSeaNet: Improving Underwater Object Detection using EfficientDet,Sanyam Jain,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06075"" target=""_blank"">2306.06075</a>",,2025-12-03 22:39:25
CARSO: Counter-Adversarial Recall of Synthetic Observations,"Emanuele Ballarin, Alessio Ansuini, Luca Bortolussi",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06081"" target=""_blank"">2306.06081</a>","<a href=""https://github.com/emaballarin/CARSO"" target=""_blank"">emaballarin</a>",2025-12-03 22:39:25
Adversarial Attacks on Leakage Detectors in Water Distribution Networks,"Paul Stahlhofen, André Artelt, Luca Hermes, Barbara Hammer",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06107"" target=""_blank"">2306.06107</a>",,2025-12-03 22:39:25
Backdoor Attack with Sparse and Invisible Trigger,"Yinghua Gao, Yiming Li, Xueluan Gong, Shu-Tao Xia, Qian Wang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.06209"" target=""_blank"">2306.06209</a>","<a href=""https://github.com/YinghuaGao/SIBA"" target=""_blank"">YinghuaGao</a>",2025-12-03 22:39:25
VoteTRANS: Detecting Adversarial Text without Training by Voting on Hard Labels of Transformations,"Hoang-Quoc Nguyen-Son, Seira Hidano, Kazuhide Fukushima, Shinsaku Kiyomoto, Isao Echizen",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01273"" target=""_blank"">2306.01273</a>",,2025-12-03 22:39:25
Covert Communication Based on the Poisoning Attack in Federated Learning,"Junchuan Liang, Rong Wang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01342"" target=""_blank"">2306.01342</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness of DEQs with Explicit Regulations Along the Neural Dynamics,"Zonghan Yang, Peng Li, Tianyu Pang, Yang Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01435"" target=""_blank"">2306.01435</a>",,2025-12-03 22:39:25
Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations,"Dou Hu, Yinan Bao, Lingwei Wei, Wei Zhou, Songlin Hu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01505"" target=""_blank"">2306.01505</a>",,2025-12-03 22:39:25
Evaluating robustness of support vector machines with the Lagrangian dual approach,"Yuting Liu, Hong Gu, Pan Qin",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02639"" target=""_blank"">2306.02639</a>",,2025-12-03 22:39:25
A Robust Likelihood Model for Novelty Detection,"Ranya Almohsen, Shivang Patel, Donald A. Adjeroh, Gianfranco Doretto",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03331"" target=""_blank"">2306.03331</a>",,2025-12-03 22:39:25
Adversarial Ink: Componentwise Backward Error Attacks on Deep Learning,"Lucas Beerens, Desmond J. Higham",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02918"" target=""_blank"">2306.02918</a>",,2025-12-03 22:39:25
Enhance Diffusion to Improve Robust Generalization,"Jianhui Sun, Sanchit Sinha, Aidong Zhang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02618"" target=""_blank"">2306.02618</a>",,2025-12-03 22:39:25
KNOW How to Make Up Your Mind! Adversarially Detecting and Alleviating Inconsistencies in Natural Language Explanations,"Myeongjun Jang, Bodhisattwa Prasad Majumder, Julian McAuley, Thomas Lukasiewicz, Oana-Maria Camburu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02980"" target=""_blank"">2306.02980</a>",,2025-12-03 22:39:25
Stable Diffusion is Unstable,"Chengbin Du, Yanxi Li, Zhongwei Qiu, Chang Xu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02583"" target=""_blank"">2306.02583</a>",,2025-12-03 22:39:25
Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization,"Yibing Liu, Chris Xing Tian, Haoliang Li, Lei Ma, Shiqi Wang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02879"" target=""_blank"">2306.02879</a>",,2025-12-03 22:39:25
Security Knowledge-Guided Fuzzing of Deep Learning Libraries,"Nima Shiri Harzevili, Hung Viet Pham, Song Wang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.03269"" target=""_blank"">2306.03269</a>",,2025-12-03 22:39:25
Input-gradient space particle inference for neural network ensembles,"Trung Trinh, Markus Heinonen, Luigi Acerbi, Samuel Kaski",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02775"" target=""_blank"">2306.02775</a>",,2025-12-03 22:39:25
Adversary for Social Good: Leveraging Adversarial Attacks to Protect Personal Attribute Privacy,"Xiaoting Li, Lingwei Chen, Dinghao Wu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02488"" target=""_blank"">2306.02488</a>",,2025-12-03 22:39:25
Aerial Swarm Defense using Interception and Herding Strategies,"Vishnu S. Chipade, Dimitra Panagou",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02482"" target=""_blank"">2306.02482</a>",,2025-12-03 22:39:25
Towards Black-box Adversarial Example Detection: A Data Reconstruction-based Method,"Yifei Gao, Zhiyu Lin, Yunfan Yang, Jitao Sang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02021"" target=""_blank"">2306.02021</a>",,2025-12-03 22:39:25
Learning to Defend by Attacking (and Vice-Versa): Transfer of Learning in Cybersecurity Games,"Tailia Malloy, Cleotilde Gonzalez",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02165"" target=""_blank"">2306.02165</a>",,2025-12-03 22:39:25
Can Directed Graph Neural Networks be Adversarially Robust? (56%),"Zhichao Hou, Xitong Zhang, Wei Wang, Charu C. Aggarwal, Xiaorui Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02002"" target=""_blank"">2306.02002</a>",,2025-12-03 22:39:25
Flew Over Learning Trap: Learn Unlearnable Samples by Progressive Staged Training,"Pucheng Dang, Xing Hu, Kaidi Xu, Jinhao Duan, Di Huang, Husheng Han, Rui Zhang, Zidong Du, Qi Guo, Yunji Chen",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02064"" target=""_blank"">2306.02064</a>",,2025-12-03 22:39:25
Benchmarking Robustness of Adaptation Methods on Pre-trained Vision-Language Models,"Shuo Chen, Jindong Gu, Zhen Han, Yunpu Ma, Philip Torr, Volker Tresp",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.02080"" target=""_blank"">2306.02080</a>","<a href=""https://adarobustness.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Towards Understanding Clean Generalization and Robust Overfitting in Adversarial Training,"Binghui Li, Yuanzhi Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01271"" target=""_blank"">2306.01271</a>",,2025-12-03 22:39:25
A Closer Look at the Adversarial Robustness of Deep Equilibrium Models,"Zonghan Yang, Tianyu Pang, Yang Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01429"" target=""_blank"">2306.01429</a>",,2025-12-03 22:39:25
Adaptive Attractors: A Defense Strategy against ML Adversarial Collusion Attacks,"Jiyi Zhang, Han Fang, Ee-Chien Chang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01400"" target=""_blank"">2306.01400</a>",,2025-12-03 22:39:25
Poisoning Network Flow Classifiers,"Giorgio Severi, Simona Boboila, Alina Oprea, John Holodnak, Kendra Kratkiewicz, Jason Matterer",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01655"" target=""_blank"">2306.01655</a>",,2025-12-03 22:39:25
Hyperparameter Learning under Data Poisoning: Analysis of the Influence of Regularization via Multiobjective Bilevel Optimization,"Javier Carnerero-Cano, Luis Muñoz-González, Phillippa Spencer, Emil C. Lupu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01613"" target=""_blank"">2306.01613</a>",,2025-12-03 22:39:25
Invisible Image Watermarks Are Provably Removable Using Generative AI,"Xuandong Zhao, Kexun Zhang, Zihao Su, Saastha Vasan, Ilya Grishchenko, Christopher Kruegel, Giovanni Vigna, Yu-Xiang Wang, Lei Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01953"" target=""_blank"">2306.01953</a>","<a href=""https://github.com/XuandongZhao/WatermarkAttacker"" target=""_blank"">XuandongZhao</a>",2025-12-03 22:39:25
Robust low-rank training via approximate orthonormal constraints,"Dayana Savostianova, Emanuele Zangrando, Gianluca Ceruti, Francesco Tudisco",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.01485"" target=""_blank"">2306.01485</a>",,2025-12-03 22:39:25
Malafide: a novel adversarial convolutive noise attack against deepfake and spoofing detection systems,"Michele Panariello, Wanying Ge, Hemlata Tak, Massimiliano Todisco, Nicholas Evans",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07655"" target=""_blank"">2306.07655</a>",,2025-12-03 22:39:25
DHBE: Data-free Holistic Backdoor Erasing in Deep Neural Networks via Restricted Adversarial Distillation,"Zhicong Yan, Shenghong Li, Ruijie Zhao, Yuan Tian, Yuanyuan Zhao",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08009"" target=""_blank"">2306.08009</a>","<a href=""https://github.com/yanzhicong/DHBE"" target=""_blank"">yanzhicong</a>",2025-12-03 22:39:25
Robustness of SAM: Segment Anything Under Corruptions and Beyond,"Yu Qiao, Chaoning Zhang, Taegoo Kang, Donghun Kim, Chenshuang Zhang, Choong Seon Hong",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07713"" target=""_blank"">2306.07713</a>",,2025-12-03 22:39:25
Boosting Model Inversion Attacks with Adversarial Examples,"Shuai Zhou, Tianqing Zhu, Dayong Ye, Xin Yu, Wanlei Zhou",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13965"" target=""_blank"">2306.13965</a>",,2025-12-03 22:39:25
The race to robustness: exploiting fragile models for urban camouflage and the imperative for machine learning security,"Harriet Farlow, Matthew Garratt, Gavin Mount, Tim Lynar",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14609"" target=""_blank"">2306.14609</a>",,2025-12-03 22:39:25
3D-Aware Adversarial Makeup Generation for Facial Privacy Protection,"Yueming Lyu, Yue Jiang, Ziwen He, Bo Peng, Yunfan Liu, Jing Dong",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14640"" target=""_blank"">2306.14640</a>",,2025-12-03 22:39:25
Towards Sybil Resilience in Decentralized Learning,"Thomas Werthenbach, Johan Pouwelse",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15044"" target=""_blank"">2306.15044</a>",,2025-12-03 22:39:25
DSRM: Boost Textual Adversarial Training with Distribution Shift Risk Minimization,"Songyang Gao, Shihan Dou, Yan Liu, Xiao Wang, Qi Zhang, Zhongyu Wei, Jin Ma, Ying Shan",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15164"" target=""_blank"">2306.15164</a>",,2025-12-03 22:39:25
PWSHAP: A Path-Wise Explanation Model for Targeted Variables,"Lucile Ter-Minassian, Oscar Clivio, Karla Diaz-Ordaz, Robin J. Evans, Chris Holmes",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14672"" target=""_blank"">2306.14672</a>",,2025-12-03 22:39:25
A Spectral Perspective towards Understanding and Improving Adversarial Robustness,"Binxiao Huang, Rui Lin, Chaofan Tao, Ngai Wong",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14262"" target=""_blank"">2306.14262</a>",,2025-12-03 22:39:25
On Evaluating the Adversarial Robustness of Semantic Segmentation Models,"Levente Halmosi, Mark Jelasity",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14217"" target=""_blank"">2306.14217</a>",,2025-12-03 22:39:25
Robust Spatiotemporal Traffic Forecasting with Reinforced Dynamic Adversarial Training,"Fan Liu, Weijia Zhang, Hao Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14126"" target=""_blank"">2306.14126</a>","<a href=""https://github.com/usail-hkust/RDAT"" target=""_blank"">usail-hkust</a>",2025-12-03 22:39:25
Enhancing Adversarial Training via Reweighting Optimization Trajectory,"Tianjin Huang, Shiwei Liu, Tianlong Chen, Meng Fang, Li Shen, Vlaod Menkovski, Lu Yin, Yulong Pei, Mykola Pechenizkiy",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14275"" target=""_blank"">2306.14275</a>",,2025-12-03 22:39:25
RobuT: A Systematic Study of Table QA Robustness Against Human-Annotated Adversarial Perturbations,"Yilun Zhao, Chen Zhao, Linyong Nan, Zhenting Qi, Wenlin Zhang, Xiangru Tang, Boyu Mi, Dragomir Radev",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14321"" target=""_blank"">2306.14321</a>","<a href=""https://github.com/yilunzhao/RobuT"" target=""_blank"">yilunzhao</a>",2025-12-03 22:39:25
Computational Asymmetries in Robust Classification,"Samuele Marro, Michele Lombardi",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14326"" target=""_blank"">2306.14326</a>",,2025-12-03 22:39:25
Machine Learning needs Better Randomness Standards: Randomised Smoothing and PRNG-based attacks,"Pranav Dahiya, Ilia Shumailov, Ross Anderson",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14043"" target=""_blank"">2306.14043</a>",,2025-12-03 22:39:25
On the Universal Adversarial Perturbations for Efficient Data-free Adversarial Detection,"Songyang Gao, Shihan Dou, Qi Zhang, Xuanjing Huang, Jin Ma, Ying Shan",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15705"" target=""_blank"">2306.15705</a>",,2025-12-03 22:39:25
Similarity Preserving Adversarial Graph Contrastive Learning,"Yeonjun In, Kanghoon Yoon, Chanyoung Park",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13854"" target=""_blank"">2306.13854</a>","<a href=""https://github.com/yeonjun-in/torch-SP-AGCL"" target=""_blank"">yeonjun-in</a>",2025-12-03 22:39:25
Weighted Automata Extraction and Explanation of Recurrent Neural Networks for Natural Language Tasks,"Zeming Wei, Xiyue Zhang, Yihao Zhang, Meng Sun",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14040"" target=""_blank"">2306.14040</a>",,2025-12-03 22:39:25
Creating Valid Adversarial Examples of Malware,"Matouš Kozák, Martin Jureček, Mark Stamp, Troia Fabio Di",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13587"" target=""_blank"">2306.13587</a>",,2025-12-03 22:39:25
Adversarial Robustness Certification for Bayesian Neural Networks,"Matthew Wicker, Andrea Patane, Luca Laurenti, Marta Kwiatkowska",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13614"" target=""_blank"">2306.13614</a>",,2025-12-03 22:39:25
A First Order Meta Stackelberg Method for Robust Federated Learning,"Yunian Pan, Tao Li, Henger Li, Tianyi Xu, Zizhan Zheng, Quanyan Zhu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13800"" target=""_blank"">2306.13800</a>",,2025-12-03 22:39:25
Visual Adversarial Examples Jailbreak Large Language Models,"Xiangyu Qi, Kaixuan Huang, Ashwinee Panda, Mengdi Wang, Prateek Mittal",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13213"" target=""_blank"">2306.13213</a>",,2025-12-03 22:39:25
Towards quantum enhanced adversarial robustness in machine learning,"Maxwell T. West, Shu-Lok Tsang, Jia S. Low, Charles D. Hill, Christopher Leckie, Lloyd C. L. Hollenberg, Sarah M. Erfani, Muhammad Usman",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12688"" target=""_blank"">2306.12688</a>",,2025-12-03 22:39:25
Rethinking the Backward Propagation for Adversarial Transferability,"Xiaosen Wang, Kangheng Tong, Kun He",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12685"" target=""_blank"">2306.12685</a>","<a href=""https://github.com/Trustworthy-AI-Group/RPA"" target=""_blank"">Trustworthy-AI-Group</a>",2025-12-03 22:39:25
Evading Forensic Classifiers with Attribute-Conditioned Adversarial Faces,"Fahad Shamshad, Koushik Srivatsan, Karthik Nandakumar",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13091"" target=""_blank"">2306.13091</a>","<a href=""https://github.com/koushiksrivats/face_attribute_attack"" target=""_blank"">koushiksrivats</a>",2025-12-03 22:39:25
Adversarial Resilience in Sequential Prediction via Abstention,"Surbhi Goel, Steve Hanneke, Shay Moran, Abhishek Shetty",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13119"" target=""_blank"">2306.13119</a>",,2025-12-03 22:39:25
Document Image Cleaning using Budget-Aware Black-Box Approximation,"Ganesh Tata, Katyani Singh, Oeveren Eric Van, Nilanjan Ray",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13236"" target=""_blank"">2306.13236</a>",,2025-12-03 22:39:25
Are aligned neural networks adversarially aligned? (99%),"Nicholas Carlini, Milad Nasr, Christopher A. Choquette-Choo, Matthew Jagielski, Irena Gao, Anas Awadalla, Pang Wei Koh, Daphne Ippolito, Katherine Lee, Florian Tramer, Ludwig Schmidt",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15447"" target=""_blank"">2306.15447</a>",,2025-12-03 22:39:25
Shilling Black-box Review-based Recommender Systems through Fake Review Generation,"Hung-Yun Chiang, Yi-Syuan Chen, Yun-Zhu Song, Hong-Han Shuai, Jason S. Chang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16526"" target=""_blank"">2306.16526</a>",,2025-12-03 22:39:25
Towards Reliable Evaluation and Fast Training of Robust Semantic Segmentation Models,"Francesco Croce, Naman D Singh, Matthias Hein",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12941"" target=""_blank"">2306.12941</a>","<a href=""https://github.com/nmndeep/robust-segmentation"" target=""_blank"">nmndeep</a>",2025-12-03 22:39:25
Group-based Robustness: A General Framework for Customized Robustness in the Real World,"Weiran Lin, Keane Lucas, Neo Eyal, Lujo Bauer, Michael K. Reiter, Mahmood Sharif",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16614"" target=""_blank"">2306.16614</a>",,2025-12-03 22:39:25
Efficient Backdoor Removal Through Natural Gradient Fine-tuning,"Nazmul Karim, Abdullah Al Arafat, Umar Khalid, Zhishan Guo, Naznin Rahnavard",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.17441"" target=""_blank"">2306.17441</a>",,2025-12-03 22:39:25
Minimum-norm Sparse Perturbations for Opacity in Linear Systems,"Varkey M John, Vaibhav Katewa",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.17606"" target=""_blank"">2306.17606</a>",,2025-12-03 22:39:25
Defense against Adversarial Cloud Attack on Remote Sensing Salient Object Detection,"Huiming Sun, Lan Fu, Jinlong Li, Qing Guo, Zibo Meng, Tianyun Zhang, Yuewei Lin, Hongkai Yu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.17431"" target=""_blank"">2306.17431</a>",,2025-12-03 22:39:25
Post-train Black-box Defense via Bayesian Boundary Correction,"He Wang, Yunfeng Diao",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16979"" target=""_blank"">2306.16979</a>",,2025-12-03 22:39:25
Towards Optimal Randomized Strategies in Adversarial Example Game,"Jiahao Xie, Chao Zhang, Weijie Liu, Wensong Bai, Hui Qian",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16738"" target=""_blank"">2306.16738</a>",,2025-12-03 22:39:25
Neural Polarizer: A Lightweight and Effective Backdoor Defense via Purifying Poisoned Features,"Mingli Zhu, Shaokui Wei, Hongyuan Zha, Baoyuan Wu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16697"" target=""_blank"">2306.16697</a>",,2025-12-03 22:39:25
NeuralFuse: Learning to Recover the Accuracy of Access-Limited Neural Network Inference in Low-Voltage Regimes,"Hao-Lun Sun, Lei Hsiung, Nandhini Chandramoorthy, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16869"" target=""_blank"">2306.16869</a>","<a href=""https://github.com/IBM/NeuralFuse"" target=""_blank"">IBM</a>",2025-12-03 22:39:25
Boosting Adversarial Transferability with Learnable Patch-wise Masks,"Xingxing Wei, Shiji Zhao",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15931"" target=""_blank"">2306.15931</a>",,2025-12-03 22:39:25
I See Dead People: Gray-Box Adversarial Attack on Image-To-Text Models,"Raz Lapid, Moshe Sipper",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07591"" target=""_blank"">2306.07591</a>",,2025-12-03 22:39:25
Evaluating Similitude and Robustness of Deep Image Denoising Models via Adversarial Attack,"Jie Ning, Yao Li, Zhichang Guo",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16050"" target=""_blank"">2306.16050</a>",,2025-12-03 22:39:25
Mitigating Accuracy-Robustness Trade-off via Balanced Multi-Teacher Adversarial Distillation,"Shiji Zhao, Xizhe Wang, Xingxing Wei",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16170"" target=""_blank"">2306.16170</a>",,2025-12-03 22:39:25
Distributional Modeling for Location-Aware Adversarial Patches,"Xingxing Wei, Shouwei Ruan, Yinpeng Dong, Hang Su",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16131"" target=""_blank"">2306.16131</a>",,2025-12-03 22:39:25
Catch Me If You Can: A New Low-Rate DDoS Attack Strategy Disguised by Feint,"Tianyang Cai, Yuqi Li, Tao Jia, Leo Yu Zhang, Zheng Yang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15248"" target=""_blank"">2306.15248</a>",,2025-12-03 22:39:25
Enrollment-stage Backdoor Attacks on Speaker Recognition Systems via Adversarial Ultrasound,"Xinfeng Li, Junning Ze, Chen Yan, Yushi Cheng, Xiaoyu Ji, Wenyuan Xu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16022"" target=""_blank"">2306.16022</a>",,2025-12-03 22:39:25
Does Saliency-Based Training bring Robustness for Deep Neural Networks in Image Classification? (93%),Ali Karkehabadi,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16581"" target=""_blank"">2306.16581</a>",,2025-12-03 22:39:25
On Practical Aspects of Aggregation Defenses against Data Poisoning Attacks,"Wenxiao Wang, Soheil Feizi",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.16415"" target=""_blank"">2306.16415</a>",,2025-12-03 22:39:25
On the Exploitability of Instruction Tuning,"Manli Shu, Jiongxiao Wang, Chen Zhu, Jonas Geiping, Chaowei Xiao, Tom Goldstein",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.17194"" target=""_blank"">2306.17194</a>","<a href=""https://github.com/azshue/AutoPoison"" target=""_blank"">azshue</a>",2025-12-03 22:39:25
Advancing Adversarial Training by Injecting Booster Signal,"Hong Joo Lee, Youngjoon Yu, Yong Man Ro",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15451"" target=""_blank"">2306.15451</a>",,2025-12-03 22:39:25
IMPOSITION: Implicit Backdoor Attack through Scenario Injection,"Mozhgan Pourkeshavarz, Mohammad Sabokrou, Amir Rasouli",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15755"" target=""_blank"">2306.15755</a>",,2025-12-03 22:39:25
"Adversarial Training for Graph Neural Networks: Pitfalls, Solutions, and New Directions","Lukas Gosch, Simon Geisler, Daniel Sturm, Bertrand Charpentier, Daniel Zügner, Stephan Günnemann",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15427"" target=""_blank"">2306.15427</a>",,2025-12-03 22:39:25
Robust Proxy: Improving Adversarial Robustness by Robust Proxy Learning,"Hong Joo Lee, Yong Man Ro",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15457"" target=""_blank"">2306.15457</a>",,2025-12-03 22:39:25
Your Attack Is Too DUMB: Formalizing Attacker Scenarios for Adversarial Transferability,"Marco Alecci, Mauro Conti, Francesco Marchiori, Luca Martinelli, Luca Pajola",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15363"" target=""_blank"">2306.15363</a>",,2025-12-03 22:39:25
[Re] Double Sampling Randomized Smoothing,"Aryan Gupta, Sarthak Gupta, Abhay Kumar, Harsh Dugar",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15221"" target=""_blank"">2306.15221</a>",,2025-12-03 22:39:25
Cooperation or Competition: Avoiding Player Domination for Multi-Target Robustness via Adaptive Budgets,"Yimu Wang, Dinghuai Zhang, Yihan Wu, Heng Huang, Hongyang Zhang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.15482"" target=""_blank"">2306.15482</a>",,2025-12-03 22:39:25
Anticipatory Thinking Challenges in Open Worlds: Risk Management,"Adam Amos-Binks, Dustin Dannenhauer, Leilani H. Gilpin",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13157"" target=""_blank"">2306.13157</a>",,2025-12-03 22:39:25
On the Resilience of Machine Learning-Based IDS for Automotive Networks,"Ivo Zenden, Han Wang, Alfonso Iacovazzi, Arash Vahidi, Rolf Blom, Shahid Raza",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.14782"" target=""_blank"">2306.14782</a>",,2025-12-03 22:39:25
"Cross-lingual Cross-temporal Summarization: Dataset, Models, Evaluation","Ran Zhang, Jihed Ouni, Steffen Eger",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12916"" target=""_blank"">2306.12916</a>",,2025-12-03 22:39:25
Community Detection Attack against Collaborative Learning-based Recommender Systems,"Yacine Belal, Sonia Ben Mokhtar, Mohamed Maouche, Anthony Simonet-Boulogne",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08929"" target=""_blank"">2306.08929</a>",,2025-12-03 22:39:25
Query-Free Evasion Attacks Against Machine Learning-Based Malware Detectors with Generative Adversarial Networks,"Daniel Gibert, Jordi Planes, Quan Le, Giulio Zizzo",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09925"" target=""_blank"">2306.09925</a>",,2025-12-03 22:39:25
You Don't Need Robust Machine Learning to Manage Adversarial Attack Risks,"Edward Raff, Michel Benaroch, Andrew L. Farris",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09951"" target=""_blank"">2306.09951</a>",,2025-12-03 22:39:25
Towards Better Certified Segmentation via Diffusion Models,"Othmane Laousy, Alexandre Araujo, Guillaume Chassagnon, Marie-Pierre Revel, Siddharth Garg, Farshad Khorrami, Maria Vakalopoulou",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09949"" target=""_blank"">2306.09949</a>",,2025-12-03 22:39:25
Adversarially robust clustering with optimality guarantees,"Soham Jana, Kun Yang, Sanjeev Kulkarni",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09977"" target=""_blank"">2306.09977</a>",,2025-12-03 22:39:25
CLIP2Protect: Protecting Facial Privacy using Text-Guided Makeup via Adversarial Latent Search,"Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10008"" target=""_blank"">2306.10008</a>","<a href=""https://github.com/fahadshamshad/Clip2Protect"" target=""_blank"">fahadshamshad</a>",2025-12-03 22:39:25
DIFFender: Diffusion-Based Adversarial Defense against Patch Attacks in the Physical World,"Caixin Kang, Yinpeng Dong, Zhengyi Wang, Shouwei Ruan, Hang Su, Xingxing Wei",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09124"" target=""_blank"">2306.09124</a>",,2025-12-03 22:39:25
OVLA: Neural Network Ownership Verification using Latent Watermarks,"Feisi Fu, Wenchao Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13215"" target=""_blank"">2306.13215</a>",,2025-12-03 22:39:25
On Strengthening and Defending Graph Reconstruction Attack with Markov Chain Approximation,"Zhanke Zhou, Chenyu Zhou, Xuan Li, Jiangchao Yao, Quanming Yao, Bo Han",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09104"" target=""_blank"">2306.09104</a>","<a href=""https://github.com/tmlr-group/MC-GRA"" target=""_blank"">tmlr-group</a>",2025-12-03 22:39:25
Robustness Analysis on Foundational Segmentation Models,"Madeline Chantry Schiappa, Sachidanand VS, Yunhao Ge, Ondrej Miksik, Yogesh S. Rawat, Vibhav Vineet",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09278"" target=""_blank"">2306.09278</a>",,2025-12-03 22:39:25
DiffAug: A Diffuse-and-Denoise Augmentation for Training Robust Classifiers,"Chandramouli Sastry, Sri Harsha Dumpala, Sageev Oore",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09192"" target=""_blank"">2306.09192</a>",,2025-12-03 22:39:25
"Explore, Establish, Exploit: Red Teaming Language Models from Scratch","Stephen Casper, Jason Lin, Joe Kwon, Gatlen Culp, Dylan Hadfield-Menell",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09442"" target=""_blank"">2306.09442</a>",,2025-12-03 22:39:25
Concealing CAN Message Sequences to Prevent Schedule-based Bus-off Attacks,"Sunandan Adhikary, Ipsita Koley, Arkaprava Sain, Soumyadeep das, Shuvam Saha, Soumyajit Dey",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09206"" target=""_blank"">2306.09206</a>",,2025-12-03 22:39:25
Bkd-FedGNN: A Benchmark for Classification Backdoor Attacks on Federated Graph Neural Network,"Fan Liu, Siqi Lai, Yansong Ning, Hao Liu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10351"" target=""_blank"">2306.10351</a>","<a href=""https://github.com/usail-hkust/BkdFedGCN"" target=""_blank"">usail-hkust</a>",2025-12-03 22:39:25
Reliable Evaluation of Adversarial Transferability,"Wenqian Yu, Jindong Gu, Zhijiang Li, Philip Torr",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08565"" target=""_blank"">2306.08565</a>","<a href=""https://adv-trans-eval.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
A Relaxed Optimization Approach for Adversarial Attacks against Neural Machine Translation Models,"Sahar Sadrizadeh, Clément Barbier, Ljiljana Dolamic, Pascal Frossard",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08492"" target=""_blank"">2306.08492</a>",,2025-12-03 22:39:25
X-Detect: Explainable Adversarial Patch Detection for Object Detectors in Retail,"Omer Hofman, Amit Giloni, Yarin Hayun, Ikuya Morikawa, Toshiya Shimizu, Yuval Elovici, Asaf Shabtai",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08422"" target=""_blank"">2306.08422</a>",,2025-12-03 22:39:25
"Finite Gaussian Neurons: Defending against adversarial attacks by making neural networks say ""I don't know""",Felix Grezes,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07796"" target=""_blank"">2306.07796</a>",,2025-12-03 22:39:25
A First Order Meta Stackelberg Method for Robust Federated Learning (Technical Report),"Henger Li, Tianyi Xu, Tao Li, Yunian Pan, Quanyan Zhu, Zizhan Zheng",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13273"" target=""_blank"">2306.13273</a>",,2025-12-03 22:39:25
Theoretical Foundations of Adversarially Robust Learning,Omar Montasser,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.07723"" target=""_blank"">2306.07723</a>",,2025-12-03 22:39:25
Improving Selective Visual Question Answering by Learning from Your Peers,"Corentin Dancette, Spencer Whitehead, Rishabh Maheshwary, Ramakrishna Vedantam, Stefan Scherer, Xinlei Chen, Matthieu Cord, Marcus Rohrbach",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08751"" target=""_blank"">2306.08751</a>",,2025-12-03 22:39:25
A Proxy Attack-Free Strategy for Practically Improving the Poisoning Efficiency in Backdoor Attacks,"Ziqiang Li, Hong Sun, Pengfei Xia, Beihao Xia, Xue Rui, Wei Zhang, Qinglang Guo, Bin Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08313"" target=""_blank"">2306.08313</a>",,2025-12-03 22:39:25
Augment then Smooth: Reconciling Differential Privacy with Certified Robustness,"Jiapeng Wu, Atiyeh Ashari Ghomi, David Glukhov, Jesse C. Cresswell, Franziska Boenisch, Nicolas Papernot",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08656"" target=""_blank"">2306.08656</a>",,2025-12-03 22:39:25
Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios,"Ziqiang Li, Hong Sun, Pengfei Xia, Heng Li, Beihao Xia, Yi Wu, Bin Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08386"" target=""_blank"">2306.08386</a>","<a href=""https://github.com/sunh1113/Efficient-backdoor-attacks-for-deep-neural-networks-in-real-world-scenarios"" target=""_blank"">sunh1113</a>",2025-12-03 22:39:25
On the Robustness of Latent Diffusion Models,"Jianping Zhang, Zhuoer Xu, Shiwen Cui, Changhua Meng, Weibin Wu, Michael R. Lyu",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08257"" target=""_blank"">2306.08257</a>","<a href=""https://github.com/jpzhang1810/LDM-Robustness"" target=""_blank"">jpzhang1810</a>",2025-12-03 22:39:25
Wasserstein distributional robustness of neural networks,"Xingjian Bai, Guangyi He, Yifan Jiang, Jan Obloj",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.09844"" target=""_blank"">2306.09844</a>","<a href=""https://github.com/JanObloj/W-DRO-Adversarial-Methods"" target=""_blank"">JanObloj</a>",2025-12-03 22:39:25
Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks,"Hongcheng Gao, Hao Zhang, Yinpeng Dong, Zhijie Deng",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13103"" target=""_blank"">2306.13103</a>",,2025-12-03 22:39:25
GlyphNet: Homoglyph domains dataset and detection using attention-based Convolutional Neural Networks,"Akshat Gupta, Laxman Singh Tomar, Ridhima Garg",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10392"" target=""_blank"">2306.10392</a>",,2025-12-03 22:39:25
DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models,"Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang, Chenhui Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, Sang T. Truong, Simran Arora, Mantas Mazeika, Dan Hendrycks, Zinan Lin, Yu Cheng, Sanmi Koyejo, Dawn Song, Bo Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11698"" target=""_blank"">2306.11698</a>","<a href=""https://decodingtrust.github.io/"" target=""_blank"">decodingtrust.github.io</a>",2025-12-03 22:39:25
Impacts and Risk of Generative AI Technology on Cyber Defense,"Subash Neupane, Ivan A. Fernandez, Sudip Mittal, Shahram Rahimi",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.13033"" target=""_blank"">2306.13033</a>",,2025-12-03 22:39:25
Adversarial Attacks Neutralization via Data Set Randomization,"Mouna Rabhi, Pietro Roberto Di",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12161"" target=""_blank"">2306.12161</a>",,2025-12-03 22:39:25
A Comprehensive Study on the Robustness of Image Classification and Object Detection in Remote Sensing: Surveying and Benchmarking,"Shaohui Mei, Jiawei Lian, Xiaofei Wang, Yuru Su, Mingyang Ma, Lap-Pui Chau",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12111"" target=""_blank"">2306.12111</a>",,2025-12-03 22:39:25
Sample Attackability in Natural Language Adversarial Attacks,"Vyas Raina, Mark Gales",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12043"" target=""_blank"">2306.12043</a>",,2025-12-03 22:39:25
Revisiting Image Classifier Training for Improved Certified Robust Defense against Adversarial Patches,"Aniruddha Saha, Shuhua Yu, Arash Norouzzadeh, Wan-Yi Lin, Chaithanya Kumar Mummadi",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12610"" target=""_blank"">2306.12610</a>",,2025-12-03 22:39:25
DP-BREM: Differentially-Private and Byzantine-Robust Federated Learning with Client Momentum,"Xiaolan Gu, Ming Li, Li Xiong",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12608"" target=""_blank"">2306.12608</a>",,2025-12-03 22:39:25
Understanding Certified Training with Interval Bound Propagation,"Yuhao Mao, Mark Niklas Müller, Marc Fischer, Martin Vechev",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10426"" target=""_blank"">2306.10426</a>",,2025-12-03 22:39:25
Reversible Adversarial Examples with Beam Search Attack and Grayscale Invariance,"Haodong Zhang, Chi Man Pun, Xia Du",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11322"" target=""_blank"">2306.11322</a>",,2025-12-03 22:39:25
Universal adversarial perturbations for multiple classification tasks with quantum classifiers,Yun-Zhong Qiu,arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11974"" target=""_blank"">2306.11974</a>",,2025-12-03 22:39:25
Physics-constrained Attack against Convolution-based Human Motion Prediction,"Chengxu Duan, Zhicheng Zhang, Xiaoli Liu, Yonghao Dang, Jianqin Yin",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11990"" target=""_blank"">2306.11990</a>",,2025-12-03 22:39:25
FDINet: Protecting against DNN Model Extraction via Feature Distortion Index,"Hongwei Yao, Zheng Li, Haiqin Weng, Feng Xue, Zhan Qin, Kui Ren",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11338"" target=""_blank"">2306.11338</a>",,2025-12-03 22:39:25
FFCV: Accelerating Training by Removing Data Bottlenecks,"Guillaume Leclerc, Andrew Ilyas, Logan Engstrom, Sung Min Park, Hadi Salman, Aleksander Madry",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.12517"" target=""_blank"">2306.12517</a>",,2025-12-03 22:39:25
Towards a robust and reliable deep learning approach for detection of compact binary mergers in gravitational wave data,"Shreejit Jadhav, Mihir Shrivastava, Sanjit Mitra",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11797"" target=""_blank"">2306.11797</a>",,2025-12-03 22:39:25
Adversarial Robustness of Prompt-based Few-Shot Learning for Natural Language Understanding,"Venkata Prabhakara Sarath Nookala, Gaurav Verma, Subhabrata Mukherjee, Srijan Kumar",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11066"" target=""_blank"">2306.11066</a>",,2025-12-03 22:39:25
"Edge Learning for 6G-enabled Internet of Things: A Comprehensive Survey of Vulnerabilities, Datasets, and Defenses","Mohamed Amine Ferrag, Othmane Friha, Burak Kantarci, Norbert Tihanyi, Lucas Cordeiro, Merouane Debbah, Djallel Hamouda, Muna Al-Hawawreh, Kim-Kwang Raymond Choo",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10309"" target=""_blank"">2306.10309</a>",,2025-12-03 22:39:25
BNN-DP: Robustness Certification of Bayesian Neural Networks via Dynamic Programming,"Steven Adams, Andrea Patane, Morteza Lahijanian, Luca Laurenti",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10742"" target=""_blank"">2306.10742</a>",,2025-12-03 22:39:25
Practical and General Backdoor Attacks against Vertical Federated Learning,"Yuexin Xuan, Xiaojun Chen, Zhendong Zhao, Bisheng Tang, Ye Dong",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10746"" target=""_blank"">2306.10746</a>",,2025-12-03 22:39:25
Eigenpatches -- Adversarial Patches from Principal Components,"Jens Bayer, Stefan Becker, David Münch, Michael Arens",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.10963"" target=""_blank"">2306.10963</a>",,2025-12-03 22:39:25
Adversarial Training Should Be Cast as a Non-Zero-Sum Game,"Alexander Robey, Fabian Latorre, George J. Pappas, Hamed Hassani, Volkan Cevher",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11035"" target=""_blank"">2306.11035</a>",,2025-12-03 22:39:25
A Unified Framework of Graph Information Bottleneck for Robustness and Membership Privacy,"Enyan Dai, Limeng Cui, Zhengyang Wang, Xianfeng Tang, Yinghan Wang, Monica Cheng, Bing Yin, Suhang Wang",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.08604"" target=""_blank"">2306.08604</a>",,2025-12-03 22:39:25
Mitigating Speculation-based Attacks through Configurable Hardware/Software Co-design,"Ali Hajiabadi, Archit Agarwal, Andreas Diavastos, Trevor E. Carlson",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11291"" target=""_blank"">2306.11291</a>",,2025-12-03 22:39:25
LVM-Med: Learning Large-Scale Self-Supervised Vision Models for Medical Imaging via Second-order Graph Matching,"Duy M. H. Nguyen, Hoang Nguyen, Nghiem T. Diep, Tan N. Pham, Tri Cao, Binh T. Nguyen, Paul Swoboda, Nhat Ho, Shadi Albarqouni, Pengtao Xie, Daniel Sonntag, Mathias Niepert",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11925"" target=""_blank"">2306.11925</a>",,2025-12-03 22:39:25
Comparative Evaluation of Recent Universal Adversarial Perturbations in Image Classification,"Juanjuan Weng, Zhiming Luo, Dazhen Lin, Shaozi Li",arXiv,2023-06,"<a href=""http://arxiv.org/abs/2306.11261"" target=""_blank"">2306.11261</a>",,2025-12-03 22:39:25
Training Neural Networks without Backpropagation: A Deeper Dive into the Likelihood Ratio Method,"Jinyang Jiang, Zeliang Zhang, Chenliang Xu, Zhaofei Yu, Yijie Peng",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08960"" target=""_blank"">2305.08960</a>",,2025-12-03 22:39:25
On enhancing the robustness of Vision Transformers: Defensive Diffusion,"Raza Imam, Muhammad Huzaifa, Mohammed El-Amine Azz",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08031"" target=""_blank"">2305.08031</a>",,2025-12-03 22:39:25
"Assessing Hidden Risks of LLMs: An Empirical Study on Robustness, Consistency, and Credibility","Wentao Ye, Mingfeng Ou, Tianyi Li, Yipeng chen, Xuetao Ma, Yifan Yanggong, Sai Wu, Jie Fu, Gang Chen, Haobo Wang, Junbo Zhao",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10235"" target=""_blank"">2305.10235</a>",,2025-12-03 22:39:25
Diffusion Models for Imperceptible and Transferable Adversarial Attack,"Jianqi Chen, Hao Chen, Keyan Chen, Yilan Zhang, Zhengxia Zou, Zhenwei Shi",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08192"" target=""_blank"">2305.08192</a>",,2025-12-03 22:39:25
Improving Defensive Distillation using Teacher Assistant,"Maniratnam Mandal, Suna Gao",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08076"" target=""_blank"">2305.08076</a>",,2025-12-03 22:39:25
Manipulating Visually-aware Federated Recommender Systems and Its Countermeasures,"Wei Yuan, Shilong Yuan, Chaoqun Yang, Quoc Viet Hung Nguyen, Hongzhi Yin",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08183"" target=""_blank"">2305.08183</a>",,2025-12-03 22:39:25
Watermarking Text Generated by Black-Box Language Models,"Xi Yang, Kejiang Chen, Weiming Zhang, Chang Liu, Yuang Qi, Jie Zhang, Han Fang, Nenghai Yu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08883"" target=""_blank"">2305.08883</a>",,2025-12-03 22:39:25
The Robustness of Computer Vision Models against Common Corruptions: a Survey,"Shunxin Wang, Raymond Veldhuis, Nicola Strisciuglio",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.06024"" target=""_blank"">2305.06024</a>",,2025-12-03 22:39:25
DNN-Defender: A Victim-Focused In-DRAM Defense Mechanism for Taming Adversarial Weight Attack on DNNs,"Ranyang Zhou, Sabbir Ahmed, Adnan Siraj Rakin, Shaahin Angizi",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08034"" target=""_blank"">2305.08034</a>",,2025-12-03 22:39:25
Decision-based iterative fragile watermarking for model integrity verification,"Zhaoxia Yin, Heng Yin, Hang Su, Xinpeng Zhang, Zhenzhe Gao",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09684"" target=""_blank"">2305.09684</a>",,2025-12-03 22:39:25
Efficient Search of Comprehensively Robust Neural Architectures via Multi-fidelity Evaluation,"Jialiang Sun, Wen Yao, Tingsong Jiang, Xiaoqian Chen",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.07308"" target=""_blank"">2305.07308</a>",,2025-12-03 22:39:25
Adversarial Security and Differential Privacy in mmWave Beam Prediction in 6G networks,"Ghanta Sai Krishna, Kundrapu Supriya, Sanskar Singh, Sabur Baidya",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09679"" target=""_blank"">2305.09679</a>",,2025-12-03 22:39:25
Stealthy Low-frequency Backdoor Attack against Deep Neural Networks,"Xinrui Liu, Yu-an Tan, Yajie Wang, Kefan Qiu, Yuanzhang Li",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09677"" target=""_blank"">2305.09677</a>",,2025-12-03 22:39:25
Towards Invisible Backdoor Attacks in the Frequency Domain against Deep Neural Networks,"Xinrui Liu, Yajie Wang, Yu-an Tan, Kefan Qiu, Yuanzhang Li",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10596"" target=""_blank"">2305.10596</a>",,2025-12-03 22:39:25
Distracting Downpour: Adversarial Weather Attacks for Motion Estimation,"Jenny Schmalfuss, Lukas Mehl, Andrés Bruhn",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.06716"" target=""_blank"">2305.06716</a>",,2025-12-03 22:39:25
Randomized Smoothing with Masked Inference for Adversarially Robust Text Classifications,"Han Cheol Moon, Shafiq Joty, Ruochen Zhao, Megh Thakkar, Xu Chi",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.06522"" target=""_blank"">2305.06522</a>","<a href=""https://github.com/Han8931/rsmi_nlp"" target=""_blank"">Han8931</a>",2025-12-03 22:39:25
Watch This Space: Securing Satellite Communication through Resilient Transmitter Fingerprinting,"Joshua Smailes, Sebastian Kohler, Simon Birnbach, Martin Strohmeier, Ivan Martinovic",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.06947"" target=""_blank"">2305.06947</a>",,2025-12-03 22:39:25
A Black-Box Attack on Code Models via Representation Nearest Neighbor Search,"Jie Zhang, Wei Ma, Qiang Hu, Shangqing Liu, Xiaofei Xie, Yves Le Traon, Yang Liu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.05896"" target=""_blank"">2305.05896</a>",,2025-12-03 22:39:25
Inter-frame Accelerate Attack against Video Interpolation Models,"Junpei Liao, Zhikai Chen, Liang Yi, Wenyuan Yang, Baoyuan Wu, Xiaochun Cao",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.06540"" target=""_blank"">2305.06540</a>",,2025-12-03 22:39:25
Mastering Percolation-like Games with Deep Learning,"Michael M. Danziger, Omkar R. Gojala, Sean P. Cornelius",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.07687"" target=""_blank"">2305.07687</a>",,2025-12-03 22:39:25
Towards an Accurate and Secure Detector against Adversarial Perturbations,"Chao Wang, Shuren Qi, Zhiqiu Huang, Yushu Zhang, Xiaochun Cao",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10856"" target=""_blank"">2305.10856</a>",,2025-12-03 22:39:25
Exploiting Frequency Spectrum of Adversarial Images for General Robustness,"Chun Yang Tan, Kazuhiko Kawamoto, Hiroshi Kera",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08439"" target=""_blank"">2305.08439</a>",,2025-12-03 22:39:25
Zero-Day Backdoor Attack against Text-to-Image Diffusion Models via Personalization,"Yihao Huang, Qing Guo, Felix Juefei-Xu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10701"" target=""_blank"">2305.10701</a>",,2025-12-03 22:39:25
Robust multi-agent coordination via evolutionary generation of auxiliary adversarial attackers,"Lei Yuan, Zi-Qian Zhang, Ke Xue, Hao Yin, Feng Chen, Cong Guan, Li-He Li, Chao Qian, Yang Yu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.05909"" target=""_blank"">2305.05909</a>",,2025-12-03 22:39:25
Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning,"Mustafa Safa Ozdayi, Charith Peris, Jack FitzGerald, Christophe Dupuy, Jimit Majmudar, Haidar Khan, Rahil Parikh, Rahul Gupta",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11759"" target=""_blank"">2305.11759</a>",,2025-12-03 22:39:25
Deep PackGen: A Deep Reinforcement Learning Framework for Adversarial Network Packet Generation,"Soumyadeep Hore, Jalal Ghadermazi, Diwas Paudel, Ankit Shah, Tapas K. Das, Nathaniel D. Bastian",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11039"" target=""_blank"">2305.11039</a>",,2025-12-03 22:39:25
Adversarial Amendment is the Only Force Capable of Transforming an Enemy into a Friend,"Chong Yu, Tao Chen, Zhongxue Gan",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10766"" target=""_blank"">2305.10766</a>",,2025-12-03 22:39:25
Architecture-agnostic Iterative Black-box Certified Defense against Adversarial Patches,"Di Yang, Yihao Huang, Qing Guo, Felix Juefei-Xu, Ming Hu, Yang Liu, Geguang Pu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10929"" target=""_blank"">2305.10929</a>",,2025-12-03 22:39:25
Quantifying the robustness of deep multispectral segmentation models against natural perturbations and data poisoning,"Elise Bishoff, Charles Godfrey, Myles McKay, Eleanor Byler",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11347"" target=""_blank"">2305.11347</a>",,2025-12-03 22:39:25
How Deep Learning Sees the World: A Survey on Adversarial Attacks & Defenses,"Joana C. Costa, Tiago Roxo, Hugo Proença, Pedro R. M. Inácio",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10862"" target=""_blank"">2305.10862</a>",,2025-12-03 22:39:25
RobustFair: Adversarial Evaluation through Fairness Confusion Directed Gradient Search,"Xuran Li, Peng Wu, Kaixiang Dong, Zhen Zhang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10906"" target=""_blank"">2305.10906</a>",,2025-12-03 22:39:25
Attacks on Online Learners: a Teacher-Student Analysis,"Riccardo Giuseppe Margiotta, Sebastian Goldt, Guido Sanguinetti",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11132"" target=""_blank"">2305.11132</a>",,2025-12-03 22:39:25
Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture,"Galen Pogoncheff, Jacob Granley, Michael Beyeler",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11275"" target=""_blank"">2305.11275</a>",,2025-12-03 22:39:25
Large Language Models can be Guided to Evade AI-Generated Text Detection,"Ning Lu, Shengcai Liu, Rui He, Qi Wang, Yew-Soon Ong, Ke Tang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10847"" target=""_blank"">2305.10847</a>","<a href=""https://github.com/ColinLu50/Evade-GPT-Detector"" target=""_blank"">ColinLu50</a>",2025-12-03 22:39:25
SneakyPrompt: Evaluating Robustness of Text-to-image Generative Models' Safety Filters,"Yuchen Yang, Bo Hui, Haolin Yuan, Neil Gong, Yinzhi Cao",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12082"" target=""_blank"">2305.12082</a>",,2025-12-03 22:39:25
Attacking Perceptual Similarity Metrics,"Abhijay Ghildyal, Feng Liu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.08840"" target=""_blank"">2305.08840</a>",,2025-12-03 22:39:25
TrustSER: On the Trustworthiness of Fine-tuning Pre-trained Speech Embeddings For Speech Emotion Recognition,"Tiantian Feng, Rajat Hebbar, Shrikanth Narayanan",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11229"" target=""_blank"">2305.11229</a>","<a href=""https://github.com/usc-sail/trust-ser"" target=""_blank"">usc-sail</a>",2025-12-03 22:39:25
Content-based Unrestricted Adversarial Attack,"Zhaoyu Chen, Bo Li, Shuang Wu, Kaixun Jiang, Shouhong Ding, Wenqiang Zhang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10665"" target=""_blank"">2305.10665</a>",,2025-12-03 22:39:25
Raising the Bar for Certified Adversarial Robustness with Diffusion Models,"Thomas Altstidl, David Dobre, Björn Eskofier, Gauthier Gidel, Leo Schwinn",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10388"" target=""_blank"">2305.10388</a>",,2025-12-03 22:39:25
The Adversarial Consistency of Surrogate Risks for Binary Classification,"Natalie Frank, Jonathan Niles-Weed",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09956"" target=""_blank"">2305.09956</a>",,2025-12-03 22:39:25
Variational Classification,"Shehzaad Dhuliawala, Mrinmaya Sachan, Carl Allen",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10406"" target=""_blank"">2305.10406</a>",,2025-12-03 22:39:25
"Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt","Zhaozhuo Xu, Zirui Liu, Beidi Chen, Yuxin Tang, Jue Wang, Kaixiong Zhou, Xia Hu, Anshumali Shrivastava",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11186"" target=""_blank"">2305.11186</a>",,2025-12-03 22:39:25
PaLM 2 Technical Report,"Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey, Yanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan Botha, James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng, Colin Cherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, Clément Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark Díaz, Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, Guy Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey Hui, Jeremy Hurwitz, Michael Isard, Abe Ittycheriah, Matthew Jagielski, Wenhao Jia, Kathleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric Ni, Andrew Nystrom, Alicia Parrish, Marie Pellat, Martin Polacek, Alex Polozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel, Renee Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng, Ce Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, Yonghui Wu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10403"" target=""_blank"">2305.10403</a>",,2025-12-03 22:39:25
Iterative Adversarial Attack on Image-guided Story Ending Generation,"Youze Wang, Wenbo Hu, Richang Hong",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.13208"" target=""_blank"">2305.13208</a>",,2025-12-03 22:39:25
Releasing Inequality Phenomena in $L_{\infty}$-Adversarial Training via Input Gradient Distillation,"Junxi Chen, Junhao Dong, Xiaohua Xie",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09305"" target=""_blank"">2305.09305</a>",,2025-12-03 22:39:25
Ortho-ODE: Enhancing Robustness and of Neural ODEs against Adversarial Attacks,Vishal Purohit,arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09179"" target=""_blank"">2305.09179</a>",,2025-12-03 22:39:25
Unlearnable Examples Give a False Sense of Security: Piercing through Unexploitable Data with Learnable Examples,"Wan Jiang, Yunfeng Diao, He Wang, Jianxin Sun, Meng Wang, Richang Hong",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09241"" target=""_blank"">2305.09241</a>","<a href=""https://github.com/jiangw-0/LE_JCDP"" target=""_blank"">jiangw-0</a>",2025-12-03 22:39:25
An Empirical Study on the Robustness of the Segment Anything Model (SAM),"Yuqing Wang, Yun Zhao, Linda Petzold",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.06422"" target=""_blank"">2305.06422</a>",,2025-12-03 22:39:25
FedGrad: Mitigating Backdoor Attacks in Federated Learning Through Local Ultimate Gradients Inspection,"Thuy Dung Nguyen, Anh Duy Nguyen, Kok-Seng Wong, Huy Hieu Pham, Thanh Hung Nguyen, Phi Le Nguyen, Truong Thao Nguyen",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.00328"" target=""_blank"">2305.00328</a>",,2025-12-03 22:39:25
Quantization Aware Attack: Enhancing the Transferability of Adversarial Attacks across Target Models with Different Quantization Bitwidths,"Yulong Yang, Chenhao Lin, Qian Li, Chao Shen, Dawei Zhou, Nannan Wang, Tongliang Liu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.05875"" target=""_blank"">2305.05875</a>",,2025-12-03 22:39:25
Towards Imperceptible Document Manipulations against Neural Ranking Models,"Xuanang Chen, Ben He, Zheng Ye, Le Sun, Yingfei Sun",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.01860"" target=""_blank"">2305.01860</a>",,2025-12-03 22:39:25
Faulting original McEliece's implementations is possible: How to mitigate this risk? (2%),"Vincent Giraud, Guillaume Bouffard",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02855"" target=""_blank"">2305.02855</a>",,2025-12-03 22:39:25
New Adversarial Image Detection Based on Sentiment Analysis,"Yulong Wang, Tianxiang Li, Shenghong Li, Xin Yuan, Wei Ni",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.03173"" target=""_blank"">2305.03173</a>",,2025-12-03 22:39:25
A Data-Driven Defense against Edge-case Model Poisoning Attacks on Federated Learning,"Kiran Purohit, Soumi Das, Sourangshu Bhattacharya, Santu Rana",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02022"" target=""_blank"">2305.02022</a>",,2025-12-03 22:39:25
Defending against Insertion-based Textual Backdoor Attacks via Attribution,"Jiazhao Li, Zhuofeng Wu, Wei Ping, Chaowei Xiao, V. G. Vinod Vydiswaran",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02394"" target=""_blank"">2305.02394</a>",,2025-12-03 22:39:25
On the Security Risks of Knowledge Graph Reasoning,"Zhaohan Xi, Tianyu Du, Changjiang Li, Ren Pang, Shouling Ji, Xiapu Luo, Xusheng Xiao, Fenglong Ma, Ting Wang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02383"" target=""_blank"">2305.02383</a>",,2025-12-03 22:39:25
Backdoor Learning on Sequence to Sequence Models,"Lichang Chen, Minhao Cheng, Heng Huang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02424"" target=""_blank"">2305.02424</a>",,2025-12-03 22:39:25
Rethinking Graph Lottery Tickets: Graph Sparsity Matters,"Bo Hui, Da Yan, Xiaolong Ma, Wei-Shinn Ku",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02190"" target=""_blank"">2305.02190</a>",,2025-12-03 22:39:25
PTP: Boosting Stability and Performance of Prompt Tuning with Perturbation-Based Regularizer,"Lichang Chen, Heng Huang, Minhao Cheng",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02423"" target=""_blank"">2305.02423</a>",,2025-12-03 22:39:25
Boosting Adversarial Transferability via Fusing Logits of Top-1 Decomposed Feature,"Juanjuan Weng, Zhiming Luo, Dazhen Lin, Shaozi Li, Zhun Zhong",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.01361"" target=""_blank"">2305.01361</a>",,2025-12-03 22:39:25
DABS: Data-Agnostic Backdoor attack at the Server in Federated Learning,"Wenqiang Sun, Sen Li, Yuchang Sun, Jun Zhang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.01267"" target=""_blank"">2305.01267</a>",,2025-12-03 22:39:25
Sentiment Perception Adversarial Attacks on Neural Machine Translation Systems,"Vyas Raina, Mark Gales",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.01437"" target=""_blank"">2305.01437</a>",,2025-12-03 22:39:25
Attack Named Entity Recognition by Entity Boundary Interference,"Yifei Yang, Hongqiu Wu, Hai Zhao",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.05253"" target=""_blank"">2305.05253</a>",,2025-12-03 22:39:25
Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models,"Shuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, Jie Fu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.01219"" target=""_blank"">2305.01219</a>","<a href=""https://github.com/shuaizhao95/Prompt_attack"" target=""_blank"">shuaizhao95</a>",2025-12-03 22:39:25
Attack-SAM: Towards Evaluating Adversarial Robustness of Segment Anything Model,"Chenshuang Zhang, Chaoning Zhang, Taegoo Kang, Donghun Kim, Sung-Ho Bae, In So Kweon",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.00866"" target=""_blank"">2305.00866</a>","<a href=""https://github.com/chenshuang-zhang/attack-sam"" target=""_blank"">chenshuang-zhang</a>",2025-12-03 22:39:25
Physical Adversarial Attacks for Surveillance: A Survey,"Kien Nguyen, Tharindu Fernando, Clinton Fookes, Sridha Sridharan",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.01074"" target=""_blank"">2305.01074</a>",,2025-12-03 22:39:25
Revisiting Robustness in Graph Machine Learning,"Lukas Gosch, Daniel Sturm, Simon Geisler, Stephan Günnemann",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.00851"" target=""_blank"">2305.00851</a>",,2025-12-03 22:39:25
Stratified Adversarial Robustness with Rejection,"Jiefeng Chen, Jayaram Raghuram, Jihye Choi, Xi Wu, Yingyu Liang, Somesh Jha",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.01139"" target=""_blank"">2305.01139</a>",,2025-12-03 22:39:25
Poisoning Language Models During Instruction Tuning,"Alexander Wan, Eric Wallace, Sheng Shen, Dan Klein",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.00944"" target=""_blank"">2305.00944</a>",,2025-12-03 22:39:25
Assessing Vulnerabilities of Adversarial Learning Algorithm through Poisoning Attacks,"Jingfeng Zhang, Bo Song, Bo Han, Lei Liu, Gang Niu, Masashi Sugiyama",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.00399"" target=""_blank"">2305.00399</a>","<a href=""https://github.com/zjfheart/Poison-adv-training"" target=""_blank"">zjfheart</a>",2025-12-03 22:39:25
Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization,"Xilie Xu, Jingfeng Zhang, Feng Liu, Masashi Sugiyama, Mohan Kankanhalli",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.00374"" target=""_blank"">2305.00374</a>",,2025-12-03 22:39:25
Adversarial Representation Learning for Robust Privacy Preservation in Audio,"Shayan Gharib, Minh Tran, Diep Luong, Konstantinos Drossos, Tuomas Virtanen",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.00011"" target=""_blank"">2305.00011</a>",,2025-12-03 22:39:25
On the existence of solutions to adversarial training in multiclass classification,"Nicolas Garcia Trillos, Matt Jacobs, Jakwang Kim",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.00075"" target=""_blank"">2305.00075</a>",,2025-12-03 22:39:25
Single Node Injection Label Specificity Attack on Graph Neural Networks via Reinforcement Learning,"Dayuan Chen, Jian Zhang, Yuqian Lv, Jinhuan Wang, Hongjie Ni, Shanqing Yu, Zhen Wang, Qi Xuan",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02901"" target=""_blank"">2305.02901</a>",,2025-12-03 22:39:25
IMAP: Intrinsically Motivated Adversarial Policy,"Xiang Zheng, Xingjun Ma, Shengjie Wang, Xinyu Wang, Chao Shen, Cong Wang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02605"" target=""_blank"">2305.02605</a>",,2025-12-03 22:39:25
Madvex: Instrumentation-based Adversarial Attacks on Machine Learning Malware Detection,"Nils Loose, Felix Mächtle, Claudius Pott, Volodymyr Bezsmertnyi, Thomas Eisenbarth",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.02559"" target=""_blank"">2305.02559</a>",,2025-12-03 22:39:25
Repairing Deep Neural Networks Based on Behavior Imitation,"Zhen Liang, Taoran Wu, Changyuan Zhao, Wanwei Liu, Bai Xue, Wenjing Yang, Ji Wang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.03365"" target=""_blank"">2305.03365</a>",,2025-12-03 22:39:25
VSMask: Defending Against Voice Synthesis Attack via Real-Time Predictive Perturbation,"Yuanda Wang, Hanqing Guo, Guangjing Wang, Bocheng Chen, Qiben Yan",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.05736"" target=""_blank"">2305.05736</a>",,2025-12-03 22:39:25
Investigating the Corruption Robustness of Image Classifiers with Random Lp-norm Corruptions,"Georg Siedel, Weijia Shao, Silvia Vock, Andrey Morozov",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.05400"" target=""_blank"">2305.05400</a>",,2025-12-03 22:39:25
On the Relation between Sharpness-Aware Minimization and Adversarial Robustness,"Zeming Wei, Jingyu Zhu, Yihao Zhang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.05392"" target=""_blank"">2305.05392</a>","<a href=""https://github.com/weizeming/SAM_AT"" target=""_blank"">weizeming</a>",2025-12-03 22:39:25
Effects of Real-Life Traffic Sign Alteration on YOLOv7- an Object Recognition Model,"Farhin Farhad Riya, Shahinul Hoque, Md Saif Hassan Onim, Edward Michaud, Edmon Begoli, Jinyuan Stella Sun",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.05499"" target=""_blank"">2305.05499</a>",,2025-12-03 22:39:25
Turning Privacy-preserving Mechanisms against Federated Learning,"Marco Arazzi, Mauro Conti, Antonino Nocera, Stjepan Picek",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.05355"" target=""_blank"">2305.05355</a>",,2025-12-03 22:39:25
BadCS: A Backdoor Attack Framework for Code search,"Shiyi Qi, Yuanhang Yang, Shuzhzeng Gao, Cuiyun Gao, Zenglin Xu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.05503"" target=""_blank"">2305.05503</a>",,2025-12-03 22:39:25
Quantum Machine Learning for Malware Classification,"Grégoire Barrué, Tony Quertier",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09674"" target=""_blank"">2305.09674</a>",,2025-12-03 22:39:25
Toward Adversarial Training on Contextualized Language Representation,"Hongqiu Wu, Yongxiang Liu, Hanwen Shi, Hai Zhao, Min Zhang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.04557"" target=""_blank"">2305.04557</a>",,2025-12-03 22:39:25
Understanding Noise-Augmented Training for Randomized Smoothing,"Ambar Pal, Jeremias Sulam",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.04746"" target=""_blank"">2305.04746</a>",,2025-12-03 22:39:25
TAPS: Connecting Certified and Adversarial Training,"Yuhao Mao, Mark Niklas Müller, Marc Fischer, Martin Vechev",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.04574"" target=""_blank"">2305.04574</a>","<a href=""https://github.com/eth-sri/taps"" target=""_blank"">eth-sri</a>",2025-12-03 22:39:25
Privacy-preserving Adversarial Facial Features,"Zhibo Wang, He Wang, Shuaifan Jin, Wenwen Zhang, Jiahui Hu, Yan Wang, Peng Sun, Wei Yuan, Kaixin Liu, Kui Ren",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.05391"" target=""_blank"">2305.05391</a>",,2025-12-03 22:39:25
Communication-Robust Multi-Agent Learning by Adaptable Auxiliary Multi-Agent Adversary Generation,"Lei Yuan, Feng Chen, Zhongzhang Zhang, Yang Yu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.05116"" target=""_blank"">2305.05116</a>",,2025-12-03 22:39:25
Adversarial Examples Detection with Enhanced Image Difference Features based on Local Histogram Equalization,"Zhaoxia Yin, Shaowei Zhu, Hang Su, Jianteng Peng, Wanli Lyu, Bin Luo",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.04436"" target=""_blank"">2305.04436</a>",,2025-12-03 22:39:25
Pick your Poison: Undetectability versus Robustness in Data Poisoning Attacks against Deep Image Classification,"Nils Lukas, Florian Kerschbaum",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.09671"" target=""_blank"">2305.09671</a>",,2025-12-03 22:39:25
The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples,"Heng Yang, Ke Li",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.04067"" target=""_blank"">2305.04067</a>",,2025-12-03 22:39:25
Beyond the Model: Data Pre-processing Attack to Deep Learning Models in Android Apps,"Ye Sang, Yujin Huang, Shuo Huang, Helei Cui",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.03963"" target=""_blank"">2305.03963</a>",,2025-12-03 22:39:25
Towards Prompt-robust Face Privacy Protection via Adversarial Decoupling Augmentation Framework,"Ruijia Wu, Yuhang Wang, Huafeng Shi, Zhipeng Yu, Yichao Wu, Ding Liang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.03980"" target=""_blank"">2305.03980</a>",,2025-12-03 22:39:25
Text-to-Image Diffusion Models can be Easily Backdoored through Multimodal Data Poisoning,"Shengfang Zhai, Yinpeng Dong, Qingni Shen, Shi Pu, Yuejian Fang, Hang Su",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.04175"" target=""_blank"">2305.04175</a>",,2025-12-03 22:39:25
White-Box Multi-Objective Adversarial Attack on Dialogue Generation,"Yufei Li, Zexin Li, Yingfan Gao, Cong Liu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.03655"" target=""_blank"">2305.03655</a>",,2025-12-03 22:39:25
Evading Watermark based Detection of AI-Generated Content,"Zhengyuan Jiang, Jinghuai Zhang, Neil Zhenqiang Gong",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.03807"" target=""_blank"">2305.03807</a>","<a href=""https://github.com/zhengyuan-jiang/WEvade"" target=""_blank"">zhengyuan-jiang</a>",2025-12-03 22:39:25
Verifiable Learning for Robust Tree Ensembles,"Stefano Calzavara, Lorenzo Cazzaro, Giulio Ermanno Pibiri, Nicola Prezza",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.03626"" target=""_blank"">2305.03626</a>",,2025-12-03 22:39:25
Latent Imitator: Generating Natural Individual Discriminatory Instances for Black-Box Fairness Testing,"Yisong Xiao, Aishan Liu, Tianlin Li, Xianglong Liu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11602"" target=""_blank"">2305.11602</a>",,2025-12-03 22:39:25
Re-thinking Data Availablity Attacks Against Deep Neural Networks,"Bin Fang, Bo Li, Shuang Wu, Ran Yi, Shouhong Ding, Lizhuang Ma",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.10691"" target=""_blank"">2305.10691</a>",,2025-12-03 22:39:25
Long-tailed Visual Recognition via Gaussian Clouded Logit Adjustment,"Mengke Li, Yiu-ming Cheung, Yang Lu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11733"" target=""_blank"">2305.11733</a>","<a href=""https://github.com/Keke921/GCLLoss"" target=""_blank"">Keke921</a>",2025-12-03 22:39:25
A Tale of Two Approximations: Tightening Over-Approximation for DNN Robustness Verification via Under-Approximation,"Zhiyi Xue, Si Liu, Zhaodi Zhang, Yiting Wu, Min Zhang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.16998"" target=""_blank"">2305.16998</a>",,2025-12-03 22:39:25
BadLabel: A Robust Perspective on Evaluating and Enhancing Label-noise Learning,"Jingfeng Zhang, Bo Song, Haohan Wang, Bo Han, Tongliang Liu, Lei Liu, Masashi Sugiyama",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.18377"" target=""_blank"">2305.18377</a>","<a href=""https://github.com/zjfheart/BadLabels"" target=""_blank"">zjfheart</a>",2025-12-03 22:39:25
Black-Box Anomaly Attribution,"Tsuyoshi Idé, Naoki Abe",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.18440"" target=""_blank"">2305.18440</a>",,2025-12-03 22:39:25
Two Heads are Better than One: Towards Better Adversarial Robustness by Combining Transduction and Rejection,"Nils Palumbo, Yang Guo, Xi Wu, Jiefeng Chen, Yingyu Liang, Somesh Jha",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.17528"" target=""_blank"">2305.17528</a>",,2025-12-03 22:39:25
On the Importance of Backbone to the Adversarial Robustness of Object Detectors,"Xiao Li, Hang Chen, Xiaolin Hu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.17438"" target=""_blank"">2305.17438</a>","<a href=""https://github.com/thu-ml/oddefense"" target=""_blank"">thu-ml</a>",2025-12-03 22:39:25
Modeling Adversarial Attack on Pre-trained Language Models as Sequential Decision Making,"Xuanjie Fang, Sijie Cheng, Yang Liu, Wei Wang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.17440"" target=""_blank"">2305.17440</a>","<a href=""https://github.com/fduxuan/SDM-Attack"" target=""_blank"">fduxuan</a>",2025-12-03 22:39:25
No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions,"Tiancheng Jin, Junyan Liu, Chloé Rouyer, William Chang, Chen-Yu Wei, Haipeng Luo",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.17380"" target=""_blank"">2305.17380</a>",,2025-12-03 22:39:25
FoPro-KD: Fourier Prompted Effective Knowledge Distillation for Long-Tailed Medical Image Recognition,"Marawan Elbatel, Robert Martí, Xiaomeng Li",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.17421"" target=""_blank"">2305.17421</a>","<a href=""https://github.com/xmed-lab/FoPro-KD"" target=""_blank"">xmed-lab</a>",2025-12-03 22:39:25
On Evaluating Adversarial Robustness of Large Vision-Language Models,"Yunqing Zhao, Tianyu Pang, Chao Du, Xiao Yang, Chongxuan Li, Ngai-Man Cheung, Min Lin",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.16934"" target=""_blank"">2305.16934</a>","<a href=""https://github.com/yunqing-me/AttackVLM"" target=""_blank"">yunqing-me</a>",2025-12-03 22:39:25
DistriBlock: Identifying adversarial audio samples by leveraging characteristics of the output distribution,"Matías Pizarro, Dorothea Kolossa, Asja Fischer",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.17000"" target=""_blank"">2305.17000</a>",,2025-12-03 22:39:25
Rethinking Adversarial Policies: A Generalized Attack Formulation and Provable Defense in Multi-Agent RL,"Xiangyu Liu, Souradip Chakraborty, Yanchao Sun, Furong Huang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.17342"" target=""_blank"">2305.17342</a>",,2025-12-03 22:39:25
Adversarial Attacks on Online Learning to Rank with Click Feedback,"Jinhang Zuo, Zhiyao Zhang, Zhiyong Wang, Shuai Li, Mohammad Hajiesmaili, Adam Wierman",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.17071"" target=""_blank"">2305.17071</a>",,2025-12-03 22:39:25
NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models,"Kai Mei, Zheng Li, Zhenting Wang, Yang Zhang, Shiqing Ma",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.17826"" target=""_blank"">2305.17826</a>","<a href=""https://github.com/RU-System-Software-and-Security/Notable"" target=""_blank"">RU-System-Software-and-Security</a>",2025-12-03 22:39:25
Trust-Aware Resilient Control and Coordination of Connected and Automated Vehicles,"H M Sabbir Ahmad, Ehsan Sabouni, Wei Xiao, Christos G. Cassandras, Wenchao Li",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.16818"" target=""_blank"">2305.16818</a>",,2025-12-03 22:39:25
Efficient Detection of LLM-generated Texts with a Bayesian Surrogate Model,"Zhijie Deng, Hongcheng Gao, Yibo Miao, Hao Zhang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.16617"" target=""_blank"">2305.16617</a>",,2025-12-03 22:39:25
IDEA: Invariant Defense for Graph Adversarial Robustness,"Shuchang Tao, Qi Cao, Huawei Shen, Yunfan Wu, Bingbing Xu, Xueqi Cheng",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.15792"" target=""_blank"">2305.15792</a>",,2025-12-03 22:39:25
"Don't Retrain, Just Rewrite: Countering Adversarial Perturbations by Rewriting Text","Ashim Gupta, Carter Wood Blum, Temma Choji, Yingjie Fei, Shalin Shah, Alakananda Vempala, Vivek Srikumar",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.16444"" target=""_blank"">2305.16444</a>",,2025-12-03 22:39:25
Diffusion-Based Adversarial Sample Generation for Improved Stealthiness and Controllability,"Haotian Xue, Alexandre Araujo, Bin Hu, Yongxin Chen",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.16494"" target=""_blank"">2305.16494</a>","<a href=""https://github.com/xavihart/Diff-PGD"" target=""_blank"">xavihart</a>",2025-12-03 22:39:25
PEARL: Preprocessing Enhanced Adversarial Robust Learning of Image Deraining for Semantic Segmentation,"Xianghao Jiao, Yaohua Liu, Jiaxin Gao, Xinyuan Chu, Risheng Liu, Xin Fan",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.15709"" target=""_blank"">2305.15709</a>",,2025-12-03 22:39:25
On the Robustness of Segment Anything,"Yihao Huang, Yue Cao, Tianlin Li, Felix Juefei-Xu, Di Lin, Ivor W. Tsang, Yang Liu, Qing Guo",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.16220"" target=""_blank"">2305.16220</a>",,2025-12-03 22:39:25
Detecting Adversarial Data by Probing Multiple Perturbations Using Expected Perturbation Score,"Shuhai Zhang, Feng Liu, Jiahao Yang, Yifan Yang, Changsheng Li, Bo Han, Mingkui Tan",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.16035"" target=""_blank"">2305.16035</a>",,2025-12-03 22:39:25
Rethinking Diversity in Deep Neural Network Testing,"Zi Wang, Jihye Choi, Ke Wang, Somesh Jha",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.15698"" target=""_blank"">2305.15698</a>",,2025-12-03 22:39:25
IMBERT: Making BERT Immune to Insertion-based Backdoor Attacks,"Xuanli He, Jun Wang, Benjamin Rubinstein, Trevor Cohn",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.16503"" target=""_blank"">2305.16503</a>",,2025-12-03 22:39:25
Choose your Data Wisely: A Framework for Semantic Counterfactuals,"Edmund Dervakos, Konstantinos Thomas, Giorgos Filandrianos, Giorgos Stamou",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.17667"" target=""_blank"">2305.17667</a>",,2025-12-03 22:39:25
Backdoor Attacks Against Incremental Learners: An Empirical Evaluation Study,"Yiqi Zhong, Xianming Liu, Deming Zhai, Junjun Jiang, Xiangyang Ji",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.18384"" target=""_blank"">2305.18384</a>",,2025-12-03 22:39:25
Concept-Centric Transformers: Enhancing Model Interpretability through Object-Centric Concept Learning within a Shared Global Workspace,"Jinyung Hong, Keun Hee Park, Theodore P. Pavlic",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.15775"" target=""_blank"">2305.15775</a>",,2025-12-03 22:39:25
Defense Against Shortest Path Attacks,"Benjamin A. Miller, Zohair Shafi, Wheeler Ruml, Yevgeniy Vorobeychik, Tina Eliassi-Rad, Scott Alfeld",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.19083"" target=""_blank"">2305.19083</a>",,2025-12-03 22:39:25
Exploring the Vulnerabilities of Machine Learning and Quantum Machine Learning to Adversarial Attacks using a Malware Dataset: A Comparative Analysis,"Mst Shapna Akter, Hossain Shahriar, Iysa Iqbal, MD Hossain, M. A. Karim, Victor Clincy, Razvan Voicu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.19593"" target=""_blank"">2305.19593</a>",,2025-12-03 22:39:25
Mitigating Backdoor Poisoning Attacks through the Lens of Spurious Correlation,"Xuanli He, Qiongkai Xu, Jun Wang, Benjamin Rubinstein, Trevor Cohn",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11596"" target=""_blank"">2305.11596</a>",,2025-12-03 22:39:25
Adversarial Clean Label Backdoor Attacks and Defenses on Text Classification Systems,"Ashim Gupta, Amrith Krishna",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.19607"" target=""_blank"">2305.19607</a>",,2025-12-03 22:39:25
Deception by Omission: Using Adversarial Missingness to Poison Causal Structure Learning,"Deniz Koyuncu, Alex Gittens, Bülent Yener, Moti Yung",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.20043"" target=""_blank"">2305.20043</a>",,2025-12-03 22:39:25
Red Teaming Language Model Detectors with Language Models,"Zhouxing Shi, Yihan Wang, Fan Yin, Xiangning Chen, Kai-Wei Chang, Cho-Jui Hsieh",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.19713"" target=""_blank"">2305.19713</a>",,2025-12-03 22:39:25
Ambiguity in solving imaging inverse problems with deep learning based operators,"Davide Evangelista, Elena Morotti, Elena Loli Piccolomini, James Nagy",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.19774"" target=""_blank"">2305.19774</a>",,2025-12-03 22:39:25
Pseudo-Siamese Network based Timbre-reserved Black-box Adversarial Attack in Speaker Identification,"Qing Wang, Jixun Yao, Ziqian Wang, Pengcheng Guo, Lei Xie",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.19020"" target=""_blank"">2305.19020</a>",,2025-12-03 22:39:25
Breeding Machine Translations: Evolutionary approach to survive and thrive in the world of automated evaluation,"Josef Jon, Ondřej Bojar",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.19330"" target=""_blank"">2305.19330</a>",,2025-12-03 22:39:25
Which Models have Perceptually-Aligned Gradients? An Explanation via Off-Manifold Robustness,"Suraj Srinivas, Sebastian Bordt, Hima Lakkaraju",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.19101"" target=""_blank"">2305.19101</a>",,2025-12-03 22:39:25
Incremental Randomized Smoothing Certification,"Shubham Ugare, Tarun Suresh, Debangshu Banerjee, Gagandeep Singh, Sasa Misailovic",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.19521"" target=""_blank"">2305.19521</a>",,2025-12-03 22:39:25
A Multilingual Evaluation of NER Robustness to Adversarial Inputs,"Akshay Srinivasan, Sowmya Vajjala",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.18933"" target=""_blank"">2305.18933</a>",,2025-12-03 22:39:25
NaturalFinger: Generating Natural Fingerprint with Generative Adversarial Networks,"Kang Yang, Kunhao Lai",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.17868"" target=""_blank"">2305.17868</a>",,2025-12-03 22:39:25
It begins with a boundary: A geometric view on probabilistically robust learning,"Leon Bungert, Nicolás García Trillos, Matt Jacobs, Daniel McKenzie, Đorđe Nikolić, Qingsong Wang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.18779"" target=""_blank"">2305.18779</a>",,2025-12-03 22:39:25
Adversarial Attacks on Online Learning to Rank with Stochastic Click Models,"Zichen Wang, Rishab Balasubramanian, Hui Yuan, Chenyu Song, Mengdi Wang, Huazheng Wang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.19218"" target=""_blank"">2305.19218</a>",,2025-12-03 22:39:25
Learning Perturbations to Explain Time Series Predictions,Joseph Enguehard,arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.18840"" target=""_blank"">2305.18840</a>",,2025-12-03 22:39:25
From Adversarial Arms Race to Model-centric Evaluation: Motivating a Unified Automatic Robustness Evaluation Framework,"Yangyi Chen, Hongcheng Gao, Ganqu Cui, Lifan Yuan, Dehan Kong, Hanlu Wu, Ning Shi, Bo Yuan, Longtao Huang, Hui Xue, Zhiyuan Liu, Maosong Sun, Heng Ji",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.18503"" target=""_blank"">2305.18503</a>","<a href=""https://github.com/thunlp/RobTest"" target=""_blank"">thunlp</a>",2025-12-03 22:39:25
Fourier Analysis on Robustness of Graph Convolutional Neural Networks for Skeleton-based Action Recognition,"Nariki Tanaka, Hiroshi Kera, Kazuhiko Kawamoto",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.17939"" target=""_blank"">2305.17939</a>",,2025-12-03 22:39:25
Exploiting Explainability to Design Adversarial Attacks and Evaluate Attack Resilience in Hate-Speech Detection Models,"Pranath Reddy Kumbam, Sohaib Uddin Syed, Prashanth Thamminedi, Suhas Harish, Ian Perera, Bonnie J. Dorr",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.18585"" target=""_blank"">2305.18585</a>",,2025-12-03 22:39:25
UMD: Unsupervised Model Detection for X2X Backdoor Attacks,"Zhen Xiang, Zidi Xiong, Bo Li",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.18651"" target=""_blank"">2305.18651</a>",,2025-12-03 22:39:25
Membership Inference Attacks against Language Models via Neighbourhood Comparison,"Justus Mattern, Fatemehsadat Mireshghallah, Zhijing Jin, Bernhard Schölkopf, Mrinmaya Sachan, Taylor Berg-Kirkpatrick",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.18462"" target=""_blank"">2305.18462</a>",,2025-12-03 22:39:25
Towards minimizing efforts for Morphing Attacks -- Deep embeddings for morphing pair selection and improved Morphing Attack Detection,"Roman Kessler, Kiran Raja, Juan Tapia, Christoph Busch",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.18216"" target=""_blank"">2305.18216</a>",,2025-12-03 22:39:25
Amplification trojan network: Attack deep neural networks by amplifying their inherent weakness,"Zhanhao Hu, Jun Zhu, Bo Zhang, Xiaolin Hu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.17688"" target=""_blank"">2305.17688</a>",,2025-12-03 22:39:25
Securing Deep Generative Models with Universal Adversarial Signature,"Yu Zeng, Mo Zhou, Yuan Xue, Vishal M. Patel",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.16310"" target=""_blank"">2305.16310</a>","<a href=""https://github.com/zengxianyu/genwm"" target=""_blank"">zengxianyu</a>",2025-12-03 22:39:25
Robust Lipschitz Bandits to Adversarial Corruptions,"Yue Kang, Cho-Jui Hsieh, Thomas C. M. Lee",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.18543"" target=""_blank"">2305.18543</a>",,2025-12-03 22:39:25
How do humans perceive adversarial text? A reality check on the validity and naturalness of word-based adversarial attacks,"Salijona Dyrmishi, Salah Ghamizi, Maxime Cordy",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.15587"" target=""_blank"">2305.15587</a>",,2025-12-03 22:39:25
Tied-Augment: Controlling Representation Similarity Improves Data Augmentation,"Emirhan Kurtulus, Zichao Li, Yann Dauphin, Ekin Dogus Cubuk",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.13520"" target=""_blank"">2305.13520</a>","<a href=""https://github.com/ekurtulus/tied-augment/tree/main"" target=""_blank"">tree</a>",2025-12-03 22:39:25
Attribute-Guided Encryption with Facial Texture Masking,"Chun Pong Lau, Jiang Liu, Rama Chellappa",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.13548"" target=""_blank"">2305.13548</a>",,2025-12-03 22:39:25
DiffProtect: Generate Adversarial Examples with Diffusion Models for Facial Privacy Protection,"Jiang Liu, Chun Pong Lau, Rama Chellappa",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.13625"" target=""_blank"">2305.13625</a>",,2025-12-03 22:39:25
Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game,"Simin Li, Jun Guo, Jingqiao Xiu, Ruixiao Xu, Xin Yu, Jiakai Wang, Aishan Liu, Yaodong Yang, Xianglong Liu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12872"" target=""_blank"">2305.12872</a>",,2025-12-03 22:39:25
Towards Benchmarking and Assessing Visual Naturalness of Physical World Adversarial Attacks,"Simin Li, Shuing Zhang, Gujun Chen, Dong Wang, Pu Feng, Jiakai Wang, Aishan Liu, Xin Yi, Xianglong Liu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12863"" target=""_blank"">2305.12863</a>","<a href=""https://github.com/zhangsn-19/PAN"" target=""_blank"">zhangsn-19</a>",2025-12-03 22:39:25
Flying Adversarial Patches: Manipulating the Behavior of Deep Learning-based Autonomous Multirotors,"Pia Hanfeld, Marina M. -C. Höhne, Michael Bussmann, Wolfgang Hönig",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12859"" target=""_blank"">2305.12859</a>",,2025-12-03 22:39:25
DeepBern-Nets: Taming the Complexity of Certifying Neural Networks using Bernstein Polynomial Activations and Precise Bound Propagation,"Haitham Khedr, Yasser Shoukry",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.13508"" target=""_blank"">2305.13508</a>",,2025-12-03 22:39:25
The defender's perspective on automatic speaker verification: An overview,"Haibin Wu, Jiawen Kang, Lingwei Meng, Helen Meng, Hung-yi Lee",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12804"" target=""_blank"">2305.12804</a>",,2025-12-03 22:39:25
Model Stealing Attack against Multi-Exit Networks,"Li Pan, Lv Peizhuo, Chen Kai, Cai Yuling, Xiang Fan, Zhang Shengzhi",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.13584"" target=""_blank"">2305.13584</a>",,2025-12-03 22:39:25
Adversarial Nibbler: A Data-Centric Challenge for Improving the Safety of Text-to-Image Models,"Alicia Parrish, Hannah Rose Kirk, Jessica Quaye, Charvi Rastogi, Max Bartolo, Oana Inel, Juan Ciro, Rafael Mosquera, Addison Howard, Will Cukierski, D. Sculley, Vijay Janapa Reddi, Lora Aroyo",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14384"" target=""_blank"">2305.14384</a>",,2025-12-03 22:39:25
Improving Classifier Robustness through Active Generation of Pairwise Counterfactuals,"Ananth Balashankar, Xuezhi Wang, Yao Qin, Ben Packer, Nithum Thain, Jilin Chen, Ed H. Chi, Alex Beutel",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.13535"" target=""_blank"">2305.13535</a>",,2025-12-03 22:39:25
Watermarking Text Data on Large Language Models for Dataset Copyright,"Yixin Liu, Hongsheng Hu, Xun Chen, Xuyun Zhang, Lichao Sun",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.13257"" target=""_blank"">2305.13257</a>",,2025-12-03 22:39:25
Uncertainty-based Detection of Adversarial Attacks in Semantic Segmentation,"Kira Maag, Asja Fischer",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12825"" target=""_blank"">2305.12825</a>",,2025-12-03 22:39:25
Mist: Towards Improved Adversarial Examples for Diffusion Models,"Chumeng Liang, Xiaoyu Wu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12683"" target=""_blank"">2305.12683</a>",,2025-12-03 22:39:25
Are Your Explanations Reliable? Investigating the Stability of LIME in Explaining Text Classifiers by Marrying XAI and Adversarial Attack,"Christopher Burger, Lingwei Chen, Thai Le",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12351"" target=""_blank"">2305.12351</a>",,2025-12-03 22:39:25
FAQ: Mitigating the Impact of Faults in the Weight Memory of DNN Accelerators through Fault-Aware Quantization,"Muhammad Abdullah Hanif, Muhammad Shafique",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12590"" target=""_blank"">2305.12590</a>",,2025-12-03 22:39:25
Dynamic Transformers Provide a False Sense of Efficiency,"Yiming Chen, Simin Chen, Zexin Li, Wei Yang, Cong Liu, Robby T. Tan, Haizhou Li",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12228"" target=""_blank"">2305.12228</a>",,2025-12-03 22:39:25
Annealing Self-Distillation Rectification Improves Adversarial Training,"Yu-Yu Wu, Hung-Jui Wang, Shang-Tse Chen",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12118"" target=""_blank"">2305.12118</a>",,2025-12-03 22:39:25
"Stability, Generalization and Privacy: Precise Analysis for Random and NTK Features","Simone Bombari, Marco Mondelli",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12100"" target=""_blank"">2305.12100</a>",,2025-12-03 22:39:25
Multi-Task Models Adversarial Attacks,"Lijun Zhang, Xiao Liu, Kaleel Mahmood, Caiwen Ding, Hui Guan",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12066"" target=""_blank"">2305.12066</a>",,2025-12-03 22:39:25
DAP: A Dynamic Adversarial Patch for Evading Person Detectors,"Amira Guesmi, Ruitian Ding, Muhammad Abdullah Hanif, Ihsen Alouani, Muhammad Shafique",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11618"" target=""_blank"">2305.11618</a>",,2025-12-03 22:39:25
Efficient ConvBN Blocks for Transfer Learning and Beyond,"Kaichao You, Guo Qin, Anchang Bao, Meng Cao, Ping Huang, Jiulong Shan, Mingsheng Long",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.11624"" target=""_blank"">2305.11624</a>",,2025-12-03 22:39:25
Introducing Competition to Boost the Transferability of Targeted Adversarial Examples through Clean Feature Mixup,"Junyoung Byun, Myung-Joon Kwon, Seungju Cho, Yoonji Kim, Changick Kim",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14846"" target=""_blank"">2305.14846</a>","<a href=""https://github.com/dreamflake/CFM"" target=""_blank"">dreamflake</a>",2025-12-03 22:39:25
FGAM:Fast Adversarial Malware Generation Method Based on Gradient Sign,"Kun Li, Fan Zhang, Wei Guo",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12770"" target=""_blank"">2305.12770</a>",,2025-12-03 22:39:25
Adaptive Face Recognition Using Adversarial Information Network,"Mei Wang, Weihong Deng",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.13605"" target=""_blank"">2305.13605</a>",,2025-12-03 22:39:25
Latent Magic: An Investigation into Adversarial Examples Crafted in the Semantic Latent Space,BoYang Zheng,arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.12906"" target=""_blank"">2305.12906</a>",,2025-12-03 22:39:25
Adversarial robustness of amortized Bayesian inference,"Manuel Glöckler, Michael Deistler, Jakob H. Macke",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14984"" target=""_blank"">2305.14984</a>",,2025-12-03 22:39:25
Robust Classification via a Single Diffusion Model,"Huanran Chen, Yinpeng Dong, Zhengyi Wang, Xiao Yang, Chengqi Duan, Hang Su, Jun Zhu",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.15241"" target=""_blank"">2305.15241</a>","<a href=""https://github.com/huanranchen/DiffusionClassifier"" target=""_blank"">huanranchen</a>",2025-12-03 22:39:25
Decoupled Kullback-Leibler Divergence Loss,"Jiequan Cui, Zhuotao Tian, Zhisheng Zhong, Xiaojuan Qi, Bei Yu, Hanwang Zhang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.13948"" target=""_blank"">2305.13948</a>","<a href=""https://github.com/jiequancui/DKL"" target=""_blank"">jiequancui</a>",2025-12-03 22:39:25
Frequency maps reveal the correlation between Adversarial Attacks and Implicit Bias,"Lorenzo Basile, Nikos Karantzas, Alberto d'Onofrio, Luca Manzoni, Luca Bortolussi, Alex Rodriguez, Fabio Anselmi",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.15203"" target=""_blank"">2305.15203</a>",,2025-12-03 22:39:25
Fantastic DNN Classifiers and How to Identify them without Data,"Nathaniel Dean, Dilip Sarkar",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.15563"" target=""_blank"">2305.15563</a>",,2025-12-03 22:39:25
Adversarial Demonstration Attacks on Large Language Models,"Jiongxiao Wang, Zichen Liu, Keun Hee Park, Muhao Chen, Chaowei Xiao",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14950"" target=""_blank"">2305.14950</a>",,2025-12-03 22:39:25
AdvFunMatch: When Consistent Teaching Meets Adversarial Robustness,"Ziuhi Wu, Haichang Gao, Bingqian Zhou, Ping Wang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14700"" target=""_blank"">2305.14700</a>",,2025-12-03 22:39:25
Reconstructive Neuron Pruning for Backdoor Defense,"Yige Li, Xixiang Lyu, Xingjun Ma, Nodens Koren, Lingjuan Lyu, Bo Li, Yu-Gang Jiang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14876"" target=""_blank"">2305.14876</a>","<a href=""https://github.com/bboylyg/RNP"" target=""_blank"">bboylyg</a>",2025-12-03 22:39:25
Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models,"Jiashu Xu, Mingyu Derek Ma, Fei Wang, Chaowei Xiao, Muhao Chen",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14710"" target=""_blank"">2305.14710</a>",,2025-12-03 22:39:25
From Shortcuts to Triggers: Backdoor Defense with Denoised PoE,"Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14910"" target=""_blank"">2305.14910</a>",,2025-12-03 22:39:25
Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models,"Natalie Shapira, Mosh Levy, Seyed Hossein Alavi, Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, Vered Shwartz",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14763"" target=""_blank"">2305.14763</a>",,2025-12-03 22:39:25
Another Dead End for Morphological Tags? Perturbed Inputs and Parsing,"Alberto Muñoz-Ortiz, David Vilares",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.15119"" target=""_blank"">2305.15119</a>",,2025-12-03 22:39:25
QFA2SR: Query-Free Adversarial Transfer Attacks to Speaker Recognition Systems,"Guangke Chen, Yedi Zhang, Zhe Zhao, Fu Song",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14097"" target=""_blank"">2305.14097</a>",,2025-12-03 22:39:25
The Best Defense is a Good Offense: Adversarial Augmentation against Adversarial Attacks,"Iuri Frosio, Jan Kautz",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14188"" target=""_blank"">2305.14188</a>","<a href=""https://github.com/NVlabs/A5"" target=""_blank"">NVlabs</a>",2025-12-03 22:39:25
Sharpness-Aware Data Poisoning Attack,"Pengfei He, Han Xu, Jie Ren, Yingqian Cui, Hui Liu, Charu C. Aggarwal, Jiliang Tang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14851"" target=""_blank"">2305.14851</a>",,2025-12-03 22:39:25
Impact of Light and Shadow on Robustness of Deep Neural Networks,"Chengyin Hu, Weiwen Shi, Chao Li, Jialiang Sun, Donghua Wang, Junqi Wu, Guijian Tang",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14165"" target=""_blank"">2305.14165</a>",,2025-12-03 22:39:25
Expressive Losses for Verified Robustness via Convex Combinations,"Palma Alessandro De, Rudy Bunel, Krishnamurthy Dvijotham, M. Pawan Kumar, Robert Stanforth, Alessio Lomuscio",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.13991"" target=""_blank"">2305.13991</a>",,2025-12-03 22:39:25
Enhancing Accuracy and Robustness through Adversarial Training in Class Incremental Continual Learning,"Minchan Kwon, Kangil Kim",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.13678"" target=""_blank"">2305.13678</a>",,2025-12-03 22:39:25
A Causal View of Entity Bias in (Large) Language Models,"Fei Wang, Wenjie Mo, Yiwei Wang, Wenxuan Zhou, Muhao Chen",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14695"" target=""_blank"">2305.14695</a>","<a href=""https://github.com/luka-group/Causal-View-of-Entity-Bias"" target=""_blank"">luka-group</a>",2025-12-03 22:39:25
Ghostbuster: Detecting Text Ghostwritten by Large Language Models,"Vivek Verma, Eve Fleisig, Nicholas Tomlin, Dan Klein",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.15047"" target=""_blank"">2305.15047</a>",,2025-12-03 22:39:25
"M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection","Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, Akim Tsvigun, Chenxi Whitehouse, Osama Mohammed Afzal, Tarek Mahmoud, Toru Sasaki, Thomas Arnold, Alham Fikri Aji, Nizar Habash, Iryna Gurevych, Preslav Nakov",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.14902"" target=""_blank"">2305.14902</a>","<a href=""https://github.com/mbzuai-nlp/M4"" target=""_blank"">mbzuai-nlp</a>",2025-12-03 22:39:25
How to fix a broken confidence estimator: Evaluating post-hoc methods for selective classification with deep neural networks,"Luís Felipe P. Cattelan, Danilo Silva",arXiv,2023-05,"<a href=""http://arxiv.org/abs/2305.15508"" target=""_blank"">2305.15508</a>",,2025-12-03 22:39:25
Reinforcement Learning-Based Black-Box Model Inversion Attacks,"Gyojin Han, Jaehyun Choi, Haeil Lee, Junmo Kim",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.04625"" target=""_blank"">2304.04625</a>",,2025-12-03 22:39:25
Unsupervised Multi-Criteria Adversarial Detection in Deep Image Retrieval,"Yanru Xiao, Cong Wang, Xing Gao",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.04228"" target=""_blank"">2304.04228</a>",,2025-12-03 22:39:25
Defense-Prefix for Preventing Typographic Attacks on CLIP,"Hiroki Azuma, Yusuke Matsui",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.04512"" target=""_blank"">2304.04512</a>","<a href=""https://github.com/azuma164/Defense-Prefix"" target=""_blank"">azuma164</a>",2025-12-03 22:39:25
Helix++: A platform for efficiently securing software,"Jack W. Davidson, Jason D. Hiser, Anh Nguyen-Tuong",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.04846"" target=""_blank"">2304.04846</a>",,2025-12-03 22:39:25
Certifiable Black-Box Attacks with Randomized Adversarial Examples: Breaking Defenses with Provable Confidence,"Hanbin Hong, Xinyu Zhang, Binghui Wang, Zhongjie Ba, Yuan Hong",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.04343"" target=""_blank"">2304.04343</a>","<a href=""https://github.com/datasec-lab/CertifiedAttack"" target=""_blank"">datasec-lab</a>",2025-12-03 22:39:25
Adversarially Robust Neural Architecture Search for Graph Neural Networks,"Beini Xie, Heng Chang, Ziwei Zhang, Xin Wang, Daixin Wang, Zhiqiang Zhang, Rex Ying, Wenwu Zhu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.04168"" target=""_blank"">2304.04168</a>",,2025-12-03 22:39:25
Attack-Augmentation Mixing-Contrastive Skeletal Representation Learning,"Binqian Xu, Xiangbo Shu, Jiachao Zhang, Rui Yan, Guo-Sen Xie",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.04023"" target=""_blank"">2304.04023</a>","<a href=""https://github.com/1xbq1/A2MC"" target=""_blank"">1xbq1</a>",2025-12-03 22:39:25
Exploring the Connection between Robust and Generative Models,"Senad Beadini, Iacopo Masi",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.04033"" target=""_blank"">2304.04033</a>",,2025-12-03 22:39:25
Robust Deep Learning Models Against Semantic-Preserving Adversarial Attack,"Dashan Gao, Yunce Zhao, Yinghua Yao, Zeqi Zhang, Bifei Mao, Xin Yao",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.03955"" target=""_blank"">2304.03955</a>",,2025-12-03 22:39:25
RobCaps: Evaluating the Robustness of Capsule Networks against Affine Transformations and Adversarial Attacks,"Alberto Marchisio, Marco Antonio De, Alessio Colucci, Maurizio Martina, Muhammad Shafique",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.03973"" target=""_blank"">2304.03973</a>",,2025-12-03 22:39:25
Deep Prototypical-Parts Ease Morphological Kidney Stone Identification and are Competitively Robust to Photometric Perturbations,"Daniel Flores-Araiza, Francisco Lopez-Tiro, Jonathan El-Beze, Jacques Hubert, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.04077"" target=""_blank"">2304.04077</a>",,2025-12-03 22:39:25
Benchmarking the Robustness of Quantized Models,"Yisong Xiao, Tianyuan Zhang, Shunchang Liu, Haotong Qin",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.03968"" target=""_blank"">2304.03968</a>",,2025-12-03 22:39:25
Towards More Robust and Accurate Sequential Recommendation with Cascade-guided Adversarial Training,"Juntao Tan, Shelby Heinecke, Zhiwei Liu, Yongjun Chen, Yongfeng Zhang, Huan Wang",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.05492"" target=""_blank"">2304.05492</a>",,2025-12-03 22:39:25
Generating Adversarial Attacks in the Latent Space,"Nitish Shukla, Sudipta Banerjee",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.04386"" target=""_blank"">2304.04386</a>",,2025-12-03 22:39:25
Adversarial Examples from Dimensional Invariance,Benjamin L. Badger,arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.06575"" target=""_blank"">2304.06575</a>",,2025-12-03 22:39:25
Overload: Latency Attacks on Object Detection for Edge Devices,"Erh-Chung Chen, Pin-Yu Chen, I-Hsin Chung, Che-rung Lee",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.05370"" target=""_blank"">2304.05370</a>",,2025-12-03 22:39:25
On the Adversarial Inversion of Deep Biometric Representations,"Gioacchino Tangari, Shreesh Keskar, Hassan Jameel Asghar, Dali Kaafar",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.05561"" target=""_blank"">2304.05561</a>",,2025-12-03 22:39:25
Benchmarking the Physical-world Adversarial Robustness of Vehicle Detection,"Tianyuan Zhang, Yisong Xiao, Xiaoya Zhang, Hao Li, Lu Wang",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.05098"" target=""_blank"">2304.05098</a>",,2025-12-03 22:39:25
Boosting Cross-task Transferability of Adversarial Patches with Visual Relations,"Tony Ma, Songze Li, Yisong Xiao, Shunchang Liu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.05402"" target=""_blank"">2304.05402</a>",,2025-12-03 22:39:25
Simultaneous Adversarial Attacks On Multiple Face Recognition System Components,"Inderjeet Singh, Kazuya Kakizaki, Toshinori Araki",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.05048"" target=""_blank"">2304.05048</a>",,2025-12-03 22:39:25
RecUP-FL: Reconciling Utility and Privacy in Federated Learning via User-configurable Privacy Defense,"Yue Cui, Syed Irfan Ali Meerza, Zhuohang Li, Luyang Liu, Jiaxin Zhang, Jian Liu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.05135"" target=""_blank"">2304.05135</a>",,2025-12-03 22:39:25
Exploiting Logic Locking for a Neural Trojan Attack on Machine Learning Accelerators,"Hongye Xu, Dongfang Liu, Cory Merkel, Michael Zuzak",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.06017"" target=""_blank"">2304.06017</a>",,2025-12-03 22:39:25
Generative Adversarial Networks-Driven Cyber Threat Intelligence Detection Framework for Securing Internet of Things,"Mohamed Amine Ferrag, Djallel Hamouda, Merouane Debbah, Leandros Maglaras, Abderrahmane Lakas",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.05644"" target=""_blank"">2304.05644</a>",,2025-12-03 22:39:25
LSFSL: Leveraging Shape Information in Few-shot Learning,"Deepan Chakravarthi Padmanabhan, Shruthi Gowda, Elahe Arani, Bahram Zonooz",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.06672"" target=""_blank"">2304.06672</a>",,2025-12-03 22:39:25
Understanding Overfitting in Adversarial Training in Kernel Regression,"Teng Zhang, Kang Li",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.06326"" target=""_blank"">2304.06326</a>",,2025-12-03 22:39:25
False Claims against Model Ownership Resolution,"Jian Liu, Rui Zhang, Sebastian Szyller, Kui Ren, N. Asokan",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.06607"" target=""_blank"">2304.06607</a>",,2025-12-03 22:39:25
Generating Adversarial Examples with Better Transferability via Masking Unimportant Parameters of Surrogate Model,"Dingcheng Yang, Wenjian Yu, Zihao Xiao, Jiaqi Luo",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.06908"" target=""_blank"">2304.06908</a>",,2025-12-03 22:39:25
Architecture-Preserving Provable Repair of Deep Neural Networks,"Zhe Tao, Stephanie Nawas, Jacqueline Mitchell, Aditya V. Thakur",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.03496"" target=""_blank"">2304.03496</a>",,2025-12-03 22:39:25
Pool Inference Attacks on Local Differential Privacy: Quantifying the Privacy Guarantees of Apple's Count Mean Sketch in Practice,"Andrea Gadotti, Florimond Houssiau, Meenatchi Sundaram Muthu Selva Annamalai, Montjoye Yves-Alexandre de",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.07134"" target=""_blank"">2304.07134</a>",,2025-12-03 22:39:25
EMP-SSL: Towards Self-Supervised Learning in One Training Epoch,"Shengbang Tong, Yubei Chen, Yi Ma, Yann Lecun",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.03977"" target=""_blank"">2304.03977</a>","<a href=""https://github.com/tsb0601/EMP-SSL"" target=""_blank"">tsb0601</a>",2025-12-03 22:39:25
Instance-level Trojan Attacks on Visual Question Answering via Adversarial Learning in Neuron Activation Space,"Yuwei Sun, Hideya Ochiai, Jun Sakuma",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.00436"" target=""_blank"">2304.00436</a>",,2025-12-03 22:39:25
ASPEST: Bridging the Gap Between Active Learning and Selective Prediction,"Jiefeng Chen, Jinsung Yoon, Sayna Ebrahimi, Sercan Arik, Somesh Jha, Tomas Pfister",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.03870"" target=""_blank"">2304.03870</a>",,2025-12-03 22:39:25
CGDTest: A Constrained Gradient Descent Algorithm for Testing Neural Networks,"Vineel Nagisetty, Laura Graves, Guanting Pan, Piyush Jha, Vijay Ganesh",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.01826"" target=""_blank"">2304.01826</a>",,2025-12-03 22:39:25
Combining Generators of Adversarial Malware Examples to Increase Evasion Rate,"Matouš Kozák, Martin Jureček",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.07360"" target=""_blank"">2304.07360</a>",,2025-12-03 22:39:25
Towards Reasonable Budget Allocation in Untargeted Graph Structure Attacks via Gradient Debias,"Zihan Liu, Yun Luo, Lirong Wu, Zicheng Liu, Stan Z. Li",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.00010"" target=""_blank"">2304.00010</a>",,2025-12-03 22:39:25
A Generative Framework for Low-Cost Result Validation of Outsourced Machine Learning Tasks,"Abhinav Kumar, Miguel A. Guirao Aguilera, Reza Tourani, Satyajayant Misra",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.00083"" target=""_blank"">2304.00083</a>",,2025-12-03 22:39:25
Secure Federated Learning against Model Poisoning Attacks via Client Filtering,"Duygu Nur Yaldiz, Tuo Zhang, Salman Avestimehr",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.00160"" target=""_blank"">2304.00160</a>",,2025-12-03 22:39:25
To be Robust and to be Fair: Aligning Fairness with Robustness,"Junyi Chai, Xiaoqian Wang",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.00061"" target=""_blank"">2304.00061</a>",,2025-12-03 22:39:25
Improving Fast Adversarial Training with Prior-Guided Knowledge,"Xiaojun Jia, Yong Zhang, Xingxing Wei, Baoyuan Wu, Ke Ma, Jue Wang, Xiaochun Sr Cao",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.00202"" target=""_blank"">2304.00202</a>",,2025-12-03 22:39:25
GradMDM: Adversarial Attack on Dynamic Networks,"Jianhong Pan, Lin Geng Foo, Qichen Zheng, Zhipeng Fan, Hossein Rahmani, Qiuhong Ke, Jun Liu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.06724"" target=""_blank"">2304.06724</a>",,2025-12-03 22:39:25
Learning About Simulated Adversaries from Human Defenders using Interactive Cyber-Defense Games,"Baptiste Prebot, Yinuo Du, Cleotilde Gonzalez",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.01142"" target=""_blank"">2304.01142</a>",,2025-12-03 22:39:25
NetFlick: Adversarial Flickering Attacks on Deep Learning Based Video Compression,"Jung-Woo Chang, Nojan Sheybani, Shehzeen Samarah Hussain, Mojan Javaheripi, Seira Hidano, Farinaz Koushanfar",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.01441"" target=""_blank"">2304.01441</a>",,2025-12-03 22:39:25
Model-Agnostic Reachability Analysis on Deep Neural Networks,"Chi Zhang, Wenjie Ruan, Fu Wang, Peipei Xu, Geyong Min, Xiaowei Huang",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.00813"" target=""_blank"">2304.00813</a>",,2025-12-03 22:39:25
Defending Against Patch-based Backdoor Attacks on Self-Supervised Learning,"Ajinkya Tejankar, Maziar Sanjabi, Qifan Wang, Sinong Wang, Hamed Firooz, Hamed Pirsiavash, Liang Tan",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.01482"" target=""_blank"">2304.01482</a>","<a href=""https://github.com/UCDvision/PatchSearch"" target=""_blank"">UCDvision</a>",2025-12-03 22:39:25
EGC: Image Generation and Classification via a Single Energy-Based Model,"Qiushan Guo, Chuofan Ma, Yi Jiang, Zehuan Yuan, Yizhou Yu, Ping Luo",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.02012"" target=""_blank"">2304.02012</a>",,2025-12-03 22:39:25
Selective Knowledge Sharing for Privacy-Preserving Federated Distillation without A Good Teacher,"Jiawei Shao, Fangzhao Wu, Jun Zhang",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.01731"" target=""_blank"">2304.01731</a>",,2025-12-03 22:39:25
FACE-AUDITOR: Data Auditing in Facial Recognition Systems,"Min Chen, Zhikun Zhang, Tianhao Wang, Michael Backes, Yang Zhang",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.02782"" target=""_blank"">2304.02782</a>","<a href=""https://github.com/MinChen00/Face-Auditor"" target=""_blank"">MinChen00</a>",2025-12-03 22:39:25
Manipulating Federated Recommender Systems: Poisoning with Synthetic Users and Its Countermeasures,"Wei Yuan, Quoc Viet Hung Nguyen, Tieke He, Liang Chen, Hongzhi Yin",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.03054"" target=""_blank"">2304.03054</a>",,2025-12-03 22:39:25
JPEG Compressed Images Can Bypass Protections Against AI Editing,"Pedro Sandoval-Segura, Jonas Geiping, Tom Goldstein",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.02234"" target=""_blank"">2304.02234</a>",,2025-12-03 22:39:25
Hyper-parameter Tuning for Adversarially Robust Models,"Pedro Mendes, Paolo Romano, David Garlan",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.02497"" target=""_blank"">2304.02497</a>",,2025-12-03 22:39:25
Robust Neural Architecture Search,"Xunyu Zhu, Jian Li, Yong Liu, Weiping Wang",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.02845"" target=""_blank"">2304.02845</a>",,2025-12-03 22:39:25
Going Further: Flatness at the Rescue of Early Stopping for Adversarial Example Transferability,"Martin Gubri, Maxime Cordy, Yves Le Traon",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.02688"" target=""_blank"">2304.02688</a>",,2025-12-03 22:39:25
How to choose your best allies for a transferable attack? (99%),"Thibault Maho, Seyed-Mohsen Moosavi-Dezfooli, Teddy Furon",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.02312"" target=""_blank"">2304.02312</a>","<a href=""https://github.com/t-maho/transferability_measure_fit"" target=""_blank"">t-maho</a>",2025-12-03 22:39:25
A Certified Radius-Guided Attack Framework to Image Segmentation Models,"Wenjie Qu, Youqi Li, Binghui Wang",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.02693"" target=""_blank"">2304.02693</a>",,2025-12-03 22:39:25
Benchmarking Robustness to Text-Guided Corruptions,"Mohammadreza Mofayezi, Yasamin Medghalchi",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.02963"" target=""_blank"">2304.02963</a>","<a href=""https://github.com/ckoorosh/RobuText"" target=""_blank"">ckoorosh</a>",2025-12-03 22:39:25
Reliable Learning for Test-time Attacks and Distribution Shift,"Maria-Florina Balcan, Steve Hanneke, Rattana Pukdee, Dravyansh Sharma",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.03370"" target=""_blank"">2304.03370</a>",,2025-12-03 22:39:25
Rethinking Evaluation Protocols of Visual Representations Learned via Self-supervised Learning,"Jae-Hun Lee, Doyoung Yoon, ByeongMoon Ji, Kyungyul Kim, Sangheum Hwang",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.03456"" target=""_blank"">2304.03456</a>",,2025-12-03 22:39:25
Evaluating the Robustness of Machine Reading Comprehension Models to Low Resource Entity Renaming,"Clemencia Siro, Tunde Oluwaseyi Ajayi",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.03145"" target=""_blank"">2304.03145</a>",,2025-12-03 22:39:25
EZClone: Improving DNN Model Extraction Attack via Shape Distillation from GPU Execution Profiles,"Jonah O'Brien Weiss, Tiago Alves, Sandip Kundu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.03388"" target=""_blank"">2304.03388</a>",,2025-12-03 22:39:25
Improving Visual Question Answering Models through Robustness Analysis and In-Context Learning with a Chain of Basic Questions,"Jia-Hong Huang, Modar Alfadly, Bernard Ghanem, Marcel Worring",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.03147"" target=""_blank"">2304.03147</a>",,2025-12-03 22:39:25
Quantifying and Defending against Privacy Threats on Federated Knowledge Graph Embedding,"Yuke Hu, Wei Liang, Ruofan Wu, Kai Xiao, Weiqiang Wang, Xiaochen Li, Jinfei Liu, Zhan Qin",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.02932"" target=""_blank"">2304.02932</a>",,2025-12-03 22:39:25
Cross-Entropy Loss Functions: Theoretical Analysis and Applications,"Anqi Mao, Mehryar Mohri, Yutao Zhong",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.07288"" target=""_blank"">2304.07288</a>",,2025-12-03 22:39:25
Certified Zeroth-order Black-Box Defense with Robust UNet Denoiser,"Astha Verma, Siddhesh Bangar, A V Subramanyam, Naman Lal, Rajiv Ratn Shah, Shin'ichi Satoh",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.06430"" target=""_blank"">2304.06430</a>",,2025-12-03 22:39:25
Interpretability is a Kind of Safety: An Interpreter-based Ensemble for Adversary Defense,"Jingyuan Wang, Yufan Wu, Mingxuan Li, Xin Lin, Junjie Wu, Chao Li",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.06919"" target=""_blank"">2304.06919</a>",,2025-12-03 22:39:25
Denial-of-Service or Fine-Grained Control: Towards Flexible Model Poisoning Attacks on Federated Learning,"Hangtao Zhang, Zeming Yao, Leo Yu Zhang, Shengshan Hu, Chao Chen, Alan Liew, Zhetao Li",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10783"" target=""_blank"">2304.10783</a>","<a href=""https://github.com/ZhangHangTao/Poisoning-Attack-on-FL"" target=""_blank"">ZhangHangTao</a>",2025-12-03 22:39:25
INK: Inheritable Natural Backdoor Attack Against Model Distillation,"Xiaolei Liu, Ming Yi, Kangyi Ding, Bangzhou Xin, Yixiao Xu, Li Yan, Chao Shen",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10985"" target=""_blank"">2304.10985</a>",,2025-12-03 22:39:25
Universal Adversarial Backdoor Attacks to Fool Vertical Federated Learning in Cloud-Edge Collaboration,"Peng Chen, Xin Du, Zhihui Lu, Hongfeng Chai",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.11432"" target=""_blank"">2304.11432</a>",,2025-12-03 22:39:25
Detecting Adversarial Faces Using Only Real Face Self-Perturbations,"Qian Wang, Yongqin Xian, Hefei Ling, Jinyuan Zhang, Xiaorui Lin, Ping Li, Jiazhong Chen, Ning Yu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.11359"" target=""_blank"">2304.11359</a>",,2025-12-03 22:39:25
Evading DeepFake Detectors via Adversarial Statistical Consistency,"Yang Hou, Qing Guo, Yihao Huang, Xiaofei Xie, Lei Ma, Jianjun Zhao",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.11670"" target=""_blank"">2304.11670</a>",,2025-12-03 22:39:25
StyLess: Boosting the Transferability of Adversarial Examples,"Kaisheng Liang, Bin Xiao",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.11579"" target=""_blank"">2304.11579</a>",,2025-12-03 22:39:25
Robust Tickets Can Transfer Better: Drawing More Transferable Subnetworks in Transfer Learning,"Yonggan Fu, Ye Yuan, Shang Wu, Jiayi Yuan, Yingyan Celine Lin",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.11834"" target=""_blank"">2304.11834</a>",,2025-12-03 22:39:25
Opinion Control under Adversarial Network Perturbation: A Stackelberg Game Approach,"Yuejiang Li, Zhanjiang Chen, H. Vicky Zhao",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.12540"" target=""_blank"">2304.12540</a>",,2025-12-03 22:39:25
Enhancing Fine-Tuning Based Backdoor Defense with Sharpness-Aware Minimization,"Mingli Zhu, Shaokui Wei, Li Shen, Yanbo Fan, Baoyuan Wu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.11823"" target=""_blank"">2304.11823</a>",,2025-12-03 22:39:25
Combining Adversaries with Anti-adversaries in Training,"Xiaoling Zhou, Nan Yang, Ou Wu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.12550"" target=""_blank"">2304.12550</a>",,2025-12-03 22:39:25
Evaluating Adversarial Robustness on Document Image Classification,"Timothée Fronteau, Arnaud Paran, Aymen Shabou",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.12486"" target=""_blank"">2304.12486</a>",,2025-12-03 22:39:25
LSTM-based Load Forecasting Robustness Against Noise Injection Attack in Microgrid,"Amirhossein Nazeri, Pierluigi Pisu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.13104"" target=""_blank"">2304.13104</a>",,2025-12-03 22:39:25
Lyapunov-Stable Deep Equilibrium Models,"Haoyu Chu, Shikui Wei, Ting Liu, Yao Zhao, Yuto Miyatake",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.12707"" target=""_blank"">2304.12707</a>",,2025-12-03 22:39:25
SHIELD: Thwarting Code Authorship Attribution,"Mohammed Abuhamad, Changhun Jung, David Mohaisen, DaeHun Nyang",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.13255"" target=""_blank"">2304.13255</a>",,2025-12-03 22:39:25
Generating Adversarial Examples with Task Oriented Multi-Objective Optimization,"Anh Bui, Trung Le, He Zhao, Quan Tran, Paul Montague, Dinh Phung",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.13229"" target=""_blank"">2304.13229</a>","<a href=""https://github.com/tuananhbui89/TAMOO"" target=""_blank"">tuananhbui89</a>",2025-12-03 22:39:25
Improving Robustness Against Adversarial Attacks with Deeply Quantized Neural Networks,"Ferheen Ayaz, Idris Zakariyya, José Cano, Sye Loong Keoh, Jeremy Singer, Danilo Pau, Mounia Kharbouche-Harrari",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.12829"" target=""_blank"">2304.12829</a>",,2025-12-03 22:39:25
Blockchain-based Federated Learning with SMPC Model Verification Against Poisoning Attack for Healthcare Systems,"Aditya Pribadi Kalapaaking, Ibrahim Khalil, Xun Yi",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.13360"" target=""_blank"">2304.13360</a>",,2025-12-03 22:39:25
Detection of Adversarial Physical Attacks in Time-Series Image Data,"Ramneet Kaur, Yiannis Kantaros, Wenwen Si, James Weimer, Insup Lee",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.13919"" target=""_blank"">2304.13919</a>",,2025-12-03 22:39:25
Improving Adversarial Transferability via Intermediate-level Perturbation Decay,"Qizhang Li, Yiwen Guo, Wangmeng Zuo, Hao Chen",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.13410"" target=""_blank"">2304.13410</a>","<a href=""https://github.com/qizhangli/ILPD-attack"" target=""_blank"">qizhangli</a>",2025-12-03 22:39:25
Interactive Greybox Penetration Testing for Cloud Access Control using IAM Modeling and Deep Reinforcement Learning,"Yang Hu, Wenxi Wang, Sarfraz Khurshid, Mohit Tiwari",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.14540"" target=""_blank"">2304.14540</a>",,2025-12-03 22:39:25
Deep Intellectual Property Protection: A Survey,"Yuchen Sun, Tianpeng Liu, Panhe Hu, Qing Liao, Shaojing Fu, Nenghai Yu, Deke Guo, Yongxiang Liu, Li Liu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.14613"" target=""_blank"">2304.14613</a>",,2025-12-03 22:39:25
Origin Tracing and Detecting of LLMs,"Linyang Li, Pengyu Wang, Ke Ren, Tianxiang Sun, Xipeng Qiu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.14072"" target=""_blank"">2304.14072</a>","<a href=""https://github.com/OpenLMLab/"" target=""_blank"">OpenLMLab</a>",2025-12-03 22:39:25
Improve Video Representation with Temporal Adversarial Augmentation,"Jinhao Duan, Quanfu Fan, Hao Cheng, Xiaoshuang Shi, Kaidi Xu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.14601"" target=""_blank"">2304.14601</a>","<a href=""https://github.com/jinhaoduan/TAF"" target=""_blank"">jinhaoduan</a>",2025-12-03 22:39:25
ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger,"Jiazhao Li, Yijin Yang, Zhuofeng Wu, V. G. Vinod Vydiswaran, Chaowei Xiao",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.14475"" target=""_blank"">2304.14475</a>",,2025-12-03 22:39:25
Boosting Big Brother: Attacking Search Engines with Encodings,"Nicholas Boucher, Luca Pajola, Ilia Shumailov, Ross Anderson, Mauro Conti",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.14031"" target=""_blank"">2304.14031</a>",,2025-12-03 22:39:25
Adversary Aware Continual Learning,"Muhammad Umer, Robi Polikar",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.14483"" target=""_blank"">2304.14483</a>",,2025-12-03 22:39:25
SAM Meets Robotic Surgery: An Empirical Study in Robustness Perspective,"An Wang, Mobarakol Islam, Mengya Xu, Yang Zhang, Hongliang Ren",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.14674"" target=""_blank"">2304.14674</a>",,2025-12-03 22:39:25
faulTPM: Exposing AMD fTPMs' Deepest Secrets,"Hans Niklas Jacob, Christian Werling, Robert Buhren, Jean-Pierre Seifert",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.14717"" target=""_blank"">2304.14717</a>",,2025-12-03 22:39:25
The Power of Typed Affine Decision Structures: A Case Study,"Gerrit Nolte, Maximilian Schlüter, Alnis Murtovi, Bernhard Steffen",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.14888"" target=""_blank"">2304.14888</a>",,2025-12-03 22:39:25
JoB-VS: Joint Brain-Vessel Segmentation in TOF-MRA Images,"Natalia Valderrama, Ioannis Pitsiorlas, Luisa Vargas, Pablo Arbeláez, Maria A. Zuluaga",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.07744"" target=""_blank"">2304.07744</a>",,2025-12-03 22:39:25
Individual Fairness in Bayesian Neural Networks,"Alice Doherty, Matthew Wicker, Luca Laurenti, Andrea Patane",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10828"" target=""_blank"">2304.10828</a>",,2025-12-03 22:39:25
Fusion is Not Enough: Single-Modal Attacks to Compromise Fusion Models in Autonomous Driving,"Zhiyuan Cheng, Hongjun Choi, James Liang, Shiwei Feng, Guanhong Tao, Dongfang Liu, Michael Zuzak, Xiangyu Zhang",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.14614"" target=""_blank"">2304.14614</a>",,2025-12-03 22:39:25
MAWSEO: Adversarial Wiki Search Poisoning for Illicit Online Promotion,"Zilong Lin, Zhengyi Li, Xiaojing Liao, XiaoFeng Wang, Xiaozhong Liu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.11300"" target=""_blank"">2304.11300</a>",,2025-12-03 22:39:25
Density-Insensitive Unsupervised Domain Adaption on 3D Object Detection,"Qianjiang Hu, Daizong Liu, Wei Hu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.09446"" target=""_blank"">2304.09446</a>","<a href=""https://github.com/WoodwindHu/DTS"" target=""_blank"">WoodwindHu</a>",2025-12-03 22:39:25
RNN-Guard: Certified Robustness Against Multi-frame Attacks for Recurrent Neural Networks,"Yunruo Zhang, Tianyu Du, Shouling Ji, Peng Tang, Shanqing Guo",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.07980"" target=""_blank"">2304.07980</a>",,2025-12-03 22:39:25
A Random-patch based Defense Strategy Against Physical Attacks for Face Recognition Systems,"JiaHao Xie, Ye Luo, Jianwei Lu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.07822"" target=""_blank"">2304.07822</a>",,2025-12-03 22:39:25
Towards the Universal Defense for Query-Based Audio Adversarial Attacks,"Feng Guo, Zheng Sun, Yuxuan Chen, Lei Ju",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10088"" target=""_blank"">2304.10088</a>",,2025-12-03 22:39:25
OOD-CV-v2: An extended Benchmark for Robustness to Out-of-Distribution Shifts of Individual Nuisances in Natural Images,"Bingchen Zhao, Jiahao Wang, Wufei Ma, Artur Jesslen, Siwei Yang, Shaozuo Yu, Oliver Zendel, Christian Theobalt, Alan Yuille, Adam Kortylewski",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10266"" target=""_blank"">2304.10266</a>",,2025-12-03 22:39:25
GrOVe: Ownership Verification of Graph Neural Networks using Embeddings,"Asim Waheed, Vasisht Duddu, N. Asokan",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.08566"" target=""_blank"">2304.08566</a>",,2025-12-03 22:39:25
Evil from Within: Machine Learning Backdoors through Hardware Trojans,"Alexander Warnecke, Julian Speith, Jan-Niklas Möller, Konrad Rieck, Christof Paar",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.08411"" target=""_blank"">2304.08411</a>",,2025-12-03 22:39:25
Generative models improve fairness of medical classifiers under distribution shifts,"Ira Ktena, Olivia Wiles, Isabela Albuquerque, Sylvestre-Alvise Rebuffi, Ryutaro Tanno, Abhijit Guha Roy, Shekoofeh Azizi, Danielle Belgrave, Pushmeet Kohli, Alan Karthikesalingam, Taylan Cemgil, Sven Gowal",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.09218"" target=""_blank"">2304.09218</a>",,2025-12-03 22:39:25
In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT,"Xinyue Shen, Zeyuan Chen, Michael Backes, Yang Zhang",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.08979"" target=""_blank"">2304.08979</a>",,2025-12-03 22:39:25
Masked Language Model Based Textual Adversarial Example Detection,"Xiaomei Zhang, Zhaoxi Zhang, Qi Zhong, Xufei Zheng, Yanjun Zhang, Shengshan Hu, Leo Yu Zhang",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.08767"" target=""_blank"">2304.08767</a>","<a href=""https://github.com/mlmddetection/MLMDdetection"" target=""_blank"">mlmddetection</a>",2025-12-03 22:39:25
Towards the Transferable Audio Adversarial Attack via Ensemble Methods,"Feng Guo, Zheng Sun, Yuxuan Chen, Lei Ju",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.08811"" target=""_blank"">2304.08811</a>",,2025-12-03 22:39:25
Wavelets Beat Monkeys at Adversarial Robustness,"Jingtong Su, Julia Kempe",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.09403"" target=""_blank"">2304.09403</a>",,2025-12-03 22:39:25
Fundamental Limitations of Alignment in Large Language Models,"Yotam Wolf, Noam Wies, Oshri Avnery, Yoav Levine, Amnon Shashua",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.11082"" target=""_blank"">2304.11082</a>",,2025-12-03 22:39:25
"On the Robustness of Aspect-based Sentiment Analysis: Rethinking Model, Data, and Training","Hao Fei, Tat-Seng Chua, Chenliang Li, Donghong Ji, Meishan Zhang, Yafeng Ren",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.09563"" target=""_blank"">2304.09563</a>",,2025-12-03 22:39:25
Topic-oriented Adversarial Attacks against Black-box Neural Ranking Models,"Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Rijke Maarten de, Wei Chen, Yixing Fan, Xueqi Cheng",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.14867"" target=""_blank"">2304.14867</a>",,2025-12-03 22:39:25
"Secure Split Learning against Property Inference, Data Reconstruction, and Feature Space Hijacking Attacks","Yunlong Mao, Zexi Xin, Zhenyu Li, Jue Hong, Qingyou Yang, Sheng Zhong",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.09515"" target=""_blank"">2304.09515</a>",,2025-12-03 22:39:25
An Analysis of the Completion Time of the BB84 Protocol,"Sounak Kar, Jean-Yves Le Boudec",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10218"" target=""_blank"">2304.10218</a>",,2025-12-03 22:39:25
Using Z3 for Formal Modeling and Verification of FNN Global Robustness,"Yihao Zhang, Zeming Wei, Xiyue Zhang, Meng Sun",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10558"" target=""_blank"">2304.10558</a>",,2025-12-03 22:39:25
GREAT Score: Global Robustness Evaluation of Adversarial Perturbation using Generative Models,"Zaitang Li, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.09875"" target=""_blank"">2304.09875</a>",,2025-12-03 22:39:25
Can Perturbations Help Reduce Investment Risks? Risk-Aware Stock Recommendation via Split Variational Adversarial Training,"Jiezhu Cheng, Kaizhu Huang, Zibin Zheng",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.11043"" target=""_blank"">2304.11043</a>",,2025-12-03 22:39:25
Diversifying the High-level Features for better Adversarial Transferability,"Zhiyuan Wang, Zeliang Zhang, Siyuan Liang, Xiaosen Wang",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10136"" target=""_blank"">2304.10136</a>","<a href=""https://github.com/Trustworthy-AI-Group/DHF"" target=""_blank"">Trustworthy-AI-Group</a>",2025-12-03 22:39:25
Adversarial Infrared Blocks: A Black-box Attack to Thermal Infrared Detectors at Multiple Angles in Physical World,"Chengyin Hu, Weiwen Shi, Tingsong Jiang, Wen Yao, Ling Tian, Xiaoqian Chen",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10712"" target=""_blank"">2304.10712</a>",,2025-12-03 22:39:25
Certified Adversarial Robustness Within Multiple Perturbation Bounds,"Soumalya Nandi, Sravanti Addepalli, Harsh Rangwani, R. Venkatesh Babu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10446"" target=""_blank"">2304.10446</a>",,2025-12-03 22:39:25
A Plug-and-Play Defensive Perturbation for Copyright Protection of DNN-based Applications,"Donghua Wang, Wen Yao, Tingsong Jiang, Weien Zhou, Lang Lin, Xiaoqian Chen",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10679"" target=""_blank"">2304.10679</a>",,2025-12-03 22:39:25
Enhancing object detection robustness: A synthetic and natural perturbation approach,"Nilantha Premakumara, Brian Jalaian, Niranjan Suri, Hooman Samani",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10622"" target=""_blank"">2304.10622</a>",,2025-12-03 22:39:25
RoCOCO: Robustness Benchmark of MS-COCO to Stress-test Image-Text Matching Models,"Seulki Park, Daeho Um, Hajung Yoon, Sanghyuk Chun, Sangdoo Yun, Jin Young Choi",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10727"" target=""_blank"">2304.10727</a>","<a href=""https://github.com/pseulki/rococo"" target=""_blank"">pseulki</a>",2025-12-03 22:39:25
Get Rid Of Your Trail: Remotely Erasing Backdoors in Federated Learning,"Manaar Alam, Hithem Lamri, Michail Maniatakos",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10638"" target=""_blank"">2304.10638</a>",,2025-12-03 22:39:25
Learning Sample Difficulty from Pre-trained Models for Reliable Prediction,"Peng Cui, Dan Zhang, Zhijie Deng, Yinpeng Dong, Jun Zhu",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10127"" target=""_blank"">2304.10127</a>",,2025-12-03 22:39:25
Jedi: Entropy-based Localization and Removal of Adversarial Patches,"Bilel Tarchoun, Anouar Ben Khalifa, Mohamed Ali Mahjoub, Nael Abu-Ghazaleh, Ihsen Alouani",arXiv,2023-04,"<a href=""http://arxiv.org/abs/2304.10029"" target=""_blank"">2304.10029</a>",,2025-12-03 22:39:25
Multi-metrics adaptively identifies backdoors in Federated learning,"Siquan Huang, Yijiang Li, Chong Chen, Leyu Shi, Ying Gao",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06601"" target=""_blank"">2303.06601</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defenses in Machine Learning-Powered Networks: A Contemporary Survey,"Yulong Wang, Tong Sun, Shenghong Li, Xin Yuan, Wei Ni, Ekram Hossain, H. Vincent Poor",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06302"" target=""_blank"">2303.06302</a>",,2025-12-03 22:39:25
Backdoor Defense via Deconfounded Representation Learning,"Zaixi Zhang, Qi Liu, Zhicai Wang, Zepu Lu, Qingyong Hu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06818"" target=""_blank"">2303.06818</a>","<a href=""https://github.com/zaixizhang/CBD"" target=""_blank"">zaixizhang</a>",2025-12-03 22:39:25
Interpreting Hidden Semantics in the Intermediate Layers of 3D Point Cloud Classification Neural Network,"Weiquan Liu, Minghao Liu, Shijun Zheng, Cheng Wang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06652"" target=""_blank"">2303.06652</a>",,2025-12-03 22:39:25
Boosting Source Code Learning with Data Augmentation: An Empirical Study,"Zeming Dong, Qiang Hu, Yuejun Guo, Zhenya Zhang, Maxime Cordy, Mike Papadakis, Yves Le Traon, Jianjun Zhao",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06808"" target=""_blank"">2303.06808</a>",,2025-12-03 22:39:25
Improving the Robustness of Deep Convolutional Neural Networks Through Feature Learning,"Jin Ding, Jie-Chao Zhao, Yong-Zhi Sun, Ping Tan, Ji-En Ma, You-Tong Fang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06425"" target=""_blank"">2303.06425</a>",,2025-12-03 22:39:25
SHIELD: An Adaptive and Lightweight Defense against the Remote Power Side-Channel Attacks on Multi-tenant FPGAs,"Mahya Morid Ahmadi, Faiq Khalid, Radha Vaidya, Florian Kriebel, Andreas Steininger, Muhammad Shafique",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06486"" target=""_blank"">2303.06486</a>",,2025-12-03 22:39:25
Turning Strengths into Weaknesses: A Certified Robustness Inspired Attack Framework against Graph Neural Networks,"Binghui Wang, Meng Pang, Yun Dong",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06199"" target=""_blank"">2303.06199</a>",,2025-12-03 22:39:25
Boosting Adversarial Attacks by Leveraging Decision Boundary Information,"Boheng Zeng, LianLi Gao, QiLong Zhang, ChaoQun Li, JingKuan Song, ShuaiQi Jing",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.05719"" target=""_blank"">2303.05719</a>",,2025-12-03 22:39:25
Adversarial Attacks to Direct Data-driven Control for Destabilization,Hampei Sasahara,arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06837"" target=""_blank"">2303.06837</a>",,2025-12-03 22:39:25
Adapting Contrastive Language-Image Pretrained (CLIP) Models for Out-of-Distribution Detection,"Nikolas Adaloglou, Felix Michels, Tim Kaiser, Markus Kollmann",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.05828"" target=""_blank"">2303.05828</a>",,2025-12-03 22:39:25
Investigating Stateful Defenses Against Black-Box Adversarial Examples,"Ryan Feng, Ashish Hooda, Neal Mangaokar, Kassem Fawaz, Somesh Jha, Atul Prakash",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06280"" target=""_blank"">2303.06280</a>",,2025-12-03 22:39:25
MIXPGD: Hybrid Adversarial Training for Speech Recognition Systems,"Aminul Huq, Weiyi Zhang, Xiaolin Hu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.05758"" target=""_blank"">2303.05758</a>",,2025-12-03 22:39:25
Do we need entire training data for adversarial training? (99%),"Vipul Gupta, Apurva Narayan",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06241"" target=""_blank"">2303.06241</a>",,2025-12-03 22:39:25
TrojDiff: Trojan Attacks on Diffusion Models with Diverse Targets,"Weixin Chen, Dawn Song, Bo Li",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.05762"" target=""_blank"">2303.05762</a>","<a href=""https://github.com/chenweixin107/TrojDiff"" target=""_blank"">chenweixin107</a>",2025-12-03 22:39:25
Adaptive Local Adversarial Attacks on 3D Point Clouds for Augmented Reality,"Weiquan Liu, Shijun Zheng, Cheng Wang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06641"" target=""_blank"">2303.06641</a>",,2025-12-03 22:39:25
NoiseCAM: Explainable AI for the Boundary Between Noise and Adversarial Attacks,"Wenkai Tan, Justus Renkhoff, Alvaro Velasquez, Ziyu Wang, Lusi Li, Jian Wang, Shuteng Niu, Fan Yang, Yongxin Liu, Houbing Song",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06151"" target=""_blank"">2303.06151</a>",,2025-12-03 22:39:25
Evaluating the Robustness of Conversational Recommender Systems by Adversarial Examples,"Ali Montazeralghaem, James Allan",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.05575"" target=""_blank"">2303.05575</a>",,2025-12-03 22:39:25
Identification of Systematic Errors of Image Classifiers on Rare Subgroups,"Jan Hendrik Metzen, Robin Hutmacher, N. Grace Hua, Valentyn Boreiko, Dan Zhang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.05072"" target=""_blank"">2303.05072</a>",,2025-12-03 22:39:25
Learning the Legibility of Visual Text Perturbations,"Dev Seth, Rickard Stureborg, Danish Pruthi, Bhuwan Dhingra",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.05077"" target=""_blank"">2303.05077</a>","<a href=""https://github.com/dvsth/learning-legibility-2023"" target=""_blank"">dvsth</a>",2025-12-03 22:39:25
Efficient Certified Training and Robustness Verification of Neural ODEs,"Mustafa Zeqiri, Mark Niklas Müller, Marc Fischer, Martin Vechev",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.05246"" target=""_blank"">2303.05246</a>",,2025-12-03 22:39:25
Feature Unlearning for Pre-trained GANs and VAEs,"Saemi Moon, Seunghyuk Cho, Dongwoo Kim",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.05699"" target=""_blank"">2303.05699</a>",,2025-12-03 22:39:25
Immune Defense: A Novel Adversarial Defense Mechanism for Preventing the Generation of Adversarial Examples,"Jinwei Wang, Hao Wu, Haihua Wang, Jiawei Zhang, Xiangyang Luo, Bin Ma",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.04502"" target=""_blank"">2303.04502</a>",,2025-12-03 22:39:25
Decision-BADGE: Decision-based Adversarial Batch Attack with Directional Gradient Estimation,"Geunhyeok Yu, Minwoo Jeon, Hyoseok Hwang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.04980"" target=""_blank"">2303.04980</a>",,2025-12-03 22:39:25
Exploring Adversarial Attacks on Neural Networks: An Explainable Approach,"Justus Renkhoff, Wenkai Tan, Alvaro Velasquez, illiam Yichen Wang, Yongxin Liu, Jian Wang, Shuteng Niu, Lejla Begic Fazlic, Guido Dartmann, Houbing Song",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06032"" target=""_blank"">2303.06032</a>",,2025-12-03 22:39:25
DNN-Alias: Deep Neural Network Protection Against Side-Channel Attacks via Layer Balancing,"Mahya Morid Ahmadi, Lilas Alrahis, Ozgur Sinanoglu, Muhammad Shafique",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06746"" target=""_blank"">2303.06746</a>",,2025-12-03 22:39:25
Model-tuning Via Prompts Makes NLP Models Adversarially Robust,"Mrigank Raman, Pratyush Maini, J. Zico Kolter, Zachary C. Lipton, Danish Pruthi",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.07320"" target=""_blank"">2303.07320</a>","<a href=""https://github.com/acmi-lab/mvp"" target=""_blank"">acmi-lab</a>",2025-12-03 22:39:25
Adv-Bot: Realistic Adversarial Botnet Attacks against Network Intrusion Detection Systems,"Islam Debicha, Benjamin Cochez, Tayeb Kenaza, Thibault Debatty, Jean-Michel Dricot, Wim Mees",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06664"" target=""_blank"">2303.06664</a>",,2025-12-03 22:39:25
EvalAttAI: A Holistic Approach to Evaluating Attribution Maps in Robust and Non-Robust Models,"Ian E. Nielsen, Ravi P. Ramachandran, Nidhal Bouaynaya, Hassan M. Fathallah-Shaykh, Ghulam Rasool",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.08866"" target=""_blank"">2303.08866</a>",,2025-12-03 22:39:25
BeamAttack: Generating High-quality Textual Adversarial Examples through Beam Search and Mixed Semantic Spaces,"Hai Zhu, Qingyang Zhao, Yuren Wu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.07199"" target=""_blank"">2303.07199</a>","<a href=""https://github.com/zhuhai-ustc/beamattack/tree/master"" target=""_blank"">tree</a>",2025-12-03 22:39:25
Rethinking Model Ensemble in Transfer-based Adversarial Attacks,"Huanran Chen, Yichi Zhang, Yinpeng Dong, Jun Zhu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.09105"" target=""_blank"">2303.09105</a>",,2025-12-03 22:39:25
Class Attribute Inference Attacks: Inferring Sensitive Class Information by Diffusion-Based Attribute Manipulations,"Lukas Struppek, Dominik Hintersdorf, Felix Friedrich, Manuel Brack, Patrick Schramowski, Kristian Kersting",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.09289"" target=""_blank"">2303.09289</a>",,2025-12-03 22:39:25
Among Us: Adversarially Robust Collaborative Perception by Consensus,"Yiming Li, Qi Fang, Jiamu Bai, Siheng Chen, Felix Juefei-Xu, Chen Feng",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.09495"" target=""_blank"">2303.09495</a>",,2025-12-03 22:39:25
Moving Target Defense for Service-oriented Mission-critical Networks,"Doğanalp Ergenç, Florian Schneider, Peter Kling, Mathias Fischer",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.09893"" target=""_blank"">2303.09893</a>",,2025-12-03 22:39:25
Exorcising ''Wraith'': Protecting LiDAR-based Object Detector in Automated Driving System from Appearing Attacks,"Qifan Xiao, Xudong Pan, Yifan Lu, Mi Zhang, Jiarun Dai, Min Yang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.09731"" target=""_blank"">2303.09731</a>",,2025-12-03 22:39:25
Rethinking White-Box Watermarks on Deep Learning Models under Neural Structural Obfuscation,"Yifan Yan, Xudong Pan, Mi Zhang, Min Yang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.09732"" target=""_blank"">2303.09732</a>",,2025-12-03 22:39:25
Black-box Adversarial Example Attack towards FCG Based Android Malware Detection under Incomplete Feature Information,"Heng Li, Zhang Cheng, Bang Wu, Liheng Yuan, Cuiying Gao, Wei Yuan, Xiapu Luo",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.08509"" target=""_blank"">2303.08509</a>",,2025-12-03 22:39:25
Robust Evaluation of Diffusion-Based Adversarial Purification,"Minjong Lee, Dongwoo Kim",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.09051"" target=""_blank"">2303.09051</a>",,2025-12-03 22:39:25
DeeBBAA: A benchmark Deep Black Box Adversarial Attack against Cyber-Physical Power Systems,"Arnab Bhattacharjee, Tapan K. Saha, Ashu Verma, Sukumar Mishra",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.09024"" target=""_blank"">2303.09024</a>",,2025-12-03 22:39:25
The Devil's Advocate: Shattering the Illusion of Unexploitable Data using Diffusion Models,"Hadi M. Dolatabadi, Sarah Erfani, Christopher Leckie",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.08500"" target=""_blank"">2303.08500</a>","<a href=""https://github.com/hmdolatabadi/AVATAR"" target=""_blank"">hmdolatabadi</a>",2025-12-03 22:39:25
Agnostic Multi-Robust Learning Using ERM,"Saba Ahmadi, Avrim Blum, Omar Montasser, Kevin Stangl",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.08944"" target=""_blank"">2303.08944</a>",,2025-12-03 22:39:25
Pixel-wise Gradient Uncertainty for Convolutional Neural Networks applied to Out-of-Distribution Segmentation,"Kira Maag, Tobias Riedlinger",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06920"" target=""_blank"">2303.06920</a>",,2025-12-03 22:39:25
"Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness with Dataset Reinforcement","Fartash Faghri, Hadi Pouransari, Sachin Mehta, Mehrdad Farajtabar, Ali Farhadi, Mohammad Rastegari, Oncel Tuzel",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.08983"" target=""_blank"">2303.08983</a>",,2025-12-03 22:39:25
GPT-4 Technical Report,"Rai OpenAI, Josh Rai Achiam, Steven Rai Adler, Sandhini Rai Agarwal, Lama Rai Ahmad, Ilge Rai Akkaya, Florencia Leoni Rai Aleman, Diogo Rai Almeida, Janko Rai Altenschmidt, Sam Rai Altman, Shyamal Rai Anadkat, Red Rai Avila, Igor Rai Babuschkin, Suchir Rai Balaji, Valerie Rai Balcom, Paul Rai Baltescu, Haiming Rai Bao, Mohammad Rai Bavarian, Jeff Rai Belgum, Irwan Rai Bello, Jake Rai Berdine, Gabriel Rai Bernadett-Shapiro, Christopher Rai Berner, Lenny Rai Bogdonoff, Oleg Rai Boiko, Madelaine Rai Boyd, Anna-Luisa Rai Brakman, Greg Rai Brockman, Tim Rai Brooks, Miles Rai Brundage, Kevin Rai Button, Trevor Rai Cai, Rosie Rai Campbell, Andrew Rai Cann, Brittany Rai Carey, Chelsea Rai Carlson, Rory Rai Carmichael, Brooke Rai Chan, Che Rai Chang, Fotis Rai Chantzis, Derek Rai Chen, Sully Rai Chen, Ruby Rai Chen, Jason Rai Chen, Mark Rai Chen, Ben Rai Chess, Chester Rai Cho, Casey Rai Chu, Hyung Won Rai Chung, Dave Rai Cummings, Jeremiah Rai Currier, Yunxing Rai Dai, Cory Rai Decareaux, Thomas Rai Degry, Noah Rai Deutsch, Damien Rai Deville, Arka Rai Dhar, David Rai Dohan, Steve Rai Dowling, Sheila Rai Dunning, Adrien Rai Ecoffet, Atty Rai Eleti, Tyna Rai Eloundou, David Rai Farhi, Liam Rai Fedus, Niko Rai Felix, Simón Posada Rai Fishman, Juston Rai Forte, Isabella Rai Fulford, Leo Rai Gao, Elie Rai Georges, Christian Rai Gibson, Vik Rai Goel, Tarun Rai Gogineni, Gabriel Rai Goh, Rapha Rai Gontijo-Lopes, Jonathan Rai Gordon, Morgan Rai Grafstein, Scott Rai Gray, Ryan Rai Greene, Joshua Rai Gross, Shixiang Shane Rai Gu, Yufei Rai Guo, Chris Rai Hallacy, Jesse Rai Han, Jeff Rai Harris, Yuchen Rai He, Mike Rai Heaton, Johannes Rai Heidecke, Chris Rai Hesse, Alan Rai Hickey, Wade Rai Hickey, Peter Rai Hoeschele, Brandon Rai Houghton, Kenny Rai Hsu, Shengli Rai Hu, Xin Rai Hu, Joost Rai Huizinga, Shantanu Rai Jain, Shawn Rai Jain, Joanne Rai Jang, Angela Rai Jiang, Roger Rai Jiang, Haozhun Rai Jin, Denny Rai Jin, Shino Rai Jomoto, Billie Rai Jonn, Heewoo Rai Jun, Tomer Rai Kaftan, Łukasz Rai Kaiser, Ali Rai Kamali, Ingmar Rai Kanitscheider, Nitish Shirish Rai Keskar, Tabarak Rai Khan, Logan Rai Kilpatrick, Jong Wook Rai Kim, Christina Rai Kim, Yongjik Rai Kim, Jan Hendrik Rai Kirchner, Jamie Rai Kiros, Matt Rai Knight, Daniel Rai Kokotajlo, Łukasz Rai Kondraciuk, Andrew Rai Kondrich, Aris Rai Konstantinidis, Kyle Rai Kosic, Gretchen Rai Krueger, Vishal Rai Kuo, Michael Rai Lampe, Ikai Rai Lan, Teddy Rai Lee, Jan Rai Leike, Jade Rai Leung, Daniel Rai Levy, Chak Ming Rai Li, Rachel Rai Lim, Molly Rai Lin, Stephanie Rai Lin, Mateusz Rai Litwin, Theresa Rai Lopez, Ryan Rai Lowe, Patricia Rai Lue, Anna Rai Makanju, Kim Rai Malfacini, Sam Rai Manning, Todor Rai Markov, Yaniv Rai Markovski, Bianca Rai Martin, Katie Rai Mayer, Andrew Rai Mayne, Bob Rai McGrew, Scott Mayer Rai McKinney, Christine Rai McLeavey, Paul Rai McMillan, Jake Rai McNeil, David Rai Medina, Aalok Rai Mehta, Jacob Rai Menick, Luke Rai Metz, Andrey Rai Mishchenko, Pamela Rai Mishkin, Vinnie Rai Monaco, Evan Rai Morikawa, Daniel Rai Mossing, Tong Rai Mu, Mira Rai Murati, Oleg Rai Murk, David Rai Mély, Ashvin Rai Nair, Reiichiro Rai Nakano, Rajeev Rai Nayak, Arvind Rai Neelakantan, Richard Rai Ngo, Hyeonwoo Rai Noh, Long Rai Ouyang, Cullen Rai O'Keefe, Jakub Rai Pachocki, Alex Rai Paino, Joe Rai Palermo, Ashley Rai Pantuliano, Giambattista Rai Parascandolo, Joel Rai Parish, Emy Rai Parparita, Alex Rai Passos, Mikhail Rai Pavlov, Andrew Rai Peng, Adam Rai Perelman, Filipe de Avila Belbute Rai Peres, Michael Rai Petrov, Henrique Ponde de Oliveira Rai Pinto, Rai Michael, Pokorny, Michelle Pokrass, Vitchyr H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine B. Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe Cerón Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJ Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, Barret Zoph",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.08774"" target=""_blank"">2303.08774</a>",,2025-12-03 22:39:25
Resilient Dynamic Average Consensus based on Trusted agents,"Shamik Bhattacharyya, Rachel Kalpana Kalaimani",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.08171"" target=""_blank"">2303.08171</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness with Hypersphere Embedding and Angular-based Regularizations,"Olukorede Fakorede, Ashutosh Nirala, Modeste Atsague, Jin Tian",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.08289"" target=""_blank"">2303.08289</a>",,2025-12-03 22:39:25
Review on the Feasibility of Adversarial Evasion Attacks and Defenses for Network Intrusion Detection Systems,"Islam Debicha, Benjamin Cochez, Tayeb Kenaza, Thibault Debatty, Jean-Michel Dricot, Wim Mees",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.07003"" target=""_blank"">2303.07003</a>",,2025-12-03 22:39:25
Constrained Adversarial Learning for Automated Software Testing: a literature review,"João Vitorino, Tiago Dias, Tiago Fonseca, Eva Maia, Isabel Praça",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.07546"" target=""_blank"">2303.07546</a>",,2025-12-03 22:39:25
Can Adversarial Examples Be Parsed to Reveal Victim Model Information? (99%),"Yuguang Yao, Jiancheng Liu, Yifan Gong, Xiaoming Liu, Yanzhi Wang, Xue Lin, Sijia Liu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.07474"" target=""_blank"">2303.07474</a>",,2025-12-03 22:39:25
SMUG: Towards robust MRI reconstruction by smoothed unrolling,"Hui Li, Jinghan Jia, Shijun Liang, Yuguang Yao, Saiprasad Ravishankar, Sijia Liu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.12735"" target=""_blank"">2303.12735</a>","<a href=""https://github.com/LGM70/SMUG"" target=""_blank"">LGM70</a>",2025-12-03 22:39:25
Robust Contrastive Language-Image Pretraining against Adversarial Attacks,"Wenhan Yang, Baharan Mirzasoleiman",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.06854"" target=""_blank"">2303.06854</a>",,2025-12-03 22:39:25
Model Extraction Attacks on Split Federated Learning,"Jingtao Li, Adnan Siraj Rakin, Xing Chen, Li Yang, Zhezhi He, Deliang Fan, Chaitali Chakrabarti",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.08581"" target=""_blank"">2303.08581</a>",,2025-12-03 22:39:25
WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminative Analysis,"Yiye Chen, Yunzhi Lin, Ruinian Xu, Patricio A. Vela",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.07543"" target=""_blank"">2303.07543</a>",,2025-12-03 22:39:25
Verifying the Robustness of Automatic Credibility Assessment,"Piotr Przybyła, Alexander Shvets, Horacio Saggion",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.08032"" target=""_blank"">2303.08032</a>",,2025-12-03 22:39:25
Demystifying Causal Features on Adversarial Examples and Causal Inoculation for Robust Network by Adversarial Instrumental Variable Regression,"Junho Kim. Byung-Kwan Lee, Yong Man Ro",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01052"" target=""_blank"">2303.01052</a>",,2025-12-03 22:39:25
DeepGD: A Multi-Objective Black-Box Test Selection Approach for Deep Neural Networks,"Zohreh Aghababaeyan, Manel Abdellatif, Mahboubeh Dadkhah, Lionel Briand",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.04878"" target=""_blank"">2303.04878</a>",,2025-12-03 22:39:25
Adversarial Examples Exist in Two-Layer ReLU Networks for Low Dimensional Data Manifolds,"Odelia Melamed, Gilad Yehudai, Gal Vardi",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.00783"" target=""_blank"">2303.00783</a>",,2025-12-03 22:39:25
AdvRain: Adversarial Raindrops to Attack Camera-based Smart Vision Systems,"Amira Guesmi, Muhammad Abdullah Hanif, Muhammad Shafique",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01338"" target=""_blank"">2303.01338</a>",,2025-12-03 22:39:25
APARATE: Adaptive Adversarial Patch for CNN-based Monocular Depth Estimation for Autonomous Navigation,"Amira Guesmi, Muhammad Abdullah Hanif, Ihsen Alouani, Muhammad Shafique",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01351"" target=""_blank"">2303.01351</a>",,2025-12-03 22:39:25
Targeted Adversarial Attacks against Neural Machine Translation,"Sahar Sadrizadeh, AmirHossein Dabiri Aghdam, Ljiljana Dolamic, Pascal Frossard",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01068"" target=""_blank"">2303.01068</a>",,2025-12-03 22:39:25
The Double-Edged Sword of Implicit Bias: Generalization vs,"Spencer Frei, Gal Vardi, Peter L. Bartlett, Nathan Srebro",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01456"" target=""_blank"">2303.01456</a>",,2025-12-03 22:39:25
Feature Perturbation Augmentation for Reliable Evaluation of Importance Estimators in Neural Networks,"Lennart Brocki, Neo Christopher Chung",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01538"" target=""_blank"">2303.01538</a>",,2025-12-03 22:39:25
D-Score: An Expert-Based Method for Assessing the Detectability of IoT-Related Cyber-Attacks,"Yair Meidan, Daniel Benatar, Ron Bitton, Dan Avraham, Asaf Shabtai",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01041"" target=""_blank"">2303.01041</a>",,2025-12-03 22:39:25
Interpretable System Identification and Long-term Prediction on Time-Series Data,"Xiaoyi Liu, Duxin Chen, Wenjia Wei, Xia Zhu, Wenwu Yu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01193"" target=""_blank"">2303.01193</a>",,2025-12-03 22:39:25
Consistency Models,"Yang Song, Prafulla Dhariwal, Mark Chen, Ilya Sutskever",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01469"" target=""_blank"">2303.01469</a>",,2025-12-03 22:39:25
CADeSH: Collaborative Anomaly Detection for Smart Homes,"Yair Meidan, Dan Avraham, Hanan Libhaber, Asaf Shabtai",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01021"" target=""_blank"">2303.01021</a>",,2025-12-03 22:39:25
Conflict-Based Cross-View Consistency for Semi-Supervised Semantic Segmentation,"Zicheng Wang, Zhen Zhao, Xiaoxia Xing, Dong Xu, Xiangyu Kong, Luping Zhou",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01276"" target=""_blank"">2303.01276</a>","<a href=""https://github.com/xiaoyao3302/CCVC"" target=""_blank"">xiaoyao3302</a>",2025-12-03 22:39:25
To Make Yourself Invisible with Adversarial Semantic Contours,"Yichi Zhang, Zijian Zhu, Hang Su, Jun Zhu, Shibao Zheng, Yuan He, Hui Xue",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.00284"" target=""_blank"">2303.00284</a>",,2025-12-03 22:39:25
Frauds Bargain Attack: Generating Adversarial Text Samples via Word Manipulation Process,"Mingze Ni, Zhensu Sun, Wei Liu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01234"" target=""_blank"">2303.01234</a>",,2025-12-03 22:39:25
TrojText: Test-time Invisible Textual Trojan Insertion,"Qian Lou, Yepeng Liu, Bo Feng",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.02242"" target=""_blank"">2303.02242</a>","<a href=""https://github.com/UCF-ML-Research/TrojText"" target=""_blank"">UCF-ML-Research</a>",2025-12-03 22:39:25
A Practical Upper Bound for the Worst-Case Attribution Deviations,"Fan Wang, Adams Wai-Kin Kong",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.00340"" target=""_blank"">2303.00340</a>",,2025-12-03 22:39:25
Combating Exacerbated Heterogeneity for Robust Models in Federated Learning,"Jianing Zhu, Jiangchao Yao, Tongliang Liu, Quanming Yao, Jianliang Xu, Bo Han",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.00250"" target=""_blank"">2303.00250</a>","<a href=""https://github.com/ZFancy/SFAT"" target=""_blank"">ZFancy</a>",2025-12-03 22:39:25
Poster: Sponge ML Model Attacks of Mobile Apps,"Souvik Paul, Nicolas Kourtellis",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01243"" target=""_blank"">2303.01243</a>",,2025-12-03 22:39:25
DOLOS: A Novel Architecture for Moving Target Defense,"Giulio Pagnotta, Gaspari Fabio De, Dorjan Hitaj, Mauro Andreolini, Michele Colajanni, Luigi V. Mancini",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.00387"" target=""_blank"">2303.00387</a>",,2025-12-03 22:39:25
Mitigating Backdoors in Federated Learning with FLD,"Yihang Lin, Pengyuan Zhou, Zhiqian Wu, Yong Liao",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.00302"" target=""_blank"">2303.00302</a>",,2025-12-03 22:39:25
Competence-Based Analysis of Language Models,"Adam Davies, Jize Jiang, ChengXiang Zhai",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.00333"" target=""_blank"">2303.00333</a>",,2025-12-03 22:39:25
Single Image Backdoor Inversion via Robust Smoothed Classifiers,"Mingjie Sun, J. Zico Kolter",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.00215"" target=""_blank"">2303.00215</a>","<a href=""https://github.com/locuslab/smoothinv"" target=""_blank"">locuslab</a>",2025-12-03 22:39:25
Feature Extraction Matters More: Universal Deepfake Disruption through Attacking Ensemble Feature Extractors,"Long Tang, Dengpan Ye, Zhenhao Lu, Yunming Zhang, Shengshan Hu, Yue Xu, Chuanxi Chen",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.00200"" target=""_blank"">2303.00200</a>",,2025-12-03 22:39:25
An Incremental Gray-box Physical Adversarial Attack on Neural Network Training,"Rabiah Al-qudah, Moayad Aloqaily, Bassem Ouni, Mohsen Guizani, Thierry Lestable",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01245"" target=""_blank"">2303.01245</a>",,2025-12-03 22:39:25
Unnoticeable Backdoor Attacks on Graph Neural Networks,"Enyan Dai, Minhua Lin, Xiang Zhang, Suhang Wang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01263"" target=""_blank"">2303.01263</a>",,2025-12-03 22:39:25
MedLocker: A Transferable Adversarial Watermarking for Preventing Unauthorized Analysis of Medical Image Dataset,"Bangzheng Pu, Xingxing Wei, Shiji Zhao, Huazhu Fu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.09858"" target=""_blank"">2303.09858</a>",,2025-12-03 22:39:25
Defending against Adversarial Audio via Diffusion Model,"Shutong Wu, Jiongxiao Wang, Wei Ping, Weili Nie, Chaowei Xiao",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01507"" target=""_blank"">2303.01507</a>",,2025-12-03 22:39:25
Stealthy Perception-based Attacks on Unmanned Aerial Vehicles,"Amir Khazraei, Haocheng Meng, Miroslav Pajic",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.02112"" target=""_blank"">2303.02112</a>",,2025-12-03 22:39:25
Patch of Invisibility: Naturalistic Physical Black-Box Adversarial Attacks on Object Detectors,"Raz Lapid, Eylon Mizrahi, Moshe Sipper",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.04238"" target=""_blank"">2303.04238</a>",,2025-12-03 22:39:25
Rethinking Confidence Calibration for Failure Prediction,"Fei Zhu, Zhen Cheng, Xu-Yao Zhang, Cheng-Lin Liu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.02970"" target=""_blank"">2303.02970</a>","<a href=""https://github.com/Impression2805/FMFP"" target=""_blank"">Impression2805</a>",2025-12-03 22:39:25
Robustness-preserving Lifelong Learning via Dataset Condensation,"Jinghan Jia, Yihua Zhang, Dogyoon Song, Sijia Liu, Alfred Hero",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.04183"" target=""_blank"">2303.04183</a>",,2025-12-03 22:39:25
CUDA: Convolution-based Unlearnable Datasets,"Vinu Sankar Sadasivan, Mahdi Soltanolkotabi, Soheil Feizi",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.04278"" target=""_blank"">2303.04278</a>",,2025-12-03 22:39:25
EavesDroid: Eavesdropping User Behaviors via OS Side-Channels on Smartphones,"Quancheng Wang, Ming Tang, Jianming Fu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.03700"" target=""_blank"">2303.03700</a>",,2025-12-03 22:39:25
Stabilized training of joint energy-based models and their practical applications,"Martin Sustek, Samik Sadhu, Lukas Burget, Hynek Hermansky, Jesus Villalba, Laureano Moro-Velazquez, Najim Dehak",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.04187"" target=""_blank"">2303.04187</a>",,2025-12-03 22:39:25
CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning,"Hritik Bansal, Nishad Singhi, Yu Yang, Fan Yin, Aditya Grover, Kai-Wei Chang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.03323"" target=""_blank"">2303.03323</a>",,2025-12-03 22:39:25
Students Parrot Their Teachers: Membership Inference on Model Distillation,"Matthew Jagielski, Milad Nasr, Christopher Choquette-Choo, Katherine Lee, Nicholas Carlini",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.03446"" target=""_blank"">2303.03446</a>",,2025-12-03 22:39:25
On the Feasibility of Specialized Ability Extracting for Large Language Code Models,"Zongjie Li, Chaozheng Wang, Pingchuan Ma, Chaowei Liu, Shuai Wang, Daoyuan Wu, Cuiyun Gao",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.03012"" target=""_blank"">2303.03012</a>",,2025-12-03 22:39:25
A Unified Algebraic Perspective on Lipschitz Neural Networks,"Alexandre Araujo, Aaron Havens, Blaise Delattre, Alexandre Allauzen, Bin Hu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.03169"" target=""_blank"">2303.03169</a>","<a href=""https://github.com/araujoalexandre/Lipschitz-SLL-Networks"" target=""_blank"">araujoalexandre</a>",2025-12-03 22:39:25
Learning to Backdoor Federated Learning,"Henger Li, Chen Wu, Sencun Zhu, Zizhan Zheng",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.03320"" target=""_blank"">2303.03320</a>",,2025-12-03 22:39:25
"Partial-Information, Longitudinal Cyber Attacks on LiDAR in Autonomous Vehicles","R. Spencer Hallyburton, Qingzhao Zhang, Z. Morley Mao, Miroslav Pajic",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.03470"" target=""_blank"">2303.03470</a>",,2025-12-03 22:39:25
ALMOST: Adversarial Learning to Mitigate Oracle-less ML Attacks via Synthesis Tuning,"Animesh Basak Chowdhury, Lilas Alrahis, Luca Collini, Johann Knechtel, Ramesh Karri, Siddharth Garg, Ozgur Sinanoglu, Benjamin Tan",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.03372"" target=""_blank"">2303.03372</a>",,2025-12-03 22:39:25
Visual Analytics of Neuron Vulnerability to Adversarial Attacks on Convolutional Neural Networks,"Yiran Li, Junpeng Wang, Takanori Fujiwara, Kwan-Liu Ma",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.02814"" target=""_blank"">2303.02814</a>",,2025-12-03 22:39:25
"Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models","Naman D Singh, Francesco Croce, Matthias Hein",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01870"" target=""_blank"">2303.01870</a>",,2025-12-03 22:39:25
Consistent Valid Physically-Realizable Adversarial Attack against Crowd-flow Prediction Models,"Hassan Ali, Muhammad Atif Butt, Fethi Filali, Ala Al-Fuqaha, Junaid Qadir",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.02669"" target=""_blank"">2303.02669</a>",,2025-12-03 22:39:25
Adversarial Sampling for Fairness Testing in Deep Neural Network,"Tosin Ige, William Marfo, Justin Tonkinson, Sikiru Adewale, Bolanle Hafiz Matti",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.02874"" target=""_blank"">2303.02874</a>",,2025-12-03 22:39:25
Local Environment Poisoning Attacks on Federated Reinforcement Learning,"Evelyn Ma, Rasoul Etesami",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.02725"" target=""_blank"">2303.02725</a>",,2025-12-03 22:39:25
"Robustness, Evaluation and Adaptation of Machine Learning Models in the Wild",Vihari Piratla,arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.02781"" target=""_blank"">2303.02781</a>",,2025-12-03 22:39:25
Knowledge-Based Counterfactual Queries for Visual Question Answering,"Theodoti Stoikou, Maria Lymperaiou, Giorgos Stamou",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.02601"" target=""_blank"">2303.02601</a>",,2025-12-03 22:39:25
Improved Robustness Against Adaptive Attacks With Ensembles and Error-Correcting Output Codes,"Thomas Philippon, Christian Gagné",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.02322"" target=""_blank"">2303.02322</a>",,2025-12-03 22:39:25
PointCert: Point Cloud Classification with Deterministic Certified Robustness Guarantees,"Jinghuai Zhang, Jinyuan Jia, Hongbin Liu, Neil Zhenqiang Gong",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01959"" target=""_blank"">2303.01959</a>",,2025-12-03 22:39:25
Certified Robust Neural Networks: Generalization and Corruption Resistance,"Amine Bennouna, Ryan Lucas, Parys Bart Van",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.02251"" target=""_blank"">2303.02251</a>","<a href=""https://github.com/RyanLucas3/HR_Neural_Networks"" target=""_blank"">RyanLucas3</a>",2025-12-03 22:39:25
AdvART: Adversarial Art for Camouflaged Object Detection Attacks,"Amira Guesmi, Ioan Marius Bilasco, Muhammad Shafique, Ihsen Alouani",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.01734"" target=""_blank"">2303.01734</a>",,2025-12-03 22:39:25
"Backdoor Attacks and Defenses in Federated Learning: Survey, Challenges and Future Research Directions","Thuy Dung Nguyen, Tuan Nguyen, Phi Le Nguyen, Hieu H. Pham, Khoa Doan, Kok-Seng Wong",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.02213"" target=""_blank"">2303.02213</a>",,2025-12-03 22:39:25
Adversarial Attacks on Machine Learning in Embedded and IoT Platforms,"Christian Westbrook, Sudeep Pasricha",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.02214"" target=""_blank"">2303.02214</a>",,2025-12-03 22:39:25
Mobile Edge Adversarial Detection for Digital Twinning to the Metaverse with Deep Reinforcement Learning,"Terence Jie Chua, Wenhan Yu, Jun Zhao",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.10288"" target=""_blank"">2303.10288</a>",,2025-12-03 22:39:25
Logit Margin Matters: Improving Transferable Targeted Adversarial Attack by Logit Calibration,"Juanjuan Weng, Zhiming Luo, Zhun Zhong, Shaozi Li, Nicu Sebe",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.03680"" target=""_blank"">2303.03680</a>","<a href=""https://github.com/WJJLL/Target-Attack/"" target=""_blank"">Target-Attack</a>",2025-12-03 22:39:25
Adversarial Counterfactual Visual Explanations,"Guillaume Jeanneret, Loïc Simon, Frédéric Jurie",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.09962"" target=""_blank"">2303.09962</a>",,2025-12-03 22:39:25
Personalized Federated Learning on Long-Tailed Data via Adversarial Feature Augmentation,"Yang Lu, Pinxin Qian, Gang Huang, Hanzi Wang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.15168"" target=""_blank"">2303.15168</a>","<a href=""https://github.com/pxqian/FedAFA"" target=""_blank"">pxqian</a>",2025-12-03 22:39:25
Machine-learned Adversarial Attacks against Fault Prediction Systems in Smart Electrical Grids,"Carmelo Ardito, Yashar Deldjoo, Noia Tommaso Di, Sciascio Eugenio Di, Fatemeh Nazary, Giovanni Servedio",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.18136"" target=""_blank"">2303.18136</a>",,2025-12-03 22:39:25
On the Use of Reinforcement Learning for Attacking and Defending Load Frequency Control,"Amr S. Mohamed, Deepa Kundur",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.15736"" target=""_blank"">2303.15736</a>",,2025-12-03 22:39:25
Hard-normal Example-aware Template Mutual Matching for Industrial Anomaly Detection,"Zixuan Chen, Xiaohua Xie, Lingxiao Yang, Jianhuang Lai",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.16191"" target=""_blank"">2303.16191</a>",,2025-12-03 22:39:25
A Universal Identity Backdoor Attack against Speaker Verification based on Siamese Network,"Haodong Zhao, Wei Du, Junjie Guo, Gongshen Liu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.16031"" target=""_blank"">2303.16031</a>",,2025-12-03 22:39:25
Classifier Robustness Enhancement Via Test-Time Transformation,"Tsachi Blau, Roy Ganz, Chaim Baskin, Michael Elad, Alex Bronstein",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.15409"" target=""_blank"">2303.15409</a>",,2025-12-03 22:39:25
Improving the Transferability of Adversarial Examples via Direction Tuning,"Xiangyuan Yang, Jie Lin, Hanlin Zhang, Xinyu Yang, Peng Zhao",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.15109"" target=""_blank"">2303.15109</a>",,2025-12-03 22:39:25
EMShepherd: Detecting Adversarial Samples via Side-channel Leakage,"Ruyi Ding, Cheng Gongye, Siyue Wang, Aidong Ding, Yunsi Fei",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.15571"" target=""_blank"">2303.15571</a>",,2025-12-03 22:39:25
Learning the Unlearnable: Adversarial Augmentations Suppress Unlearnable Example Attacks,"Tianrui Qin, Xitong Gao, Juanjuan Zhao, Kejiang Ye, Cheng-Zhong Xu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.15127"" target=""_blank"">2303.15127</a>","<a href=""https://github.com/lafeat/ueraser"" target=""_blank"">lafeat</a>",2025-12-03 22:39:25
Detecting Backdoors During the Inference Stage Based on Corruption Robustness Consistency,"Xiaogeng Liu, Minghui Li, Haoyu Wang, Shengshan Hu, Dengpan Ye, Hai Jin, Libing Wu, Chaowei Xiao",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.18191"" target=""_blank"">2303.18191</a>",,2025-12-03 22:39:25
CAT:Collaborative Adversarial Training,"Xingbin Liu, Huafeng Kuang, Xianming Lin, Yongjian Wu, Rongrong Ji",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14922"" target=""_blank"">2303.14922</a>","<a href=""https://github.com/liuxingbin/CAT"" target=""_blank"">liuxingbin</a>",2025-12-03 22:39:25
Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection,"Nicola Franco, Daniel Korth, Jeanette Miriam Lorenz, Karsten Roscher, Stephan Guennemann",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14961"" target=""_blank"">2303.14961</a>",,2025-12-03 22:39:25
Mask and Restore: Blind Backdoor Defense at Test Time with Masked Autoencoder,"Tao Sun, Lu Pang, Chao Chen, Haibin Ling",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.15564"" target=""_blank"">2303.15564</a>","<a href=""https://github.com/tsun/BDMAE"" target=""_blank"">tsun</a>",2025-12-03 22:39:25
A Survey on Malware Detection with Graph Representation Learning,"Tristan Bilot, Nour El Madhoun, Khaldoun Al Agha, Anis Zouaoui",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.16004"" target=""_blank"">2303.16004</a>",,2025-12-03 22:39:25
"Sequential training of GANs against GAN-classifiers reveals correlated ""knowledge gaps"" present among independently trained GAN instances","Arkanath Pathak, Nicholas Dufour",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.15533"" target=""_blank"">2303.15533</a>",,2025-12-03 22:39:25
Anti-DreamBooth: Protecting users from personalized text-to-image synthesis,"Le Thanh Van, Hao Phung, Thuan Hoang Nguyen, Quan Dao, Ngoc Tran, Anh Tran",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.15433"" target=""_blank"">2303.15433</a>","<a href=""https://github.com/VinAIResearch/Anti-DreamBooth"" target=""_blank"">VinAIResearch</a>",2025-12-03 22:39:25
MGTBench: Benchmarking Machine-Generated Text Detection,"Xinlei He, Xinyue Shen, Zeyuan Chen, Michael Backes, Yang Zhang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14822"" target=""_blank"">2303.14822</a>","<a href=""https://github.com/xinleihe/MGTBench"" target=""_blank"">xinleihe</a>",2025-12-03 22:39:25
AdvCheck: Characterizing Adversarial Examples via Local Gradient Checking,"Ruoxi Chen, Haibo Jin, Jinyin Chen, Haibin Zheng",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.18131"" target=""_blank"">2303.18131</a>",,2025-12-03 22:39:25
CFA: Class-wise Calibrated Fair Adversarial Training,"Zeming Wei, Yifei Wang, Yiwen Guo, Yisen Wang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14460"" target=""_blank"">2303.14460</a>","<a href=""https://github.com/PKU-ML/CFA"" target=""_blank"">PKU-ML</a>",2025-12-03 22:39:25
PORE: Provably Robust Recommender Systems against Data Poisoning Attacks,"Jinyuan Jia, Yupei Liu, Yuepeng Hu, Neil Zhenqiang Gong",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14601"" target=""_blank"">2303.14601</a>",,2025-12-03 22:39:25
Improving robustness of jet tagging algorithms with adversarial training: exploring the loss surface,Annika Stein,arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14511"" target=""_blank"">2303.14511</a>",,2025-12-03 22:39:25
PIAT: Parameter Interpolation based Adversarial Training for Image Classification,"Kun He, Xin Liu, Yichen Yang, Zhou Qin, Weigao Wen, Hui Xue, John E. Hopcroft",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13955"" target=""_blank"">2303.13955</a>",,2025-12-03 22:39:25
How many dimensions are required to find an adversarial example? (99%),"Charles Godfrey, Henry Kvinge, Elise Bishoff, Myles Mckay, Davis Brown, Tim Doster, Eleanor Byler",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14173"" target=""_blank"">2303.14173</a>",,2025-12-03 22:39:25
Effective black box adversarial attack with handcrafted kernels,"Petr Dvořáček, Petr Hurtik, Petra Števuliáková",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13887"" target=""_blank"">2303.13887</a>",,2025-12-03 22:39:25
Survey on Adversarial Attack and Defense for Medical Image Analysis: Methods and Challenges,"Junhao Dong, Junxi Chen, Xiaohua Xie, Jianhuang Lai, Hao Chen",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14133"" target=""_blank"">2303.14133</a>","<a href=""https://github.com/tomvii/Adv_MIA"" target=""_blank"">tomvii</a>",2025-12-03 22:39:25
Provable Robustness for Streaming Models with a Sliding Window,"Aounon Kumar, Vinu Sankar Sadasivan, Soheil Feizi",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.16308"" target=""_blank"">2303.16308</a>",,2025-12-03 22:39:25
TransAudio: Towards the Transferable Adversarial Audio Attack via Learning Contextualized Perturbations,"Qi Gege, Yuefeng Chen, Xiaofeng Mao, Yao Zhu, Binyuan Hui, Xiaodan Li, Rong Zhang, Hui Xue",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.15940"" target=""_blank"">2303.15940</a>",,2025-12-03 22:39:25
Feature Separation and Recalibration for Adversarial Robustness,"Woo Jae Kim, Yoonki Cho, Junsik Jung, Sung-Eui Yoon",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13846"" target=""_blank"">2303.13846</a>","<a href=""https://github.com/wkim97/FSR"" target=""_blank"">wkim97</a>",2025-12-03 22:39:25
Explainable Intrusion Detection Systems Using Competitive Learning Techniques,"Jesse Ables, Thomas Kirby, Sudip Mittal, Ioana Banicescu, Shahram Rahimi, William Anderson, Maria Seale",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.17387"" target=""_blank"">2303.17387</a>",,2025-12-03 22:39:25
Fooling Polarization-based Vision using Locally Controllable Polarizing Projection,"Zhuoxiao Li, Zhihang Zhong, Shohei Nobuhara, Ko Nishino, Yinqiang Zheng",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.17890"" target=""_blank"">2303.17890</a>",,2025-12-03 22:39:25
Can AI-Generated Text be Reliably Detected? (45%),"Vinu Sankar Sadasivan, Aounon Kumar, Sriram Balasubramanian, Wenxiao Wang, Soheil Feizi",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.11156"" target=""_blank"">2303.11156</a>","<a href=""https://github.com/vinusankars/Reliability-of-AI-text-detectors"" target=""_blank"">vinusankars</a>",2025-12-03 22:39:25
Per-Example Gradient Regularization Improves Learning Signals from Noisy Data,"Xuran Meng, Yuan Cao, Difan Zou",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.17940"" target=""_blank"">2303.17940</a>",,2025-12-03 22:39:25
DIME-FM: DIstilling Multimodal and Efficient Foundation Models,"Ximeng Sun, Pengchuan Zhang, Peizhao Zhang, Hardik Shah, Kate Saenko, Xide Xia",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.18232"" target=""_blank"">2303.18232</a>",,2025-12-03 22:39:25
Adversarial Attack and Defense for Dehazing Networks,"Jie Gui, Xiaofeng Cong, Chengwei Peng, Yuan Yan Tang, James Tin-Yau Kwok",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.17255"" target=""_blank"">2303.17255</a>","<a href=""https://github.com/guijiejie/AADN"" target=""_blank"">guijiejie</a>",2025-12-03 22:39:25
Generating Adversarial Samples in Mini-Batches May Be Detrimental To Adversarial Robustness,"Timothy Redgrave, Colton Crum",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.17720"" target=""_blank"">2303.17720</a>",,2025-12-03 22:39:25
Towards Adversarially Robust Continual Learning,"Tao Bai, Chen Chen, Lingjuan Lyu, Jun Zhao, Bihan Wen",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.17764"" target=""_blank"">2303.17764</a>",,2025-12-03 22:39:25
Understanding the Robustness of 3D Object Detection with Bird's-Eye-View Representations in Autonomous Driving,"Zijian Zhu, Yichi Zhang, Hai Chen, Yinpeng Dong, Shu Zhao, Wenbo Ding, Jiachen Zhong, Shibao Zheng",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.17297"" target=""_blank"">2303.17297</a>",,2025-12-03 22:39:25
Robo3D: Towards Robust and Reliable 3D Perception against Corruptions,"Lingdong Kong, Youquan Liu, Xin Li, Runnan Chen, Wenwei Zhang, Jiawei Ren, Liang Pan, Kai Chen, Ziwei Liu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.17597"" target=""_blank"">2303.17597</a>",,2025-12-03 22:39:25
Model-agnostic explainable artificial intelligence for object detection in image data,"Milad Moradi, Ke Yan, David Colwell, Matthias Samwald, Rhona Asgari",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.17249"" target=""_blank"">2303.17249</a>",,2025-12-03 22:39:25
Establishing baselines and introducing TernaryMixOE for fine-grained out-of-distribution detection,"Noah Fleischmann, Walter Bennette, Nathan Inkawhich",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.17658"" target=""_blank"">2303.17658</a>",,2025-12-03 22:39:25
"Differential Area Analysis for Ransomware: Attacks, Countermeasures, and Limitations","Marco Venturini, Francesco Freda, Emanuele Miotto, Alberto Giaretta, Mauro Conti",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.17351"" target=""_blank"">2303.17351</a>",,2025-12-03 22:39:25
Denoising Autoencoder-based Defensive Distillation as an Adversarial Robustness Algorithm,"Bakary Badjie, José Cecílio, António Casimiro",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.15901"" target=""_blank"">2303.15901</a>",,2025-12-03 22:39:25
Latent Feature Relation Consistency for Adversarial Robustness,"Xingbin Liu, Huafeng Kuang, Hong Liu, Xianming Lin, Yongjian Wu, Rongrong Ji",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.16697"" target=""_blank"">2303.16697</a>","<a href=""https://github.com/liuxingbin/LFRC"" target=""_blank"">liuxingbin</a>",2025-12-03 22:39:25
Beyond Empirical Risk Minimization: Local Structure Preserving Regularization for Improving Adversarial Robustness,"Wei Wei, Jiahuan Zhou, Ying Wu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.16861"" target=""_blank"">2303.16861</a>",,2025-12-03 22:39:25
Targeted Adversarial Attacks on Wind Power Forecasts,"René Heinrich, Christoph Scholz, Stephan Vogt, Malte Lehna",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.16633"" target=""_blank"">2303.16633</a>",,2025-12-03 22:39:25
Graph Neural Networks for Hardware Vulnerability Analysis -- Can you Trust your GNN? (16%),"Lilas Alrahis, Ozgur Sinanoglu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.16690"" target=""_blank"">2303.16690</a>",,2025-12-03 22:39:25
Mole Recruitment: Poisoning of Image Classifiers via Selective Batch Sampling,"Ethan Wisdom, Tejas Gokhale, Chaowei Xiao, Yezhou Yang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.17080"" target=""_blank"">2303.17080</a>",,2025-12-03 22:39:25
A Tensor-based Convolutional Neural Network for Small Dataset Classification,"Zhenhua Chen, David Crandall",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.17061"" target=""_blank"">2303.17061</a>",,2025-12-03 22:39:25
ALUM: Adversarial Data Uncertainty Modeling from Latent Model Uncertainty Compensation,"Wei Wei, Jiahuan Zhou, Hongze Li, Ying Wu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.16866"" target=""_blank"">2303.16866</a>","<a href=""https://github.com/wwzjer/ALUM"" target=""_blank"">wwzjer</a>",2025-12-03 22:39:25
A Pilot Study of Query-Free Adversarial Attack against Stable Diffusion,"Haomin Zhuang, Yihua Zhang, Sijia Liu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.16378"" target=""_blank"">2303.16378</a>",,2025-12-03 22:39:25
Improving the Transferability of Adversarial Samples by Path-Augmented Method,"Jianping Zhang, Jen-tse Huang, Wenxuan Wang, Yichen Li, Weibin Wu, Xiaosen Wang, Yuxin Su, Michael R. Lyu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.15735"" target=""_blank"">2303.15735</a>",,2025-12-03 22:39:25
Towards Effective Adversarial Textured 3D Meshes on Physical Face Recognition,"Xiao Yang, Chang Liu, Longlong Xu, Yikai Wang, Yinpeng Dong, Ning Chen, Hang Su, Jun Zhu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.15818"" target=""_blank"">2303.15818</a>",,2025-12-03 22:39:25
Transferable Adversarial Attacks on Vision Transformers with Token Gradient Regularization,"Jianping Zhang, Yizhan Huang, Weibin Wu, Michael R. Lyu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.15754"" target=""_blank"">2303.15754</a>",,2025-12-03 22:39:25
Improved Adversarial Training Through Adaptive Instance-wise Loss Smoothing,"Lin Li, Michael Spratling",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14077"" target=""_blank"">2303.14077</a>","<a href=""https://github.com/TreeLLi/Instance-adaptive-Smoothness-Enhanced-AT"" target=""_blank"">TreeLLi</a>",2025-12-03 22:39:25
ImageNet-E: Benchmarking Neural Network Robustness via Attribute Editing,"Xiaodan Li, Yuefeng Chen, Yao Zhu, Shuhui Wang, Rong Zhang, Hui Xue",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.17096"" target=""_blank"">2303.17096</a>","<a href=""https://github.com/alibaba/easyrobust"" target=""_blank"">alibaba</a>",2025-12-03 22:39:25
Physically Adversarial Infrared Patches with Learnable Shapes and Locations,"Wei Xingxing, Yu Jie, Huang Yao",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13868"" target=""_blank"">2303.13868</a>",,2025-12-03 22:39:25
Benchmarking Robustness of 3D Object Detection to Common Corruptions in Autonomous Driving,"Yinpeng Dong, Caixin Kang, Jinlai Zhang, Zijian Zhu, Yikai Wang, Xiao Yang, Hang Su, Xingxing Wei, Jun Zhu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.11040"" target=""_blank"">2303.11040</a>","<a href=""https://github.com/kkkcx/3D_Corruptions_AD"" target=""_blank"">kkkcx</a>",2025-12-03 22:39:25
Efficient Decision-based Black-box Patch Attacks on Video Recognition,"Kaixun Jiang, Zhaoyu Chen, Hao Huang, Jiafeng Wang, Dingkang Yang, Bo Li, Yan Wang, Wenqiang Zhang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.11917"" target=""_blank"">2303.11917</a>",,2025-12-03 22:39:25
Black-box Backdoor Defense via Zero-shot Image Purification,"Yucheng Shi, Mengnan Du, Xuansheng Wu, Zihan Guan, Jin Sun, Ninghao Liu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.12175"" target=""_blank"">2303.12175</a>","<a href=""https://github.com/sycny/ZIP"" target=""_blank"">sycny</a>",2025-12-03 22:39:25
Out of Thin Air: Exploring Data-Free Adversarial Robustness Distillation,"Yuzheng Wang, Zhaoyu Chen, Dingkang Yang, Pinxue Guo, Kaixun Jiang, Wenqiang Zhang, Lizhe Qi",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.11611"" target=""_blank"">2303.11611</a>",,2025-12-03 22:39:25
Influencer Backdoor Attack on Semantic Segmentation,"Haoheng Lan, Jindong Gu, Philip Torr, Hengshuang Zhao",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.12054"" target=""_blank"">2303.12054</a>",,2025-12-03 22:39:25
LOKI: Large-scale Data Reconstruction Attack against Federated Learning through Model Manipulation,"Joshua C. Zhao, Atul Sharma, Ahmed Roushdy Elkordy, Yahya H. Ezzeldin, Salman Avestimehr, Saurabh Bagchi",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.12233"" target=""_blank"">2303.12233</a>",,2025-12-03 22:39:25
Poisoning Attacks in Federated Edge Learning for Digital Twin 6G-enabled IoTs: An Anticipatory Study,"Mohamed Amine Ferrag, Burak Kantarci, Lucas C. Cordeiro, Merouane Debbah, Kim-Kwang Raymond Choo",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.11745"" target=""_blank"">2303.11745</a>",,2025-12-03 22:39:25
TWINS: A Fine-Tuning Framework for Improved Transferability of Adversarial Robustness and Generalization,"Ziquan Liu, Yi Xu, Xiangyang Ji, Antoni B. Chan",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.11135"" target=""_blank"">2303.11135</a>","<a href=""https://github.com/ziquanliu/CVPR2023-TWINS"" target=""_blank"">ziquanliu</a>",2025-12-03 22:39:25
Adversarial Attacks against Binary Similarity Systems,"Gianluca Capozzi, Daniele Cono D'Elia, Luna Giuseppe Antonio Di, Leonardo Querzoni",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.11143"" target=""_blank"">2303.11143</a>",,2025-12-03 22:39:25
DRSM: De-Randomized Smoothing on Malware Classifier Providing Certified Robustness,"Shoumik Saha, Wenxiao Wang, Yigitcan Kaya, Soheil Feizi, Tudor Dumitras",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13372"" target=""_blank"">2303.13372</a>",,2025-12-03 22:39:25
Translate your gibberish: black-box adversarial attack on machine translation systems,"Andrei Chertkov, Olga Tsymboi, Mikhail Pautov, Ivan Oseledets",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.10974"" target=""_blank"">2303.10974</a>",,2025-12-03 22:39:25
GNN-Ensemble: Towards Random Decision Graph Neural Networks,"Wenqi Wei, Mu Qiao, Divyesh Jadav",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.11376"" target=""_blank"">2303.11376</a>",,2025-12-03 22:39:25
Did You Train on My Dataset? Towards Public Dataset Protection with Clean-Label Backdoor Watermarking,"Ruixiang Tang, Qizhang Feng, Ninghao Liu, Fan Yang, Xia Hu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.11470"" target=""_blank"">2303.11470</a>",,2025-12-03 22:39:25
State-of-the-art optical-based physical adversarial attacks for deep learning computer vision systems,"Junbin Fang, You Jiang, Canjian Jiang, Zoe L. Jiang, Siu-Ming Yiu, Chuanyi Liu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.12249"" target=""_blank"">2303.12249</a>",,2025-12-03 22:39:25
Boosting Semi-Supervised Learning by Exploiting All Unlabeled Data,"Yuhao Chen, Xin Tan, Borui Zhao, Zhaowei Chen, Renjie Song, Jiajun Liang, Xuequan Lu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.11066"" target=""_blank"">2303.11066</a>","<a href=""https://github.com/megvii-research/FullMatch"" target=""_blank"">megvii-research</a>",2025-12-03 22:39:25
Robustifying Token Attention for Vision Transformers,"Yong Guo, David Stutz, Bernt Schiele",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.11126"" target=""_blank"">2303.11126</a>",,2025-12-03 22:39:25
Randomized Adversarial Training via Taylor Expansion,"Gaojie Jin, Xinping Yi, Dengyu Wu, Ronghui Mu, Xiaowei Huang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.10653"" target=""_blank"">2303.10653</a>","<a href=""https://github.com/Alexkael/Randomized-Adversarial-Training"" target=""_blank"">Alexkael</a>",2025-12-03 22:39:25
AdaptGuard: Defending Against Universal Attacks for Model Adaptation,"Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.10594"" target=""_blank"">2303.10594</a>","<a href=""https://github.com/TomSheng21/AdaptGuard"" target=""_blank"">TomSheng21</a>",2025-12-03 22:39:25
NoisyHate: Mining Online Human-Written Perturbations for Realistic Robustness Benchmarking of Content Moderation Models,"Yiran Ye, Thai Le, Dongwon Lee",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.10430"" target=""_blank"">2303.10430</a>",,2025-12-03 22:39:25
FedRight: An Effective Model Copyright Protection for Federated Learning,"Jinyin Chen, Mingjun Li, Mingjun Li, Haibin Zheng",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.10399"" target=""_blank"">2303.10399</a>",,2025-12-03 22:39:25
Fuzziness-tuned: Improving the Transferability of Adversarial Examples,"Xiangyuan Yang, Jie Lin, Hanlin Zhang, Xinyu Yang, Peng Zhao",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.10078"" target=""_blank"">2303.10078</a>",,2025-12-03 22:39:25
Detection of Uncertainty in Exceedance of Threshold (DUET): An Adversarial Patch Localizer,"Terence Jie Chua, Wenhan Yu, Jun Zhao",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.10291"" target=""_blank"">2303.10291</a>",,2025-12-03 22:39:25
Generalist: Decoupling Natural and Robust Generalization,"Hongjun Wang, Yisen Wang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13813"" target=""_blank"">2303.13813</a>","<a href=""https://github.com/PKU-ML/Generalist"" target=""_blank"">PKU-ML</a>",2025-12-03 22:39:25
Robust Mode Connectivity-Oriented Adversarial Defense: Enhancing Neural Network Robustness Against Diversified $\ell_p$ Attacks,"Ren Wang, Yuxuan Li, Sijia Liu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.10225"" target=""_blank"">2303.10225</a>","<a href=""https://github.com/wangren09/MCGR"" target=""_blank"">wangren09</a>",2025-12-03 22:39:25
It Is All About Data: A Survey on the Effects of Data on Adversarial Robustness,"Peiyu Xiong, Michael Tegegn, Jaskeerat Singh Sarin, Shubhraneel Pal, Julia Rubin",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.09767"" target=""_blank"">2303.09767</a>",,2025-12-03 22:39:25
Bridging Optimal Transport and Jacobian Regularization by Optimal Trajectory for Enhanced Adversarial Defense,"Binh M. Le, Shahroz Tariq, Simon S. Woo",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.11793"" target=""_blank"">2303.11793</a>",,2025-12-03 22:39:25
Make Landscape Flatter in Differentially Private Federated Learning,"Yifan Shi, Yingqi Liu, Kang Wei, Li Shen, Xueqian Wang, Dacheng Tao",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.11242"" target=""_blank"">2303.11242</a>","<a href=""https://github.com/YMJS-Irfan/DP-FedSAM"" target=""_blank"">YMJS-Irfan</a>",2025-12-03 22:39:25
Information-containing Adversarial Perturbation for Combating Facial Manipulation Systems,"Yao Zhu, Yuefeng Chen, Xiaodan Li, Rong Zhang, Xiang Tian, Bolun Zheng, Yaowu Chen",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.11625"" target=""_blank"">2303.11625</a>",,2025-12-03 22:39:25
Don't FREAK Out: A Frequency-Inspired Approach to Detecting Backdoor Poisoned Samples in DNNs,"Hasan Abed Al Kader Hammoud, Adel Bibi, Philip H. S. Torr, Bernard Ghanem",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13211"" target=""_blank"">2303.13211</a>",,2025-12-03 22:39:25
PoisonedGNN: Backdoor Attack on Graph Neural Networks-based Hardware Security Systems,"Lilas Alrahis, Satwik Patnaik, Muhammad Abdullah Hanif, Muhammad Shafique, Ozgur Sinanoglu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14009"" target=""_blank"">2303.14009</a>",,2025-12-03 22:39:25
Enhancing Multiple Reliability Measures via Nuisance-extended Information Bottleneck,"Jongheon Jeong, Sihyun Yu, Hankook Lee, Jinwoo Shin",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14096"" target=""_blank"">2303.14096</a>","<a href=""https://github.com/jh-jeong/nuisance_ib"" target=""_blank"">jh-jeong</a>",2025-12-03 22:39:25
Edge Deep Learning Model Protection via Neuron Authorization,"Jinyin Chen, Haibin Zheng, Tao Liu, Rongchang Li, Yao Cheng, Xuhong Zhang, Shouling Ji",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.12397"" target=""_blank"">2303.12397</a>","<a href=""https://github.com/Leon022/Edg"" target=""_blank"">Leon022</a>",2025-12-03 22:39:25
Optimal Smoothing Distribution Exploration for Backdoor Neutralization in Deep Learning-based Traffic Systems,"Yue Wang, Wending Li, Michail Maniatakos, Saif Eddin Jabari",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14197"" target=""_blank"">2303.14197</a>",,2025-12-03 22:39:25
TRAK: Attributing Model Behavior at Scale,"Sung Min Park, Kristian Georgiev, Andrew Ilyas, Guillaume Leclerc, Aleksander Madry",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14186"" target=""_blank"">2303.14186</a>","<a href=""https://github.com/MadryLab/trak"" target=""_blank"">MadryLab</a>",2025-12-03 22:39:25
Backdoor Attacks with Input-unique Triggers in NLP,"Xukun Zhou, Jiwei Li, Tianwei Zhang, Lingjuan Lyu, Muqiao Yang, Jun He",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14325"" target=""_blank"">2303.14325</a>",,2025-12-03 22:39:25
Quadratic Graph Attention Network (Q-GAT) for Robust Construction of Gene Regulatory Networks,"Hui Zhang, Xuexin An, Qiang He, Yudong Yao, Feng-Lei Fan, Yueyang Teng",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14193"" target=""_blank"">2303.14193</a>","<a href=""https://github.com/Minorway/Q-GAT_for_Robust_Construction_of_GRN"" target=""_blank"">Minorway</a>",2025-12-03 22:39:25
Optimization and Optimizers for Adversarial Robustness,"Hengyue Liang, Buyun Liang, Le Peng, Ying Cui, Tim Mitchell, Ju Sun",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13401"" target=""_blank"">2303.13401</a>",,2025-12-03 22:39:25
Adversarial Robustness and Feature Impact Analysis for Driver Drowsiness Detection,"João Vitorino, Lourenço Rodrigues, Eva Maia, Isabel Praça, André Lourenço",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13649"" target=""_blank"">2303.13649</a>",,2025-12-03 22:39:25
Ensemble-based Blackbox Attacks on Dense Prediction,"Zikui Cai, Yaoteng Tan, M. Salman Asif",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.14304"" target=""_blank"">2303.14304</a>","<a href=""https://github.com/CSIPlab/EBAD"" target=""_blank"">CSIPlab</a>",2025-12-03 22:39:25
Decentralized Adversarial Training over Graphs,"Ying Cao, Elsa Rizk, Stefan Vlaski, Ali H. Sayed",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13326"" target=""_blank"">2303.13326</a>",,2025-12-03 22:39:25
"Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense","Kalpesh Krishna, Yixiao Song, Marzena Karpinska, John Wieting, Mohit Iyyer",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13408"" target=""_blank"">2303.13408</a>",,2025-12-03 22:39:25
Watch Out for the Confusing Faces: Detecting Face Swapping with the Probability Distribution of Face Identification Models,"Yuxuan Duan, Xuhong Zhang, Chuer Yu, Zonghui Wang, Shouling Ji, Wenzhi Chen",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13131"" target=""_blank"">2303.13131</a>",,2025-12-03 22:39:25
Low-frequency Image Deep Steganography: Manipulate the Frequency Distribution to Hide Secrets with Tenacious Robustness,"Huajie Chen, Tianqing Zhu, Yuan Zhao, Bo Liu, Xin Yu, Wanlei Zhou",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13713"" target=""_blank"">2303.13713</a>",,2025-12-03 22:39:25
Wasserstein Adversarial Examples on Univariant Time Series Data,"Wenjie Wang, Li Xiong, Jian Lou",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.12357"" target=""_blank"">2303.12357</a>",,2025-12-03 22:39:25
An Extended Study of Human-like Behavior under Adversarial Training,"Paul Gavrikov, Janis Keuper, Margret Keuper",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.12669"" target=""_blank"">2303.12669</a>",,2025-12-03 22:39:25
Efficient Symbolic Reasoning for Neural-Network Verification,"Zi Dj Wang, Somesh Dj Jha, Dj Krishnamurthy, Dvijotham",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13588"" target=""_blank"">2303.13588</a>",,2025-12-03 22:39:25
Backdoor Defense via Adaptively Splitting Poisoned Dataset,"Kuofeng Gao, Yang Bai, Jindong Gu, Yong Yang, Shu-Tao Xia",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.12993"" target=""_blank"">2303.12993</a>","<a href=""https://github.com/KuofengGao/ASD"" target=""_blank"">KuofengGao</a>",2025-12-03 22:39:25
Test-time Defense against Adversarial Attacks: Detection and Reconstruction of Adversarial Examples via Masked Autoencoder,"Yun-Yun Tsai, Ju-Chin Chao, Albert Wen, Zhaoyuan Yang, Chengzhi Mao, Tapan Shah, Junfeng Yang",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.12848"" target=""_blank"">2303.12848</a>",,2025-12-03 22:39:25
Sibling-Attack: Rethinking Transferable Adversarial Attacks against Face Recognition,"Zexin Li, Bangjie Yin, Taiping Yao, Juefeng Guo, Shouhong Ding, Simin Chen, Cong Liu",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.12512"" target=""_blank"">2303.12512</a>",,2025-12-03 22:39:25
Revisiting DeepFool: generalization and improvement,"Alireza Abdollahpourrostam, Mahed Abroshan, Seyed-Mohsen Moosavi-Dezfooli",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.12481"" target=""_blank"">2303.12481</a>",,2025-12-03 22:39:25
Semantic Image Attack for Visual Model Diagnosis,"Jinqi Luo, Zhaoning Wang, Chen Henry Wu, Dong Huang, la Torre Fernando De",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.13010"" target=""_blank"">2303.13010</a>",,2025-12-03 22:39:25
Reliable and Efficient Evaluation of Adversarial Robustness for Deep Hashing-Based Retrieval,"Xunguang Wang, Jiawang Bai, Xinyue Xu, Xiaomeng Li",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.12658"" target=""_blank"">2303.12658</a>",,2025-12-03 22:39:25
Distribution-restrained Softmax Loss for the Model Robustness,"Hao Wang, Chen Li, Jinzhe Jiang, Xin Zhang, Yaqian Zhao, Weifeng Gong",arXiv,2023-03,"<a href=""http://arxiv.org/abs/2303.12363"" target=""_blank"">2303.12363</a>",,2025-12-03 22:39:25
Shortcut Detection with Variational Autoencoders,"Nicolas M. Müller, Simon Roschmann, Shahbaz Khan, Philip Sperl, Konstantin Böttinger",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.04246"" target=""_blank"">2302.04246</a>",,2025-12-03 22:39:25
Toward Face Biometric De-identification using Adversarial Examples,"Mahdi Ghafourian, Julian Fierrez, Luis Felipe Gomez, Ruben Vera-Rodriguez, Aythami Morales, Zohra Rezgui, Raymond Veldhuis",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.03657"" target=""_blank"">2302.03657</a>",,2025-12-03 22:39:25
Continuous Learning for Android Malware Detection,"Yizheng Chen, Zhoujie Ding, David Wagner",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.04332"" target=""_blank"">2302.04332</a>",,2025-12-03 22:39:25
Training-free Lexical Backdoor Attacks on Language Models,"Yujin Huang, Terry Yue Zhuo, Qiongkai Xu, Han Hu, Xingliang Yuan, Chunyang Chen",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.04116"" target=""_blank"">2302.04116</a>","<a href=""https://github.com/Jinxhy/TFLexAttack"" target=""_blank"">Jinxhy</a>",2025-12-03 22:39:25
On Function-Coupled Watermarks for Deep Neural Networks,"Xiangyu Wen, Yu Li, Wei Jiang, Qiang Xu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.10296"" target=""_blank"">2302.10296</a>","<a href=""https://github.com/cure-lab/Function-Coupled-Watermark"" target=""_blank"">cure-lab</a>",2025-12-03 22:39:25
Et Tu Certifications: Robustness Certificates Yield Better Adversarial Examples,"Andrew C. Cullen, Shijie Liu, Paul Montague, Sarah M. Erfani, Benjamin I. P. Rubinstein",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.04379"" target=""_blank"">2302.04379</a>",,2025-12-03 22:39:25
Unsupervised Learning of Initialization in Deep Neural Networks via Maximum Mean Discrepancy,"Cheolhyoung Lee, Kyunghyun Cho",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.04369"" target=""_blank"">2302.04369</a>",,2025-12-03 22:39:25
Temporal Robustness against Data Poisoning,"Wenxiao Wang, Soheil Feizi",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.03684"" target=""_blank"">2302.03684</a>",,2025-12-03 22:39:25
Attacking Cooperative Multi-Agent Reinforcement Learning by Adversarial Minority Influence,"Simin Li, Jun Guo, Jingqiao Xiu, Yuwei Zheng, Pu Feng, Xin Yu, Aishan Liu, Yaodong Yang, Bo An, Wenjun Wu, Xianglong Liu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.03322"" target=""_blank"">2302.03322</a>","<a href=""https://github.com/DIG-Beihang/AMI"" target=""_blank"">DIG-Beihang</a>",2025-12-03 22:39:25
Membership Inference Attacks against Diffusion Models,"Tomoya Matsumoto, Takayuki Miura, Naoto Yanai",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.03262"" target=""_blank"">2302.03262</a>",,2025-12-03 22:39:25
Robustness Implies Fairness in Casual Algorithmic Recourse,"Ahmad-Reza Ehyaei, Amir-Hossein Karimi, Bernhard Schölkopf, Setareh Maghsudi",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.03465"" target=""_blank"">2302.03465</a>",,2025-12-03 22:39:25
Low-Latency Communication using Delay-Aware Relays Against Reactive Adversaries,"Vivek Chaudhary, J. Harshan",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.03335"" target=""_blank"">2302.03335</a>",,2025-12-03 22:39:25
Less is More: Understanding Word-level Textual Adversarial Attack via n-gram Frequency Descend,"Ning Lu, Shengcai Liu, Zhirui Zhang, Qi Wang, Haifeng Liu, Ke Tang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02568"" target=""_blank"">2302.02568</a>",,2025-12-03 22:39:25
SCALE-UP: An Efficient Black-box Input-level Backdoor Detection via Analyzing Scaled Prediction Consistency,"Junfeng Guo, Yiming Li, Xun Chen, Hanqing Guo, Lichao Sun, Cong Liu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.03251"" target=""_blank"">2302.03251</a>","<a href=""https://github.com/JunfengGo/SCALE-UP"" target=""_blank"">JunfengGo</a>",2025-12-03 22:39:25
Incremental Satisfiability Modulo Theory for Verification of Deep Neural Networks,"Pengfei Yang, Zhiming Chi, Zongxin Liu, Mengyu Zhao, Cheng-Chao Huang, Shaowei Cai, Lijun Zhang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.06455"" target=""_blank"">2302.06455</a>",,2025-12-03 22:39:25
Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks,"Jan Schuchardt, Aleksandar Bojchevski, Johannes Gasteiger, Stephan Günnemann",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02829"" target=""_blank"">2302.02829</a>",,2025-12-03 22:39:25
WAT: Improve the Worst-class Robustness in Adversarial Training,"Boqi Li, Weiwei Liu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.04025"" target=""_blank"">2302.04025</a>",,2025-12-03 22:39:25
Pushing the Accuracy-Group Robustness Frontier with Introspective Self-play,"Jeremiah Zhe Liu, Krishnamurthy Dj Dvijotham, Jihyeon Lee, Quan Yuan, Martin Strobel, Balaji Lakshminarayanan, Deepak Ramachandran",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.05807"" target=""_blank"">2302.05807</a>",,2025-12-03 22:39:25
Augmenting NLP data to counter Annotation Artifacts for NLI Tasks,Armaan Singh Bhullar,arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.04700"" target=""_blank"">2302.04700</a>",,2025-12-03 22:39:25
HateProof: Are Hateful Meme Detection Systems really Robust? (13%),"Piush Aggarwal, Pranit Chawla, Mithun Das, Punyajoy Saha, Binny Mathew, Torsten Zesch, Animesh Mukherjee",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.05703"" target=""_blank"">2302.05703</a>",,2025-12-03 22:39:25
Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural Networks with Neuromorphic Data,"Gorka Abad, Oguzhan Ersoy, Stjepan Picek, Aitor Urbieta",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.06279"" target=""_blank"">2302.06279</a>",,2025-12-03 22:39:25
Target-based Surrogates for Stochastic Optimization,"Jonathan Wilder Lavington, Sharan Vaswani, Reza Babanezhad, Mark Schmidt, Nicolas Le Roux",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02607"" target=""_blank"">2302.02607</a>",,2025-12-03 22:39:25
Raising the Cost of Malicious AI-Powered Image Editing,"Hadi Salman, Alaa Khaddaj, Guillaume Leclerc, Andrew Ilyas, Aleksander Madry",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.06588"" target=""_blank"">2302.06588</a>",,2025-12-03 22:39:25
Targeted Attack on GPT-Neo for the SATML Language Model Data Extraction Challenge,"Ali Al-Kaswan, Maliheh Izadi, Deursen Arie van",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.07735"" target=""_blank"">2302.07735</a>",,2025-12-03 22:39:25
"Backdoor Learning for NLP: Recent Advances, Challenges, and Future Research Directions",Marwan Omar,arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.06801"" target=""_blank"">2302.06801</a>",,2025-12-03 22:39:25
TextDefense: Adversarial Text Detection based on Word Importance Entropy,"Lujia Shen, Xuhong Zhang, Shouling Ji, Yuwen Pu, Chunpeng Ge, Xing Yang, Yanghe Feng",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.05892"" target=""_blank"">2302.05892</a>",,2025-12-03 22:39:25
Mutation-Based Adversarial Attacks on Neural Text Detectors,"Gongbo Liang, Jesus Guerrero, Izzat Alsmadi",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.05794"" target=""_blank"">2302.05794</a>",,2025-12-03 22:39:25
MTTM: Metamorphic Testing for Textual Content Moderation Software,"Wenxuan Wang, Jen-tse Huang, Weibin Wu, Jianping Zhang, Yizhan Huang, Shuqing Li, Pinjia He, Michael Lyu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.05706"" target=""_blank"">2302.05706</a>",,2025-12-03 22:39:25
Better Diffusion Models Further Improve Adversarial Training,"Zekai Wang, Tianyu Pang, Chao Du, Min Lin, Weiwei Liu, Shuicheng Yan",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.04638"" target=""_blank"">2302.04638</a>","<a href=""https://github.com/wzekai99/DM-Improves-AT"" target=""_blank"">wzekai99</a>",2025-12-03 22:39:25
High Recovery with Fewer Injections: Practical Binary Volumetric Injection Attacks against Dynamic Searchable Encryption,"Xianglong Zhang, Wei Wang, Peng Xu, Laurence T. Yang, Kaitai Liang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.05628"" target=""_blank"">2302.05628</a>",,2025-12-03 22:39:25
Making Substitute Models More Bayesian Can Enhance Transferability of Adversarial Examples,"Qizhang Li, Yiwen Guo, Wangmeng Zuo, Hao Chen",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.05086"" target=""_blank"">2302.05086</a>","<a href=""https://github.com/qizhangli/MoreBayesian-attack"" target=""_blank"">qizhangli</a>",2025-12-03 22:39:25
Step by Step Loss Goes Very Far: Multi-Step Quantization for Adversarial Text Attacks,"Piotr Gaiński, Klaudia Bałazy",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.05120"" target=""_blank"">2302.05120</a>",,2025-12-03 22:39:25
IB-RAR: Information Bottleneck as Regularizer for Adversarial Robustness,"Xiaoyun Xu, Guilherme Perin, Stjepan Picek",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.10896"" target=""_blank"">2302.10896</a>",,2025-12-03 22:39:25
Adversarial Example Does Good: Preventing Painting Imitation from Diffusion Models via Adversarial Examples,"Chumeng Liang, Xiaoyu Wu, Yang Hua, Jiaru Zhang, Yiming Xue, Tao Song, Zhengui Xue, Ruhui Ma, Haibing Guan",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.04578"" target=""_blank"">2302.04578</a>",,2025-12-03 22:39:25
Mithridates: Auditing and Boosting Backdoor Resistance of Machine Learning Pipelines,"Eugene Bagdasaryan, Vitaly Shmatikov",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.04977"" target=""_blank"">2302.04977</a>",,2025-12-03 22:39:25
Imperceptible Sample-Specific Backdoor to DNN with Denoising Autoencoder,"Xiangqi Wang, Mingfu Xue, Kewei Chen, Jing Xu, Wenmao Liu, Leo Yu Zhang, Yushu Zhang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.04457"" target=""_blank"">2302.04457</a>",,2025-12-03 22:39:25
GAT: Guided Adversarial Training with Pareto-optimal Auxiliary Tasks,"Salah Ghamizi, Jingfeng Zhang, Maxime Cordy, Mike Papadakis, Masashi Sugiyama, Yves Le Traon",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02907"" target=""_blank"">2302.02907</a>",,2025-12-03 22:39:25
Effective Robustness against Natural Distribution Shifts for Models with Different Training Data,"Zhouxing Shi, Nicholas Carlini, Ananth Balashankar, Ludwig Schmidt, Cho-Jui Hsieh, Alex Beutel, Yao Qin",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01381"" target=""_blank"">2302.01381</a>",,2025-12-03 22:39:25
Dropout Injection at Test Time for Post Hoc Uncertainty Quantification in Neural Networks,"Emanuele Ledda, Giorgio Fumera, Fabio Roli",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02924"" target=""_blank"">2302.02924</a>",,2025-12-03 22:39:25
One-shot Empirical Privacy Estimation for Federated Learning,"Galen Andrew, Peter Kairouz, Sewoong Oh, Alina Oprea, H. Brendan McMahan, Vinith Suriyakumar",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.03098"" target=""_blank"">2302.03098</a>",,2025-12-03 22:39:25
Provably Bounding Neural Network Preimages,"Suhas Kotha, Christopher Brix, Zico Kolter, Krishnamurthy Dvijotham, Huan Zhang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01404"" target=""_blank"">2302.01404</a>",,2025-12-03 22:39:25
A sliced-Wasserstein distance-based approach for out-of-class-distribution detection,"Mohammad Shifat E Rabbi, Abu Hasnat Mohammad Rubaiyat, Yan Zhuang, Gustavo K Rohde",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01459"" target=""_blank"">2302.01459</a>",,2025-12-03 22:39:25
SPECWANDS: An Efficient Priority-based Scheduler Against Speculation Contention Attacks,"Bowen Tang, Chenggang Wu, Pen-Chung Yew, Yinqian Zhang, Mengyao Xie, Yuanming Lai, Yan Kang, Wei Wang, Qiang Wei, Zhe Wang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.00947"" target=""_blank"">2302.00947</a>",,2025-12-03 22:39:25
Defensive ML: Defending Architectural Side-channels with Adversarial Obfuscation,"Hyoungwook Nam, Raghavendra Pradyumna Pothukuchi, Bo Li, Nam Sung Kim, Josep Torrellas",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01474"" target=""_blank"">2302.01474</a>",,2025-12-03 22:39:25
Generalized Uncertainty of Deep Neural Networks: Taxonomy and Applications,Chengyu Dong,arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01440"" target=""_blank"">2302.01440</a>",,2025-12-03 22:39:25
Dataset Distillation Fixes Dataset Reconstruction Attacks,"Noel Loo, Ramin Hasani, Mathias Lechner, Daniela Rus",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01428"" target=""_blank"">2302.01428</a>",,2025-12-03 22:39:25
Universal Soldier: Using Universal Adversarial Perturbations for Detecting Backdoor Attacks,"Xiaoyun Xu, Oguzhan Ersoy, Stjepan Picek",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.00747"" target=""_blank"">2302.00747</a>",,2025-12-03 22:39:25
Effectiveness of Moving Target Defenses for Adversarial Attacks in ML-based Malware Detection,"Aqib Rashid, Jose Such",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.00537"" target=""_blank"">2302.00537</a>",,2025-12-03 22:39:25
Exploring Semantic Perturbations on Grover,"Ziqing Ji, Pranav Kulkarni, Marko Neskovic, Kevin Nolan, Yan Xu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.00509"" target=""_blank"">2302.00509</a>",,2025-12-03 22:39:25
BackdoorBox: A Python Toolbox for Backdoor Learning,"Yiming Li, Mengxi Ya, Yang Bai, Yong Jiang, Shu-Tao Xia",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01762"" target=""_blank"">2302.01762</a>","<a href=""https://github.com/THUYimingLi/BackdoorBox"" target=""_blank"">THUYimingLi</a>",2025-12-03 22:39:25
The Impacts of Unanswerable Questions on the Robustness of Machine Reading Comprehension Models,"Son Quoc Tran, Phong Nguyen-Thuan Do, Uyen Le, Matt Kretchmar",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.00094"" target=""_blank"">2302.00094</a>",,2025-12-03 22:39:25
RS-Del: Edit Distance Robustness Certificates for Sequence Classifiers via Randomized Deletion,"Zhuoqun Huang, Neil G. Marchant, Keane Lucas, Lujo Bauer, Olga Ohrimenko, Benjamin I. P. Rubinstein",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01757"" target=""_blank"">2302.01757</a>",,2025-12-03 22:39:25
Out-of-distribution Detection with Energy-based Models,Sven Elflein,arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.12002"" target=""_blank"">2302.12002</a>",,2025-12-03 22:39:25
MoreauGrad: Sparse and Robust Interpretation of Neural Networks via Moreau Envelope,"Jingwei Zhang, Farzan Farnia",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.05294"" target=""_blank"">2302.05294</a>",,2025-12-03 22:39:25
Can Large Language Models Change User Preference Adversarially? (1%),Varshini Subhash,arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.10291"" target=""_blank"">2302.10291</a>",,2025-12-03 22:39:25
Sparse Mixture Once-for-all Adversarial Training for Efficient In-Situ Trade-Off Between Accuracy and Robustness of DNNs,"Souvik Kundu, Sairam Sundaresan, Sharath Nittur Sridhar, Shunlin Lu, Han Tang, Peter A. Beerel",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.03523"" target=""_blank"">2302.03523</a>",,2025-12-03 22:39:25
Security Defense For Smart Contracts: A Comprehensive Survey,"Nikolay Ivanov, Chenning Li, Qiben Yan, Zhiyuan Sun, Zhichao Cao, Xiapu Luo",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.07347"" target=""_blank"">2302.07347</a>",,2025-12-03 22:39:25
On the Robustness of Randomized Ensembles to Adversarial Perturbations,"Hassan Dbouk, Naresh R. Shanbhag",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01375"" target=""_blank"">2302.01375</a>","<a href=""https://github.com/hsndbk4/BARRE"" target=""_blank"">hsndbk4</a>",2025-12-03 22:39:25
Beyond Pretrained Features: Noisy Image Modeling Provides Adversarial Defense,"Zunzhi You, Daochang Liu, Bohyung Han, Chang Xu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01056"" target=""_blank"">2302.01056</a>","<a href=""https://github.com/youzunzhi/NIM-AdvDef"" target=""_blank"">youzunzhi</a>",2025-12-03 22:39:25
TransFool: An Adversarial Attack against Neural Machine Translation Models,"Sahar Sadrizadeh, Ljiljana Dolamic, Pascal Frossard",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.00944"" target=""_blank"">2302.00944</a>",,2025-12-03 22:39:25
TextShield: Beyond Successfully Detecting Adversarial Sentences in Text Classification,"Lingfeng Shen, Ze Zhang, Haiyun Jiang, Ying Chen",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02023"" target=""_blank"">2302.02023</a>",,2025-12-03 22:39:25
On the Role of Contrastive Representation Learning in Adversarial Robustness: An Empirical Study,"Fatemeh Ghofrani, Mehdi Yaghouti, Pooyan Jamshidi",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02502"" target=""_blank"">2302.02502</a>","<a href=""https://github.com/softsys4ai/CL-Robustness"" target=""_blank"">softsys4ai</a>",2025-12-03 22:39:25
Leaving Reality to Imagination: Robust Classification via Generated Datasets,"Hritik Bansal, Aditya Grover",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02503"" target=""_blank"">2302.02503</a>","<a href=""https://github.com/Hritikbansal/generative-robustness"" target=""_blank"">Hritikbansal</a>",2025-12-03 22:39:25
CosPGD: a unified white-box adversarial attack for pixel-wise prediction tasks,"Shashank Agnihotri, Steffen Jung, Margret Keuper",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02213"" target=""_blank"">2302.02213</a>",,2025-12-03 22:39:25
A Minimax Approach Against Multi-Armed Adversarial Attacks Detection,"Federica Granese, Marco Romanelli, Siddharth Garg, Pablo Piantanida",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02216"" target=""_blank"">2302.02216</a>",,2025-12-03 22:39:25
AUTOLYCUS: Exploiting Explainable AI (XAI) for Model Extraction Attacks against Decision Tree Models,"Abdullah Caglar Oksuz, Anisa Halimi, Erman Ayday",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02162"" target=""_blank"">2302.02162</a>",,2025-12-03 22:39:25
Run-Off Election: Improved Provable Defense against Data Poisoning Attacks,"Keivan Rezaei, Kiarash Banihashem, Atoosa Chegini, Soheil Feizi",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02300"" target=""_blank"">2302.02300</a>",,2025-12-03 22:39:25
Certified Robust Control under Adversarial Perturbations,"Jinghan Yang, Hunmin Kim, Wenbin Wan, Naira Hovakimyan, Yevgeniy Vorobeychik",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02208"" target=""_blank"">2302.02208</a>",,2025-12-03 22:39:25
DeTorrent: An Adversarial Padding-only Traffic Analysis Defense,"James K Holland, Jason Carpenter, Se Eun Oh, Nicholas Hopper",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02012"" target=""_blank"">2302.02012</a>",,2025-12-03 22:39:25
Augmenting Rule-based DNS Censorship Detection at Scale with Machine Learning,"Jacob Alexander Markson Brown, Xi Jiang, Van Tran, Arjun Nitin Bhagoji, Nguyen Phong Hoang, Nick Feamster, Prateek Mittal, Vinod Yegneswaran",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02031"" target=""_blank"">2302.02031</a>",,2025-12-03 22:39:25
SoK: A Systematic Evaluation of Backdoor Trigger Characteristics in Image Classification,"Gorka Abad, Jing Xu, Stefanos Koffas, Behrad Tajalli, Stjepan Picek, Mauro Conti",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01740"" target=""_blank"">2302.01740</a>",,2025-12-03 22:39:25
Beyond the Universal Law of Robustness: Sharper Laws for Random Features and Neural Tangent Kernels,"Simone Bombari, Shayan Kiyani, Marco Mondelli",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01629"" target=""_blank"">2302.01629</a>",,2025-12-03 22:39:25
Asymmetric Certified Robustness via Feature-Convex Neural Networks,"Samuel Pfrommer, Brendon G. Anderson, Julien Piet, Somayeh Sojoudi",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01961"" target=""_blank"">2302.01961</a>",,2025-12-03 22:39:25
Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks,"Zeyu Qin, Liuyi Yao, Daoyuan Chen, Yaliang Li, Bolin Ding, Minhao Cheng",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01677"" target=""_blank"">2302.01677</a>","<a href=""https://github.com/alibaba/FederatedScope/tree/backdoor-bench"" target=""_blank"">tree</a>",2025-12-03 22:39:25
BarrierBypass: Out-of-Sight Clean Voice Command Injection Attacks through Physical Barriers,"Payton Walker, Tianfang Zhang, Cong Shi, Nitesh Saxena, Yingying Chen",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.02042"" target=""_blank"">2302.02042</a>",,2025-12-03 22:39:25
From Robustness to Privacy and Back,"Hilal Asi, Jonathan Ullman, Lydia Zakynthinou",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01855"" target=""_blank"">2302.01855</a>",,2025-12-03 22:39:25
DCA: Delayed Charging Attack on the Electric Shared Mobility System,"Shuocheng Guo, Hanlin Chen, Mizanur Rahman, Xinwu Qian",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.01972"" target=""_blank"">2302.01972</a>",,2025-12-03 22:39:25
READIN: A Chinese Multi-Task Benchmark with Realistic and Diverse Input Noises,"Chenglei Si, Zhengyan Zhang, Yingfa Chen, Xiaozhi Wang, Zhiyuan Liu, Maosong Sun",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.07324"" target=""_blank"">2302.07324</a>","<a href=""https://github.com/thunlp/READIN"" target=""_blank"">thunlp</a>",2025-12-03 22:39:25
Exploring and Exploiting Decision Boundary Dynamics for Adversarial Robustness,"Yuancheng Xu, Yanchao Sun, Micah Goldblum, Tom Goldstein, Furong Huang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.03015"" target=""_blank"">2302.03015</a>","<a href=""https://github.com/Yuancheng-Xu/Dynamics-Aware-Robust-Training"" target=""_blank"">Yuancheng-Xu</a>",2025-12-03 22:39:25
Bounding Training Data Reconstruction in DP-SGD,"Jamie Hayes, Saeed Mahloujifar, Borja Balle",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.07225"" target=""_blank"">2302.07225</a>",,2025-12-03 22:39:25
MalProtect: Stateful Defense Against Adversarial Query Attacks in ML-based Malware Detection,"Aqib Rashid, Jose Such",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.10739"" target=""_blank"">2302.10739</a>",,2025-12-03 22:39:25
Bayesian Neural Networks Avoid Encoding Complex and Perturbation-Sensitive Concepts,"Qihan Ren, Huiqi Deng, Yunuo Chen, Siyu Lou, Quanshi Zhang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.13095"" target=""_blank"">2302.13095</a>","<a href=""https://github.com/sjtu-xai-lab/BNN-concepts"" target=""_blank"">sjtu-xai-lab</a>",2025-12-03 22:39:25
Defending Against Backdoor Attacks by Layer-wise Feature Analysis,"Najeeb Moharram Jebreel, Josep Domingo-Ferrer, Yiming Li",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.12758"" target=""_blank"">2302.12758</a>",,2025-12-03 22:39:25
Chaotic Variational Auto encoder-based Adversarial Machine Learning,"Pavan Venkata Sainadh Reddy, Yelleti Vivek, Gopi Pranay, Vadlamani Ravi",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.12959"" target=""_blank"">2302.12959</a>",,2025-12-03 22:39:25
Robust Weight Signatures: Gaining Robustness as Easy as Patching Weights? (12%),"Ruisi Cai, Zhenyu Zhang, Zhangyang Wang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.12480"" target=""_blank"">2302.12480</a>",,2025-12-03 22:39:25
Less is More: Data Pruning for Faster Adversarial Training,"Yize Li, Pu Zhao, Xue Lin, Bhavya Kailkhura, Ryan Goldhahn",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.12366"" target=""_blank"">2302.12366</a>",,2025-12-03 22:39:25
A Plot is Worth a Thousand Words: Model Information Stealing Attacks via Scientific Plots,"Boyang Zhang, Xinlei He, Yun Shen, Tianhao Wang, Yang Zhang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.11982"" target=""_blank"">2302.11982</a>",,2025-12-03 22:39:25
Boosting Adversarial Transferability using Dynamic Cues,"Muzammal Naseer, Ahmad Mahmood, Salman Khan, Fahad Khan",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.12252"" target=""_blank"">2302.12252</a>",,2025-12-03 22:39:25
HyperAttack: Multi-Gradient-Guided White-box Adversarial Structure Attack of Hypergraph Neural Networks,"Chao Hu, Ruishi Yu, Binqi Zeng, Yu Zhan, Ying Fu, Quan Zhang, Rongkai Liu, Heyuan Shi",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.12407"" target=""_blank"">2302.12407</a>",,2025-12-03 22:39:25
Investigating Catastrophic Overfitting in Fast Adversarial Training: A Self-fitting Perspective,"Zhengbao He, Tao Li, Sizhe Chen, Xiaolin Huang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.11963"" target=""_blank"">2302.11963</a>",,2025-12-03 22:39:25
More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models,"Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph Endres, Thorsten Holz, Mario Fritz",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.12173"" target=""_blank"">2302.12173</a>",,2025-12-03 22:39:25
On the Hardness of Robustness Transfer: A Perspective from Rademacher Complexity over Symmetric Difference Hypothesis Space,"Yuyang Deng, Nidham Gazagnadou, Junyuan Hong, Mehrdad Mahdavi, Lingjuan Lyu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.12351"" target=""_blank"">2302.12351</a>",,2025-12-03 22:39:25
Harnessing the Speed and Accuracy of Machine Learning to Advance Cybersecurity,Khatoon Mohammed,arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.12415"" target=""_blank"">2302.12415</a>",,2025-12-03 22:39:25
Mitigating Adversarial Attacks in Deepfake Detection: An Exploration of Perturbation and AI Techniques,"Saminder Dhesi, Laura Fontes, Pedro Machado, Isibor Kennedy Ihianle, Farhad Fassihi Tash, David Ada Adama",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.11704"" target=""_blank"">2302.11704</a>",,2025-12-03 22:39:25
PAD: Towards Principled Adversarial Malware Detection Against Evasion Attacks,"Deqiang Li, Shicheng Cui, Yun Li, Jia Xu, Fu Xiao, Shouhuai Xu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.11328"" target=""_blank"">2302.11328</a>",,2025-12-03 22:39:25
Provable Robustness Against a Union of $\ell_0$ Adversarial Attacks,"Zayd Hammoudeh, Daniel Lowd",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.11628"" target=""_blank"">2302.11628</a>",,2025-12-03 22:39:25
ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep Learning Paradigms,"Minzhou Pan, Yi Zeng, Lingjuan Lyu, Xue Lin, Ruoxi Jia",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.11408"" target=""_blank"">2302.11408</a>","<a href=""https://github.com/ruoxi-jia-group/ASSET"" target=""_blank"">ruoxi-jia-group</a>",2025-12-03 22:39:25
On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective,"Jindong Wang, Xixu Hu, Wenxin Hou, Hao Chen, Runkai Zheng, Yidong Wang, Linyi Yang, Haojun Huang, Wei Ye, Xiubo Geng, Binxin Jiao, Yue Zhang, Xing Xie",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.12095"" target=""_blank"">2302.12095</a>",,2025-12-03 22:39:25
SATBA: An Invisible Backdoor Attack Based On Spatial Attention,"Huasong Zhou, Xiaowei Xu, Xiaodong Wang, Leon Bevan Bullock",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.13056"" target=""_blank"">2302.13056</a>",,2025-12-03 22:39:25
Scalable Attribution of Adversarial Attacks via Multi-Task Learning,"Zhongyi Guo, Keji Han, Yao Ge, Wei Ji, Yun Li",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.14059"" target=""_blank"">2302.14059</a>",,2025-12-03 22:39:25
Deep Learning-based Multi-Organ CT Segmentation with Adversarial Data Augmentation,"Shaoyan Pan, Shao-Yuan Lo, Min Huang, Chaoqiong Ma, Jacob Wynne, Tonghe Wang, Tian Liu, Xiaofeng Yang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.13172"" target=""_blank"">2302.13172</a>",,2025-12-03 22:39:25
Aegis: Mitigating Targeted Bit-flip Attacks against Deep Neural Networks,"Jialai Wang, Ziyuan Zhang, Meiqi Wang, Han Qiu, Tianwei Zhang, Qi Li, Zongpeng Li, Tao Wei, Chao Zhang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.13520"" target=""_blank"">2302.13520</a>",,2025-12-03 22:39:25
A Modern Look at the Relationship between Sharpness and Generalization,"Maksym Andriushchenko, Francesco Croce, Maximilian Müller, Matthias Hein, Nicolas Flammarion",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.07011"" target=""_blank"">2302.07011</a>","<a href=""https://github.com/tml-epfl/sharpness-vs-generalization"" target=""_blank"">tml-epfl</a>",2025-12-03 22:39:25
A Comprehensive Study on Robustness of Image Classification Models: Benchmarking and Rethinking,"Chang Liu, Yinpeng Dong, Wenzhao Xiang, Xiao Yang, Hang Su, Jun Zhu, Yuefeng Chen, Yuan He, Hui Xue, Shibao Zheng",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.14301"" target=""_blank"">2302.14301</a>",,2025-12-03 22:39:25
FreeEagle: Detecting Complex Neural Trojans in Data-Free Cases,"Chong Fu, Xuhong Zhang, Shouling Ji, Ting Wang, Peng Lin, Yanghe Feng, Jianwei Yin",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.14500"" target=""_blank"">2302.14500</a>",,2025-12-03 22:39:25
Backdoor Attacks Against Deep Image Compression via Adaptive Frequency Trigger,"Yi Yu, Yufei Wang, Wenhan Yang, Shijian Lu, Yap-peng Tan, Alex C. Kot",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.14677"" target=""_blank"">2302.14677</a>",,2025-12-03 22:39:25
Adversarial Attack with Raindrops,"Jiyuan Liu, Bingyi Lu, Mingkang Xiong, Tao Zhang, Huilin Xiong",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.14267"" target=""_blank"">2302.14267</a>",,2025-12-03 22:39:25
A semantic backdoor attack against Graph Convolutional Networks,"Jiazhu Dai, Zhipeng Xiong",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.14353"" target=""_blank"">2302.14353</a>",,2025-12-03 22:39:25
Physical Adversarial Attacks on Deep Neural Networks for Traffic Sign Recognition: A Feasibility Study,"Fabian Woitschek, Georg Schneider",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.13570"" target=""_blank"">2302.13570</a>",,2025-12-03 22:39:25
CBA: Contextual Background Attack against Optical Aerial Detection in the Physical World,"Jiawei Lian, Xiaofei Wang, Yuru Su, Mingyang Ma, Shaohui Mei",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.13519"" target=""_blank"">2302.13519</a>",,2025-12-03 22:39:25
Randomness in ML Defenses Helps Persistent Attackers and Hinders Evaluators,"Keane Lucas, Matthew Jagielski, Florian Tramèr, Lujo Bauer, Nicholas Carlini",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.13464"" target=""_blank"">2302.13464</a>",,2025-12-03 22:39:25
Improving Model Generalization by On-manifold Adversarial Augmentation in the Frequency Domain,"Chang Liu, Wenzhao Xiang, Yuan He, Hui Xue, Shibao Zheng, Hang Su",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.14302"" target=""_blank"">2302.14302</a>",,2025-12-03 22:39:25
Efficient and Low Overhead Website Fingerprinting Attacks and Defenses based on TCP/IP Traffic,"Guodong Huang, Chuan Ma, Ming Ding, Yuwen Qian, Chunpeng Ge, Liming Fang, Zhe Liu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.13763"" target=""_blank"">2302.13763</a>",,2025-12-03 22:39:25
Online Black-Box Confidence Estimation of Deep Neural Networks,"Fabian Woitschek, Georg Schneider",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.13578"" target=""_blank"">2302.13578</a>",,2025-12-03 22:39:25
Implicit Poisoning Attacks in Two-Agent Reinforcement Learning: Adversarial Policies for Training-Time Attacks,"Mohammad Mohammadi, Jonathan Nöther, Debmalya Mandal, Adish Singla, Goran Radanovic",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.13851"" target=""_blank"">2302.13851</a>",,2025-12-03 22:39:25
Differentially Private Diffusion Models Generate Useful Synthetic Images,"Sahra Ghalebikesabi, Leonard Berrada, Sven Gowal, Ira Ktena, Robert Stanforth, Jamie Hayes, Soham De, Samuel L. Smith, Olivia Wiles, Borja Balle",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.13861"" target=""_blank"">2302.13861</a>",,2025-12-03 22:39:25
Learning to Retain while Acquiring: Combating Distribution-Shift in Adversarial Data-Free Knowledge Distillation,"Gaurav Patel, Konda Reddy Mopuri, Qiang Qiu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.14290"" target=""_blank"">2302.14290</a>",,2025-12-03 22:39:25
Contextual adversarial attack against aerial detection in the physical world,"Jiawei Lian, Xiaofei Wang, Yuru Su, Mingyang Ma, Shaohui Mei",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.13487"" target=""_blank"">2302.13487</a>",,2025-12-03 22:39:25
MultiRobustBench: Benchmarking Robustness Against Multiple Attacks,"Sihui Dai, Saeed Mahloujifar, Chong Xiang, Vikash Sehwag, Pin-Yu Chen, Prateek Mittal",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.10980"" target=""_blank"">2302.10980</a>",,2025-12-03 22:39:25
GLOW: Global Layout Aware Attacks on Object Detection,"Buyu Liu, BaoJun, Jianping Fan, Xi Peng, Kui Ren, Jun Yu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.14166"" target=""_blank"">2302.14166</a>",,2025-12-03 22:39:25
Interpretable Spectrum Transformation Attacks to Speaker Recognition,"Jiadi Yao, Hong Luo, Xiao-Lei Zhang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.10686"" target=""_blank"">2302.10686</a>",,2025-12-03 22:39:25
Robust Mid-Pass Filtering Graph Convolutional Networks,"Jincheng Huang, Lun Du, Xu Chen, Qiang Fu, Shi Han, Dongmei Zhang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.08048"" target=""_blank"">2302.08048</a>",,2025-12-03 22:39:25
"Function Composition in Trustworthy Machine Learning: Implementation Choices, Insights, and Questions","Manish Nagireddy, Moninder Singh, Samuel C. Hoffman, Evaline Ju, Karthikeyan Natesan Ramamurthy, Kush R. Varshney",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09190"" target=""_blank"">2302.09190</a>",,2025-12-03 22:39:25
RetVec: Resilient and Efficient Text Vectorizer,"Elie Bursztein, Marina Zhang, Owen Vallis, Xinyu Jia, Alexey Kurakin",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09207"" target=""_blank"">2302.09207</a>","<a href=""https://github.com/[anonymized]"" target=""_blank"">github.com</a>",2025-12-03 22:39:25
On the Effect of Adversarial Training Against Invariance-based Adversarial Examples,"Roland Rauter, Martin Nocker, Florian Merkle, Pascal Schöttle",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.08257"" target=""_blank"">2302.08257</a>",,2025-12-03 22:39:25
High-frequency Matters: An Overwriting Attack and defense for Image-processing Neural Network Watermarking,"Huajie Chen, Tianqing Zhu, Chi Liu, Shui Yu, Wanlei Zhou",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.08637"" target=""_blank"">2302.08637</a>",,2025-12-03 22:39:25
Marich: A Query-efficient Distributionally Equivalent Model Extraction Attack using Public Data,"Pratik Karmakar, Debabrota Basu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.08466"" target=""_blank"">2302.08466</a>",,2025-12-03 22:39:25
A Novel Noise Injection-based Training Scheme for Better Model Robustness,"Zeliang Zhang, Jinyang Jiang, Minjie Chen, Zhiyuan Wang, Yijie Peng, Zhaofei Yu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.10802"" target=""_blank"">2302.10802</a>",,2025-12-03 22:39:25
Masking and Mixing Adversarial Training,"Hiroki Adachi, Tsubasa Hirakawa, Takayoshi Yamashita, Hironobu Fujiyoshi, Yasunori Ishii, Kazuki Kozuka",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.08066"" target=""_blank"">2302.08066</a>",,2025-12-03 22:39:25
Graph Adversarial Immunization for Certifiable Robustness,"Shuchang Tao, Huawei Shen, Qi Cao, Yunfan Wu, Liang Hou, Xueqi Cheng",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.08051"" target=""_blank"">2302.08051</a>",,2025-12-03 22:39:25
Beyond Distribution Shift: Spurious Features Through the Lens of Training Dynamics,"Nihal Murali, Aahlad Puli, Ke Yu, Rajesh Ranganath, Kayhan Batmanghelich",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09344"" target=""_blank"">2302.09344</a>",,2025-12-03 22:39:25
XploreNAS: Explore Adversarially Robust & Hardware-efficient Neural Architectures for Non-ideal Xbars,"Abhiroop Bhattacharjee, Abhishek Moitra, Priyadarshini Panda",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.07769"" target=""_blank"">2302.07769</a>",,2025-12-03 22:39:25
Field-sensitive Data Flow Integrity,"So Shizukuishi, Yoshitaka Arahori, Katsuhiko Gondow",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.07717"" target=""_blank"">2302.07717</a>",,2025-12-03 22:39:25
An Experimental Study of Byzantine-Robust Aggregation Schemes in Federated Learning,"Shenghui Li, Edith C. -H. Ngai, Thiemo Voigt",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.07173"" target=""_blank"">2302.07173</a>",,2025-12-03 22:39:25
Uncertainty-Estimation with Normalized Logits for Out-of-Distribution Detection,"Mouxiao Huang, Yu Qiao",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.07608"" target=""_blank"">2302.07608</a>",,2025-12-03 22:39:25
Characterizing the Optimal 0-1 Loss for Multi-class Classification with a Test-time Attacker,"Sihui Dai, Wenxin Ding, Arjun Nitin Bhagoji, Daniel Cullina, Ben Y. Zhao, Haitao Zheng, Prateek Mittal",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.10722"" target=""_blank"">2302.10722</a>",,2025-12-03 22:39:25
Regret-Based Defense in Adversarial Reinforcement Learning,"Roman Belaire, Pradeep Varakantham, Thanh Nguyen, David Lo",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.06912"" target=""_blank"">2302.06912</a>",,2025-12-03 22:39:25
On the Role of Randomization in Adversarially Robust Classification,"Lucas Gnecco-Heredia, Yann Chevaleyre, Benjamin Negrevergne, Laurent Meunier, Muni Sreenivas Pydi",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.07221"" target=""_blank"">2302.07221</a>",,2025-12-03 22:39:25
Measuring Equality in Machine Learning Security Defenses,"Luke E. Richards, Edward Raff, Cynthia Matuszek",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.08973"" target=""_blank"">2302.08973</a>",,2025-12-03 22:39:25
Tight Auditing of Differentially Private Machine Learning,"Milad Nasr, Jamie Hayes, Thomas Steinke, Borja Balle, Florian Tramèr, Matthew Jagielski, Nicholas Carlini, Andreas Terzis",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.07956"" target=""_blank"">2302.07956</a>",,2025-12-03 22:39:25
RobustNLP: A Technique to Defend NLP Models Against Backdoor Attacks,Marwan Omar,arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09420"" target=""_blank"">2302.09420</a>","<a href=""https://github.com/marwanomar1/Backdoor-Learning-for-NLP"" target=""_blank"">marwanomar1</a>",2025-12-03 22:39:25
Prompt Stealing Attacks Against Text-to-Image Generation Models,"Xinyue Shen, Yiting Qu, Michael Backes, Yang Zhang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09923"" target=""_blank"">2302.09923</a>",,2025-12-03 22:39:25
Generalization Bounds for Adversarial Contrastive Learning,"Xin Zou, Weiwei Liu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.10633"" target=""_blank"">2302.10633</a>",,2025-12-03 22:39:25
Variation Enhanced Attacks Against RRAM-based Neuromorphic Computing System,"Hao Lv, Bing Li, Lei Zhang, Cheng Liu, Ying Wang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09902"" target=""_blank"">2302.09902</a>",,2025-12-03 22:39:25
Seasoning Model Soups for Robustness to Adversarial and Natural Distribution Shifts,"Francesco Croce, Sylvestre-Alvise Rebuffi, Evan Shelhamer, Sven Gowal",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.10164"" target=""_blank"">2302.10164</a>",,2025-12-03 22:39:25
Poisoning Web-Scale Training Datasets is Practical,"Nicholas Carlini, Matthew Jagielski, Christopher A. Choquette-Choo, Daniel Paleka, Will Pearce, Hyrum Anderson, Andreas Terzis, Kurt Thomas, Florian Tramèr",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.10149"" target=""_blank"">2302.10149</a>",,2025-12-03 22:39:25
MedViT: A Robust Vision Transformer for Generalized Medical Image Classification,"Omid Nejati Manzari, Hamid Ahmadabadi, Hossein Kashiani, Shahriar B. Shokouhi, Ahmad Ayatollahi",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09462"" target=""_blank"">2302.09462</a>",,2025-12-03 22:39:25
Pseudo Label-Guided Model Inversion Attack via Conditional Generative Adversarial Network,"Xiaojian Yuan, Kejiang Chen, Jie Zhang, Weiming Zhang, Nenghai Yu, Yang Zhang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09814"" target=""_blank"">2302.09814</a>","<a href=""https://github.com/LetheSec/PLG-MI-Attack"" target=""_blank"">LetheSec</a>",2025-12-03 22:39:25
Take Me Home: Reversing Distribution Shifts using Reinforcement Learning,"Vivian Lin, Kuk Jin Jang, Souradeep Dutta, Michele Caprio, Oleg Sokolsky, Insup Lee",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.10341"" target=""_blank"">2302.10341</a>",,2025-12-03 22:39:25
Model-based feature selection for neural networks: A mixed-integer programming approach,"Shudian Zhao, Calvin Tsay, Jan Kronqvist",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.10344"" target=""_blank"">2302.10344</a>",,2025-12-03 22:39:25
Attacking Fake News Detectors via Manipulating News Social Engagement,"Haoran Wang, Yingtong Dou, Canyu Chen, Lichao Sun, Philip S. Yu, Kai Shu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.07363"" target=""_blank"">2302.07363</a>",,2025-12-03 22:39:25
X-Adv: Physical Adversarial Object Attacks against X-ray Prohibited Item Detection,"Aishan Liu, Jun Guo, Jiakai Wang, Siyuan Liang, Renshuai Tao, Wenbo Zhou, Cong Liu, Xianglong Liu, Dacheng Tao",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09491"" target=""_blank"">2302.09491</a>",,2025-12-03 22:39:25
On Feasibility of Server-side Backdoor Attacks on Split Learning,"Behrad Tajalli, Oguzhan Ersoy, Stjepan Picek",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09578"" target=""_blank"">2302.09578</a>",,2025-12-03 22:39:25
"Towards Safer Generative Language Models: A Survey on Safety Risks, Evaluations, and Improvements","Jiawen Deng, Jiale Cheng, Hao Sun, Zhexin Zhang, Minlie Huang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09270"" target=""_blank"">2302.09270</a>",,2025-12-03 22:39:25
Meta Style Adversarial Training for Cross-Domain Few-Shot Learning,"Yuqian Fu, Yu Xie, Yanwei Fu, Yu-Gang Jiang",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09309"" target=""_blank"">2302.09309</a>",,2025-12-03 22:39:25
"Adversarial Machine Learning: A Systematic Survey of Backdoor Attack, Weight Attack and Adversarial Example","Baoyuan Wu, Li Liu, Zihao Zhu, Qingshan Liu, Zhaofeng He, Siwei Lyu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09457"" target=""_blank"">2302.09457</a>",,2025-12-03 22:39:25
Delving into the Adversarial Robustness of Federated Learning,"Jie Zhang, Bo Li, Chen Chen, Lingjuan Lyu, Shuang Wu, Shouhong Ding, Chao Wu",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09479"" target=""_blank"">2302.09479</a>",,2025-12-03 22:39:25
Stationary Point Losses for Robust Model,"Weiwei Gao, Dazhi Zhang, Yao Li, Zhichang Guo, Ovanes Petrosian",arXiv,2023-02,"<a href=""http://arxiv.org/abs/2302.09575"" target=""_blank"">2302.09575</a>",,2025-12-03 22:39:25
ContraBERT: Enhancing Code Pre-trained Models via Contrastive Learning,"Shangqing Liu, Bozhi Wu, Xiaofei Xie, Guozhu Meng, Yang Liu",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.09072"" target=""_blank"">2301.09072</a>",,2025-12-03 22:39:25
Towards Understanding How Self-training Tolerates Data Backdoor Poisoning,"Soumyadeep Pal, Ren Wang, Yuguang Yao, Sijia Liu",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.08751"" target=""_blank"">2301.08751</a>",,2025-12-03 22:39:25
On the Susceptibility and Robustness of Time Series Models through Adversarial Attack and Defense,"Asadullah Hill Galib, Bidhan Bashyal",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.03703"" target=""_blank"">2301.03703</a>",,2025-12-03 22:39:25
Over-The-Air Adversarial Attacks on Deep Learning Wi-Fi Fingerprinting,"Fei Xiao, Yong Huang, Yingying Zuo, Wei Kuang, Wei Wang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.03760"" target=""_blank"">2301.03760</a>",,2025-12-03 22:39:25
Leveraging Diffusion For Strong and High Quality Face Morphing Attacks,"Zander W. Blasingame, Chen Liu",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.04218"" target=""_blank"">2301.04218</a>",,2025-12-03 22:39:25
Is Federated Learning a Practical PET Yet? (13%),"Franziska Boenisch, Adam Dziedzic, Roei Schuster, Ali Shahin Shamsabadi, Ilia Shumailov, Nicolas Papernot",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.04017"" target=""_blank"">2301.04017</a>",,2025-12-03 22:39:25
User-Centered Security in Natural Language Processing,Chris Emmery,arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.04230"" target=""_blank"">2301.04230</a>",,2025-12-03 22:39:25
CDA: Contrastive-adversarial Domain Adaptation,"Nishant Yadav, Mahbubul Alam, Ahmed Farahat, Dipanjan Ghosh, Chetan Gupta, Auroop R. Ganguly",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.03826"" target=""_blank"">2301.03826</a>",,2025-12-03 22:39:25
On the Robustness of AlphaFold: A COVID-19 Case Study,"Ismail Alkhouri, Sumit Jha, Andre Beckus, George Atia, Alvaro Velasquez, Rickard Ewetz, Arvind Ramanathan, Susmit Jha",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.04093"" target=""_blank"">2301.04093</a>",,2025-12-03 22:39:25
Universal Detection of Backdoor Attacks via Density-based Clustering and Centroids Analysis,"Wei Guo, Benedetta Tondi, Mauro Barni",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.04554"" target=""_blank"">2301.04554</a>",,2025-12-03 22:39:25
Phase-shifted Adversarial Training,"Yeachan Kim, Seongyeon Kim, Ihyeok Seo, Bonggun Shin",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.04785"" target=""_blank"">2301.04785</a>",,2025-12-03 22:39:25
Jamming Attacks on Decentralized Federated Learning in General Multi-Hop Wireless Networks,"Yi Shi, Yalin E. Sagduyu, Tugba Erpek",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.05250"" target=""_blank"">2301.05250</a>",,2025-12-03 22:39:25
Security-Aware Approximate Spiking Neural Networks,"Syed Tihaam Ahmad, Ayesha Siddique, Khaza Anuarul Hoque",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.05264"" target=""_blank"">2301.05264</a>",,2025-12-03 22:39:25
On the feasibility of attacking Thai LPR systems with adversarial examples,"Chissanupong Jiamsuchon, Jakapan Suaboot, Norrathep Rattanavipanon",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.05506"" target=""_blank"">2301.05506</a>",,2025-12-03 22:39:25
Adaptive Deep Neural Network Inference Optimization with EENet,"Fatih Ilhan, Ka-Ho Chow, Sihao Hu, Tiansheng Huang, Selim Tekin, Wenqi Wei, Yanzhao Wu, Myungjin Lee, Ramana Kompella, Hugo Latapie, Gaowen Liu, Ling Liu",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.07099"" target=""_blank"">2301.07099</a>",,2025-12-03 22:39:25
Defending SDN against packet injection attacks using deep learning,"Anh Tuan Phu, Bo Li, Faheem Ullah, Tanvir Ul Huque, Ranesh Naha, Ali Babar, Hung Nguyen",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.08428"" target=""_blank"">2301.08428</a>",,2025-12-03 22:39:25
BEAGLE: Forensics of Deep Learning Backdoor Attack for Better Defense,"Siyuan Cheng, Guanhong Tao, Yingqi Liu, Shengwei An, Xiangzhe Xu, Shiwei Feng, Guangyu Shen, Kaiyuan Zhang, Qiuling Xu, Shiqing Ma, Xiangyu Zhang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.06241"" target=""_blank"">2301.06241</a>",,2025-12-03 22:39:25
Modeling Uncertain Feature Representation for Domain Generalization,"Xiaotong Li, Zixuan Hu, Jun Liu, Yixiao Ge, Yongxing Dai, Ling-Yu Duan",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.06442"" target=""_blank"">2301.06442</a>","<a href=""https://github.com/lixiaotong97/DSU"" target=""_blank"">lixiaotong97</a>",2025-12-03 22:39:25
Limitations of Piecewise Linearity for Efficient Robustness Certification,Klas Leino,arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.08842"" target=""_blank"">2301.08842</a>",,2025-12-03 22:39:25
$\beta$-DARTS++: Bi-level Regularization for Proxy-robust Differentiable Architecture Search,"Peng Ye, Tong He, Baopu Li, Tao Chen, Lei Bai, Wanli Ouyang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.06393"" target=""_blank"">2301.06393</a>",,2025-12-03 22:39:25
Label Inference Attack against Split Learning under Regression Setting,"Shangyu Xie, Xin Yang, Yuanshun Yao, Tianyi Liu, Taiqing Wang, Jiankai Sun",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.07284"" target=""_blank"">2301.07284</a>",,2025-12-03 22:39:25
Adversarial Robust Deep Reinforcement Learning Requires Redefining Robustness,Ezgi Korkmaz,arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.07487"" target=""_blank"">2301.07487</a>",,2025-12-03 22:39:25
Dr,"Shuaichen Chang, Jun Wang, Mingwen Dong, Lin Pan, Henghui Zhu, Alexander Hanbo Li, Wuwei Lan, Sheng Zhang, Jiarong Jiang, Joseph Lilien, Steve Ash, William Yang Wang, Zhiguo Wang, Vittorio Castelli, Patrick Ng, Bing Xiang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.08881"" target=""_blank"">2301.08881</a>",,2025-12-03 22:39:25
Enhancing Deep Learning with Scenario-Based Override Rules: a Case Study,"Adiel Ashrov, Guy Katz",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.08114"" target=""_blank"">2301.08114</a>",,2025-12-03 22:39:25
RNAS-CL: Robust Neural Architecture Search by Cross-Layer Knowledge Distillation,"Utkarsh Nath, Yancheng Wang, Yingzhen Yang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.08092"" target=""_blank"">2301.08092</a>",,2025-12-03 22:39:25
On the Relationship Between Information-Theoretic Privacy Metrics And Probabilistic Information Privacy,"Chong Xiao Wang, Wee Peng Tay",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.08401"" target=""_blank"">2301.08401</a>",,2025-12-03 22:39:25
On the Vulnerability of Backdoor Defenses for Federated Learning,"Pei Fang, Jinghui Chen",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.08170"" target=""_blank"">2301.08170</a>",,2025-12-03 22:39:25
Denoising Diffusion Probabilistic Models as a Defense against Adversarial Attacks,"Lars Lien Ankile, Anna Midgley, Sebastian Weisshaar",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.06871"" target=""_blank"">2301.06871</a>","<a href=""https://github.com/ankile/Adversarial-Diffusion"" target=""_blank"">ankile</a>",2025-12-03 22:39:25
Enhancement attacks in biomedical machine learning,"Matthew Rosenblatt, Javid Dadashkarimi, Dustin Scheinost",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.01885"" target=""_blank"">2301.01885</a>",,2025-12-03 22:39:25
SoK: Hardware Defenses Against Speculative Execution Attacks,"Guangyuan Hu, Zecheng He, Ruby Lee",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.03724"" target=""_blank"">2301.03724</a>",,2025-12-03 22:39:25
"Look, Listen, and Attack: Backdoor Attacks Against Video Action Recognition","Hasan Abed Al Kader Hammoud, Shuming Liu, Mohammed Alkhrashi, Fahad AlBalawi, Bernard Ghanem",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.00986"" target=""_blank"">2301.00986</a>",,2025-12-03 22:39:25
Optimising Event-Driven Spiking Neural Network with Regularisation and Cutoff,"Dengyu Wu, Gaojie Jin, Han Yu, Xinping Yi, Xiaowei Huang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.09522"" target=""_blank"">2301.09522</a>","<a href=""https://github.com/Dengyu-Wu/SNNCutoff"" target=""_blank"">Dengyu-Wu</a>",2025-12-03 22:39:25
White-box Inference Attacks against Centralized Machine Learning and Federated Learning,Jingyi Ge,arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.03595"" target=""_blank"">2301.03595</a>",,2025-12-03 22:39:25
Discrete Point-wise Attack Is Not Enough: Generalized Manifold Adversarial Attack for Face Recognition,"Qian Li, Yuxiao Hu, Ye Liu, Dongxiao Zhang, Xin Jin, Yuntian Chen",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.06083"" target=""_blank"">2301.06083</a>",,2025-12-03 22:39:25
Targeted k-node Collapse Problem: Towards Understanding the Robustness of Local k-core Structure,"Yuqian Lv, Bo Zhou, Jinhuan Wang, Qi Xuan",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.00108"" target=""_blank"">2301.00108</a>",,2025-12-03 22:39:25
Unlearnable Clusters: Towards Label-agnostic Unlearnable Examples,"Jiaming Zhang, Xingjun Ma, Qi Yi, Jitao Sang, Yugang Jiang, Yaowei Wang, Changsheng Xu",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.01217"" target=""_blank"">2301.01217</a>","<a href=""https://github.com/jiamingzhang94/Unlearnable-Clusters"" target=""_blank"">jiamingzhang94</a>",2025-12-03 22:39:25
Tracing the Origin of Adversarial Attack for Forensic Investigation and Deterrence,"Han Fang, Jiyi Zhang, Yupeng Qiu, Ke Xu, Chengfang Fang, Ee-Chien Chang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.01218"" target=""_blank"">2301.01218</a>",,2025-12-03 22:39:25
Trojaning semi-supervised learning model via poisoning wild images on the web,"Le Feng, Zhenxing Qian, Sheng Li, Xinpeng Zhang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.00435"" target=""_blank"">2301.00435</a>",,2025-12-03 22:39:25
ExploreADV: Towards exploratory attack for Neural Networks,"Tianzuo Luo, Yuyi Zhong, Siaucheng Khoo",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.01223"" target=""_blank"">2301.01223</a>",,2025-12-03 22:39:25
Generalizable Black-Box Adversarial Attack with Meta Learning,"Fei Yin, Yong Zhang, Baoyuan Wu, Yan Feng, Jingyi Zhang, Yanbo Fan, Yujiu Yang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.00364"" target=""_blank"">2301.00364</a>",,2025-12-03 22:39:25
Efficient Robustness Assessment via Adversarial Spatial-Temporal Focus on Videos,"Wei Xingxing, Wang Songping, Yan Huanqian",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.00896"" target=""_blank"">2301.00896</a>",,2025-12-03 22:39:25
Analysis of Label-Flip Poisoning Attack on Machine Learning Based Malware Detector,"Kshitiz Aryal, Maanak Gupta, Mahmoud Abdelsalam",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.01044"" target=""_blank"">2301.01044</a>",,2025-12-03 22:39:25
Backdoor Attacks Against Dataset Distillation,"Yugeng Liu, Zheng Li, Michael Backes, Yun Shen, Yang Zhang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.01197"" target=""_blank"">2301.01197</a>",,2025-12-03 22:39:25
Explainability and Robustness of Deep Visual Classification Models,Jindong Gu,arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.01343"" target=""_blank"">2301.01343</a>",,2025-12-03 22:39:25
RobArch: Designing Robust Architectures against Adversarial Attacks,"ShengYun Peng, Weilin Xu, Cory Cornelius, Kevin Li, Rahul Duggal, Duen Horng Chau, Jason Martin",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.03110"" target=""_blank"">2301.03110</a>","<a href=""https://github.com/ShengYun-Peng/RobArch"" target=""_blank"">ShengYun-Peng</a>",2025-12-03 22:39:25
GUAP: Graph Universal Attack Through Adversarial Patching,"Xiao Zang, Jie Chen, Bo Yuan",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.01731"" target=""_blank"">2301.01731</a>",,2025-12-03 22:39:25
Beckman Defense,A. V. Subramanyam,arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.01495"" target=""_blank"">2301.01495</a>","<a href=""https://github.com/Visual-Conception-Group/test-barycentric-defense"" target=""_blank"">Visual-Conception-Group</a>",2025-12-03 22:39:25
Availability Adversarial Attack and Countermeasures for Deep Learning-based Load Forecasting,"Wangkun Xu, Fei Teng",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.01832"" target=""_blank"">2301.01832</a>","<a href=""https://github.com/xuwkk/AAA_Load_Forecast"" target=""_blank"">xuwkk</a>",2025-12-03 22:39:25
TrojanPuzzle: Covertly Poisoning Code-Suggestion Models,"Hojjat Aghakhani, Wei Dai, Andre Manoel, Xavier Fernandes, Anant Kharkar, Christopher Kruegel, Giovanni Vigna, David Evans, Ben Zorn, Robert Sim",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.02344"" target=""_blank"">2301.02344</a>",,2025-12-03 22:39:25
Randomized Message-Interception Smoothing: Gray-box Certificates for Graph Neural Networks,"Yan Scholten, Jan Schuchardt, Simon Geisler, Aleksandar Bojchevski, Stephan Günnemann",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.02039"" target=""_blank"">2301.02039</a>",,2025-12-03 22:39:25
gRoMA: a Tool for Measuring the Global Robustness of Deep Neural Networks,"Natan Levy, Raz Yerushalmi, Guy Katz",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.02288"" target=""_blank"">2301.02288</a>",,2025-12-03 22:39:25
"Silent Killer: A Stealthy, Clean-Label, Black-Box Backdoor Attack","Tzvi Lederer, Gallil Maimon, Lior Rokach",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.02615"" target=""_blank"">2301.02615</a>",,2025-12-03 22:39:25
Stealthy Backdoor Attack for Code Models,"Zhou Yang, Bowen Xu, Jie M. Zhang, Hong Jin Kang, Jieke Shi, Junda He, David Lo",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.02496"" target=""_blank"">2301.02496</a>",,2025-12-03 22:39:25
Code Difference Guided Adversarial Example Generation for Deep Code Models,"Zhao Tian, Junjie Chen, Zhi Jin",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.02412"" target=""_blank"">2301.02412</a>",,2025-12-03 22:39:25
Adversarial training with informed data selection,"Marcele O. K. Mendonça, Javier Maroto, Pascal Frossard, Paulo S. R. Diniz",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.04472"" target=""_blank"">2301.04472</a>",,2025-12-03 22:39:25
REaaS: Enabling Adversarially Robust Downstream Classifiers via Robust Encoder as a Service,"Wenjie Qu, Jinyuan Jia, Neil Zhenqiang Gong",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.02905"" target=""_blank"">2301.02905</a>",,2025-12-03 22:39:25
Facial Misrecognition Systems: Simple Weight Manipulations Force DNNs to Err Only on Specific Persons,"Irad Zehavi, Roee Nitzan, Adi Shamir",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.03118"" target=""_blank"">2301.03118</a>",,2025-12-03 22:39:25
Provable Unrestricted Adversarial Training without Compromise with Generalizability,"Lilin Zhang, Ning Yang, Yanchao Sun, Philip S. Yu",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.09069"" target=""_blank"">2301.09069</a>",,2025-12-03 22:39:25
Blockchain-aided Secure Semantic Communication for AI-Generated Content in Metaverse,"Yijing Lin, Hongyang Du, Dusit Niyato, Jiangtian Nie, Jiayi Zhang, Yanyu Cheng, Zhaohui Yang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.11289"" target=""_blank"">2301.11289</a>",,2025-12-03 22:39:25
Backdoor Attacks in Peer-to-Peer Federated Learning,"Gokberk Yar, Cristina Nita-Rotaru, Alina Oprea",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.09732"" target=""_blank"">2301.09732</a>",,2025-12-03 22:39:25
Anchor-Based Adversarially Robust Zero-Shot Learning Driven by Language,"Xiao Li, Wei Zhang, Yining Liu, Zhanhao Hu, Bo Zhang, Xiaolin Hu",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.13096"" target=""_blank"">2301.13096</a>",,2025-12-03 22:39:25
"Diverse, Difficult, and Odd Instances (D2O): A New Test Set for Object Classification",Ali Borji,arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12527"" target=""_blank"">2301.12527</a>",,2025-12-03 22:39:25
Lateralized Learning for Multi-Class Visual Classification Tasks,"Abubakar Siddique, Will N. Browne, Gina M. Grimshaw",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12637"" target=""_blank"">2301.12637</a>",,2025-12-03 22:39:25
Towards Verifying the Geometric Robustness of Large-scale Neural Networks,"Fu Wang, Peipei Xu, Wenjie Ruan, Xiaowei Huang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12456"" target=""_blank"">2301.12456</a>","<a href=""https://github.com/TrustAI/GeoRobust"" target=""_blank"">TrustAI</a>",2025-12-03 22:39:25
Adversarial Attacks on Adversarial Bandits,"Yuzhe Ma, Zhijin Zhou",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12595"" target=""_blank"">2301.12595</a>",,2025-12-03 22:39:25
Uncovering Adversarial Risks of Test-Time Adaptation,"Tong Wu, Feiran Jia, Xiangyu Qi, Jiachen T. Wang, Vikash Sehwag, Saeed Mahloujifar, Prateek Mittal",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12576"" target=""_blank"">2301.12576</a>",,2025-12-03 22:39:25
Improving the Accuracy-Robustness Trade-Off of Classifiers via Adaptive Smoothing,"Yatong Bai, Brendon G. Anderson, Aerin Kim, Somayeh Sojoudi",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12554"" target=""_blank"">2301.12554</a>","<a href=""https://github.com/Bai-YT/AdaptiveSmoothing"" target=""_blank"">Bai-YT</a>",2025-12-03 22:39:25
Mitigating Adversarial Effects of False Data Injection Attacks in Power Grid,"Farhin Farhad Riya, Shahinul Hoque, Yingyuan Yang, Jiangnan Li, Jinyuan Stella Sun, Hairong Qi",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12487"" target=""_blank"">2301.12487</a>",,2025-12-03 22:39:25
Unlocking Deterministic Robustness Certification on ImageNet,"Kai Hu, Andy Zou, Zifan Wang, Klas Leino, Matt Fredrikson",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12549"" target=""_blank"">2301.12549</a>",,2025-12-03 22:39:25
M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing System,"Chenqi Kong, Kexin Zheng, Yibing Liu, Shiqi Wang, Anderson Rocha, Haoliang Li",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12831"" target=""_blank"">2301.12831</a>",,2025-12-03 22:39:25
Affinity Uncertainty-based Hard Negative Mining in Graph Contrastive Learning,"Chaoxi Niu, Guansong Pang, Ling Chen",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.13340"" target=""_blank"">2301.13340</a>","<a href=""https://github.com/mala-lab/AUGCL"" target=""_blank"">mala-lab</a>",2025-12-03 22:39:25
Extracting Training Data from Diffusion Models,"Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramèr, Borja Balle, Daphne Ippolito, Eric Wallace",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.13188"" target=""_blank"">2301.13188</a>",,2025-12-03 22:39:25
Benchmarking Robustness to Adversarial Image Obfuscations,"Florian Stimberg, Ayan Chakrabarti, Chun-Ta Lu, Hussein Hazimeh, Otilia Stretcu, Wei Qiao, Yintao Liu, Merve Kaya, Cyrus Rashtchian, Ariel Fuxman, Mehmet Tek, Sven Gowal",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12993"" target=""_blank"">2301.12993</a>",,2025-12-03 22:39:25
Inference Time Evidences of Adversarial Attacks for Forensic on Transformers,"Hugo Lemarchant, Liangzi Li, Yiming Qian, Yuta Nakashima, Hajime Nagahara",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.13356"" target=""_blank"">2301.13356</a>",,2025-12-03 22:39:25
On Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on Codex,"Terry Yue Zhuo, Zhuang Li, Yujin Huang, Fatemeh Shiri, Weiqing Wang, Gholamreza Haffari, Yuan-Fang Li",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12868"" target=""_blank"">2301.12868</a>",,2025-12-03 22:39:25
Confidence-Aware Calibration and Scoring Functions for Curriculum Learning,"Shuang Ao, Stefan Rueger, Advaith Siddharthan",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12589"" target=""_blank"">2301.12589</a>","<a href=""https://github.com/AoShuang92/Confidence_Calibration_CL"" target=""_blank"">AoShuang92</a>",2025-12-03 22:39:25
Identifying Adversarially Attackable and Robust Samples,"Vyas Raina, Mark Gales",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12896"" target=""_blank"">2301.12896</a>",,2025-12-03 22:39:25
Towards Adversarial Realism and Robust Learning for IoT Intrusion Detection and Classification,"João Vitorino, Isabel Praça, Eva Maia",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.13122"" target=""_blank"">2301.13122</a>",,2025-12-03 22:39:25
Improving Adversarial Transferability with Scheduled Step Size and Dual Example,"Zeliang Zhang, Peihan Liu, Xiaosen Wang, Chenliang Xu",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12968"" target=""_blank"">2301.12968</a>",,2025-12-03 22:39:25
Feature-Space Bayesian Adversarial Learning Improved Malware Detector Robustness,"Bao Gia Doan, Shuiqiao Yang, Paul Montague, Vel Olivier De, Tamas Abraham, Seyit Camtepe, Salil S. Kanhere, Ehsan Abbasnejad, Damith C. Ranasinghe",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12680"" target=""_blank"">2301.12680</a>",,2025-12-03 22:39:25
Identifying the Hazard Boundary of ML-enabled Autonomous Systems Using Cooperative Co-Evolutionary Search,"Sepehr Sharifi, Donghwan Shin, Lionel C. Briand, Nathan Aschbacher",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.13807"" target=""_blank"">2301.13807</a>",,2025-12-03 22:39:25
DRAINCLoG: Detecting Rogue Accounts with Illegally-obtained NFTs using Classifiers Learned on Graphs,"Hanna Kim, Jian Cui, Eugene Jang, Chanhee Lee, Yongjae Lee, Jin-Woo Chung, Seungwon Shin",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.13577"" target=""_blank"">2301.13577</a>",,2025-12-03 22:39:25
Image Shortcut Squeezing: Countering Perturbative Availability Poisons with Compression,"Zhuoran Liu, Zhengyu Zhao, Martha Larson",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.13838"" target=""_blank"">2301.13838</a>",,2025-12-03 22:39:25
"Robust Linear Regression: Gradient-descent, Early-stopping, and Beyond","Meyer Scetbon, Elvis Dohmatob",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.13486"" target=""_blank"">2301.13486</a>",,2025-12-03 22:39:25
Fairness-aware Vision Transformer via Debiased Self-Attention,"Yao Qiang, Chengyin Li, Prashant Khanduri, Dongxiao Zhu",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.13803"" target=""_blank"">2301.13803</a>",,2025-12-03 22:39:25
Reverse engineering adversarial attacks with fingerprints from adversarial examples,"David Aaron Embedded Intelligence Nicholson, Vincent Embedded Intelligence Emanuele",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.13869"" target=""_blank"">2301.13869</a>",,2025-12-03 22:39:25
BayBFed: Bayesian Backdoor Defense for Federated Learning,"Kavita Kumari, Phillip Rieger, Hossein Fereidooni, Murtuza Jadliwala, Ahmad-Reza Sadeghi",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.09508"" target=""_blank"">2301.09508</a>",,2025-12-03 22:39:25
Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks,"Zhiyuan Cheng, James Liang, Guanhong Tao, Dongfang Liu, Xiangyu Zhang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.13487"" target=""_blank"">2301.13487</a>",,2025-12-03 22:39:25
Are Defenses for Graph Neural Networks Robust? (80%),"Felix Mujkanovic, Simon Geisler, Stephan Günnemann, Aleksandar Bojchevski",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.13694"" target=""_blank"">2301.13694</a>",,2025-12-03 22:39:25
Adversarial Style Augmentation for Domain Generalization,"Yabin Zhang, Bin Deng, Ruihuang Li, Kui Jia, Lei Zhang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12643"" target=""_blank"">2301.12643</a>","<a href=""https://github.com/YBZh/AdvStyle"" target=""_blank"">YBZh</a>",2025-12-03 22:39:25
On the Efficacy of Metrics to Describe Adversarial Attacks,"Tommaso Puccetti, Tommaso Zoppi, Andrea Ceccarelli",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.13028"" target=""_blank"">2301.13028</a>",,2025-12-03 22:39:25
Node Injection for Class-specific Network Poisoning,"Ansh Kumar Sharma, Rahul Kukreja, Mayank Kharbanda, Tanmoy Chakraborty",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12277"" target=""_blank"">2301.12277</a>",,2025-12-03 22:39:25
Certified Interpretability Robustness for Class Activation Mapping,"Alex Gu, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, Luca Daniel",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.11324"" target=""_blank"">2301.11324</a>",,2025-12-03 22:39:25
Practical Adversarial Attacks Against AI-Driven Power Allocation in a Distributed MIMO Network,"Ömer Faruk Tuna, Fehmi Emre Kadan, Leyli Karaçay",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.09305"" target=""_blank"">2301.09305</a>",,2025-12-03 22:39:25
DODEM: DOuble DEfense Mechanism Against Adversarial Attacks Towards Secure Industrial Internet of Things Analytics,"Onat Gungor, Tajana Rosing, Baris Aksanli",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.09740"" target=""_blank"">2301.09740</a>",,2025-12-03 22:39:25
Data Augmentation Alone Can Improve Adversarial Training,"Lin Li, Michael Spratling",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.09879"" target=""_blank"">2301.09879</a>","<a href=""https://github.com/TreeLLi/DA-Alone-Improves-AT"" target=""_blank"">TreeLLi</a>",2025-12-03 22:39:25
Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering,"Rui Zhu, Di Tang, Siyuan Tang, Guanhong Tao, Shiqing Ma, Xiaofeng Wang, Haixu Tang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12318"" target=""_blank"">2301.12318</a>",,2025-12-03 22:39:25
Connecting metrics for shape-texture knowledge in computer vision,"Tiago Oliveira, Tiago Marques, Arlindo L. Oliveira",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.10608"" target=""_blank"">2301.10608</a>",,2025-12-03 22:39:25
Distilling Cognitive Backdoor Patterns within an Image,"Hanxun Huang, Xingjun Ma, Sarah Erfani, James Bailey",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.10908"" target=""_blank"">2301.10908</a>","<a href=""https://github.com/HanxunH/CognitiveDistillation"" target=""_blank"">HanxunH</a>",2025-12-03 22:39:25
A Study on FGSM Adversarial Training for Neural Retrieval,"Simon Lupart, Stéphane Clinchant",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.10576"" target=""_blank"">2301.10576</a>",,2025-12-03 22:39:25
A Data-Centric Approach for Improving Adversarial Training Through the Lens of Out-of-Distribution Detection,"Mohammad Azizmalayeri, Arman Zarei, Alireza Isavand, Mohammad Taghi Manzuri, Mohammad Hossein Rohban",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.10454"" target=""_blank"">2301.10454</a>",,2025-12-03 22:39:25
BDMMT: Backdoor Sample Detection for Language Models through Model Mutation Testing,"Jiali Wei, Ming Fan, Wenjing Jiao, Wuxia Jin, Ting Liu",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.10412"" target=""_blank"">2301.10412</a>",,2025-12-03 22:39:25
RobustPdM: Designing Robust Predictive Maintenance against Adversarial Attacks,"Ayesha Siddique, Ripan Kumar Kundu, Gautam Raj Mode, Khaza Anuarul Hoque",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.10822"" target=""_blank"">2301.10822</a>",,2025-12-03 22:39:25
On the Adversarial Robustness of Camera-based 3D Object Detection,"Shaoyuan Xie, Zichao Li, Zeyu Wang, Cihang Xie",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.10766"" target=""_blank"">2301.10766</a>",,2025-12-03 22:39:25
Interaction-level Membership Inference Attack Against Federated Recommender Systems,"Wei Yuan, Chaoqun Yang, Quoc Viet Hung Nguyen, Lizhen Cui, Tieke He, Hongzhi Yin",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.10964"" target=""_blank"">2301.10964</a>",,2025-12-03 22:39:25
Minerva: A File-Based Ransomware Detector,"Dorjan Hitaj, Giulio Pagnotta, Gaspari Fabio De, Carli Lorenzo De, Luigi V. Mancini",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.11050"" target=""_blank"">2301.11050</a>",,2025-12-03 22:39:25
Learning Effective Strategies for Moving Target Defense with Switching Costs,"Vignesh Viswanathan, Megha Bose, Praveen Paruchuri",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.09892"" target=""_blank"">2301.09892</a>",,2025-12-03 22:39:25
Attacking Important Pixels for Anchor-free Detectors,"Yunxu Xie, Shu Hu, Xin Wang, Quanyu Liao, Bin Zhu, Xi Wu, Siwei Lyu",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.11457"" target=""_blank"">2301.11457</a>",,2025-12-03 22:39:25
Vertex-based reachability analysis for verifying ReLU deep neural networks,"João Zago, Eduardo Camponogara, Eric Antonelo",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12001"" target=""_blank"">2301.12001</a>",,2025-12-03 22:39:25
Selecting Models based on the Risk of Damage Caused by Adversarial Attacks,"Jona Klemenc, Holger Trittenbach",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12151"" target=""_blank"">2301.12151</a>",,2025-12-03 22:39:25
Semantic Adversarial Attacks on Face Recognition through Significant Attributes,"Yasmeen M. Khedr, Yifeng Xiong, Kun He",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12046"" target=""_blank"">2301.12046</a>",,2025-12-03 22:39:25
Certified Invertibility in Neural Networks via Mixed-Integer Programming,"Tianqi Cui, Thomas Bertalan, George J. Pappas, Manfred Morari, Ioannis G. Kevrekidis, Mahyar Fazlyab",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.11783"" target=""_blank"">2301.11783</a>",,2025-12-03 22:39:25
Targeted Attacks on Timeseries Forecasting,"Yuvaraj Govindarajulu, Avinash Amballa, Pavan Kulkarni, Manojkumar Parmar",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.11544"" target=""_blank"">2301.11544</a>",,2025-12-03 22:39:25
PECAN: A Deterministic Certified Defense Against Backdoor Attacks,"Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.11824"" target=""_blank"">2301.11824</a>",,2025-12-03 22:39:25
Adapting Step-size: A Unified Perspective to Analyze and Improve Gradient-based Methods for Adversarial Attacks,"Wei Tao, Lei Bao, Long Sheng, Gaowei Wu, Qing Tao",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.11546"" target=""_blank"">2301.11546</a>",,2025-12-03 22:39:25
OccRob: Efficient SMT-Based Occlusion Robustness Verification of Deep Neural Networks,"Xingwu Guo, Ziwei Zhou, Yueling Zhang, Guy Katz, Min Zhang",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.11912"" target=""_blank"">2301.11912</a>",,2025-12-03 22:39:25
PCV: A Point Cloud-Based Network Verifier,"Arup Kumar Sarker, Farzana Yasmin Ahmad, Matthew B. Dwyer",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.11806"" target=""_blank"">2301.11806</a>",,2025-12-03 22:39:25
Robust Transformer with Locality Inductive Bias and Feature Normalization,"Omid Nejati Manzari, Hossein Kashiani, Hojat Asgarian Dehkordi, Shahriar Baradaran Shokouhi",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.11553"" target=""_blank"">2301.11553</a>",,2025-12-03 22:39:25
Learning to Unlearn: Instance-wise Unlearning for Pre-trained Classifiers,"Sungmin Cha, Sungjun Cho, Dasol Hwang, Honglak Lee, Taesup Moon, Moontae Lee",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.11578"" target=""_blank"">2301.11578</a>",,2025-12-03 22:39:25
Analyzing Robustness of the Deep Reinforcement Learning Algorithm in Ramp Metering Applications Considering False Data Injection Attack and Defense,"Diyi Liu, Lanmin Liu, Lee D Han",arXiv,2023-01,"<a href=""http://arxiv.org/abs/2301.12036"" target=""_blank"">2301.12036</a>",,2025-12-03 22:39:25
Dynamic Test-Time Augmentation via Differentiable Functions,"Shohei Enomoto, Monikka Roslianna Busto, Takeharu Eda",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.04681"" target=""_blank"">2212.04681</a>","<a href=""https://github.com/s-enmt/DynTTA"" target=""_blank"">s-enmt</a>",2025-12-03 22:39:25
Untargeted Attack against Federated Recommendation Systems via Poisonous Item Embeddings and the Defense,"Yang Yu, Qi Liu, Likang Wu, Runlong Yu, Sanshi Lei Yu, Zaixi Zhang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.05399"" target=""_blank"">2212.05399</a>",,2025-12-03 22:39:25
DISCO: Adversarial Defense with Local Implicit Functions,"Chih-Hui Ho, Nuno Vasconcelos",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.05630"" target=""_blank"">2212.05630</a>",,2025-12-03 22:39:25
Spurious Features Everywhere -- Large-Scale Detection of Harmful Spurious Features in ImageNet,"Yannic Neuhaus, Maximilian Augustin, Valentyn Boreiko, Matthias Hein",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.04871"" target=""_blank"">2212.04871</a>","<a href=""https://github.com/YanNeu/spurious_imagenet"" target=""_blank"">YanNeu</a>",2025-12-03 22:39:25
REAP: A Large-Scale Realistic Adversarial Patch Benchmark,"Nabeel Hingun, Chawin Sitawarin, Jerry Li, David Wagner",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.05680"" target=""_blank"">2212.05680</a>","<a href=""https://github.com/wagner-group/reap-benchmark"" target=""_blank"">wagner-group</a>",2025-12-03 22:39:25
General Adversarial Defense Against Black-box Attacks via Pixel Level and Feature Level Distribution Alignments,"Xiaogang Xu, Hengshuang Zhao, Philip Torr, Jiaya Jia",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.05387"" target=""_blank"">2212.05387</a>",,2025-12-03 22:39:25
Mitigating Adversarial Gray-Box Attacks Against Phishing Detectors,"Giovanni Apruzzese, V. S. Subrahmanian",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.05380"" target=""_blank"">2212.05380</a>",,2025-12-03 22:39:25
Targeted Adversarial Attacks on Deep Reinforcement Learning Policies via Model Checking,"Dennis Gross, Thiago D. Simao, Nils Jansen, Guillermo A. Perez",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.05337"" target=""_blank"">2212.05337</a>",,2025-12-03 22:39:25
Expeditious Saliency-guided Mix-up through Random Gradient Thresholding,"Minh-Long Luu, Zeyi Huang, Eric P. Xing, Yong Jae Lee, Haohan Wang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.04875"" target=""_blank"">2212.04875</a>","<a href=""https://github.com/minhlong94/Random-Mixup]"" target=""_blank"">minhlong94</a>",2025-12-03 22:39:25
How to Backdoor Diffusion Models? (12%),"Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.05400"" target=""_blank"">2212.05400</a>","<a href=""https://github.com/IBM/BadDiffusion"" target=""_blank"">IBM</a>",2025-12-03 22:39:25
Identifying the Source of Vulnerability in Explanation Discrepancy: A Case Study in Neural Text Classification,"Ruixuan Tang, Hanjie Chen, Yangfeng Ji",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.05327"" target=""_blank"">2212.05327</a>",,2025-12-03 22:39:25
Carpet-bombing patch: attacking a deep network without usual requirements,"Pol Labarbarie, Adrien Chan-Hon-Tong, Stéphane Herbin, Milad Leyli-Abadi",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.05827"" target=""_blank"">2212.05827</a>",,2025-12-03 22:39:25
Understanding and Combating Robust Overfitting via Input Loss Landscape Analysis and Regularization,"Lin Li, Michael Spratling",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.04985"" target=""_blank"">2212.04985</a>","<a href=""https://github.com/TreeLLi/Combating-RO-AdvLC"" target=""_blank"">TreeLLi</a>",2025-12-03 22:39:25
Numerical Stability of DeepGOPlus Inference,"Inés Gonzalez Pepe, Yohan Chatelain, Gregory Kiar, Tristan Glatard",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.06361"" target=""_blank"">2212.06361</a>",,2025-12-03 22:39:25
Adversarially Robust Video Perception by Seeing Motion,"Lingyu Zhang, Chengzhi Mao, Junfeng Yang, Carl Vondrick",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.07815"" target=""_blank"">2212.07815</a>",,2025-12-03 22:39:25
AFLGuard: Byzantine-robust Asynchronous Federated Learning,"Minghong Fang, Jia Liu, Neil Zhenqiang Gong, Elizabeth S. Bentley",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.06325"" target=""_blank"">2212.06325</a>",,2025-12-03 22:39:25
"Despite ""super-human"" performance, current LLMs are unsuited for decisions about ethics and safety","Joshua Albrecht, Ellie Kitanidis, Abraham J. Fetterman",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.06295"" target=""_blank"">2212.06295</a>",,2025-12-03 22:39:25
Robust Perception through Equivariance,"Chengzhi Mao, Lingyu Zhang, Abhishek Joshi, Junfeng Yang, Hao Wang, Carl Vondrick",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.06079"" target=""_blank"">2212.06079</a>",,2025-12-03 22:39:25
HOTCOLD Block: Fooling Thermal Infrared Detectors with a Novel Wearable Design,"Hui Wei, Zhixiang Wang, Xuemei Jia, Yinqiang Zheng, Hao Tang, Shin'ichi Satoh, Zheng Wang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.05709"" target=""_blank"">2212.05709</a>","<a href=""https://github.com/weihui1308/HOTCOLDBlock"" target=""_blank"">weihui1308</a>",2025-12-03 22:39:25
SRoUDA: Meta Self-training for Robust Unsupervised Domain Adaptation,"Wanqing Zhu, Jia-Li Yin, Bo-Hao Chen, Ximeng Liu",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.05917"" target=""_blank"">2212.05917</a>","<a href=""https://github.com/Vision"" target=""_blank"">github.com</a>",2025-12-03 22:39:25
Boosting Semi-Supervised Learning with Contrastive Complementary Labeling,"Qinyi Deng, Yong Guo, Zhibang Yang, Haolin Pan, Jian Chen",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.06643"" target=""_blank"">2212.06643</a>",,2025-12-03 22:39:25
Privacy-preserving Security Inference Towards Cloud-Edge Collaborative Using Differential Privacy,"Yulong Wang, Xingshu Chen, Qixu Wang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.06428"" target=""_blank"">2212.06428</a>",,2025-12-03 22:39:25
AdvCat: Domain-Agnostic Robustness Assessment for Cybersecurity-Critical Applications with Categorical Inputs,"Helene Orsini, Hongyan Bao, Yujun Zhou, Xiangrui Xu, Yufei Han, Longyang Yi, Wei Wang, Xin Gao, Xiangliang Zhang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.13989"" target=""_blank"">2212.13989</a>",,2025-12-03 22:39:25
Pixel is All You Need: Adversarial Trajectory-Ensemble Active Learning for Salient Object Detection,"Zhenyu Wu, Lin Wang, Wei Wang, Qing Xia, Chenglizhao Chen, Aimin Hao, Shuo Li",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.06493"" target=""_blank"">2212.06493</a>",,2025-12-03 22:39:25
Understanding Zero-Shot Adversarial Robustness for Large-Scale Models,"Chengzhi Mao, Scott Geng, Junfeng Yang, Xin Wang, Carl Vondrick",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.07016"" target=""_blank"">2212.07016</a>",,2025-12-03 22:39:25
Towards Efficient and Domain-Agnostic Evasion Attack with High-dimensional Categorical Inputs,"Hongyan Bao, Yufei Han, Yujun Zhou, Xin Gao, Xiangliang Zhang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.06836"" target=""_blank"">2212.06836</a>",,2025-12-03 22:39:25
Unfolding Local Growth Rate Estimates for (Almost) Perfect Adversarial Detection,"Peter Lorenz, Margret Keuper, Janis Keuper",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.06776"" target=""_blank"">2212.06776</a>","<a href=""https://github.com/adverML/multiLID"" target=""_blank"">adverML</a>",2025-12-03 22:39:25
Adversarial Attacks and Defences for Skin Cancer Classification,"Vinay Jogani, Joy Purohit, Ishaan Shivhare, Samina Attari, Shraddha Surtkar",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.06822"" target=""_blank"">2212.06822</a>",,2025-12-03 22:39:25
DOC-NAD: A Hybrid Deep One-class Classifier for Network Anomaly Detection,"Mohanad Sarhan, Gayan Kulatilleke, Wai Weng Lo, Siamak Layeghy, Marius Portmann",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.07558"" target=""_blank"">2212.07558</a>",,2025-12-03 22:39:25
Robustness Implies Privacy in Statistical Estimation,"Samuel B. Hopkins, Gautam Kamath, Mahbod Majid, Shyam Narayanan",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.05015"" target=""_blank"">2212.05015</a>",,2025-12-03 22:39:25
Generalizing and Improving Jacobian and Hessian Regularization,"Chenwei Cui, Zehao Yan, Guangshen Liu, Liangfu Lu",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.00311"" target=""_blank"">2212.00311</a>",,2025-12-03 22:39:25
QVIP: An ILP-based Formal Verification Approach for Quantized Neural Networks,"Yedi Zhang, Zhe Zhao, Fu Song, Min Zhang, Taolue Chen, Jun Sun",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.11138"" target=""_blank"">2212.11138</a>",,2025-12-03 22:39:25
Targeted Adversarial Attacks against Neural Network Trajectory Predictors,"Kaiyuan Tan, Jun Wang, Yiannis Kantaros",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.04138"" target=""_blank"">2212.04138</a>",,2025-12-03 22:39:25
Adversarial Artifact Detection in EEG-Based Brain-Computer Interfaces,"Xiaoqing Chen, Dongrui Wu",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.00727"" target=""_blank"">2212.00727</a>",,2025-12-03 22:39:25
Interpretation of Neural Networks is Susceptible to Universal Adversarial Perturbations,"Haniyeh Ehsani Oskouie, Farzan Farnia",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.03095"" target=""_blank"">2212.03095</a>",,2025-12-03 22:39:25
SimpleMind adds thinking to deep neural networks,"Youngwon Choi, M. Wasil Wahi-Anwar, Matthew S. Brown",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.00951"" target=""_blank"">2212.00951</a>",,2025-12-03 22:39:25
On the Limit of Explaining Black-box Temporal Graph Neural Networks,"Minh N. Vu, My T. Thai",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.00952"" target=""_blank"">2212.00952</a>",,2025-12-03 22:39:25
All You Need Is Hashing: Defending Against Data Reconstruction Attack in Vertical Federated Learning,"Pengyu Qiu, Xuhong Zhang, Shouling Ji, Yuwen Pu, Ting Wang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.00325"" target=""_blank"">2212.00325</a>",,2025-12-03 22:39:25
Pareto Regret Analyses in Multi-objective Multi-armed Bandit,"Mengfan Xu, Diego Klabjan",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.00884"" target=""_blank"">2212.00884</a>",,2025-12-03 22:39:25
Purifier: Defending Data Inference Attacks via Transforming Confidence Scores,"Ziqi Yang, Lijin Wang, Da Yang, Jie Wan, Ziming Zhao, Ee-Chien Chang, Fan Zhang, Kui Ren",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.00612"" target=""_blank"">2212.00612</a>",,2025-12-03 22:39:25
Guaranteed Conformance of Neurosymbolic Models to Natural Constraints,"Kaustubh Sridhar, Souradeep Dutta, James Weimer, Insup Lee",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.01346"" target=""_blank"">2212.01346</a>",,2025-12-03 22:39:25
Membership Inference Attacks Against Semantic Segmentation Models,"Tomas Chobola, Dmitrii Usynin, Georgios Kaissis",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.01082"" target=""_blank"">2212.01082</a>",,2025-12-03 22:39:25
Security Analysis of SplitFed Learning,"Momin Ahmad Khan, Virat Shejwalkar, Amir Houmansadr, Fatima Muhammad Anwar",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.01716"" target=""_blank"">2212.01716</a>",,2025-12-03 22:39:25
LDL: A Defense for Label-Based Membership Inference Attacks,"Arezoo Rajabi, Dinuka Sahabandu, Luyao Niu, Bhaskar Ramasubramanian, Radha Poovendran",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.01688"" target=""_blank"">2212.01688</a>",,2025-12-03 22:39:25
ConfounderGAN: Protecting Image Data Privacy with Causal Confounder,"Qi Tian, Kun Kuang, Kelu Jiang, Furui Liu, Zhihua Wang, Fei Wu",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.01767"" target=""_blank"">2212.01767</a>",,2025-12-03 22:39:25
FedCC: Robust Federated Learning against Model Poisoning Attacks,"Hyejun Jeong, Hamin Son, Seohu Lee, Jayun Hyun, Tai-Myoung Chung",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.01976"" target=""_blank"">2212.01976</a>",,2025-12-03 22:39:25
CSTAR: Towards Compact and STructured Deep Neural Networks with Adversarial Robustness,"Huy Phan, Miao Yin, Yang Sui, Bo Yuan, Saman Zonouz",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.01957"" target=""_blank"">2212.01957</a>",,2025-12-03 22:39:25
Recognizing Object by Components with Human Prior Knowledge Enhances Adversarial Robustness of Deep Neural Networks,"Xiao Li, Ziqi Wang, Bo Zhang, Fuchun Sun, Xiaolin Hu",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.01806"" target=""_blank"">2212.01806</a>",,2025-12-03 22:39:25
Bayesian Learning with Information Gain Provably Bounds Risk for a Robust Adversarial Defense,"Bao Gia Doan, Ehsan Abbasnejad, Javen Qinfeng Shi, Damith C. Ranasinghe",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.02003"" target=""_blank"">2212.02003</a>",,2025-12-03 22:39:25
Efficient Malware Analysis Using Metric Embeddings,"Ethan M. Rudd, David Krisiloff, Scott Coull, Daniel Olszewski, Edward Raff, James Holt",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.02663"" target=""_blank"">2212.02663</a>",,2025-12-03 22:39:25
Spuriosity Rankings: Sorting Data for Spurious Correlation Robustness,"Mazda Moayeri, Wenxiao Wang, Sahil Singla, Soheil Feizi",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.02648"" target=""_blank"">2212.02648</a>",,2025-12-03 22:39:25
What is the Solution for State-Adversarial Multi-Agent Reinforcement Learning? (3%),"Songyang Han, Sanbao Su, Sihong He, Shuo Han, Haizhao Yang, Fei Miao",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.02705"" target=""_blank"">2212.02705</a>",,2025-12-03 22:39:25
"Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics, Directional Convergence, and Equilibria",Tengyuan Liang,arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.02457"" target=""_blank"">2212.02457</a>",,2025-12-03 22:39:25
Refiner: Data Refining against Gradient Leakage Attacks in Federated Learning,"Mingyuan Fan, Cen Chen, Chengyu Wang, Xiaodan Li, Wenmeng Zhou",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.02042"" target=""_blank"">2212.02042</a>",,2025-12-03 22:39:25
FaceQAN: Face Image Quality Assessment Through Adversarial Noise Exploration,"Žiga Babnik, Peter Peer, Vitomir Štruc",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.02127"" target=""_blank"">2212.02127</a>",,2025-12-03 22:39:25
Multiple Perturbation Attack: Attack Pixelwise Under Different $\ell_p$-norms For Better Adversarial Performance,"Ngoc N. Tran, Anh Tuan Bui, Dinh Phung, Trung Le",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.03069"" target=""_blank"">2212.03069</a>",,2025-12-03 22:39:25
Enhancing Quantum Adversarial Robustness by Randomized Encodings,"Weiyuan Gong, Dong Yuan, Weikang Li, Dong-Ling Deng",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.02531"" target=""_blank"">2212.02531</a>",,2025-12-03 22:39:25
Pre-trained Encoders in Self-Supervised Learning Improve Secure and Privacy-preserving Supervised Learning,"Hongbin Liu, Wenjie Qu, Jinyuan Jia, Neil Zhenqiang Gong",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.03334"" target=""_blank"">2212.03334</a>",,2025-12-03 22:39:25
Use of Cryptography in Malware Obfuscation,"Hassan Jameel Asghar, Benjamin Zi Hao Zhao, Muhammad Ikram, Giang Nguyen, Dali Kaafar, Sean Lamont, Daniel Coscia",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.04008"" target=""_blank"">2212.04008</a>",,2025-12-03 22:39:25
Multi-Objective Linear Ensembles for Robust and Sparse Training of Few-Bit Neural Networks,"Ambrogio Maria Bernardelli, Stefano Gualandi, Hoong Chuin Lau, Simone Milanesi, Neil Yorke-Smith",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.03659"" target=""_blank"">2212.03659</a>",,2025-12-03 22:39:25
Robust Graph Representation Learning via Predictive Coding,"Billy Byiringiro, Tommaso Salvatori, Thomas Lukasiewicz",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.04656"" target=""_blank"">2212.04656</a>",,2025-12-03 22:39:25
XRand: Differentially Private Defense against Explanation-Guided Attacks,"Truc Nguyen, Phung Lai, NhatHai Phan, My T. Thai",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.04454"" target=""_blank"">2212.04454</a>",,2025-12-03 22:39:25
Object-fabrication Targeted Attack for Object Detection,"Xuchong Zhang, Changfeng Sun, Haoliang Han, Hongbin Sun",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.06431"" target=""_blank"">2212.06431</a>",,2025-12-03 22:39:25
"Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of Backdoor Effects in Trojaned Machine Learning Models","Rui Zhu, Di Tang, Siyuan Tang, XiaoFeng Wang, Haixu Tang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.04687"" target=""_blank"">2212.04687</a>",,2025-12-03 22:39:25
Synthesis of Adversarial DDOS Attacks Using Tabular Generative Adversarial Networks,"Abdelmageed Ahmed Hassan, Mohamed Sayed Hussein, Ahmed Shehata AboMoustafa, Sarah Hossam Elmowafy",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.14109"" target=""_blank"">2212.14109</a>",,2025-12-03 22:39:25
Learned Systems Security,"Roei Schuster, Jin Peng Zhou, Paul Grubbs, Thorsten Eisenhofer, Nicolas Papernot",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.10318"" target=""_blank"">2212.10318</a>",,2025-12-03 22:39:25
Is Semantic Communications Secure? A Tale of Multi-Domain Adversarial Attacks,"Yalin E. Sagduyu, Tugba Erpek, Sennur Ulukus, Aylin Yener",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.10438"" target=""_blank"">2212.10438</a>",,2025-12-03 22:39:25
In and Out-of-Domain Text Adversarial Robustness via Label Smoothing,"Yahan Yang, Soham Dan, Dan Roth, Insup Lee",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.10258"" target=""_blank"">2212.10258</a>",,2025-12-03 22:39:25
Multi-head Uncertainty Inference for Adversarial Attack Detection,"Yuqi Yang, Songyun Yang, Jiyang Xie. Zhongwei Si, Kai Guo, Ke Zhang, Kongming Liang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.10006"" target=""_blank"">2212.10006</a>",,2025-12-03 22:39:25
A Comprehensive Study and Comparison of the Robustness of 3D Object Detectors Against Adversarial Attacks,"Yifan Zhang, Junhui Hou, Yixuan Yuan",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.10230"" target=""_blank"">2212.10230</a>",,2025-12-03 22:39:25
A Theoretical Study of The Effects of Adversarial Attacks on Sparse Regression,"Deepak Maurya, Jean Honorio",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.11209"" target=""_blank"">2212.11209</a>",,2025-12-03 22:39:25
Vulnerabilities of Deep Learning-Driven Semantic Communications to Backdoor (Trojan) Attacks,"Yalin E. Sagduyu, Tugba Erpek, Sennur Ulukus, Aylin Yener",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.11205"" target=""_blank"">2212.11205</a>",,2025-12-03 22:39:25
Revisiting Residual Networks for Adversarial Robustness: An Architectural Perspective,"Shihua Huang, Zhichao Lu, Kalyanmoy Deb, Vishnu Naresh Boddeti",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.11005"" target=""_blank"">2212.11005</a>","<a href=""https://github.com/zhichao-lu/robust-residual-network"" target=""_blank"">zhichao-lu</a>",2025-12-03 22:39:25
Hybrid Quantum-Classical Generative Adversarial Network for High Resolution Image Generation,"Shu Lok Tsang, Maxwell T. West, Sarah M. Erfani, Muhammad Usman",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.11614"" target=""_blank"">2212.11614</a>",,2025-12-03 22:39:25
GAN-based Domain Inference Attack,"Yuechun Gu, Keke Chen",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.11810"" target=""_blank"">2212.11810</a>",,2025-12-03 22:39:25
Aliasing is a Driver of Adversarial Attacks,"Adrián Rodríguez-Muñoz, Antonio Torralba",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.11760"" target=""_blank"">2212.11760</a>",,2025-12-03 22:39:25
Adversarial Machine Learning and Defense Game for NextG Signal Classification with Deep Learning,Yalin E. Sagduyu,arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.11778"" target=""_blank"">2212.11778</a>",,2025-12-03 22:39:25
Towards Scalable Physically Consistent Neural Networks: an Application to Data-driven Multi-zone Thermal Building Models,"Natale Loris Di, Bratislav Svetozarevic, Philipp Heer, Colin Neil Jones",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.12380"" target=""_blank"">2212.12380</a>",,2025-12-03 22:39:25
Out-of-Distribution Detection with Reconstruction Error and Typicality-based Penalty,"Genki Osada, Takahashi Tsubasa, Budrul Ahsan, Takashi Nishide",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.12641"" target=""_blank"">2212.12641</a>",,2025-12-03 22:39:25
Frequency Regularization for Improving Adversarial Robustness,"Binxiao Huang, Chaofan Tao, Rui Lin, Ngai Wong",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.12732"" target=""_blank"">2212.12732</a>",,2025-12-03 22:39:25
Simultaneously Optimizing Perturbations and Positions for Black-box Adversarial Patch Attacks,"Xingxing Wei, Ying Guo, Jie Yu, Bo Zhang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.12995"" target=""_blank"">2212.12995</a>",,2025-12-03 22:39:25
XMAM:X-raying Models with A Matrix to Reveal Backdoor Attacks for Federated Learning,"Jianyi Zhang, Fangjiao Zhang, Qichao Jin, Zhiqiang Wang, Xiaodong Lin, Xiali Hei",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.13675"" target=""_blank"">2212.13675</a>",,2025-12-03 22:39:25
Learning When to Use Adaptive Adversarial Image Perturbations against Autonomous Vehicles,"Hyung-Jin Yoon, Hamidreza Jafarnejadsani, Petros Voulgaris",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.13667"" target=""_blank"">2212.13667</a>",,2025-12-03 22:39:25
EDoG: Adversarial Edge Detection For Graph Neural Networks,"Xiaojun Xu, Yue Yu, Hanzhang Wang, Alok Lal, Carl A. Gunter, Bo Li",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.13607"" target=""_blank"">2212.13607</a>",,2025-12-03 22:39:25
Evaluating Generalizability of Deep Learning Models Using Indian-COVID-19 CT Dataset,"Suba S, Nita Parekh, Ramesh Loganathan, Vikram Pudi, Chinnababu Sunkavalli",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.13929"" target=""_blank"">2212.13929</a>","<a href=""https://github.com/aleesuss/c19"" target=""_blank"">aleesuss</a>",2025-12-03 22:39:25
Robust Ranking Explanations,"Chao Chen, Chenghua Guo, Guixiang Ma, Xi Zhang, Sihong Xie",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.14106"" target=""_blank"">2212.14106</a>",,2025-12-03 22:39:25
Differentiable Search of Accurate and Robust Architectures,"Yuwei Ou, Xiangning Xie, Shangce Gao, Yanan Sun, Kay Chen Tan, Jiancheng Lv",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.14049"" target=""_blank"">2212.14049</a>",,2025-12-03 22:39:25
Certifying Safety in Reinforcement Learning under Adversarial Perturbation Attacks,"Junlin Wu, Hussein Sibai, Yevgeniy Vorobeychik",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.14115"" target=""_blank"">2212.14115</a>",,2025-12-03 22:39:25
Thermal Heating in ReRAM Crossbar Arrays: Challenges and Solutions,"Kamilya Smagulova, Mohammed E. Fouda, Ahmed Eltawil",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.13707"" target=""_blank"">2212.13707</a>",,2025-12-03 22:39:25
Detection of out-of-distribution samples using binary neuron activation patterns,"Bartlomiej Olber, Krystian Radlak, Adam Popowicz, Michal Szczepankiewicz, Krystian Chachula",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.14268"" target=""_blank"">2212.14268</a>",,2025-12-03 22:39:25
"""Real Attackers Don't Compute Gradients"": Bridging the Gap Between Adversarial ML Research and Practice","Giovanni Apruzzese, Hyrum S. Anderson, Savino Dambra, David Freeman, Fabio Pierazzi, Kevin A. Roundy",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.14315"" target=""_blank"">2212.14315</a>",,2025-12-03 22:39:25
Adversarial attacks and defenses on ML- and hardware-based IoT device fingerprinting and identification,"Pedro Miguel Sánchez Sánchez, Alberto Huertas Celdrán, Gérôme Bovet, Gregorio Martínez Pérez",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.14677"" target=""_blank"">2212.14677</a>",,2025-12-03 22:39:25
Defense Against Adversarial Attacks on Audio DeepFake Detection,"Piotr Kawa, Marcin Plata, Piotr Syga",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.14597"" target=""_blank"">2212.14597</a>",,2025-12-03 22:39:25
Generative Robust Classification,Xuwang Yin,arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.07283"" target=""_blank"">2212.07283</a>",,2025-12-03 22:39:25
Guidance Through Surrogate: Towards a Generic Diagnostic Attack,"Muzammal Naseer, Salman Khan, Fatih Porikli, Fahad Shahbaz Khan",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.14875"" target=""_blank"">2212.14875</a>",,2025-12-03 22:39:25
Unleashing the Power of Visual Prompting At the Pixel Level,"Junyang Wu, Xianhang Li, Chen Wei, Huiyu Wang, Alan Yuille, Yuyin Zhou, Cihang Xie",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.10556"" target=""_blank"">2212.10556</a>","<a href=""https://github.com/UCSC-VLAA/EVP"" target=""_blank"">UCSC-VLAA</a>",2025-12-03 22:39:25
Publishing Efficient On-device Models Increases Adversarial Vulnerability,"Sanghyun Hong, Nicholas Carlini, Alexey Kurakin",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.13700"" target=""_blank"">2212.13700</a>",,2025-12-03 22:39:25
Hidden Poison: Machine Unlearning Enables Camouflaged Poisoning Attacks,"Jimmy Z. Di, Jack Douglas, Jayadev Acharya, Gautam Kamath, Ayush Sekhari",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.10717"" target=""_blank"">2212.10717</a>",,2025-12-03 22:39:25
"A Review of Speech-centric Trustworthy Machine Learning: Privacy, Safety, and Fairness","Tiantian Feng, Rajat Hebbar, Nicholas Mehlman, Xuan Shi, Aditya Kommineni, and Shrikanth Narayanan",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.09006"" target=""_blank"">2212.09006</a>",,2025-12-03 22:39:25
Dissecting Distribution Inference,"Anshuman Suri, Yifu Lu, Yanjin Chen, David Evans",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.07591"" target=""_blank"">2212.07591</a>","<a href=""https://github.com/iamgroot42/dissecting_distribution_inference"" target=""_blank"">iamgroot42</a>",2025-12-03 22:39:25
ReCode: Robustness Evaluation of Code Generation Models,"Shiqi Wang, Zheng Li, Haifeng Qian, Chenghao Yang, Zijian Wang, Mingyue Shang, Varun Kumar, Samson Tan, Baishakhi Ray, Parminder Bhatia, Ramesh Nallapati, Murali Krishna Ramanathan, Dan Roth, Bing Xiang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.10264"" target=""_blank"">2212.10264</a>",,2025-12-03 22:39:25
SAIF: Sparse Adversarial and Interpretable Attack Framework,"Tooba Imtiaz, Morgan Kohler, Jared Miller, Zifeng Wang, Mario Sznaier, Octavia Camps, Jennifer Dy",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.07495"" target=""_blank"">2212.07495</a>",,2025-12-03 22:39:25
Defending against cybersecurity threats to the payments and banking system,"Williams Haruna, Toyin Ajiboro Aremu, Yetunde Ajao Modupe",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.12307"" target=""_blank"">2212.12307</a>",,2025-12-03 22:39:25
Holistic risk assessment of inference attacks in machine learning,Yang Yang,arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.10628"" target=""_blank"">2212.10628</a>",,2025-12-03 22:39:25
On Evaluating Adversarial Robustness of Chest X-ray Classification: Pitfalls and Best Practices,"Salah Ghamizi, Maxime Cordy, Michail Papadakis, Yves Le Traon",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.08130"" target=""_blank"">2212.08130</a>",,2025-12-03 22:39:25
Alternating Objectives Generates Stronger PGD-Based Adversarial Attacks,"Nikolaos Antoniou, Efthymios Georgiou, Alexandros Potamianos",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.07992"" target=""_blank"">2212.07992</a>",,2025-12-03 22:39:25
On Human Visual Contrast Sensitivity and Machine Vision Robustness: A Comparative Study,"Ming-Chang Chiu, Yingfei Wang, Derrick Eui Gyu Kim, Pin-Yu Chen, Xuezhe Ma",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.08650"" target=""_blank"">2212.08650</a>",,2025-12-03 22:39:25
Better May Not Be Fairer: Can Data Augmentation Mitigate Subgroup Degradation? (1%),"Ming-Chang Chiu, Pin-Yu Chen, Xuezhe Ma",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.08649"" target=""_blank"">2212.08649</a>",,2025-12-03 22:39:25
Biomedical image analysis competitions: The state of current participation practice,"Matthias Eisenmann, Annika Reinke, Vivienn Weru, Minu Dietlinde Tizabi, Fabian Isensee, Tim J. Adler, Patrick Godau, Veronika Cheplygina, Michal Kozubek, Sharib Ali, Anubha Gupta, Jan Kybic, Alison Noble, Solórzano Carlos Ortiz de, Samiksha Pachade, Caroline Petitjean, Daniel Sage, Donglai Wei, Elizabeth Wilden, Deepak Alapatt, Vincent Andrearczyk, Ujjwal Baid, Spyridon Bakas, Niranjan Balu, Sophia Bano, Vivek Singh Bawa, Jorge Bernal, Sebastian Bodenstedt, Alessandro Casella, Jinwook Choi, Olivier Commowick, Marie Daum, Adrien Depeursinge, Reuben Dorent, Jan Egger, Hannah Eichhorn, Sandy Engelhardt, Melanie Ganz, Gabriel Girard, Lasse Hansen, Mattias Heinrich, Nicholas Heller, Alessa Hering, Arnaud Huaulmé, Hyunjeong Kim, Bennett Landman, Hongwei Bran Li, Jianning Li, Jun Ma, Anne Martel, Carlos Martín-Isla, Bjoern Menze, Chinedu Innocent Nwoye, Valentin Oreiller, Nicolas Padoy, Sarthak Pati, Kelly Payette, Carole Sudre, Wijnen Kimberlin van, Armine Vardazaryan, Tom Vercauteren, Martin Wagner, Chuanbo Wang, Moi Hoon Yap, Zeyun Yu, Chun Yuan, Maximilian Zenk, Aneeq Zia, David Zimmerer, Rina Bao, Chanyeol Choi, Andrew Cohen, Oleh Dzyubachyk, Adrian Galdran, Tianyuan Gan, Tianqi Guo, Pradyumna Gupta, Mahmood Haithami, Edward Ho, Ikbeom Jang, Zhili Li, Zhengbo Luo, Filip Lux, Sokratis Makrogiannis, Dominik Müller, Young-tack Oh, Subeen Pang, Constantin Pape, Gorkem Polat, Charlotte Rosalie Reed, Kanghyun Ryu, Tim Scherr, Vajira Thambawita, Haoyu Wang, Xinliang Wang, Kele Xu, Hung Yeh, Doyeob Yeo, Yixuan Yuan, Yan Zeng, Xin Zhao, Julian Abbing, Jannes Adam, Nagesh Adluru, Niklas Agethen, Salman Ahmed, Yasmina Al Khalil, Mireia Alenyà, Esa Alhoniemi, Chengyang An, Talha Anwar, Tewodros Weldebirhan Arega, Netanell Avisdris, Dogu Baran Aydogan, Yingbin Bai, Maria Baldeon Calisto, Berke Doga Basaran, Marcel Beetz, Cheng Bian, Hao Bian, Kevin Blansit, Louise Bloch, Robert Bohnsack, Sara Bosticardo, Jack Breen, Mikael Brudfors, Raphael Brüngel, Mariano Cabezas, Alberto Cacciola, Zhiwei Chen, Yucong Chen, Daniel Tianming Chen, Minjeong Cho, Min-Kook Choi, Chuantao Xie Chuantao Xie, Dana Cobzas, Julien Cohen-Adad, Jorge Corral Acero, Sujit Kumar Das, Oliveira Marcela de, Hanqiu Deng, Guiming Dong, Lars Doorenbos, Cory Efird, Di Fan, Mehdi Fatan Serj, Alexandre Fenneteau, Lucas Fidon, Patryk Filipiak, René Finzel, Nuno R. Freitas, Christoph M. Friedrich, Mitchell Fulton, Finn Gaida, Francesco Galati, Christoforos Galazis, Chang Hee Gan, Zheyao Gao, Shengbo Gao, Matej Gazda, Beerend Gerats, Neil Getty, Adam Gibicar, Ryan Gifford, Sajan Gohil, Maria Grammatikopoulou, Daniel Grzech, Orhun Güley, Timo Günnemann, Chunxu Guo, Sylvain Guy, Heonjin Ha, Luyi Han, Il Song Han, Ali Hatamizadeh, Tian He, Jimin Heo, Sebastian Hitziger, SeulGi Hong, SeungBum Hong, Rian Huang, Ziyan Huang, Markus Huellebrand, Stephan Huschauer, Mustaffa Hussain, Tomoo Inubushi, Ece Isik Polat, Mojtaba Jafaritadi, SeongHun Jeong, Bailiang Jian, Yuanhong Jiang, Zhifan Jiang, Yueming Jin, Smriti Joshi, Abdolrahim Kadkhodamohammadi, Reda Abdellah Kamraoui, Inha Kang, Junghwa Kang, Davood Karimi, April Khademi, Muhammad Irfan Khan, Suleiman A. Khan, Rishab Khantwal, Kwang-Ju Kim, Timothy Kline, Satoshi Kondo, Elina Kontio, Adrian Krenzer, Artem Kroviakov, Hugo Kuijf, Satyadwyoom Kumar, Rosa Francesco La, Abhi Lad, Doohee Lee, Minho Lee, Chiara Lena, Hao Li, Ling Li, Xingyu Li, Fuyuan Liao, KuanLun Liao, Arlindo Limede Oliveira, Chaonan Lin, Shan Lin, Akis Linardos, Marius George Linguraru, Han Liu, Tao Liu, Di Liu, Yanling Liu, João Lourenço-Silva, Jingpei Lu, Jiangshan Lu, Imanol Luengo, Christina B. Lund, Huan Minh Luu, Yi Lv, Yi Lv, Uzay Macar, Leon Maechler, Sina Mansour L., Kenji Marshall, Moona Mazher, Richard McKinley, Alfonso Medela, Felix Meissen, Mingyuan Meng, Dylan Miller, Seyed Hossein Mirjahanmardi, Arnab Mishra, Samir Mitha, Hassan Mohy-ud-Din, Tony Chi Wing Mok, Gowtham Krishnan Murugesan, Enamundram Naga Karthik, Sahil Nalawade, Jakub Nalepa, Mohamed Naser, Ramin Nateghi, Hammad Naveed, Quang-Minh Nguyen, Cuong Nguyen Quoc, Brennan Nichyporuk, Bruno Oliveira, David Owen, Jimut Bahan Pal, Junwen Pan, Wentao Pan, Winnie Pang, Bogyu Park, Vivek Pawar, Kamlesh Pawar, Michael Peven, Lena Philipp, Tomasz Pieciak, Szymon Plotka, Marcel Plutat, Fattaneh Pourakpour, Domen Preložnik, Kumaradevan Punithakumar, Abdul Qayyum, Sandro Queirós, Arman Rahmim, Salar Razavi, Jintao Ren, Mina Rezaei, Jonathan Adam Rico, ZunHyan Rieu, Markus Rink, Johannes Roth, Yusely Ruiz-Gonzalez, Numan Saeed, Anindo Saha, Mostafa Salem, Ricardo Sanchez-Matilla, Kurt Schilling, Wei Shao, Zhiqiang Shen, Ruize Shi, Pengcheng Shi, Daniel Sobotka, Théodore Soulier, Bella Specktor Fadida, Danail Stoyanov, Timothy Sum Hon Mun, Xiaowu Sun, Rong Tao, Franz Thaler, Antoine Théberge, Felix Thielke, Helena Torres, Kareem A. Wahid, Jiacheng Wang, YiFei Wang, Wei Wang, Xiong Wang, Jianhui Wen, Ning Wen, Marek Wodzinski, Ye Wu, Fangfang Xia, Tianqi Xiang, Chen Xiaofei, Lizhan Xu, Tingting Xue, Yuxuan Yang, Lin Yang, Kai Yao, Huifeng Yao, Amirsaeed Yazdani, Michael Yip, Hwanseung Yoo, Fereshteh Yousefirizi, Shunkai Yu, Lei Yu, Jonathan Zamora, Ramy Ashraf Zeineldin, Dewen Zeng, Jianpeng Zhang, Bokai Zhang, Jiapeng Zhang, Fan Zhang, Huahong Zhang, Zhongchen Zhao, Zixuan Zhao, Jiachen Zhao, Can Zhao, Qingshuo Zheng, Yuheng Zhi, Ziqi Zhou, Baosheng Zou, Klaus Maier-Hein, Paul F. Jäger, Annette Kopp-Schneider, Lena Maier-Hein",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.08568"" target=""_blank"">2212.08568</a>",,2025-12-03 22:39:25
WebAssembly Diversification for Malware Evasion,"Javier Cabrera-Arteaga, Martin Monperrus, Tim Toady, Benoit Baudry",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.08427"" target=""_blank"">2212.08427</a>",,2025-12-03 22:39:25
Adversarial Example Defense via Perturbation Grading Strategy,"Shaowei Zhu, Wanli Lyu, Bin Li, Zhaoxia Yin, Bin Luo",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.08341"" target=""_blank"">2212.08341</a>",,2025-12-03 22:39:25
HyPe: Better Pre-trained Language Model Fine-tuning with Hidden Representation Perturbation,"Hongyi Yuan, Zheng Yuan, Chuanqi Tan, Fei Huang, Songfang Huang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.08853"" target=""_blank"">2212.08853</a>",,2025-12-03 22:39:25
Are Multimodal Models Robust to Image and Text Perturbations? (5%),"Jielin Qiu, Yi Zhu, Xingjian Shi, Florian Wenzel, Zhiqiang Tang, Ding Zhao, Bo Li, Mu Li",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.08044"" target=""_blank"">2212.08044</a>",,2025-12-03 22:39:25
Confidence-aware Training of Smoothed Classifiers for Certified Robustness,"Jongheon Jeong, Seojin Kim, Jinwoo Shin",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.09000"" target=""_blank"">2212.09000</a>",,2025-12-03 22:39:25
AI Security for Geoscience and Remote Sensing: Challenges and Future Trends,"Yonghao Xu, Tao Bai, Weikang Yu, Shizhen Chang, Peter M. Atkinson, Pedram Ghamisi",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.09360"" target=""_blank"">2212.09360</a>",,2025-12-03 22:39:25
SoK: Analysis of Root Causes and Defense Strategies for Attacks on Microarchitectural Optimizations,"Nadja Ramhöj Holtryd, Madhavan Manivannan, Per Stenström",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.10221"" target=""_blank"">2212.10221</a>",,2025-12-03 22:39:25
Fine-Tuning Is All You Need to Mitigate Backdoor Attacks,"Zeyang Sha, Xinlei He, Pascal Berrang, Mathias Humbert, Yang Zhang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.09067"" target=""_blank"">2212.09067</a>",,2025-12-03 22:39:25
Walking Noise: On Layer-Specific Robustness of Neural Architectures against Noisy Computations and Associated Characteristic Learning Dynamics,"Hendrik Borras, Bernhard Klein, Holger Fröning",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.10430"" target=""_blank"">2212.10430</a>",,2025-12-03 22:39:25
DISCO: Distilling Phrasal Counterfactuals with Large Language Models,"Zeming Chen, Qiyue Gao, Kyle Richardson, Antoine Bosselut, Ashish Sabharwal",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.10534"" target=""_blank"">2212.10534</a>",,2025-12-03 22:39:25
TextGrad: Advancing Robustness Evaluation in NLP by Gradient-Driven Optimization,"Bairu Hou, Jinghan Jia, Yihua Zhang, Guanhua Zhang, Yang Zhang, Sijia Liu, Shiyu Chang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.09254"" target=""_blank"">2212.09254</a>",,2025-12-03 22:39:25
Towards Robustness of Text-to-SQL Models Against Natural and Realistic Adversarial Table Perturbation,"Xinyu Pi, Bing Wang, Yan Gao, Jiaqi Guo, Zhoujun Li, Jian-Guang Lou",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.09994"" target=""_blank"">2212.09994</a>","<a href=""https://github.com/microsoft/ContextualSP"" target=""_blank"">microsoft</a>",2025-12-03 22:39:25
Defending Against Poisoning Attacks in Open-Domain Question Answering,"Orion Weller, Aleem Khan, Nathaniel Weir, Dawn Lawrie, Durme Benjamin Van",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.10002"" target=""_blank"">2212.10002</a>",,2025-12-03 22:39:25
Task-Oriented Communications for NextG: End-to-End Deep Learning and AI Security Aspects,"Yalin E. Sagduyu, Sennur Ulukus, Aylin Yener",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.09668"" target=""_blank"">2212.09668</a>",,2025-12-03 22:39:25
Flareon: Stealthy any2any Backdoor Injection via Poisoned Augmentation,"Tianrui Qin, Xianghuan He, Xitong Gao, Yiren Zhao, Kejiang Ye, Cheng-Zhong Xu",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.09979"" target=""_blank"">2212.09979</a>","<a href=""https://github.com/lafeat/flareon"" target=""_blank"">lafeat</a>",2025-12-03 22:39:25
Exploring Optimal Substructure for Out-of-distribution Generalization via Feature-targeted Model Pruning,"Yingchun Wang, Jingcai Guo, Song Guo, Weizhan Zhang, Jie Zhang",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.09458"" target=""_blank"">2212.09458</a>",,2025-12-03 22:39:25
Estimating the Adversarial Robustness of Attributions in Text with Transformers,"Adam Ivankay, Mattia Rigotti, Ivan Girardi, Chiara Marchiori, Pascal Frossard",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.09155"" target=""_blank"">2212.09155</a>",,2025-12-03 22:39:25
Minimizing Maximum Model Discrepancy for Transferable Black-box Targeted Attacks,"Anqi Zhao, Tong Chu, Yahao Liu, Wen Li, Jingjing Li, Lixin Duan",arXiv,2022-12,"<a href=""http://arxiv.org/abs/2212.09035"" target=""_blank"">2212.09035</a>",,2025-12-03 22:39:25
Generating Textual Adversaries with Minimal Perturbation,"Xingyi Zhao, Lu Zhang, Depeng Xu, Shuhan Yuan",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.06571"" target=""_blank"">2211.06571</a>",,2025-12-03 22:39:25
DriftRec: Adapting diffusion models to blind JPEG restoration,"Simon Welker, Henry N. Chapman, Timo Gerkmann",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.06757"" target=""_blank"">2211.06757</a>",,2025-12-03 22:39:25
Stay Home Safe with Starving Federated Data,"Jaechul Roh, Yajun Fang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.05410"" target=""_blank"">2211.05410</a>","<a href=""https://github.com/jcroh0508/FLATS"" target=""_blank"">jcroh0508</a>",2025-12-03 22:39:25
An investigation of security controls and MITRE ATT\&CK techniques,"Md Rayhanur Rahman, Laurie Williams",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.06500"" target=""_blank"">2211.06500</a>",,2025-12-03 22:39:25
Investigating co-occurrences of MITRE ATT\&CK Techniques,"Md Rayhanur Rahman, Laurie Williams",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.06495"" target=""_blank"">2211.06495</a>",,2025-12-03 22:39:25
Remapped Cache Layout: Thwarting Cache-Based Side-Channel Attacks with a Hardware Defense,"Wei Song, Rui Hou, Peng Liu, Xiaoxin Li, Peinan Li, Lutan Zhao, Xiaofei Fu, Yifei Sun, Dan Meng",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.06056"" target=""_blank"">2211.06056</a>",,2025-12-03 22:39:25
Test-time adversarial detection and robustness for localizing humans using ultra wide band channel impulse responses,"Abhiram Kolli, Muhammad Jehanzeb Mirza, Horst Possegger, Horst Bischof",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.05854"" target=""_blank"">2211.05854</a>",,2025-12-03 22:39:25
Impact of Adversarial Training on Robustness and Generalizability of Language Models,"Enes Altinisik, Hassan Sajjad, Husrev Taha Sencar, Safa Messaoud, Sanjay Chawla",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.05523"" target=""_blank"">2211.05523</a>",,2025-12-03 22:39:25
Privacy-Utility Balanced Voice De-Identification Using Adversarial Examples,"Meng Chen, Li Lu, Jiadi Yu, Yingying Chen, Zhongjie Ba, Feng Lin, Kui Ren",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.05446"" target=""_blank"">2211.05446</a>",,2025-12-03 22:39:25
On the robustness of non-intrusive speech quality model by adversarial examples,"Hsin-Yi Lin, Huan-Hsin Tseng, Yu Tsao",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.06508"" target=""_blank"">2211.06508</a>",,2025-12-03 22:39:25
QuerySnout: Automating the Discovery of Attribute Inference Attacks against Query-Based Systems,"Ana-Maria Cretu, Florimond Houssiau, Antoine Cully, Montjoye Yves-Alexandre de",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.05249"" target=""_blank"">2211.05249</a>",,2025-12-03 22:39:25
MSDT: Masked Language Model Scoring Defense in Text Domain,"Jaechul Roh, Minhao Cheng, Yajun Fang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.05371"" target=""_blank"">2211.05371</a>","<a href=""https://github.com/jcroh0508/MSDT"" target=""_blank"">jcroh0508</a>",2025-12-03 22:39:25
Robust DNN Surrogate Models with Uncertainty Quantification via Adversarial Training,"Lixiang Zhang, Jia Li",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09954"" target=""_blank"">2211.09954</a>",,2025-12-03 22:39:25
Mitigating Forgetting in Online Continual Learning via Contrasting Semantically Distinct Augmentations,"Sheng-Feng Yu, Wei-Chen Chiu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.05347"" target=""_blank"">2211.05347</a>",,2025-12-03 22:39:25
On the Robustness of Explanations of Deep Neural Network Models: A Survey,"Amlan Jyoti, Karthik Balaji Ganesh, Manoj Gayala, Nandita Lakshmi Tunuguntla, Sandesh Kamath, Vineeth N Balasubramanian",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.04780"" target=""_blank"">2211.04780</a>",,2025-12-03 22:39:25
Are All Edges Necessary? A Unified Framework for Graph Purification,"Zishan Gu, Jintang Li, Liang Chen",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.05184"" target=""_blank"">2211.05184</a>",,2025-12-03 22:39:25
Accountable and Explainable Methods for Complex Reasoning over Text,Pepa Atanasova,arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.04946"" target=""_blank"">2211.04946</a>",,2025-12-03 22:39:25
Directional Privacy for Deep Learning,"Pedro Faustini, Natasha Fernandes, Shakila Tonni, Annabelle McIver, Mark Dras",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.04686"" target=""_blank"">2211.04686</a>",,2025-12-03 22:39:25
Preserving Semantics in Textual Adversarial Attacks,"David Herel, Hugo Cisneros, Tomas Mikolov",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.04205"" target=""_blank"">2211.04205</a>",,2025-12-03 22:39:25
NaturalAdversaries: Can Naturalistic Adversaries Be as Effective as Artificial Adversaries? (98%),"Saadia Gabriel, Hamid Palangi, Yejin Choi",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.04364"" target=""_blank"">2211.04364</a>",,2025-12-03 22:39:25
Tightening Robustness Verification of MaxPool-based Neural Networks via Minimizing the Over-Approximation Zone,"Yuan Xiao, Yuchen Chen, Shiqing Ma, Chunrong Fang, Tongtong Bai, Mingzheng Gu, Yuxin Cheng, Yanwei Chen, Zhenyu Chen",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09810"" target=""_blank"">2211.09810</a>","<a href=""https://github.com/xiaoyuanpigo/Ti-Lin-Hybrid-Lin"" target=""_blank"">xiaoyuanpigo</a>",2025-12-03 22:39:25
How Fraudster Detection Contributes to Robust Recommendation,"Yuni Lai, Kai Zhou",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11534"" target=""_blank"">2211.11534</a>",,2025-12-03 22:39:25
Adversarial and Random Transformations for Robust Domain Adaptation and Generalization,"Liang Xiao, Jiaolong Xu, Dawei Zhao, Erke Shang, Qi Zhu, Bin Dai",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.06788"" target=""_blank"">2211.06788</a>",,2025-12-03 22:39:25
Holistic Evaluation of Language Models,"Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, Benjamin Newman, Binhang Yuan, Bobby Yan, Ce Zhang, Christian Cosgrove, Christopher D. Manning, Christopher Ré, Diana Acosta-Navas, Drew A. Hudson, Eric Zelikman, Esin Durmus, Faisal Ladhak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue Wang, Keshav Santhanam, Laurel Orr, Lucia Zheng, Mert Yuksekgonul, Mirac Suzgun, Nathan Kim, Neel Guha, Niladri Chatterji, Omar Khattab, Peter Henderson, Qian Huang, Ryan Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli, Tatsunori Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav Chaudhary, William Wang, Xuechen Li, Yifan Mai, Yuhui Zhang, Yuta Koreeda",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09110"" target=""_blank"">2211.09110</a>",,2025-12-03 22:39:25
Robustifying Deep Vision Models Through Shape Sensitization,"Aditay Tripathi, Rishubh Singh, Anirban Chakraborty, Pradeep Shenoy",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.07277"" target=""_blank"">2211.07277</a>",,2025-12-03 22:39:25
Analysis and Detectability of Offline Data Poisoning Attacks on Linear Systems,"Alessio Russo, Alexandre Proutiere",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.08804"" target=""_blank"">2211.08804</a>",,2025-12-03 22:39:25
Learning advisor networks for noisy image classification,"Simone Ricci, Tiberio Uricchio, Bimbo Alberto Del",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.04177"" target=""_blank"">2211.04177</a>",,2025-12-03 22:39:25
VeriSparse: Training Verified Locally Robust Sparse Neural Networks from Scratch,"Sawinder Kaur, Yi Xiao, Asif Salekin",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09945"" target=""_blank"">2211.09945</a>",,2025-12-03 22:39:25
T-SEA: Transfer-based Self-Ensemble Attack on Object Detection,"Hao Huang, Ziyan Chen, Huanran Chen, Yongtao Wang, Kevin Zhang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09773"" target=""_blank"">2211.09773</a>","<a href=""https://github.com/VDIGPKU/T-SEA"" target=""_blank"">VDIGPKU</a>",2025-12-03 22:39:25
Efficiently Finding Adversarial Examples with DNN Preprocessing,"Avriti Chauhan, Mohammad Afzal, Hrishikesh Karmarkar, Yizhak Elboher, Kumar Madhukar, Guy Katz",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.08706"" target=""_blank"">2211.08706</a>",,2025-12-03 22:39:25
Improving Interpretability via Regularization of Neural Activation Sensitivity,"Ofir Moshe, Gil Fidel, Ron Bitton, Asaf Shabtai",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.08686"" target=""_blank"">2211.08686</a>",,2025-12-03 22:39:25
Attacking Object Detector Using A Universal Targeted Label-Switch Patch,"Avishag Shapira, Ron Bitton, Dan Avraham, Alon Zolfi, Yuval Elovici, Asaf Shabtai",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.08859"" target=""_blank"">2211.08859</a>",,2025-12-03 22:39:25
Differentially Private Optimizers Can Learn Adversarially Robust Models,"Yuan Zhang, Zhiqi Bu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.08942"" target=""_blank"">2211.08942</a>",,2025-12-03 22:39:25
Interpretable Dimensionality Reduction by Feature Preserving Manifold Approximation and Projection,"Yang Yang, Hongjian Sun, Jialei Gong, Di Yu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09321"" target=""_blank"">2211.09321</a>",,2025-12-03 22:39:25
Privacy against Real-Time Speech Emotion Detection via Acoustic Adversarial Evasion of Machine Learning,"Brian Testa, Yi Xiao, Harshit Sharma, Avery Gump, Asif Salekin",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09273"" target=""_blank"">2211.09273</a>",,2025-12-03 22:39:25
Resisting Graph Adversarial Attack via Cooperative Homophilous Augmentation,"Zhihao Zhu, Chenwang Wu, Min Zhou, Hao Liao, Defu Lian, Enhong Chen",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.08068"" target=""_blank"">2211.08068</a>",,2025-12-03 22:39:25
Explainer Divergence Scores (EDS): Some Post-Hoc Explanations May be Effective for Detecting Unknown Spurious Correlations,"Shea Cardozo, Gabriel Islas Montero, Dmitry Kazhdan, Botty Dimanov, Maleakhi Wijaya, Mateja Jamnik, Pietro Lio",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.07650"" target=""_blank"">2211.07650</a>",,2025-12-03 22:39:25
Universal Distributional Decision-based Black-box Adversarial Attack with Reinforcement Learning,"Yiran Huang, Yexu Zhou, Michael Hefenbrock, Till Riedel, Likun Fang, Michael Beigl",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.08384"" target=""_blank"">2211.08384</a>",,2025-12-03 22:39:25
MORA: Improving Ensemble Robustness Evaluation with Model-Reweighing Attack,"Yunrui Yu, Xitong Gao, Cheng-Zhong Xu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.08008"" target=""_blank"">2211.08008</a>",,2025-12-03 22:39:25
Person Text-Image Matching via Text-Featur Interpretability Embedding and External Attack Node Implantation,"Fan Li, Hang Zhou, Huafeng Li, Yafei Zhang, Zhengtao Yu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.08657"" target=""_blank"">2211.08657</a>",,2025-12-03 22:39:25
Backdoor Attacks on Time Series: A Generative Approach,"Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, James Bailey",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.07915"" target=""_blank"">2211.07915</a>",,2025-12-03 22:39:25
CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive Learning,"Jinghuai Zhang, Hongbin Liu, Jinyuan Jia, Neil Zhenqiang Gong",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.08229"" target=""_blank"">2211.08229</a>",,2025-12-03 22:39:25
Improved techniques for deterministic l2 robustness,"Sahil Singla, Soheil Feizi",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.08453"" target=""_blank"">2211.08453</a>","<a href=""https://github.com/singlasahil14/improved_l2_robustness"" target=""_blank"">singlasahil14</a>",2025-12-03 22:39:25
Backdoor Attacks for Remote Sensing Data with Wavelet Transform,"Nikolaus Dräger, Yonghao Xu, Pedram Ghamisi",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.08044"" target=""_blank"">2211.08044</a>","<a href=""https://github.com/ndraeger/waba"" target=""_blank"">ndraeger</a>",2025-12-03 22:39:25
Efficient Adversarial Training with Robust Early-Bird Tickets,"Zhiheng Xi, Rui Zheng, Tao Gui, Qi Zhang, Xuanjing Huang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.07263"" target=""_blank"">2211.07263</a>",,2025-12-03 22:39:25
"Attacking Face Recognition with T-shirts: Database, Vulnerability Assessment and Detection","M. Ibsen, C. Rathgeb, F. Brechtel, R. Klepp, K. Pöppelmann, A. George, S. Marcel, C. Busch",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.07383"" target=""_blank"">2211.07383</a>",,2025-12-03 22:39:25
Lipschitz Continuous Algorithms for Graph Problems,"Soh Kumabe, Yuichi Yoshida",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.04674"" target=""_blank"">2211.04674</a>",,2025-12-03 22:39:25
Untargeted Backdoor Attack against Object Detection,"Chengxiao Luo, Yiming Li, Yong Jiang, Shu-Tao Xia",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.05638"" target=""_blank"">2211.05638</a>",,2025-12-03 22:39:25
Are AlphaZero-like Agents Robust to Adversarial Perturbations? (99%),"Li-Cheng Lan, Huan Zhang, Ti-Rong Wu, Meng-Yu Tsai, I-Chen Wu, Cho-Jui Hsieh",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.03769"" target=""_blank"">2211.03769</a>",,2025-12-03 22:39:25
Black-Box Attack against GAN-Generated Image Detector with Contrastive Perturbation,"Zijie Lou, Gang Cao, Man Lin",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.03509"" target=""_blank"">2211.03509</a>","<a href=""https://github.com/ZXMMD/BAttGAND"" target=""_blank"">ZXMMD</a>",2025-12-03 22:39:25
Improving transferability of 3D adversarial attacks with scale and shear transformations,"Jinali Zhang, Yinpeng Dong, Jun Zhu, Jihong Zhu, Minchi Kuang, Xiaming Yuan",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.01093"" target=""_blank"">2211.01093</a>","<a href=""https://github.com/cuge1995/SS-attack"" target=""_blank"">cuge1995</a>",2025-12-03 22:39:25
Certified Robustness of Quantum Classifiers against Adversarial Examples through Quantum Noise,"Jhih-Cing Huang, Yu-Lin Tsai, Chao-Han Huck Yang, Cheng-Fang Su, Chia-Mu Yu, Pin-Yu Chen, Sy-Yen Kuo",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.00887"" target=""_blank"">2211.00887</a>",,2025-12-03 22:39:25
Adversarial Attack on Radar-based Environment Perception Systems,"Amira Guesmi, Ihsen Alouani",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.01112"" target=""_blank"">2211.01112</a>",,2025-12-03 22:39:25
Isometric Representations in Neural Networks Improve Robustness,"Kosio Beshkov, Jonas Verhellen, Mikkel Elle Lepperød",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.01236"" target=""_blank"">2211.01236</a>",,2025-12-03 22:39:25
BATT: Backdoor Attack with Transformation-based Triggers,"Tong Xu, Yiming Li, Yong Jiang, Shu-Tao Xia",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.01806"" target=""_blank"">2211.01806</a>",,2025-12-03 22:39:25
Data-Centric Debugging: mitigating model failures via targeted data collection,"Sahil Singla, Atoosa Malemir Chegini, Mazda Moayeri, Soheil Feiz",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09859"" target=""_blank"">2211.09859</a>",,2025-12-03 22:39:25
Generative Adversarial Training Can Improve Neural Language Models,"Sajad Movahedi, Azadeh Shakery",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09728"" target=""_blank"">2211.09728</a>",,2025-12-03 22:39:25
Backdoor Defense via Suppressing Model Shortcuts,"Sheng Yang, Yiming Li, Yong Jiang, Shu-Tao Xia",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.05631"" target=""_blank"">2211.05631</a>",,2025-12-03 22:39:25
Human-in-the-Loop Mixup,"Katherine M. Collins, Umang Bhatt, Weiyang Liu, Vihari Piratla, Ilia Sucholutsky, Bradley Love, Adrian Weller",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.01202"" target=""_blank"">2211.01202</a>",,2025-12-03 22:39:25
The Enemy of My Enemy is My Friend: Exploring Inverse Adversaries for Improving Adversarial Training,"Junhao Dong, Seyed-Mohsen Moosavi-Dezfooli, Jianhuang Lai, Xiaohua Xie",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.00525"" target=""_blank"">2211.00525</a>",,2025-12-03 22:39:25
LMD: A Learnable Mask Network to Detect Adversarial Examples for Speaker Verification,"Xing Chen, Jie Wang, Xiao-Lei Zhang, Wei-Qiang Zhang, Kunde Yang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.00825"" target=""_blank"">2211.00825</a>",,2025-12-03 22:39:25
DensePure: Understanding Diffusion Models towards Adversarial Robustness,"Chaowei Xiao, Zhongzhu Chen, Kun Jin, Jiongxiao Wang, Weili Nie, Mingyan Liu, Anima Anandkumar, Bo Li, Dawn Song",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.00322"" target=""_blank"">2211.00322</a>",,2025-12-03 22:39:25
Adversarial Training with Complementary Labels: On the Benefit of Gradually Informative Attacks,"Jianan Zhou, Jianing Zhu, Jingfeng Zhang, Tongliang Liu, Gang Niu, Bo Han, Masashi Sugiyama",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.00269"" target=""_blank"">2211.00269</a>","<a href=""https://github.com/RoyalSkye/ATCL"" target=""_blank"">RoyalSkye</a>",2025-12-03 22:39:25
Universal Perturbation Attack on Differentiable No-Reference Image- and Video-Quality Metrics,"Ekaterina Shumitskaya, Anastasia Antsiferova, Dmitriy Vatolin",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.00366"" target=""_blank"">2211.00366</a>",,2025-12-03 22:39:25
The Perils of Learning From Unlabeled Data: Backdoor Attacks on Semi-supervised Learning,"Virat Shejwalkar, Lingjuan Lyu, Amir Houmansadr",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.00453"" target=""_blank"">2211.00453</a>",,2025-12-03 22:39:25
Maximum Likelihood Distillation for Robust Modulation Classification,"Javier Maroto, Gérôme Bovet, Pascal Frossard",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.00748"" target=""_blank"">2211.00748</a>",,2025-12-03 22:39:25
FRSUM: Towards Faithful Abstractive Summarization via Enhancing Factual Robustness,"Wenhao Wu, Wei Li, Jiachen Liu, Xinyan Xiao, Ziqiang Cao, Sujian Li, Hua Wu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.00294"" target=""_blank"">2211.00294</a>",,2025-12-03 22:39:25
Amplifying Membership Exposure via Data Poisoning,"Yufei Chen, Chao Shen, Yun Shen, Cong Wang, Yang Zhang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.00463"" target=""_blank"">2211.00463</a>",,2025-12-03 22:39:25
ActGraph: Prioritization of Test Cases Based on Deep Neural Network Activation Graph,"Jinyin Chen, Jie Ge, Haibin Zheng",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.00273"" target=""_blank"">2211.00273</a>",,2025-12-03 22:39:25
ARDIR: Improving Robustness using Knowledge Distillation of Internal Representation,"Tomokatsu Takahashi, Masanori Yamada, Yuuki Yamanaka, Tomoya Yamashita",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.00239"" target=""_blank"">2211.00239</a>",,2025-12-03 22:39:25
A Streamlit-based Artificial Intelligence Trust Platform for Next-Generation Wireless Networks,"M. Kuzlu, F. O. Catak, S. Sarp, U. Cali, O Gueler",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.12851"" target=""_blank"">2211.12851</a>",,2025-12-03 22:39:25
Defending with Errors: Approximate Computing for Robustness of Deep Neural Networks,"Amira Guesmi, Ihsen Alouani, Khaled N. Khasawneh, Mouna Baklouti, Tarek Frikha, Mohamed Abid, Nael Abu-Ghazaleh",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.01182"" target=""_blank"">2211.01182</a>",,2025-12-03 22:39:25
Unintended Memorization and Timing Attacks in Named Entity Recognition Models,"Rana Salal Ali, Benjamin Zi Hao Zhao, Hassan Jameel Asghar, Tham Nguyen, Ian David Wood, Dali Kaafar",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.02245"" target=""_blank"">2211.02245</a>",,2025-12-03 22:39:25
Try to Avoid Attacks: A Federated Data Sanitization Defense for Healthcare IoMT Systems,"Chong Chen, Ying Gao, Leyu Shi, Siquan Huang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.01592"" target=""_blank"">2211.01592</a>",,2025-12-03 22:39:25
Logits are predictive of network type,Ali Borji,arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.02272"" target=""_blank"">2211.02272</a>","<a href=""https://github.com/aliborji/logits"" target=""_blank"">aliborji</a>",2025-12-03 22:39:25
Deviations in Representations Induced by Adversarial Attacks,"Daniel Steinberg, Paul Munro",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.03714"" target=""_blank"">2211.03714</a>",,2025-12-03 22:39:25
Interpreting deep learning output for out-of-distribution detection,"Damian Matuszewski, Ida-Maria Sintorn",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.03637"" target=""_blank"">2211.03637</a>",,2025-12-03 22:39:25
Resilience of Wireless Ad Hoc Federated Learning against Model Poisoning Attacks,"Naoya Tezuka, Hideya Ochiai, Yuwei Sun, Hiroshi Esaki",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.03489"" target=""_blank"">2211.03489</a>",,2025-12-03 22:39:25
A Hypergraph-Based Machine Learning Ensemble Network Intrusion Detection System,"Zong-Zhi Lin, Thomas D. Pike, Mark M. Bailey, Nathaniel D. Bastian",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.03933"" target=""_blank"">2211.03933</a>",,2025-12-03 22:39:25
Contrastive Weighted Learning for Near-Infrared Gaze Estimation,Adam Lee,arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.03073"" target=""_blank"">2211.03073</a>",,2025-12-03 22:39:25
Textual Manifold-based Defense Against Natural Language Adversarial Examples,"Dang Minh Nguyen, Luu Anh Tuan",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.02878"" target=""_blank"">2211.02878</a>","<a href=""https://github.com/dangne/tmd"" target=""_blank"">dangne</a>",2025-12-03 22:39:25
Stateful Detection of Adversarial Reprogramming,"Yang Zheng, Xiaoyi Feng, Zhaoqiang Xia, Xiaoyue Jiang, Maura Pintor, Ambra Demontis, Battista Biggio, Fabio Roli",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.02885"" target=""_blank"">2211.02885</a>",,2025-12-03 22:39:25
Robust Lottery Tickets for Pre-trained Language Models,"Rui Zheng, Rong Bao, Yuhao Zhou, Di Liang, Sirui Wang, Wei Wu, Tao Gui, Qi Zhang, Xuanjing Huang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.03013"" target=""_blank"">2211.03013</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness to Sensitivity and Invariance Attacks with Deep Metric Learning,"Anaelia Ovalle, Evan Czyzycki, Cho-Jui Hsieh",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.02468"" target=""_blank"">2211.02468</a>",,2025-12-03 22:39:25
An Adversarial Robustness Perspective on the Topology of Neural Networks,"Morgane Goibert, Thomas Ricatte, Elvis Dohmatob",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.02675"" target=""_blank"">2211.02675</a>",,2025-12-03 22:39:25
Leveraging Domain Features for Detecting Adversarial Attacks Against Deep Speech Recognition in Noise,"Christian Heider Nielsen, Zheng-Hua Tan",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.01621"" target=""_blank"">2211.01621</a>",,2025-12-03 22:39:25
Fairness-aware Regression Robust to Adversarial Attacks,"Yulu Jin, Lifeng Lai",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.04449"" target=""_blank"">2211.04449</a>",,2025-12-03 22:39:25
Extension of Simple Algorithms to the Matroid Secretary Problem,Simon Park,arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.02755"" target=""_blank"">2211.02755</a>",,2025-12-03 22:39:25
Robustness of Fusion-based Multimodal Classifiers to Cross-Modal Content Dilutions,"Gaurav Verma, Vishwa Vinay, Ryan A. Rossi, Srijan Kumar",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.02646"" target=""_blank"">2211.02646</a>","<a href=""https://claws-lab.github.io/multimodal-robustness/"" target=""_blank"">multimodal-robustness</a>",2025-12-03 22:39:25
Data Models for Dataset Drift Controls in Machine Learning With Images,"Luis Oala, Marco Aversa, Gabriel Nobis, Kurt Willis, Yoan Neuenschwander, Michèle Buck, Christian Matek, Jerome Extermann, Enrico Pomarico, Wojciech Samek, Roderick Murray-Smith, Christoph Clausen, Bruno Sanguinetti",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.02578"" target=""_blank"">2211.02578</a>","<a href=""https://github.com/aiaudit-org/raw2logit"" target=""_blank"">aiaudit-org</a>",2025-12-03 22:39:25
Physically Adversarial Attacks and Defenses in Computer Vision: A Survey,"Xingxing Wei, Bangzheng Pu, Jiefan Lu, Baoyuan Wu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.01671"" target=""_blank"">2211.01671</a>",,2025-12-03 22:39:25
Adversarial Defense via Neural Oscillation inspired Gradient Masking,"Chunming Jiang, Yilei Zhang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.02223"" target=""_blank"">2211.02223</a>",,2025-12-03 22:39:25
M-to-N Backdoor Paradigm: A Multi-Trigger and Multi-Target Attack to Deep Learning Models,"Linshan Hou, Zhongyun Hua, Yuhong Li, Yifeng Zheng, Leo Yu Zhang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.01875"" target=""_blank"">2211.01875</a>",,2025-12-03 22:39:25
Robust Few-shot Learning Without Using any Adversarial Samples,"Gaurav Kumar Nayak, Ruchit Rawal, Inder Khatri, Anirban Chakraborty",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.01598"" target=""_blank"">2211.01598</a>","<a href=""https://github.com/vcl-iisc/robust-few-shot-learning"" target=""_blank"">vcl-iisc</a>",2025-12-03 22:39:25
Data-free Defense of Black Box Models Against Adversarial Attacks,"Gaurav Kumar Nayak, Inder Khatri, Shubham Randive, Ruchit Rawal, Anirban Chakraborty",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.01579"" target=""_blank"">2211.01579</a>","<a href=""https://github.com/vcl-iisc/data-free-black-box-defense"" target=""_blank"">vcl-iisc</a>",2025-12-03 22:39:25
A Tale of Two Cities: Data and Configuration Variances in Robust Deep Learning,"Guanqin Zhang, Jiankun Sun, Feng Xu, H. M. N. Dilum Bandara, Shiping Chen, Yulei Sui, Tim Menzies",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10012"" target=""_blank"">2211.10012</a>",,2025-12-03 22:39:25
Towards Robust Numerical Question Answering: Diagnosing Numerical Capabilities of NLP Systems,"Jialiang Xu, Mengyu Zhou, Xinyi He, Shi Han, Dongmei Zhang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.07455"" target=""_blank"">2211.07455</a>",,2025-12-03 22:39:25
Potential Auto-driving Threat: Universal Rain-removal Attack,"Jinchegn Hu, Jihao Li, Zhuoran Hou, Jingjing Jiang, Cunjia Liu, Yuanjian Zhang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09959"" target=""_blank"">2211.09959</a>",,2025-12-03 22:39:25
Imperceptible Adversarial Attack via Invertible Neural Networks,"Zihan Chen, Ziyue Wang, Junjie Huang, Wentao Zhao, Xiao Liu, Dejian Guan",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.15030"" target=""_blank"">2211.15030</a>",,2025-12-03 22:39:25
Navigation as the Attacker Wishes? Towards Building Byzantine-Robust Embodied Agents under Federated Learning,"Yunchao Zhang, Zonglin Di, Kaiwen Zhou, Cihang Xie, Xin Wang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.14769"" target=""_blank"">2211.14769</a>",,2025-12-03 22:39:25
Traditional Classification Neural Networks are Good Generators: They are Competitive with DDPMs and GANs,"Guangrun Wang, Philip H. S. Torr",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.14794"" target=""_blank"">2211.14794</a>",,2025-12-03 22:39:25
Federated Learning Attacks and Defenses: A Survey,"Yao Chen, Yijie Gui, Hong Lin, Wensheng Gan, Yongdong Wu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.14952"" target=""_blank"">2211.14952</a>",,2025-12-03 22:39:25
Adversarial Rademacher Complexity of Deep Neural Networks,"Jiancong Xiao, Yanbo Fan, Ruoyu Sun, Zhi-Quan Luo",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.14966"" target=""_blank"">2211.14966</a>",,2025-12-03 22:39:25
Game Theoretic Mixed Experts for Combinational Adversarial Machine Learning,"Ethan Rathbun, Kaleel Mahmood, Sohaib Ahmad, Caiwen Ding, Dijk Marten van",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.14669"" target=""_blank"">2211.14669</a>",,2025-12-03 22:39:25
Boundary Adversarial Examples Against Adversarial Overfitting,"Muhammad Zaid Hameed, Beat Buesser",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.14088"" target=""_blank"">2211.14088</a>",,2025-12-03 22:39:25
Supervised Contrastive Prototype Learning: Augmentation Free Robust Neural Network,"Iordanis Fostiropoulos, Laurent Itti",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.14424"" target=""_blank"">2211.14424</a>",,2025-12-03 22:39:25
Beyond Smoothing: Unsupervised Graph Representation Learning with Edge Heterophily Discriminating,"Yixin Liu, Yizhen Zheng, Daokun Zhang, Vincent CS Lee, Shirui Pan",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.14065"" target=""_blank"">2211.14065</a>",,2025-12-03 22:39:25
TrustGAN: Training safe and trustworthy deep learning models through generative adversarial networks,Hélion du Mas des Bourboux,arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.13991"" target=""_blank"">2211.13991</a>",,2025-12-03 22:39:25
SAGA: Spectral Adversarial Geometric Attack on 3D Meshes,"Tomer Stolik, Itai Lang, Shai Avidan",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.13775"" target=""_blank"">2211.13775</a>","<a href=""https://github.com/StolikTomer/SAGA"" target=""_blank"">StolikTomer</a>",2025-12-03 22:39:25
Tracking Dataset IP Use in Deep Neural Networks,"Seonhye Park, Alsharif Abuadbba, Shuo Wang, Kristen Moore, Yansong Gao, Hyoungshick Kim, Surya Nepal",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.13535"" target=""_blank"">2211.13535</a>",,2025-12-03 22:39:25
Explainable and Safe Reinforcement Learning for Autonomous Air Mobility,"Lei Wang, Hongyu Yang, Yi Lin, Suwan Yin, Yuankai Wu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.13474"" target=""_blank"">2211.13474</a>","<a href=""https://github.com/WLeiiiii/Gym-ATC-Attack-Project"" target=""_blank"">WLeiiiii</a>",2025-12-03 22:39:25
Neural Network Complexity of Chaos and Turbulence,"Tim Whittaker, Romuald A. Janik, Yaron Oz",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.15382"" target=""_blank"">2211.15382</a>",,2025-12-03 22:39:25
Seeds Don't Lie: An Adaptive Watermarking Framework for Computer Vision Models,"Jacob Shams, Ben Nassi, Ikuya Morikawa, Toshiya Shimizu, Asaf Shabtai, Yuval Elovici",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.13644"" target=""_blank"">2211.13644</a>",,2025-12-03 22:39:25
Generative Joint Source-Channel Coding for Semantic Image Transmission,"Ecenaz Erdemir, Tze-Yang Tung, Pier Luigi Dragotti, Deniz Gunduz",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.13772"" target=""_blank"">2211.13772</a>",,2025-12-03 22:39:25
CycleGANWM: A CycleGAN watermarking method for ownership verification,"Dongdong Lin, Benedetta Tondi, Bin Li, Mauro Barni",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.13737"" target=""_blank"">2211.13737</a>",,2025-12-03 22:39:25
Query Efficient Cross-Dataset Transferable Black-Box Attack on Action Recognition,"Rohit Gupta, Naveed Akhtar, Gaurav Kumar Nayak, Ajmal Mian, Mubarak Shah",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.13171"" target=""_blank"">2211.13171</a>",,2025-12-03 22:39:25
Adversarial Attacks are a Surprisingly Strong Baseline for Poisoning Few-Shot Meta-Learners,"Elre T. Oldewage, John Bronskill, Richard E. Turner",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.12990"" target=""_blank"">2211.12990</a>",,2025-12-03 22:39:25
Reliable Robustness Evaluation via Automatically Constructed Attack Ensembles,"Shengcai Liu, Fu Peng, Ke Tang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.12713"" target=""_blank"">2211.12713</a>","<a href=""https://github.com/LeegerPENG/AutoAE"" target=""_blank"">LeegerPENG</a>",2025-12-03 22:39:25
Dual Graphs of Polyhedral Decompositions for the Detection of Adversarial Attacks,"Huma Jamil, Yajing Liu, Christina Cole, Nathaniel Blanchard, Emily J. King, Michael Kirby, Christopher Peterson",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.13305"" target=""_blank"">2211.13305</a>",,2025-12-03 22:39:25
Privacy-Enhancing Optical Embeddings for Lensless Classification,"Eric Bezzam, Martin Vetterli, Matthieu Simeoni",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.12864"" target=""_blank"">2211.12864</a>",,2025-12-03 22:39:25
Foiling Explanations in Deep Neural Networks,"Snir Vitrack Tamam, Raz Lapid, Moshe Sipper",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.14860"" target=""_blank"">2211.14860</a>",,2025-12-03 22:39:25
CoNAL: Anticipating Outliers with Large Language Models,"Albert Xu, Xiang Ren, Robin Jia",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.15718"" target=""_blank"">2211.15718</a>",,2025-12-03 22:39:25
Data Provenance Inference in Machine Learning,"Mingxue Xu, Xiang-Yang Li",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.13416"" target=""_blank"">2211.13416</a>",,2025-12-03 22:39:25
Gamma-convergence of a nonlocal perimeter arising in adversarial machine learning,"Leon Bungert, Kerrek Stinson",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.15223"" target=""_blank"">2211.15223</a>",,2025-12-03 22:39:25
Towards Interpreting Vulnerability of Multi-Instance Learning via Customized and Universal Adversarial Perturbations,"Yu-Xuan Zhang, Hua Meng, Xue-Mei Cao, Zhengchun Zhou, Mei Yang, Avik Ranjan Adhikary",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.17071"" target=""_blank"">2211.17071</a>","<a href=""https://github.com/InkiInki/MI-UAP"" target=""_blank"">InkiInki</a>",2025-12-03 22:39:25
More Effective Centrality-Based Attacks on Weighted Networks,"Balume Mburano, Weisheng Si, Qing Cao, Wei Xing Zheng",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09345"" target=""_blank"">2211.09345</a>",,2025-12-03 22:39:25
Efficient Adversarial Input Generation via Neural Net Patching,"Tooba Khan, Kumar Madhukar, Subodh Vishnu Sharma",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.16808"" target=""_blank"">2211.16808</a>",,2025-12-03 22:39:25
Toward Robust Diagnosis: A Contour Attention Preserving Adversarial Defense for COVID-19 Detection,"Kun Xiang, Xing Zhang, Jinwen She, Jinpeng Liu, Haohan Wang, Shiqi Deng, Shancheng Jiang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.16806"" target=""_blank"">2211.16806</a>","<a href=""https://github.com/Quinn777/CAP"" target=""_blank"">Quinn777</a>",2025-12-03 22:39:25
Tight Certification of Adversarially Trained Neural Networks via Nonconvex Low-Rank Semidefinite Relaxations,"Hong-Ming Chiu, Richard Y. Zhang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.17244"" target=""_blank"">2211.17244</a>",,2025-12-03 22:39:25
Improved Smoothed Analysis of 2-Opt for the Euclidean TSP,"Bodo Manthey, Rhijn Jesse van",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.16908"" target=""_blank"">2211.16908</a>",,2025-12-03 22:39:25
Understanding and Enhancing Robustness of Concept-based Models,"Sanchit Sinha, Mengdi Huai, Jianhui Sun, Aidong Zhang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.16080"" target=""_blank"">2211.16080</a>",,2025-12-03 22:39:25
Ada3Diff: Defending against 3D Adversarial Point Clouds via Adaptive Diffusion,"Kui Zhang, Hang Zhou, Jie Zhang, Qidong Huang, Weiming Zhang, Nenghai Yu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.16247"" target=""_blank"">2211.16247</a>",,2025-12-03 22:39:25
Advancing Deep Metric Learning Through Multiple Batch Norms And Multi-Targeted Adversarial Examples,"Inderjeet Singh, Kazuya Kakizaki, Toshinori Araki",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.16253"" target=""_blank"">2211.16253</a>",,2025-12-03 22:39:25
Penalizing Confident Predictions on Largely Perturbed Inputs Does Not Improve Out-of-Distribution Generalization in Question Answering,"Kazutoshi Shinoda, Saku Sugawara, Akiko Aizawa",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.16093"" target=""_blank"">2211.16093</a>",,2025-12-03 22:39:25
Quantization-aware Interval Bound Propagation for Training Certifiably Robust Quantized Neural Networks,"Mathias Lechner, Đorđe Žikelić, Krishnendu Chatterjee, Thomas A. Henzinger, Daniela Rus",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.16187"" target=""_blank"">2211.16187</a>",,2025-12-03 22:39:25
AdvMask: A Sparse Adversarial Attack Based Data Augmentation Method for Image Classification,"Suorong Yang, Jinqiao Li, Jian Zhao, Furao Shen",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.16040"" target=""_blank"">2211.16040</a>",,2025-12-03 22:39:25
A3T: Accuracy Aware Adversarial Training,"Enes Altinisik, Safa Messaoud, Husrev Taha Sencar, Sanjay Chawla",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.16316"" target=""_blank"">2211.16316</a>",,2025-12-03 22:39:25
Building Resilience to Out-of-Distribution Visual Data via Input Optimization and Model Finetuning,"Christopher J. Holder, Majid Khonji, Jorge Dias, Muhammad Shafique",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.16228"" target=""_blank"">2211.16228</a>",,2025-12-03 22:39:25
Interpretations Cannot Be Trusted: Stealthy and Effective Adversarial Perturbations against Interpretable Deep Learning,"Eldor Abdukhamidov, Mohammed Abuhamad, Simon S. Woo, Eric Chan-Tin, Tamer Abuhmed",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.15926"" target=""_blank"">2211.15926</a>",,2025-12-03 22:39:25
Training Time Adversarial Attack Aiming the Vulnerability of Continual Learning,"Gyojin Han, Jaehyun Choi, Hyeong Gwon Hong, Junmo Kim",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.15875"" target=""_blank"">2211.15875</a>",,2025-12-03 22:39:25
Towards More Robust Interpretation via Local Gradient Alignment,"Sunghwan Joo, Seokhyeon Jeong, Juyeon Heo, Adrian Weller, Taesup Moon",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.15900"" target=""_blank"">2211.15900</a>",,2025-12-03 22:39:25
Understanding the Impact of Adversarial Robustness on Accuracy Disparity,"Yuzheng Hu, Fan Wu, Hongyang Zhang, Han Zhao",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.15762"" target=""_blank"">2211.15762</a>",,2025-12-03 22:39:25
How Important are Good Method Names in Neural Code Generation? A Model Robustness Perspective,"Guang Yang, Yu Zhou, Wenhua Yang, Tao Yue, Xiang Chen, Taolue Chen",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.15844"" target=""_blank"">2211.15844</a>",,2025-12-03 22:39:25
Rethinking the Number of Shots in Robust Model-Agnostic Meta-Learning,"Xiaoyue Duan, Guoliang Kang, Runqi Wang, Shumin Han, Song Xue, Tian Wang, Baochang Zhang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.15180"" target=""_blank"">2211.15180</a>",,2025-12-03 22:39:25
Attack on Unfair ToS Clause Detection: A Case Study using Universal Adversarial Triggers,"Shanshan Xu, Irina Broda, Rashid Haddad, Marco Negrini, Matthias Grabmair",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.15556"" target=""_blank"">2211.15556</a>",,2025-12-03 22:39:25
Principled Data-Driven Decision Support for Cyber-Forensic Investigations,"Soodeh Atefi, Sakshyam Panda, Manos Panaousis, Aron Laszka",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.13345"" target=""_blank"">2211.13345</a>",,2025-12-03 22:39:25
Learning Antidote Data to Individual Unfairness,"Peizhao Li, Ethan Xia, Hongfu Liu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.15897"" target=""_blank"">2211.15897</a>",,2025-12-03 22:39:25
Benchmarking Adversarially Robust Quantum Machine Learning at Scale,"Maxwell T. West, Sarah M. Erfani, Christopher Leckie, Martin Sevior, Lloyd C. L. Hollenberg, Muhammad Usman",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.12681"" target=""_blank"">2211.12681</a>",,2025-12-03 22:39:25
"Deep Composite Face Image Attacks: Generation, Vulnerability and Detection","Jag Mohan Singh, Raghavendra Ramachandra",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11039"" target=""_blank"">2211.11039</a>",,2025-12-03 22:39:25
Multi-head Ensemble of Smoothed Classifiers for Certified Robustness,"Kun Fang, Qinghua Tao, Yingwen Wu, Tao Li, Xiaolin Huang, Jie Yang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10882"" target=""_blank"">2211.10882</a>",,2025-12-03 22:39:25
Towards Adversarial Robustness of Deep Vision Algorithms,Hanshu Yan,arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10670"" target=""_blank"">2211.10670</a>",,2025-12-03 22:39:25
Phonemic Adversarial Attack against Audio Recognition in Real World,"Jiakai Wang, Zhendong Chen, Zixin Yin, Qinghong Yang, Xianglong Liu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10661"" target=""_blank"">2211.10661</a>",,2025-12-03 22:39:25
Towards Robust Dataset Learning,"Yihan Wu, Xinda Li, Florian Kerschbaum, Heng Huang, Hongyang Zhang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10752"" target=""_blank"">2211.10752</a>",,2025-12-03 22:39:25
Let Graph be the Go Board: Gradient-free Node Injection Attack for Graph Neural Networks via Reinforcement Learning,"Mingxuan Ju, Yujie Fan, Chuxu Zhang, Yanfang Ye",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10782"" target=""_blank"">2211.10782</a>","<a href=""https://github.com/jumxglhf/G2A2C"" target=""_blank"">jumxglhf</a>",2025-12-03 22:39:25
Exploring validation metrics for offline model-based optimisation with diffusion models,"Christopher Beckham, Alexandre Piche, David Vazquez, Christopher Pal",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10747"" target=""_blank"">2211.10747</a>",,2025-12-03 22:39:25
Mask Off: Analytic-based Malware Detection By Transfer Learning and Model Personalization,"Amirmohammad Pasdar, Young Choon Lee, Seok-Hee Hong",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10843"" target=""_blank"">2211.10843</a>",,2025-12-03 22:39:25
Investigating the Security of EV Charging Mobile Applications As an Attack Surface,"K. Sarieddine, M. A. Sayed, S. Torabi, R. Atallah, C. Assi",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10603"" target=""_blank"">2211.10603</a>",,2025-12-03 22:39:25
Adversarial Stimuli: Attacking Brain-Computer Interfaces via Perturbed Sensory Events,"Bibek Upadhayay, Vahid Behzadan",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10033"" target=""_blank"">2211.10033</a>",,2025-12-03 22:39:25
Leveraging Algorithmic Fairness to Mitigate Blackbox Attribute Inference Attacks,"Jan Aalmoes, Vasisht Duddu, Antoine Boutet",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10209"" target=""_blank"">2211.10209</a>",,2025-12-03 22:39:25
Invariant Learning via Diffusion Dreamed Distribution Shifts,"Priyatham Kattakinda, Alexander Levine, Soheil Feizi",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10370"" target=""_blank"">2211.10370</a>",,2025-12-03 22:39:25
Intrusion Detection in Internet of Things using Convolutional Neural Networks,"Martin Kodys, Zhi Lu, Kar Wai Fok, Vrizlynn L. L. Thing",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10062"" target=""_blank"">2211.10062</a>",,2025-12-03 22:39:25
Improving Robustness of TCM-based Robust Steganography with Variable Robustness,"Jimin Zhang, Xianfeng Zhao, Xiaolei He",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10095"" target=""_blank"">2211.10095</a>",,2025-12-03 22:39:25
Provable Defense against Backdoor Policies in Reinforcement Learning,"Shubham Kumar Bharti, Xuezhou Zhang, Adish Singla, Xiaojin Zhu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10530"" target=""_blank"">2211.10530</a>",,2025-12-03 22:39:25
Scaling Up Dataset Distillation to ImageNet-1K with Constant Memory,"Justin Cui, Ruochen Wang, Si Si, Cho-Jui Hsieh",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10586"" target=""_blank"">2211.10586</a>","<a href=""https://github.com/justincui03/tesla"" target=""_blank"">justincui03</a>",2025-12-03 22:39:25
Diagnostics for Deep Neural Networks with Automated Copy/Paste Attacks,"Stephen Casper, Kaivalya Hariharan, Dylan Hadfield-Menell",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10024"" target=""_blank"">2211.10024</a>","<a href=""https://github.com/thestephencasper/snafue"" target=""_blank"">thestephencasper</a>",2025-12-03 22:39:25
Towards Good Practices in Evaluating Transfer Adversarial Attacks,"Zhengyu Zhao, Hanwei Zhang, Renjue Li, Ronan Sicre, Laurent Amsaleg, Michael Backes",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09565"" target=""_blank"">2211.09565</a>",,2025-12-03 22:39:25
Assessing Neural Network Robustness via Adversarial Pivotal Tuning,"Peter Ebert Christensen, Vésteinn Snæbjarnarson, Andrea Dittadi, Serge Belongie, Sagie Benaim",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09782"" target=""_blank"">2211.09782</a>","<a href=""https://captaine.github.io/apt/"" target=""_blank"">apt</a>",2025-12-03 22:39:25
PointCA: Evaluating the Robustness of 3D Point Cloud Completion Models Against Adversarial Examples,"Shengshan Hu, Junwei Zhang, Wei Liu, Junhui Hou, Minghui Li, Leo Yu Zhang, Hai Jin, Lichao Sun",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.12294"" target=""_blank"">2211.12294</a>",,2025-12-03 22:39:25
Generalizable Deepfake Detection with Phase-Based Motion Analysis,"Ekta Prashnani, Michael Goebel, B. S. Manjunath",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09363"" target=""_blank"">2211.09363</a>",,2025-12-03 22:39:25
UPTON: Unattributable Authorship Text via Data Poisoning,"Ziyao Wang, Thai Le, Dongwon Lee",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.09717"" target=""_blank"">2211.09717</a>",,2025-12-03 22:39:25
AI-KD: Adversarial learning and Implicit regularization for self-Knowledge Distillation,"Hyungmin Kim, Sungho Suh, Sunghyun Baek, Daehwan Kim, Daun Jeong, Hansang Cho, Junmo Kim",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10938"" target=""_blank"">2211.10938</a>",,2025-12-03 22:39:25
Adversarial Detection by Approximation of Ensemble Boundary,T. Windeatt,arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10227"" target=""_blank"">2211.10227</a>",,2025-12-03 22:39:25
Addressing Mistake Severity in Neural Networks with Semantic Knowledge,"Natalie Abreu, Nathan Vaska, Victoria Helus",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11880"" target=""_blank"">2211.11880</a>",,2025-12-03 22:39:25
SPIN: Simulated Poisoning and Inversion Network for Federated Learning-Based 6G Vehicular Networks,"Sunder Ali Khowaja, Parus Khuwaja, Kapal Dev, Angelos Antonopoulos",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11321"" target=""_blank"">2211.11321</a>",,2025-12-03 22:39:25
Improving Robust Generalization by Direct PAC-Bayesian Bound Minimization,"Zifan Wang, Nan Ding, Tomer Levinboim, Xi Chen, Radu Soricut",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.12624"" target=""_blank"">2211.12624</a>",,2025-12-03 22:39:25
Adversarial Cheap Talk,"Chris Lu, Timon Willi, Alistair Letcher, Jakob Foerster",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11030"" target=""_blank"">2211.11030</a>",,2025-12-03 22:39:25
SoK: Inference Attacks and Defenses in Human-Centered Wireless Sensing,"Wei Sun, Tingjun Chen, Neil Gong",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.12087"" target=""_blank"">2211.12087</a>",,2025-12-03 22:39:25
Understanding the Vulnerability of Skeleton-based Human Activity Recognition via Black-box Attack,"Yunfeng Diao, He Wang, Tianjia Shao, Yong-Liang Yang, Kun Zhou, David Hogg",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11312"" target=""_blank"">2211.11312</a>",,2025-12-03 22:39:25
Self-Ensemble Protection: Training Checkpoints Are Good Data Protectors,"Sizhe Chen, Geng Yuan, Xinwen Cheng, Yifan Gong, Minghai Qin, Yanzhi Wang, Xiaolin Huang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.12005"" target=""_blank"">2211.12005</a>","<a href=""https://github.com/Sizhe-Chen/SEP"" target=""_blank"">Sizhe-Chen</a>",2025-12-03 22:39:25
Boosting the Transferability of Adversarial Attacks with Global Momentum Initialization,"Jiafeng Wang, Zhaoyu Chen, Kaixun Jiang, Dingkang Yang, Lingyi Hong, Pinxue Guo, Haijing Guo, Wenqiang Zhang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11236"" target=""_blank"">2211.11236</a>","<a href=""https://github.com/Omenzychen/Global-Momentum-Initialization"" target=""_blank"">Omenzychen</a>",2025-12-03 22:39:25
Efficient Generalization Improvement Guided by Random Weight Perturbation,"Tao Li, Weihao Yan, Zehao Lei, Yingwen Wu, Kun Fang, Ming Yang, Xiaolin Huang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11489"" target=""_blank"">2211.11489</a>","<a href=""https://github.com/nblt/RWP"" target=""_blank"">nblt</a>",2025-12-03 22:39:25
CLAWSAT: Towards Both Robust and Accurate Code Models,"Jinghan Jia, Shashank Srikant, Tamara Mitrovska, Chuang Gan, Shiyu Chang, Sijia Liu, Una-May O'Reilly",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11711"" target=""_blank"">2211.11711</a>",,2025-12-03 22:39:25
Fairness Increases Adversarial Vulnerability,"Cuong Tran, Keyu Zhu, Ferdinando Fioretto, Henternyck Pascal Van",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11835"" target=""_blank"">2211.11835</a>",,2025-12-03 22:39:25
Attacking Image Splicing Detection and Localization Algorithms Using Synthetic Traces,"Shengbang Fang, Matthew C Stamm",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.12314"" target=""_blank"">2211.12314</a>",,2025-12-03 22:39:25
Don't Watch Me: A Spatio-Temporal Trojan Attack on Deep-Reinforcement-Learning-Augment Autonomous Driving,"Yinbo Yu, Jiajia Liu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.14440"" target=""_blank"">2211.14440</a>",,2025-12-03 22:39:25
A Survey on Backdoor Attack and Defense in Natural Language Processing,"Xuan Sheng, Zhaoyang Han, Piji Li, Xiangmao Chang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11958"" target=""_blank"">2211.11958</a>",,2025-12-03 22:39:25
Understanding and Improving Visual Prompting: A Label-Mapping Perspective,"Aochuan Chen, Yuguang Yao, Pin-Yu Chen, Yihua Zhang, Sijia Liu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11635"" target=""_blank"">2211.11635</a>","<a href=""https://github.com/OPTML-Group/ILM-VP"" target=""_blank"">OPTML-Group</a>",2025-12-03 22:39:25
Multi-Level Knowledge Distillation for Out-of-Distribution Detection in Text,"Qianhui Wu, Huiqiang Jiang, Haonan Yin, Börje F. Karlsson, Chin-Yew Lin",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11300"" target=""_blank"">2211.11300</a>",,2025-12-03 22:39:25
Privacy in Practice: Private COVID-19 Detection in X-Ray Images,"Lucas Lange, Maja Schneider, Erhard Rahm",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11434"" target=""_blank"">2211.11434</a>",,2025-12-03 22:39:25
A Tale of Frozen Clouds: Quantifying the Impact of Algorithmic Complexity Vulnerabilities in Popular Web Servers,"Masudul Hasan Masud Bhuiyan, Cristian-Alexandru Staicu",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11357"" target=""_blank"">2211.11357</a>",,2025-12-03 22:39:25
Spectral Adversarial Training for Robust Graph Neural Network,"Jintang Li, Jiaying Peng, Liang Chen, Zibin Zheng, Tingting Liang, Qing Ling",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10896"" target=""_blank"">2211.10896</a>",,2025-12-03 22:39:25
Invisible Backdoor Attack with Dynamic Triggers against Person Re-identification,"Wenli Sun, Xinyang Jiang, Shuguang Dou, Dongsheng Li, Duoqian Miao, Cheng Deng, Cairong Zhao",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.10933"" target=""_blank"">2211.10933</a>",,2025-12-03 22:39:25
Taming Reachability Analysis of DNN-Controlled Systems via Abstraction-Based Training,"Jiaxu Tian, Dapeng Zhi, Si Liu, Peixin Wang, Guy Katz, Min Zhang",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.11127"" target=""_blank"">2211.11127</a>",,2025-12-03 22:39:25
Backdoor Cleansing with Unlabeled Data,"Lu Pang, Tao Sun, Haibin Ling, Chao Chen",arXiv,2022-11,"<a href=""http://arxiv.org/abs/2211.12044"" target=""_blank"">2211.12044</a>",,2025-12-03 22:39:25
Curved Representation Space of Vision Transformers,"Juyeop Kim, Junha Park, Songkuk Kim, Jong-Seok Lee",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.05742"" target=""_blank"">2210.05742</a>",,2025-12-03 22:39:25
Human Body Measurement Estimation with Adversarial Augmentation,"Nataniel Ruiz, Miriam Bellver, Timo Bolkart, Ambuj Arora, Ming C. Lin, Javier Romero, Raja Bala",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.05667"" target=""_blank"">2210.05667</a>","<a href=""https://adversarialbodysim.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Detecting Backdoors in Deep Text Classifiers,"You Guo, Jun Wang, Trevor Cohn",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11264"" target=""_blank"">2210.11264</a>",,2025-12-03 22:39:25
Zeroth-Order Hard-Thresholding: Gradient Error vs,"Vazelhes William de, Hualin Zhang, Huimin Wu, Xiao-Tong Yuan, Bin Gu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.05279"" target=""_blank"">2210.05279</a>",,2025-12-03 22:39:25
Adversarial Attack Against Image-Based Localization Neural Networks,"Meir Brand, Itay Naeh, Daniel Teitelman",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06589"" target=""_blank"">2210.06589</a>",,2025-12-03 22:39:25
Pre-trained Adversarial Perturbations,"Yuanhao Ban, Yinpeng Dong",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03372"" target=""_blank"">2210.03372</a>",,2025-12-03 22:39:25
RoHNAS: A Neural Architecture Search Framework with Conjoint Optimization for Adversarial Robustness and Hardware Efficiency of Convolutional and Capsule Networks,"Alberto Marchisio, Vojtech Mrazek, Andrea Massa, Beatrice Bussolino, Maurizio Martina, Muhammad Shafique",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.05276"" target=""_blank"">2210.05276</a>",,2025-12-03 22:39:25
Stable and Efficient Adversarial Training through Local Linearization,"Zhuorong Li, Daiwei Yu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.05373"" target=""_blank"">2210.05373</a>",,2025-12-03 22:39:25
Boosting Adversarial Robustness From The Perspective of Effective Margin Regularization,"Ziquan Liu, Antoni B. Chan",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.05118"" target=""_blank"">2210.05118</a>",,2025-12-03 22:39:25
What Can the Neural Tangent Kernel Tell Us About Adversarial Robustness? (99%),"Nikolaos Tsilivis, Julia Kempe",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.05577"" target=""_blank"">2210.05577</a>",,2025-12-03 22:39:25
When are Local Queries Useful for Robust Learning? (1%),"Pascale Gourdeau, Varun Kanade, Marta Kwiatkowska, James Worrell",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06089"" target=""_blank"">2210.06089</a>",,2025-12-03 22:39:25
Make Sharpness-Aware Minimization Stronger: A Sparsified Perturbation Approach,"Peng Mi, Li Shen, Tianhe Ren, Yiyi Zhou, Xiaoshuai Sun, Rongrong Ji, Dacheng Tao",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.05177"" target=""_blank"">2210.05177</a>","<a href=""https://github.com/Mi-Peng/Sparse-Sharpness-Aware-Minimization"" target=""_blank"">Mi-Peng</a>",2025-12-03 22:39:25
Symmetry Defense Against CNN Adversarial Perturbation Attacks,Blerta Lindqvist,arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.04087"" target=""_blank"">2210.04087</a>",,2025-12-03 22:39:25
Revisiting adapters with adversarial training,"Sylvestre-Alvise Rebuffi, Francesco Croce, Sven Gowal",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.04886"" target=""_blank"">2210.04886</a>",,2025-12-03 22:39:25
Universal Adversarial Perturbations: Efficiency on a small image dataset,"Waris ENSEIRB-MATMECA, UB Radji",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.04591"" target=""_blank"">2210.04591</a>",,2025-12-03 22:39:25
Certified Training: Small Boxes are All You Need,"Mark Niklas Müller, Franziska Eckert, Marc Fischer, Martin Vechev",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.04871"" target=""_blank"">2210.04871</a>",,2025-12-03 22:39:25
Denoising Masked AutoEncoders Help Robust Classification,"Quanlin Wu, Hang Ye, Yuntian Gu, Huishuai Zhang, Liwei Wang, Di He",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06983"" target=""_blank"">2210.06983</a>","<a href=""https://github.com/quanlin-wu/dmae"" target=""_blank"">quanlin-wu</a>",2025-12-03 22:39:25
Pruning Adversarially Robust Neural Networks without Adversarial Examples,"Tong Jian, Zifeng Wang, Yanzhi Wang, Jennifer Dy, Stratis Ioannidis",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.04311"" target=""_blank"">2210.04311</a>","<a href=""https://github.com/neu-spiral/PwoA/"" target=""_blank"">PwoA</a>",2025-12-03 22:39:25
Towards Understanding and Boosting Adversarial Transferability from a Distribution Perspective,"Yao Zhu, Yuefeng Chen, Xiaodan Li, Kejiang Chen, Yuan He, Xiang Tian, Bolun Zheng, Yaowu Chen, Qingming Huang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.04213"" target=""_blank"">2210.04213</a>",,2025-12-03 22:39:25
Online Training Through Time for Spiking Neural Networks,"Mingqing Xiao, Qingyan Meng, Zongpeng Zhang, Di He, Zhouchen Lin",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.04195"" target=""_blank"">2210.04195</a>",,2025-12-03 22:39:25
FedDef: Defense Against Gradient Leakage in Federated Learning-based Network Intrusion Detection Systems,"Jiahui Chen, Yi Zhao, Qi Li, Xuewei Feng, Ke Xu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.04052"" target=""_blank"">2210.04052</a>",,2025-12-03 22:39:25
Robustness of Unsupervised Representation Learning without Labels,"Aleksandar Petrov, Marta Kwiatkowska",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.04076"" target=""_blank"">2210.04076</a>",,2025-12-03 22:39:25
How to Sift Out a Clean Data Subset in the Presence of Data Poisoning? (9%),"Yi Zeng, Minzhou Pan, Himanshu Jahagirdar, Ming Jin, Lingjuan Lyu, Ruoxi Jia",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06516"" target=""_blank"">2210.06516</a>",,2025-12-03 22:39:25
Adversarially Robust Prototypical Few-shot Segmentation with Neural-ODEs,"Prashant Pandey, Aleti Vardhan, Mustafa Chasmai, Tanuj Sur, Brejesh Lall",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03429"" target=""_blank"">2210.03429</a>",,2025-12-03 22:39:25
Understanding Impacts of Task Similarity on Backdoor Attack and Detection,"Di Tang, Rui Zhu, XiaoFeng Wang, Haixu Tang, Yi Chen",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06509"" target=""_blank"">2210.06509</a>",,2025-12-03 22:39:25
When Adversarial Training Meets Vision Transformers: Recipes from Training to Architecture,"Yichuan Mo, Dongxian Wu, Yifei Wang, Yiwen Guo, Yisen Wang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.07540"" target=""_blank"">2210.07540</a>","<a href=""https://github.com/mo666666/When-Adversarial-Training-Meets-Vision-Transformers"" target=""_blank"">mo666666</a>",2025-12-03 22:39:25
Few-shot Backdoor Attacks via Neural Tangent Kernels,"Jonathan Hayase, Sewoong Oh",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.05929"" target=""_blank"">2210.05929</a>",,2025-12-03 22:39:25
Improving Out-of-Distribution Generalization by Adversarial Training with Structured Priors,"Qixun Wang, Yifei Wang, Hong Zhu, Yisen Wang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06807"" target=""_blank"">2210.06807</a>","<a href=""https://github.com/NOVAglow646/NIPS22-MAT-and-LDAT-for-OOD"" target=""_blank"">NOVAglow646</a>",2025-12-03 22:39:25
ViewFool: Evaluating the Robustness of Visual Recognition to Adversarial Viewpoints,"Yinpeng Dong, Shouwei Ruan, Hang Su, Caixin Kang, Xingxing Wei, Jun Zhu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03895"" target=""_blank"">2210.03895</a>",,2025-12-03 22:39:25
ODG-Q: Robust Quantization via Online Domain Generalization,"Chaofan Tao, Ngai Wong",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.08701"" target=""_blank"">2210.08701</a>",,2025-12-03 22:39:25
Interpretable Machine Learning for Detection and Classification of Ransomware Families Based on API Calls,"Rawshan Ara Mowri, Madhuri Siddula, Kaushik Roy",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11235"" target=""_blank"">2210.11235</a>",,2025-12-03 22:39:25
RoS-KD: A Robust Stochastic Knowledge Distillation Approach for Noisy Medical Imaging,"Ajay Jaiswal, Kumar Ashutosh, Justin F Rousseau, Yifan Peng, Zhangyang Wang, Ying Ding",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.08388"" target=""_blank"">2210.08388</a>",,2025-12-03 22:39:25
Dynamics-aware Adversarial Attack of Adaptive Neural Networks,"An Tao, Yueqi Duan, Yingqi Wang, Jiwen Lu, Jie Zhou",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.08159"" target=""_blank"">2210.08159</a>","<a href=""https://github.com/antao97/LGM"" target=""_blank"">antao97</a>",2025-12-03 22:39:25
Is Face Recognition Safe from Realizable Attacks? (84%),"Sanjay Saha, Terence Sim",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.08178"" target=""_blank"">2210.08178</a>",,2025-12-03 22:39:25
Expose Backdoors on the Way: A Feature-Based Efficient Defense against Textual Backdoor Attacks,"Sishuo Chen, Wenkai Yang, Zhiyuan Zhang, Xiaohan Bi, Xu Sun",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.07907"" target=""_blank"">2210.07907</a>","<a href=""https://github.com/lancopku/DAN"" target=""_blank"">lancopku</a>",2025-12-03 22:39:25
Close the Gate: Detecting Backdoored Models in Federated Learning based on Client-Side Deep Layer Output Analysis,"Phillip Technical University Darmstadt Rieger, Torsten University of Würzburg Krauß, Markus Technical University Darmstadt Miettinen, Alexandra University of Würzburg Dmitrienko, Ahmad-Reza Technical University Darmstadt Sadeghi",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.07714"" target=""_blank"">2210.07714</a>",,2025-12-03 22:39:25
Adv-Attribute: Inconspicuous and Transferable Adversarial Attack on Face Recognition,"Shuai Jia, Bangjie Yin, Taiping Yao, Shouhong Ding, Chunhua Shen, Xiaokang Yang, Chao Ma",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06871"" target=""_blank"">2210.06871</a>",,2025-12-03 22:39:25
AccelAT: A Framework for Accelerating the Adversarial Training of Deep Neural Networks through Accuracy Gradient,"Farzad Nikfam, Alberto Marchisio, Maurizio Martina, Muhammad Shafique",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06888"" target=""_blank"">2210.06888</a>",,2025-12-03 22:39:25
Demystifying Self-supervised Trojan Attacks,"Changjiang Li, Ren Pang, Zhaohan Xi, Tianyu Du, Shouling Ji, Yuan Yao, Ting Wang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.07346"" target=""_blank"">2210.07346</a>",,2025-12-03 22:39:25
Efficiently Computing Local Lipschitz Constants of Neural Networks via Bound Propagation,"Zhouxing Shi, Yihan Wang, Huan Zhang, Zico Kolter, Cho-Jui Hsieh",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.07394"" target=""_blank"">2210.07394</a>","<a href=""https://github.com/shizhouxing/Local-Lipschitz-Constants"" target=""_blank"">shizhouxing</a>",2025-12-03 22:39:25
Trap and Replace: Defending Backdoor Attacks by Trapping Them into an Easy-to-Replace Subnetwork,"Haotao Wang, Junyuan Hong, Aston Zhang, Jiayu Zhou, Zhangyang Wang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06428"" target=""_blank"">2210.06428</a>",,2025-12-03 22:39:25
Large-Scale Open-Set Classification Protocols for ImageNet,"Jesus Andres Palechor Anacona, Annesha Bhoumik, Manuel Günther",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06789"" target=""_blank"">2210.06789</a>",,2025-12-03 22:39:25
SoK: How Not to Architect Your Next-Generation TEE Malware? (1%),"Kubilay Ahmet Küçük, Steve Moyle, Andrew Martin, Alexandru Mereacre, Nicholas Allott",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06792"" target=""_blank"">2210.06792</a>",,2025-12-03 22:39:25
Feature Reconstruction Attacks and Countermeasures of DNN training in Vertical Federated Learning,"Peng Ye, Zhifeng Jiang, Wei Wang, Bo Li, Baochun Li",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06771"" target=""_blank"">2210.06771</a>",,2025-12-03 22:39:25
Characterizing the Influence of Graph Elements,"Zizhang Chen, Peizhao Li, Hongfu Liu, Pengyu Hong",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.07441"" target=""_blank"">2210.07441</a>",,2025-12-03 22:39:25
A Game Theoretical vulnerability analysis of Adversarial Attack,"Khondker Fariha Hossain, Alireza Tavakkoli, Shamik Sengupta",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06670"" target=""_blank"">2210.06670</a>",,2025-12-03 22:39:25
Boosting the Transferability of Adversarial Attacks with Reverse Adversarial Perturbation,"Zeyu Qin, Yanbo Fan, Yi Liu, Li Shen, Yong Zhang, Jue Wang, Baoyuan Wu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.05968"" target=""_blank"">2210.05968</a>","<a href=""https://github.com/SCLBD/Transfer_attack_RAP"" target=""_blank"">SCLBD</a>",2025-12-03 22:39:25
Visual Prompting for Adversarial Robustness,"Aochuan Chen, Peter Lorenz, Yuguang Yao, Pin-Yu Chen, Sijia Liu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06284"" target=""_blank"">2210.06284</a>",,2025-12-03 22:39:25
Robust Models are less Over-Confident,"Julia Grabinski, Paul Gavrikov, Janis Keuper, Margret Keuper",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.05938"" target=""_blank"">2210.05938</a>","<a href=""https://github.com/GeJulia/robustness_confidences_evaluation"" target=""_blank"">GeJulia</a>",2025-12-03 22:39:25
"Double Bubble, Toil and Trouble: Enhancing Certified Robustness through Transitivity","Andrew C. Cullen, Paul Montague, Shijie Liu, Sarah M. Erfani, Benjamin I. P. Rubinstein",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06077"" target=""_blank"">2210.06077</a>",,2025-12-03 22:39:25
Efficient Adversarial Training without Attacking: Worst-Case-Aware Robust Reinforcement Learning,"Yongyuan Liang, Yanchao Sun, Ruijie Zheng, Furong Huang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.05927"" target=""_blank"">2210.05927</a>","<a href=""https://github.com/umd-huang-lab/WocaR-RL"" target=""_blank"">umd-huang-lab</a>",2025-12-03 22:39:25
COLLIDER: A Robust Training Framework for Backdoor Data,"Hadi M. Dolatabadi, Sarah Erfani, Christopher Leckie",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.06704"" target=""_blank"">2210.06704</a>",,2025-12-03 22:39:25
NMTSloth: Understanding and Testing Efficiency Degradation of Neural Machine Translation Systems,"Simin Chen, Cong Liu, Mirazul Haque, Zihe Song, Wei Yang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03696"" target=""_blank"">2210.03696</a>",,2025-12-03 22:39:25
Learning Robust Kernel Ensembles with Kernel Average Pooling,"Pouya Bashivan, Adam Ibrahim, Amirozhan Dehghani, Yifei Ren",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00062"" target=""_blank"">2210.00062</a>",,2025-12-03 22:39:25
Game-Theoretic Understanding of Misclassification,"Kosuke Sumiyasu, Kazuhiko Kawamoto, Hiroshi Kera",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03349"" target=""_blank"">2210.03349</a>",,2025-12-03 22:39:25
Understanding Adversarial Robustness Against On-manifold Adversarial Examples,"Jiancong Xiao, Liusha Yang, Yanbo Fan, Jue Wang, Zhi-Quan Luo",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00430"" target=""_blank"">2210.00430</a>",,2025-12-03 22:39:25
Backdoor Attacks in the Supply Chain of Masked Image Modeling,"Xinyue Shen, Xinlei He, Zheng Li, Yun Shen, Michael Backes, Yang Zhang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.01632"" target=""_blank"">2210.01632</a>",,2025-12-03 22:39:25
CADet: Fully Self-Supervised Anomaly Detection With Contrastive Learning,"Charles Guille-Escuret, Pau Rodriguez, David Vazquez, Ioannis Mitliagkas, Joao Monteiro",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.01742"" target=""_blank"">2210.01742</a>",,2025-12-03 22:39:25
MultiGuard: Provably Robust Multi-label Classification against Adversarial Examples,"Jinyuan Jia, Wenjie Qu, Neil Zhenqiang Gong",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.01111"" target=""_blank"">2210.01111</a>","<a href=""https://github.com/quwenjie/MultiGuard"" target=""_blank"">quwenjie</a>",2025-12-03 22:39:25
Push-Pull: Characterizing the Adversarial Robustness for Audio-Visual Active Speaker Detection,"Xuanjun Chen, Haibin Wu, Helen Meng, Hung-yi Lee, Jyh-Shing Roger Jang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00753"" target=""_blank"">2210.00753</a>",,2025-12-03 22:39:25
Stability Analysis and Generalization Bounds of Adversarial Training,"Jiancong Xiao, Yanbo Fan, Ruoyu Sun, Jue Wang, Zhi-Quan Luo",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00960"" target=""_blank"">2210.00960</a>",,2025-12-03 22:39:25
On Attacking Out-Domain Uncertainty Estimation in Deep Neural Networks,"Huimin Zeng, Zhenrui Yue, Yang Zhang, Ziyi Kou, Lanyu Shang, Dong Wang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.02191"" target=""_blank"">2210.02191</a>",,2025-12-03 22:39:25
Decompiling x86 Deep Neural Network Executables,"Zhibo Liu, Yuanyuan Yuan, Shuai Wang, Xiaofei Xie, Lei Ma",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.01075"" target=""_blank"">2210.01075</a>",,2025-12-03 22:39:25
Strength-Adaptive Adversarial Training,"Chaojian Yu, Dawei Zhou, Li Shen, Jun Yu, Bo Han, Mingming Gong, Nannan Wang, Tongliang Liu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.01288"" target=""_blank"">2210.01288</a>",,2025-12-03 22:39:25
ASGNN: Graph Neural Networks with Adaptive Structure,"Zepeng Zhang, Songtao Lu, Zengfeng Huang, Ziping Zhao",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.01002"" target=""_blank"">2210.01002</a>",,2025-12-03 22:39:25
UnGANable: Defending Against GAN-based Face Manipulation,"Zheng Li, Ning Yu, Ahmed Salem, Michael Backes, Mario Fritz, Yang Zhang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00957"" target=""_blank"">2210.00957</a>",,2025-12-03 22:39:25
Adaptive Smoothness-weighted Adversarial Training for Multiple Perturbations with Its Stability Analysis,"Jiancong Xiao, Zeyu Qin, Yanbo Fan, Baoyuan Wu, Jue Wang, Zhi-Quan Luo",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00557"" target=""_blank"">2210.00557</a>",,2025-12-03 22:39:25
FLCert: Provably Secure Federated Learning against Poisoning Attacks,"Xiaoyu Cao, Zaixi Zhang, Jinyuan Jia, Neil Zhenqiang Gong",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00584"" target=""_blank"">2210.00584</a>",,2025-12-03 22:39:25
A2: Efficient Automated Attacker for Boosting Adversarial Training,"Zhuoer Xu, Guanghui Zhu, Changhua Meng, Shiwen Cui, Zhenzhe Ying, Weiqiang Wang, Ming GU, Yihua Huang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03543"" target=""_blank"">2210.03543</a>",,2025-12-03 22:39:25
Optimization for Robustness Evaluation beyond $\ell_p$ Metrics,"Hengyue Liang, Buyun Liang, Ying Cui, Tim Mitchell, Ju Sun",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00621"" target=""_blank"">2210.00621</a>",,2025-12-03 22:39:25
Automated Security Analysis of Exposure Notification Systems,"Kevin Morio, Ilkan Esiyok, Dennis Jackson, Robert Künnemann",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00649"" target=""_blank"">2210.00649</a>",,2025-12-03 22:39:25
DeltaBound Attack: Efficient decision-based attack in low queries regime,Lorenzo Rossi,arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00292"" target=""_blank"">2210.00292</a>",,2025-12-03 22:39:25
Adversarial Attacks on Transformers-Based Malware Detectors,"Yash Jakhotiya, Heramb Patil, Jugal Rawlani, Sunil B. Mane",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00008"" target=""_blank"">2210.00008</a>","<a href=""https://github.com/yashjakhotiya/Adversarial-Attacks-On-Transformers"" target=""_blank"">yashjakhotiya</a>",2025-12-03 22:39:25
"Voice Spoofing Countermeasures: Taxonomy, State-of-the-art, experimental analysis of generalizability, open challenges, and the way forward","Awais Khan, Khalid Mahmood Malik, James Ryan, Mikul Saravanan",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00417"" target=""_blank"">2210.00417</a>",,2025-12-03 22:39:25
Adversarial Robustness of Representation Learning for Knowledge Graphs,Peru Bhardwaj,arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00122"" target=""_blank"">2210.00122</a>",,2025-12-03 22:39:25
On the tightness of linear relaxation based robustness certification methods,Cheng Tang,arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00178"" target=""_blank"">2210.00178</a>",,2025-12-03 22:39:25
ImpNet: Imperceptible and blackbox-undetectable backdoors in compiled neural networks,"Tim Clifford, Ilia Shumailov, Yiren Zhao, Ross Anderson, Robert Mullins",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00108"" target=""_blank"">2210.00108</a>",,2025-12-03 22:39:25
Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection,"Yiming Li, Yang Bai, Yong Jiang, Yong Yang, Shu-Tao Xia, Bo Li",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00875"" target=""_blank"">2210.00875</a>","<a href=""https://github.com/THUYimingLi/Untargeted_Backdoor_Watermark"" target=""_blank"">THUYimingLi</a>",2025-12-03 22:39:25
Stability Via Adversarial Training of Neural Network Stochastic Control of Mean-Field Type,"Julian Barreiro-Gomez, Salah Eddine Choutri, Boualem Djehiche",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.00874"" target=""_blank"">2210.00874</a>",,2025-12-03 22:39:25
Object-Attentional Untargeted Adversarial Attack,"Chao Zhou, Yuan-Gen Wang, Guopu Zhu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.08472"" target=""_blank"">2210.08472</a>",,2025-12-03 22:39:25
Robustness Certification of Visual Perception Models via Camera Motion Smoothing,"Hanjiang Hu, Zuxin Liu, Linyi Li, Jiacheng Zhu, Ding Zhao",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.04625"" target=""_blank"">2210.04625</a>","<a href=""https://github.com/HanjiangHu/camera-motion-smoothing"" target=""_blank"">HanjiangHu</a>",2025-12-03 22:39:25
On the Robustness of Deep Clustering Models: Adversarial Attacks and Defenses,"Anshuman Chhabra, Ashwin Sekhari, Prasant Mohapatra",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.01940"" target=""_blank"">2210.01940</a>",,2025-12-03 22:39:25
Invariant Aggregator for Defending against Federated Backdoor Attacks,"Xiaoyang Wang, Dimitrios Dimitriadis, Sanmi Koyejo, Shruti Tople",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.01834"" target=""_blank"">2210.01834</a>",,2025-12-03 22:39:25
Practical Adversarial Attacks on Spatiotemporal Traffic Forecasting Models,"Fan Liu, Hao Liu, Wenzhao Jiang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.02447"" target=""_blank"">2210.02447</a>","<a href=""https://github.com/luckyfan-cs/ASTFA"" target=""_blank"">luckyfan-cs</a>",2025-12-03 22:39:25
BAFFLE: Hiding Backdoors in Offline Reinforcement Learning Datasets,"Chen Gong, Zhou Yang, Yunpeng Bai, Junda He, Jieke Shi, Kecen Li, Arunesh Sinha, Bowen Xu, Xinwen Hou, David Lo, Tianhao Wang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.04688"" target=""_blank"">2210.04688</a>",,2025-12-03 22:39:25
A Wolf in Sheep's Clothing: Spreading Deadly Pathogens Under the Disguise of Popular Music,"Anomadarshi Barua, Yonatan Gizachew Achamyeleh, Mohammad Abdullah Al Faruque",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03688"" target=""_blank"">2210.03688</a>",,2025-12-03 22:39:25
Improving Fine-Grain Segmentation via Interpretable Modifications: A Case Study in Fossil Segmentation,"Indu Panigrahi, Ryan Manzuk, Adam Maloof, Ruth Fong",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03879"" target=""_blank"">2210.03879</a>",,2025-12-03 22:39:25
Preprocessors Matter! Realistic Decision-Based Attacks on Machine Learning Systems,"Chawin Sitawarin, Florian Tramèr, Nicholas Carlini",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03297"" target=""_blank"">2210.03297</a>","<a href=""https://github.com/google-research/preprocessor-aware-black-box-attack"" target=""_blank"">google-research</a>",2025-12-03 22:39:25
Enhancing Code Classification by Mixup-Based Data Augmentation,"Zeming Dong, Qiang Hu, Yuejun Guo, Maxime Cordy, Mike Papadakis, Yves Le Traon, Jianjun Zhao",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03003"" target=""_blank"">2210.03003</a>",,2025-12-03 22:39:25
Deep Reinforcement Learning based Evasion Generative Adversarial Network for Botnet Detection,"Rizwan Hamid Randhawa, Nauman Aslam, Mohammad Alauthman, Muhammad Khalid, Husnain Rafiq",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.02840"" target=""_blank"">2210.02840</a>","<a href=""https://github.com/rhr407/RELEVAGAN"" target=""_blank"">rhr407</a>",2025-12-03 22:39:25
On Optimal Learning Under Targeted Data Poisoning,"Steve Hanneke, Amin Karbasi, Mohammad Mahmoody, Idan Mehalel, Shay Moran",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.02713"" target=""_blank"">2210.02713</a>",,2025-12-03 22:39:25
Towards Out-of-Distribution Adversarial Robustness,"Adam Ibrahim, Charles Guille-Escuret, Ioannis Mitliagkas, Irina Rish, David Krueger, Pouya Bashivan",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03150"" target=""_blank"">2210.03150</a>",,2025-12-03 22:39:25
InferES : A Natural Language Inference Corpus for Spanish Featuring Negation-Based Contrastive and Adversarial Examples,"Venelin Kovatchev, Mariona Taulé",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03068"" target=""_blank"">2210.03068</a>",,2025-12-03 22:39:25
Unsupervised Domain Adaptation for COVID-19 Information Service with Contrastive Adversarial Domain Mixup,"Huimin Zeng, Zhenrui Yue, Ziyi Kou, Lanyu Shang, Yang Zhang, Dong Wang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03250"" target=""_blank"">2210.03250</a>",,2025-12-03 22:39:25
Synthetic Dataset Generation for Privacy-Preserving Machine Learning,"Efstathia Soufleri, Gobinda Saha, Kaushik Roy",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03205"" target=""_blank"">2210.03205</a>",,2025-12-03 22:39:25
Enhancing Mixup-Based Graph Learning for Language Processing via Hybrid Pooling,"Zeming Dong, Qiang Hu, Yuejun Guo, Maxime Cordy, Mike Papadakis, Yves Le Traon, Jianjun Zhao",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03123"" target=""_blank"">2210.03123</a>",,2025-12-03 22:39:25
Bad Citrus: Reducing Adversarial Costs with Model Distances,"Giorgio Severi, Will Pearce, Alina Oprea",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.03239"" target=""_blank"">2210.03239</a>",,2025-12-03 22:39:25
Natural Color Fool: Towards Boosting Black-box Unrestricted Attacks,"Shengming Yuan, Qilong Zhang, Lianli Gao, Yaya Cheng, Jingkuan Song",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.02041"" target=""_blank"">2210.02041</a>","<a href=""https://github.com/ylhz/Natural-Color-Fool"" target=""_blank"">ylhz</a>",2025-12-03 22:39:25
Dynamic Stochastic Ensemble with Adversarial Robust Lottery Ticket Subnetworks,"Qi Peng, Wenlin Liu, Ruoxi Qin, Libin Hou, Bin Yan, Linyuan Wang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.02618"" target=""_blank"">2210.02618</a>",,2025-12-03 22:39:25
On Adversarial Robustness of Deep Image Deblurring,"Kanchana Vaishnavi Gandikota, Paramanand Chandramouli, Michael Moeller",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.02502"" target=""_blank"">2210.02502</a>",,2025-12-03 22:39:25
A Closer Look at Robustness to L-infinity and Spatial Perturbations and their Composition,"Luke Rowe, Benjamin Thérien, Krzysztof Czarnecki, Hongyang Zhang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.02577"" target=""_blank"">2210.02577</a>",,2025-12-03 22:39:25
Jitter Does Matter: Adapting Gaze Estimation to New Domains,"Ruicong Liu, Yiwei Bao, Mingjie Xu, Haofei Wang, Yunfei Liu, Feng Lu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.02082"" target=""_blank"">2210.02082</a>",,2025-12-03 22:39:25
Image Masking for Robust Self-Supervised Monocular Depth Estimation,"Hemang Chawla, Kishaan Jeeveswaran, Elahe Arani, Bahram Zonooz",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.02357"" target=""_blank"">2210.02357</a>",,2025-12-03 22:39:25
Over-the-Air Federated Learning with Privacy Protection via Correlated Additive Perturbations,"Jialing Liao, Zheng Chen, Erik G. Larsson",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.02235"" target=""_blank"">2210.02235</a>",,2025-12-03 22:39:25
Rethinking Lipschitz Neural Networks and Certified Robustness: A Boolean Function Perspective,"Bohang Zhang, Du Jiang, Di He, Liwei Wang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.01787"" target=""_blank"">2210.01787</a>","<a href=""https://github.com/zbh2047/SortNet"" target=""_blank"">zbh2047</a>",2025-12-03 22:39:25
Robust Fair Clustering: A Novel Fairness Attack and Defense Framework,"Anshuman Chhabra, Peizhao Li, Prasant Mohapatra, Hongfu Liu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.01953"" target=""_blank"">2210.01953</a>",,2025-12-03 22:39:25
A Study on the Efficiency and Generalization of Light Hybrid Retrievers,"Man Luo, Shashank Jain, Anchit Gupta, Arash Einolghozati, Barlas Oguz, Debojeet Chatterjee, Xilun Chen, Chitta Baral, Peyman Heidari",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.01371"" target=""_blank"">2210.01371</a>",,2025-12-03 22:39:25
Nowhere to Hide: A Lightweight Unsupervised Detector against Adversarial Examples,"Hui Liu, Bo Zhao, Kehuan Zhang, Peng Liu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.08579"" target=""_blank"">2210.08579</a>",,2025-12-03 22:39:25
Training set cleansing of backdoor poisoning by self-supervised representation learning,"H. Wang, S. Karami, O. Dia, H. Ritter, E. Emamjomeh-Zadeh, J. Chen, Z. Xiang, D. J. Miller, G. Kesidis",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.10272"" target=""_blank"">2210.10272</a>",,2025-12-03 22:39:25
Understanding CNN Fragility When Learning With Imbalanced Data,"Damien Dablain, Kristen N. Jacobson, Colin Bellinger, Mark Roberts, Nitesh Chawla",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.09465"" target=""_blank"">2210.09465</a>",,2025-12-03 22:39:25
A White-Box Adversarial Attack Against a Digital Twin,"Wilson Patterson, Ivan Fernandez, Subash Neupane, Milan Parmar, Sudip Mittal, Shahram Rahimi",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.14018"" target=""_blank"">2210.14018</a>",,2025-12-03 22:39:25
There is more than one kind of robustness: Fooling Whisper with adversarial examples,"Raphael Olivier, Bhiksha Raj",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.17316"" target=""_blank"">2210.17316</a>",,2025-12-03 22:39:25
Disentangled Text Representation Learning with Information-Theoretic Perspective for Adversarial Robustness,"Jiahao Zhao, Wenji Mao",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.14957"" target=""_blank"">2210.14957</a>",,2025-12-03 22:39:25
BioNLI: Generating a Biomedical NLI Dataset Using Lexico-semantic Constraints for Adversarial Examples,"Mohaddeseh Bastan, Mihai Surdeanu, Niranjan Balasubramanian",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.14814"" target=""_blank"">2210.14814</a>",,2025-12-03 22:39:25
Secure IP Address Allocation at Cloud Scale,"Eric University of Wisconsin-Madison Pauley, Kyle Pennsylvania State University Domico, Blaine University of Wisconsin-Madison Hoak, Ryan University of Wisconsin-Madison Sheatsley, Quinn University of Wisconsin-Madison Burke, Yohan University of Wisconsin-Madison Beugin, Engin Northeastern University Kirda, Patrick University of Wisconsin-Madison McDaniel",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.14999"" target=""_blank"">2210.14999</a>",,2025-12-03 22:39:25
"V-Cloak: Intelligibility-, Naturalness- & Timbre-Preserving Real-Time Voice Anonymization","Jiangyi Zhejiang University Deng, Fei Zhejiang University Teng, Yanjiao Zhejiang University Chen, Xiaofu Wuhan University Chen, Zhaohui Wuhan University Wang, Wenyuan Zhejiang University Xu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15140"" target=""_blank"">2210.15140</a>",,2025-12-03 22:39:25
Rethinking the Reverse-engineering of Trojan Triggers,"Zhenting Wang, Kai Mei, Hailun Ding, Juan Zhai, Shiqing Ma",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15127"" target=""_blank"">2210.15127</a>","<a href=""https://github.com/RU-System-Software-and-Security/FeatureRE"" target=""_blank"">RU-System-Software-and-Security</a>",2025-12-03 22:39:25
Cover Reproducible Steganography via Deep Generative Models,"Kejiang Chen, Hang Zhou, Yaofei Wang, Menghan Li, Weiming Zhang, Nenghai Yu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.14632"" target=""_blank"">2210.14632</a>",,2025-12-03 22:39:25
DEMIS: A Threat Model for Selectively Encrypted Visual Surveillance Data,"Ifeoluwapo Aribilola, Mamoona Naveed Asghar, Brian Lee",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.14622"" target=""_blank"">2210.14622</a>","<a href=""https://github.com/Ifeoluwapoo/video-datasets"" target=""_blank"">Ifeoluwapoo</a>",2025-12-03 22:39:25
Privately Fine-Tuning Large Language Models with Differential Privacy,"Rouzbeh Behnia, Mohamamdreza Ebrahimi, Jason Pacheco, Balaji Padmanabhan",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15042"" target=""_blank"">2210.15042</a>",,2025-12-03 22:39:25
LP-BFGS attack: An adversarial attack based on the Hessian with limited pixels,"Jiebao Zhang, Wenhua Qian, Rencan Nie, Jinde Cao, Dan Xu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15446"" target=""_blank"">2210.15446</a>",,2025-12-03 22:39:25
Adversarially Robust Medical Classification via Attentive Convolutional Neural Networks,Isaac Wasserman,arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.14405"" target=""_blank"">2210.14405</a>",,2025-12-03 22:39:25
Multi-view Representation Learning from Malware to Defend Against Adversarial Variants,"James Lee Hu, Mohammadreza Ebrahimi, Weifeng Li, Xin Li, Hsinchun Chen",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15429"" target=""_blank"">2210.15429</a>",,2025-12-03 22:39:25
Flexible Android Malware Detection Model based on Generative Adversarial Networks with Code Tensor,"Zhao Yang, Fengyang Deng, Linxi Han",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.14225"" target=""_blank"">2210.14225</a>",,2025-12-03 22:39:25
Adversarial Purification with the Manifold Hypothesis,"Zhaoyuan Yang, Zhiwei Xu, Jing Zhang, Richard Hartley, Peter Tu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.14404"" target=""_blank"">2210.14404</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness via Joint Classification and Multiple Explicit Detection Classes,"Sina Baharlouei, Fatemeh Sheikholeslami, Meisam Razaviyayn, Zico Kolter",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.14410"" target=""_blank"">2210.14410</a>",,2025-12-03 22:39:25
Accelerating Certified Robustness Training via Knowledge Transfer,"Pratik Vaishnavi, Kevin Eykholt, Amir Rahmati",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.14283"" target=""_blank"">2210.14283</a>",,2025-12-03 22:39:25
Causal Information Bottleneck Boosts Adversarial Robustness of Deep Neural Network,"Huan Hua, Jun Yan, Xi Fang, Weiquan Huang, Huilin Yin, Wancheng Ge",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.14229"" target=""_blank"">2210.14229</a>",,2025-12-03 22:39:25
Towards Robust Recommender Systems via Triple Cooperative Defense,"Qingyang Wang, Defu Lian, Chenwang Wu, Enhong Chen",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.13762"" target=""_blank"">2210.13762</a>",,2025-12-03 22:39:25
Towards Formal Approximated Minimal Explanations of Neural Networks,"Shahaf Bassan, Guy Katz",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.13915"" target=""_blank"">2210.13915</a>",,2025-12-03 22:39:25
FocusedCleaner: Sanitizing Poisoned Graphs for Robust GNN-based Node Classification,"Yulin Zhu, Liang Tong, Kai Zhou",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.13815"" target=""_blank"">2210.13815</a>",,2025-12-03 22:39:25
Robustness of Locally Differentially Private Graph Analysis Against Poisoning,"Jacob Imola, Amrita Roy Chowdhury, Kamalika Chaudhuri",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.14376"" target=""_blank"">2210.14376</a>",,2025-12-03 22:39:25
Ares: A System-Oriented Wargame Framework for Adversarial ML,"Farhan Ahmed, Pratik Vaishnavi, Kevin Eykholt, Amir Rahmati",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.12952"" target=""_blank"">2210.12952</a>",,2025-12-03 22:39:25
SpacePhish: The Evasion-space of Adversarial Attacks against Phishing Website Detectors using Machine Learning,"Giovanni Apruzzese, Mauro Conti, Ying Yuan",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.13660"" target=""_blank"">2210.13660</a>",,2025-12-03 22:39:25
Motif-Backdoor: Rethinking the Backdoor Attack on Graph Neural Networks via Motifs,"Haibin Zheng, Haiyang Xiong, Jinyin Chen, Haonan Ma, Guohan Huang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.13710"" target=""_blank"">2210.13710</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness with Self-Paced Hard-Class Pair Reweighting,"Pengyue Hou, Jie Han, Xingyu Li",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15068"" target=""_blank"">2210.15068</a>",,2025-12-03 22:39:25
Domain Adaptive Object Detection for Autonomous Driving under Foggy Weather,"Jinlong Li, Runsheng Xu, Jin Ma, Qin Zou, Jiaqi Ma, Hongkai Yu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15176"" target=""_blank"">2210.15176</a>","<a href=""https://github.com/jinlong17/DA-Detect"" target=""_blank"">jinlong17</a>",2025-12-03 22:39:25
Noise Injection Node Regularization for Robust Learning,"Noam Levi, Itay M. Bloch, Marat Freytsis, Tomer Volansky",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15764"" target=""_blank"">2210.15764</a>",,2025-12-03 22:39:25
Efficient and Effective Augmentation Strategy for Adversarial Training,"Sravanti Addepalli, Samyak Jain, R. Venkatesh Babu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15318"" target=""_blank"">2210.15318</a>","<a href=""https://github.com/val-iisc/DAJAT"" target=""_blank"">val-iisc</a>",2025-12-03 22:39:25
Fine-mixing: Mitigating Backdoors in Fine-tuned Language Models,"Zhiyuan Zhang, Lingjuan Lyu, Xingjun Ma, Chenguang Wang, Xu Sun",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.09545"" target=""_blank"">2210.09545</a>",,2025-12-03 22:39:25
"SoK: Modeling Explainability in Security Analytics for Interpretability, Trustworthiness, and Usability","Dipkamal Bhusal, Rosalyn Shin, Ajay Ashok Shewale, Monish Kumar Manikya Veerabhadran, Michael Clifford, Sara Rampazzi, Nidhi Rastogi",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.17376"" target=""_blank"">2210.17376</a>",,2025-12-03 22:39:25
Preventing Verbatim Memorization in Language Models Gives a False Sense of Privacy,"Daphne Ippolito, Florian Tramèr, Milad Nasr, Chiyuan Zhang, Matthew Jagielski, Katherine Lee, Christopher A. Choquette-Choo, Nicholas Carlini",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.17546"" target=""_blank"">2210.17546</a>",,2025-12-03 22:39:25
Poison Attack and Defense on Deep Source Code Processing Models,"Jia Li, Zhuo Li, Huangzhao Zhang, Ge Li, Zhi Jin, Xing Hu, Xin Xia",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.17029"" target=""_blank"">2210.17029</a>",,2025-12-03 22:39:25
Character-level White-Box Adversarial Attacks against Transformers via Attachable Subwords Substitution,"Aiwei Liu, Honghai Yu, Xuming Hu, Shu'ang Li, Li Lin, Fukun Ma, Yawen Yang, Lijie Wen",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.17004"" target=""_blank"">2210.17004</a>",,2025-12-03 22:39:25
Scoring Black-Box Models for Adversarial Robustness,"Jian Vora, Pranay Reddy Samala",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.17140"" target=""_blank"">2210.17140</a>",,2025-12-03 22:39:25
Benchmarking Adversarial Patch Against Aerial Detection,"Jiawei Lian, Shaohui Mei, Shun Zhang, Mingyang Ma",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.16765"" target=""_blank"">2210.16765</a>","<a href=""https://github.com/JiaweiLian/AP-PA"" target=""_blank"">JiaweiLian</a>",2025-12-03 22:39:25
Symmetric Saliency-based Adversarial Attack To Speaker Identification,"Jiadi Yao, Xing Chen, Xiao-Lei Zhang, Wei-Qiang Zhang, Kunde Yang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.16777"" target=""_blank"">2210.16777</a>",,2025-12-03 22:39:25
FI-ODE: Certified and Robust Forward Invariance in Neural ODEs,"Yujia Huang, Ivan Dario Jimenez Rodriguez, Huan Zhang, Yuanyuan Shi, Yisong Yue",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.16940"" target=""_blank"">2210.16940</a>",,2025-12-03 22:39:25
Imitating Opponent to Win: Adversarial Policy Imitation Learning in Two-player Competitive Games,"The Viet Bui, Tien Mai, Thanh H. Nguyen",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.16915"" target=""_blank"">2210.16915</a>",,2025-12-03 22:39:25
On the Need of Neuromorphic Twins to Detect Denial-of-Service Attacks on Communication Networks,"Holger Boche, Rafael F. Schaefer, H. Vincent Poor, Frank H. P. Fitzek",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.16690"" target=""_blank"">2210.16690</a>",,2025-12-03 22:39:25
Universal Adversarial Directions,"Ching Lam Choi, Farzan Farnia",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15997"" target=""_blank"">2210.15997</a>",,2025-12-03 22:39:25
Improving the Transferability of Adversarial Attacks on Face Recognition with Beneficial Perturbation Feature Augmentation,"Fengfan Zhou, Hefei Ling, Yuxuan Shi, Jiazhong Chen, Zongyi Li, Ping Li",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.16117"" target=""_blank"">2210.16117</a>",,2025-12-03 22:39:25
Improving Hyperspectral Adversarial Robustness Under Multiple Attacks,"Nicholas Soucy, Salimeh Yasaei Sekeh",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.16346"" target=""_blank"">2210.16346</a>",,2025-12-03 22:39:25
Distributed Black-box Attack against Image Classification Cloud Services,"Han Wu, Sareh Rowlands, Johan Wahlstrom",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.16371"" target=""_blank"">2210.16371</a>",,2025-12-03 22:39:25
RoChBert: Towards Robust BERT Fine-tuning for Chinese,"Zihan Zhang, Jinfeng Li, Ning Shi, Bo Yuan, Xiangyu Liu, Rong Zhang, Hui Xue, Donghong Sun, Chao Zhang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15944"" target=""_blank"">2210.15944</a>",,2025-12-03 22:39:25
Robust Boosting Forests with Richer Deep Feature Hierarchy,Jianqiao Wangni,arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.16451"" target=""_blank"">2210.16451</a>",,2025-12-03 22:39:25
Localized Randomized Smoothing for Collective Robustness Certification,"Jan Schuchardt, Tom Wollschläger, Aleksandar Bojchevski, Stephan Günnemann",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.16140"" target=""_blank"">2210.16140</a>",,2025-12-03 22:39:25
On the Vulnerability of Data Points under Multiple Membership Inference Attacks and Target Models,"Mauro Conti, Jiaxin Li, Stjepan Picek",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.16258"" target=""_blank"">2210.16258</a>",,2025-12-03 22:39:25
TAD: Transfer Learning-based Multi-Adversarial Detection of Evasion Attacks against Network Intrusion Detection Systems,"Islam Debicha, Richard Bauwens, Thibault Debatty, Jean-Michel Dricot, Tayeb Kenaza, Wim Mees",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15700"" target=""_blank"">2210.15700</a>",,2025-12-03 22:39:25
Isometric 3D Adversarial Examples in the Physical World,"Yibo Miao, Yinpeng Dong, Jun Zhu, Xiao-Shan Gao",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15291"" target=""_blank"">2210.15291</a>",,2025-12-03 22:39:25
LeNo: Adversarial Robust Salient Object Detection Networks with Learnable Noise,"He Tang, He Wang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15392"" target=""_blank"">2210.15392</a>",,2025-12-03 22:39:25
TASA: Deceiving Question Answering Models by Twin Answer Sentences Attack,"Yu Cao, Dianqi Li, Meng Fang, Tianyi Zhou, Jun Gao, Yibing Zhan, Dacheng Tao",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15221"" target=""_blank"">2210.15221</a>",,2025-12-03 22:39:25
On the Robustness of Dataset Inference,"Sebastian Szyller, Rui Zhang, Jian Liu, N. Asokan",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.13631"" target=""_blank"">2210.13631</a>",,2025-12-03 22:39:25
Towards Reliable Neural Specifications,"Chuqin Geng, Nham Le, Xiaojie Xu, Zhaoyue Wang, Arie Gurfinkel, Xujie Si",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.16114"" target=""_blank"">2210.16114</a>",,2025-12-03 22:39:25
Revisiting Sparse Convolutional Model for Visual Recognition,"Xili Dai, Mingyang Li, Pengyuan Zhai, Shengbang Tong, Xingjian Gao, Shao-Lun Huang, Zhihui Zhu, Chong You, Yi Ma",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.12945"" target=""_blank"">2210.12945</a>","<a href=""https://github.com/Delay-Xili/SDNet"" target=""_blank"">Delay-Xili</a>",2025-12-03 22:39:25
No-Box Attacks on 3D Point Cloud Classification,"Hanieh Naderi, Chinthaka Dinesh, Ivan V. Bajic, Shohreh Kasaei",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.14164"" target=""_blank"">2210.14164</a>",,2025-12-03 22:39:25
Chaos Theory and Adversarial Robustness,Jonathan S. Kent,arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.13235"" target=""_blank"">2210.13235</a>",,2025-12-03 22:39:25
Emerging Threats in Deep Learning-Based Autonomous Driving: A Comprehensive Survey,"Hui Cao, Wenlong Zou, Yinkun Wang, Ting Song, Mengjun Liu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11237"" target=""_blank"">2210.11237</a>",,2025-12-03 22:39:25
Why Should Adversarial Perturbations be Imperceptible? Rethink the Research Paradigm in Adversarial NLP,"Yangyi Chen, Hongcheng Gao, Ganqu Cui, Fanchao Qi, Longtao Huang, Zhiyuan Liu, Maosong Sun",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.10683"" target=""_blank"">2210.10683</a>","<a href=""https://github.com/thunlp/Advbench"" target=""_blank"">thunlp</a>",2025-12-03 22:39:25
FedRecover: Recovering from Poisoning Attacks in Federated Learning using Historical Information,"Xiaoyu Cao, Jinyuan Jia, Zaixi Zhang, Neil Zhenqiang Gong",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.10936"" target=""_blank"">2210.10936</a>",,2025-12-03 22:39:25
Learning to Invert: Simple Adaptive Attacks for Gradient Inversion in Federated Learning,"Ruihan Wu, Xiangyu Chen, Chuan Guo, Kilian Q. Weinberger",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.10880"" target=""_blank"">2210.10880</a>",,2025-12-03 22:39:25
Variational Model Perturbation for Source-Free Domain Adaptation,"Mengmeng Jing, Xiantong Zhen, Jingjing Li, Cees G. M. Snoek",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.10378"" target=""_blank"">2210.10378</a>",,2025-12-03 22:39:25
Scaling Adversarial Training to Large Perturbation Bounds,"Sravanti Addepalli, Samyak Jain, Gaurang Sriramanan, R. Venkatesh Babu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.09852"" target=""_blank"">2210.09852</a>",,2025-12-03 22:39:25
Not All Poisons are Created Equal: Robust Training against Data Poisoning,"Yu Yang, Tian Yu Liu, Baharan Mirzasoleiman",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.09671"" target=""_blank"">2210.09671</a>",,2025-12-03 22:39:25
ROSE: Robust Selective Fine-tuning for Pre-trained Language Models,"Lan Jiang, Hao Zhou, Yankai Lin, Peng Li, Jie Zhou, Rui Jiang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.09658"" target=""_blank"">2210.09658</a>","<a href=""https://github.com/jiangllan/ROSE"" target=""_blank"">jiangllan</a>",2025-12-03 22:39:25
Analysis of Master Vein Attacks on Finger Vein Recognition Systems,"Huy H. Nguyen, Trung-Nghia Le, Junichi Yamagishi, Isao Echizen",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.10667"" target=""_blank"">2210.10667</a>",,2025-12-03 22:39:25
On the Adversarial Robustness of Mixture of Experts,"Joan Puigcerver, Rodolphe Jenatton, Carlos Riquelme, Pranjal Awasthi, Srinadh Bhojanapalli",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.10253"" target=""_blank"">2210.10253</a>",,2025-12-03 22:39:25
Transferable Unlearnable Examples,"Jie Ren, Han Xu, Yuxuan Wan, Xingjun Ma, Lichao Sun, Jiliang Tang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.10114"" target=""_blank"">2210.10114</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness by Contrastive Guided Diffusion Process,"Yidong Ouyang, Liyan Xie, Guang Cheng",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.09643"" target=""_blank"">2210.09643</a>",,2025-12-03 22:39:25
Towards Generating Adversarial Examples on Mixed-type Data,"Han Xu, Menghai Pan, Zhimeng Jiang, Huiyuan Chen, Xiaoting Li, Mahashweta Das, Hao Yang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.09405"" target=""_blank"">2210.09405</a>",,2025-12-03 22:39:25
Differential Evolution based Dual Adversarial Camouflage: Fooling Human Eyes and Object Detectors,"Jialiang Sun, Tingsong Jiang, Wen Yao, Donghua Wang, Xiaoqian Chen",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.08870"" target=""_blank"">2210.08870</a>",,2025-12-03 22:39:25
Probabilistic Categorical Adversarial Attack & Adversarial Training,"Pengfei He, Han Xu, Jie Ren, Yuxuan Wan, Zitao Liu, Jiliang Tang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.09364"" target=""_blank"">2210.09364</a>",,2025-12-03 22:39:25
Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class,"Khoa D. Doan, Yingjie Lao, Ping Li",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.09194"" target=""_blank"">2210.09194</a>",,2025-12-03 22:39:25
DE-CROP: Data-efficient Certified Robustness for Pretrained Classifiers,"Gaurav Kumar Nayak, Ruchit Rawal, Anirban Chakraborty",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.08929"" target=""_blank"">2210.08929</a>",,2025-12-03 22:39:25
Beyond Model Interpretability: On the Faithfulness and Adversarial Robustness of Contrastive Textual Explanations,"Julia El Zini, Mariette Awad",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.08902"" target=""_blank"">2210.08902</a>",,2025-12-03 22:39:25
You Can't See Me: Physical Removal Attacks on LiDAR-based Autonomous Vehicles Driving Frameworks,"Yulong Cao, S. Hrushikesh Bhupathiraju, Pirouz Naghavi, Takeshi Sugawara, Z. Morley Mao, Sara Rampazzi",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.09482"" target=""_blank"">2210.09482</a>",,2025-12-03 22:39:25
FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning,"Kaiyuan Zhang, Guanhong Tao, Qiuling Xu, Siyuan Cheng, Shengwei An, Yingqi Liu, Shiwei Feng, Guangyu Shen, Pin-Yu Chen, Shiqing Ma, Xiangyu Zhang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.12873"" target=""_blank"">2210.12873</a>",,2025-12-03 22:39:25
Towards Fair Classification against Poisoning Attacks,"Han Xu, Xiaorui Liu, Yuxuan Wan, Jiliang Tang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.09503"" target=""_blank"">2210.09503</a>",,2025-12-03 22:39:25
Deepfake Text Detection: Limitations and Opportunities,"Jiameng Pu, Zain Sarwar, Sifat Muhammad Abdullah, Abdullah Rehman, Yoonjin Kim, Parantapa Bhattacharya, Mobin Javed, Bimal Viswanath",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.09421"" target=""_blank"">2210.09421</a>",,2025-12-03 22:39:25
Backdoor Attack and Defense in Federated Generative Adversarial Network-based Medical Image Synthesis,"Ruinan Jin, Xiaoxiao Li",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.10886"" target=""_blank"">2210.10886</a>",,2025-12-03 22:39:25
Automatic Detection of Fake Key Attacks in Secure Messaging,"Tarun Kumar Yadav, Devashish Gosain, Amir Herzberg, Daniel Zappala, Kent Seamons",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.09940"" target=""_blank"">2210.09940</a>",,2025-12-03 22:39:25
Effective Targeted Attacks for Adversarial Self-Supervised Learning,"Minseon Kim, Hyeonjeong Ha, Sooel Son, Sung Ju Hwang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.10482"" target=""_blank"">2210.10482</a>",,2025-12-03 22:39:25
Identifying Human Strategies for Generating Word-Level Adversarial Examples,"Maximilian Mozes, Bennett Kleinberg, Lewis D. Griffin",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11598"" target=""_blank"">2210.11598</a>",,2025-12-03 22:39:25
"Adversarial Pretraining of Self-Supervised Deep Networks: Past, Present and Future","Guo-Jun Qi, Mubarak Shah",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.13463"" target=""_blank"">2210.13463</a>",,2025-12-03 22:39:25
Hindering Adversarial Attacks with Implicit Neural Representations,"Andrei A. Rusu, Dan A. Calian, Sven Gowal, Raia Hadsell",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.13982"" target=""_blank"">2210.13982</a>","<a href=""https://github.com/deepmind/linac"" target=""_blank"">deepmind</a>",2025-12-03 22:39:25
GANI: Global Attacks on Graph Neural Networks via Imperceptible Node Injections,"Junyuan Fang, Haixian Wen, Jiajing Wu, Qi Xuan, Zibin Zheng, Chi K. Tse",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.12598"" target=""_blank"">2210.12598</a>",,2025-12-03 22:39:25
Learning Transferable Adversarial Robust Representations via Multi-view Consistency,"Minseon Kim, Hyeonjeong Ha, Dong Bok Lee, Sung Ju Hwang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.10485"" target=""_blank"">2210.10485</a>",,2025-12-03 22:39:25
Nash Equilibria and Pitfalls of Adversarial Training in Adversarial Robustness Games,"Maria-Florina Balcan, Rattana Pukdee, Pradeep Ravikumar, Hongyang Zhang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.12606"" target=""_blank"">2210.12606</a>",,2025-12-03 22:39:25
Precisely the Point: Adversarial Augmentations for Faithful and Informative Text Generation,"Wenhao Wu, Wei Li, Jiachen Liu, Xinyan Xiao, Sujian Li, Yajuan Lyu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.12367"" target=""_blank"">2210.12367</a>",,2025-12-03 22:39:25
Evolution of Neural Tangent Kernels under Benign and Adversarial Training,"Noel Loo, Ramin Hasani, Alexander Amini, Daniela Rus",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.12030"" target=""_blank"">2210.12030</a>",,2025-12-03 22:39:25
The Dark Side of AutoML: Towards Architectural Backdoor Search,"Ren Pang, Changjiang Li, Zhaohan Xi, Shouling Ji, Ting Wang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.12179"" target=""_blank"">2210.12179</a>",,2025-12-03 22:39:25
TCAB: A Large-Scale Text Classification Attack Benchmark,"Kalyani Asthana, Zhouhang Xie, Wencong You, Adam Noack, Jonathan Brophy, Sameer Singh, Daniel Lowd",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.12233"" target=""_blank"">2210.12233</a>","<a href=""https://react-nlp.github.io/tcab/"" target=""_blank"">tcab</a>",2025-12-03 22:39:25
A critical review of cyber-physical security for building automation systems,"Guowen Li, Lingyu Ren, Yangyang Fu, Zhiyao Yang, Veronica Adetola, Jin Wen, Qi Zhu, Teresa Wu, K. Selcuk Candanf, Zheng O'Neill",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11726"" target=""_blank"">2210.11726</a>",,2025-12-03 22:39:25
Extracted BERT Model Leaks More Information than You Think! (1%),"Xuanli He, Chen Chen, Lingjuan Lyu, Qiongkai Xu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11735"" target=""_blank"">2210.11735</a>",,2025-12-03 22:39:25
Diffusion Visual Counterfactual Explanations,"Maximilian Augustin, Valentyn Boreiko, Francesco Croce, Matthias Hein",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11841"" target=""_blank"">2210.11841</a>",,2025-12-03 22:39:25
ADDMU: Detection of Far-Boundary Adversarial Examples with Data and Model Uncertainty Estimation,"Fan Yin, Yao Li, Cho-Jui Hsieh, Kai-Wei Chang",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.12396"" target=""_blank"">2210.12396</a>",,2025-12-03 22:39:25
Similarity of Neural Architectures using Adversarial Attack Transferability,"Jaehui Hwang, Dongyoon Han, Byeongho Heo, Song Park, Sanghyuk Chun, Jong-Seok Lee",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11407"" target=""_blank"">2210.11407</a>",,2025-12-03 22:39:25
Are You Stealing My Model? Sample Correlation for Fingerprinting Deep Neural Networks,"Jiyang Guan, Jian Liang, Ran He",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.15427"" target=""_blank"">2210.15427</a>","<a href=""https://github.com/guanjiyang/SAC"" target=""_blank"">guanjiyang</a>",2025-12-03 22:39:25
Analyzing the Robustness of Decentralized Horizontal and Vertical Federated Learning Architectures in a Non-IID Scenario,"Pedro Miguel Sánchez Sánchez, Alberto Huertas Celdrán, Enrique Tomás Martínez Beltrán, Daniel Demeter, Gérôme Bovet, Gregorio Martínez Pérez, Burkhard Stiller",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11061"" target=""_blank"">2210.11061</a>",,2025-12-03 22:39:25
Attacking Motion Estimation with Adversarial Snow,"Jenny Schmalfuss, Lukas Mehl, Andrés Bruhn",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11242"" target=""_blank"">2210.11242</a>",,2025-12-03 22:39:25
Apple of Sodom: Hidden Backdoors in Superior Sentence Embeddings via Contrastive Learning,"Xiaoyi Chen, Baisong Xin, Shengfang Zhai, Shiqing Ma, Qingni Shen, Zhonghai Wu",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11082"" target=""_blank"">2210.11082</a>",,2025-12-03 22:39:25
New data poison attacks on machine learning classifiers for mobile exfiltration,"Miguel A. Ramirez, Sangyoung Yoon, Ernesto Damiani, Hussam Al Hamadi, Claudio Agostino Ardagna, Nicola Bena, Young-Ji Byon, Tae-Yeon Kim, Chung-Suk Cho, Chan Yeob Yeun",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11592"" target=""_blank"">2210.11592</a>",,2025-12-03 22:39:25
How Does a Deep Learning Model Architecture Impact Its Privacy? A Comprehensive Study of Privacy Attacks on CNNs and Transformers,"Guangsheng Zhang, Bo Liu, Huan Tian, Tianqing Zhu, Ming Ding, Wanlei Zhou",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11049"" target=""_blank"">2210.11049</a>",,2025-12-03 22:39:25
LOT: Layer-wise Orthogonal Training on Improving $\ell_2$ Certified Robustness,"Xiaojun Xu, Linyi Li, Bo Li",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11620"" target=""_blank"">2210.11620</a>",,2025-12-03 22:39:25
Learning Sample Reweighting for Accuracy and Adversarial Robustness,"Chester Holtz, Tsui-Wei Weng, Gal Mishne",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11513"" target=""_blank"">2210.11513</a>",,2025-12-03 22:39:25
Balanced Adversarial Training: Balancing Tradeoffs between Fickleness and Obstinacy in NLP Models,"Hannah Chen, Yangfeng Ji, David Evans",arXiv,2022-10,"<a href=""http://arxiv.org/abs/2210.11498"" target=""_blank"">2210.11498</a>",,2025-12-03 22:39:25
Robust and Lossless Fingerprinting of Deep Neural Networks via Pooled Membership Inference,Hanzhou Wu,arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.04113"" target=""_blank"">2209.04113</a>",,2025-12-03 22:39:25
Scattering Model Guided Adversarial Examples for SAR Target Recognition: Attack and Defense,"Bowen Peng, Bo Peng, Jie Zhou, Jianyue Xie, Li Liu",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.04779"" target=""_blank"">2209.04779</a>",,2025-12-03 22:39:25
Generate novel and robust samples from data: accessible sharing without privacy concerns,"David Banh, Alan Huang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.06113"" target=""_blank"">2209.06113</a>",,2025-12-03 22:39:25
Defend Data Poisoning Attacks on Voice Authentication,"Ke Li, Cameron Baird, Dan Lin",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.04547"" target=""_blank"">2209.04547</a>",,2025-12-03 22:39:25
Robust-by-Design Classification via Unitary-Gradient Neural Networks,"Fabio Brau, Giulio Rossolini, Alessandro Biondi, Giorgio Buttazzo",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.04293"" target=""_blank"">2209.04293</a>",,2025-12-03 22:39:25
The Space of Adversarial Strategies,"Ryan Sheatsley, Blaine Hoak, Eric Pauley, Patrick McDaniel",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.04521"" target=""_blank"">2209.04521</a>",,2025-12-03 22:39:25
Securing the Spike: On the Transferabilty and Security of Spiking Neural Networks to Adversarial Examples,"Nuo Xu, Kaleel Mahmood, Haowen Fang, Ethan Rathbun, Caiwen Ding, Wujie Wen",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.03358"" target=""_blank"">2209.03358</a>",,2025-12-03 22:39:25
Saliency Guided Adversarial Training for Learning Generalizable Features with Applications to Medical Imaging Classification System,"Xin Li, Yao Qiang, Chengyin Li, Sijia Liu, Dongxiao Zhu",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.04326"" target=""_blank"">2209.04326</a>",,2025-12-03 22:39:25
Incorporating Locality of Images to Generate Targeted Transferable Adversarial Examples,"Zhipeng Wei, Jingjing Chen, Zuxuan Wu, Yu-Gang Jiang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.03716"" target=""_blank"">2209.03716</a>",,2025-12-03 22:39:25
Unraveling the Connections between Privacy and Certified Robustness in Federated Learning Against Poisoning Attacks,"Chulin Xie, Yunhui Long, Pin-Yu Chen, Qinbin Li, Arash Nourian, Sanmi Koyejo, Bo Li",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.04030"" target=""_blank"">2209.04030</a>",,2025-12-03 22:39:25
A Survey of Recent Advances in Deep Learning Models for Detecting Malware in Desktop and Mobile Platforms,"Pascal Maniriho, Abdun Naser Mahmood, Mohammad Jabed Morshed Chowdhury",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.03622"" target=""_blank"">2209.03622</a>",,2025-12-03 22:39:25
Reward Delay Attacks on Deep Reinforcement Learning,"Anindya Sarkar, Jiarui Feng, Yevgeniy Vorobeychik, Christopher Gill, Ning Zhang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.03540"" target=""_blank"">2209.03540</a>",,2025-12-03 22:39:25
Resisting Deep Learning Models Against Adversarial Attack Transferability via Feature Randomization,"Ehsan Nowroozi, Mohammadreza Mohammadi, Pargol Golmohammadi, Yassine Mekdad, Mauro Conti, Selcuk Uluagac",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.04930"" target=""_blank"">2209.04930</a>",,2025-12-03 22:39:25
FADE: Enabling Large-Scale Federated Adversarial Training on Resource-Constrained Edge Devices,"Minxue Tang, Jianyi Zhang, Mingyuan Ma, Louis DiValentin, Aolin Ding, Amin Hassanzadeh, Hai Li, Yiran Chen",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.03839"" target=""_blank"">2209.03839</a>",,2025-12-03 22:39:25
On the Transferability of Adversarial Examples between Encrypted Models,"Miki Tanaka, Isao Echizen, Hitoshi Kiya",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02997"" target=""_blank"">2209.02997</a>",,2025-12-03 22:39:25
Evaluating the Security of Aircraft Systems,"Edan Habler, Ron Bitton, Asaf Shabtai",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.04028"" target=""_blank"">2209.04028</a>",,2025-12-03 22:39:25
Defense against Privacy Leakage in Federated Learning,"Jing Wu, Munawar Hayat, Mingyi Zhou, Mehrtash Harandi",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.05724"" target=""_blank"">2209.05724</a>",,2025-12-03 22:39:25
Class-Level Logit Perturbation,"Mengyang Li, Fengguang Su, Ou Wu, Ji Zhang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.05668"" target=""_blank"">2209.05668</a>","<a href=""https://github.com/limengyang1992/lpl"" target=""_blank"">limengyang1992</a>",2025-12-03 22:39:25
Holistic Segmentation,"Stefano Gasperini, Alvaro Marcos-Ramiro, Michael Schmidt, Nassir Navab, Benjamin Busam, Federico Tombari",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.05407"" target=""_blank"">2209.05407</a>",,2025-12-03 22:39:25
Robust Constrained Reinforcement Learning,"Yue Wang, Fei Miao, Shaofeng Zou",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.06866"" target=""_blank"">2209.06866</a>",,2025-12-03 22:39:25
Adversarial Coreset Selection for Efficient Robust Training,"Hadi M. Dolatabadi, Sarah Erfani, Christopher Leckie",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.05785"" target=""_blank"">2209.05785</a>",,2025-12-03 22:39:25
Why So Toxic? Measuring and Triggering Toxic Behavior in Open-Domain Chatbots,"Wai Man Si, Michael Backes, Jeremy Blackburn, Cristofaro Emiliano De, Gianluca Stringhini, Savvas Zannettou, Yand Zhang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.03463"" target=""_blank"">2209.03463</a>",,2025-12-03 22:39:25
TSFool: Crafting Highly-Imperceptible Adversarial Time Series through Multi-Objective Attack,"Yanyun Wang, Dehui Du, Haibo Hu, Zi Liang, Yuanhao Liu",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.06388"" target=""_blank"">2209.06388</a>",,2025-12-03 22:39:25
PINCH: An Adversarial Extraction Attack Framework for Deep Learning Models,"William Hackett, Stefan Trawicki, Zhengxin Yu, Neeraj Suri, Peter Garraghan",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.06300"" target=""_blank"">2209.06300</a>",,2025-12-03 22:39:25
Certified Defences Against Adversarial Patch Attacks on Semantic Segmentation,"Maksym Yatsura, Kaspar Sakmann, N. Grace Hua, Matthias Hein, Jan Hendrik Metzen",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.05980"" target=""_blank"">2209.05980</a>",,2025-12-03 22:39:25
Adversarial Inter-Group Link Injection Degrades the Fairness of Graph Neural Networks,"Hussain Hussain, Meng Cao, Sandipan Sikdar, Denis Helic, Elisabeth Lex, Markus Strohmaier, Roman Kern",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.05957"" target=""_blank"">2209.05957</a>",,2025-12-03 22:39:25
ADMM based Distributed State Observer Design under Sparse Sensor Attacks,"Vinaya Mary Prinse, Rachel Kalpana Kalaimani",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.06292"" target=""_blank"">2209.06292</a>",,2025-12-03 22:39:25
A Tale of HodgeRank and Spectral Method: Target Attack Against Rank Aggregation Is the Fixed Point of Adversarial Game,"Ke Ma, Qianqian Xu, Jinshan Zeng, Guorong Li, Xiaochun Cao, Qingming Huang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.05742"" target=""_blank"">2209.05742</a>",,2025-12-03 22:39:25
Federated Learning based on Defending Against Data Poisoning Attacks in IoT,"Jiayin Li, Wenzhong Guo, Xingshuo Han, Jianping Cai, Ximeng Liu",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.06397"" target=""_blank"">2209.06397</a>",,2025-12-03 22:39:25
Adaptive Perturbation Generation for Multiple Backdoors Detection,"Yuhang Wang, Huafeng Shi, Rui Min, Ruijia Wu, Siyuan Liang, Yichao Wu, Ding Liang, Aishan Liu",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.05244"" target=""_blank"">2209.05244</a>",,2025-12-03 22:39:25
CARE: Certifiably Robust Learning with Reasoning via Variational Inference,"Jiawei Zhang, Linyi Li, Ce Zhang, Bo Li",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.05055"" target=""_blank"">2209.05055</a>",,2025-12-03 22:39:25
Sample Complexity of an Adversarial Attack on UCB-based Best-arm Identification Policy,Varsha Pendyala,arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.05692"" target=""_blank"">2209.05692</a>",,2025-12-03 22:39:25
Boosting Robustness Verification of Semantic Feature Neighborhoods,"Anan Kabaha, Dana Drachsler-Cohen",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.05446"" target=""_blank"">2209.05446</a>",,2025-12-03 22:39:25
Semantic-Preserving Adversarial Code Comprehension,"Yiyang Li, Hongqiu Wu, Hai Zhao",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.05130"" target=""_blank"">2209.05130</a>",,2025-12-03 22:39:25
Fact-Saboteurs: A Taxonomy of Evidence Manipulation Attacks against Fact-Verification Systems,"Sahar Abdelnabi, Mario Fritz",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.03755"" target=""_blank"">2209.03755</a>",,2025-12-03 22:39:25
Impact of Scaled Image on Robustness of Deep Neural Networks,"Chengyin Hu, Weiwen Shi",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02132"" target=""_blank"">2209.02132</a>",,2025-12-03 22:39:25
Physics-Guided Adversarial Machine Learning for Aircraft Systems Simulation,"Houssem Ben Braiek, Thomas Reid, Foutse Khomh",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.03431"" target=""_blank"">2209.03431</a>",,2025-12-03 22:39:25
An Adaptive Black-box Defense against Trojan Attacks (TrojDef),"Guanxiong Liu, Abdallah Khreishah, Fatima Sharadgah, Issa Khalil",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.01721"" target=""_blank"">2209.01721</a>",,2025-12-03 22:39:25
Synergistic Redundancy: Towards Verifiable Safety for Autonomous Vehicles,"Ayoosh Bansal, Simon Yu, Hunmin Kim, Bo Li, Naira Hovakimyan, Marco Caccamo, Lui Sha",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.01710"" target=""_blank"">2209.01710</a>",,2025-12-03 22:39:25
Adversarial Color Film: Effective Physical-World Attack to DNNs,"Chengyin Hu, Weiwen Shi",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02430"" target=""_blank"">2209.02430</a>",,2025-12-03 22:39:25
Property inference attack; Graph neural networks; Privacy attacks and defense; Trustworthy machine learning,"Xiuling Wang, Wendy Hui Wang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.01100"" target=""_blank"">2209.01100</a>",,2025-12-03 22:39:25
Impact of Colour Variation on Robustness of Deep Neural Networks,"Chengyin Hu, Weiwen Shi",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02832"" target=""_blank"">2209.02832</a>",,2025-12-03 22:39:25
Scalable Adversarial Attack Algorithms on Influence Maximization,"Lichao Sun, Xiaobin Rui, Wei Chen",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.00892"" target=""_blank"">2209.00892</a>",,2025-12-03 22:39:25
Are Attribute Inference Attacks Just Imputation? (31%),"Bargav Jayaraman, David Evans",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.01292"" target=""_blank"">2209.01292</a>","<a href=""https://github.com/bargavj/EvaluatingDPML"" target=""_blank"">bargavj</a>",2025-12-03 22:39:25
Explainable AI for Android Malware Detection: Towards Understanding Why the Models Perform So Well? (9%),"Yue Liu, Chakkrit Tantithamthavorn, Li Li, Yepang Liu",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.00812"" target=""_blank"">2209.00812</a>",,2025-12-03 22:39:25
Revisiting Outer Optimization in Adversarial Training,"Ali Dabouei, Fariborz Taherkhani, Sobhan Soleymani, Nasser M. Nasrabadi",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.01199"" target=""_blank"">2209.01199</a>",,2025-12-03 22:39:25
Adversarial for Social Privacy: A Poisoning Strategy to Degrade User Identity Linkage,"Jiangli Shao, Yongqing Wang, Boshen Shi, Hao Gao, Huawei Shen, Xueqi Cheng",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.00269"" target=""_blank"">2209.00269</a>",,2025-12-03 22:39:25
Universal Fourier Attack for Time Series,"Elizabeth Coda, Brad Clymer, Chance DeSmet, Yijing Watkins, Michael Girard",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.00757"" target=""_blank"">2209.00757</a>",,2025-12-03 22:39:25
Be Your Own Neighborhood: Detecting Adversarial Example by the Neighborhood Relations Built on Self-Supervised Learning,"Zhiyuan He, Yijun Yang, Pin-Yu Chen, Qiang Xu, Tsung-Yi Ho",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.00005"" target=""_blank"">2209.00005</a>",,2025-12-03 22:39:25
Unrestricted Adversarial Samples Based on Non-semantic Feature Clusters Substitution,"MingWei Zhou, Xiaobing Pei",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02406"" target=""_blank"">2209.02406</a>",,2025-12-03 22:39:25
MA-RECON: Mask-aware deep-neural-network for robust fast MRI k-space interpolation,"Nitzan Avidan, Moti Freiman",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.00462"" target=""_blank"">2209.00462</a>",,2025-12-03 22:39:25
Robustness and invariance properties of image classifiers,Apostolos Modas,arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02408"" target=""_blank"">2209.02408</a>",,2025-12-03 22:39:25
M^4I: Multi-modal Models Membership Inference,"Pingyi Hu, Zihan Wang, Ruoxi Sun, Hu Wang, Minhui Xue",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.06997"" target=""_blank"">2209.06997</a>","<a href=""https://github.com/MultimodalMI/Multimodal-membership-inference"" target=""_blank"">MultimodalMI</a>",2025-12-03 22:39:25
Hide & Seek: Seeking the (Un)-Hidden key in Provably-Secure Logic Locking Techniques,"Satwik Patnaik, Nimisha Limaye, Ozgur Sinanoglu",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.01711"" target=""_blank"">2209.01711</a>",,2025-12-03 22:39:25
Improving Out-of-Distribution Detection via Epistemic Uncertainty Adversarial Training,"Derek Everett, Andre T. Nguyen, Luke E. Richards, Edward Raff",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.03148"" target=""_blank"">2209.03148</a>",,2025-12-03 22:39:25
Hardware faults that matter: Understanding and Estimating the safety impact of hardware faults on object detection DNNs,"Syed Qutub, Florian Geissler, Yang Peng, Ralf Grafe, Michael Paulitsch, Gereon Hinz, Alois Knoll",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.03225"" target=""_blank"">2209.03225</a>",,2025-12-03 22:39:25
Federated Zero-Shot Learning for Visual Recognition,"Zhi Chen, Yadan Luo, Sen Wang, Jingjing Li, Zi Huang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.01994"" target=""_blank"">2209.01994</a>",,2025-12-03 22:39:25
MalDetConv: Automated Behaviour-based Malware Detection Framework Based on Natural Language Processing and Deep Learning Techniques,"Pascal Maniriho, Abdun Naser Mahmood, Mohammad Jabed Morshed Chowdhury",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.03547"" target=""_blank"">2209.03547</a>",,2025-12-03 22:39:25
Instance Attack:An Explanation-based Vulnerability Analysis Framework Against DNNs for Malware Detection,"Sun RuiJin, Guo ShiZe, Guo JinHong, Xing ChangYou, Yang LuMing, Guo Xi, Pan ZhiSong",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02453"" target=""_blank"">2209.02453</a>",,2025-12-03 22:39:25
Bag of Tricks for FGSM Adversarial Training,"Zichao Li, Li Liu, Zeyu Wang, Yuyin Zhou, Cihang Xie",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02684"" target=""_blank"">2209.02684</a>","<a href=""https://github.com/UCSC-VLAA/Bag-of-Tricks-for-FGSM-AT"" target=""_blank"">UCSC-VLAA</a>",2025-12-03 22:39:25
Improving Robustness to Out-of-Distribution Data by Frequency-based Augmentation,"Koki Mukai, Soichiro Kumano, Toshihiko Yamasaki",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02369"" target=""_blank"">2209.02369</a>",,2025-12-03 22:39:25
Defending Against Backdoor Attack on Graph Nerual Network by Explainability,"Bingchen Jiang, Zhao Li",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02902"" target=""_blank"">2209.02902</a>",,2025-12-03 22:39:25
MACAB: Model-Agnostic Clean-Annotation Backdoor to Object Detection with Natural Trigger in Real-World,"Hua Ma, Yinshan Li, Yansong Gao, Zhi Zhang, Alsharif Abuadbba, Anmin Fu, Said F. Al-Sarawi, Nepal Surya, Derek Abbott",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02339"" target=""_blank"">2209.02339</a>",,2025-12-03 22:39:25
Multimodal contrastive learning for remote sensing tasks,"Umangi Jain, Alex Wilson, Varun Gulshan",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02329"" target=""_blank"">2209.02329</a>",,2025-12-03 22:39:25
Annealing Optimization for Progressive Learning with Stochastic Approximation,"Christos Mavridis, John Baras",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02826"" target=""_blank"">2209.02826</a>",,2025-12-03 22:39:25
Interpretations Steered Network Pruning via Amortized Inferred Saliency Maps,"Alireza Ganjdanesh, Shangqian Gao, Heng Huang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02869"" target=""_blank"">2209.02869</a>","<a href=""https://github.com/Alii-Ganjj/InterpretationsSteeredPruning"" target=""_blank"">Alii-Ganjj</a>",2025-12-03 22:39:25
A Survey of Machine Unlearning,"Thanh Tam Nguyen, Thanh Trung Huynh, Phi Le Nguyen, Alan Wee-Chung Liew, Hongzhi Yin, Quoc Viet Hung Nguyen",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02299"" target=""_blank"">2209.02299</a>","<a href=""https://github.com/tamlhp/awesome-machine-unlearning"" target=""_blank"">tamlhp</a>",2025-12-03 22:39:25
Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples,"Hezekiah J. Branch, Jonathan Rodriguez Cefalu, Jeremy McHugh, Leyla Hujer, Aditya Bahl, Daniel del Castillo Iglesias, Ron Heichman, Ramesh Darwishi",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02128"" target=""_blank"">2209.02128</a>",,2025-12-03 22:39:25
White-Box Adversarial Policies in Deep Reinforcement Learning,"Stephen Casper, Taylor Killian, Gabriel Kreiman, Dylan Hadfield-Menell",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.02167"" target=""_blank"">2209.02167</a>","<a href=""https://github.com/thestephencasper/lm_white_box_attacks"" target=""_blank"">thestephencasper</a>",2025-12-03 22:39:25
"""Is your explanation stable?"": A Robustness Evaluation Framework for Feature Attribution","Yuyou Gan, Yuhao Mao, Xuhong Zhang, Shouling Ji, Yuwen Pu, Meng Han, Jianwei Yin, Ting Wang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.01782"" target=""_blank"">2209.01782</a>",,2025-12-03 22:39:25
Adversarial Detection: Attacking Object Detection in Real Time,"Han Wu, Syed Yunas, Sareh Rowlands, Wenjie Ruan, Johan Wahlstrom",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.01962"" target=""_blank"">2209.01962</a>",,2025-12-03 22:39:25
PromptAttack: Prompt-based Attack for Language Models via Gradient Search,"Yundi Shi, Piji Li, Changchun Yin, Zhaoyang Han, Lu Zhou, Zhe Liu",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.01882"" target=""_blank"">2209.01882</a>",,2025-12-03 22:39:25
Finetuning Pretrained Vision-Language Models with Correlation Information Bottleneck for Robust Visual Question Answering,"Jingjing Jiang, Ziyi Liu, Nanning Zheng",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.06954"" target=""_blank"">2209.06954</a>",,2025-12-03 22:39:25
PA-Boot: A Formally Verified Authentication Protocol for Multiprocessor Secure Boot,"Zhuoruo Zhang, Rui Chang, Mingshuai Chen, Wenbo Shen, Chenyang Yu, He Huang, Qinming Dai, Yongwang Zhao",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.07936"" target=""_blank"">2209.07936</a>",,2025-12-03 22:39:25
"On the interplay of adversarial robustness and architecture components: patches, convolution and attention","Francesco Croce, Matthias Hein",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.06953"" target=""_blank"">2209.06953</a>",,2025-12-03 22:39:25
Attacking Compressed Vision Transformers,"Swapnil Parekh, Devansh Shah, Pratyush Shukla",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.13785"" target=""_blank"">2209.13785</a>",,2025-12-03 22:39:25
Reconstruction-guided attention improves the robustness and shape processing of neural networks,"Seoyoung Ahn, Hossein Adeli, Gregory J. Zelinsky",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.13620"" target=""_blank"">2209.13620</a>",,2025-12-03 22:39:25
A Learning-based Honeypot Game for Collaborative Defense in UAV Networks,"Yuntao Wang, Zhou Su, Abderrahim Benslimane, Qichao Xu, Minghui Dai, Ruidong Li",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.13815"" target=""_blank"">2209.13815</a>",,2025-12-03 22:39:25
Measuring Overfitting in Convolutional Neural Networks using Adversarial Perturbations and Label Noise,"Svetlana Pavlitskaya, Joël Oswald, J. Marius Zöllner",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.13382"" target=""_blank"">2209.13382</a>",,2025-12-03 22:39:25
FG-UAP: Feature-Gathering Universal Adversarial Perturbation,"Zhixing Ye, Xinwen Cheng, Xiaolin Huang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.13113"" target=""_blank"">2209.13113</a>",,2025-12-03 22:39:25
Activation Learning by Local Competitions,Hongchao Zhou,arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.13400"" target=""_blank"">2209.13400</a>",,2025-12-03 22:39:25
Multi-Task Adversarial Training Algorithm for Multi-Speaker Neural Text-to-Speech,"Yusuke Nakai, Yuki Saito, Kenta Udagawa, Hiroshi Saruwatari",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.12549"" target=""_blank"">2209.12549</a>",,2025-12-03 22:39:25
Greybox XAI: a Neural-Symbolic learning framework to produce interpretable predictions for image classification,"Adrien Bennetot, Gianni Franchi, Ser Javier Del, Raja Chatila, Natalia Diaz-Rodriguez",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.14974"" target=""_blank"">2209.14974</a>",,2025-12-03 22:39:25
SPRITZ-1,"Ehsan Nowroozi, Mohammadreza Mohammadi, Erkay Savas, Mauro Conti, Yassine Mekdad",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.12195"" target=""_blank"">2209.12195</a>",,2025-12-03 22:39:25
Strong Transferable Adversarial Attacks via Ensembled Asymptotically Normal Distribution Learning,"Zhengwei Fang, Rui Wang, Tao Huang, Liping Jing",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.11964"" target=""_blank"">2209.11964</a>",,2025-12-03 22:39:25
"The ""Beatrix'' Resurrections: Robust Backdoor Detection via Gram Matrices","Wanlun Ma, Derui Wang, Ruoxi Sun, Minhui Xue, Sheng Wen, Yang Xiang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.11715"" target=""_blank"">2209.11715</a>",,2025-12-03 22:39:25
Privacy Attacks Against Biometric Models with Fewer Samples: Incorporating the Output of Multiple Models,"Sohaib Ahmad, Benjamin Fuller, Kaleel Mahmood",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.11020"" target=""_blank"">2209.11020</a>",,2025-12-03 22:39:25
Fair Robust Active Learning by Joint Inconsistency,"Tsung-Han Wu, Shang-Tse Chen, Winston H. Hsu",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.10729"" target=""_blank"">2209.10729</a>",,2025-12-03 22:39:25
Toy Models of Superposition,"Nelson Elhage, Tristan Hume, Catherine Olsson, Nicholas Schiefer, Tom Henighan, Shauna Kravec, Zac Hatfield-Dodds, Robert Lasenby, Dawn Drain, Carol Chen, Roger Grosse, Sam McCandlish, Jared Kaplan, Dario Amodei, Martin Wattenberg, Christopher Olah",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.10652"" target=""_blank"">2209.10652</a>",,2025-12-03 22:39:25
DARTSRepair: Core-failure-set Guided DARTS for Network Robustness to Common Corruptions,"Xuhong Ren, Jianlang Chen, Felix Juefei-Xu, Wanli Xue, Qing Guo, Lei Ma, Jianjun Zhao, Shengyong Chen",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.10381"" target=""_blank"">2209.10381</a>",,2025-12-03 22:39:25
Fairness Reprogramming,"Guanhua Zhang, Yihua Zhang, Yang Zhang, Wenqi Fan, Qing Li, Sijia Liu, Shiyu Chang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.10222"" target=""_blank"">2209.10222</a>","<a href=""https://github.com/UCSB-NLP-Chang/Fairness-Reprogramming"" target=""_blank"">UCSB-NLP-Chang</a>",2025-12-03 22:39:25
Mitigating Attacks on Artificial Intelligence-based Spectrum Sensing for Cellular Network Signals,"Ferhat Ozgur Catak, Murat Kuzlu, Salih Sarp, Evren Catak, Umit Cali",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.13007"" target=""_blank"">2209.13007</a>",,2025-12-03 22:39:25
Inducing Data Amplification Using Auxiliary Datasets in Adversarial Training,"Saehyung Lee, Hyungyu Lee",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.14053"" target=""_blank"">2209.14053</a>","<a href=""https://github.com/Saehyung-Lee/BiaMAT"" target=""_blank"">Saehyung-Lee</a>",2025-12-03 22:39:25
Audit and Improve Robustness of Private Neural Networks on Encrypted Data,"Jiaqi Xue, Lei Xu, Lin Chen, Weidong Shi, Kaidi Xu, Qian Lou",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.09996"" target=""_blank"">2209.09996</a>",,2025-12-03 22:39:25
Suppress with a Patch: Revisiting Universal Adversarial Patch Attacks against Object Detection,"Svetlana Pavlitskaya, Jonas Hendl, Sebastian Kleim, Leopold Müller, Fabian Wylczoch, J. Marius Zöllner",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.13353"" target=""_blank"">2209.13353</a>",,2025-12-03 22:39:25
Order-Disorder: Imitation Adversarial Attacks for Black-box Neural Ranking Models,"Jiawei Liu, Yangyang Kang, Di Tang, Kaisong Song, Changlong Sun, Xiaofeng Wang, Wei Lu, Xiaozhong Liu",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.06506"" target=""_blank"">2209.06506</a>",,2025-12-03 22:39:25
Hiding Visual Information via Obfuscating Adversarial Perturbations,"Zhigang Su, Dawei Zhou, Nannan Wangu, Decheng Li, Zhen Wang, Xinbo Gao",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.15304"" target=""_blank"">2209.15304</a>",,2025-12-03 22:39:25
Data Poisoning Attacks Against Multimodal Encoders,"Ziqing Yang, Xinlei He, Zheng Li, Michael Backes, Mathias Humbert, Pascal Berrang, Yang Zhang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.15266"" target=""_blank"">2209.15266</a>",,2025-12-03 22:39:25
Physical Adversarial Attack meets Computer Vision: A Decade Survey,"Hui Wei, Hao Tang, Xuemei Jia, Zhixiang Wang, Hanxun Yu, Zhubo Li, Shin'ichi Satoh, Gool Luc Van, Zheng Wang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.15179"" target=""_blank"">2209.15179</a>",,2025-12-03 22:39:25
Towards Lightweight Black-Box Attacks against Deep Neural Networks,"Chenghao Sun, Yonggang Zhang, Wan Chaoqun, Qizhou Wang, Ya Li, Tongliang Liu, Bo Han, Xinmei Tian",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.14826"" target=""_blank"">2209.14826</a>",,2025-12-03 22:39:25
Generalizability of Adversarial Robustness Under Distribution Shifts,"Kumail Alhamoud, Hasan Abed Al Kader Hammoud, Motasem Alfarra, Bernard Ghanem",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.15042"" target=""_blank"">2209.15042</a>",,2025-12-03 22:39:25
Digital and Physical Face Attacks: Reviewing and One Step Further,"Chenqi Kong, Shiqi Wang, Haoliang Li",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.14692"" target=""_blank"">2209.14692</a>",,2025-12-03 22:39:25
Chameleon Cache: Approximating Fully Associative Caches with Random Replacement to Prevent Contention-Based Cache Attacks,"Thomas Unterluggauer, Austin Harris, Scott Constable, Fangfei Liu, Carlos Rozas",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.14673"" target=""_blank"">2209.14673</a>",,2025-12-03 22:39:25
A Survey on Physical Adversarial Attack in Computer Vision,"Donghua Wang, Wen Yao, Tingsong Jiang, Guijian Tang, Xiaoqian Chen",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.14262"" target=""_blank"">2209.14262</a>",,2025-12-03 22:39:25
Exploring the Relationship between Architecture and Adversarially Robust Generalization,"Aishan Liu, Shiyu Tang, Siyuan Liang, Ruihao Gong, Boxi Wu, Xianglong Liu, Dacheng Tao",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.14105"" target=""_blank"">2209.14105</a>",,2025-12-03 22:39:25
A Closer Look at Evaluating the Bit-Flip Attack Against Deep Neural Networks,"Kevin Hector, Mathieu Dumont, Pierre-Alain Moellic, Jean-Max Dutertre",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.14243"" target=""_blank"">2209.14243</a>",,2025-12-03 22:39:25
Supervised Contrastive Learning as Multi-Objective Optimization for Fine-Tuning Large Pre-trained Language Models,"Youness Moukafih, Mounir Ghogho, Kamel Smaili",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.14161"" target=""_blank"">2209.14161</a>",,2025-12-03 22:39:25
On the Robustness of Random Forest Against Untargeted Data Poisoning: An Ensemble-Based Approach,"Marco Anisetti, Claudio A. Ardagna, Alessandro Balestrucci, Nicola Bena, Ernesto Damiani, Chan Yeob Yeun",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.14013"" target=""_blank"">2209.14013</a>",,2025-12-03 22:39:25
CALIP: Zero-Shot Enhancement of CLIP with Parameter-free Attention,"Ziyu Guo, Renrui Zhang, Longtian Qiu, Xianzheng Ma, Xupeng Miao, Xuming He, Bin Cui",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.14169"" target=""_blank"">2209.14169</a>",,2025-12-03 22:39:25
Improving alignment of dialogue agents via targeted human judgements,"Amelia Glaese, Nat McAleese, Maja Trębacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, Lucy Campbell-Gillingham, Jonathan Uesato, Po-Sen Huang, Ramona Comanescu, Fan Yang, Abigail See, Sumanth Dathathri, Rory Greig, Charlie Chen, Doug Fritz, Jaume Sanchez Elias, Richard Green, Soňa Mokrá, Nicholas Fernando, Boxi Wu, Rachel Foley, Susannah Young, Iason Gabriel, William Isaac, John Mellor, Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, Geoffrey Irving",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.14375"" target=""_blank"">2209.14375</a>",,2025-12-03 22:39:25
Understanding Real-world Threats to Deep Learning Models in Android Apps,"Zizhuang Deng, Kai Chen, Guozhu Meng, Xiaodong Zhang, Ke Xu, Yao Cheng",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.09577"" target=""_blank"">2209.09577</a>",,2025-12-03 22:39:25
Your Out-of-Distribution Detection Method is Not Robust! (99%),"Mohammad Azizmalayeri, Arshia Soltani Moakhar, Arman Zarei, Reihaneh Zohrabi, Mohammad Taghi Manzuri, Mohammad Hossein Rohban",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.15246"" target=""_blank"">2209.15246</a>","<a href=""https://github.com/rohban-lab/ATD"" target=""_blank"">rohban-lab</a>",2025-12-03 22:39:25
GAMA: Generative Adversarial Multi-Object Scene Attacks,"Abhishek Aich, Calvin-Khang Ta, Akash Gupta, Chengyu Song, Srikanth V. Krishnamurthy, M. Salman Asif, Amit K. Roy-Chowdhury",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.09502"" target=""_blank"">2209.09502</a>","<a href=""https://abhishekaich27.github.io/gama.html"" target=""_blank"">abhishekaich27.github.io</a>",2025-12-03 22:39:25
PointCAT: Contrastive Adversarial Training for Robust Point Cloud Recognition,"Qidong Huang, Xiaoyi Dong, Dongdong Chen, Hang Zhou, Weiming Zhang, Kui Zhang, Gang Hua, Nenghai Yu",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.07788"" target=""_blank"">2209.07788</a>",,2025-12-03 22:39:25
Dataset Inference for Self-Supervised Models,"Adam Dziedzic, Haonan Duan, Muhammad Ahmad Kaleem, Nikita Dhawan, Jonas Guan, Yannis Cattan, Franziska Boenisch, Nicolas Papernot",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.09024"" target=""_blank"">2209.09024</a>",,2025-12-03 22:39:25
On the Robustness of Graph Neural Diffusion to Topology Perturbations,"Yang Song, Qiyu Kang, Sijie Wang, Zhao Kai, Wee Peng Tay",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.07754"" target=""_blank"">2209.07754</a>",,2025-12-03 22:39:25
A Systematic Evaluation of Node Embedding Robustness,"Alexandru Mara, Jefrey Lijffijt, Stephan Günnemann, Bie Tijl De",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.08064"" target=""_blank"">2209.08064</a>",,2025-12-03 22:39:25
Improving Robust Fairness via Balance Adversarial Training,"Chunyu Sun, Chenye Xu, Chengyuan Yao, Siyuan Liang, Yichao Wu, Ding Liang, XiangLong Liu, Aishan Liu",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.07534"" target=""_blank"">2209.07534</a>",,2025-12-03 22:39:25
A Light Recipe to Train Robust Vision Transformers,"Edoardo Debenedetti, Vikash Sehwag, Prateek Mittal",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.07399"" target=""_blank"">2209.07399</a>",,2025-12-03 22:39:25
Part-Based Models Improve Adversarial Robustness,"Chawin Sitawarin, Kornrapat Pongmala, Yizheng Chen, Nicholas Carlini, David Wagner",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.09117"" target=""_blank"">2209.09117</a>","<a href=""https://github.com/chawins/adv-part-model"" target=""_blank"">chawins</a>",2025-12-03 22:39:25
Adversarially Robust Learning: A Generic Minimax Optimal Learner and Characterization,"Omar Montasser, Steve Hanneke, Nathan Srebro",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.07369"" target=""_blank"">2209.07369</a>",,2025-12-03 22:39:25
Defending Root DNS Servers Against DDoS Using Layered Defenses,"A S M Rizvi, Jelena Mirkovic, John Heidemann, Wesley Hardaker, Robert Story",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.07491"" target=""_blank"">2209.07491</a>",,2025-12-03 22:39:25
BadRes: Reveal the Backdoors through Residual Connection,"Mingrui He, Tianyu Chen, Haoyi Zhou, Shanghang Zhang, Jianxin Li",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.07125"" target=""_blank"">2209.07125</a>",,2025-12-03 22:39:25
Adversarial Cross-View Disentangled Graph Contrastive Learning,"Qianlong Wen, Zhongyu Ouyang, Chunhui Zhang, Yiyue Qian, Yanfang Ye, Chuxu Zhang",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.07699"" target=""_blank"">2209.07699</a>",,2025-12-03 22:39:25
Towards Improving Calibration in Object Detection Under Domain Shift,"Muhammad Akhtar Munir, Muhammad Haris Khan, M. Saquib Sarfraz, Mohsen Ali",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.07601"" target=""_blank"">2209.07601</a>",,2025-12-03 22:39:25
Robust Transferable Feature Extractors: Learning to Defend Pre-Trained Networks Against White Box Adversaries,"Alexander Cann, Ian Colbert, Ihab Amer",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.06931"" target=""_blank"">2209.06931</a>",,2025-12-03 22:39:25
PointACL:Adversarial Contrastive Learning for Robust Point Clouds Representation under Adversarial Attack,"Junxuan Huang, Yatong An, Lu cheng, Bai Chen, Junsong Yuan, Chunming Qiao",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.06971"" target=""_blank"">2209.06971</a>",,2025-12-03 22:39:25
Certified Robustness to Word Substitution Ranking Attack for Neural Ranking Models,"Chen Wu, Ruqing Zhang, Jiafeng Guo, Wei Chen, Yixing Fan, Rijke Maarten de, Xueqi Cheng",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.06691"" target=""_blank"">2209.06691</a>",,2025-12-03 22:39:25
Sparse Vicious Attacks on Graph Neural Networks,"Giovanni Trappolini, Valentino Maiorca, Silvio Severino, Emanuele Rodolà, Fabrizio Silvestri, Gabriele Tolomei",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.09688"" target=""_blank"">2209.09688</a>",,2025-12-03 22:39:25
Cascading Failures in Power Grids,Rounak Meyur,arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.08116"" target=""_blank"">2209.08116</a>",,2025-12-03 22:39:25
Explicit Tradeoffs between Adversarial and Natural Distributional Robustness,"Mazda Moayeri, Kiarash Banihashem, Soheil Feizi",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.07592"" target=""_blank"">2209.07592</a>",,2025-12-03 22:39:25
Model Inversion Attacks against Graph Neural Networks,"Zaixi Zhang, Qi Liu, Zhenya Huang, Hao Wang, Chee-Kong Lee, Enhong Chen",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.07807"" target=""_blank"">2209.07807</a>",,2025-12-03 22:39:25
AdvDO: Realistic Adversarial Attacks for Trajectory Prediction,"Yulong Cao, Chaowei Xiao, Anima Anandkumar, Danfei Xu, Marco Pavone",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.08744"" target=""_blank"">2209.08744</a>",,2025-12-03 22:39:25
Rethinking Data Augmentation in Knowledge Distillation for Object Detection,"Jiawei Liang, Siyuan Liang, Aishan Liu, Mingli Zhu, Danni Yuan, Chenye Xu, Xiaochun Cao",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.09841"" target=""_blank"">2209.09841</a>",,2025-12-03 22:39:25
Enhance the Visual Representation via Discrete Adversarial Training,"Xiaofeng Mao, Yuefeng Chen, Ranjie Duan, Yao Zhu, Gege Qi, Shaokai Ye, Xiaodan Li, Rong Zhang, Hui Xue",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.07735"" target=""_blank"">2209.07735</a>","<a href=""https://github.com/alibaba/easyrobust"" target=""_blank"">alibaba</a>",2025-12-03 22:39:25
Leveraging Local Patch Differences in Multi-Object Scenes for Generative Adversarial Attacks,"Abhishek Aich, Shasha Li, Chengyu Song, M. Salman Asif, Srikanth V. Krishnamurthy, Amit K. Roy-Chowdhury",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.09883"" target=""_blank"">2209.09883</a>",,2025-12-03 22:39:25
CANflict: Exploiting Peripheral Conflicts for Data-Link Layer Attacks on Automotive Networks,"Alvise de Faveri Tron, Stefano Longari, Michele Carminati, Mario Polino, Stefano Zanero",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.09557"" target=""_blank"">2209.09557</a>",,2025-12-03 22:39:25
EM-Fault It Yourself: Building a Replicable EMFI Setup for Desktop and Server Hardware,"Niclas Kühnapfel, Robert Buhren, Hans Niklas Jacob, Thilo Krachenfels, Christian Werling, Jean-Pierre Seifert",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.09835"" target=""_blank"">2209.09835</a>",,2025-12-03 22:39:25
Adversarial Color Projection: A Projector-Based Physical Attack to DNNs,"Chengyin Hu, Weiwen Shi",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.09652"" target=""_blank"">2209.09652</a>",,2025-12-03 22:39:25
On the Adversarial Transferability of ConvMixer Models,"Ryota Iijima, Miki Tanaka, Isao Echizen, Hitoshi Kiya",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.08724"" target=""_blank"">2209.08724</a>",,2025-12-03 22:39:25
"Adversarial Catoptric Light: An Effective, Stealthy and Robust Physical-World Attack to DNNs","Chengyin Hu, Weiwen Shi",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.11739"" target=""_blank"">2209.11739</a>",,2025-12-03 22:39:25
Distribution inference risks: Identifying and mitigating sources of leakage,"Valentin Hartmann, Léo Meynent, Maxime Peyrard, Dimitrios Dimitriadis, Shruti Tople, Robert West",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.08541"" target=""_blank"">2209.08541</a>",,2025-12-03 22:39:25
"Watch What You Pretrain For: Targeted, Transferable Adversarial Examples on Self-Supervised Speech Recognition models","Raphael Olivier, Hadi Abdullah, Bhiksha Raj",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.13523"" target=""_blank"">2209.13523</a>",,2025-12-03 22:39:25
Characterizing Internal Evasion Attacks in Federated Learning,"Taejin Kim, Shubhranshu Singh, Nikhil Madaan, Carlee Joe-Wong",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.08412"" target=""_blank"">2209.08412</a>",,2025-12-03 22:39:25
A study on the deviations in performance of FNNs and CNNs in the realm of grayscale adversarial images,"Durga Shree Nagabushanam, Steve Mathew, Chiranji Lal Chowdhary",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.08262"" target=""_blank"">2209.08262</a>",,2025-12-03 22:39:25
Robust Ensemble Morph Detection with Domain Generalization,"Hossein Kashiani, Shoaib Meraj Sami, Sobhan Soleymani, Nasser M. Nasrabadi",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.08130"" target=""_blank"">2209.08130</a>",,2025-12-03 22:39:25
A Large-scale Multiple-objective Method for Black-box Attack against Object Detection,"Siyuan Liang, Longkang Li, Yanbo Fan, Xiaojun Jia, Jingzhi Li, Baoyuan Wu, Xiaochun Cao",arXiv,2022-09,"<a href=""http://arxiv.org/abs/2209.07790"" target=""_blank"">2209.07790</a>","<a href=""https://github.com/LiangSiyuan21/"" target=""_blank"">LiangSiyuan21</a>",2025-12-03 22:39:25
Unifying Gradients to Improve Real-world Robustness for Deep Networks,"Yingwen Wu, Sizhe Chen, Kun Fang, Xiaolin Huang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.06228"" target=""_blank"">2208.06228</a>","<a href=""https://github.com/snowien/UniG-pytorch"" target=""_blank"">snowien</a>",2025-12-03 22:39:25
On deceiving malware classification with section injection,"Silva Adeilson Antonio da, Mauricio Pamplona Segundo",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.06092"" target=""_blank"">2208.06092</a>","<a href=""https://github.com/adeilsonsilva/malware-injection"" target=""_blank"">adeilsonsilva</a>",2025-12-03 22:39:25
A Knowledge Distillation-Based Backdoor Attack in Federated Learning,"Yifan Wang, Wei Fan, Keke Yang, Naji Alhusaini, Jing Li",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.06176"" target=""_blank"">2208.06176</a>",,2025-12-03 22:39:25
Dropout is NOT All You Need to Prevent Gradient Leakage,"Daniel Scheliga, Patrick Mäder, Marco Seeland",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.06163"" target=""_blank"">2208.06163</a>",,2025-12-03 22:39:25
Defense against Backdoor Attacks via Identifying and Purifying Bad Neurons,"Mingyuan Fan, Yang Liu, Cen Chen, Ximeng Liu, Wenzhong Guo",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.06537"" target=""_blank"">2208.06537</a>",,2025-12-03 22:39:25
PRIVEE: A Visual Analytic Workflow for Proactive Privacy Risk Inspection of Open Data,"Kaustav Bhattacharjee, Akm Islam, Jaideep Vaidya, Aritra Dasgupta",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.06481"" target=""_blank"">2208.06481</a>",,2025-12-03 22:39:25
Diverse Generative Perturbations on Attention Space for Transferable Adversarial Attacks,"Woo Jae Kim, Seunghoon Hong, Sung-Eui Yoon",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.05650"" target=""_blank"">2208.05650</a>","<a href=""https://github.com/wkim97/ADA"" target=""_blank"">wkim97</a>",2025-12-03 22:39:25
General Cutting Planes for Bound-Propagation-Based Neural Network Verification,"Huan Zhang, Shiqi Wang, Kaidi Xu, Linyi Li, Bo Li, Suman Jana, Cho-Jui Hsieh, J. Zico Kolter",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.05740"" target=""_blank"">2208.05740</a>",,2025-12-03 22:39:25
DVR: Micro-Video Recommendation Optimizing Watch-Time-Gain under Duration Bias,"Yu Zheng, Chen Gao, Jingtao Ding, Lingling Yi, Depeng Jin, Yong Li, Meng Wang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.05190"" target=""_blank"">2208.05190</a>","<a href=""https://github.com/tsinghua-fib-lab/WTG-DVR"" target=""_blank"">tsinghua-fib-lab</a>",2025-12-03 22:39:25
A Probabilistic Framework for Mutation Testing in Deep Neural Networks,"Florian Tambon, Foutse Khomh, Giuliano Antoniol",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.06018"" target=""_blank"">2208.06018</a>",,2025-12-03 22:39:25
"Safety and Performance, Why not Both? Bi-Objective Optimized Model Compression toward AI Software Deployment","Jie Zhu, Leye Wang, Xiao Han",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.05969"" target=""_blank"">2208.05969</a>",,2025-12-03 22:39:25
Shielding Federated Learning Systems against Inference Attacks with ARM TrustZone,"Aghiles Ait Messaoud, Sonia Ben Mokhtar, Vlad Nitu, Valerio Schiavoni",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.05895"" target=""_blank"">2208.05895</a>",,2025-12-03 22:39:25
Explaining Machine Learning DGA Detectors from DNS Traffic Data,"Giorgio Piras, Maura Pintor, Luca Demetrio, Battista Biggio",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.05285"" target=""_blank"">2208.05285</a>",,2025-12-03 22:39:25
A Sublinear Adversarial Training Algorithm,"Yeqi Gao, Lianke Qin, Zhao Song, Yitan Wang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.05395"" target=""_blank"">2208.05395</a>",,2025-12-03 22:39:25
Adversarial Machine Learning-Based Anticipation of Threats Against Vehicle-to-Microgrid Services,"Ahmed Omara, Burak Kantarci",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.05073"" target=""_blank"">2208.05073</a>",,2025-12-03 22:39:25
Reducing Exploitability with Population Based Training,"Pavel Czempin, Adam Gleave",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.05083"" target=""_blank"">2208.05083</a>",,2025-12-03 22:39:25
Scale-free and Task-agnostic Attack: Generating Photo-realistic Adversarial Patterns with Patch Quilting Generator,"Xiangbo Gao, Cheng Luo, Qinliang Lin, Weicheng Xie, Minmin Liu, Linlin Shen, Keerthy Kusumam, Siyang Song",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.06222"" target=""_blank"">2208.06222</a>",,2025-12-03 22:39:25
Defensive Distillation based Adversarial Attacks Mitigation Method for Channel Estimation using Deep Learning Models in Next-Generation Wireless Networks,"Ferhat Ozgur Catak, Murat Kuzlu, Evren Catak, Umit Cali, Ozgur Guler",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10279"" target=""_blank"">2208.10279</a>",,2025-12-03 22:39:25
A Context-Aware Approach for Textual Adversarial Attack through Probability Difference Guided Beam Search,"Huijun Liu, Jie Yu, Shasha Li, Jun Ma, Bin Ji",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08029"" target=""_blank"">2208.08029</a>",,2025-12-03 22:39:25
Transferable Adversarial Examples with Bayes Approach,"Mingyuan Fan, Cen Chen, Wenmeng Zhou, Yinggui Wang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.06538"" target=""_blank"">2208.06538</a>",,2025-12-03 22:39:25
MENLI: Robust Evaluation Metrics from Natural Language Inference,"Yanran Chen, Steffen Eger",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.07316"" target=""_blank"">2208.07316</a>",,2025-12-03 22:39:25
DF-Captcha: A Deepfake Captcha for Preventing Fake Calls,Yisroel Mirsky,arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08524"" target=""_blank"">2208.08524</a>",,2025-12-03 22:39:25
Analyzing Robustness of End-to-End Neural Models for Automatic Speech Recognition,"Goutham Rajendran, Wei Zou",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08509"" target=""_blank"">2208.08509</a>",,2025-12-03 22:39:25
Robust Machine Learning for Malware Detection over Time,"Daniele Angioni, Luca Demetrio, Maura Pintor, Battista Biggio",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.04838"" target=""_blank"">2208.04838</a>",,2025-12-03 22:39:25
Imperceptible and Robust Backdoor Attack in 3D Point Cloud,"Kuofeng Gao, Jiawang Bai, Baoyuan Wu, Mengxi Ya, Shu-Tao Xia",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08052"" target=""_blank"">2208.08052</a>",,2025-12-03 22:39:25
AutoCAT: Reinforcement Learning for Automated Exploration of Cache-Timing Attacks,"Mulong Luo, Wenjie Xiong, Geunbae Lee, Yueying Li, Xiaomeng Yang, Amy Zhang, Yuandong Tian, Hsien-Hsin S. Lee, G. Edward Suh",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08025"" target=""_blank"">2208.08025</a>",,2025-12-03 22:39:25
Investigating the Impact of Model Width and Density on Generalization in Presence of Label Noise,"Yihao Xue, Kyle Whitecross, Baharan Mirzasoleiman",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08003"" target=""_blank"">2208.08003</a>",,2025-12-03 22:39:25
Man-in-the-Middle Attack against Object Detection Systems,"Han Wu, Sareh Rowlands, Johan Wahlstrom",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.07174"" target=""_blank"">2208.07174</a>",,2025-12-03 22:39:25
Training-Time Attacks against k-Nearest Neighbors,"Ara Vartanian, Will Rosenbaum, Scott Alfeld",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.07272"" target=""_blank"">2208.07272</a>",,2025-12-03 22:39:25
Confidence Matters: Inspecting Backdoors in Deep Neural Networks via Distribution Transfer,"Tong Wang, Yuan Yao, Feng Xu, Miao Xu, Shengwei An, Ting Wang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.06592"" target=""_blank"">2208.06592</a>",,2025-12-03 22:39:25
CTI4AI: Threat Intelligence Generation and Sharing after Red Teaming AI Models,"Chuyen Nguyen, Caleb Morgan, Sudip Mittal",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.07476"" target=""_blank"">2208.07476</a>",,2025-12-03 22:39:25
A Multi-objective Memetic Algorithm for Auto Adversarial Attack Optimization Design,"Jialiang Sun, Wen Yao, Tingsong Jiang, Xiaoqian Chen",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.06984"" target=""_blank"">2208.06984</a>",,2025-12-03 22:39:25
Link-Backdoor: Backdoor Attack on Link Prediction via Node Injection,"Haibin Zheng, Haiyang Xiong, Haonan Ma, Guohan Huang, Jinyin Chen",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.06776"" target=""_blank"">2208.06776</a>","<a href=""https://github.com/Seaocn/Link-Backdoor"" target=""_blank"">Seaocn</a>",2025-12-03 22:39:25
InvisibiliTee: Angle-agnostic Cloaking from Person-Tracking Systems with a Tee,"Yaxian Li, Bingqing Zhang, Guoping Zhao, Mingyu Zhang, Jiajun Liu, Ziwei Wang, Jirong Wen",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.06962"" target=""_blank"">2208.06962</a>",,2025-12-03 22:39:25
Long-Short History of Gradients is All You Need: Detecting Malicious and Unreliable Clients in Federated Learning,"Ashish Gupta, Tie Luo, Mao V. Ngo, Sajal K. Das",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10273"" target=""_blank"">2208.10273</a>","<a href=""https://github.com/LabSAINT/MUD-HoG_Federated_Learning"" target=""_blank"">LabSAINT</a>",2025-12-03 22:39:25
Revisiting Adversarial Attacks on Graph Neural Networks for Graph Classification,"Beini Xie, Heng Chang, Xin Wang, Tian Bian, Shiji Zhou, Daixin Wang, Zhiqiang Zhang, Wenwu Zhu",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.06651"" target=""_blank"">2208.06651</a>",,2025-12-03 22:39:25
Friendly Noise against Adversarial Noise: A Powerful Defense against Data Poisoning Attacks,"Tian Yu Liu, Yu Yang, Baharan Mirzasoleiman",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10224"" target=""_blank"">2208.10224</a>",,2025-12-03 22:39:25
Combining Stochastic Defenses to Resist Gradient Inversion: An Ablation Study,"Daniel Scheliga, Patrick Mäder, Marco Seeland",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.04767"" target=""_blank"">2208.04767</a>",,2025-12-03 22:39:25
Spectrum Focused Frequency Adversarial Attacks for Automatic Modulation Classification,"Sicheng College of Information and Communication Engineering, Harbin Engineering University, Harbin Zhang, Jiarun College of Information and Communication Engineering, Harbin Engineering University, Harbin Yu, Zhida College of Information and Communication Engineering, Harbin Engineering University, Harbin Bao, Shiwen Department of Electrical & Computer Engineering, Auburn University, Auburn Mao, Yun College of Information and Communication Engineering, Harbin Engineering University, Harbin Lin",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.01919"" target=""_blank"">2208.01919</a>",,2025-12-03 22:39:25
Robust and Imperceptible Black-box DNN Watermarking Based on Fourier Perturbation Analysis and Frequency Sensitivity Clustering,"Yong Liu, Hanzhou Wu, Xinpeng Zhang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.03944"" target=""_blank"">2208.03944</a>",,2025-12-03 22:39:25
Attacking Adversarial Defences by Smoothing the Loss Landscape,"Panagiotis Eustratiadis, Henry Gouk, Da Li, Timothy Hospedales",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.00862"" target=""_blank"">2208.00862</a>",,2025-12-03 22:39:25
Robust Graph Neural Networks using Weighted Graph Laplacian,"Bharat Runwal, Vivek, Sandeep Kumar",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.01853"" target=""_blank"">2208.01853</a>","<a href=""https://github.com/Bharat-Runwal/RWL-GNN"" target=""_blank"">Bharat-Runwal</a>",2025-12-03 22:39:25
Adversarial Camouflage for Node Injection Attack on Graphs,"Shuchang Tao, Qi Cao, Huawei Shen, Yunfan Wu, Liang Hou, Xueqi Cheng",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.01819"" target=""_blank"">2208.01819</a>",,2025-12-03 22:39:25
Success of Uncertainty-Aware Deep Models Depends on Data Manifold Geometry,"Mark Penrod, Harrison Termotto, Varshini Reddy, Jiayu Yao, Finale Doshi-Velez, Weiwei Pan",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.01705"" target=""_blank"">2208.01705</a>",,2025-12-03 22:39:25
SCFI: State Machine Control-Flow Hardening Against Fault Attacks,"Pascal Nasahl, Martin Unterguggenberger, Rishub Nagpal, Robert Schilling, David Schrammel, Stefan Mangard",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.01356"" target=""_blank"">2208.01356</a>",,2025-12-03 22:39:25
GeoECG: Data Augmentation via Wasserstein Geodesic Perturbation for Robust Electrocardiogram Prediction,"Jiacheng Zhu, Jielin Qiu, Zhuolin Yang, Douglas Weber, Michael A. Rosenberg, Emerson Liu, Bo Li, Ding Zhao",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.01220"" target=""_blank"">2208.01220</a>",,2025-12-03 22:39:25
Understanding Adversarial Robustness of Vision Transformers via Cauchy Problem,"Zheng Wang, Wenjie Ruan",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.00906"" target=""_blank"">2208.00906</a>",,2025-12-03 22:39:25
On the Evaluation of User Privacy in Deep Neural Networks using Timing Side Channel,"Shubhi Shukla, Manaar Alam, Sarani Bhattacharya, Debdeep Mukhopadhyay, Pabitra Mitra",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.01113"" target=""_blank"">2208.01113</a>",,2025-12-03 22:39:25
"DNNShield: Dynamic Randomized Model Sparsification, A Defense Against Adversarial Machine Learning","Mohammad Hossein Samavatian, Saikat Majumdar, Kristin Barber, Radu Teodorescu",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.00498"" target=""_blank"">2208.00498</a>",,2025-12-03 22:39:25
Multiclass ASMA vs Targeted PGD Attack in Image Segmentation,"Johnson University of Toronto Vo, Jiabao University of Toronto Xie, Sahil University of Toronto Patel",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.01844"" target=""_blank"">2208.01844</a>",,2025-12-03 22:39:25
Robust Real-World Image Super-Resolution against Adversarial Attacks,"Jiutao Yue, Haofeng Li, Pengxu Wei, Guanbin Li, Liang Lin",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.00428"" target=""_blank"">2208.00428</a>",,2025-12-03 22:39:25
Is current research on adversarial robustness addressing the right problem? (97%),Ali Borji,arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.00539"" target=""_blank"">2208.00539</a>",,2025-12-03 22:39:25
Efficient Detection and Filtering Systems for Distributed Training,"Konstantinos Konstantinidis, Aditya Ramamoorthy",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08085"" target=""_blank"">2208.08085</a>",,2025-12-03 22:39:25
enpheeph: A Fault Injection Framework for Spiking and Compressed Deep Neural Networks,"Alessio Colucci, Andreas Steininger, Muhammad Shafique",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.00328"" target=""_blank"">2208.00328</a>","<a href=""https://github.com/Alexei95/enpheeph"" target=""_blank"">Alexei95</a>",2025-12-03 22:39:25
Robust Trajectory Prediction against Adversarial Attacks,"Yulong Cao, Danfei Xu, Xinshuo Weng, Zhuoqing Mao, Anima Anandkumar, Chaowei Xiao, Marco Pavone",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.00094"" target=""_blank"">2208.00094</a>",,2025-12-03 22:39:25
Sampling Attacks on Meta Reinforcement Learning: A Minimax Formulation and Complexity Analysis,"Tao Li, Haozhe Lei, Quanyan Zhu",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.00081"" target=""_blank"">2208.00081</a>",,2025-12-03 22:39:25
Rethinking Textual Adversarial Defense for Pre-trained Language Models,"Jiayi Wang, Rongzhou Bao, Zhuosheng Zhang, Hai Zhao",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10251"" target=""_blank"">2208.10251</a>",,2025-12-03 22:39:25
MOVE: Effective and Harmless Ownership Verification via Embedded External Features,"Yiming Li, Linghui Zhu, Xiaojun Jia, Yang Bai, Yong Jiang, Shu-Tao Xia, Xiaochun Cao",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.02820"" target=""_blank"">2208.02820</a>","<a href=""https://github.com/THUYimingLi/MOVE"" target=""_blank"">THUYimingLi</a>",2025-12-03 22:39:25
Adversarial Attacks on ASR Systems: An Overview,"Xiao Zhang, Hao Tan, Xuan Huang, Denghui Zhang, Keke Tang, Zhaoquan Gu",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.02250"" target=""_blank"">2208.02250</a>",,2025-12-03 22:39:25
PerD: Perturbation Sensitivity-based Neural Trojan Detection Framework on NLP Applications,"Diego Garcia-soto, Huili Chen, Farinaz Koushanfar",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.04943"" target=""_blank"">2208.04943</a>",,2025-12-03 22:39:25
On the Fundamental Limits of Formally (Dis)Proving Robustness in Proof-of-Learning,"Congyu Fang, Hengrui Jia, Anvith Thudi, Mohammad Yaghini, Christopher A. Choquette-Choo, Natalie Dullerud, Varun Chandrasekaran, Nicolas Papernot",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.03567"" target=""_blank"">2208.03567</a>",,2025-12-03 22:39:25
Adversarial robustness of VAEs through the lens of local geometry,"Asif Khan, Amos Storkey",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.03923"" target=""_blank"">2208.03923</a>",,2025-12-03 22:39:25
AWEncoder: Adversarial Watermarking Pre-trained Encoders in Contrastive Learning,"Tianxing Zhang, Hanzhou Wu, Xiaofeng Lu, Guangling Sun",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.03948"" target=""_blank"">2208.03948</a>",,2025-12-03 22:39:25
Abutting Grating Illusion: Cognitive Challenge to Neural Network Models,"Jinyu Fan, Yi Zeng",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.03958"" target=""_blank"">2208.03958</a>",,2025-12-03 22:39:25
Testing of Machine Learning Models with Limited Samples: An Industrial Vacuum Pumping Application,"Ayan Chatterjee, Bestoun S. Ahmed, Erik Hallin, Anton Engman",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.04062"" target=""_blank"">2208.04062</a>",,2025-12-03 22:39:25
Federated Adversarial Learning: A Framework with Convergence Analysis,"Xiaoxiao Li, Zhao Song, Jiaming Yang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.03635"" target=""_blank"">2208.03635</a>",,2025-12-03 22:39:25
Are Gradients on Graph Structure Reliable in Gray-box Attacks? (13%),"Zihan Liu, Yun Luo, Lirong Wu, Siyuan Li, Zicheng Liu, Stan Z. Li",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.05514"" target=""_blank"">2208.05514</a>",,2025-12-03 22:39:25
Blackbox Attacks via Surrogate Ensemble Search,"Zikui Cai, Chengyu Song, Srikanth Krishnamurthy, Amit Roy-Chowdhury, M. Salman Asif",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.03610"" target=""_blank"">2208.03610</a>",,2025-12-03 22:39:25
Preventing or Mitigating Adversarial Supply Chain Attacks; a legal analysis,"Kaspar Rosager Ludvigsen, Shishir Nagaraja, Angela Daly",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.03466"" target=""_blank"">2208.03466</a>",,2025-12-03 22:39:25
A New Kind of Adversarial Example,Ali Borji,arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.02430"" target=""_blank"">2208.02430</a>","<a href=""https://github.com/aliborji/NKE"" target=""_blank"">aliborji</a>",2025-12-03 22:39:25
Adversarial Robustness of MR Image Reconstruction under Realistic Perturbations,"Jan Nikolas Morshuis, Sergios Gatidis, Matthias Hein, Christian F. Baumgartner",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.03161"" target=""_blank"">2208.03161</a>",,2025-12-03 22:39:25
Data-free Backdoor Removal based on Channel Lipschitzness,"Runkai Zheng, Rongjun Tang, Jianze Li, Li Liu",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.03111"" target=""_blank"">2208.03111</a>","<a href=""https://github.com/rkteddy/channel-Lipschitzness-based-pruning"" target=""_blank"">rkteddy</a>",2025-12-03 22:39:25
Lethal Dose Conjecture on Data Poisoning,"Wenxiao Wang, Alexander Levine, Soheil Feizi",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.03309"" target=""_blank"">2208.03309</a>",,2025-12-03 22:39:25
LCCDE: A Decision-Based Ensemble Framework for Intrusion Detection in The Internet of Vehicles,"Li Yang, Abdallah Shami, Gary Stevens, Rusett Stephen De",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.03399"" target=""_blank"">2208.03399</a>",,2025-12-03 22:39:25
Almost-Orthogonal Layers for Efficient General-Purpose Lipschitz Networks,"Bernd Prach, Christoph H. Lampert",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.03160"" target=""_blank"">2208.03160</a>","<a href=""https://github.com/berndprach/AOL"" target=""_blank"">berndprach</a>",2025-12-03 22:39:25
Self-Ensembling Vision Transformer (SEViT) for Robust Medical Image Classification,"Faris Almalik, Mohammad Yaqub, Karthik Nandakumar",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.02851"" target=""_blank"">2208.02851</a>","<a href=""https://github.com/faresmalik/SEViT"" target=""_blank"">faresmalik</a>",2025-12-03 22:39:25
Design of secure and robust cognitive system for malware detection,Sanket Shukla,arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.02310"" target=""_blank"">2208.02310</a>",,2025-12-03 22:39:25
ObfuNAS: A Neural Architecture Search-based DNN Obfuscation Approach,"Tong Zhou, Shaolei Ren, Xiaolin Xu",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08569"" target=""_blank"">2208.08569</a>","<a href=""https://github.com/Tongzhou0101/ObfuNAS"" target=""_blank"">Tongzhou0101</a>",2025-12-03 22:39:25
CoNLoCNN: Exploiting Correlation and Non-Uniform Quantization for Energy-Efficient Low-precision Deep Convolutional Neural Networks,"Muhammad Abdullah Hanif, Giuseppe Maria Sarda, Alberto Marchisio, Guido Masera, Maurizio Martina, Muhammad Shafique",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.00331"" target=""_blank"">2208.00331</a>",,2025-12-03 22:39:25
An Empirical Study on the Membership Inference Attack against Tabular Data Synthesis Models,"Jihyeon Hyeong, Jayoung Kim, Noseong Park, Sushil Jajodia",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08114"" target=""_blank"">2208.08114</a>",,2025-12-03 22:39:25
Robust DNN Watermarking via Fixed Embedding Weights with Optimized Distribution,"Benedetta Tondi, Andrea Costanzo, Mauro Barni",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10973"" target=""_blank"">2208.10973</a>",,2025-12-03 22:39:25
Semantic Preserving Adversarial Attack Generation with Autoencoder and Genetic Algorithm,"Xinyi Wang, Simon Yusuf Enoch, Dong Seong Kim",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.12230"" target=""_blank"">2208.12230</a>",,2025-12-03 22:39:25
SNAP: Efficient Extraction of Private Properties with Poisoning,"Harsh Chaudhari, John Abascal, Alina Oprea, Matthew Jagielski, Florian Tramèr, Jonathan Ullman",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.12348"" target=""_blank"">2208.12348</a>",,2025-12-03 22:39:25
FuncFooler: A Practical Black-box Attack Against Learning-based Binary Code Similarity Detection Methods,"Lichen Jia, Bowen Tang, Chenggang Wu, Zhe Wang, Zihan Jiang, Yuanming Lai, Yan Kang, Ning Liu, Jingfeng Zhang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.14191"" target=""_blank"">2208.14191</a>",,2025-12-03 22:39:25
Robust Prototypical Few-Shot Organ Segmentation with Regularized Neural-ODEs,"Prashant Pandey, Mustafa Chasmai, Tanuj Sur, Brejesh Lall",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.12428"" target=""_blank"">2208.12428</a>",,2025-12-03 22:39:25
Calibrated Selective Classification,"Adam Fisch, Tommi Jaakkola, Regina Barzilay",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.12084"" target=""_blank"">2208.12084</a>",,2025-12-03 22:39:25
XDRI Attacks - and - How to Enhance Resilience of Residential Routers,"Philipp Jeitner, Haya Shulman, Lucas Teichmann, Michael Waidner",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.12003"" target=""_blank"">2208.12003</a>",,2025-12-03 22:39:25
FedPrompt: Communication-Efficient and Privacy Preserving Prompt Tuning in Federated Learning,"Haodong Zhao, Wei Du, Fangqi Li, Peixuan Li, Gongshen Liu",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.12268"" target=""_blank"">2208.12268</a>",,2025-12-03 22:39:25
Attacking Neural Binary Function Detection,"Joshua Bundt, Michael Davinroy, Ioannis Agadakos, Alina Oprea, William Robertson",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.11667"" target=""_blank"">2208.11667</a>",,2025-12-03 22:39:25
Unrestricted Black-box Adversarial Attack Using GAN with Limited Queries,"Dongbin Na, Sangwoo Ji, Jong Kim",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.11613"" target=""_blank"">2208.11613</a>",,2025-12-03 22:39:25
Trace and Detect Adversarial Attacks on CNNs using Feature Response Maps,"Mohammadreza Amirian, Friedhelm Schwenker, Thilo Stadelmann",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.11436"" target=""_blank"">2208.11436</a>",,2025-12-03 22:39:25
A Perturbation Resistant Transformation and Classification System for Deep Neural Networks,"Nathaniel Dean, Dilip Sarkar",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.11839"" target=""_blank"">2208.11839</a>",,2025-12-03 22:39:25
Rethinking Cost-sensitive Classification in Deep Learning via Adversarial Data Augmentation,"Qiyuan Chen, Raed Al Kontar, Maher Nouiehed, Jessie Yang, Corey Lester",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.11739"" target=""_blank"">2208.11739</a>",,2025-12-03 22:39:25
Bidirectional Contrastive Split Learning for Visual Question Answering,"Yuwei Sun, Hideya Ochiai",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.11435"" target=""_blank"">2208.11435</a>",,2025-12-03 22:39:25
Towards an Awareness of Time Series Anomaly Detection Models' Adversarial Vulnerability,"Shahroz Tariq, Binh M. Le, Simon S. Woo",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.11264"" target=""_blank"">2208.11264</a>",,2025-12-03 22:39:25
Adversarial Vulnerability of Temporal Feature Networks for Object Detection,"Svetlana Pavlitskaya, Nikolai Polley, Michael Weber, J. Marius Zöllner",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10773"" target=""_blank"">2208.10773</a>",,2025-12-03 22:39:25
Transferability Ranking of Adversarial Examples,"Mosh Levy, Yuval Elovici, Yisroel Mirsky",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10878"" target=""_blank"">2208.10878</a>",,2025-12-03 22:39:25
Auditing Membership Leakages of Multi-Exit Networks,"Zheng Li, Yiyong Liu, Xinlei He, Ning Yu, Michael Backes, Yang Zhang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.11180"" target=""_blank"">2208.11180</a>",,2025-12-03 22:39:25
ATTRITION: Attacking Static Hardware Trojan Detection Techniques Using Reinforcement Learning,"Vasudev JV Gohil, Hao JV Guo, Satwik JV Patnaik, JV Jeyavijayan, Rajendran",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.12897"" target=""_blank"">2208.12897</a>",,2025-12-03 22:39:25
Network-Level Adversaries in Federated Learning,"Giorgio Severi, Matthew Jagielski, Gökberk Yar, Yuxuan Wang, Alina Oprea, Cristina Nita-Rotaru",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.12911"" target=""_blank"">2208.12911</a>",,2025-12-03 22:39:25
What Does the Gradient Tell When Attacking the Graph Structure,"Zihan Liu, Ge Wang, Yun Luo, Stan Z. Li",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.12815"" target=""_blank"">2208.12815</a>",,2025-12-03 22:39:25
Constraining Representations Yields Models That Know What They Don't Know,"Joao Monteiro, Pau Rodriguez, Pierre-Andre Noel, Issam Laradji, David Vazquez",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.14488"" target=""_blank"">2208.14488</a>",,2025-12-03 22:39:25
Explainable Artificial Intelligence Applications in Cyber Security: State-of-the-Art in Research,"Zhibo Zhang, Hussam Al Hamadi, Ernesto Damiani, Chan Yeob Yeun, Fatma Taher",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.14937"" target=""_blank"">2208.14937</a>",,2025-12-03 22:39:25
On the Privacy Effect of Data Enhancement via the Lens of Memorization,"Xiao Li, Qiongxiu Li, Zhanhao Hu, Xiaolin Hu",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08270"" target=""_blank"">2208.08270</a>",,2025-12-03 22:39:25
Feature Alignment by Uncertainty and Self-Training for Source-Free Unsupervised Domain Adaptation,"JoonHo Lee, Gyemin Lee",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.14888"" target=""_blank"">2208.14888</a>",,2025-12-03 22:39:25
Vulnerability of Distributed Inverter VAR Control in PV Distributed Energy System,"Bo Tu, Wen-Tai Li, Chau Yuen",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.14672"" target=""_blank"">2208.14672</a>",,2025-12-03 22:39:25
Membership Inference Attacks by Exploiting Loss Trajectory,"Yiyong Liu, Zhengyu Zhao, Michael Backes, Yang Zhang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.14933"" target=""_blank"">2208.14933</a>",,2025-12-03 22:39:25
A Black-Box Attack on Optical Character Recognition Systems,"Samet Bayram, Kenneth Barner",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.14302"" target=""_blank"">2208.14302</a>",,2025-12-03 22:39:25
Solving the Capsulation Attack against Backdoor-based Deep Neural Network Watermarks by Reversing Triggers,"Fangqi Li, Shilin Wang, Yun Zhu",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.14127"" target=""_blank"">2208.14127</a>",,2025-12-03 22:39:25
Towards Adversarial Purification using Denoising AutoEncoders,"Dvij Kalaria, Aritra Hazra, Partha Pratim Chakrabarti",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.13838"" target=""_blank"">2208.13838</a>",,2025-12-03 22:39:25
RL-DistPrivacy: Privacy-Aware Distributed Deep Inference for low latency IoT systems,"Emna Baccour, Aiman Erbad, Amr Mohamed, Mounir Hamdi, Mohsen Guizani",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.13032"" target=""_blank"">2208.13032</a>",,2025-12-03 22:39:25
Reducing Certified Regression to Certified Classification for General Poisoning Attacks,"Zayd Hammoudeh, Daniel Lowd",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.13904"" target=""_blank"">2208.13904</a>","<a href=""https://github.com/ZaydH/certified-regression"" target=""_blank"">ZaydH</a>",2025-12-03 22:39:25
Interpreting Black-box Machine Learning Models for High Dimensional Datasets,"Md. Rezaul Karim, Md. Shajalal, Alex Graß, Till Döhmen, Sisay Adugna Chala, Christian Beecks, Stefan Decker",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.13405"" target=""_blank"">2208.13405</a>",,2025-12-03 22:39:25
Cross-domain Cross-architecture Black-box Attacks on Fine-tuned Models with Transferred Evolutionary Strategies,"Yinghua Zhang, Yangqiu Song, Kun Bai, Qiang Yang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.13182"" target=""_blank"">2208.13182</a>",,2025-12-03 22:39:25
Adversarial Robustness for Tabular Data through Cost and Utility Awareness,"Klim Kireev, Bogdan Kulynych, Carmela Troncoso",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.13058"" target=""_blank"">2208.13058</a>",,2025-12-03 22:39:25
SA: Sliding attack for synthetic speech detection with resistance to clipping and self-splicing,"Deng JiaCheng, Dong Li, Yan Diqun, Wang Rangding, Zeng Jiaming",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.13066"" target=""_blank"">2208.13066</a>",,2025-12-03 22:39:25
TrojViT: Trojan Insertion in Vision Transformers,"Mengxin Zheng, Qian Lou, Lei Jiang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.13049"" target=""_blank"">2208.13049</a>",,2025-12-03 22:39:25
Overparameterized (robust) models from computational constraints,"Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody, Mingyuan Wang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.12926"" target=""_blank"">2208.12926</a>",,2025-12-03 22:39:25
A Comprehensive Study of Real-Time Object Detection Networks Across Multiple Domains: A Survey,"Elahe Arani, Shruthi Gowda, Ratnajit Mukherjee, Omar Magdy, Senthilkumar Kathiresan, Bahram Zonooz",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10895"" target=""_blank"">2208.10895</a>",,2025-12-03 22:39:25
Lower Difficulty and Better Robustness: A Bregman Divergence Perspective for Adversarial Training,"Zihui Wu, Haichang Gao, Bingqian Zhou, Xiaoyan Guo, Shudong Zhang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.12511"" target=""_blank"">2208.12511</a>",,2025-12-03 22:39:25
Fight Fire With Fire: Reversing Skin Adversarial Examples by Multiscale Diffusive and Denoising Aggregation Mechanism,"Yongwei Wang, Yuan Li, Zhiqi Shen",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10373"" target=""_blank"">2208.10373</a>",,2025-12-03 22:39:25
Real-Time Robust Video Object Detection System Against Physical-World Adversarial Attacks,"Husheng Han, Xing Hu, Kaidi Xu, Pucheng Dang, Ying Wang, Yongwei Zhao, Zidong Du, Qi Guo, Yanzhi Yang, Tianshi Chen",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09195"" target=""_blank"">2208.09195</a>",,2025-12-03 22:39:25
Dispersed Pixel Perturbation-based Imperceptible Backdoor Trigger for Image Classifier Models,"Yulong Wang, Minghui Zhao, Shenghong Li, Xin Yuan, Wei Ni",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09336"" target=""_blank"">2208.09336</a>",,2025-12-03 22:39:25
A Novel Plug-and-Play Approach for Adversarially Robust Generalization,"Deepak Maurya, Adarsh Barik, Jean Honorio",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09449"" target=""_blank"">2208.09449</a>",,2025-12-03 22:39:25
SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability,"Wei Huang, Xingyu Zhao, Gaojie Jin, Xiaowei Huang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09418"" target=""_blank"">2208.09418</a>",,2025-12-03 22:39:25
UKP-SQuARE v2 Explainability and Adversarial Attacks for Trustworthy QA,"Rachneet Sachdeva, Haritz Puerto, Tim Baumgärtner, Sewin Tariverdian, Hao Zhang, Kexin Wang, Hossain Shaikh Saadi, Leonardo F. R. Ribeiro, Iryna Gurevych",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09316"" target=""_blank"">2208.09316</a>",,2025-12-03 22:39:25
Resisting Adversarial Attacks in Deep Neural Networks using Diverse Decision Boundaries,"Manaar Alam, Shubhajit Datta, Debdeep Mukhopadhyay, Arijit Mondal, Partha Pratim Chakrabarti",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08697"" target=""_blank"">2208.08697</a>",,2025-12-03 22:39:25
Enhancing Targeted Attack Transferability via Diversified Weight Pruning,"Hung-Jui Wang, Yu-Yu Wu, Shang-Tse Chen",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08677"" target=""_blank"">2208.08677</a>",,2025-12-03 22:39:25
Reverse Engineering of Integrated Circuits: Tools and Techniques,Abhijitt Dhavlle,arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08689"" target=""_blank"">2208.08689</a>",,2025-12-03 22:39:25
DAFT: Distilling Adversarially Fine-tuned Models for Better OOD Generalization,"Anshul Nasery, Sravanti Addepalli, Praneeth Netrapalli, Prateek Jain",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09139"" target=""_blank"">2208.09139</a>",,2025-12-03 22:39:25
Discovering Bugs in Vision Models using Off-the-shelf Image Generation and Captioning,"Olivia Wiles, Isabela Albuquerque, Sven Gowal",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08831"" target=""_blank"">2208.08831</a>",,2025-12-03 22:39:25
"Private, Efficient, and Accurate: Protecting Models Trained by Multi-party Learning with Differential Privacy","Wenqiang Ruan, Mingxin Xu, Wenjing Fang, Li Wang, Lei Wang, Weili Han",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08662"" target=""_blank"">2208.08662</a>",,2025-12-03 22:39:25
Profiler: Profile-Based Model to Detect Phishing Emails,"Mariya Shmalko, Alsharif Abuadbba, Raj Gaire, Tingmin Wu, Hye-Young Paik, Surya Nepal",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08745"" target=""_blank"">2208.08745</a>",,2025-12-03 22:39:25
Two Heads are Better than One: Robust Learning Meets Multi-branch Models,"Dong Huang, Qingwen Bu, Yuhao Qing, Haowen Pi, Sen Wang, Heming Cui",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08083"" target=""_blank"">2208.08083</a>","<a href=""https://github.com/huangd1999/BORT"" target=""_blank"">huangd1999</a>",2025-12-03 22:39:25
"An Evolutionary, Gradient-Free, Query-Efficient, Black-Box Algorithm for Generating Adversarial Instances in Deep Networks","Raz Lapid, Zvika Haramaty, Moshe Sipper",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08297"" target=""_blank"">2208.08297</a>",,2025-12-03 22:39:25
Shadows Aren't So Dangerous After All: A Fast and Robust Defense Against Shadow-Based Adversarial Attacks,"Andrew Wang, Wyatt Mayor, Ryan Smith, Gopal Nookula, Gregory Ditzler",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09285"" target=""_blank"">2208.09285</a>",,2025-12-03 22:39:25
Hierarchical Perceptual Noise Injection for Social Media Fingerprint Privacy Protection,"Simin Li, Huangxinxin Xu, Jiakai Wang, Aishan Liu, Fazhi He, Xianglong Liu, Dacheng Tao",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10688"" target=""_blank"">2208.10688</a>","<a href=""https://github.com/nlsde-safety-team/FingerSafe"" target=""_blank"">nlsde-safety-team</a>",2025-12-03 22:39:25
Label Flipping Data Poisoning Attack Against Wearable Human Activity Recognition System,"Abdur R. Shahid, Ahmed Imteaj, Peter Y. Wu, Diane A. Igoche, Tauhidul Alam",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08433"" target=""_blank"">2208.08433</a>",,2025-12-03 22:39:25
An Efficient Multi-Step Framework for Malware Packing Identification,"Jong-Wouk Kim, Yang-Sae Moon, Mi-Jung Choi",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08071"" target=""_blank"">2208.08071</a>",,2025-12-03 22:39:25
Gender Bias and Universal Substitution Adversarial Attacks on Grammatical Error Correction Systems for Automated Assessment,"Vyas Raina, Mark Gales",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09466"" target=""_blank"">2208.09466</a>",,2025-12-03 22:39:25
Enhancing Diffusion-Based Image Synthesis with Robust Classifier Guidance,"Bahjat Kawar, Roy Ganz, Michael Elad",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.08664"" target=""_blank"">2208.08664</a>",,2025-12-03 22:39:25
Adversarial contamination of networks in the setting of vertex nomination: a new trimming method,"Sheyda Peyman, Minh Tang, Vince Lyzinski",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09710"" target=""_blank"">2208.09710</a>",,2025-12-03 22:39:25
Byzantines can also Learn from History: Fall of Centered Clipping in Federated Learning,"Kerem Ozfatura, Emre Ozfatura, Alptekin Kupcu, Deniz Gunduz",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09894"" target=""_blank"">2208.09894</a>",,2025-12-03 22:39:25
Different Spectral Representations in Optimized Artificial Neural Networks and Brains,"Richard C. Gerum, Cassidy Pirlot, Alona Fyshe, Joel Zylberberg",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10576"" target=""_blank"">2208.10576</a>",,2025-12-03 22:39:25
Membership-Doctor: Comprehensive Assessment of Membership Inference Against Machine Learning Models,"Xinlei He, Zheng Li, Weilin Xu, Cory Cornelius, Yang Zhang",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10445"" target=""_blank"">2208.10445</a>",,2025-12-03 22:39:25
RIBAC: Towards Robust and Imperceptible Backdoor Attack against Compact DNN,"Huy Phan, Cong Shi, Yi Xie, Tianfang Zhang, Zhuohang Li, Tianming Zhao, Jian Liu, Yan Wang, Yingying Chen, Bo Yuan",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10608"" target=""_blank"">2208.10608</a>","<a href=""https://github.com/huyvnphan/ECCV2022-RIBAC"" target=""_blank"">huyvnphan</a>",2025-12-03 22:39:25
Toward Better Target Representation for Source-Free and Black-Box Domain Adaptation,"Qucheng Peng, Zhengming Ding, Lingjuan Lyu, Lichao Sun, Chen Chen",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10531"" target=""_blank"">2208.10531</a>",,2025-12-03 22:39:25
Optimal Bootstrapping of PoW Blockchains,"Ranvir Rana, Dimitris Karakostas, Sreeram Kannan, Aggelos Kiayias, Pramod Viswanath",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10618"" target=""_blank"">2208.10618</a>",,2025-12-03 22:39:25
PointDP: Diffusion-driven Purification against Adversarial Attacks on 3D Point Cloud Recognition,"Jiachen Sun, Weili Nie, Zhiding Yu, Z. Morley Mao, Chaowei Xiao",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09801"" target=""_blank"">2208.09801</a>",,2025-12-03 22:39:25
Inferring Sensitive Attributes from Model Explanations,"Vasisht Duddu, Antoine Boutet",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09967"" target=""_blank"">2208.09967</a>",,2025-12-03 22:39:25
BARReL: Bottleneck Attention for Adversarial Robustness in Vision-Based Reinforcement Learning,"Eugene Bykovets, Yannick Metz, Mennatallah El-Assady, Daniel A. Keim, Joachim M. Buhmann",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10481"" target=""_blank"">2208.10481</a>",,2025-12-03 22:39:25
MockingBERT: A Method for Retroactively Adding Resilience to NLP Models,"Jan Jezabek, Akash Singh",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09915"" target=""_blank"">2208.09915</a>",,2025-12-03 22:39:25
A Unified Analysis of Mixed Sample Data Augmentation: A Loss Function Perspective,"Chanwoo Park, Sangdoo Yun, Sanghyuk Chun",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09913"" target=""_blank"">2208.09913</a>","<a href=""https://github.com/naver-ai/hmix-gmix"" target=""_blank"">naver-ai</a>",2025-12-03 22:39:25
Analyzing Adversarial Robustness of Vision Transformers against Spatial and Spectral Attacks,"Gihyun Kim, Jong-Seok Lee",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09602"" target=""_blank"">2208.09602</a>",,2025-12-03 22:39:25
GAIROSCOPE: Injecting Data from Air-Gapped Computers to Nearby Gyroscopes,Mordechai Guri,arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09764"" target=""_blank"">2208.09764</a>",,2025-12-03 22:39:25
"Sensor Security: Current Progress, Research Challenges, and Future Roadmap","Anomadarshi Barua, Mohammad Abdullah Al Faruque",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.09741"" target=""_blank"">2208.09741</a>",,2025-12-03 22:39:25
NOSMOG: Learning Noise-robust and Structure-aware MLPs on Graphs,"Yijun Tian, Chuxu Zhang, Zhichun Guo, Xiangliang Zhang, Nitesh V. Chawla",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10010"" target=""_blank"">2208.10010</a>",,2025-12-03 22:39:25
Evaluating Out-of-Distribution Detectors Through Adversarial Generation of Outliers,"Sangwoong Yoon, Jinwon Choi, Yonghyeon Lee, Yung-Kyun Noh, Frank Chongwoo Park",arXiv,2022-08,"<a href=""http://arxiv.org/abs/2208.10940"" target=""_blank"">2208.10940</a>",,2025-12-03 22:39:25
Dynamic Time Warping based Adversarial Framework for Time-Series Domain,"Taha Belkhouja, Yan Yan, Janardhan Rao Doppa",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.04308"" target=""_blank"">2207.04308</a>","<a href=""https://github.com/tahabelkhouja/DTW-AR"" target=""_blank"">tahabelkhouja</a>",2025-12-03 22:39:25
"""Why do so?"" -- A Practical Perspective on Machine Learning Security","Kathrin Grosse, Lukas Bieringer, Tarek Richard Besold, Battista Biggio, Katharina Krombholz",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05164"" target=""_blank"">2207.05164</a>",,2025-12-03 22:39:25
Physical Attack on Monocular Depth Estimation with Optimal Adversarial Patches,"Zhiyuan Cheng, James Liang, Hongjun Choi, Guanhong Tao, Zhiwen Cao, Dongfang Liu, Xiangyu Zhang",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.04718"" target=""_blank"">2207.04718</a>",,2025-12-03 22:39:25
Adversarial Style Augmentation for Domain Generalized Urban-Scene Segmentation,"Zhun Zhong, Yuyang Zhao, Gim Hee Lee, Nicu Sebe",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.04892"" target=""_blank"">2207.04892</a>",,2025-12-03 22:39:25
One-shot Neural Backdoor Erasing via Adversarial Weight Masking,"Shuwen Chai, Jinghui Chen",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.04497"" target=""_blank"">2207.04497</a>",,2025-12-03 22:39:25
Hiding Your Signals: A Security Analysis of PPG-based Biometric Authentication,"Lin Li, Chao Chen, Lei Pan, Yonghang Tai, Jun Zhang, Yang Xiang",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.04434"" target=""_blank"">2207.04434</a>",,2025-12-03 22:39:25
Adversarial Framework with Certified Robustness for Time-Series Domain via Statistical Features,"Taha Belkhouja, Janardhan Rao Doppa",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.04307"" target=""_blank"">2207.04307</a>","<a href=""https://github.com/tahabelkhouja/Time-Series-Attacks-via-STATistical-Features"" target=""_blank"">tahabelkhouja</a>",2025-12-03 22:39:25
Invisible Backdoor Attacks Using Data Poisoning in the Frequency Domain,"Chang Yue, Peizhuo Lv, Ruigang Liang, Kai Chen",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.04209"" target=""_blank"">2207.04209</a>",,2025-12-03 22:39:25
Improved and Interpretable Defense to Transferred Adversarial Examples by Jacobian Norm with Selective Input Gradient Regularization,"Deyin Liu, Lin Wu, Lingqiao Liu, Haifeng Zhao, Farid Boussaid, Mohammed Bennamoun",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.13036"" target=""_blank"">2207.13036</a>",,2025-12-03 22:39:25
Training Robust Deep Models for Time-Series Domain: Novel Algorithms and Theoretical Analysis,"Taha Belkhouja, Yan Yan, Janardhan Rao Doppa",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.04305"" target=""_blank"">2207.04305</a>","<a href=""https://github.com/tahabelkhouja/Robust-Training-for-Time-Series"" target=""_blank"">tahabelkhouja</a>",2025-12-03 22:39:25
Not all broken defenses are equal: The dead angles of adversarial accuracy,"Raphael Olivier, Bhiksha Raj",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.04129"" target=""_blank"">2207.04129</a>",,2025-12-03 22:39:25
Defense Against Multi-target Trojan Attacks,"Haripriya Harikumar, Santu Rana, Kien Do, Sunil Gupta, Wei Zong, Willy Susilo, Svetha Venkastesh",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.03895"" target=""_blank"">2207.03895</a>",,2025-12-03 22:39:25
Guiding the retraining of convolutional neural networks against adversarial inputs,"Francisco Durán López, Silverio Martínez-Fernández, Michael Felderer, Xavier Franch",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.03689"" target=""_blank"">2207.03689</a>",,2025-12-03 22:39:25
Online Evasion Attacks on Recurrent Models:The Power of Hallucinating the Future,"Byunggill Joe, Insik Shin, Jihun Hamm",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.09912"" target=""_blank"">2207.09912</a>",,2025-12-03 22:39:25
"A law of adversarial risk, interpolation, and label noise","Daniel Paleka, Amartya Sanyal",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.03933"" target=""_blank"">2207.03933</a>",,2025-12-03 22:39:25
Models Out of Line: A Fourier Lens on Distribution Shift Robustness,"Sara Fridovich-Keil, Brian R. Bartoldson, James Diffenderfer, Bhavya Kailkhura, Peer-Timo Bremer",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.04075"" target=""_blank"">2207.04075</a>",,2025-12-03 22:39:25
Towards Effective Multi-Label Recognition Attacks via Knowledge Graph Consistency,"Hassan Mahmood, Ehsan Elhamifar",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05137"" target=""_blank"">2207.05137</a>",,2025-12-03 22:39:25
Susceptibility of Continual Learning Against Adversarial Attacks,"Hikmat Khan, Pir Masoom Shah, Syed Farhan Alam Zaidi, Saif ul Islam",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05225"" target=""_blank"">2207.05225</a>",,2025-12-03 22:39:25
"Explainable Intrusion Detection Systems (X-IDS): A Survey of Current Methods, Challenges, and Opportunities","Subash Neupane, Jesse Ables, William Anderson, Sudip Mittal, Shahram Rahimi, Ioana Banicescu, Maria Seale",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.06236"" target=""_blank"">2207.06236</a>",,2025-12-03 22:39:25
Physical Passive Patch Adversarial Attacks on Visual Odometry Systems,"Yaniv Nemcovsky, Matan Yaakoby, Alex M. Bronstein, Chaim Baskin",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05729"" target=""_blank"">2207.05729</a>","<a href=""https://github.com/patchadversarialattacks/patchadversarialattacks"" target=""_blank"">patchadversarialattacks</a>",2025-12-03 22:39:25
RUSH: Robust Contrastive Learning via Randomized Smoothing,"Yijiang Pang, Boyang Liu, Jiayu Zhou",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05127"" target=""_blank"">2207.05127</a>",,2025-12-03 22:39:25
CausalAgents: A Robustness Benchmark for Motion Forecasting using Causal Relationships,"Rebecca Roelofs, Liting Sun, Ben Caine, Khaled S. Refaat, Ben Sapp, Scott Ettinger, Wei Chai",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.03586"" target=""_blank"">2207.03586</a>","<a href=""https://github.com/google-research/causal-agents"" target=""_blank"">google-research</a>",2025-12-03 22:39:25
PIAT: Physics Informed Adversarial Training for Solving Partial Differential Equations,"Simin Shekarpaz, Mohammad Azizmalayeri, Mohammad Hossein Rohban",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.06647"" target=""_blank"">2207.06647</a>","<a href=""https://github.com/rohban-lab/PIAT"" target=""_blank"">rohban-lab</a>",2025-12-03 22:39:25
Interactive Machine Learning: A State of the Art Review,"Natnael A. Wondimu, Cédric Buche, Ubbo Visser",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.06196"" target=""_blank"">2207.06196</a>",,2025-12-03 22:39:25
Sample-dependent Adaptive Temperature Scaling for Improved Calibration,"Tom Joy, Francesco Pinto, Ser-Nam Lim, Philip H. S. Torr, Puneet K. Dokania",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.06211"" target=""_blank"">2207.06211</a>","<a href=""https://github.com/thwjoy/adats"" target=""_blank"">thwjoy</a>",2025-12-03 22:39:25
DiverGet: A Search-Based Software Testing Approach for Deep Neural Network Quantization Assessment,"Ahmed Haj Yahmed, Houssem Ben Braiek, Foutse Khomh, Sonia Bouzidi, Rania Zaatour",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.06282"" target=""_blank"">2207.06282</a>",,2025-12-03 22:39:25
Exploring Adversarial Examples and Adversarial Robustness of Convolutional Neural Networks by Mutual Information,"Jiebao Zhang, Wenhua Qian, Rencan Nie, Jinde Cao, Dan Xu",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05756"" target=""_blank"">2207.05756</a>",,2025-12-03 22:39:25
Adversarial Robustness Assessment of NeuroEvolution Approaches,"Inês Valentim, Nuno Lourenço, Nuno Antunes",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05451"" target=""_blank"">2207.05451</a>",,2025-12-03 22:39:25
Frequency Domain Model Augmentation for Adversarial Attack,"Yuyang Long, Qilong Zhang, Boheng Zeng, Lianli Gao, Xianglong Liu, Jian Zhang, Jingkuan Song",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05382"" target=""_blank"">2207.05382</a>","<a href=""https://github.com/yuyang-long/SSA"" target=""_blank"">yuyang-long</a>",2025-12-03 22:39:25
Practical Attacks on Machine Learning: A Case Study on Adversarial Windows Malware,"Luca Demetrio, Battista Biggio, Fabio Roli",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05548"" target=""_blank"">2207.05548</a>",,2025-12-03 22:39:25
Bi-fidelity Evolutionary Multiobjective Search for Adversarially Robust Deep Neural Architectures,"Jia Liu, Ran Cheng, Yaochu Jin",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05321"" target=""_blank"">2207.05321</a>",,2025-12-03 22:39:25
Certified Adversarial Robustness via Anisotropic Randomized Smoothing,"Hanbin Hong, Yuan Hong",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05327"" target=""_blank"">2207.05327</a>",,2025-12-03 22:39:25
RelaxLoss: Defending Membership Inference Attacks without Losing Utility,"Dingfan Chen, Ning Yu, Mario Fritz",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05801"" target=""_blank"">2207.05801</a>","<a href=""https://github.com/DingfanChen/RelaxLoss"" target=""_blank"">DingfanChen</a>",2025-12-03 22:39:25
Verifying Attention Robustness of Deep Neural Networks against Semantic Perturbations,"Satoshi Munakata, Caterina Urban, Haruki Yokoyama, Koji Yamamoto, Kazuki Munakata",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05902"" target=""_blank"">2207.05902</a>",,2025-12-03 22:39:25
Markov Decision Process For Automatic Cyber Defense,"Simon Yusuf Enoch, Simon Yusuf Enoch, Dong Seong Kim",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05436"" target=""_blank"">2207.05436</a>",,2025-12-03 22:39:25
Estimating Test Performance for AI Medical Devices under Distribution Shift with Conformal Prediction,"Charles Lu, Syed Rakin Ahmed, Praveer Singh, Jayashree Kalpathy-Cramer",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05796"" target=""_blank"">2207.05796</a>",,2025-12-03 22:39:25
Backdoor Attacks on Crowd Counting,"Yuhua Sun, Tailai Zhang, Xingjun Ma, Pan Zhou, Jian Lou, Zichuan Xu, Xing Di, Yu Cheng, Lichao",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05641"" target=""_blank"">2207.05641</a>",,2025-12-03 22:39:25
Statistical Detection of Adversarial examples in Blockchain-based Federated Forest In-vehicle Network Intrusion Detection Systems,"Ibrahim Aliyu, Engelenburg Selinde van, Muhammed Bashir Muazu, Jinsul Kim, Chang Gyoon Lim",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.04843"" target=""_blank"">2207.04843</a>",,2025-12-03 22:39:25
Harnessing Out-Of-Distribution Examples via Augmenting Content and Style,"Zhuo Huang, Xiaobo Xia, Li Shen, Bo Han, Mingming Gong, Chen Gong, Tongliang Liu",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.03162"" target=""_blank"">2207.03162</a>",,2025-12-03 22:39:25
Demystifying the Adversarial Robustness of Random Transformation Defenses,"Chawin Sitawarin, Zachary Golan-Strieb, David Wagner",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.03574"" target=""_blank"">2207.03574</a>","<a href=""https://github.com/wagner-group/demystify-random-transform"" target=""_blank"">wagner-group</a>",2025-12-03 22:39:25
The Weaknesses of Adversarial Camouflage in Overhead Imagery,Etten Adam Van,arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.02963"" target=""_blank"">2207.02963</a>","<a href=""https://github.com/IQTLabs/camolo"" target=""_blank"">IQTLabs</a>",2025-12-03 22:39:25
Adversarial Robustness of Visual Dialog,"Lu Yu, Verena Rieser",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.02639"" target=""_blank"">2207.02639</a>",,2025-12-03 22:39:25
Anomaly Detection with Adversarially Learned Perturbations of Latent Space,"Vahid Reza Khazaie, Anthony Wong, John Taylor Jewell, Yalda Mohsenzadeh",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.01106"" target=""_blank"">2207.01106</a>",,2025-12-03 22:39:25
Identifying the Context Shift between Test Benchmarks and Production Data,Matthew Groh,arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.01059"" target=""_blank"">2207.01059</a>",,2025-12-03 22:39:25
FL-Defender: Combating Targeted Attacks in Federated Learning,"Najeeb Jebreel, Josep Domingo-Ferrer",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.00872"" target=""_blank"">2207.00872</a>",,2025-12-03 22:39:25
Backdoor Attack is a Devil in Federated GAN-based Medical Image Synthesis,"Ruinan Jin, Xiaoxiao Li",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.00762"" target=""_blank"">2207.00762</a>",,2025-12-03 22:39:25
PhilaeX: Explaining the Failure and Success of AI Models in Malware Detection,"Zhi Lu, Vrizlynn L. L. Thing",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.00740"" target=""_blank"">2207.00740</a>",,2025-12-03 22:39:25
Efficient Adversarial Training With Data Pruning,"Maximilian Kaufmann, Yiren Zhao, Ilia Shumailov, Robert Mullins, Nicolas Papernot",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.00694"" target=""_blank"">2207.00694</a>",,2025-12-03 22:39:25
BadHash: Invisible Backdoor Attacks against Deep Hashing with Clean Label,"Shengshan Hu, Ziqi Zhou, Yechao Zhang, Leo Yu Zhang, Yifeng Zheng, Yuanyuan HE, Hai Jin",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.00278"" target=""_blank"">2207.00278</a>",,2025-12-03 22:39:25
Measuring Forgetting of Memorized Training Examples,"Matthew Jagielski, Om Thakkar, Florian Tramèr, Daphne Ippolito, Katherine Lee, Nicholas Carlini, Eric Wallace, Shuang Song, Abhradeep Thakurta, Nicolas Papernot, Chiyuan Zhang",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.00099"" target=""_blank"">2207.00099</a>",,2025-12-03 22:39:25
Reliable Representations Make A Stronger Defender: Unsupervised Structure Refinement for Robust GNN,"Kuan Li, Yang Liu, Xiang Ao, Jianfeng Chi, Jinghua Feng, Hao Yang, Qing He",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.00012"" target=""_blank"">2207.00012</a>",,2025-12-03 22:39:25
Threat Assessment in Machine Learning based Systems,"Lionel Nganyewou Tidjon, Foutse Khomh",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.00091"" target=""_blank"">2207.00091</a>",,2025-12-03 22:39:25
Robustness of Epinets against Distributional Shifts,"Xiuyuan Lu, Ian Osband, Seyed Mohammad Asghari, Sven Gowal, Vikranth Dwaracherla, Zheng Wen, Roy Benjamin Van",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.00137"" target=""_blank"">2207.00137</a>",,2025-12-03 22:39:25
ProSelfLC: Progressive Self Label Correction Towards A Low-Temperature Entropy State,"Xinshao Wang, Yang Hua, Elyor Kodirov, Sankha Subhra Mukherjee, David A. Clifton, Neil M. Robertson",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.00118"" target=""_blank"">2207.00118</a>",,2025-12-03 22:39:25
Robustness Evaluation of Deep Unsupervised Learning Algorithms for Intrusion Detection Systems,"D'Jeff Kanda Nkashama, Arian Soltani, Jean-Charles Verdier, Marc Frappier, Pierre-Martin Tardif, Froduald Kabanza",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.03576"" target=""_blank"">2207.03576</a>",,2025-12-03 22:39:25
Transferable Graph Backdoor Attack,"Shuiqiao Yang, Bao Gia Doan, Paul Montague, Vel Olivier De, Tamas Abraham, Seyit Camtepe, Damith C. Ranasinghe, Salil S. Kanhere",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.00425"" target=""_blank"">2207.00425</a>",,2025-12-03 22:39:25
Generative Adversarial Networks and Image-Based Malware Classification,"Huy Nguyen, Troia Fabio Di, Genya Ishigaki, Mark Stamp",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.00421"" target=""_blank"">2207.00421</a>",,2025-12-03 22:39:25
On the Robustness of Bayesian Neural Networks to Adversarial Attacks,"Luca Bortolussi, Ginevra Carbone, Luca Laurenti, Andrea Patane, Guido Sanguinetti, Matthew Wicker",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.06154"" target=""_blank"">2207.06154</a>",,2025-12-03 22:39:25
Adversarial Robustness is at Odds with Lazy Training,"Yunjuan Wang, Enayat Ullah, Poorya Mianjy, Raman Arora",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.00411"" target=""_blank"">2207.00411</a>",,2025-12-03 22:39:25
Removing Batch Normalization Boosts Adversarial Training,"Haotao Wang, Aston Zhang, Shuai Zheng, Xingjian Shi, Mu Li, Zhangyang Wang",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.01156"" target=""_blank"">2207.01156</a>","<a href=""https://github.com/amazon-research/normalizer-free-robust-training"" target=""_blank"">amazon-research</a>",2025-12-03 22:39:25
RAF: Recursive Adversarial Attacks on Face Recognition Using Extremely Limited Queries,"Keshav Kasichainula, Hadi Mansourifar, Weidong Shi",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.01149"" target=""_blank"">2207.01149</a>",,2025-12-03 22:39:25
Counterbalancing Teacher: Regularizing Batch Normalized Models for Robustness,"Saeid Asgari Taghanaki, Ali Gholami, Fereshte Khani, Kristy Choi, Linh Tran, Ran Zhang, Aliasghar Khani",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.01548"" target=""_blank"">2207.01548</a>",,2025-12-03 22:39:25
PRoA: A Probabilistic Robustness Assessment against Functional Perturbations,"Tianle Zhang, Wenjie Ruan, Jonathan E. Fieldsend",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.02036"" target=""_blank"">2207.02036</a>",,2025-12-03 22:39:25
Enhancing Adversarial Attacks on Single-Layer NVM Crossbar-Based Neural Networks with Power Consumption Information,Cory Merkel,arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.02764"" target=""_blank"">2207.02764</a>",,2025-12-03 22:39:25
When does Bias Transfer in Transfer Learning? (10%),"Hadi Salman, Saachi Jain, Andrew Ilyas, Logan Engstrom, Eric Wong, Aleksander Madry",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.02842"" target=""_blank"">2207.02842</a>","<a href=""https://github.com/MadryLab/bias-transfer"" target=""_blank"">MadryLab</a>",2025-12-03 22:39:25
Privacy-preserving Reflection Rendering for Augmented Reality,"Yiqin Zhao, Sheng Wei, Tian Guo",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.03056"" target=""_blank"">2207.03056</a>",,2025-12-03 22:39:25
Not All Models Are Equal: Predicting Model Transferability in a Self-challenging Fisher Space,"Wenqi Shao, Xun Zhao, Yixiao Ge, Zhaoyang Zhang, Lei Yang, Xiaogang Wang, Ying Shan, Ping Luo",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.03036"" target=""_blank"">2207.03036</a>","<a href=""https://github.com/TencentARC/SFDA"" target=""_blank"">TencentARC</a>",2025-12-03 22:39:25
Query-Efficient Adversarial Attack Based on Latin Hypercube Sampling,"Dan Wang, Jiayu Lin, Yuan-Gen Wang",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.02391"" target=""_blank"">2207.02391</a>","<a href=""https://github.com/GZHU-DVL/LHS-BA"" target=""_blank"">GZHU-DVL</a>",2025-12-03 22:39:25
Defending against the Label-flipping Attack in Federated Learning,"Najeeb Moharram Jebreel, Josep Domingo-Ferrer, David Sánchez, Alberto Blanco-Justicia",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.01982"" target=""_blank"">2207.01982</a>",,2025-12-03 22:39:25
UniCR: Universally Approximated Certified Robustness via Randomized Smoothing,"Hanbin Hong, Binghui Wang, Yuan Hong",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.02152"" target=""_blank"">2207.02152</a>",,2025-12-03 22:39:25
Learning to Accelerate Approximate Methods for Solving Integer Programming via Early Fixing,"Longkang Li, Baoyuan Wu",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.02087"" target=""_blank"">2207.02087</a>","<a href=""https://github.com/SCLBD/Accelerated-Lpbox-ADMM"" target=""_blank"">SCLBD</a>",2025-12-03 22:39:25
Large-scale Robustness Analysis of Video Action Recognition Models,"Madeline C. Schiappa, Naman Biyani, Shruti Vyas, Hamid Palangi, Vibhav Vineet, Yogesh Rawat",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.01398"" target=""_blank"">2207.01398</a>","<a href=""https://rose-ar.github.io/"" target=""_blank"">rose-ar.github.io</a>",2025-12-03 22:39:25
Robustness Analysis of Video-Language Models Against Visual and Language Perturbations,"Madeline C. Schiappa, Shruti Vyas, Hamid Palangi, Yogesh S. Rawat, Vibhav Vineet",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.02159"" target=""_blank"">2207.02159</a>",,2025-12-03 22:39:25
Conflicting Interactions Among Protection Mechanisms for Machine Learning Models,"Sebastian Szyller, N. Asokan",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.01991"" target=""_blank"">2207.01991</a>",,2025-12-03 22:39:25
PoF: Post-Training of Feature Extractor for Improving Generalization,"Ikuro Sato, Ryota Yamada, Masayuki Tanaka, Nakamasa Inoue, Rei Kawakami",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.01847"" target=""_blank"">2207.01847</a>","<a href=""https://github.com/DensoITLab/PoF-v1"" target=""_blank"">DensoITLab</a>",2025-12-03 22:39:25
Class-Specific Semantic Reconstruction for Open Set Recognition,"Hongzhi Huang, Yu Wang, Qinghua Hu, Ming-Ming Cheng",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.02158"" target=""_blank"">2207.02158</a>",,2025-12-03 22:39:25
Hessian-Free Second-Order Adversarial Examples for Adversarial Learning,"Yaguan Qian, Yuqi Wang, Bin Wang, Zhaoquan Gu, Yuhan Guo, Wassim Swaileh",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.01396"" target=""_blank"">2207.01396</a>",,2025-12-03 22:39:25
Wild Networks: Exposure of 5G Network Infrastructures to Adversarial Examples,"Giovanni Apruzzese, Rodion Vladimirov, Aliya Tastemirova, Pavel Laskov",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.01531"" target=""_blank"">2207.01531</a>",,2025-12-03 22:39:25
Task-agnostic Defense against Adversarial Patch Attacks,"Ke Xu, Yao Xiao, Zhaoheng Zheng, Kaijie Cai, Ram Nevatia",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.01795"" target=""_blank"">2207.01795</a>",,2025-12-03 22:39:25
Adversarially-Aware Robust Object Detector,"Ziyi Dong, Pengxu Wei, Liang Lin",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.06202"" target=""_blank"">2207.06202</a>",,2025-12-03 22:39:25
Game of Trojans: A Submodular Byzantine Approach,"Dinuka Sahabandu, Arezoo Rajabi, Luyao Niu, Bo Li, Bhaskar Ramasubramanian, Radha Poovendran",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.05937"" target=""_blank"">2207.05937</a>",,2025-12-03 22:39:25
Perturbation Inactivation Based Adversarial Defense for Face Recognition,"Min Ren, Yuhao Zhu, Yunlong Wang, Zhenan Sun",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.06035"" target=""_blank"">2207.06035</a>","<a href=""https://github.com/RenMin1991/Perturbation-Inactivate"" target=""_blank"">RenMin1991</a>",2025-12-03 22:39:25
Can we achieve robustness from data alone? (82%),"Nikolaos Tsilivis, Jingtong Su, Julia Kempe",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.11727"" target=""_blank"">2207.11727</a>",,2025-12-03 22:39:25
Privacy Against Inference Attacks in Vertical Federated Learning,"Borzoo Rassouli, Morteza Varasteh, Deniz Gunduz",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.11788"" target=""_blank"">2207.11788</a>",,2025-12-03 22:39:25
Semantic-guided Multi-Mask Image Harmonization,"Xuqian Ren, Yifan Liu",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.11722"" target=""_blank"">2207.11722</a>","<a href=""https://github.com/XuqianRen/Semantic-guided-Multi-mask-Image-Harmonization"" target=""_blank"">XuqianRen</a>",2025-12-03 22:39:25
Do Perceptually Aligned Gradients Imply Adversarial Robustness? (99%),"Roy Ganz, Bahjat Kawar, Michael Elad",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.11378"" target=""_blank"">2207.11378</a>",,2025-12-03 22:39:25
Provable Defense Against Geometric Transformations,"Rem Yang, Jacob Laurel, Sasa Misailovic, Gagandeep Singh",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.11177"" target=""_blank"">2207.11177</a>",,2025-12-03 22:39:25
Aries: Efficient Testing of Deep Neural Networks via Labeling-Free Accuracy Estimation,"Qiang Hu, Yuejun Guo, Xiaofei Xie, Maxime Cordy, Lei Ma, Mike Papadakis, Yves Le Traon",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.10942"" target=""_blank"">2207.10942</a>",,2025-12-03 22:39:25
Learning from Multiple Annotator Noisy Labels via Sample-wise Label Fusion,"Zhengqi Gao, Fan-Keng Sun, Mingran Yang, Sucheng Ren, Zikai Xiong, Marc Engeler, Antonio Burazer, Linda Wildling, Luca Daniel, Duane S. Boning",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.11327"" target=""_blank"">2207.11327</a>","<a href=""https://github.com/zhengqigao/Learning-from-Multiple-Annotator-Noisy-Labels"" target=""_blank"">zhengqigao</a>",2025-12-03 22:39:25
Synthetic Dataset Generation for Adversarial Machine Learning Research,"Xiruo Liu, Shibani Singh, Cory Cornelius, Colin Busho, Mike Tan, Anindya Paul, Jason Martin",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.10719"" target=""_blank"">2207.10719</a>","<a href=""https://github.com/carla-simulator/carla/pull/4992"" target=""_blank"">pull</a>",2025-12-03 22:39:25
Careful What You Wish For: on the Extraction of Adversarially Trained Models,"Kacem Khaled, Gabriela Nicolescu, Magalhães Felipe Gohring de",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.10561"" target=""_blank"">2207.10561</a>",,2025-12-03 22:39:25
AugRmixAT: A Data Processing and Training Method for Improving Multiple Robustness and Generalization Performance,"Xiaoliang Liu, Furao Shen, Jian Zhao, Changhai Nie",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.10290"" target=""_blank"">2207.10290</a>",,2025-12-03 22:39:25
Knowledge-enhanced Black-box Attacks for Recommendations,"Jingfan Chen, Wenqi Fan, Guanghui Zhu, Xiangyu Zhao, Chunfeng Yuan, Qing Li, Yihua Huang",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.10307"" target=""_blank"">2207.10307</a>",,2025-12-03 22:39:25
Towards Efficient Adversarial Training on Vision Transformers,"Boxi Wu, Jindong Gu, Zhifeng Li, Deng Cai, Xiaofei He, Wei Liu",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.10498"" target=""_blank"">2207.10498</a>",,2025-12-03 22:39:25
Just Rotate it: Deploying Backdoor Attacks via Rotation Transformation,"Tong Wu, Tianhao Wang, Vikash Sehwag, Saeed Mahloujifar, Prateek Mittal",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.10825"" target=""_blank"">2207.10825</a>",,2025-12-03 22:39:25
Contrastive Self-Supervised Learning Leads to Higher Adversarial Susceptibility,"Rohit Gupta, Naveed Akhtar, Ajmal Mian, Mubarak Shah",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.10862"" target=""_blank"">2207.10862</a>",,2025-12-03 22:39:25
Generating and Detecting True Ambiguity: A Forgotten Danger in DNN Supervision Testing,"Michael Weiss, André García Gómez, Paolo Tonella",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.10495"" target=""_blank"">2207.10495</a>",,2025-12-03 22:39:25
Switching One-Versus-the-Rest Loss to Increase the Margin of Logits for Adversarial Robustness,"Sekitoshi Kanai, Shin'ya Yamaguchi, Masanori Yamada, Hiroshi Takahashi, Kentaro Ohno, Yasutoshi Ida",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.10283"" target=""_blank"">2207.10283</a>",,2025-12-03 22:39:25
Illusory Attacks: Detectability Matters in Adversarial Attacks on Sequential Decision-Makers,"Tim Franzmeyer, Stephen McAleer, João F. Henriques, Jakob N. Foerster, Philip H. S. Torr, Adel Bibi, Witt Christian Schroeder de",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.10170"" target=""_blank"">2207.10170</a>",,2025-12-03 22:39:25
Test-Time Adaptation via Conjugate Pseudo-labels,"Sachin Goyal, Mingjie Sun, Aditi Raghunathan, Zico Kolter",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.09640"" target=""_blank"">2207.09640</a>","<a href=""https://github.com/locuslab/tta_conjugate"" target=""_blank"">locuslab</a>",2025-12-03 22:39:25
Proving Common Mechanisms Shared by Twelve Methods of Boosting Adversarial Transferability,"Quanshi Zhang, Xin Wang, Jie Ren, Xu Cheng, Shuyun Lin, Yisen Wang, Xiangming Zhu",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.11694"" target=""_blank"">2207.11694</a>",,2025-12-03 22:39:25
Versatile Weight Attack via Flipping Limited Bits,"Jiawang Bai, Baoyuan Wu, Zhifeng Li, Shu-tao Xia",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.12405"" target=""_blank"">2207.12405</a>",,2025-12-03 22:39:25
A temporally and spatially local spike-based backpropagation algorithm to enable training in hardware,"Anmol Biswas, Vivek Saraswat, Udayan Ganguly",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.09755"" target=""_blank"">2207.09755</a>",,2025-12-03 22:39:25
Semi-Leak: Membership Inference Attacks Against Semi-supervised Learning,"Xinlei He, Hongbin Liu, Neil Zhenqiang Gong, Yang Zhang",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.12535"" target=""_blank"">2207.12535</a>",,2025-12-03 22:39:25
Membership Inference Attacks via Adversarial Examples,"Hamid Jalalzai, Elie Kadoche, Rémi Leluc, Vincent Plassier",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.13572"" target=""_blank"">2207.13572</a>",,2025-12-03 22:39:25
Point Cloud Attacks in Graph Spectral Domain: When 3D Geometry Meets Graph Signal Processing,"Daizong Liu, Wei Hu, Xin Li",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.13326"" target=""_blank"">2207.13326</a>",,2025-12-03 22:39:25
Look Closer to Your Enemy: Learning to Attack via Teacher-student Mimicking,"Mingejie Wang, Zhiqing Tang, Sirui Li, Dingwen Xiao",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.13381"" target=""_blank"">2207.13381</a>",,2025-12-03 22:39:25
Hardly Perceptible Trojan Attack against Neural Networks with Bit Flips,"Jiawang Bai, Kuofeng Gao, Dihong Gong, Shu-Tao Xia, Zhifeng Li, Wei Liu",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.13417"" target=""_blank"">2207.13417</a>","<a href=""https://github.com/jiawangbai/HPT"" target=""_blank"">jiawangbai</a>",2025-12-03 22:39:25
Pro-tuning: Unified Prompt Tuning for Vision Tasks,"Xing Nie, Bolin Ni, Jianlong Chang, Gaomeng Meng, Chunlei Huo, Zhaoxiang Zhang, Shiming Xiang, Qi Tian, Chunhong Pan",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.14381"" target=""_blank"">2207.14381</a>",,2025-12-03 22:39:25
DynaMarks: Defending Against Deep Learning Model Extraction Using Dynamic Watermarking,"Abhishek Chakraborty, Daniel Xing, Yuntao Liu, Ankur Srivastava",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.13321"" target=""_blank"">2207.13321</a>",,2025-12-03 22:39:25
Lipschitz Bound Analysis of Neural Networks,Sarosij Bose,arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07232"" target=""_blank"">2207.07232</a>",,2025-12-03 22:39:25
Label-Only Membership Inference Attack against Node-Level Graph Neural Networks,"Mauro Conti, Jiaxin Li, Stjepan Picek, Jing Xu",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.13766"" target=""_blank"">2207.13766</a>",,2025-12-03 22:39:25
Generative Steganography Network,"Ping Wei, Sheng Li, Xinpeng Zhang, Ge Luo, Zhenxing Qian, Qing Zhou",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.13867"" target=""_blank"">2207.13867</a>",,2025-12-03 22:39:25
LGV: Boosting Adversarial Example Transferability from Large Geometric Vicinity,"Martin Gubri, Maxime Cordy, Mike Papadakis, Yves Le Traon, Koushik Sen",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.13129"" target=""_blank"">2207.13129</a>",,2025-12-03 22:39:25
Perception-Aware Attack: Creating Adversarial Music via Reverse-Engineering Human Perception,"Rui Duan, Zhe Qu, Shangqing Zhao, Leah Ding, Yao Liu, Zhuo Lu",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.13192"" target=""_blank"">2207.13192</a>",,2025-12-03 22:39:25
Generative Extraction of Audio Classifiers for Speaker Identification,"Tejumade Afonja, Lucas Bourtoule, Varun Chandrasekaran, Sageev Oore, Nicolas Papernot",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.12816"" target=""_blank"">2207.12816</a>",,2025-12-03 22:39:25
Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks,"Tilman Räuker, Anson Ho, Stephen Casper, Dylan Hadfield-Menell",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.13243"" target=""_blank"">2207.13243</a>",,2025-12-03 22:39:25
$p$-DkNN: Out-of-Distribution Detection Through Statistical Testing of Deep Representations,"Adam Dziedzic, Stephan Rabanser, Mohammad Yaghini, Armin Ale, Murat A. Erdogdu, Nicolas Papernot",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.12545"" target=""_blank"">2207.12545</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness via Mutual Information Estimation,"Dawei Zhou, Nannan Wang, Xinbo Gao, Bo Han, Xiaoyu Wang, Yibing Zhan, Tongliang Liu",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.12203"" target=""_blank"">2207.12203</a>",,2025-12-03 22:39:25
SegPGD: An Effective and Efficient Adversarial Attack for Evaluating and Boosting Segmentation Robustness,"Jindong Gu, Hengshuang Zhao, Volker Tresp, Philip Torr",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.12391"" target=""_blank"">2207.12391</a>",,2025-12-03 22:39:25
Jigsaw-ViT: Learning Jigsaw Puzzles in Vision Transformer,"Yingyi Chen, Xi Shen, Yahui Liu, Qinghua Tao, Johan A. K. Suykens",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.11971"" target=""_blank"">2207.11971</a>","<a href=""https://yingyichen-cyy.github.io/Jigsaw-ViT/"" target=""_blank"">Jigsaw-ViT</a>",2025-12-03 22:39:25
Malware Triage Approach using a Task Memory based on Meta-Transfer Learning Framework,"Jinting Zhu, Julian Jang-Jaccard, Ian Welch, Harith Al-Sahaf, Seyit Camtepe",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.10242"" target=""_blank"">2207.10242</a>",,2025-12-03 22:39:25
Technical Report: Assisting Backdoor Federated Learning with Whole Population Knowledge Alignment,"Tian Liu, Xueyang Hu, Tao Shu",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.12327"" target=""_blank"">2207.12327</a>",,2025-12-03 22:39:25
Robust Multivariate Time-Series Forecasting: Adversarial Attacks and Defense Mechanisms,"Linbo Liu, Youngsuk Park, Trong Nghia Hoang, Hilaf Hasson, Jun Huan",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.09572"" target=""_blank"">2207.09572</a>",,2025-12-03 22:39:25
Progress and limitations of deep networks to recognize objects in unusual poses,"Amro Abbas, Stéphane Deny",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08034"" target=""_blank"">2207.08034</a>","<a href=""https://github.com/amro-kamal/ObjectPose"" target=""_blank"">amro-kamal</a>",2025-12-03 22:39:25
Exploring The Resilience of Control Execution Skips against False Data Injection Attacks,"Ipsita Koley, Sunandan Adhikary, Soumyajit Dey",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08005"" target=""_blank"">2207.08005</a>",,2025-12-03 22:39:25
Towards the Desirable Decision Boundary by Moderate-Margin Adversarial Training,"Xiaoyu Liang, Yaguan Qian, Jianchang Huang, Xiang Ling, Bin Wang, Chunming Wu, Wassim Swaileh",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07793"" target=""_blank"">2207.07793</a>",,2025-12-03 22:39:25
CARBEN: Composite Adversarial Robustness Benchmark,"Lei Hsiung, Yun-Yun Tsai, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07797"" target=""_blank"">2207.07797</a>",,2025-12-03 22:39:25
Masked Spatial-Spectral Autoencoders Are Excellent Hyperspectral Defenders,"Jiahao Qi, Zhiqiang Gong, Xingyue Liu, Kangcheng Bin, Chen Chen, Yongqian Li, Wei Xue, Yu Zhang, Ping Zhong",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07803"" target=""_blank"">2207.07803</a>",,2025-12-03 22:39:25
Feasibility of Inconspicuous GAN-generated Adversarial Patches against Object Detection,"Svetlana Pavlitskaya, Bianca-Marina Codău, J. Marius Zöllner",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07347"" target=""_blank"">2207.07347</a>",,2025-12-03 22:39:25
PASS: Parameters Audit-based Secure and Fair Federated Learning Scheme against Free Rider,Jianhua Wang,arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07292"" target=""_blank"">2207.07292</a>",,2025-12-03 22:39:25
Adversarial Examples for Model-Based Control: A Sensitivity Analysis,"Po-han Department of Electrical and Computer Engineering, The University of Texas at Austin Li, Ufuk Oden Institute for Computational Engineering and Sciences, The University of Texas at Austin Topcu, Sandeep P. Department of Electrical and Computer Engineering, The University of Texas at Austin Chinchali",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.06982"" target=""_blank"">2207.06982</a>",,2025-12-03 22:39:25
Contrastive Adapters for Foundation Model Group Robustness,"Michael Zhang, Christopher Ré",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07180"" target=""_blank"">2207.07180</a>",,2025-12-03 22:39:25
Adversarial Attacks on Monocular Pose Estimation,"Hemang Chawla, Arnav Varma, Elahe Arani, Bahram Zonooz",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07032"" target=""_blank"">2207.07032</a>",,2025-12-03 22:39:25
Provably Adversarially Robust Nearest Prototype Classifiers,"Václav Voráček, Matthias Hein",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07208"" target=""_blank"">2207.07208</a>",,2025-12-03 22:39:25
Active Data Pattern Extraction Attacks on Generative Language Models,"Bargav Jayaraman, Esha Ghosh, Huseyin Inan, Melissa Chase, Sambuddha Roy, Wei Dai",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.10802"" target=""_blank"">2207.10802</a>",,2025-12-03 22:39:25
Distance Learner: Incorporating Manifold Prior to Model Training,"Aditya Chetan, Nipun Kwatra",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.06888"" target=""_blank"">2207.06888</a>",,2025-12-03 22:39:25
FLDetector: Defending Federated Learning Against Model Poisoning Attacks via Detecting Malicious Clients,"Zaixi Zhang, Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.09209"" target=""_blank"">2207.09209</a>","<a href=""https://github.com/zaixizhang/FLDetector"" target=""_blank"">zaixizhang</a>",2025-12-03 22:39:25
Improving Task-free Continual Learning by Distributionally Robust Memory Evolution,"Zhenyi Wang, Li Shen, Le Fang, Qiuling Suo, Tiehang Duan, Mingchen Gao",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07256"" target=""_blank"">2207.07256</a>",,2025-12-03 22:39:25
Audio-guided Album Cover Art Generation with Genetic Algorithms,"James Marien, Sam Leroux, Bart Dhoedt, Boom Cedric De",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07162"" target=""_blank"">2207.07162</a>",,2025-12-03 22:39:25
Sound Randomized Smoothing in Floating-Point Arithmetics,"Václav Voráček, Matthias Hein",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07209"" target=""_blank"">2207.07209</a>",,2025-12-03 22:39:25
RSD-GAN: Regularized Sobolev Defense GAN Against Speech-to-Text Adversarial Attacks,"Mohammad Esmaeilpour, Nourhene Chaalia, Patrick Cardinal",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.06858"" target=""_blank"">2207.06858</a>",,2025-12-03 22:39:25
MixTailor: Mixed Gradient Aggregation for Robust Learning Against Tailored Attacks,"Ali Ramezani-Kebrya, Iman Tabrizian, Fartash Faghri, Petar Popovski",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07941"" target=""_blank"">2207.07941</a>",,2025-12-03 22:39:25
3DVerifier: Efficient Robustness Verification for 3D Point Cloud Models,"Ronghui Mu, Wenjie Ruan, Leandro S. Marcolino, Qiang Ni",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07539"" target=""_blank"">2207.07539</a>","<a href=""https://github.com/TrustAI/3DVerifier"" target=""_blank"">TrustAI</a>",2025-12-03 22:39:25
Certified Neural Network Watermarks with Randomized Smoothing,"Arpit Bansal, Ping-yeh Chiang, Michael Curry, Rajiv Jain, Curtis Wigington, Varun Manjunatha, John P Dickerson, Tom Goldstein",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.07972"" target=""_blank"">2207.07972</a>","<a href=""https://github.com/arpitbansal297/Certified_Watermarks"" target=""_blank"">arpitbansal297</a>",2025-12-03 22:39:25
A Certifiable Security Patch for Object Tracking in Self-Driving Systems via Historical Deviation Modeling,"Xudong Pan, Qifan Xiao, Mi Zhang, Min Yang",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08556"" target=""_blank"">2207.08556</a>",,2025-12-03 22:39:25
Prior-Guided Adversarial Initialization for Fast Adversarial Training,"Xiaojun Jia, Yong Zhang, Xingxing Wei, Baoyuan Wu, Ke Ma, Jue Wang, Xiaochun Cao",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08859"" target=""_blank"">2207.08859</a>","<a href=""https://github.com/jiaxiaojunQAQ/FGSM-PGI"" target=""_blank"">jiaxiaojunQAQ</a>",2025-12-03 22:39:25
Decorrelative Network Architecture for Robust Electrocardiogram Classification,"Christopher Wiedeman, Ge Wang",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.09031"" target=""_blank"">2207.09031</a>",,2025-12-03 22:39:25
Multi-step domain adaptation by adversarial attack to $\mathcal{H} \Delta \mathcal{H}$-divergence,"Arip Asadulaev, Alexander Panfilov, Andrey Filchenkov",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08948"" target=""_blank"">2207.08948</a>",,2025-12-03 22:39:25
Defending Substitution-Based Profile Pollution Attacks on Sequential Recommenders,"Zhenrui Yue, Huimin Zeng, Ziyi Kou, Lanyu Shang, Dong Wang",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.11237"" target=""_blank"">2207.11237</a>",,2025-12-03 22:39:25
DIMBA: Discretely Masked Black-Box Attack in Single Object Tracking,"Xiangyu Yin, Wenjie Ruan, Jonathan Fieldsend",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08044"" target=""_blank"">2207.08044</a>",,2025-12-03 22:39:25
Adversarial Pixel Restoration as a Pretext Task for Transferable Perturbations,"Hashmat Shadab Malik, Shahina K Kunhimon, Muzammal Naseer, Salman Khan, Fahad Shahbaz Khan",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08803"" target=""_blank"">2207.08803</a>","<a href=""https://github.com/HashmatShadab/APR"" target=""_blank"">HashmatShadab</a>",2025-12-03 22:39:25
Easy Batch Normalization,"Arip Asadulaev, Alexander Panfilov, Andrey Filchenkov",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08940"" target=""_blank"">2207.08940</a>",,2025-12-03 22:39:25
Using Anomaly Detection to Detect Poisoning Attacks in Federated Learning Applications,"Ali Raza, Shujun Li, Kim-Phuc Tran, Ludovic Koehl",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08486"" target=""_blank"">2207.08486</a>",,2025-12-03 22:39:25
Adversarial Contrastive Learning via Asymmetric InfoNCE,"Qiying Yu, Jieming Lou, Xianyuan Zhan, Qizhang Li, Wangmeng Zuo, Yang Liu, Jingjing Liu",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08374"" target=""_blank"">2207.08374</a>","<a href=""https://github.com/yqy2001/A-InfoNCE"" target=""_blank"">yqy2001</a>",2025-12-03 22:39:25
Assaying Out-Of-Distribution Generalization in Transfer Learning,"Florian Wenzel, Andrea Dittadi, Peter Vincent Gehler, Carl-Johann Simon-Gabriel, Max Horn, Dominik Zietlow, David Kernert, Chris Russell, Thomas Brox, Bernt Schiele, Bernhard Schölkopf, Francesco Locatello",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.09239"" target=""_blank"">2207.09239</a>",,2025-12-03 22:39:25
Is Vertical Logistic Regression Privacy-Preserving? A Comprehensive Privacy Analysis and Beyond,"Yuzheng Hu, Tianle Cai, Jinyong Shan, Shange Tang, Chaochao Cai, Ethan Song, Bo Li, Dawn Song",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.09087"" target=""_blank"">2207.09087</a>",,2025-12-03 22:39:25
Benchmarking Machine Learning Robustness in Covid-19 Genome Sequence Classification,"Sarwan Ali, Bikram Sahoo, Alexander Zelikovskiy, Pin-Yu Chen, Murray Patterson",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08898"" target=""_blank"">2207.08898</a>",,2025-12-03 22:39:25
Watermark Vaccine: Adversarial Attacks to Prevent Watermark Removal,"Xinwei Liu, Jian Liu, Yang Bai, Jindong Gu, Tao Chen, Xiaojun Jia, Xiaochun Cao",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08178"" target=""_blank"">2207.08178</a>",,2025-12-03 22:39:25
Threat Model-Agnostic Adversarial Defense using Diffusion Models,"Tsachi Blau, Roy Ganz, Bahjat Kawar, Alex Bronstein, Michael Elad",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08089"" target=""_blank"">2207.08089</a>",,2025-12-03 22:39:25
Achieve Optimal Adversarial Accuracy for Adversarial Deep Learning using Stackelberg Game,"Xiao-Shan Gao, Shuang Liu, Lijia Yu",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08137"" target=""_blank"">2207.08137</a>",,2025-12-03 22:39:25
Automated Repair of Neural Networks,"Dor Cohen, Ofer Strichman",arXiv,2022-07,"<a href=""http://arxiv.org/abs/2207.08157"" target=""_blank"">2207.08157</a>",,2025-12-03 22:39:25
Data-Efficient Double-Win Lottery Tickets from Robust Pre-training,"Tianlong Chen, Zhenyu Zhang, Sijia Liu, Yang Zhang, Shiyu Chang, Zhangyang Wang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04762"" target=""_blank"">2206.04762</a>","<a href=""https://github.com/VITA-Group/Double-Win-LTH"" target=""_blank"">VITA-Group</a>",2025-12-03 22:39:25
ReFace: Real-time Adversarial Attacks on Face Recognition Systems,"Shehzeen Hussain, Todd Huster, Chris Mesterharm, Paarth Neekhara, Kevin An, Malhar Jere, Harshvardhan Sikka, Farinaz Koushanfar",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04783"" target=""_blank"">2206.04783</a>",,2025-12-03 22:39:25
CARLA-GeAR: a Dataset Generator for a Systematic Evaluation of Adversarial Robustness of Vision Models,"Federico Nesti, Giulio Rossolini, Gianluca D'Amico, Alessandro Biondi, Giorgio Buttazzo",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04365"" target=""_blank"">2206.04365</a>",,2025-12-03 22:39:25
Meet You Halfway: Explaining Deep Learning Mysteries,Oriel BenShmuel,arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04463"" target=""_blank"">2206.04463</a>",,2025-12-03 22:39:25
Early Transferability of Adversarial Examples in Deep Neural Networks,Oriel BenShmuel,arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04472"" target=""_blank"">2206.04472</a>",,2025-12-03 22:39:25
GSmooth: Certified Robustness against Semantic Transformations via Generalized Randomized Smoothing,"Zhongkai Hao, Chengyang Ying, Yinpeng Dong, Hang Su, Jun Zhu, Jian Song",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04310"" target=""_blank"">2206.04310</a>",,2025-12-03 22:39:25
Adversarial Counterfactual Environment Model Learning,"Xiong-Hui Chen, Yang Yu, Zheng-Mao Zhu, Zhihua Yu, Zhenjun Chen, Chenghe Wang, Yinan Wu, Hongqiu Wu, Rong-Jun Qin, Ruijin Ding, Fangsheng Huang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04890"" target=""_blank"">2206.04890</a>",,2025-12-03 22:39:25
Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models,"Aarohi Shammie Srivastava, Abhinav Shammie Rastogi, Abhishek Shammie Rao, Abu Awal Md Shammie Shoeb, Abubakar Shammie Abid, Adam Shammie Fisch, Adam R. Shammie Brown, Adam Shammie Santoro, Aditya Shammie Gupta, Adrià Shammie Garriga-Alonso, Agnieszka Shammie Kluska, Aitor Shammie Lewkowycz, Akshat Shammie Agarwal, Alethea Shammie Power, Alex Shammie Ray, Alex Shammie Warstadt, Alexander W. Shammie Kocurek, Ali Shammie Safaya, Ali Shammie Tazarv, Alice Shammie Xiang, Alicia Shammie Parrish, Allen Shammie Nie, Aman Shammie Hussain, Amanda Shammie Askell, Amanda Shammie Dsouza, Ambrose Shammie Slone, Ameet Shammie Rahane, Anantharaman S. Shammie Iyer, Anders Shammie Andreassen, Andrea Shammie Madotto, Andrea Shammie Santilli, Andreas Shammie Stuhlmüller, Andrew Shammie Dai, Andrew Shammie La, Andrew Shammie Lampinen, Andy Shammie Zou, Angela Shammie Jiang, Angelica Shammie Chen, Anh Shammie Vuong, Animesh Shammie Gupta, Anna Shammie Gottardi, Antonio Shammie Norelli, Anu Shammie Venkatesh, Arash Shammie Gholamidavoodi, Arfa Shammie Tabassum, Arul Shammie Menezes, Arun Shammie Kirubarajan, Asher Shammie Mullokandov, Ashish Shammie Sabharwal, Austin Shammie Herrick, Avia Shammie Efrat, Aykut Shammie Erdem, Ayla Shammie Karakaş, B. Ryan Shammie Roberts, Bao Sheng Shammie Loe, Barret Shammie Zoph, Bartłomiej Shammie Bojanowski, Batuhan Shammie Özyurt, Behnam Shammie Hedayatnia, Behnam Shammie Neyshabur, Benjamin Shammie Inden, Benno Shammie Stein, Berk Shammie Ekmekci, Bill Yuchen Shammie Lin, Blake Shammie Howald, Cameron Shammie Diao, Cameron Shammie Dour, Catherine Shammie Stinson, Cedrick Shammie Argueta, César Ferri Shammie Ramírez, Chandan Shammie Singh, Charles Shammie Rathkopf, Chenlin Shammie Meng, Chitta Shammie Baral, Chiyu Shammie Wu, Chris Shammie Callison-Burch, Chris Shammie Waites, Christian Shammie Voigt, Christopher D. Shammie Manning, Christopher Shammie Potts, Cindy Shammie Ramirez, Clara E. Shammie Rivera, Clemencia Shammie Siro, Colin Shammie Raffel, Courtney Shammie Ashcraft, Cristina Shammie Garbacea, Damien Shammie Sileo, Dan Shammie Garrette, Dan Shammie Hendrycks, Dan Shammie Kilman, Dan Shammie Roth, Daniel Shammie Freeman, Daniel Shammie Khashabi, Daniel Shammie Levy, Daniel Moseguí Shammie González, Danielle Shammie Perszyk, Danny Shammie Hernandez, Danqi Shammie Chen, Daphne Shammie Ippolito, Dar Shammie Gilboa, David Shammie Dohan, David Shammie Drakard, David Shammie Jurgens, Debajyoti Shammie Datta, Deep Shammie Ganguli, Denis Shammie Emelin, Denis Shammie Kleyko, Deniz Shammie Yuret, Derek Shammie Chen, Derek Shammie Tam, Dieuwke Shammie Hupkes, Diganta Shammie Misra, Dilyar Shammie Buzan, Dimitri Coelho Shammie Mollo, Diyi Shammie Yang, Dong-Ho Shammie Lee, Ekaterina Shammie Shutova, Ekin Dogus Shammie Cubuk, Elad Shammie Segal, Eleanor Shammie Hagerman, Elizabeth Shammie Barnes, Elizabeth Shammie Donoway, Ellie Shammie Pavlick, Emanuele Shammie Rodola, Emma Shammie Lam, Eric Shammie Chu, Eric Shammie Tang, Erkut Shammie Erdem, Ernie Shammie Chang, Ethan A. Shammie Chi, Ethan Shammie Dyer, Ethan Shammie Jerzak, Ethan Shammie Kim, Eunice Engefu Shammie Manyasi, Evgenii Shammie Zheltonozhskii, Fanyue Shammie Xia, Fatemeh Shammie Siar, Fernando Shammie Martínez-Plumed, Francesca Shammie Happé, Francois Shammie Chollet, Frieda Shammie Rong, Gaurav Shammie Mishra, Genta Indra Shammie Winata, Melo Gerard Shammie de, Germán Shammie Kruszewski, Giambattista Shammie Parascandolo, Giorgio Shammie Mariani, Gloria Shammie Wang, Gonzalo Shammie Jaimovitch-López, Gregor Shammie Betz, Guy Shammie Gur-Ari, Hana Shammie Galijasevic, Hannah Shammie Kim, Hannah Shammie Rashkin, Hannaneh Shammie Hajishirzi, Harsh Shammie Mehta, Hayden Shammie Bogar, Henry Shammie Shevlin, Hinrich Shammie Schütze, Hiromu Shammie Yakura, Hongming Shammie Zhang, Hugh Mee Shammie Wong, Ian Shammie Ng, Isaac Shammie Noble, Jaap Shammie Jumelet, Jack Shammie Geissinger, Jackson Shammie Kernion, Jacob Shammie Hilton, Jaehoon Shammie Lee, Jaime Fernández Shammie Fisac, James B. Shammie Simon, James Shammie Koppel, James Shammie Zheng, James Shammie Zou, Jan Shammie Kocoń, Jana Shammie Thompson, Jared Shammie Kaplan, Jarema Shammie Radom, Jascha Shammie Sohl-Dickstein, Jason Shammie Phang, Jason Shammie Wei, Jason Shammie Yosinski, Jekaterina Shammie Novikova, Jelle Shammie Bosscher, Jennifer Shammie Marsh, Jeremy Shammie Kim, Jeroen Shammie Taal, Jesse Shammie Engel, Jesujoba Shammie Alabi, Jiacheng Shammie Xu, Jiaming Shammie Song, Jillian Shammie Tang, Joan Shammie Waweru, John Shammie Burden, John Shammie Miller, John U. Shammie Balis, Jonathan Shammie Berant, Jörg Shammie Frohberg, Jos Shammie Rozen, Jose Shammie Hernandez-Orallo, Joseph Shammie Boudeman, Joseph Shammie Jones, Joshua B. Shammie Tenenbaum, Joshua S. Shammie Rule, Joyce Shammie Chua, Kamil Shammie Kanclerz, Karen Shammie Livescu, Karl Shammie Krauth, Karthik Shammie Gopalakrishnan, Katerina Shammie Ignatyeva, Katja Shammie Markert, Kaustubh D. Shammie Dhole, Kevin Shammie Gimpel, Kevin Shammie Omondi, Kory Shammie Mathewson, Kristen Shammie Chiafullo, Ksenia Shammie Shkaruta, Kumar Shammie Shridhar, Kyle Shammie McDonell, Kyle Shammie Richardson, Laria Shammie Reynolds, Leo Shammie Gao, Li Shammie Zhang, Liam Shammie Dugan, Lianhui Shammie Qin, Lidia Shammie Contreras-Ochando, Louis-Philippe Shammie Morency, Luca Shammie Moschella, Lucas Shammie Lam, Lucy Shammie Noble, Ludwig Shammie Schmidt, Luheng Shammie He, Luis Oliveros Shammie Colón, Luke Shammie Metz, Lütfi Kerem Shammie Şenel, Maarten Shammie Bosma, Maarten Shammie Sap, Hoeve Maartje Shammie ter, Maheen Shammie Farooqi, Manaal Shammie Faruqui, Mantas Shammie Mazeika, Marco Shammie Baturan, Marco Shammie Marelli, Marco Shammie Maru, Maria Jose Ramírez Shammie Quintana, Marie Shammie Tolkiehn, Mario Shammie Giulianelli, Martha Shammie Lewis, Martin Shammie Potthast, Matthew L. Shammie Leavitt, Matthias Shammie Hagen, Mátyás Shammie Schubert, Medina Orduna Shammie Baitemirova, Melody Shammie Arnaud, Melvin Shammie McElrath, Michael A. Shammie Yee, Michael Shammie Cohen, Michael Shammie Gu, Michael Shammie Ivanitskiy, Michael Shammie Starritt, Michael Shammie Strube, Michał Shammie Swędrowski, Michele Shammie Bevilacqua, Michihiro Shammie Yasunaga, Mihir Shammie Kale, Mike Shammie Cain, Mimee Shammie Xu, Mirac Shammie Suzgun, Mo Shammie Tiwari, Mohit Shammie Bansal, Moin Shammie Aminnaseri, Mor Shammie Geva, Mozhdeh Shammie Gheini, Mukund Varma Shammie T, Nanyun Shammie Peng, Nathan Shammie Chi, Nayeon Shammie Lee, Neta Gur-Ari Shammie Krakover, Nicholas Shammie Cameron, Nicholas Shammie Roberts, Nick Shammie Doiron, Nikita Shammie Nangia, Niklas Shammie Deckers, Niklas Shammie Muennighoff, Nitish Shirish Shammie Keskar, Niveditha S. Shammie Iyer, Noah Shammie Constant, Noah Shammie Fiedel, Nuan Shammie Wen, Oliver Shammie Zhang, Omar Shammie Agha, Omar Shammie Elbaghdadi, Omer Shammie Levy, Owain Shammie Evans, Pablo Antonio Moreno Shammie Casares, Parth Shammie Doshi, Pascale Shammie Fung, Paul Pu Shammie Liang, Paul Shammie Vicol, Pegah Shammie Alipoormolabashi, Peiyuan Shammie Liao, Percy Shammie Liang, Peter Shammie Chang, Peter Shammie Eckersley, Phu Mon Shammie Htut, Pinyu Shammie Hwang, Piotr Shammie Miłkowski, Piyush Shammie Patil, Pouya Shammie Pezeshkpour, Priti Shammie Oli, Qiaozhu Shammie Mei, Qing Shammie Lyu, Qinlang Shammie Chen, Rabin Shammie Banjade, Rachel Etta Shammie Rudolph, Raefer Shammie Gabriel, Rahel Shammie Habacker, Ramón Risco Shammie Delgado, Raphaël Shammie Millière, Rhythm Shammie Garg, Richard Shammie Barnes, Rif A. Shammie Saurous, Riku Shammie Arakawa, Robbe Shammie Raymaekers, Robert Shammie Frank, Rohan Shammie Sikand, Roman Shammie Novak, Roman Shammie Sitelew, Ronan Shammie LeBras, Rosanne Shammie Liu, Rowan Shammie Jacobs, Rui Shammie Zhang, Ruslan Shammie Salakhutdinov, Ryan Shammie Chi, Ryan Shammie Lee, Ryan Shammie Stovall, Ryan Shammie Teehan, Rylan Shammie Yang, Sahib Shammie Singh, Saif M. Shammie Mohammad, Sajant Shammie Anand, Sam Shammie Dillavou, Sam Shammie Shleifer, Sam Shammie Wiseman, Samuel Shammie Gruetter, Samuel R. Shammie Bowman, Samuel S. Shammie Schoenholz, Sanghyun Shammie Han, Sanjeev Shammie Kwatra, Sarah A. Shammie Rous, Sarik Shammie Ghazarian, Sayan Shammie Ghosh, Sean Shammie Casey, Sebastian Shammie Bischoff, Sebastian Shammie Gehrmann, Sebastian Shammie Schuster, Sepideh Shammie Sadeghi, Shadi Shammie Hamdan, Sharon Shammie Zhou, Shashank Shammie Srivastava, Sherry Shammie Shi, Shikhar Shammie Singh, Shima Shammie Asaadi, Shixiang Shane Shammie Gu, Shubh Shammie Pachchigar, Shubham Shammie Toshniwal, Shyam Shammie Upadhyay, Shammie Shyamolima, Debnath, Siamak Shakeri, Simon Thormeyer, Simone Melzi, Siva Reddy, Sneha Priscilla Makini, Soo-Hwan Lee, Spencer Torene, Sriharsha Hatwar, Stanislas Dehaene, Stefan Divic, Stefano Ermon, Stella Biderman, Stephanie Lin, Stephen Prasad, Steven T. Piantadosi, Stuart M. Shieber, Summer Misherghi, Svetlana Kiritchenko, Swaroop Mishra, Tal Linzen, Tal Schuster, Tao Li, Tao Yu, Tariq Ali, Tatsu Hashimoto, Te-Lin Wu, Théo Desbordes, Theodore Rothschild, Thomas Phan, Tianle Wang, Tiberius Nkinyili, Timo Schick, Timofei Kornev, Timothy Telleen-Lawton, Titus Tunduny, Tobias Gerstenberg, Trenton Chang, Trishala Neeraj, Tushar Khot, Tyler Shultz, Uri Shaham, Vedant Misra, Vera Demberg, Victoria Nyamai, Vikas Raunak, Vinay Ramasesh, Vinay Uday Prabhu, Vishakh Padmakumar, Vivek Srikumar, William Fedus, William Saunders, William Zhang, Wout Vossen, Xiang Ren, Xiaoyu Tong, Xinran Zhao, Xinyi Wu, Xudong Shen, Yadollah Yaghoobzadeh, Yair Lakretz, Yangqiu Song, Yasaman Bahri, Yejin Choi, Yichi Yang, Yiding Hao, Yifu Chen, Yonatan Belinkov, Yu Hou, Yufang Hou, Yuntao Bai, Zachary Seid, Zhuoye Zhao, Zijian Wang, Zijie J. Wang, Zirui Wang, Ziyi Wu",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04615"" target=""_blank"">2206.04615</a>",,2025-12-03 22:39:25
Adversarial Text Normalization,"Joanna Bitton, Maya Pavlova, Ivan Evtimov",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04137"" target=""_blank"">2206.04137</a>",,2025-12-03 22:39:25
DORA: Exploring outlier representations in Deep Neural Networks,"Kirill Bykov, Mayukh Deb, Dennis Grinwald, Klaus-Robert Müller, Marina M. -C. Höhne",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04530"" target=""_blank"">2206.04530</a>",,2025-12-03 22:39:25
Membership Inference via Backdooring,"Hongsheng Hu, Zoran Salcic, Gillian Dobbie, Jinjun Chen, Lichao Sun, Xuyun Zhang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04823"" target=""_blank"">2206.04823</a>",,2025-12-03 22:39:25
Wavelet Regularization Benefits Adversarial Training,"Jun Yan, Huilin Yin, Xiaoyang Deng, Ziming Zhao, Wancheng Ge, Hao Zhang, Gerhard Rigoll",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03727"" target=""_blank"">2206.03727</a>","<a href=""https://github.com/momo1986/AdversarialWaveletTraining"" target=""_blank"">momo1986</a>",2025-12-03 22:39:25
Latent Boundary-guided Adversarial Training,"Xiaowei Zhou, Ivor W. Tsang, Jie Yin",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03717"" target=""_blank"">2206.03717</a>",,2025-12-03 22:39:25
Autoregressive Perturbations for Data Poisoning,"Pedro Sandoval-Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein, David W. Jacobs",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03693"" target=""_blank"">2206.03693</a>",,2025-12-03 22:39:25
Toward Certified Robustness Against Real-World Distribution Shifts,"Haoze Wu, Teruhiro Tagomori, Alexander Robey, Fengjun Yang, Nikolai Matni, George Pappas, Hamed Hassani, Corina Pasareanu, Clark Barrett",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03669"" target=""_blank"">2206.03669</a>",,2025-12-03 22:39:25
Robust Deep Ensemble Method for Real-world Image Denoising,"Pengju Liu, Hongzhi Zhang, Jinghui Wang, Yuzhi Wang, Dongwei Ren, Wangmeng Zuo",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03691"" target=""_blank"">2206.03691</a>",,2025-12-03 22:39:25
Fooling Explanations in Text Classifiers,"Adam Ivankay, Ivan Girardi, Chiara Marchiori, Pascal Frossard",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03178"" target=""_blank"">2206.03178</a>",,2025-12-03 22:39:25
Enhancing Clean Label Backdoor Attack with Two-phase Specific Triggers,"Nan Luo, Yuanzhang Li, Yajie Wang, Shangbo Wu, Yu-an Tan, Quanxin Zhang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04881"" target=""_blank"">2206.04881</a>",,2025-12-03 22:39:25
AS2T: Arbitrary Source-To-Target Adversarial Attack on Speaker Recognition Systems,"Guangke Chen, Zhe Zhao, Fu Song, Sen Chen, Lingling Fan, Yang Liu",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03351"" target=""_blank"">2206.03351</a>",,2025-12-03 22:39:25
Towards Understanding and Mitigating Audio Adversarial Examples for Speaker Recognition,"Guangke Chen, Zhe Zhao, Fu Song, Sen Chen, Lingling Fan, Feng Wang, Jiashui Wang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03393"" target=""_blank"">2206.03393</a>",,2025-12-03 22:39:25
Deep Leakage from Model in Federated Learning,"Zihao Zhao, Mengen Luo, Wenbo Ding",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04887"" target=""_blank"">2206.04887</a>",,2025-12-03 22:39:25
"An adversarially robust data-market for spatial, crowd-sourced data","Aida Manzano Kharman, Christian Jursitzky, Quan Zhou, Pietro Ferraro, Jakub Marecek, Pierre Pinson, Robert Shorten",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.06299"" target=""_blank"">2206.06299</a>",,2025-12-03 22:39:25
Blades: A Unified Benchmark Suite for Byzantine Attacks and Defenses in Federated Learning,"Shenghui Li, Edith Ngai, Fanghua Ye, Li Ju, Tianru Zhang, Thiemo Voigt",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.05359"" target=""_blank"">2206.05359</a>",,2025-12-03 22:39:25
Efficient Human-in-the-loop System for Guiding DNNs Attention,"Yi He, Xi Yang, Chia-Ming Chang, Haoran Xie, Takeo Igarashi",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.05981"" target=""_blank"">2206.05981</a>",,2025-12-03 22:39:25
Building Robust Ensembles via Margin Boosting,"Dinghuai Zhang, Hongyang Zhang, Aaron Courville, Yoshua Bengio, Pradeep Ravikumar, Arun Sai Suggala",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03362"" target=""_blank"">2206.03362</a>",,2025-12-03 22:39:25
Turning a Curse Into a Blessing: Enabling Clean-Data-Free Defenses by Model Inversion,"Si Chen, Yi Zeng, Won Park, Ruoxi Jia",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07018"" target=""_blank"">2206.07018</a>",,2025-12-03 22:39:25
Human Eyes Inspired Recurrent Neural Networks are More Robust Against Adversarial Noises,"Minkyu Choi, Yizhen Zhang, Kuan Han, Xiaokai Wang, Zhongming Liu",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07282"" target=""_blank"">2206.07282</a>",,2025-12-03 22:39:25
Exploring Adversarial Attacks and Defenses in Vision Transformers trained with DINO,"Javier Rando, Nasib Naimi, Thomas Baumann, Max Mathys",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.06761"" target=""_blank"">2206.06761</a>",,2025-12-03 22:39:25
Attacks on Perception-Based Control Systems: Modeling and Fundamental Limits,"Amir Khazraei, Henry Pfister, Miroslav Pajic",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07150"" target=""_blank"">2206.07150</a>",,2025-12-03 22:39:25
A Gift from Label Smoothing: Robust Training with Adaptive Label Smoothing via Auxiliary Classifier under Label Noise,"Jongwoo Ko, Bongsoo Yi, Se-Young Yun",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07277"" target=""_blank"">2206.07277</a>","<a href=""https://github.com/jongwooko/ALASCA"" target=""_blank"">jongwooko</a>",2025-12-03 22:39:25
"A Survey on Gradient Inversion: Attacks, Defenses and Future Directions","Rui Zhang, Song Guo, Junxiao Wang, Xin Xie, Dacheng Tao",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07284"" target=""_blank"">2206.07284</a>",,2025-12-03 22:39:25
Towards Alternative Techniques for Improving Adversarial Robustness: Analysis of Adversarial Training at a Spectrum of Perturbations,"Kaustubh Sridhar, Souradeep Dutta, Ramneet Kaur, James Weimer, Oleg Sokolsky, Insup Lee",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.06496"" target=""_blank"">2206.06496</a>",,2025-12-03 22:39:25
Distributed Adversarial Training to Robustify Deep Neural Networks at Scale,"Gaoyuan Zhang, Songtao Lu, Yihua Zhang, Xiangyi Chen, Pin-Yu Chen, Quanfu Fan, Lee Martie, Lior Horesh, Mingyi Hong, Sijia Liu",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.06257"" target=""_blank"">2206.06257</a>","<a href=""https://github.com/dat-2022/dat"" target=""_blank"">dat-2022</a>",2025-12-03 22:39:25
Pixel to Binary Embedding Towards Robustness for CNNs,"Ikki Kishida, Hideki Nakayama",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.05898"" target=""_blank"">2206.05898</a>",,2025-12-03 22:39:25
Towards Understanding Sharpness-Aware Minimization,"Maksym Andriushchenko, Nicolas Flammarion",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.06232"" target=""_blank"">2206.06232</a>","<a href=""https://github.com/tml-epfl/understanding-sam"" target=""_blank"">tml-epfl</a>",2025-12-03 22:39:25
Consistent Attack: Universal Adversarial Perturbation on Embodied Vision Navigation,"Chengyang Ying, You Qiaoben, Xinning Zhou, Hang Su, Wenbo Ding, Jianyong Ai",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.05751"" target=""_blank"">2206.05751</a>",,2025-12-03 22:39:25
Rethinking the Defense Against Free-rider Attack From the Perspective of Model Weight Evolving Frequency,"Jinyin Chen, Mingjun Li, Tao Liu, Haibin Zheng, Yao Cheng, Changting Lin",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.05406"" target=""_blank"">2206.05406</a>",,2025-12-03 22:39:25
Security of Machine Learning-Based Anomaly Detection in Cyber Physical Systems,"Zahra Jadidi, Shantanu Pal, Nithesh Nayak K, Arawinkumaar Selvakkumar, Chih-Chia Chang, Maedeh Beheshti, Alireza Jolfaei",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.05678"" target=""_blank"">2206.05678</a>",,2025-12-03 22:39:25
Darknet Traffic Classification and Adversarial Attacks,"Nhien Rust-Nguyen, Mark Stamp",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.06371"" target=""_blank"">2206.06371</a>",,2025-12-03 22:39:25
InBiaseD: Inductive Bias Distillation to Improve Generalization and Robustness through Shape-awareness,"Shruthi Gowda, Bahram Zonooz, Elahe Arani",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.05846"" target=""_blank"">2206.05846</a>",,2025-12-03 22:39:25
RSSD: Defend against Ransomware with Hardware-Isolated Network-Storage Codesign and Post-Attack Analysis,"Benjamin Reidys, Peng Liu, Jian Huang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.05821"" target=""_blank"">2206.05821</a>",,2025-12-03 22:39:25
Neurotoxin: Durable Backdoors in Federated Learning,"Zhengming Zhang, Ashwinee Panda, Linyue Song, Yaoqing Yang, Michael W. Mahoney, Joseph E. Gonzalez, Kannan Ramchandran, Prateek Mittal",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.10341"" target=""_blank"">2206.10341</a>",,2025-12-03 22:39:25
An Efficient Method for Sample Adversarial Perturbations against Nonlinear Support Vector Machines,"Wen Su, Qingna Li",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.05664"" target=""_blank"">2206.05664</a>",,2025-12-03 22:39:25
Improving the Adversarial Robustness of NLP Models by Information Bottleneck,"Cenyuan Zhang, Xiang Zhou, Yixin Wan, Xiaoqing Zheng, Kai-Wei Chang, Cho-Jui Hsieh",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.05511"" target=""_blank"">2206.05511</a>",,2025-12-03 22:39:25
Defending Adversarial Examples by Negative Correlation Ensemble,"Wenjian Luo, Hongwei Zhang, Linghao Kong, Zhijian Chen, Ke Tang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.10334"" target=""_blank"">2206.10334</a>",,2025-12-03 22:39:25
NeuGuard: Lightweight Neuron-Guided Defense against Membership Inference Attacks,"Nuo Xu, Binghui Wang, Ran Ran, Wujie Wen, Parv Venkitasubramaniam",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.05565"" target=""_blank"">2206.05565</a>",,2025-12-03 22:39:25
Bilateral Dependency Optimization: Defending Against Model-inversion Attacks,"Xiong Peng, Feng Liu, Jingfen Zhang, Long Lan, Junjie Ye, Tongliang Liu, Bo Han",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.05483"" target=""_blank"">2206.05483</a>",,2025-12-03 22:39:25
Localized adversarial artifacts for compressed sensing MRI,"Rima Alaifari, Giovanni S. Alberti, Tandri Gauksson",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.05289"" target=""_blank"">2206.05289</a>",,2025-12-03 22:39:25
Adaptive Regularization for Adversarial Training,"Dongyoon Yang, Insung Kong, Yongdai Kim",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03353"" target=""_blank"">2206.03353</a>",,2025-12-03 22:39:25
Anti-Forgery: Towards a Stealthy and Robust DeepFake Disruption Attack via Adversarial Perceptual-aware Perturbations,"Run Wang, Ziheng Huang, Zhikai Chen, Li Liu, Jing Chen, Lina Wang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00477"" target=""_blank"">2206.00477</a>","<a href=""https://github.com/AbstractTeen/AntiForgery/"" target=""_blank"">AntiForgery</a>",2025-12-03 22:39:25
On the Permanence of Backdoors in Evolving Models,"Huiying Li, Arjun Nitin Bhagoji, Yuxin Chen, Haitao Zheng, Ben Y. Zhao",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04677"" target=""_blank"">2206.04677</a>",,2025-12-03 22:39:25
Subject Membership Inference Attacks in Federated Learning,"Anshuman Suri, Pallika Kanani, Virendra J. Marathe, Daniel W. Peterson",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03317"" target=""_blank"">2206.03317</a>",,2025-12-03 22:39:25
Adversarial Unlearning: Reducing Confidence Along Adversarial Directions,"Amrith Setlur, Benjamin Eysenbach, Virginia Smith, Sergey Levine",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.01367"" target=""_blank"">2206.01367</a>",,2025-12-03 22:39:25
A temporal chrominance trigger for clean-label backdoor attack against anti-spoof rebroadcast detection,"Wei Guo, Benedetta Tondi, Mauro Barni",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.01102"" target=""_blank"">2206.01102</a>",,2025-12-03 22:39:25
Learning Unbiased Transferability for Domain Adaptation by Uncertainty Modeling,"Jian Hu, Haowen Zhong, Junchi Yan, Shaogang Gong, Guile Wu, Fei Yang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.01319"" target=""_blank"">2206.01319</a>",,2025-12-03 22:39:25
On the reversibility of adversarial attacks,"Chau Yi Li, Ricardo Sánchez-Matilla, Ali Shahin Shamsabadi, Riccardo Mazzon, Andrea Cavallaro",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00772"" target=""_blank"">2206.00772</a>",,2025-12-03 22:39:25
NeuroUnlock: Unlocking the Architecture of Obfuscated Deep Neural Networks,"Mahya Morid Ahmadi, Lilas Alrahis, Alessio Colucci, Ozgur Sinanoglu, Muhammad Shafique",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00402"" target=""_blank"">2206.00402</a>",,2025-12-03 22:39:25
Attack-Agnostic Adversarial Detection,"Jiaxin Cheng, Mohamed Hussein, Jay Billa, Wael AbdAlmageed",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00489"" target=""_blank"">2206.00489</a>",,2025-12-03 22:39:25
On the Perils of Cascading Robust Classifiers,"Ravi Mangal, Zifan Wang, Chi Zhang, Klas Leino, Corina Pasareanu, Matt Fredrikson",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00278"" target=""_blank"">2206.00278</a>","<a href=""https://github.com/TristaChi/ensembleKW"" target=""_blank"">TristaChi</a>",2025-12-03 22:39:25
Support Vector Machines under Adversarial Label Contamination,"Huang Xiao, Battista Biggio, Blaine Nelson, Han Xiao, Claudia Eckert, Fabio Roli",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00352"" target=""_blank"">2206.00352</a>",,2025-12-03 22:39:25
Defense Against Gradient Leakage Attacks via Learning to Obscure Data,"Yuxuan Wan, Han Xu, Xiaorui Liu, Jie Ren, Wenqi Fan, Jiliang Tang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00769"" target=""_blank"">2206.00769</a>",,2025-12-03 22:39:25
The robust way to stack and bag: the local Lipschitz way,"Thulasi Tholeti, Sheetal Kalyani",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00513"" target=""_blank"">2206.00513</a>",,2025-12-03 22:39:25
Robustness Evaluation and Adversarial Training of an Instance Segmentation Model,"Jacob Bond, Andrew Lingg",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.02539"" target=""_blank"">2206.02539</a>",,2025-12-03 22:39:25
Sequential Bayesian Neural Subnetwork Ensembles,"Sanket Jantre, Shrijita Bhattacharya, Nathan M. Urban, Byung-Jun Yoon, Tapabrata Maiti, Prasanna Balaprakash, Sandeep Madireddy",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00794"" target=""_blank"">2206.00794</a>",,2025-12-03 22:39:25
RoCourseNet: Distributionally Robust Training of a Prediction Aware Recourse Model,"Hangzhi Guo, Feiran Jia, Jinghui Chen, Anna Squicciarini, Amulya Yadav",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00700"" target=""_blank"">2206.00700</a>",,2025-12-03 22:39:25
CodeAttack: Code-based Adversarial Attacks for Pre-Trained Programming Language Models,"Akshita Jha, Chandan K. Reddy",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00052"" target=""_blank"">2206.00052</a>",,2025-12-03 22:39:25
CASSOCK: Viable Backdoor Attacks against DNN in The Wall of Source-Specific Backdoor Defences,"Shang Wang, Yansong Gao, Anmin Fu, Zhi Zhang, Yuqing Zhang, Willy Susilo",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00145"" target=""_blank"">2206.00145</a>",,2025-12-03 22:39:25
Order-sensitive Shapley Values for Evaluating Conceptual Soundness of NLP Models,"Kaiji Lu, Anupam Datta",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00192"" target=""_blank"">2206.00192</a>",,2025-12-03 22:39:25
Generative Models with Information-Theoretic Protection Against Membership Inference Attacks,"Parisa Hassanzadeh, Robert E. Tillman",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00071"" target=""_blank"">2206.00071</a>",,2025-12-03 22:39:25
Securing AI-based Healthcare Systems using Blockchain Technology: A State-of-the-Art Systematic Literature Review and Future Research Directions,"Rucha Shinde, Shruti Patil, Ketan Kotecha, Vidyasagar Potdar, Ganeshsree Selvachandran, Ajith Abraham",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.04793"" target=""_blank"">2206.04793</a>",,2025-12-03 22:39:25
White-box Membership Attack Against Machine Learning Based Retinopathy Classification,"Mounia Hamidouche, Reda Bellafqira, Gwenolé Quellec, Gouenou Coatrieux",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03584"" target=""_blank"">2206.03584</a>",,2025-12-03 22:39:25
Context-based Virtual Adversarial Training for Text Classification with Noisy Labels,"Do-Myoung Lee, Yeachan Kim, Chang-gyun Seo",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.11851"" target=""_blank"">2206.11851</a>",,2025-12-03 22:39:25
Contributor-Aware Defenses Against Adversarial Backdoor Attacks,"Glenn Dawson, Muhammad Umer, Robi Polikar",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03583"" target=""_blank"">2206.03583</a>",,2025-12-03 22:39:25
A Simple Yet Efficient Method for Adversarial Word-Substitute Attack,"Tianle Li, Yi Yang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.05015"" target=""_blank"">2206.05015</a>",,2025-12-03 22:39:25
On the explainable properties of 1-Lipschitz Neural Networks: An Optimal Transport Perspective,"Mathieu IRIT, UT Serrurier, Franck UT Mamalet, Thomas UT Fel, Louis UT3, UT, IRIT Béthune, Thibaut UT Boissin",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.06854"" target=""_blank"">2206.06854</a>",,2025-12-03 22:39:25
Adversarial Laser Spot: Robust and Covert Physical Adversarial Attack to DNNs,Chengyin Hu,arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.01034"" target=""_blank"">2206.01034</a>",,2025-12-03 22:39:25
Adversarial RAW: Image-Scaling Attack Against Imaging Pipeline,"Junjian Li, Honglong Chen",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.01733"" target=""_blank"">2206.01733</a>",,2025-12-03 22:39:25
Adaptive Adversarial Training to Improve Adversarial Robustness of DNNs for Medical Image Segmentation and Detection,"Linhai Ma, Liang Liang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.01736"" target=""_blank"">2206.01736</a>",,2025-12-03 22:39:25
Anomaly Detection with Test Time Augmentation and Consistency Evaluation,"Haowei He, Jiaye Teng, Yang Yuan",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.02345"" target=""_blank"">2206.02345</a>",,2025-12-03 22:39:25
Adversarial Reprogramming Revisited,"Matthias Englert, Ranko Lazic",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03466"" target=""_blank"">2206.03466</a>",,2025-12-03 22:39:25
Certifying Data-Bias Robustness in Linear Regression,"Anna P. Meyer, Aws Albarghouthi, Loris D'Antoni",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03575"" target=""_blank"">2206.03575</a>",,2025-12-03 22:39:25
Parametric Chordal Sparsity for SDP-based Neural Network Verification,"Anton Xue, Lars Lindemann, Rajeev Alur",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03482"" target=""_blank"">2206.03482</a>",,2025-12-03 22:39:25
Can CNNs Be More Robust Than Transformers? (1%),"Zeyu Wang, Yutong Bai, Yuyin Zhou, Cihang Xie",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.03452"" target=""_blank"">2206.03452</a>","<a href=""https://github.com/UCSC-VLAA/RobustCNN"" target=""_blank"">UCSC-VLAA</a>",2025-12-03 22:39:25
Robust Adversarial Attacks Detection based on Explainable Deep Reinforcement Learning For UAV Guidance and Planning,"Thomas Hickling, Nabil Aouf, Phillippa Spencer",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.02670"" target=""_blank"">2206.02670</a>",,2025-12-03 22:39:25
Fast Adversarial Training with Adaptive Step Size,"Zhichao Huang, Yanbo Fan, Chen Liu, Weizhong Zhang, Yong Zhang, Mathieu Salzmann, Sabine Süsstrunk, Jue Wang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.02417"" target=""_blank"">2206.02417</a>",,2025-12-03 22:39:25
Certified Robustness in Federated Learning,"Motasem Alfarra, Juan C. Pérez, Egor Shulgin, Peter Richtárik, Bernard Ghanem",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.02535"" target=""_blank"">2206.02535</a>",,2025-12-03 22:39:25
Robust Image Protection Countering Cropping Manipulation,"Qichao Ying, Hang Zhou, Zhenxing Qian, Sheng Li, Xinpeng Zhang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.02405"" target=""_blank"">2206.02405</a>",,2025-12-03 22:39:25
PCPT and ACPT: Copyright Protection and Traceability Scheme for DNN Model,"Xuefeng Fan, Hangyu Gui, Xiaoyi Zhou",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.02541"" target=""_blank"">2206.02541</a>",,2025-12-03 22:39:25
Tackling covariate shift with node-based Bayesian neural networks,"Trung Trinh, Markus Heinonen, Luigi Acerbi, Samuel Kaski",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.02435"" target=""_blank"">2206.02435</a>",,2025-12-03 22:39:25
Federated Adversarial Training with Transformers,"Ahmed Aldahdooh, Wassim Hamidouche, Olivier Déforges",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.02131"" target=""_blank"">2206.02131</a>",,2025-12-03 22:39:25
FACM: Intermediate Layer Still Retain Effective Features against Adversarial Examples,"Xiangyuan Yang, Jie Lin, Hanlin Zhang, Xinyu Yang, Peng Zhao",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00924"" target=""_blank"">2206.00924</a>",,2025-12-03 22:39:25
Vanilla Feature Distillation for Improving the Accuracy-Robustness Trade-Off in Adversarial Training,"Guodong Cao, Zhibo Wang, Xiaowei Dong, Zhifei Zhang, Hengchang Guo, Zhan Qin, Kui Ren",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.02158"" target=""_blank"">2206.02158</a>",,2025-12-03 22:39:25
Which models are innately best at uncertainty estimation? (1%),"Ido Galil, Mohammed Dabbah, Ran El-Yaniv",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.02152"" target=""_blank"">2206.02152</a>",,2025-12-03 22:39:25
Soft Adversarial Training Can Retain Natural Accuracy,"Abhijith Sharma, Apurva Narayan",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.01904"" target=""_blank"">2206.01904</a>",,2025-12-03 22:39:25
Saliency Attack: Towards Imperceptible Black-box Adversarial Attack,"Zeyu Dai, Shengcai Liu, Ke Tang, Qing Li",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.01898"" target=""_blank"">2206.01898</a>",,2025-12-03 22:39:25
Towards Evading the Limits of Randomized Smoothing: A Theoretical Analysis,"Raphael Ettedgui, Alexandre Araujo, Rafael Pinot, Yann Chevaleyre, Jamal Atif",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.01715"" target=""_blank"">2206.01715</a>",,2025-12-03 22:39:25
Evaluating Transfer-based Targeted Adversarial Perturbations against Real-World Computer Vision Systems based on Human Judgments,"Zhengyu Zhao, Nga Dang, Martha Larson",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.01467"" target=""_blank"">2206.01467</a>","<a href=""https://github.com/ZhengyuZhao/Targeted-Tansfer/blob/main/google_results.zip"" target=""_blank"">main</a>",2025-12-03 22:39:25
A Robust Backpropagation-Free Framework for Images,"Timothy Zee, Alexander G. Ororbia, Ankur Mali, Ifeoma Nwogu",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.01820"" target=""_blank"">2206.01820</a>",,2025-12-03 22:39:25
Gradient Obfuscation Checklist Test Gives a False Sense of Security,"Nikola Popovic, Danda Pani Paudel, Thomas Probst, Gool Luc Van",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.01705"" target=""_blank"">2206.01705</a>",,2025-12-03 22:39:25
Kallima: A Clean-label Framework for Textual Backdoor Attacks,"Xiaoyi Chen, Yinpeng Dong, Zeyu Sun, Shengfang Zhai, Qingni Shen, Zhonghai Wu",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.01832"" target=""_blank"">2206.01832</a>",,2025-12-03 22:39:25
Improving the Robustness and Generalization of Deep Neural Network with Confidence Threshold Reduction,"Xiangyuan Yang, Jie Lin, Hanlin Zhang, Xinyu Yang, Peng Zhao",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.00913"" target=""_blank"">2206.00913</a>",,2025-12-03 22:39:25
Defending Observation Attacks in Deep Reinforcement Learning via Detection and Denoising,"Zikang Xiong, Joe Eappen, He Zhu, Suresh Jagannathan",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07188"" target=""_blank"">2206.07188</a>",,2025-12-03 22:39:25
MaxStyle: Adversarial Style Composition for Robust Medical Image Segmentation,"Chen Chen, Zeju Li, Cheng Ouyang, Matt Sinclair, Wenjia Bai, Daniel Rueckert",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.01737"" target=""_blank"">2206.01737</a>","<a href=""https://github.com/cherise215/MaxStyle"" target=""_blank"">cherise215</a>",2025-12-03 22:39:25
Proximal Splitting Adversarial Attacks for Semantic Segmentation,"Jérôme Rony, Jean-Christophe Pesquet, Ismail Ben Ayed",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07179"" target=""_blank"">2206.07179</a>",,2025-12-03 22:39:25
FlashSyn: Flash Loan Attack Synthesis via Counter Example Driven Approximation,"Zhiyang Chen, Sidi Mohamed Beillahi, Fan Long",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.10708"" target=""_blank"">2206.10708</a>",,2025-12-03 22:39:25
Defense against adversarial attacks on deep convolutional neural networks through nonlocal denoising,"Sandhya Aneja, Nagender Aneja, Pg Emeroylariffion Abas, Abdul Ghani Naim",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.12685"" target=""_blank"">2206.12685</a>",,2025-12-03 22:39:25
RSTAM: An Effective Black-Box Impersonation Attack on Face Recognition using a Mobile and Compact Printer,"Xiaoliang Liu, Furao Shen, Jian Zhao, Changhai Nie",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.12590"" target=""_blank"">2206.12590</a>",,2025-12-03 22:39:25
Defending Multimodal Fusion Models against Single-Source Adversaries,"Karren Yang, Wan-Yi Lin, Manash Barman, Filipe Condessa, Zico Kolter",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.12714"" target=""_blank"">2206.12714</a>",,2025-12-03 22:39:25
BackdoorBench: A Comprehensive Benchmark of Backdoor Learning,"Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Chao Shen, Hongyuan Zha",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.12654"" target=""_blank"">2206.12654</a>","<a href=""https://backdoorbench.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Defending Backdoor Attacks on Vision Transformer via Patch Processing,"Khoa D. Doan, Yingjie Lao, Peng Yang, Ping Li",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.12381"" target=""_blank"">2206.12381</a>",,2025-12-03 22:39:25
AdAUC: End-to-end Adversarial AUC Optimization Against Long-tail Problems,"Wenzheng Hou, Qianqian Xu, Zhiyong Yang, Shilong Bao, Yuan He, Qingming Huang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.12169"" target=""_blank"">2206.12169</a>",,2025-12-03 22:39:25
Adversarial Robustness of Deep Neural Networks: A Survey from a Formal Verification Perspective,"Mark Huasong Meng, Guangdong Bai, Sin Gee Teo, Zhe Hou, Yan Xiao, Yun Lin, Jin Song Dong",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.12227"" target=""_blank"">2206.12227</a>",,2025-12-03 22:39:25
Robustness of Explanation Methods for NLP Models,"Shriya Atmakuri, Tejas Chheda, Dinesh Kandula, Nishant Yadav, Taesung Lee, Hessel Tuinhof",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.12284"" target=""_blank"">2206.12284</a>",,2025-12-03 22:39:25
zPROBE: Zero Peek Robustness Checks for Federated Learning,"Zahra Ghodsi, Mojan Javaheripi, Nojan Sheybani, Xinqiao Zhang, Ke Huang, Farinaz Koushanfar",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.12100"" target=""_blank"">2206.12100</a>",,2025-12-03 22:39:25
Adversarial Zoom Lens: A Novel Physical-World Attack to DNNs,"Chengyin Hu, Weiwen Shi",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.12251"" target=""_blank"">2206.12251</a>",,2025-12-03 22:39:25
A Framework for Understanding Model Extraction Attack and Defense,"Xun Xian, Mingyi Hong, Jie Ding",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.11480"" target=""_blank"">2206.11480</a>",,2025-12-03 22:39:25
Towards End-to-End Private Automatic Speaker Recognition,"Francisco Teixeira, Alberto Abad, Bhiksha Raj, Isabel Trancoso",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.11750"" target=""_blank"">2206.11750</a>",,2025-12-03 22:39:25
BERT Rankers are Brittle: a Study using Adversarial Document Perturbations,"Yumeng Wang, Lijun Lyu, Avishek Anand",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.11724"" target=""_blank"">2206.11724</a>",,2025-12-03 22:39:25
"Never trust, always verify : a roadmap for Trustworthy AI? (1%)","Lionel Nganyewou Tidjon, Foutse Khomh",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.11981"" target=""_blank"">2206.11981</a>",,2025-12-03 22:39:25
Measuring Representational Robustness of Neural Networks Through Shared Invariances,"Vedant Nanda, Till Speicher, Camila Kolling, John P. Dickerson, Krishna P. Gummadi, Adrian Weller",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.11939"" target=""_blank"">2206.11939</a>","<a href=""https://github.com/nvedant07/STIR"" target=""_blank"">nvedant07</a>",2025-12-03 22:39:25
AdvSmo: Black-box Adversarial Attack by Smoothing Linear Structure of Texture,"Hui Xia, Rui Zhang, Shuliang Jiang, Zi Kang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.10988"" target=""_blank"">2206.10988</a>",,2025-12-03 22:39:25
InfoAT: Improving Adversarial Training Using the Information Bottleneck Principle,"Mengting Xu, Tao Zhang, Zhongnian Li, Daoqiang Zhang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.12292"" target=""_blank"">2206.12292</a>",,2025-12-03 22:39:25
Robust Universal Adversarial Perturbations,"Changming Xu, Gagandeep Singh",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.10858"" target=""_blank"">2206.10858</a>",,2025-12-03 22:39:25
Guided Diffusion Model for Adversarial Purification from Random Noise,"Quanlin Wu, Hang Ye, Yuntian Gu",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.10875"" target=""_blank"">2206.10875</a>",,2025-12-03 22:39:25
Understanding the effect of sparsity on neural networks robustness,"Lukas Timpl, Rahim Entezari, Hanie Sedghi, Behnam Neyshabur, Olga Saukh",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.10915"" target=""_blank"">2206.10915</a>",,2025-12-03 22:39:25
Shilling Black-box Recommender Systems by Learning to Generate Fake User Profiles,"Chen Lin, Si Chen, Meifang Zeng, Sheng Zhang, Min Gao, Hui Li",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.11433"" target=""_blank"">2206.11433</a>","<a href=""https://github.com/XMUDM/ShillingAttack"" target=""_blank"">XMUDM</a>",2025-12-03 22:39:25
SSMI: How to Make Objects of Interest Disappear without Accessing Object Detectors? (99%),"Hui Xia, Rui Zhang, Zi Kang, Shuliang Jiang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.10809"" target=""_blank"">2206.10809</a>",,2025-12-03 22:39:25
(Certified!!) Adversarial Robustness for Free! (84%),"Nicholas Dj Carlini, Florian Dj Tramer, Dj Krishnamurthy, Dvijotham, J. Zico Kolter",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.10550"" target=""_blank"">2206.10550</a>",,2025-12-03 22:39:25
Empirical Evaluation of Physical Adversarial Patch Attacks Against Overhead Object Detection Models,"Gavin S. Hartnett, Li Ang Zhang, Caolionn O'Connell, Andrew J. Lohn, Jair Aguirre",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.12725"" target=""_blank"">2206.12725</a>",,2025-12-03 22:39:25
De-END: Decoder-driven Watermarking Network,"Han Fang, Zhaoyang Jia, Yupeng Qiu, Jiyi Zhang, Weiming Zhang, Ee-Chien Chang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.13032"" target=""_blank"">2206.13032</a>",,2025-12-03 22:39:25
Self-Healing Robust Neural Networks via Closed-Loop Control,"Zhuotong Chen, Qianxiao Li, Zheng Zhang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.12963"" target=""_blank"">2206.12963</a>",,2025-12-03 22:39:25
Increasing Confidence in Adversarial Robustness Evaluations,"Roland S. Zimmermann, Wieland Brendel, Florian Tramer, Nicholas Carlini",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.13991"" target=""_blank"">2206.13991</a>",,2025-12-03 22:39:25
Detecting and Recovering Adversarial Examples from Extracting Non-robust and Highly Predictive Adversarial Perturbations,"Mingyu Dong, Jiahao Chen, Diqun Yan, Jingxing Gao, Li Dong, Rangding Wang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.15128"" target=""_blank"">2206.15128</a>",,2025-12-03 22:39:25
Efficiently Training Low-Curvature Neural Networks,"Suraj Srinivas, Kyle Matoba, Himabindu Lakkaraju, Francois Fleuret",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07144"" target=""_blank"">2206.07144</a>",,2025-12-03 22:39:25
MEAD: A Multi-Armed Approach for Evaluation of Adversarial Examples Detectors,"Federica Granese, Marine Picot, Marco Romanelli, Francisco Messina, Pablo Piantanida",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.15415"" target=""_blank"">2206.15415</a>",,2025-12-03 22:39:25
No Reason for No Supervision: Improved Generalization in Supervised Models,"Mert Bulent Sariyildiz, Yannis Kalantidis, Karteek Alahari, Diane Larlus",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.15369"" target=""_blank"">2206.15369</a>",,2025-12-03 22:39:25
Augment like there's no tomorrow: Consistently performing neural networks for medical imaging,"Joona Pohjonen, Carolin Stürenberg, Atte Föhr, Reija Randen-Brady, Lassi Luomala, Jouni Lohi, Esa Pitkänen, Antti Rannikko, Tuomas Mirtti",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.15274"" target=""_blank"">2206.15274</a>",,2025-12-03 22:39:25
IBP Regularization for Verified Adversarial Robustness via Branch-and-Bound,"Palma Alessandro De, Rudy Bunel, Krishnamurthy Dvijotham, M. Pawan Kumar, Robert Stanforth",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.14772"" target=""_blank"">2206.14772</a>",,2025-12-03 22:39:25
Adversarial Ensemble Training by Jointly Learning Label Dependencies and Member Models,"Lele Wang, Bin Liu",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.14477"" target=""_blank"">2206.14477</a>","<a href=""https://github.com/ZJLAB-AMMI/LSD"" target=""_blank"">ZJLAB-AMMI</a>",2025-12-03 22:39:25
longhorns at DADC 2022: How many linguists does it take to fool a Question Answering model? A systematic approach to adversarial attacks,"Venelin Kovatchev, Trina Chatterjee, Venkata S Govindarajan, Jifan Chen, Eunsol Choi, Gabriella Chronis, Anubrata Das, Katrin Erk, Matthew Lease, Junyi Jessy Li, Yating Wu, Kyle Mahowald",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.14729"" target=""_blank"">2206.14729</a>",,2025-12-03 22:39:25
Private Graph Extraction via Feature Explanations,"Iyiola E. Olatunji, Mandeep Rathee, Thorben Funke, Megha Khosla",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.14724"" target=""_blank"">2206.14724</a>","<a href=""https://github.com/iyempissy/graph-stealing-attacks-with-explanation"" target=""_blank"">iyempissy</a>",2025-12-03 22:39:25
RegMixup: Mixup as a Regularizer Can Surprisingly Improve Accuracy and Out Distribution Robustness,"Francesco Pinto, Harry Yang, Ser-Nam Lim, Philip H. S. Torr, Puneet K. Dokania",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.14502"" target=""_blank"">2206.14502</a>",,2025-12-03 22:39:25
Rethinking Adversarial Examples for Location Privacy Protection,"Trung-Nghia Le, Ta Gu, Huy H. Nguyen, Isao Echizen",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.14020"" target=""_blank"">2206.14020</a>",,2025-12-03 22:39:25
Quantification of Deep Neural Network Prediction Uncertainties for VVUQ of Machine Learning Models,"Mahmoud Yaseen, Xu Wu",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.14615"" target=""_blank"">2206.14615</a>",,2025-12-03 22:39:25
A Deep Learning Approach to Create DNS Amplification Attacks,"Jared Mathews, Prosenjit Chatterjee, Shankar Banik, Cory Nance",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.14346"" target=""_blank"">2206.14346</a>",,2025-12-03 22:39:25
On the amplification of security and privacy risks by post-hoc explanations in machine learning models,"Pengrui Quan, Supriyo Chakraborty, Jeya Vikranth Jeyakumar, Mani Srivastava",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.14004"" target=""_blank"">2206.14004</a>",,2025-12-03 22:39:25
How to Steer Your Adversary: Targeted and Efficient Model Stealing Defenses with Gradient Redirection,"Mantas Mazeika, Bo Li, David Forsyth",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.14157"" target=""_blank"">2206.14157</a>",,2025-12-03 22:39:25
An Empirical Study of Challenges in Converting Deep Learning Models,"Moses Jack Openja, Amin Jack Nikanjam, Ahmed Haj Jack Yahmed, Foutse Jack Khomh, Zhen Jack Ming, Jiang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.14322"" target=""_blank"">2206.14322</a>",,2025-12-03 22:39:25
Reasoning about Moving Target Defense in Attack Modeling Formalisms,"Gabriel Ballot, Vadim Malvone, Jean Leneutre, Etienne Borde",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.14076"" target=""_blank"">2206.14076</a>",,2025-12-03 22:39:25
AS-IntroVAE: Adversarial Similarity Distance Makes Robust IntroVAE,"Changjie Lu, Shen Zheng, Zirui Wang, Omar Dib, Gaurav Gupta",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.13903"" target=""_blank"">2206.13903</a>",,2025-12-03 22:39:25
Adversarial Example Detection in Deployed Tree Ensembles,"Laurens Devos, Wannes Meert, Jesse Davis",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.13083"" target=""_blank"">2206.13083</a>",,2025-12-03 22:39:25
Towards Secrecy-Aware Attacks Against Trust Prediction in Signed Graphs,"Yulin Zhu, Tomasz Michalak, Xiapu Luo, Kai Zhou",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.13104"" target=""_blank"">2206.13104</a>",,2025-12-03 22:39:25
Utilizing Class Separation Distance for the Evaluation of Corruption Robustness of Machine Learning Classifiers,"Georg Siedel, Silvia Vock, Andrey Morozov, Stefan Voß",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.13405"" target=""_blank"">2206.13405</a>",,2025-12-03 22:39:25
Cyber Network Resilience against Self-Propagating Malware Attacks,"Alesia Chernikova, Nicolò Gozzi, Simona Boboila, Priyanka Angadi, John Loughner, Matthew Wilden, Nicola Perra, Tina Eliassi-Rad, Alina Oprea",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.13594"" target=""_blank"">2206.13594</a>",,2025-12-03 22:39:25
Certifiably Robust Policy Learning against Adversarial Communication in Multi-agent Systems,"Yanchao Sun, Ruijie Zheng, Parisa Hassanzadeh, Yongyuan Liang, Soheil Feizi, Sumitra Ganesh, Furong Huang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.10158"" target=""_blank"">2206.10158</a>",,2025-12-03 22:39:25
"Cascading Failures in Smart Grids under Random, Targeted and Adaptive Attacks","Sushmita Ruj, Arindam Pal",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.12735"" target=""_blank"">2206.12735</a>",,2025-12-03 22:39:25
Natural Backdoor Datasets,"Emily Wenger, Roma Bhattacharjee, Arjun Nitin Bhagoji, Josephine Passananti, Emilio Andere, Haitao Zheng, Ben Y. Zhao",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.10673"" target=""_blank"">2206.10673</a>",,2025-12-03 22:39:25
Understanding Robust Overfitting of Adversarial Training and Beyond,"Chaojian Yu, Bo Han, Li Shen, Jun Yu, Chen Gong, Mingming Gong, Tongliang Liu",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.08675"" target=""_blank"">2206.08675</a>",,2025-12-03 22:39:25
Boosting the Adversarial Transferability of Surrogate Model with Dark Knowledge,"Dingcheng Yang, Zihao Xiao, Wenjian Yu",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.08316"" target=""_blank"">2206.08316</a>",,2025-12-03 22:39:25
Analysis and Extensions of Adversarial Training for Video Classification,"Kaleab A. Kinfu, René Vidal",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07953"" target=""_blank"">2206.07953</a>",,2025-12-03 22:39:25
Double Sampling Randomized Smoothing,"Linyi Li, Jiawei Zhang, Tao Xie, Bo Li",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07912"" target=""_blank"">2206.07912</a>","<a href=""https://github.com/llylly/DSRS"" target=""_blank"">llylly</a>",2025-12-03 22:39:25
Adversarial Robustness of Graph-based Anomaly Detection,"Yulin Zhu, Yuni Lai, Kaifa Zhao, Xiapu Luo, Mingquan Yuan, Jian Ren, Kai Zhou",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.08260"" target=""_blank"">2206.08260</a>",,2025-12-03 22:39:25
A Unified Evaluation of Textual Backdoor Learning: Frameworks and Benchmarks,"Ganqu Cui, Lifan Yuan, Bingxiang He, Yangyi Chen, Zhiyuan Liu, Maosong Sun",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.08514"" target=""_blank"">2206.08514</a>",,2025-12-03 22:39:25
Backdoor Attacks on Vision Transformers,"Akshayvarun Subramanya, Aniruddha Saha, Soroush Abbasi Koohpayegani, Ajinkya Tejankar, Hamed Pirsiavash",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.08477"" target=""_blank"">2206.08477</a>","<a href=""https://github.com/UCDvision/backdoor_transformer"" target=""_blank"">UCDvision</a>",2025-12-03 22:39:25
Adversarial Patch Attacks and Defences in Vision-Based Tasks: A Survey,"Abhijith Sharma, Yijun Bian, Phil Munz, Apurva Narayan",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.08304"" target=""_blank"">2206.08304</a>",,2025-12-03 22:39:25
I Know What You Trained Last Summer: A Survey on Stealing Machine Learning Models and Defences,"Daryna Oliynyk, Rudolf Mayer, Andreas Rauber",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.08451"" target=""_blank"">2206.08451</a>",,2025-12-03 22:39:25
Gradient-Based Adversarial and Out-of-Distribution Detection,"Jinsol Lee, Mohit Prabhushankar, Ghassan AlRegib",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.08255"" target=""_blank"">2206.08255</a>",,2025-12-03 22:39:25
"""Understanding Robustness Lottery"": A Comparative Visual Analysis of Neural Network Pruning Approaches","Zhimin Li, Shusen Liu, Xin Yu, Kailkhura Bhavya, Jie Cao, Diffenderfer James Daniel, Peer-Timo Bremer, Valerio Pascucci",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07918"" target=""_blank"">2206.07918</a>",,2025-12-03 22:39:25
Fast and Reliable Evaluation of Adversarial Robustness with Minimum-Margin Attack,"Ruize Gao, Jiongxiao Wang, Kaiwen Zhou, Feng Liu, Binghui Xie, Gang Niu, Bo Han, James Cheng",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07314"" target=""_blank"">2206.07314</a>",,2025-12-03 22:39:25
Morphence-2,"Abderrahmen Amich, Ata Kaboudi, Birhanu Eshete",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07321"" target=""_blank"">2206.07321</a>",,2025-12-03 22:39:25
Architectural Backdoors in Neural Networks,"Mikel Bober-Irizar, Ilia Shumailov, Yiren Zhao, Robert Mullins, Nicolas Papernot",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07840"" target=""_blank"">2206.07840</a>",,2025-12-03 22:39:25
Hardening DNNs against Transfer Attacks during Network Compression using Greedy Adversarial Pruning,"Jonah O'Brien Weiss, Tiago Alves, Sandip Kundu",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07406"" target=""_blank"">2206.07406</a>",,2025-12-03 22:39:25
Linearity Grafting: Relaxed Neuron Pruning Helps Certifiable Robustness,"Tianlong Chen, Huan Zhang, Zhenyu Zhang, Shiyu Chang, Sijia Liu, Pin-Yu Chen, Zhangyang Wang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07839"" target=""_blank"">2206.07839</a>","<a href=""https://github.com/VITA-Group/Linearity-Grafting"" target=""_blank"">VITA-Group</a>",2025-12-03 22:39:25
Downlink Power Allocation in Massive MIMO via Deep Learning: Adversarial Attacks and Training,"B. R. Manoj, Meysam Sadeghi, Erik G. Larsson",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.06592"" target=""_blank"">2206.06592</a>",,2025-12-03 22:39:25
The Privacy Onion Effect: Memorization is Relative,"Nicholas Carlini, Matthew Jagielski, Nicolas Papernot, Andreas Terzis, Florian Tramer, Chiyuan Zhang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.10469"" target=""_blank"">2206.10469</a>",,2025-12-03 22:39:25
A Search-Based Testing Approach for Deep Reinforcement Learning Agents,"Amirhossein Zolfagharian, Manel Abdellatif, Lionel Briand, Mojtaba Bagherzadeh, Ramesh S",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07813"" target=""_blank"">2206.07813</a>",,2025-12-03 22:39:25
Can pruning improve certified robustness of neural networks? (56%),"Zhangheng Li, Tianlong Chen, Linyi Li, Bo Li, Zhangyang Wang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07311"" target=""_blank"">2206.07311</a>","<a href=""https://github.com/VITA-Group/CertifiedPruning"" target=""_blank"">VITA-Group</a>",2025-12-03 22:39:25
Improving Diversity with Adversarially Learned Transformations for Domain Generalization,"Tejas Gokhale, Rushil Anirudh, Jayaraman J. Thiagarajan, Bhavya Kailkhura, Chitta Baral, Yezhou Yang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07736"" target=""_blank"">2206.07736</a>",,2025-12-03 22:39:25
Queried Unlabeled Data Improves and Robustifies Class-Incremental Learning,"Tianlong Chen, Sijia Liu, Shiyu Chang, Lisa Amini, Zhangyang Wang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07842"" target=""_blank"">2206.07842</a>","<a href=""https://github.com/VITA-Group/CIL-QUD"" target=""_blank"">VITA-Group</a>",2025-12-03 22:39:25
Adversarial Vulnerability of Randomized Ensembles,"Hassan Dbouk, Naresh R. Shanbhag",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.06737"" target=""_blank"">2206.06737</a>","<a href=""https://github.com/hsndbk4/ARC"" target=""_blank"">hsndbk4</a>",2025-12-03 22:39:25
The Manifold Hypothesis for Gradient-Based Explanations,"Sebastian Bordt, Uddeshya Upadhyay, Zeynep Akata, Luxburg Ulrike von",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07387"" target=""_blank"">2206.07387</a>","<a href=""https://github.com/tml-tuebingen/explanations-manifold"" target=""_blank"">tml-tuebingen</a>",2025-12-03 22:39:25
Adversarial Privacy Protection on Speech Enhancement,"Mingyu Dong, Diqun Yan, Rangding Wang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.08170"" target=""_blank"">2206.08170</a>",,2025-12-03 22:39:25
Catastrophic overfitting is a bug but also a feature,"Guillermo Ortiz-Jiménez, Jorge Pau de, Amartya Sanyal, Adel Bibi, Puneet K. Dokania, Pascal Frossard, Gregory Rogéz, Philip H. S. Torr",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.08242"" target=""_blank"">2206.08242</a>","<a href=""https://github.com/gortizji/co_features"" target=""_blank"">gortizji</a>",2025-12-03 22:39:25
Existence and Minimax Theorems for Adversarial Surrogate Risks in Binary Classification,Natalie S. Frank,arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09098"" target=""_blank"">2206.09098</a>",,2025-12-03 22:39:25
On the Role of Generalization in Transferability of Adversarial Examples,"Yilin Wang, Farzan Farnia",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09238"" target=""_blank"">2206.09238</a>",,2025-12-03 22:39:25
ProML: A Decentralised Platform for Provenance Management of Machine Learning Software Systems,"Nguyen Khoi Tran, Bushra Sabir, M. Ali Babar, Nini Cui, Mehran Abolhasan, Justin Lipman",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.10110"" target=""_blank"">2206.10110</a>",,2025-12-03 22:39:25
Understanding Robust Learning through the Lens of Representation Similarities,"Christian Cianfarani, Arjun Nitin Bhagoji, Vikash Sehwag, Ben Zhao, Prateek Mittal",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09868"" target=""_blank"">2206.09868</a>",,2025-12-03 22:39:25
Diversified Adversarial Attacks based on Conjugate Gradient Method,"Keiichiro Yamamura, Haruki Sato, Nariaki Tateiwa, Nozomi Hata, Toru Mitsutake, Issa Oe, Hiroki Ishikura, Katsuki Fujisawa",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09628"" target=""_blank"">2206.09628</a>",,2025-12-03 22:39:25
Robust Deep Reinforcement Learning through Bootstrapped Opportunistic Curriculum,"Junlin Wu, Yevgeniy Vorobeychik",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.10057"" target=""_blank"">2206.10057</a>","<a href=""https://github.com/jlwu002/BCL"" target=""_blank"">jlwu002</a>",2025-12-03 22:39:25
The Consistency of Adversarial Training for Binary Classification,"Natalie S. Frank, Jonathan Niles-Weed",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09099"" target=""_blank"">2206.09099</a>",,2025-12-03 22:39:25
Breaking Down Out-of-Distribution Detection: Many Methods Based on OOD Training Data Estimate a Combination of the Same Core Quantities,"Julian Bitterwolf, Alexander Meinke, Maximilian Augustin, Matthias Hein",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09880"" target=""_blank"">2206.09880</a>",,2025-12-03 22:39:25
On the Limitations of Stochastic Pre-processing Defenses,"Yue Gao, Ilia Shumailov, Kassem Fawaz, Nicolas Papernot",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09491"" target=""_blank"">2206.09491</a>",,2025-12-03 22:39:25
Towards Adversarial Attack on Vision-Language Pre-training Models,"Jiaming Zhang, Qi Yi, Jitao Sang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09391"" target=""_blank"">2206.09391</a>",,2025-12-03 22:39:25
A Universal Adversarial Policy for Text Classifiers,"Gallil Maimon, Lior Rokach",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09458"" target=""_blank"">2206.09458</a>",,2025-12-03 22:39:25
JPEG Compression-Resistant Low-Mid Adversarial Perturbation against Unauthorized Face Recognition System,"Jiaming Zhang, Qi Yi, Jitao Sang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09410"" target=""_blank"">2206.09410</a>",,2025-12-03 22:39:25
Adversarially trained neural representations may already be as robust as corresponding biological neural representations,"Chong Guo, Michael J. Lee, Guillaume Leclerc, Joel Dapello, Yug Rao, Aleksander Madry, James J. DiCarlo",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.11228"" target=""_blank"">2206.11228</a>",,2025-12-03 22:39:25
SafeBench: A Benchmarking Platform for Safety Evaluation of Autonomous Vehicles,"Chejian Xu, Wenhao Ding, Weijie Lyu, Zuxin Liu, Shuai Wang, Yihan He, Hanjiang Hu, Ding Zhao, Bo Li",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09682"" target=""_blank"">2206.09682</a>","<a href=""https://safebench.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
DECK: Model Hardening for Defending Pervasive Backdoors,"Guanhong Tao, Yingqi Liu, Siyuan Cheng, Shengwei An, Zhuo Zhang, Qiuling Xu, Guangyu Shen, Xiangyu Zhang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09272"" target=""_blank"">2206.09272</a>",,2025-12-03 22:39:25
Minimum Noticeable Difference based Adversarial Privacy Preserving Image Generation,"Wen Sun, Jian Jin, Weisi Lin",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.08638"" target=""_blank"">2206.08638</a>",,2025-12-03 22:39:25
RetrievalGuard: Provably Robust 1-Nearest Neighbor Image Retrieval,"Yihan Wu, Hongyang Zhang, Heng Huang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.11225"" target=""_blank"">2206.11225</a>",,2025-12-03 22:39:25
Is Multi-Modal Necessarily Better? Robustness Evaluation of Multi-modal Fake News Detection,"Jinyin Chen, Chengyu Jia, Haibin Zheng, Ruoxi Chen, Chenbo Fu",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.08788"" target=""_blank"">2206.08788</a>",,2025-12-03 22:39:25
Comment on Transferability and Input Transformation with Additive Noise,"Hoki Kim, Jinseong Park, Jaewook Lee",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09075"" target=""_blank"">2206.09075</a>",,2025-12-03 22:39:25
Query-Efficient and Scalable Black-Box Adversarial Attacks on Discrete Sequential Data via Bayesian Optimization,"Deokjae Lee, Seungyong Moon, Junhyeok Lee, Hyun Oh Song",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.08575"" target=""_blank"">2206.08575</a>",,2025-12-03 22:39:25
READ: Aggregating Reconstruction Error into Out-of-distribution Detection,"Wenyu Jiang, Hao Cheng, Mingcai Chen, Shuai Feng, Yuxin Ge, Chongjun Wang",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.07459"" target=""_blank"">2206.07459</a>",,2025-12-03 22:39:25
Adversarial Scrutiny of Evidentiary Statistical Software,"Rediet Abebe, Moritz Hardt, Angela Jin, John Miller, Ludwig Schmidt, Rebecca Wexler",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09305"" target=""_blank"">2206.09305</a>",,2025-12-03 22:39:25
Detecting Adversarial Examples in Batches -- a geometrical approach,"Danush Kumar Venkatesh, Peter Steinbach",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.08738"" target=""_blank"">2206.08738</a>",,2025-12-03 22:39:25
Measuring Lower Bounds of Local Differential Privacy via Adversary Instantiations in Federated Learning,"Marin Matsumoto, Tsubasa Takahashi, Seng Pei Liew, Masato Oguchi",arXiv,2022-06,"<a href=""http://arxiv.org/abs/2206.09122"" target=""_blank"">2206.09122</a>",,2025-12-03 22:39:25
l-Leaks: Membership Inference Attacks with Logits,"Shuhao Li, Yajie Wang, Yuanzhang Li, Yu-an Tan",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.06469"" target=""_blank"">2205.06469</a>",,2025-12-03 22:39:25
Stalloris: RPKI Downgrade Attack,"Tomas Hlavacek, Philipp Jeitner, Donika Mirdita, Haya Shulman, Michael Waidner",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.06064"" target=""_blank"">2205.06064</a>",,2025-12-03 22:39:25
DualCF: Efficient Model Extraction Attack from Counterfactual Explanations,"Yongjie Wang, Hangwei Qian, Chunyan Miao",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.06504"" target=""_blank"">2205.06504</a>",,2025-12-03 22:39:25
Model-Contrastive Learning for Backdoor Defense,"Zhihao Yue, Jun Xia, Zhiwei Ling, Ming Hu, Ting Wang, Xian Wei, Mingsong Chen",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.04411"" target=""_blank"">2205.04411</a>","<a href=""https://github.com/WeCanShow/MCL"" target=""_blank"">WeCanShow</a>",2025-12-03 22:39:25
Millimeter-Wave Automotive Radar Spoofing,"Mihai Ordean, Flavio D. Garcia",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.06567"" target=""_blank"">2205.06567</a>",,2025-12-03 22:39:25
Sample Complexity Bounds for Robustly Learning Decision Lists against Evasion Attacks,"Pascale Gourdeau, Varun Kanade, Marta Kwiatkowska, James Worrell",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.06127"" target=""_blank"">2205.06127</a>",,2025-12-03 22:39:25
PoisonedEncoder: Poisoning the Unlabeled Pre-training Data in Contrastive Learning,"Hongbin Liu, Jinyuan Jia, Neil Zhenqiang Gong",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.06401"" target=""_blank"">2205.06401</a>",,2025-12-03 22:39:25
How to Combine Membership-Inference Attacks on Multiple Updated Models,"Matthew Jagielski, Stanley Wu, Alina Oprea, Jonathan Ullman, Roxana Geambasu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.06369"" target=""_blank"">2205.06369</a>","<a href=""https://www.github.com/stanleykywu/model-updates"" target=""_blank"">stanleykywu</a>",2025-12-03 22:39:25
Infrared Invisible Clothing:Hiding from Infrared Detectors at Multiple Angles in Real World,"Xiaopei Zhu, Zhanhao Hu, Siyuan Huang, Jianmin Li, Xiaolin Hu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.05909"" target=""_blank"">2205.05909</a>",,2025-12-03 22:39:25
Smooth-Reduce: Leveraging Patches for Improved Certified Robustness,"Ameya Joshi, Minh Pham, Minsu Cho, Leonid Boytsov, Filipe Condessa, J. Zico Kolter, Chinmay Hegde",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.06154"" target=""_blank"">2205.06154</a>","<a href=""https://nyu-dice-lab.github.io/SmoothReduce/"" target=""_blank"">SmoothReduce</a>",2025-12-03 22:39:25
Federated Multi-Armed Bandits Under Byzantine Attacks,"Ilker Demirel, Yigit Yildirim, Cem Tekin",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.04134"" target=""_blank"">2205.04134</a>",,2025-12-03 22:39:25
Injection Attacks Reloaded: Tunnelling Malicious Payloads over DNS,"Philipp Jeitner, Haya Shulman",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.05439"" target=""_blank"">2205.05439</a>",,2025-12-03 22:39:25
How Does Frequency Bias Affect the Robustness of Neural Image Classifiers against Common Corruption and Adversarial Perturbations? (61%),"Alvin Chan, Yew-Soon Ong, Clement Tan",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.04533"" target=""_blank"">2205.04533</a>",,2025-12-03 22:39:25
A Longitudinal Study of Cryptographic API: a Decade of Android Malware,"Adam Janovsky, Davide Maiorca, Dominik Macko, Vashek Matyas, Giorgio Giacinto",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.05573"" target=""_blank"">2205.05573</a>",,2025-12-03 22:39:25
Robust Medical Image Classification from Noisy Labeled Data with Global and Local Representation Guided Co-training,"Cheng Xue, Lequan Yu, Pengfei Chen, Qi Dou, Pheng-Ann Heng",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.04723"" target=""_blank"">2205.04723</a>",,2025-12-03 22:39:25
White-box Testing of NLP models with Mask Neuron Coverage,"Arshdeep Sekhon, Yangfeng Ji, Matthew B. Dwyer, Yanjun Qi",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.05050"" target=""_blank"">2205.05050</a>",,2025-12-03 22:39:25
Btech thesis report on adversarial attack detection and purification of adverserially attacked images,Dvij Kalaria,arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.07859"" target=""_blank"">2205.07859</a>",,2025-12-03 22:39:25
Using Frequency Attention to Make Adversarial Patch Powerful Against Person Detector,"Xiaochun Lei, Chang Lu, Zetao Jiang, Zhaoting Gong, Xiang Cai, Linjun Lu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.04638"" target=""_blank"">2205.04638</a>",,2025-12-03 22:39:25
Do You Think You Can Hold Me? The Real Challenge of Problem-Space Evasion Attacks,"Harel Berger, Amit Dvir, Chen Hajaj, Rony Ronen",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.04293"" target=""_blank"">2205.04293</a>",,2025-12-03 22:39:25
The Hijackers Guide To The Galaxy: Off-Path Taking Over Internet Resources,"Tianxiang Dai, Philipp Jeitner, Haya Shulman, Michael Waidner",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.05473"" target=""_blank"">2205.05473</a>",,2025-12-03 22:39:25
Hierarchical Distribution-Aware Testing of Deep Learning,"Wei Huang, Xingyu Zhao, Alec Banks, Victoria Cox, Xiaowei Huang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.08589"" target=""_blank"">2205.08589</a>",,2025-12-03 22:39:25
MM-BD: Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic,"Hang Wang, Zhen Xiang, David J. Miller, George Kesidis",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.06900"" target=""_blank"">2205.06900</a>",,2025-12-03 22:39:25
Attacking and Defending Deep Reinforcement Learning Policies,Chao Wang,arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.07626"" target=""_blank"">2205.07626</a>",,2025-12-03 22:39:25
Fingerprint Template Invertibility: Minutiae vs,"Kanishka P. Wijewardena, Steven A. Grosz, Kai Cao, Anil K. Jain",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.03809"" target=""_blank"">2205.03809</a>",,2025-12-03 22:39:25
Empirical Advocacy of Bio-inspired Models for Robust Image Recognition,"Harshitha Machiraju, Oh-Hyeon Choung, Michael H. Herzog, Pascal Frossard",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.09037"" target=""_blank"">2205.09037</a>",,2025-12-03 22:39:25
Mitigating Neural Network Overconfidence with Logit Normalization,"Hongxin Wei, Renchunzi Xie, Hao Cheng, Lei Feng, Bo An, Yixuan Li",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.09310"" target=""_blank"">2205.09310</a>",,2025-12-03 22:39:25
RandoMix: A mixed sample data augmentation method with multiple mixed modes,"Xiaoliang Liu, Furao Shen, Jian Zhao, Changhai Nie",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.08728"" target=""_blank"">2205.08728</a>",,2025-12-03 22:39:25
Bankrupting DoS Attackers Despite Uncertainty,"Trisha Chakraborty, Abir Islam, Valerie King, Daniel Rayborn, Jared Saia, Maxwell Young",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.08287"" target=""_blank"">2205.08287</a>",,2025-12-03 22:39:25
A two-steps approach to improve the performance of Android malware detectors,"Nadia Daoudi, Kevin Allix, Tegawendé F. Bissyandé, Jacques Klein",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.08265"" target=""_blank"">2205.08265</a>",,2025-12-03 22:39:25
Policy Distillation with Selective Input Gradient Regularization for Efficient Interpretability,"Jinwei Xing, Takashi Nagata, Xinyun Zou, Emre Neftci, Jeffrey L. Krichmar",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.08685"" target=""_blank"">2205.08685</a>",,2025-12-03 22:39:25
Recovering Private Text in Federated Learning of Language Models,"Samyak Gupta, Yangsibo Huang, Zexuan Zhong, Tianyu Gao, Kai Li, Danqi Chen",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.08514"" target=""_blank"">2205.08514</a>",,2025-12-03 22:39:25
Semi-Supervised Building Footprint Generation with Feature and Output Consistency Training,"Qingyu Li, Yilei Shi, Xiao Xiang Zhu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.08416"" target=""_blank"">2205.08416</a>",,2025-12-03 22:39:25
Diffusion Models for Adversarial Purification,"Weili Nie, Brandon Guo, Yujia Huang, Chaowei Xiao, Arash Vahdat, Anima Anandkumar",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.07460"" target=""_blank"">2205.07460</a>","<a href=""https://diffpure.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Verifying Neural Networks Against Backdoor Attacks,"Long H. Pham, Jun Sun",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.06992"" target=""_blank"">2205.06992</a>",,2025-12-03 22:39:25
Robust Representation via Dynamic Feature Aggregation,"Haozhe Liu, Haoqin Ji, Yuexiang Li, Nanjun He, Haoqian Wu, Feng Liu, Linlin Shen, Yefeng Zheng",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.07466"" target=""_blank"">2205.07466</a>","<a href=""https://github.com/HaozheLiu-ST/DynamicFeatureAggregation"" target=""_blank"">HaozheLiu-ST</a>",2025-12-03 22:39:25
Sparse Visual Counterfactual Explanations in Image Space,"Valentyn Boreiko, Maximilian Augustin, Francesco Croce, Philipp Berens, Matthias Hein",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.07972"" target=""_blank"">2205.07972</a>",,2025-12-03 22:39:25
On the Difficulty of Defending Self-Supervised Learning against Model Extraction,"Adam Dziedzic, Nikita Dhawan, Muhammad Ahmad Kaleem, Jonas Guan, Nicolas Papernot",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.07890"" target=""_blank"">2205.07890</a>",,2025-12-03 22:39:25
Transferability of Adversarial Attacks on Synthetic Speech Detection,"Jiacheng Deng, Shunyi Chen, Li Dong, Diqun Yan, Rangding Wang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.07711"" target=""_blank"">2205.07711</a>",,2025-12-03 22:39:25
Learn2Weight: Parameter Adaptation against Similar-domain Adversarial Attacks,Siddhartha Datta,arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.07315"" target=""_blank"">2205.07315</a>",,2025-12-03 22:39:25
Exploiting the Relationship Between Kendall's Rank Correlation and Cosine Similarity for Attribution Protection,"Fan Wang, Adams Wai-Kin Kong",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.07279"" target=""_blank"">2205.07279</a>",,2025-12-03 22:39:25
RoMFAC: A robust mean-field actor-critic reinforcement learning against adversarial perturbations on states,"Ziyuan Zhou, Guanjun Liu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.07229"" target=""_blank"">2205.07229</a>",,2025-12-03 22:39:25
Automation Slicing and Testing for in-App Deep Learning Models,"Hao Wu, Yuhang Gong, Xiaopeng Ke, Hanzhong Liang, Minghao Li, Fengyuan Xu, Yunxin Liu, Sheng Zhong",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.07228"" target=""_blank"">2205.07228</a>",,2025-12-03 22:39:25
Evaluating Membership Inference Through Adversarial Robustness,"Zhaoxi Zhang, Leo Yu Zhang, Xufei Zheng, Bilal Hussain Abbasi, Shengshan Hu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.06986"" target=""_blank"">2205.06986</a>","<a href=""https://github.com/plll4zzx/Evaluating-Membership-Inference-Through-Adversarial-Robustness"" target=""_blank"">plll4zzx</a>",2025-12-03 22:39:25
Verifying Integrity of Deep Ensemble Models by Lossless Black-box Watermarking with Sensitive Samples,"Lina Lin, Hanzhou Wu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.04145"" target=""_blank"">2205.04145</a>",,2025-12-03 22:39:25
A Hybrid Defense Method against Adversarial Attacks on Traffic Sign Classifiers in Autonomous Vehicles,"Zadid Khan, Mashrur Chowdhury, Sakib Mahmud Khan",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.01225"" target=""_blank"">2205.01225</a>",,2025-12-03 22:39:25
ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning,"Jingtao Li, Adnan Siraj Rakin, Xing Chen, Zhezhi He, Deliang Fan, Chaitali Chakrabarti",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.04007"" target=""_blank"">2205.04007</a>","<a href=""https://github.com/zlijingtao/ResSFL"" target=""_blank"">zlijingtao</a>",2025-12-03 22:39:25
VPN: Verification of Poisoning in Neural Networks,"Youcheng Sun, Muhammad Usman, Divya Gopinath, Corina S. Păsăreanu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.03894"" target=""_blank"">2205.03894</a>",,2025-12-03 22:39:25
Deep-Attack over the Deep Reinforcement Learning,"Yang Li, Quan Pan, Erik Cambria",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.00807"" target=""_blank"">2205.00807</a>",,2025-12-03 22:39:25
Enhancing Adversarial Training with Feature Separability,"Yaxin Li, Xiaorui Liu, Han Xu, Wentao Wang, Jiliang Tang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.00637"" target=""_blank"">2205.00637</a>",,2025-12-03 22:39:25
BERTops: Studying BERT Representations under a Topological Lens,"Jatin Chauhan, Manohar Kaul",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.00953"" target=""_blank"">2205.00953</a>",,2025-12-03 22:39:25
MIRST-DM: Multi-Instance RST with Drop-Max Layer for Robust Classification of Breast Cancer,"Shoukun Sun, Min Xian, Aleksandar Vakanski, Hossny Ghanem",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.01674"" target=""_blank"">2205.01674</a>",,2025-12-03 22:39:25
Revisiting Gaussian Neurons for Online Clustering with Unknown Number of Clusters,Ole Christian Eidheim,arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.00920"" target=""_blank"">2205.00920</a>",,2025-12-03 22:39:25
A Word is Worth A Thousand Dollars: Adversarial Attack on Tweets Fools Stock Prediction,"Yong Xie, Dakuo Wang, Pin-Yu Chen, Jinjun Xiong, Sijia Liu, Sanmi Koyejo",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.01094"" target=""_blank"">2205.01094</a>",,2025-12-03 22:39:25
DDDM: a Brain-Inspired Framework for Robust Classification,"Xiyuan Chen, Xingyu Li, Yi Zhou, Tianming Yang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10117"" target=""_blank"">2205.10117</a>",,2025-12-03 22:39:25
Robust Fine-tuning via Perturbation and Interpolation from In-batch Instances,"Shoujie Tong, Qingxiu Dong, Damai Dai, Yifan song, Tianyu Liu, Baobao Chang, Zhifang Sui",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.00633"" target=""_blank"">2205.00633</a>",,2025-12-03 22:39:25
A Simple Approach to Improve Single-Model Deep Uncertainty via Distance-Awareness,"Jeremiah Zhe Liu, Shreyas Padhy, Jie Ren, Zi Lin, Yeming Wen, Ghassen Jerfel, Zack Nado, Jasper Snoek, Dustin Tran, Balaji Lakshminarayanan",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.00403"" target=""_blank"">2205.00403</a>","<a href=""https://github.com/google/uncertainty-baselines"" target=""_blank"">google</a>",2025-12-03 22:39:25
Adversarial Plannning,"Valentin Vie, Ryan Sheatsley, Sophia Beyda, Sushrut Shringarputale, Kevin Chan, Trent Jaeger, Patrick McDaniel",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.00566"" target=""_blank"">2205.00566</a>",,2025-12-03 22:39:25
Optimizing One-pixel Black-box Adversarial Attacks,"Tianxun Zhou, Shubhankar Agrawal, Prateek Manocha",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.02116"" target=""_blank"">2205.02116</a>",,2025-12-03 22:39:25
Cracking White-box DNN Watermarks via Invariant Neuron Transforms,"Yifan Yan, Xudong Pan, Yining Wang, Mi Zhang, Min Yang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.00199"" target=""_blank"">2205.00199</a>",,2025-12-03 22:39:25
Loss Function Entropy Regularization for Diverse Decision Boundaries,Chong Sue Sin,arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.00224"" target=""_blank"">2205.00224</a>",,2025-12-03 22:39:25
Adapting and Evaluating Influence-Estimation Methods for Gradient-Boosted Decision Trees,"Jonathan Brophy, Zayd Hammoudeh, Daniel Lowd",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.00359"" target=""_blank"">2205.00359</a>","<a href=""https://github.com/jjbrophy47/tree_influence"" target=""_blank"">jjbrophy47</a>",2025-12-03 22:39:25
Adversarial attacks on an optical neural network,"Shuming Jiao, Ziwei Song, Shuiying Xiang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.01226"" target=""_blank"">2205.01226</a>",,2025-12-03 22:39:25
Logically Consistent Adversarial Attacks for Soft Theorem Provers,"Alexander Gaskell, Yishu Miao, Lucia Specia, Francesca Toni",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.00047"" target=""_blank"">2205.00047</a>",,2025-12-03 22:39:25
Bridging Differential Privacy and Byzantine-Robustness via Model Aggregation,"Heng Zhu, Qing Ling",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.00107"" target=""_blank"">2205.00107</a>",,2025-12-03 22:39:25
Constraining the Attack Space of Machine Learning Models with Distribution Clamping Preprocessing,"Ryan Feng, Somesh Jha, Atul Prakash",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.08989"" target=""_blank"">2205.08989</a>",,2025-12-03 22:39:25
Toward Robust Spiking Neural Network Against Adversarial Perturbation,"Ling Liang, Kaidi Xu, Xing Hu, Lei Deng, Yuan Xie",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.01625"" target=""_blank"">2205.01625</a>",,2025-12-03 22:39:25
SemAttack: Natural Textual Attacks via Different Semantic Spaces,"Boxin Wang, Chejian Xu, Xiangyu Liu, Yu Cheng, Bo Li",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.01287"" target=""_blank"">2205.01287</a>","<a href=""https://github.com/AI-secure/SemAttack"" target=""_blank"">AI-secure</a>",2025-12-03 22:39:25
Meta-Cognition,"Kunal Pattanayak, Vikram Krishnamurthy, Christopher Berry",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.01794"" target=""_blank"">2205.01794</a>",,2025-12-03 22:39:25
On the uncertainty principle of neural networks,"Jun-Jie Zhang, Dong-Xiao Zhang, Jian-Nan Chen, Long-Gang Pang, Deyu Meng",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.01493"" target=""_blank"">2205.01493</a>",,2025-12-03 22:39:25
Structural Extensions of Basis Pursuit: Guarantees on Adversarial Robustness,"Dávid Szeghy, Mahmoud Aslan, Áron Fóthi, Balázs Mészáros, Zoltán Ádám Milacski, András Lőrincz",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.08955"" target=""_blank"">2205.08955</a>",,2025-12-03 22:39:25
FOLPETTI: A Novel Multi-Armed Bandit Smart Attack for Wireless Networks,"Emilie Bout, Alessandro Brighente, Mauro Conti, Valeria Loscri",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.03915"" target=""_blank"">2205.03915</a>",,2025-12-03 22:39:25
PGADA: Perturbation-Guided Adversarial Alignment for Few-shot Learning Under the Support-Query Shift,"Siyang Jiang, Wei Ding, Hsi-Wen Chen, Ming-Syan Chen",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.03817"" target=""_blank"">2205.03817</a>",,2025-12-03 22:39:25
Bandits for Structure Perturbation-based Black-box Attacks to Graph Neural Networks with Theoretical Guarantees,"Binghui Wang, Youqi Li, Pan Zhou",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.03546"" target=""_blank"">2205.03546</a>","<a href=""https://github.com/Metaoblivion/Bandit_GNN_Attack"" target=""_blank"">Metaoblivion</a>",2025-12-03 22:39:25
Imperceptible Backdoor Attack: From Input Space to Feature Representation,"Nan Zhong, Zhenxing Qian, Xinpeng Zhang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.03190"" target=""_blank"">2205.03190</a>","<a href=""https://github.com/Ekko-zn/IJCAI2022-Backdoor"" target=""_blank"">Ekko-zn</a>",2025-12-03 22:39:25
Defending against Reconstruction Attacks through Differentially Private Federated Learning for Classification of Heterogeneous Chest X-Ray Data,"Joceline Ziegler, Bjarne Pfitzner, Heinrich Schulz, Axel Saalbach, Bert Arnrich",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.03168"" target=""_blank"">2205.03168</a>",,2025-12-03 22:39:25
LPGNet: Link Private Graph Networks for Node Classification,"Aashish Kolluri, Teodora Baluta, Bryan Hooi, Prateek Saxena",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.03105"" target=""_blank"">2205.03105</a>",,2025-12-03 22:39:25
Unlimited Lives: Secure In-Process Rollback with Isolated Domains,"Merve Gülmez, Thomas Nyman, Christoph Baumann, Jan Tobias Mühlberg",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.03205"" target=""_blank"">2205.03205</a>",,2025-12-03 22:39:25
Holistic Approach to Measure Sample-level Adversarial Vulnerability and its Utility in Building Trustworthy Systems,"Gaurav Kumar Nayak, Ruchit Rawal, Rohit Lal, Himanshu Patil, Anirban Chakraborty",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.02604"" target=""_blank"">2205.02604</a>",,2025-12-03 22:39:25
"Can collaborative learning be private, robust and scalable? (61%)","Dmitrii Usynin, Helena Klause, Daniel Rueckert, Georgios Kaissis",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.02652"" target=""_blank"">2205.02652</a>",,2025-12-03 22:39:25
"Don't sweat the small stuff, classify the rest: Sample Shielding to protect text classifiers against adversarial attacks","Jonathan Rusert, Padmini Srinivasan",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.01714"" target=""_blank"">2205.01714</a>",,2025-12-03 22:39:25
Are GAN-based Morphs Threatening Face Recognition? (1%),"Eklavya Sarkar, Pavel Korshunov, Laurent Colbois, Sébastien Marcel",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.02496"" target=""_blank"">2205.02496</a>",,2025-12-03 22:39:25
Heterogeneous Domain Adaptation with Adversarial Neural Representation Learning: Experiments on E-Commerce and Cybersecurity,"Mohammadreza Ebrahimi, Yidong Chai, Hao Helen Zhang, Hsinchun Chen",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.07853"" target=""_blank"">2205.07853</a>",,2025-12-03 22:39:25
Based-CE white-box adversarial attack will not work using super-fitting,"Youhuan Yang, Lei Sun, Leyu Dai, Song Guo, Xiuqing Mao, Xiaoqin Wang, Bayi Xu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.02741"" target=""_blank"">2205.02741</a>",,2025-12-03 22:39:25
Rethinking Classifier And Adversarial Attack,"Youhuan Yang, Lei Sun, Leyu Dai, Song Guo, Xiuqing Mao, Xiaoqin Wang, Bayi Xu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.02743"" target=""_blank"">2205.02743</a>",,2025-12-03 22:39:25
Wild Patterns Reloaded: A Survey of Machine Learning Security against Training Data Poisoning,"Antonio Emanuele Cinà, Kathrin Grosse, Ambra Demontis, Sebastiano Vascon, Werner Zellinger, Bernhard A. Moser, Alina Oprea, Battista Biggio, Marcello Pelillo, Fabio Roli",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.01992"" target=""_blank"">2205.01992</a>",,2025-12-03 22:39:25
Robust Conversational Agents against Imperceptible Toxicity Triggers,"Ninareh Mehrabi, Ahmad Beirami, Fred Morstatter, Aram Galstyan",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.02392"" target=""_blank"">2205.02392</a>",,2025-12-03 22:39:25
Subverting Fair Image Search with Generative Adversarial Perturbations,"Avijit Ghosh, Matthew Jagielski, Christo Wilson",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.02414"" target=""_blank"">2205.02414</a>",,2025-12-03 22:39:25
Adversarial Training for High-Stakes Reliability,"Daniel M. Ziegler, Seraphina Nix, Lawrence Chan, Tim Bauman, Peter Schmidt-Nielsen, Tao Lin, Adam Scherlis, Noa Nabeshima, Ben Weinstein-Raun, Haas Daniel de, Buck Shlegeris, Nate Thomas",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.01663"" target=""_blank"">2205.01663</a>",,2025-12-03 22:39:25
Backdoor Attacks on Bayesian Neural Networks using Reverse Distribution,"Zhixin Pan, Prabhat Mishra",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.09167"" target=""_blank"">2205.09167</a>",,2025-12-03 22:39:25
Large Scale Transfer Learning for Differentially Private Image Classification,"Harsh Mehta, Abhradeep Thakurta, Alexey Kurakin, Ashok Cutkosky",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.02973"" target=""_blank"">2205.02973</a>",,2025-12-03 22:39:25
Property Unlearning: A Defense Strategy Against Property Inference Attacks,"Joshua Universität Hamburg Stock, Jens Universität Hamburg Wettlaufer, Daniel Universität Hamburg Demmler, Hannes Universität Hamburg Federrath",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.08821"" target=""_blank"">2205.08821</a>",,2025-12-03 22:39:25
Syntax-Guided Program Reduction for Understanding Neural Code Intelligence Models,"Md Rafiqul Islam Rabin, Aftab Hussain, Mohammad Amin Alipour",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.14374"" target=""_blank"">2205.14374</a>",,2025-12-03 22:39:25
Why Robust Generalization in Deep Learning is Difficult: Perspective of Expressive Power,"Binghui Li, Jikai Jin, Han Zhong, John E. Hopcroft, Liwei Wang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13863"" target=""_blank"">2205.13863</a>",,2025-12-03 22:39:25
Semi-supervised Semantics-guided Adversarial Training for Trajectory Prediction,"Ruochen Jiao, Xiangguo Liu, Takami Sato, Qi Alfred Chen, Qi Zhu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.14230"" target=""_blank"">2205.14230</a>",,2025-12-03 22:39:25
Defending Against Stealthy Backdoor Attacks,"Sangeet Sagar, Abhinav Bhatt, Abhijith Srinivas Bidaralli",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.14246"" target=""_blank"">2205.14246</a>",,2025-12-03 22:39:25
EvenNet: Ignoring Odd-Hop Neighbors Improves Robustness of Graph Neural Networks,"Runlin Lei, Zhen Wang, Yaliang Li, Bolin Ding, Zhewei Wei",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13892"" target=""_blank"">2205.13892</a>",,2025-12-03 22:39:25
A Physical-World Adversarial Attack Against 3D Face Recognition,"Yanjie Li, Yiquan Li, Bin Xiao",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13412"" target=""_blank"">2205.13412</a>",,2025-12-03 22:39:25
Transferable Adversarial Attack based on Integrated Gradients,"Yi Huang, Adams Wai-Kin Kong",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13152"" target=""_blank"">2205.13152</a>","<a href=""https://github.com/yihuang2016/TAIG"" target=""_blank"">yihuang2016</a>",2025-12-03 22:39:25
MALICE: Manipulation Attacks on Learned Image ComprEssion,"Kang Liu, Di Wu, Yiru Wang, Dan Feng, Benjamin Tan, Siddharth Garg",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13253"" target=""_blank"">2205.13253</a>",,2025-12-03 22:39:25
Phantom Sponges: Exploiting Non-Maximum Suppression to Attack Deep Object Detectors,"Avishag Shapira, Alon Zolfi, Luca Demetrio, Battista Biggio, Asaf Shabtai",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13618"" target=""_blank"">2205.13618</a>",,2025-12-03 22:39:25
Circumventing Backdoor Defenses That Are Based on Latent Separability,"Xiangyu Qi, Tinghao Xie, Yiming Li, Saeed Mahloujifar, Prateek Mittal",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13613"" target=""_blank"">2205.13613</a>",,2025-12-03 22:39:25
An Analytic Framework for Robust Training of Artificial Neural Networks,"Ramin Barati, Reza Safabakhsh, Mohammad Rahmati",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13502"" target=""_blank"">2205.13502</a>",,2025-12-03 22:39:25
Adversarial attacks and defenses in Speaker Recognition Systems: A survey,"Jiahe Lan, Rui Zhang, Zheng Yan, Jie Wang, Yu Chen, Ronghui Hou",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13685"" target=""_blank"">2205.13685</a>",,2025-12-03 22:39:25
PerDoor: Persistent Non-Uniform Backdoors in Federated Learning using Adversarial Perturbations,"Manaar Alam, Esha Sarkar, Michail Maniatakos",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13523"" target=""_blank"">2205.13523</a>",,2025-12-03 22:39:25
BppAttack: Stealthy and Efficient Trojan Attacks against Deep Neural Networks via Image Quantization and Contrastive Adversarial Learning,"Zhenting Wang, Juan Zhai, Shiqing Ma",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13383"" target=""_blank"">2205.13383</a>","<a href=""https://github.com/RU-System-Software-and-Security/BppAttack"" target=""_blank"">RU-System-Software-and-Security</a>",2025-12-03 22:39:25
R-HTDetector: Robust Hardware-Trojan Detection Based on Adversarial Training,"Kento Hasegawa, Seira Hidano, Kohei Nozawa, Shinsaku Kiyomoto, Nozomu Togawa",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13702"" target=""_blank"">2205.13702</a>",,2025-12-03 22:39:25
BagFlip: A Certified Defense against Data Poisoning,"Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13634"" target=""_blank"">2205.13634</a>",,2025-12-03 22:39:25
Towards A Proactive ML Approach for Detecting Backdoor Poison Samples,"Xiangyu Qi, Tinghao Xie, Jiachen T. Wang, Tong Wu, Saeed Mahloujifar, Prateek Mittal",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13616"" target=""_blank"">2205.13616</a>",,2025-12-03 22:39:25
Membership Inference Attack Using Self Influence Functions,"Gilad Cohen, Raja Giryes",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13680"" target=""_blank"">2205.13680</a>","<a href=""https://github.com/giladcohen/sif_mi_attack"" target=""_blank"">giladcohen</a>",2025-12-03 22:39:25
MemeTector: Enforcing deep focus for meme detection,"Christos Koutlis, Manos Schinas, Symeon Papadopoulos",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13268"" target=""_blank"">2205.13268</a>","<a href=""https://github.com/mever-team/memetector"" target=""_blank"">mever-team</a>",2025-12-03 22:39:25
ES-GNN: Generalizing Graph Neural Networks Beyond Homophily with Edge Splitting,"Jingwei Guo, Kaizhu Huang, Rui Zhang, Xinping Yi",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13700"" target=""_blank"">2205.13700</a>",,2025-12-03 22:39:25
fakeWeather: Adversarial Attacks for Deep Neural Networks Emulating Weather Conditions on the Camera Lens of Autonomous Systems,"Alberto Marchisio, Giovanni Caramia, Maurizio Martina, Muhammad Shafique",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13807"" target=""_blank"">2205.13807</a>",,2025-12-03 22:39:25
BadDet: Backdoor Attacks on Object Detection,"Shih-Han Chan, Yinpeng Dong, Jun Zhu, Xiaolu Zhang, Jun Zhou",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.14497"" target=""_blank"">2205.14497</a>",,2025-12-03 22:39:25
BITE: Textual Backdoor Attacks with Iterative Trigger Injection,"Jun Yan, Vansh Gupta, Xiang Ren",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.12700"" target=""_blank"">2205.12700</a>",,2025-12-03 22:39:25
A General Multiple Data Augmentation Based Framework for Training Deep Neural Networks,"Binyan Hu, Yu Sun, A. K. Qin",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.14606"" target=""_blank"">2205.14606</a>",,2025-12-03 22:39:25
Hide and Seek: on the Stealthiness of Attacks against Deep Learning Systems,"Zeyan Liu, Fengjun Li, Jingqiang Lin, Zhu Li, Bo Luo",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.15944"" target=""_blank"">2205.15944</a>",,2025-12-03 22:39:25
Exact Feature Collisions in Neural Networks,"Utku Ozbulak, Manvel Gasparyan, Shodhan Rao, Neve Wesley De, Messem Arnout Van",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.15763"" target=""_blank"">2205.15763</a>",,2025-12-03 22:39:25
Semantic Autoencoder and Its Potential Usage for Adversarial Attack,"Yurui Ming, Cuihuan Du, Chin-Teng Lin",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.15592"" target=""_blank"">2205.15592</a>",,2025-12-03 22:39:25
An Effective Fusion Method to Enhance the Robustness of CNN,"Yating Ma, Zhichao Lian",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.15582"" target=""_blank"">2205.15582</a>",,2025-12-03 22:39:25
Likelihood-Free Inference with Generative Neural Networks via Scoring Rule Minimization,"Lorenzo Pacchiardi, Ritabrata Dutta",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.15784"" target=""_blank"">2205.15784</a>",,2025-12-03 22:39:25
Level Up with ML Vulnerability Identification: Leveraging Domain Constraints in Feature Space for Robust Android Malware Detection,"Hamid Bostani, Zhengyu Zhao, Zhuoran Liu, Veelasha Moonsamy",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.15128"" target=""_blank"">2205.15128</a>",,2025-12-03 22:39:25
Searching for the Essence of Adversarial Perturbations,"Dennis Y. Menn, Tzu-hsun Feng, Hung-yi Lee",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.15357"" target=""_blank"">2205.15357</a>",,2025-12-03 22:39:25
Exposing Fine-Grained Adversarial Vulnerability of Face Anti-Spoofing Models,"Songlin Yang, Wei Wang, Chenye Xu, Ziwen He, Bo Peng, Jing Dong",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.14851"" target=""_blank"">2205.14851</a>",,2025-12-03 22:39:25
Guided Diffusion Model for Adversarial Purification,"Jinyi Wang, Zhaoyang Lyu, Dahua Lin, Bo Dai, Hongfei Fu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.14969"" target=""_blank"">2205.14969</a>",,2025-12-03 22:39:25
Why Adversarial Training of ReLU Networks Is Difficult? (68%),"Xu Cheng, Hao Zhang, Yue Xin, Wen Shen, Jie Ren, Quanshi Zhang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.15130"" target=""_blank"">2205.15130</a>",,2025-12-03 22:39:25
CalFAT: Calibrated Federated Adversarial Training with Label Skewness,"Chen Chen, Yuchen Liu, Xingjun Ma, Lingjuan Lyu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.14926"" target=""_blank"">2205.14926</a>",,2025-12-03 22:39:25
Efficient Reward Poisoning Attacks on Online Deep Reinforcement Learning,"Yinglun Xu, Qi Zeng, Gagandeep Singh",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.14842"" target=""_blank"">2205.14842</a>",,2025-12-03 22:39:25
Snoopy: A Webpage Fingerprinting Framework with Finite Query Model for Mass-Surveillance,"Gargi Mitra, Prasanna Karthik Vairam, Sandip Saha, Nitin Chandrachoodan, V. Kamakoti",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.15037"" target=""_blank"">2205.15037</a>",,2025-12-03 22:39:25
Robust Weight Perturbation for Adversarial Training,"Chaojian Yu, Bo Han, Mingming Gong, Li Shen, Shiming Ge, Bo Du, Tongliang Liu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.14826"" target=""_blank"">2205.14826</a>",,2025-12-03 22:39:25
Mixture GAN For Modulation Classification Resiliency Against Adversarial Attacks,"Eyad Shtaiwi, Ahmed El Ouadrhiri, Majid Moradikia, Salma Sultana, Ahmed Abdelhadi, Zhu Han",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.15743"" target=""_blank"">2205.15743</a>",,2025-12-03 22:39:25
Unfooling Perturbation-Based Post Hoc Explainers,"Zachariah Carmichael, Walter J Scheirer",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.14772"" target=""_blank"">2205.14772</a>",,2025-12-03 22:39:25
On the Robustness of Safe Reinforcement Learning under Observational Perturbations,"Zuxin Liu, Zijian Guo, Zhepeng Cen, Huan Zhang, Jie Tan, Bo Li, Ding Zhao",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.14691"" target=""_blank"">2205.14691</a>",,2025-12-03 22:39:25
Superclass Adversarial Attack,"Soichiro Kumano, Hiroshi Kera, Toshihiko Yamasaki",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.14629"" target=""_blank"">2205.14629</a>",,2025-12-03 22:39:25
Problem-Space Evasion Attacks in the Android OS: a Survey,"Harel Berger, Chen Hajaj, Amit Dvir",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.14576"" target=""_blank"">2205.14576</a>",,2025-12-03 22:39:25
Surprises in adversarially-trained linear regression,"Antônio H. Ribeiro, Dave Zachariah, Thomas B. Schön",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.12695"" target=""_blank"">2205.12695</a>",,2025-12-03 22:39:25
Fool SHAP with Stealthily Biased Sampling,"Gabriel Laberge, Ulrich Aïvodji, Satoshi Hara, Mario Marchand., Foutse Khomh",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.15419"" target=""_blank"">2205.15419</a>",,2025-12-03 22:39:25
Impartial Games: A Challenge for Reinforcement Learning,"Bei Zhou, Søren Riis",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.12787"" target=""_blank"">2205.12787</a>",,2025-12-03 22:39:25
Vulnerability Analysis and Performance Enhancement of Authentication Protocol in Dynamic Wireless Power Transfer Systems,"Tommaso Bianchi, Surudhi Asokraj, Alessandro Brighente, Mauro Conti, Radha Poovendran",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10292"" target=""_blank"">2205.10292</a>",,2025-12-03 22:39:25
Phrase-level Textual Adversarial Attack with Label Preservation,"Yibin Lei, Yu Cao, Dianqi Li, Tianyi Zhou, Meng Fang, Mykola Pechenizkiy",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10710"" target=""_blank"">2205.10710</a>",,2025-12-03 22:39:25
On the Feasibility and Generality of Patch-based Adversarial Attacks on Semantic Segmentation Problems,"Soma Kontar, Andras Horvath",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10539"" target=""_blank"">2205.10539</a>",,2025-12-03 22:39:25
Getting a-Round Guarantees: Floating-Point Attacks on Certified Robustness,"Jiankai Jin, Olga Ohrimenko, Benjamin I. P. Rubinstein",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10159"" target=""_blank"">2205.10159</a>",,2025-12-03 22:39:25
Robust Sensible Adversarial Learning of Deep Neural Networks for Image Classification,"Jungeum Kim, Xiao Wang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10457"" target=""_blank"">2205.10457</a>",,2025-12-03 22:39:25
Adversarial joint attacks on legged robots,"Takuto Otomo, Hiroshi Kera, Kazuhiko Kawamoto",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10098"" target=""_blank"">2205.10098</a>",,2025-12-03 22:39:25
Towards Consistency in Adversarial Classification,"Laurent Meunier, Raphaël Ettedgui, Rafael Pinot, Yann Chevaleyre, Jamal Atif",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10022"" target=""_blank"">2205.10022</a>",,2025-12-03 22:39:25
Adversarial Body Shape Search for Legged Robots,"Takaaki Azakami, Hiroshi Kera, Kazuhiko Kawamoto",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10187"" target=""_blank"">2205.10187</a>",,2025-12-03 22:39:25
SafeNet: Mitigating Data Poisoning Attacks on Private Machine Learning,"Harsh Chaudhari, Matthew Jagielski, Alina Oprea",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.09986"" target=""_blank"">2205.09986</a>",,2025-12-03 22:39:25
The developmental trajectory of object recognition robustness: children are like small adults but unlike big deep neural networks,"Lukas S. Huber, Robert Geirhos, Felix A. Wichmann",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10144"" target=""_blank"">2205.10144</a>",,2025-12-03 22:39:25
"Exploring the Trade-off between Plausibility, Change Intensity and Adversarial Power in Counterfactual Explanations using Multi-objective Optimization","Ser Javier Del, Alejandro Barredo-Arrieta, Natalia Díaz-Rodríguez, Francisco Herrera, Andreas Holzinger",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10232"" target=""_blank"">2205.10232</a>",,2025-12-03 22:39:25
Post-breach Recovery: Protection against White-box Adversarial Examples for Leaked DNN Models,"Shawn Shan, Wenxin Ding, Emily Wenger, Haitao Zheng, Ben Y. Zhao",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10686"" target=""_blank"">2205.10686</a>",,2025-12-03 22:39:25
Focused Adversarial Attacks,"Thomas Cilloni, Charles Walter, Charles Fleming",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.09624"" target=""_blank"">2205.09624</a>",,2025-12-03 22:39:25
Transferable Physical Attack against Object Detection with Separable Attention,"Yu Zhang, Zhiqiang Gong, Yichuang Zhang, YongQian Li, Kangcheng Bin, Jiahao Qi, Wei Xue, Ping Zhong",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.09592"" target=""_blank"">2205.09592</a>",,2025-12-03 22:39:25
Gradient Aligned Attacks via a Few Queries,"Xiangyuan Yang, Jie Lin, Hanlin Zhang, Xinyu Yang, Peng Zhao",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.09518"" target=""_blank"">2205.09518</a>",,2025-12-03 22:39:25
On Trace of PGD-Like Adversarial Attacks,"Mo Zhou, Vishal M. Patel",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.09586"" target=""_blank"">2205.09586</a>",,2025-12-03 22:39:25
Improving Robustness against Real-World and Worst-Case Distribution Shifts through Decision Region Quantification,"Leo Schwinn, Leon Bungert, An Nguyen, René Raab, Falk Pulsmeyer, Doina Precup, Björn Eskofier, Dario Zanca",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.09619"" target=""_blank"">2205.09619</a>",,2025-12-03 22:39:25
Defending Against Adversarial Attacks by Energy Storage Facility,"Jiawei Li, Jianxiao Wang, Lin Chen, Yang Yu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.09522"" target=""_blank"">2205.09522</a>",,2025-12-03 22:39:25
How explainable are adversarially-robust CNNs? (8%),"Mehdi Nourelahi, Lars Kotthoff, Peijie Chen, Anh Nguyen",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.13042"" target=""_blank"">2205.13042</a>",,2025-12-03 22:39:25
Sparse Adversarial Attack in Multi-agent Reinforcement Learning,"Yizheng Hu, Zhihua Zhang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.09362"" target=""_blank"">2205.09362</a>",,2025-12-03 22:39:25
Data Valuation for Offline Reinforcement Learning,"Amir Abolfazli, Gregory Palmer, Daniel Kudenko",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.09550"" target=""_blank"">2205.09550</a>",,2025-12-03 22:39:25
Gradient Concealment: Free Lunch for Defending Adversarial Attacks,"Sen Pei, Jiaxi Sun, Xiaopeng Zhang, Gaofeng Meng",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10617"" target=""_blank"">2205.10617</a>",,2025-12-03 22:39:25
Passive Defense Against 3D Adversarial Point Clouds Through the Lens of 3D Steganalysis,Jiahao Zhu,arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.08738"" target=""_blank"">2205.08738</a>",,2025-12-03 22:39:25
Generalization ability and Vulnerabilities to adversarial perturbations: Two sides of the same coin,"Jung Hoon Lee, Sujith Vijayan",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10952"" target=""_blank"">2205.10952</a>",,2025-12-03 22:39:25
Fast & Furious: Modelling Malware Detection as Evolving Data Streams,"Fabrício Ceschin, Marcus Botacin, Heitor Murilo Gomes, Felipe Pinagé, Luiz S. Oliveira, André Grégio",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.12311"" target=""_blank"">2205.12311</a>",,2025-12-03 22:39:25
Certified Robustness Against Natural Language Attacks by Causal Intervention,"Haiteng Zhao, Chang Ma, Xinshuai Dong, Anh Tuan Luu, Zhi-Hong Deng, Hanwang Zhang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.12331"" target=""_blank"">2205.12331</a>",,2025-12-03 22:39:25
Robust Quantity-Aware Aggregation for Federated Learning,"Jingwei Yi, Fangzhao Wu, Huishuai Zhang, Bin Zhu, Tao Qi, Guangzhong Sun, Xing Xie",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10848"" target=""_blank"">2205.10848</a>",,2025-12-03 22:39:25
Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box Score-Based Query Attacks,"Sizhe Chen, Zhehao Huang, Qinghua Tao, Yingwen Wu, Cihang Xie, Xiaolin Huang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.12134"" target=""_blank"">2205.12134</a>",,2025-12-03 22:39:25
Defending a Music Recommender Against Hubness-Based Adversarial Attacks,"Katharina Hoedt, Arthur Flexer, Gerhard Widmer",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.12032"" target=""_blank"">2205.12032</a>",,2025-12-03 22:39:25
One-Pixel Shortcut: on the Learning Preference of Deep Neural Networks,"Shutong Wu, Sizhe Chen, Cihang Xie, Xiaolin Huang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.12141"" target=""_blank"">2205.12141</a>",,2025-12-03 22:39:25
WeDef: Weakly Supervised Backdoor Defense for Text Classification,"Lesheng Jin, Zihan Wang, Jingbo Shang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.11803"" target=""_blank"">2205.11803</a>",,2025-12-03 22:39:25
Recipe2Vec: Multi-modal Recipe Representation Learning with Graph Neural Networks,"Yijun Tian, Chuxu Zhang, Zhichun Guo, Yihong Ma, Ronald Metoyer, Nitesh V. Chawla",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.12396"" target=""_blank"">2205.12396</a>","<a href=""https://github.com/meettyj/Recipe2Vec"" target=""_blank"">meettyj</a>",2025-12-03 22:39:25
"EBM Life Cycle: MCMC Strategies for Synthesis, Defense, and Density Modeling","Mitch Hill, Jonathan Mitchell, Chu Chen, Yuan Du, Mubarak Shah, Song-Chun Zhu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.12243"" target=""_blank"">2205.12243</a>","<a href=""https://github.com/point0bar1/ebm-life-cycle"" target=""_blank"">point0bar1</a>",2025-12-03 22:39:25
Comprehensive Privacy Analysis on Federated Recommender System against Attribute Inference Attacks,"Shijie Zhang, Hongzhi Yin",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.11857"" target=""_blank"">2205.11857</a>",,2025-12-03 22:39:25
Fine-grained Poisoning Attacks to Local Differential Privacy Protocols for Mean and Variance Estimation,"Xiaoguang Li, Neil Zhenqiang Gong, Ninghui Li, Wenhai Sun, Hui Li",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.11782"" target=""_blank"">2205.11782</a>",,2025-12-03 22:39:25
Quarantine: Sparsity Can Uncover the Trojan Attack Trigger for Free,"Tianlong Chen, Zhenyu Zhang, Yihua Zhang, Shiyu Chang, Sijia Liu, Zhangyang Wang",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.11819"" target=""_blank"">2205.11819</a>","<a href=""https://github.com/VITA-Group/Backdoor-LTH"" target=""_blank"">VITA-Group</a>",2025-12-03 22:39:25
Learning to Ignore Adversarial Attacks,"Yiming Zhang, Yangqiaoyu Zhou, Samuel Carton, Chenhao Tan",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.11551"" target=""_blank"">2205.11551</a>",,2025-12-03 22:39:25
AutoJoin: Efficient Adversarial Training for Robust Maneuvering via Denoising Autoencoder and Joint Learning,"Michael Villarreal, Bibek Poudel, Ryan Wickman, Yu Shen, Weizi Li",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.10933"" target=""_blank"">2205.10933</a>",,2025-12-03 22:39:25
RCC-GAN: Regularized Compound Conditional GAN for Large-Scale Tabular Data Synthesis,"Mohammad Esmaeilpour, Nourhene Chaalia, Adel Abusitta, Francois-Xavier Devailly, Wissem Maazoun, Patrick Cardinal",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.11693"" target=""_blank"">2205.11693</a>",,2025-12-03 22:39:25
Compressing Deep Graph Neural Networks via Adversarial Knowledge Distillation,"Huarui He, Jie Wang, Zhanqiu Zhang, Feng Wu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.11678"" target=""_blank"">2205.11678</a>",,2025-12-03 22:39:25
CDFKD-MFS: Collaborative Data-free Knowledge Distillation via Multi-level Feature Sharing,"Zhiwei Hao, Yong Luo, Zhi Wang, Han Hu, Jianping An",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.11845"" target=""_blank"">2205.11845</a>",,2025-12-03 22:39:25
Towards a Defense against Backdoor Attacks in Continual Federated Learning,"Shuaiqi Wang, Jonathan Hayase, Giulia Fanti, Sewoong Oh",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.11736"" target=""_blank"">2205.11736</a>",,2025-12-03 22:39:25
Alleviating Robust Overfitting of Adversarial Training With Consistency Regularization,"Shudong Zhang, Haichang Gao, Tianwei Zhang, Yunyi Zhou, Zihui Wu",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.11744"" target=""_blank"">2205.11744</a>",,2025-12-03 22:39:25
Collaborative Adversarial Training,"Qizhang Li, Yiwen Guo, Wangmeng Zuo, Hao Chen",arXiv,2022-05,"<a href=""http://arxiv.org/abs/2205.11156"" target=""_blank"">2205.11156</a>",,2025-12-03 22:39:25
Adaptive-Gravity: A Defense Against Adversarial Samples,"Ali Mirzaeian, Zhi Tian, Sai Manoj P D, Banafsheh S. Latibari, Ioannis Savidis, Houman Homayoun, Avesta Sasan",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.03694"" target=""_blank"">2204.03694</a>",,2025-12-03 22:39:25
Transfer Attacks Revisited: A Large-Scale Empirical Study in Real Computer Vision Settings,"Yuhao Mao, Chong Fu, Saizhuo Wang, Shouling Ji, Xuhong Zhang, Zhenguang Liu, Jun Zhou, Alex X. Liu, Raheem Beyah, Ting Wang",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.04063"" target=""_blank"">2204.04063</a>",,2025-12-03 22:39:25
The self-learning AI controller for adaptive power beaming with fiber-array laser transmitter system,"A. M. Vorontsov, G. A. Filimonov",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.05227"" target=""_blank"">2204.05227</a>",,2025-12-03 22:39:25
Does Robustness on ImageNet Transfer to Downstream Tasks? (2%),"Yutaro Yamada, Mayu Otani",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.03934"" target=""_blank"">2204.03934</a>",,2025-12-03 22:39:25
Measuring the False Sense of Security,Carlos Gomes,arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.04778"" target=""_blank"">2204.04778</a>",,2025-12-03 22:39:25
Labeling-Free Comparison Testing of Deep Learning Models,"Yuejun Guo, Qiang Hu, Maxime Cordy, Xiaofei Xie, Mike Papadakis, Yves Le Traon",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.03994"" target=""_blank"">2204.03994</a>",,2025-12-03 22:39:25
Neural Tangent Generalization Attacks,"Chia-Hung Yuan, Shan-Hung Wu",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.04090"" target=""_blank"">2204.04090</a>","<a href=""https://github.com/lionelmessi6410/ntga"" target=""_blank"">lionelmessi6410</a>",2025-12-03 22:39:25
Using Multiple Self-Supervised Tasks Improves Model Robustness,"Matthew Lawhon, Chengzhi Mao, Junfeng Yang",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.03714"" target=""_blank"">2204.03714</a>",,2025-12-03 22:39:25
Characterizing and Understanding the Behavior of Quantized Models for Reliable Deployment,"Qiang Hu, Yuejun Guo, Maxime Cordy, Xiaofei Xie, Wei Ma, Mike Papadakis, Yves Le Traon",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.04220"" target=""_blank"">2204.04220</a>",,2025-12-03 22:39:25
An Adaptive Black-box Backdoor Detection Method for Deep Neural Networks,"Xinqiao Zhang, Huili Chen, Ke Huang, Farinaz Koushanfar",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.04329"" target=""_blank"">2204.04329</a>","<a href=""https://github.com/xinqiaozhang/adatrojan"" target=""_blank"">xinqiaozhang</a>",2025-12-03 22:39:25
Backdoor Attack against NLP models with Robustness-Aware Perturbation defense,"Shaik Mohammed Maqsood, Viveros Manuela Ceron, Addluri GowthamKrishna",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.05758"" target=""_blank"">2204.05758</a>",,2025-12-03 22:39:25
Evaluating the Adversarial Robustness for Fourier Neural Operators,"Abolaji D. Adesoji, Pin-Yu Chen",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.04259"" target=""_blank"">2204.04259</a>",,2025-12-03 22:39:25
AdvEst: Adversarial Perturbation Estimation to Classify and Detect Adversarial Attacks against Speaker Identification,"Sonal Joshi, Saurabh Kataria, Jesus Villalba, Najim Dehak",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.03848"" target=""_blank"">2204.03848</a>",,2025-12-03 22:39:25
Defense against Adversarial Attacks on Hybrid Speech Recognition using Joint Adversarial Fine-tuning with Denoiser,"Sonal Joshi, Saurabh Kataria, Yiwen Shao, Piotr Zelasko, Jesus Villalba, Sanjeev Khudanpur, Najim Dehak",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.03851"" target=""_blank"">2204.03851</a>",,2025-12-03 22:39:25
3DeformRS: Certifying Spatial Deformations on Point Clouds,"Gabriel Pérez S., Juan C. Pérez, Motasem Alfarra, Silvio Giancola, Bernard Ghanem",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.05687"" target=""_blank"">2204.05687</a>",,2025-12-03 22:39:25
Analysis of Power-Oriented Fault Injection Attacks on Spiking Neural Networks,"Karthikeyan Nagarajan, Junde Li, Sina Sayyah Ensan, Mohammad Nasim Imtiaz Khan, Sachhidh Kannan, Swaroop Ghosh",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.04768"" target=""_blank"">2204.04768</a>",,2025-12-03 22:39:25
Optimal Membership Inference Bounds for Adaptive Composition of Sampled Gaussian Mechanisms,"Saeed Mahloujifar, Alexandre Sablayrolles, Graham Cormode, Somesh Jha",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.06106"" target=""_blank"">2204.06106</a>",,2025-12-03 22:39:25
Overparameterized Linear Regression under Adversarial Attacks,"Antônio H. Ribeiro, Thomas B. Schön",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.06274"" target=""_blank"">2204.06274</a>",,2025-12-03 22:39:25
Towards A Critical Evaluation of Robustness for Deep Learning Backdoor Countermeasures,"Huming Qiu, Hua Ma, Zhi Zhang, Alsharif Abuadbba, Wei Kang, Anmin Fu, Yansong Gao",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.06273"" target=""_blank"">2204.06273</a>",,2025-12-03 22:39:25
A Natural Language Processing Approach for Instruction Set Architecture Identification,"Dinuka Sahabandu, Sukarno Mertoguno, Radha Poovendran",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.06624"" target=""_blank"">2204.06624</a>",,2025-12-03 22:39:25
Liuer Mihou: A Practical Framework for Generating and Evaluating Grey-box Adversarial Attacks against NIDS,"Ke He, Dan Dongseong Kim, Jing Sun, Jeong Do Yoo, Young Hun Lee, Huy Kang Kim",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.06113"" target=""_blank"">2204.06113</a>",,2025-12-03 22:39:25
Examining the Proximity of Adversarial Examples to Class Manifolds in Deep Networks,"Štefan Pócoš, Iveta Bečková, Igor Farkaš",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.05764"" target=""_blank"">2204.05764</a>",,2025-12-03 22:39:25
Machine Learning Security against Data Poisoning: Are We There Yet? (92%),"Antonio Emanuele Cinà, Kathrin Grosse, Ambra Demontis, Battista Biggio, Fabio Roli, Marcello Pelillo",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.05986"" target=""_blank"">2204.05986</a>",,2025-12-03 22:39:25
Defending Active Directory by Combining Neural Network based Dynamic Program and Evolutionary Diversity Optimisation,"Diksha Goel, Max Hector Ward-Graham, Aneta Neumann, Frank Neumann, Hung Nguyen, Mingyu Guo",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.03397"" target=""_blank"">2204.03397</a>",,2025-12-03 22:39:25
"""That Is a Suspicious Reaction!"": Interpreting Logits Variation to Detect NLP Adversarial Attacks","Edoardo Mosca, Shreyash Agarwal, Javier Rando-Ramirez, Georg Groh",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.04636"" target=""_blank"">2204.04636</a>",,2025-12-03 22:39:25
A Simple Approach to Adversarial Robustness in Few-shot Image Classification,"Akshayvarun Subramanya, Hamed Pirsiavash",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.05432"" target=""_blank"">2204.05432</a>","<a href=""https://github.com/UCDvision/Simple_few_shot"" target=""_blank"">UCDvision</a>",2025-12-03 22:39:25
Narcissus: A Practical Clean-Label Backdoor Attack with Limited Information,"Yi Zeng, Minzhou Pan, Hoang Anh Just, Lingjuan Lyu, Meikang Qiu, Ruoxi Jia",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.05255"" target=""_blank"">2204.05255</a>",,2025-12-03 22:39:25
Generalizing Adversarial Explanations with Grad-CAM,"Tanmay Chakraborty, Utkarsh Trehan, Khawla Mallat, Jean-Luc Dugelay",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.05427"" target=""_blank"">2204.05427</a>",,2025-12-03 22:39:25
Anti-Adversarially Manipulated Attributions for Weakly Supervised Semantic Segmentation and Object Localization,"Jungbeom Lee, Eunji Kim, Jisoo Mok, Sungroh Yoon",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.04890"" target=""_blank"">2204.04890</a>",,2025-12-03 22:39:25
Exploring the Universal Vulnerability of Prompt-based Learning Paradigm,"Lei Xu, Yangyi Chen, Ganqu Cui, Hongcheng Gao, Zhiyuan Liu",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.05239"" target=""_blank"">2204.05239</a>","<a href=""https://github.com/leix28/prompt-universal-vulnerability"" target=""_blank"">leix28</a>",2025-12-03 22:39:25
medXGAN: Visual Explanations for Medical Classifiers through a Generative Latent Space,"Amil Dravid, Florian Schiffers, Boqing Gong, Aggelos K. Katsaggelos",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.05376"" target=""_blank"">2204.05376</a>","<a href=""https://github.com/avdravid/medXGAN_explanations"" target=""_blank"">avdravid</a>",2025-12-03 22:39:25
"Transformer-Based Language Models for Software Vulnerability Detection: Performance, Model's Security and Platforms","Chandra Thapa, Seung Ick Jang, Muhammad Ejaz Ahmed, Seyit Camtepe, Josef Pieprzyk, Surya Nepal",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.03214"" target=""_blank"">2204.03214</a>",,2025-12-03 22:39:25
Adversarial Robustness through the Lens of Convolutional Filters,"Paul Gavrikov, Janis Keuper",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.02481"" target=""_blank"">2204.02481</a>","<a href=""https://github.com/paulgavrikov/cvpr22w_RobustnessThroughTheLens"" target=""_blank"">paulgavrikov</a>",2025-12-03 22:39:25
Sampling-based Fast Gradient Rescaling Method for Highly Transferable Adversarial Attacks,"Xu Han, Anmin Liu, Yifeng Xiong, Yanbo Fan, Kun He",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.02887"" target=""_blank"">2204.02887</a>",,2025-12-03 22:39:25
Adversarially robust segmentation models learn perceptually-aligned gradients,Pedro Sandoval-Segura,arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.01099"" target=""_blank"">2204.01099</a>",,2025-12-03 22:39:25
A Novel Approach to Train Diverse Types of Language Models for Health Mention Classification of Tweets,"Pervaiz Iqbal Khan, Imran Razzak, Andreas Dengel, Sheraz Ahmed",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.06337"" target=""_blank"">2204.06337</a>",,2025-12-03 22:39:25
A Fast and Efficient Conditional Learning for Tunable Trade-Off between Accuracy and Robustness,"Souvik Kundu, Sairam Sundaresan, Massoud Pedram, Peter A. Beerel",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.00426"" target=""_blank"">2204.00426</a>",,2025-12-03 22:39:25
Investigating Top-$k$ White-Box and Transferable Black-box Attack,"Chaoning Zhang, Philipp Benz, Adil Karjauv, Jae Won Cho, Kang Zhang, In So Kweon",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.00089"" target=""_blank"">2204.00089</a>",,2025-12-03 22:39:25
Truth Serum: Poisoning Machine Learning Models to Reveal Their Secrets,"Florian Tramèr, Reza Shokri, Ayrton San Joaquin, Hoang Le, Matthew Jagielski, Sanghyun Hong, Nicholas Carlini",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.00032"" target=""_blank"">2204.00032</a>",,2025-12-03 22:39:25
Scalable Whitebox Attacks on Tree-based Models,"Giuseppe Castiglione, Gavin Ding, Masoud Hashemi, Christopher Srinivasa, Ga Wu",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.00103"" target=""_blank"">2204.00103</a>",,2025-12-03 22:39:25
Improving Adversarial Transferability via Neuron Attribution-Based Attacks,"Jianping Zhang, Weibin Wu, Jen-tse Huang, Yizhan Huang, Wenxuan Wang, Yuxin Su, Michael R. Lyu",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.00008"" target=""_blank"">2204.00008</a>",,2025-12-03 22:39:25
FedRecAttack: Model Poisoning Attack to Federated Recommendation,"Dazhong Rong, Shuai Ye, Ruoyan Zhao, Hon Ning Yuen, Jianhai Chen, Qinming He",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.01499"" target=""_blank"">2204.01499</a>",,2025-12-03 22:39:25
Preventing Distillation-based Attacks on Neural Network IP,"Mahdieh Grailoo, Zain Ul Abideen, Mairo Leier, Samuel Pagliarini",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.00292"" target=""_blank"">2204.00292</a>",,2025-12-03 22:39:25
FrequencyLowCut Pooling -- Plug & Play against Catastrophic Overfitting,"Julia Grabinski, Steffen Jung, Janis Keuper, Margret Keuper",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.00491"" target=""_blank"">2204.00491</a>",,2025-12-03 22:39:25
Robust and Accurate -- Compositional Architectures for Randomized Smoothing,"Miklós Z. Horváth, Mark Niklas Müller, Marc Fischer, Martin Vechev",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.00487"" target=""_blank"">2204.00487</a>","<a href=""https://github.com/eth-sri/aces"" target=""_blank"">eth-sri</a>",2025-12-03 22:39:25
SkeleVision: Towards Adversarial Resiliency of Person Tracking with Multi-Task Learning,"Nilaksh Das, Sheng-Yun Peng, Duen Horng Chau",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.00734"" target=""_blank"">2204.00734</a>",,2025-12-03 22:39:25
Adversarial Neon Beam: Robust Physical-World Adversarial Attack to DNNs,"Chengyin Hu, Kalibinuer Tiliwalidi",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.00853"" target=""_blank"">2204.00853</a>",,2025-12-03 22:39:25
DST: Dynamic Substitute Training for Data-free Black-box Attack,"Wenxuan Wang, Xuelin Qian, Yanwei Fu, Xiangyang Xue",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.00972"" target=""_blank"">2204.00972</a>",,2025-12-03 22:39:25
Detecting In-vehicle Intrusion via Semi-supervised Learning-based Convolutional Adversarial Autoencoders,"Thien-Nu Hoang, Daehee Kim",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.01193"" target=""_blank"">2204.01193</a>",,2025-12-03 22:39:25
Breaking the De-Pois Poisoning Defense,"Alaa Anani, Mohamed Ghanem, Lotfy Abdel Khaliq",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.01090"" target=""_blank"">2204.01090</a>",,2025-12-03 22:39:25
Masking Adversarial Damage: Finding Adversarial Saliency for Robust and Sparse Network,"Byung-Kwan Lee, Junho Kim, Yong Man Ro",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.02738"" target=""_blank"">2204.02738</a>",,2025-12-03 22:39:25
FaceSigns: Semi-Fragile Neural Watermarks for Media Authentication and Countering Deepfakes,"Paarth Neekhara, Shehzeen Hussain, Xinqiao Zhang, Ke Huang, Julian McAuley, Farinaz Koushanfar",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.01960"" target=""_blank"">2204.01960</a>",,2025-12-03 22:39:25
PRADA: Practical Black-Box Adversarial Attacks against Neural Ranking Models,"Chen Wu, Ruqing Zhang, Jiafeng Guo, Rijke Maarten de, Yixing Fan, Xueqi Cheng",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.01321"" target=""_blank"">2204.01321</a>",,2025-12-03 22:39:25
Experimental quantum adversarial learning with programmable superconducting qubits,"Wenhui Ren, Weikang Li, Shibo Xu, Ke Wang, Wenjie Jiang, Feitong Jin, Xuhao Zhu, Jiachen Chen, Zixuan Song, Pengfei Zhang, Hang Dong, Xu Zhang, Jinfeng Deng, Yu Gao, Chuanyu Zhang, Yaozu Wu, Bing Zhang, Qiujiang Guo, Hekang Li, Zhen Wang, Jacob Biamonte, Chao Song, Dong-Ling Deng, H. Wang",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.01738"" target=""_blank"">2204.01738</a>",,2025-12-03 22:39:25
SecureSense: Defending Adversarial Attack for Secure Device-Free Human Activity Recognition,"Jianfei Yang, Han Zou, Lihua Xie",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.01560"" target=""_blank"">2204.01560</a>",,2025-12-03 22:39:25
DAD: Data-free Adversarial Defense at Test Time,"Gaurav Kumar Nayak, Ruchit Rawal, Anirban Chakraborty",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.01568"" target=""_blank"">2204.01568</a>",,2025-12-03 22:39:25
GAIL-PT: A Generic Intelligent Penetration Testing Framework with Generative Adversarial Imitation Learning,"Jinyin Chen, Shulong Hu, Haibin Zheng, Changyou Xing, Guomin Zhang",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.01975"" target=""_blank"">2204.01975</a>",,2025-12-03 22:39:25
SwapMix: Diagnosing and Regularizing the Over-Reliance on Visual Context in Visual Question Answering,"Vipul Gupta, Zhuowan Li, Adam Kortylewski, Chenyu Zhang, Yingwei Li, Alan Yuille",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.02285"" target=""_blank"">2204.02285</a>","<a href=""https://github.com/vipulgupta1011/swapmix"" target=""_blank"">vipulgupta1011</a>",2025-12-03 22:39:25
User-Level Differential Privacy against Attribute Inference Attack of Speech Emotion Recognition in Federated Learning,"Tiantian Feng, Raghuveer Peri, Shrikanth Narayanan",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.02500"" target=""_blank"">2204.02500</a>","<a href=""https://github.com/usc-sail/fed-ser-leakage"" target=""_blank"">usc-sail</a>",2025-12-03 22:39:25
Hear No Evil: Towards Adversarial Robustness of Automatic Speech Recognition via Multi-Task Learning,"Nilaksh Das, Duen Horng Chau",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.02381"" target=""_blank"">2204.02381</a>",,2025-12-03 22:39:25
Control Barrier Function based Attack-Recovery with Provable Guarantees,"Kunal Garg, Ricardo G. Sanfelice, Alvaro A. Cardenas",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.03077"" target=""_blank"">2204.03077</a>",,2025-12-03 22:39:25
Adversarial Analysis of the Differentially-Private Federated Learning in Cyber-Physical Critical Infrastructures,"Md Tamjid Jim Hossain, Shahriar Jim Badsha, Jim Hung, La, Haoting Shen, Shafkat Islam, Ibrahim Khalil, Xun Yi",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.02654"" target=""_blank"">2204.02654</a>",,2025-12-03 22:39:25
Adversarial Machine Learning Attacks Against Video Anomaly Detection Systems,"Furkan Mumcu, Keval Doshi, Yasin Yilmaz",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.03141"" target=""_blank"">2204.03141</a>",,2025-12-03 22:39:25
Optimization Models and Interpretations for Three Types of Adversarial Perturbations against Support Vector Machines,"Wen Su, Qingna Li, Chunfeng Cui",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.03154"" target=""_blank"">2204.03154</a>",,2025-12-03 22:39:25
Distilling Robust and Non-Robust Features in Adversarial Examples by Information Bottleneck,"Junho Kim, Byung-Kwan Lee, Yong Man Ro",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.02735"" target=""_blank"">2204.02735</a>",,2025-12-03 22:39:25
Improving Vision Transformers by Revisiting High-frequency Components,"Jiawang Bai, Li Yuan, Shu-Tao Xia, Shuicheng Yan, Zhifeng Li, Wei Liu",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.00993"" target=""_blank"">2204.00993</a>","<a href=""https://github.com/jiawangbai/HAT"" target=""_blank"">jiawangbai</a>",2025-12-03 22:39:25
Stealing and Evading Malware Classifiers and Antivirus at Low False Positive Conditions,"Maria Rigaki, Sebastian Garcia",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.06241"" target=""_blank"">2204.06241</a>",,2025-12-03 22:39:25
Defensive Patches for Robust Recognition in the Physical World,"Jiakai Wang, Zixin Yin, Pengfei Hu, Aishan Liu, Renshuai Tao, Haotong Qin, Xianglong Liu, Dacheng Tao",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.06213"" target=""_blank"">2204.06213</a>","<a href=""https://github.com/nlsde-safety-team/DefensivePatch"" target=""_blank"">nlsde-safety-team</a>",2025-12-03 22:39:25
Can Rationalization Improve Robustness? (12%),"Howard Chen, Jacqueline He, Karthik Narasimhan, Danqi Chen",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.11790"" target=""_blank"">2204.11790</a>",,2025-12-03 22:39:25
Enhancing Privacy against Inversion Attacks in Federated Learning by using Mixing Gradients Strategies,"Shaltiel Eloul, Fran Silavong, Sanket Kamthe, Antonios Georgiadis, Sean J. Moran",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.12495"" target=""_blank"">2204.12495</a>",,2025-12-03 22:39:25
Performance Analysis of Out-of-Distribution Detection on Trained Neural Networks,"Jens Henriksson, Christian Berger, Markus Borg, Lars Tornberg, Sankar Raman Sathyamoorthy, Cristofer Englund",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.12378"" target=""_blank"">2204.12378</a>",,2025-12-03 22:39:25
Self-recoverable Adversarial Examples: A New Effective Protection Mechanism in Social Networks,"Jiawei Zhang, Jinwei Wang, Hao Wang, Xiangyang Luo",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.12050"" target=""_blank"">2204.12050</a>",,2025-12-03 22:39:25
When adversarial examples are excusable,"Pieter-Jan Kindermans, Charles Staats",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.11985"" target=""_blank"">2204.11985</a>",,2025-12-03 22:39:25
A Simple Structure For Building A Robust Model,"Xiao Tan, JingBo Gao, Ruolin Li",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.11596"" target=""_blank"">2204.11596</a>","<a href=""https://github.com/dowdyboy/simple_structure_for_robust_model"" target=""_blank"">dowdyboy</a>",2025-12-03 22:39:25
Real or Virtual: A Video Conferencing Background Manipulation-Detection System,"Ehsan Nowroozi, Yassine Mekdad, Mauro Conti, Simone Milani, Selcuk Uluagac, Berrin Yanikoglu",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.11853"" target=""_blank"">2204.11853</a>",,2025-12-03 22:39:25
PhysioGAN: Training High Fidelity Generative Model for Physiological Sensor Readings,"Moustafa Alzantot, Luis Garcia, Mani Srivastava",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.13597"" target=""_blank"">2204.13597</a>",,2025-12-03 22:39:25
A Tale of Two Models: Constructing Evasive Attacks on Edge Models,"Wei Hao, Aahil Awatramani, Jiayang Hu, Chengzhi Mao, Pin-Chun Chen, Eyal Cidon, Asaf Cidon, Junfeng Yang",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.10933"" target=""_blank"">2204.10933</a>",,2025-12-03 22:39:25
VITA: A Multi-Source Vicinal Transfer Augmentation Method for Out-of-Distribution Generalization,"Minghui Chen, Cheng Wen, Feng Zheng, Fengxiang He, Ling Shao",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.11531"" target=""_blank"">2204.11531</a>",,2025-12-03 22:39:25
"Enable Deep Learning on Mobile Devices: Methods, Systems, and Applications","Han Cai, Ji Lin, Yujun Lin, Zhijian Liu, Haotian Tang, Hanrui Wang, Ligeng Zhu, Song Han",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.11786"" target=""_blank"">2204.11786</a>",,2025-12-03 22:39:25
Improving Deep Learning Model Robustness Against Adversarial Attack by Increasing the Network Capacity,"Marco Marchetti, Edmond S. L. Ho",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.11357"" target=""_blank"">2204.11357</a>",,2025-12-03 22:39:25
Smart App Attack: Hacking Deep Learning Models in Android Apps,"Yujin Huang, Chunyang Chen",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.11075"" target=""_blank"">2204.11075</a>","<a href=""https://github.com/Jinxhy/SmartAppAttack"" target=""_blank"">Jinxhy</a>",2025-12-03 22:39:25
Towards Data-Free Model Stealing in a Hard Label Setting,"Sunandini Sanyal, Sravanti Addepalli, R. Venkatesh Babu",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.11022"" target=""_blank"">2204.11022</a>",,2025-12-03 22:39:25
Reinforced Causal Explainer for Graph Neural Networks,"Xiang Wang, Yingxin Wu, An Zhang, Fuli Feng, Xiangnan He, Tat-Seng Chua",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.11028"" target=""_blank"">2204.11028</a>","<a href=""https://github.com/xiangwang1223/reinforced_causal_explainer"" target=""_blank"">xiangwang1223</a>",2025-12-03 22:39:25
Designing Perceptual Puzzles by Differentiating Probabilistic Programs,"Kartik Chandra, Tzu-Mao Li, Joshua Tenenbaum, Jonathan Ragan-Kelley",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.12301"" target=""_blank"">2204.12301</a>",,2025-12-03 22:39:25
Poisoning Deep Learning based Recommender Model in Federated Learning Scenarios,"Dazhong Rong, Qinming He, Jianhai Chen",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.13594"" target=""_blank"">2204.13594</a>",,2025-12-03 22:39:25
Mixed Strategies for Security Games with General Defending Requirements,"Rufan Bai, Haoxing Lin, Xinyu Yang, Xiaowei Wu, Minming Li, Weijia Jia",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.12158"" target=""_blank"">2204.12158</a>",,2025-12-03 22:39:25
On Fragile Features and Batch Normalization in Adversarial Training,"Nils Philipp Walter, David Stutz, Bernt Schiele",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.12393"" target=""_blank"">2204.12393</a>",,2025-12-03 22:39:25
Improving the Transferability of Adversarial Examples with Restructure Embedded Patches,"Huipeng Zhou, Yu-an Tan, Yajie Wang, Haoran Lyu, Shangbo Wu, Yuanzhang Li",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.12680"" target=""_blank"">2204.12680</a>",,2025-12-03 22:39:25
Boosting Adversarial Transferability of MLP-Mixer,"Haoran Lyu, Yajie Wang, Yu-an Tan, Huipeng Zhou, Yuhang Zhao, Quanxin Zhang",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.12204"" target=""_blank"">2204.12204</a>",,2025-12-03 22:39:25
An Adversarial Attack Analysis on Malicious Advertisement URL Detection Framework,"Ehsan Nowroozi, Abhishek, Mohammadreza Mohammadi, Mauro Conti",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.13172"" target=""_blank"">2204.13172</a>",,2025-12-03 22:39:25
Defending Against Person Hiding Adversarial Patch Attack with a Universal White Frame,"Youngjoon Yu, Hong Joo Lee, Hakmin Lee, Yong Man Ro",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.13004"" target=""_blank"">2204.13004</a>",,2025-12-03 22:39:25
Adversarial Fine-tune with Dynamically Regulated Adversary,"Pengyue Hou, Ming Zhou, Jie Han, Petr Musilek, Xingyu Li",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.13232"" target=""_blank"">2204.13232</a>",,2025-12-03 22:39:25
An Online Ensemble Learning Model for Detecting Attacks in Wireless Sensor Networks,"Hiba Tabbaa, Samir Ifzarne, Imad Hafidi",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.13814"" target=""_blank"">2204.13814</a>",,2025-12-03 22:39:25
AGIC: Approximate Gradient Inversion Attack on Federated Learning,"Jin Xu, Chi Hong, Jiyue Huang, Lydia Y. Chen, Jérémie Decouchant",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.13784"" target=""_blank"">2204.13784</a>",,2025-12-03 22:39:25
Mixup-based Deep Metric Learning Approaches for Incomplete Supervision,"Luiz H. Buris, Daniel C. G. Pedronette, Joao P. Papa, Jurandy Almeida, Gustavo Carneiro, Fabio A. Faria",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.13572"" target=""_blank"">2204.13572</a>",,2025-12-03 22:39:25
Improving robustness of language models from a geometry-aware perspective,"Bin Zhu, Zhaoquan Gu, Le Wang, Jinyin Chen, Qi Xuan",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.13309"" target=""_blank"">2204.13309</a>",,2025-12-03 22:39:25
Randomized Smoothing under Attack: How Good is it in Pratice? (84%),"Thibault Maho, Teddy Furon, Erwan Le Merrer",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.14187"" target=""_blank"">2204.14187</a>",,2025-12-03 22:39:25
Formulating Robustness Against Unforeseen Attacks,"Sihui Dai, Saeed Mahloujifar, Prateek Mittal",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.13779"" target=""_blank"">2204.13779</a>","<a href=""https://github.com/inspire-group/variation-regularization"" target=""_blank"">inspire-group</a>",2025-12-03 22:39:25
Task-Driven Data Augmentation for Vision-Based Robotic Control,"Shubhankar Agarwal, Sandeep P. Chinchali",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.06173"" target=""_blank"">2204.06173</a>",,2025-12-03 22:39:25
Detecting Textual Adversarial Examples Based on Distributional Characteristics of Data Representations,"Na Liu, Mark Dras, Wei Emma Zhang",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.13853"" target=""_blank"">2204.13853</a>",,2025-12-03 22:39:25
How Sampling Impacts the Robustness of Stochastic Neural Networks,"Sina Däubener, Asja Fischer",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.10839"" target=""_blank"">2204.10839</a>",,2025-12-03 22:39:25
Restricted Black-box Adversarial Attack Against DeepFake Face Swapping,"Junhao Dong, Yuan Wang, Jianhuang Lai, Xiaohua Xie",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.12347"" target=""_blank"">2204.12347</a>",,2025-12-03 22:39:25
Enhancing the Transferability via Feature-Momentum Adversarial Attack,"Xianglong, Yuezun Li, Haipeng Qu, Junyu Dong",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.10606"" target=""_blank"">2204.10606</a>",,2025-12-03 22:39:25
Sardino: Ultra-Fast Dynamic Ensemble for Secure Visual Sensing at Mobile Edge,"Qun Song, Zhenyu Yan, Wenjie Luo, Rui Tan",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.08189"" target=""_blank"">2204.08189</a>",,2025-12-03 22:39:25
Robotic and Generative Adversarial Attacks in Offline Writer-independent Signature Verification,Jordan J. Bird,arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.07246"" target=""_blank"">2204.07246</a>",,2025-12-03 22:39:25
Q-TART: Quickly Training for Adversarial Robustness and in-Transferability,"Madan Ravi Ganesh, Salimeh Yasaei Sekeh, Jason J. Corso",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.07024"" target=""_blank"">2204.07024</a>",,2025-12-03 22:39:25
Data-Efficient Backdoor Attacks,"Pengfei Xia, Ziqiang Li, Wei Zhang, Bin Li",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.12281"" target=""_blank"">2204.12281</a>","<a href=""https://github.com/xpf/Data-Efficient-Backdoor-Attacks"" target=""_blank"">xpf</a>",2025-12-03 22:39:25
Planting Undetectable Backdoors in Machine Learning Models,"Shafi Goldwasser, Michael P. Kim, Vinod Vaikuntanathan, Or Zamir",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.06974"" target=""_blank"">2204.06974</a>",,2025-12-03 22:39:25
From Environmental Sound Representation to Robustness of 2D CNN Models Against Adversarial Attacks,"Mohammad Esmaeilpour, Patrick Cardinal, Alessandro Lameiras Koerich",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.07018"" target=""_blank"">2204.07018</a>",,2025-12-03 22:39:25
Revisiting the Adversarial Robustness-Accuracy Tradeoff in Robot Learning,"Mathias Lechner, Alexander Amini, Daniela Rus, Thomas A. Henzinger",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.07373"" target=""_blank"">2204.07373</a>",,2025-12-03 22:39:25
Homomorphic Encryption and Federated Learning based Privacy-Preserving CNN Training: COVID-19 Detection Use-Case,"Febrianti Wibawa, Ferhat Ozgur Catak, Salih Sarp, Murat Kuzlu, Umit Cali",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.07752"" target=""_blank"">2204.07752</a>",,2025-12-03 22:39:25
Towards Comprehensive Testing on the Robustness of Cooperative Multi-agent Reinforcement Learning,"Jun Guo, Yonghong Chen, Yihang Hao, Zixin Yin, Yin Yu, Simin Li",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.07932"" target=""_blank"">2204.07932</a>",,2025-12-03 22:39:25
Residue-Based Natural Language Adversarial Attack Detection,"Vyas Raina, Mark Gales",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.10192"" target=""_blank"">2204.10192</a>",,2025-12-03 22:39:25
Poisons that are learned faster are more effective,"Pedro Sandoval-Segura, Vasu Singla, Liam Fowl, Jonas Geiping, Micah Goldblum, David Jacobs, Tom Goldstein",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.08615"" target=""_blank"">2204.08615</a>",,2025-12-03 22:39:25
CorrGAN: Input Transformation Technique Against Natural Corruptions,"Mirazul Haque, Christof J. Budnik, Wei Yang",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.08623"" target=""_blank"">2204.08623</a>",,2025-12-03 22:39:25
"A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability","Enyan Dai, Tianxiang Zhao, Huaisheng Zhu, Junjie Xu, Zhimeng Guo, Hui Liu, Jiliang Tang, Suhang Wang",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.08570"" target=""_blank"">2204.08570</a>",,2025-12-03 22:39:25
Metamorphic Testing-based Adversarial Attack to Fool Deepfake Detectors,"Nyee Thoang Lim, Meng Yi Kuan, Muxin Pu, Mei Kuan Lim, Chun Yong Chong",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.08612"" target=""_blank"">2204.08612</a>",,2025-12-03 22:39:25
CgAT: Center-Guided Adversarial Training for Deep Hashing-Based Retrieval,"Xunguang Wang, Yiqun Lin, Xiaomeng Li",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.10779"" target=""_blank"">2204.10779</a>","<a href=""https://github.com/xunguangwang/CgAT"" target=""_blank"">xunguangwang</a>",2025-12-03 22:39:25
SETTI: A Self-supervised Adversarial Malware Detection Architecture in an IoT Environment,"Marjan Golmaryami, Rahim Taheri, Zahra Pooranian, Mohammad Shojafar, Pei Xiao",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.07772"" target=""_blank"">2204.07772</a>",,2025-12-03 22:39:25
UNBUS: Uncertainty-aware Deep Botnet Detection System in Presence of Perturbed Samples,Rahim Taheri,arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.09502"" target=""_blank"">2204.09502</a>",,2025-12-03 22:39:25
GUARD: Graph Universal Adversarial Defense,"Jintang Li, Jie Liao, Ruofan Wu, Liang Chen, Zibin Zheng, Jiawang Dan, Changhua Meng, Weiqiang Wang",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.09803"" target=""_blank"">2204.09803</a>",,2025-12-03 22:39:25
A Mask-Based Adversarial Defense Scheme,"Weizhen Xu, Chenyi Zhang, Fangzhen Zhao, Liangda Fang",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.11837"" target=""_blank"">2204.11837</a>",,2025-12-03 22:39:25
Testing robustness of predictions of trained classifiers against naturally occurring perturbations,"Sebastian Scher, Andreas Trügler",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.10046"" target=""_blank"">2204.10046</a>",,2025-12-03 22:39:25
Generating Authentic Adversarial Examples beyond Meaning-preserving with Doubly Round-trip Translation,"Siyu Lai, Zhen Yang, Fandong Meng, Xue Zhang, Yufeng Chen, Jinan Xu, Jie Zhou",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.08689"" target=""_blank"">2204.08689</a>",,2025-12-03 22:39:25
Adversarial Contrastive Learning by Permuting Cluster Assignments,"Muntasir Wahed, Afrina Tabassum, Ismini Lourentzou",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.10314"" target=""_blank"">2204.10314</a>",,2025-12-03 22:39:25
Eliminating Backdoor Triggers for Deep Neural Networks Using Attention Relation Graph Distillation,"Jun Xia, Ting Wang, Jiepin Ding, Xian Wei, Mingsong Chen",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.09975"" target=""_blank"">2204.09975</a>",,2025-12-03 22:39:25
Adversarial Scratches: Deployable Attacks to CNN Classifiers,"Loris Giulivi, Malhar Jere, Loris Rossi, Farinaz Koushanfar, Gabriela Ciocarlie, Briland Hitaj, Giacomo Boracchi",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.09397"" target=""_blank"">2204.09397</a>",,2025-12-03 22:39:25
Detecting Topology Attacks against Graph Neural Networks,"Senrong Xu, Yuan Yao, Liangyue Li, Wei Yang, Feng Xu, Hanghang Tong",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.10072"" target=""_blank"">2204.10072</a>",,2025-12-03 22:39:25
Fast AdvProp,"Jieru Mei, Yucheng Han, Yutong Bai, Yixiao Zhang, Yingwei Li, Xianhang Li, Alan Yuille, Cihang Xie",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.09838"" target=""_blank"">2204.09838</a>","<a href=""https://github.com/meijieru/fast_advprop"" target=""_blank"">meijieru</a>",2025-12-03 22:39:25
Case-Aware Adversarial Training,"Mingyuan Fan, Yang Liu, Wenzhong Guo, Ximeng Liu, Jianhua Li",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.09398"" target=""_blank"">2204.09398</a>",,2025-12-03 22:39:25
Improved Worst-Group Robustness via Classifier Retraining on Independent Splits,"Thien Hang Nguyen, Hongyang R. Zhang, Huy Le Nguyen",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.09583"" target=""_blank"">2204.09583</a>",,2025-12-03 22:39:25
Jacobian Ensembles Improve Robustness Trade-offs to Adversarial Attacks,"Kenneth T. Co, David Martinez-Rego, Zhongyuan Hau, Emil C. Lupu",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.08726"" target=""_blank"">2204.08726</a>",,2025-12-03 22:39:25
Robustness Testing of Data and Knowledge Driven Anomaly Detection in Cyber-Physical Systems,"Xugui Zhou, Maxfield Kouzel, Homa Alemzadeh",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.09183"" target=""_blank"">2204.09183</a>",,2025-12-03 22:39:25
Is Neuron Coverage Needed to Make Person Detection More Robust? (98%),"Svetlana Pavlitskaya, Şiyar Yıkmış, J. Marius Zöllner",arXiv,2022-04,"<a href=""http://arxiv.org/abs/2204.10027"" target=""_blank"">2204.10027</a>",,2025-12-03 22:39:25
Enhancing Adversarial Training with Second-Order Statistics of Weights,"Gaojie Jin, Xinping Yi, Wei Huang, Sven Schewe, Xiaowei Huang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.06020"" target=""_blank"">2203.06020</a>","<a href=""https://github.com/Alexkael/S2O"" target=""_blank"">Alexkael</a>",2025-12-03 22:39:25
ROOD-MRI: Benchmarking the robustness of deep learning segmentation models to out-of-distribution and corrupted data in MRI,"Lyndon Boone, Mahdi Biparva, Parisa Mojiri Forooshani, Joel Ramirez, Mario Masellis, Robert Bartha, Sean Symons, Stephen Strother, Sandra E. Black, Chris Heyn, Anne L. Martel, Richard H. Swartz, Maged Goubran",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.06060"" target=""_blank"">2203.06060</a>",,2025-12-03 22:39:25
Attacks as Defenses: Designing Robust Audio CAPTCHAs Using Attacks on Automatic Speech Recognition Systems,"Hadi Abdullah, Aditya Karlekar, Saurabh Prasad, Muhammad Sajidur Rahman, Logan Blue, Luke A. Bauer, Vincent Bindschaedler, Patrick Traynor",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.05408"" target=""_blank"">2203.05408</a>",,2025-12-03 22:39:25
Perception Over Time: Temporal Dynamics for Robust Image Understanding,"Maryam Daniali, Edward Kim",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.06254"" target=""_blank"">2203.06254</a>",,2025-12-03 22:39:25
Reinforcement Learning for Linear Quadratic Control is Vulnerable Under Cost Manipulation,"Yunhan Huang, Quanyan Zhu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.05774"" target=""_blank"">2203.05774</a>",,2025-12-03 22:39:25
Exploiting the Potential of Datasets: A Data-Centric Approach for Model Robustness,"Yiqi Zhong, Lei Wu, Xianming Liu, Junjun Jiang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.05323"" target=""_blank"">2203.05323</a>","<a href=""https://github.com/hncszyq/tianchi_challenge"" target=""_blank"">hncszyq</a>",2025-12-03 22:39:25
Membership Privacy Protection for Image Translation Models via Adversarial Knowledge Distillation,"Saeed Ranjbar Alvar, Lanjun Wang, Jian Pei, Yong Zhang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.05212"" target=""_blank"">2203.05212</a>",,2025-12-03 22:39:25
An integrated Auto Encoder-Block Switching defense approach to prevent adversarial attacks,"Anirudh Yadav, Ashutosh Upadhyay, S. Sharanya",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.10930"" target=""_blank"">2203.10930</a>",,2025-12-03 22:39:25
Attack Analysis of Face Recognition Authentication Systems Using Fast Gradient Sign Method,"Arbena Musa, Kamer Vishi, Blerim Rexha",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.05653"" target=""_blank"">2203.05653</a>",,2025-12-03 22:39:25
Controllable Evaluation and Generation of Physical Adversarial Patch on Face Recognition,"Xiao Yang, Yinpeng Dong, Tianyu Pang, Zihao Xiao, Hang Su, Jun Zhu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.04623"" target=""_blank"">2203.04623</a>",,2025-12-03 22:39:25
SoK: On the Semantic AI Security in Autonomous Driving,"Junjie Shen, Ningfei Wang, Ziwen Wan, Yunpeng Luo, Takami Sato, Zhisheng Hu, Xinyang Zhang, Shengjian Guo, Zhenyu Zhong, Kang Li, Ziming Zhao, Chunming Qiao, Qi Alfred Chen",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.05314"" target=""_blank"">2203.05314</a>",,2025-12-03 22:39:25
Practical Evaluation of Adversarial Robustness via Adaptive Auto Attack,"Ye Liu, Yaya Cheng, Lianli Gao, Xianglong Liu, Qilong Zhang, Jingkuan Song",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.05154"" target=""_blank"">2203.05154</a>","<a href=""https://github.com/liuye6666/adaptive_auto_attack"" target=""_blank"">liuye6666</a>",2025-12-03 22:39:25
Frequency-driven Imperceptible Adversarial Attack on Semantic Similarity,"Cheng Luo, Qinliang Lin, Weicheng Xie, Bizhu Wu, Jinheng Xie, Linlin Shen",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.05151"" target=""_blank"">2203.05151</a>",,2025-12-03 22:39:25
Binary Classification Under $\ell_0$ Attacks for General Noise Distribution,"Payam Delgosha, Hamed Hassani, Ramtin Pedarsani",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.04855"" target=""_blank"">2203.04855</a>",,2025-12-03 22:39:25
Reverse Engineering $\ell_p$ attacks: A block-sparse optimization approach with recovery guarantees,"Darshan Thaker, Paris Giampouras, René Vidal",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.04886"" target=""_blank"">2203.04886</a>",,2025-12-03 22:39:25
Defending Black-box Skeleton-based Human Activity Classifiers,"He Wang, Yunfeng Diao, Zichang Tan, Guodong Guo",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.04713"" target=""_blank"">2203.04713</a>","<a href=""https://github.com/realcrane/RobustActionRecogniser"" target=""_blank"">realcrane</a>",2025-12-03 22:39:25
Robust Federated Learning Against Adversarial Attacks for Speech Emotion Recognition,"Yi Chang, Sofiane Laridi, Zhao Ren, Gregory Palmer, Björn W. Schuller, Marco Fisichella",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.04696"" target=""_blank"">2203.04696</a>",,2025-12-03 22:39:25
Improving Neural ODEs via Knowledge Distillation,"Haoyu Chu, Shikui Wei, Qiming Lu, Yao Zhao",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.05103"" target=""_blank"">2203.05103</a>",,2025-12-03 22:39:25
Block-Sparse Adversarial Attack to Fool Transformer-Based Text Classifiers,"Sahar Sadrizadeh, Ljiljana Dolamic, Pascal Frossard",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.05948"" target=""_blank"">2203.05948</a>",,2025-12-03 22:39:25
Physics-aware Complex-valued Adversarial Machine Learning in Reconfigurable Diffractive All-optical Neural Network,"Ruiyang Chen, Yingjie Li, Minhan Lou, Jichao Fan, Yingheng Tang, Berardi Sensale-Rodriguez, Cunxi Yu, Weilu Gao",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.06055"" target=""_blank"">2203.06055</a>",,2025-12-03 22:39:25
Learning from Attacks: Attacking Variational Autoencoder for Improving Image Classification,"Jianzhang Zheng, Fan Yang, Hao Shen, Xuan Tang, Mingsong Chen, Liang Song, Xian Wei",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.07027"" target=""_blank"">2203.07027</a>",,2025-12-03 22:39:25
Task-Agnostic Robust Representation Learning,"A. Tuan Nguyen, Ser Nam Lim, Philip Torr",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.07596"" target=""_blank"">2203.07596</a>",,2025-12-03 22:39:25
Label-only Model Inversion Attack: The Attack that Requires the Least Information,"Dayong Ye, Tianqing Zhu, Shuai Zhou, Bo Liu, Wanlei Zhou",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.06555"" target=""_blank"">2203.06555</a>",,2025-12-03 22:39:25
Adversarial amplitude swap towards robust image classifiers,"Chun Yang Tan, Hiroshi Kera, Kazuhiko Kawamoto",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.07138"" target=""_blank"">2203.07138</a>",,2025-12-03 22:39:25
Adaptative Perturbation Patterns: Realistic Adversarial Learning for Robust NIDS,"João Vitorino, Nuno Oliveira, Isabel Praça",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.04234"" target=""_blank"">2203.04234</a>",,2025-12-03 22:39:25
"Internet-based Social Engineering Attacks, Defenses and Psychology: A Survey","Theodore Longtchi, Rosana Montañez Rodriguez, Laith Al-Shawaf, Adham Atyabi, Shouhuai Xu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08302"" target=""_blank"">2203.08302</a>",,2025-12-03 22:39:25
Towards Adversarial Control Loops in Sensor Attacks: A Case Study to Control the Kinematics and Actuation of Embedded Systems,"Yazhou Tu, Sara Rampazzi, Xiali Hei",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.07670"" target=""_blank"">2203.07670</a>",,2025-12-03 22:39:25
LDP: Learnable Dynamic Precision for Efficient Deep Neural Network Training and Inference,"Zhongzhi Yu, Yonggan Fu, Shang Wu, Mengquan Li, Haoran You, Yingyan Lin",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.07713"" target=""_blank"">2203.07713</a>",,2025-12-03 22:39:25
Adversarial Counterfactual Augmentation: Application in Alzheimer's Disease Classification,"Tian Xia, Pedro Sanchez, Chen Qin, Sotirios A. Tsaftaris",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.07815"" target=""_blank"">2203.07815</a>",,2025-12-03 22:39:25
Efficient universal shuffle attack for visual object tracking,"Siao Liu, Zhaoyu Chen, Wei Li, Jiwei Zhu, Jiafeng Wang, Wenqiang Zhang, Zhongxue Gan",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.06898"" target=""_blank"">2203.06898</a>",,2025-12-03 22:39:25
Defending Against Adversarial Attack in ECG Classification with Adversarial Distillation Training,"Jiahao Shao, Shijia Geng, Zhaoji Fu, Weilun Xu, Tong Liu, Shenda Hong",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.09487"" target=""_blank"">2203.09487</a>",,2025-12-03 22:39:25
Energy-Latency Attacks via Sponge Poisoning,"Antonio Emanuele Cinà, Ambra Demontis, Battista Biggio, Fabio Roli, Marcello Pelillo",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08147"" target=""_blank"">2203.08147</a>",,2025-12-03 22:39:25
On the benefits of knowledge distillation for adversarial robustness,"Javier Maroto, Guillermo Ortiz-Jiménez, Pascal Frossard",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.07159"" target=""_blank"">2203.07159</a>",,2025-12-03 22:39:25
A Survey of Adversarial Defences and Robustness in NLP,"Shreya Goyal, Sumanth Doddapaneni, Mitesh M. Khapra, Balaraman Ravindran",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.06414"" target=""_blank"">2203.06414</a>",,2025-12-03 22:39:25
RES-HD: Resilient Intelligent Fault Diagnosis Against Adversarial Attacks Using Hyper-Dimensional Computing,"Onat Gungor, Tajana Rosing, Baris Aksanli",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08148"" target=""_blank"">2203.08148</a>",,2025-12-03 22:39:25
Defending From Physically-Realizable Adversarial Attacks Through Internal Over-Activation Analysis,"Giulio Rossolini, Federico Nesti, Fabio Brau, Alessandro Biondi, Giorgio Buttazzo",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.07341"" target=""_blank"">2203.07341</a>",,2025-12-03 22:39:25
LAS-AT: Adversarial Training with Learnable Attack Strategy,"Xiaojun Jia, Yong Zhang, Baoyuan Wu, Ke Ma, Jue Wang, Xiaochun Cao",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.06616"" target=""_blank"">2203.06616</a>","<a href=""https://github.com/jiaxiaojunQAQ/LAS-AT"" target=""_blank"">jiaxiaojunQAQ</a>",2025-12-03 22:39:25
Generating Practical Adversarial Network Traffic Flows Using NIDSGAN,"Bolor-Erdene Zolbayar, Ryan Sheatsley, Patrick McDaniel, Michael J. Weisman, Sencun Zhu, Shitong Zhu, Srikanth Krishnamurthy",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.06694"" target=""_blank"">2203.06694</a>",,2025-12-03 22:39:25
Model Inversion Attack against Transfer Learning: Inverting a Model without Accessing It,"Dayong Ye, Huiqiang Chen, Shuai Zhou, Tianqing Zhu, Wanlei Zhou, Shouling Ji",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.06570"" target=""_blank"">2203.06570</a>",,2025-12-03 22:39:25
One Parameter Defense -- Defending against Data Inference Attacks via Differential Privacy,"Dayong Ye, Sheng Shen, Tianqing Zhu, Bo Liu, Wanlei Zhou",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.06580"" target=""_blank"">2203.06580</a>",,2025-12-03 22:39:25
Policy Learning for Robust Markov Decision Process with a Mismatched Generative Model,"Jialian Li, Tongzheng Ren, Dong Yan, Hang Su, Jun Zhu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.06587"" target=""_blank"">2203.06587</a>",,2025-12-03 22:39:25
Query-Efficient Black-box Adversarial Attacks Guided by a Transfer-based Prior,"Yinpeng Dong, Shuyu Cheng, Tianyu Pang, Hang Su, Jun Zhu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.06560"" target=""_blank"">2203.06560</a>",,2025-12-03 22:39:25
On the surprising tradeoff between ImageNet accuracy and perceptual similarity,"Manoj Kumar, Neil Houlsby, Nal Kalchbrenner, Ekin D. Cubuk",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.04946"" target=""_blank"">2203.04946</a>",,2025-12-03 22:39:25
Detecting Adversarial Perturbations in Multi-Task Perception,"Marvin Klingner, Varun Ravi Kumar, Senthil Yogamani, Andreas Bär, Tim Fingscheidt",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.01177"" target=""_blank"">2203.01177</a>","<a href=""https://github.com/ifnspaml/AdvAttackDet"" target=""_blank"">ifnspaml</a>",2025-12-03 22:39:25
Shape-invariant 3D Adversarial Point Clouds,"Qidong Huang, Xiaoyi Dong, Dongdong Chen, Hang Zhou, Weiming Zhang, Nenghai Yu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.04041"" target=""_blank"">2203.04041</a>","<a href=""https://github.com/shikiw/SI-Adv"" target=""_blank"">shikiw</a>",2025-12-03 22:39:25
Video is All You Need: Attacking PPG-based Biometric Authentication,"Lin Li, Chao Chen, Lei Pan, Jun Zhang, Yang Xiang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.00928"" target=""_blank"">2203.00928</a>",,2025-12-03 22:39:25
Fairness-aware Adversarial Perturbation Towards Bias Mitigation for Deployed Deep Models,"Zhibo Wang, Xiaowei Dong, Henry Xue, Zhifei Zhang, Weifeng Chiu, Tao Wei, Kui Ren",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.01584"" target=""_blank"">2203.01584</a>",,2025-12-03 22:39:25
Why adversarial training can hurt robust accuracy,"Jacob Clarysse, Julia Hörmann, Fanny Yang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.02006"" target=""_blank"">2203.02006</a>",,2025-12-03 22:39:25
Understanding Failure Modes of Self-Supervised Learning,"Neha Mukund Kalibhat, Kanika Narang, Liang Tan, Hamed Firooz, Maziar Sanjabi, Soheil Feizi",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.01881"" target=""_blank"">2203.01881</a>",,2025-12-03 22:39:25
Ensemble Methods for Robust Support Vector Machines using Integer Programming,Jannis Kurtz,arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.01606"" target=""_blank"">2203.01606</a>",,2025-12-03 22:39:25
Autonomous and Resilient Control for Optimal LEO Satellite Constellation Coverage Against Space Threats,"Yuhan Zhao, Quanyan Zhu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.02050"" target=""_blank"">2203.02050</a>",,2025-12-03 22:39:25
Enhancing Adversarial Robustness for Deep Metric Learning,"Mo Zhou, Vishal M. Patel",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.01439"" target=""_blank"">2203.01439</a>",,2025-12-03 22:39:25
Adversarial attacks on neural networks through canonical Riemannian foliations,"Eliot Tron, Nicolas Couellan, Stéphane Puechmorel",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.00922"" target=""_blank"">2203.00922</a>",,2025-12-03 22:39:25
Adversarial Robustness of Neural-Statistical Features in Detection of Generative Transformers,"Evan Crothers, Nathalie Japkowicz, Herna Viktor, Paula Branco",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.07983"" target=""_blank"">2203.07983</a>",,2025-12-03 22:39:25
MIAShield: Defending Membership Inference Attacks via Preemptive Exclusion of Members,"Ismat Jarin, Birhanu Eshete",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.00915"" target=""_blank"">2203.00915</a>",,2025-12-03 22:39:25
Improving Health Mentioning Classification of Tweets using Contrastive Adversarial Training,"Pervaiz Iqbal Khan, Shoaib Ahmed Siddiqui, Imran Razzak, Andreas Dengel, Sheraz Ahmed",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.01895"" target=""_blank"">2203.01895</a>",,2025-12-03 22:39:25
A Quantitative Geometric Approach to Neural-Network Smoothness,"Zi Wang, Gautam Prakriya, Somesh Jha",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.01212"" target=""_blank"">2203.01212</a>",,2025-12-03 22:39:25
Adversarial samples for deep monocular 6D object pose estimation,"Jinlai Zhang, Weiming Li, Shuang Liang, Hao Wang, Jihong Zhu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.00302"" target=""_blank"">2203.00302</a>","<a href=""https://github.com/cuge1995/U6DA"" target=""_blank"">cuge1995</a>",2025-12-03 22:39:25
Physical Backdoor Attacks to Lane Detection Systems in Autonomous Driving,"Xingshuo Han, Guowen Xu, Yuan Zhou, Xuehuan Yang, Jiwei Li, Tianwei Zhang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.00858"" target=""_blank"">2203.00858</a>",,2025-12-03 22:39:25
Global-Local Regularization Via Distributional Robustness,"Hoang Phan, Trung Le, Trung Phung, Tuan Anh Bui, Nhat Ho, Dinh Phung",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.00553"" target=""_blank"">2203.00553</a>",,2025-12-03 22:39:25
Benchmarking Robustness of Deep Learning Classifiers Using Two-Factor Perturbation,"Wei Dai, Daniel Berleant",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.01323"" target=""_blank"">2203.01323</a>",,2025-12-03 22:39:25
Signature Correction Attack on Dilithium Signature Scheme,"Saad Islam, Koksal Mus, Richa Singh, Patrick Schaumont, Berk Sunar",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.00637"" target=""_blank"">2203.00637</a>",,2025-12-03 22:39:25
Explaining RADAR features for detecting spoofing attacks in Connected Autonomous Vehicles,"Nidhi Rastogi, Sara Rampazzi, Michael Clifford, Miriam Heller, Matthew Bishop, Karl Levitt",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.00150"" target=""_blank"">2203.00150</a>",,2025-12-03 22:39:25
Understanding robustness and generalization of artificial neural networks through Fourier masks,"Nikos Karantzas, Emma Besier, Josue Ortega Caro, Xaq Pitkow, Andreas S. Tolias, Ankit B. Patel, Fabio Anselmi",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08822"" target=""_blank"">2203.08822</a>",,2025-12-03 22:39:25
Label-Only Model Inversion Attacks via Boundary Repulsion,"Mostafa Kahla, Si Chen, Hoang Anh Just, Ruoxi Jia",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.01925"" target=""_blank"">2203.01925</a>",,2025-12-03 22:39:25
Adversarial Patterns: Building Robust Android Malware Classifiers,"Dipkamal Bhusal, Nidhi Rastogi",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.02121"" target=""_blank"">2203.02121</a>",,2025-12-03 22:39:25
ART-Point: Improving Rotation Robustness of Point Cloud Classifiers via Adversarial Rotation,"Robin Wang, Yibo Yang, Dacheng Tao",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.03888"" target=""_blank"">2203.03888</a>",,2025-12-03 22:39:25
Defending Graph Convolutional Networks against Dynamic Graph Perturbations via Bayesian Self-supervision,"Jun Zhuang, Mohammad Al Hasan",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.03762"" target=""_blank"">2203.03762</a>",,2025-12-03 22:39:25
Robustly-reliable learners under poisoning attacks,"Maria-Florina Balcan, Avrim Blum, Steve Hanneke, Dravyansh Sharma",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.04160"" target=""_blank"">2203.04160</a>",,2025-12-03 22:39:25
DeepSE-WF: Unified Security Estimation for Website Fingerprinting Defenses,"Alexander Veicht, Cedric Renggli, Diogo Barradas",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.04428"" target=""_blank"">2203.04428</a>",,2025-12-03 22:39:25
Joint rotational invariance and adversarial training of a dual-stream Transformer yields state of the art Brain-Score for Area V4,"William Berrios, Arturo Deza",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.06649"" target=""_blank"">2203.06649</a>","<a href=""https://github.com/williamberrios/BrainScore-Transformers"" target=""_blank"">williamberrios</a>",2025-12-03 22:39:25
Harmonicity Plays a Critical Role in DNN Based Versus in Biologically-Inspired Monaural Speech Segregation Systems,"Rahil Institute for Systems Research, University of Maryland Parikh, Ilya Google Inc Kavalerov, Carol Institute for Systems Research, University of Maryland Espy-Wilson, Shihab Institute for Systems Research, University of Maryland Shamma",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.04420"" target=""_blank"">2203.04420</a>",,2025-12-03 22:39:25
ImageNet-Patch: A Dataset for Benchmarking Machine Learning Robustness against Adversarial Patches,"Maura Pintor, Daniele Angioni, Angelo Sotgiu, Luca Demetrio, Ambra Demontis, Battista Biggio, Fabio Roli",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.04412"" target=""_blank"">2203.04412</a>","<a href=""https://github.com/pralab/ImageNet-Patch"" target=""_blank"">pralab</a>",2025-12-03 22:39:25
Art-Attack: Black-Box Adversarial Attack via Evolutionary Art,"Phoenix Williams, Ke Li",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.04405"" target=""_blank"">2203.04405</a>",,2025-12-03 22:39:25
Shadows can be Dangerous: Stealthy and Effective Physical-world Adversarial Attack by Natural Phenomenon,"Yiqi Zhong, Xianming Liu, Deming Zhai, Junjun Jiang, Xiangyang Ji",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.03818"" target=""_blank"">2203.03818</a>",,2025-12-03 22:39:25
Adversarial Texture for Fooling Person Detectors in the Physical World,"Zhanhao Hu, Siyuan Huang, Xiaopei Zhu, Xiaolin Hu, Fuchun Sun, Bo Zhang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.03373"" target=""_blank"">2203.03373</a>",,2025-12-03 22:39:25
Towards Efficient Data-Centric Robust Machine Learning with Noise-based Augmentation,"Xiaogeng Liu, Haoyu Wang, Yechao Zhang, Fangzhou Wu, Shengshan Hu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.03810"" target=""_blank"">2203.03810</a>",,2025-12-03 22:39:25
Detection of Word Adversarial Examples in Text Classification: Benchmark and Baseline via Robust Density Estimation,"KiYoon Yoo, Jangho Kim, Jiho Jang, Nojun Kwak",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.01677"" target=""_blank"">2203.01677</a>","<a href=""https://github.com/anoymous92874838/text-adv-detection"" target=""_blank"">anoymous92874838</a>",2025-12-03 22:39:25
$A^{3}D$: A Platform of Searching for Robust Neural Architectures and Efficient Adversarial Attacks,"Jialiang Sun, Wen Yao, Tingsong Jiang, Chao Li, Xiaoqian Chen",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.03128"" target=""_blank"">2203.03128</a>",,2025-12-03 22:39:25
Protecting Facial Privacy: Generating Adversarial Identity Masks via Style-robust Makeup Transfer,"Shengshan Hu, Xiaogeng Liu, Yechao Zhang, Minghui Li, Leo Yu Zhang, Hai Jin, Libing Wu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.03121"" target=""_blank"">2203.03121</a>",,2025-12-03 22:39:25
Scalable Uncertainty Quantification for Deep Operator Networks using Randomized Priors,"Yibo Yang, Georgios Kissas, Paris Perdikaris",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.03048"" target=""_blank"">2203.03048</a>",,2025-12-03 22:39:25
Evaluation of Interpretability Methods and Perturbation Artifacts in Deep Neural Networks,"Lennart Brocki, Neo Christopher Chung",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.02928"" target=""_blank"">2203.02928</a>",,2025-12-03 22:39:25
aaeCAPTCHA: The Design and Implementation of Audio Adversarial CAPTCHA,"Md Imran Hossen, Xiali Hei",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.02735"" target=""_blank"">2203.02735</a>",,2025-12-03 22:39:25
Targeted Data Poisoning Attack on News Recommendation System by Content Perturbation,"Xudong Zhang, Zan Wang, Jingke Zhao, Lanjun Wang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.03560"" target=""_blank"">2203.03560</a>",,2025-12-03 22:39:25
Concept-based Explanations for Out-Of-Distribution Detectors,"Jihye Choi, Jayaram Raghuram, Ryan Feng, Jiefeng Chen, Somesh Jha, Atul Prakash",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.02586"" target=""_blank"">2203.02586</a>",,2025-12-03 22:39:25
Ad2Attack: Adaptive Adversarial Attack on Real-Time UAV Tracking,"Changhong Fu, Sihang Li, Xinnan Yuan, Junjie Ye, Ziang Cao, Fangqiang Ding",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.01516"" target=""_blank"">2203.01516</a>",,2025-12-03 22:39:25
Generalized but not Robust? Comparing the Effects of Data Modification Methods on Out-of-Domain Generalization and Adversarial Robustness,"Tejas Gokhale, Swaroop Mishra, Man Luo, Bhavdeep Singh Sachdeva, Chitta Baral",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.07653"" target=""_blank"">2203.07653</a>",,2025-12-03 22:39:25
Practical No-box Adversarial Attacks with Training-free Hybrid Image Transformation,"Qilong Zhang, Chaoning Zhang, Chaoqun Li, Jingkuan Song, Lianli Gao, Heng Tao Shen",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.04607"" target=""_blank"">2203.04607</a>",,2025-12-03 22:39:25
MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients,"Xiaoyu Cao, Neil Zhenqiang Gong",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08669"" target=""_blank"">2203.08669</a>",,2025-12-03 22:39:25
On Adversarial Robustness of Large-scale Audio Visual Learning,"Juncheng B Bernie Li, Shuhui Bernie Qu, Xinjian Bernie Li, Bernie Po-Yao, Huang, Florian Metze",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.12122"" target=""_blank"">2203.12122</a>","<a href=""https://github.com/lijuncheng16/AudioSetDoneRight"" target=""_blank"">lijuncheng16</a>",2025-12-03 22:39:25
A Roadmap for Big Model,"Sha Yuan, Hanyu Zhao, Shuai Zhao, Jiahong Leng, Yangxiao Liang, Xiaozhi Wang, Jifan Yu, Xin Lv, Zhou Shao, Jiaao He, Yankai Lin, Xu Han, Zhenghao Liu, Ning Ding, Yongming Rao, Yizhao Gao, Liang Zhang, Ming Ding, Cong Fang, Yisen Wang, Mingsheng Long, Jing Zhang, Yinpeng Dong, Tianyu Pang, Peng Cui, Lingxiao Huang, Zheng Liang, Huawei Shen, Hui Zhang, Quanshi Zhang, Qingxiu Dong, Zhixing Tan, Mingxuan Wang, Shuo Wang, Long Zhou, Haoran Li, Junwei Bao, Yingwei Pan, Weinan Zhang, Zhou Yu, Rui Yan, Chence Shi, Minghao Xu, Zuobai Zhang, Guoqiang Wang, Xiang Pan, Mengjie Li, Xiaoyu Chu, Zijun Yao, Fangwei Zhu, Shulin Cao, Weicheng Xue, Zixuan Ma, Zhengyan Zhang, Shengding Hu, Yujia Qin, Chaojun Xiao, Zheni Zeng, Ganqu Cui, Weize Chen, Weilin Zhao, Yuan Yao, Peng Li, Wenzhao Zheng, Wenliang Zhao, Ziyi Wang, Borui Zhang, Nanyi Fei, Anwen Hu, Zenan Ling, Haoyang Li, Boxi Cao, Xianpei Han, Weidong Zhan, Baobao Chang, Hao Sun, Jiawen Deng, Chujie Zheng, Juanzi Li, Lei Hou, Xigang Cao, Jidong Zhai, Zhiyuan Liu, Maosong Sun, Jiwen Lu, Zhiwu Lu, Qin Jin, Ruihua Song, Ji-Rong Wen, Zhouchen Lin, Liwei Wang, Hang Su, Jun Zhu, Zhifang Sui, Jiajun Zhang, Yang Liu, Xiaodong He, Minlie Huang, Jian Tang, Jie Tang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.14101"" target=""_blank"">2203.14101</a>",,2025-12-03 22:39:25
Enhancing Transferability of Adversarial Examples with Spatial Momentum,"Guoqiu Wang, Huanqian Yan, Xingxing Wei",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.13479"" target=""_blank"">2203.13479</a>",,2025-12-03 22:39:25
Origins of Low-dimensional Adversarial Perturbations,"Elvis Dohmatob, Chuan Guo, Morgane Goibert",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.13779"" target=""_blank"">2203.13779</a>",,2025-12-03 22:39:25
Give Me Your Attention: Dot-Product Attention Considered Harmful for Adversarial Patch Robustness,"Giulio Lovisotto, Nicole Finnie, Mauricio Munoz, Chaithanya Kumar Mummadi, Jan Hendrik Metzen",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.13639"" target=""_blank"">2203.13639</a>",,2025-12-03 22:39:25
Improving Robustness of Jet Tagging Algorithms with Adversarial Training,"Annika Stein, Xavier Coubez, Spandan Mondal, Andrzej Novak, Alexander Schmidt",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.13890"" target=""_blank"">2203.13890</a>",,2025-12-03 22:39:25
A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training,"Yifei Wang, Yisen Wang, Jiansheng Yang, Zhouchen Lin",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.13455"" target=""_blank"">2203.13455</a>",,2025-12-03 22:39:25
A Stitch in Time Saves Nine: A Train-Time Regularizing Loss for Improved Neural Network Calibration,"Ramya Hebbalaguppe, Jatin Prakash, Neelabh Madan, Chetan Arora",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.13834"" target=""_blank"">2203.13834</a>","<a href=""https://github.com/mdca-loss"" target=""_blank"">github.com</a>",2025-12-03 22:39:25
Trojan Horse Training for Breaking Defenses against Backdoor Attacks in Deep Learning,"Arezoo Rajabi, Bhaskar Ramasubramanian, Radha Poovendran",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.15506"" target=""_blank"">2203.15506</a>",,2025-12-03 22:39:25
A Perturbation Constrained Adversarial Attack for Evaluating the Robustness of Optical Flow,"Jenny Schmalfuss, Philipp Scholze, Andrés Bruhn",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.13214"" target=""_blank"">2203.13214</a>",,2025-12-03 22:39:25
NPC: Neuron Path Coverage via Characterizing Decision Logic of Deep Neural Networks,"Xiaofei Xie, Tianlin Li, Jian Wang, Lei Ma, Qing Guo, Felix Juefei-Xu, Yang Liu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.12915"" target=""_blank"">2203.12915</a>",,2025-12-03 22:39:25
MERLIN -- Malware Evasion with Reinforcement LearnINg,"Tony Quertier, Benjamin Marais, Stéphane Morucci, Bertrand Fournel",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.12980"" target=""_blank"">2203.12980</a>",,2025-12-03 22:39:25
Repairing Group-Level Errors for DNNs Using Weighted Regularization,"Ziyuan Zhong, Yuchi Tian, Conor J. Sweeney, Vicente Ordonez-Roman, Baishakhi Ray",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.13612"" target=""_blank"">2203.13612</a>",,2025-12-03 22:39:25
A Manifold View of Adversarial Risk,"Wenjia Zhang, Yikai Zhang, Xiaoling Hu, Mayank Goswami, Chao Chen, Dimitris Metaxas",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.13277"" target=""_blank"">2203.13277</a>",,2025-12-03 22:39:25
Powerful Physical Adversarial Examples Against Practical Face Recognition Systems,"Inderjeet Singh, Toshinori Araki, Kazuya Kakizaki",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.15498"" target=""_blank"">2203.15498</a>",,2025-12-03 22:39:25
Adversarial Training for Improving Model Robustness? Look at Both Prediction and Interpretation,"Hanjie Chen, Yangfeng Ji",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.12709"" target=""_blank"">2203.12709</a>",,2025-12-03 22:39:25
Input-specific Attention Subnetworks for Adversarial Detection,"Emil Biju, Anirudh Sriram, Pratyush Kumar, Mitesh M Khapra",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.12298"" target=""_blank"">2203.12298</a>",,2025-12-03 22:39:25
Self-supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection,"Liang Chen, Yong Zhang, Yibing Song, Lingqiao Liu, Jue Wang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.12208"" target=""_blank"">2203.12208</a>","<a href=""https://github.com/liangchen527/SLADD"" target=""_blank"">liangchen527</a>",2025-12-03 22:39:25
"Distort to Detect, not Affect: Detecting Stealthy Sensor Attacks with Micro-distortion","Suman Sourav, Binbin Chen",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.12249"" target=""_blank"">2203.12249</a>",,2025-12-03 22:39:25
On the (Limited) Generalization of MasterFace Attacks and Its Relation to the Capacity of Face Representations,"Philipp Terhörst, Florian Bierbaum, Marco Huber, Naser Damer, Florian Kirchbuchner, Kiran Raja, Arjan Kuijper",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.12387"" target=""_blank"">2203.12387</a>",,2025-12-03 22:39:25
A Systematic Survey of Attack Detection and Prevention in Connected and Autonomous Vehicles,"Trupil Limbasiya, Ko Zheng Teng, Sudipta Chattopadhyay, Jianying Zhou",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.14965"" target=""_blank"">2203.14965</a>",,2025-12-03 22:39:25
Efficient Global Robustness Certification of Neural Networks via Interleaving Twin-Network Encoding,"Zhilu Wang, Chao Huang, Qi Zhu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.14141"" target=""_blank"">2203.14141</a>",,2025-12-03 22:39:25
Reverse Engineering of Imperceptible Adversarial Image Perturbations,"Yifan Gong, Yuguang Yao, Yize Li, Yimeng Zhang, Xiaoming Liu, Xue Lin, Sijia Liu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.14145"" target=""_blank"">2203.14145</a>",,2025-12-03 22:39:25
Robust Structured Declarative Classifiers for 3D Point Clouds: Defending Adversarial Attacks with Implicit Gradients,"Kaidong Li, Ziming Zhang, Cuncong Zhong, Guanghui Wang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.15245"" target=""_blank"">2203.15245</a>","<a href=""https://zhang-vislab.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Towards Robust Rain Removal Against Adversarial Attacks: A Comprehensive Benchmark Analysis and Beyond,"Yi Yu, Wenhan Yang, Yap-Peng Tan, Alex C. Kot",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.16931"" target=""_blank"">2203.16931</a>","<a href=""https://github.com/yuyi-sd/Robust_Rain_Removal"" target=""_blank"">yuyi-sd</a>",2025-12-03 22:39:25
On the Convergence of Certified Robust Training with Interval Bound Propagation,"Yihan Wang, Zhouxing Shi, Quanquan Gu, Cho-Jui Hsieh",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08961"" target=""_blank"">2203.08961</a>",,2025-12-03 22:39:25
Sensor Data Validation and Driving Safety in Autonomous Driving Systems,Jindi Zhang,arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.16130"" target=""_blank"">2203.16130</a>",,2025-12-03 22:39:25
Example-based Explanations with Adversarial Attacks for Respiratory Sound Analysis,"Yi Chang, Zhao Ren, Thanh Tam Nguyen, Wolfgang Nejdl, Björn W. Schuller",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.16141"" target=""_blank"">2203.16141</a>",,2025-12-03 22:39:25
Mel Frequency Spectral Domain Defenses against Adversarial Attacks on Speech Recognition Systems,"Nicholas Mehlman, Anirudh Sreeram, Raghuveer Peri, Shrikanth Narayanan",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.15283"" target=""_blank"">2203.15283</a>",,2025-12-03 22:39:25
Zero-Query Transfer Attacks on Context-Aware Object Detectors,"Zikui Cai, Shantanu Rane, Alejandro E. Brito, Chengyu Song, Srikanth V. Krishnamurthy, Amit K. Roy-Chowdhury, M. Salman Asif",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.15230"" target=""_blank"">2203.15230</a>",,2025-12-03 22:39:25
Exploring Frequency Adversarial Attacks for Face Forgery Detection,"Shuai Jia, Chao Ma, Taiping Yao, Bangjie Yin, Shouhong Ding, Xiaokang Yang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.15674"" target=""_blank"">2203.15674</a>",,2025-12-03 22:39:25
StyleFool: Fooling Video Classification Systems via Style Transfer,"Yuxin Cao, Xi Xiao, Ruoxi Sun, Derui Wang, Minhui Xue, Sheng Wen",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.16000"" target=""_blank"">2203.16000</a>",,2025-12-03 22:39:25
Treatment Learning Causal Transformer for Noisy Image Classification,"Chao-Han Huck Yang, I-Te Danny Hung, Yi-Chieh Liu, Pin-Yu Chen",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.15529"" target=""_blank"">2203.15529</a>",,2025-12-03 22:39:25
"A Survey of Robust Adversarial Training in Pattern Recognition: Fundamental, Theory, and Methodologies","Zhuang Qian, Kaizhu Huang, Qiu-Feng Wang, Xu-Yao Zhang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.14046"" target=""_blank"">2203.14046</a>",,2025-12-03 22:39:25
Can NMT Understand Me? Towards Perturbation-based Evaluation of NMT Models for Code Generation,"Pietro Liguori, Cristina Improta, Vivo Simona De, Roberto Natella, Bojan Cukic, Domenico Cotroneo",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.15319"" target=""_blank"">2203.15319</a>",,2025-12-03 22:39:25
Boosting Black-Box Adversarial Attacks with Meta Learning,"Junjie the State Key Lab of Intelligent Control and Decision of Complex Systems and the School of Automation, Beijing Institute of Technology, Beijing, China Beijing Institute of Technology Chongqing Innovation Center, Chongqing, China Fu, Jian the State Key Lab of Intelligent Control and Decision of Complex Systems and the School of Automation, Beijing Institute of Technology, Beijing, China Beijing Institute of Technology Chongqing Innovation Center, Chongqing, China Sun, Gang the State Key Lab of Intelligent Control and Decision of Complex Systems and the School of Automation, Beijing Institute of Technology, Beijing, China Beijing Institute of Technology Chongqing Innovation Center, Chongqing, China Wang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.14607"" target=""_blank"">2203.14607</a>",,2025-12-03 22:39:25
Robust Unlearnable Examples: Protecting Data Against Adversarial Learning,"Shaopeng Fu, Fengxiang He, Yang Liu, Li Shen, Dacheng Tao",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.14533"" target=""_blank"">2203.14533</a>","<a href=""https://github.com/fshp971/robust-unlearnable-examples"" target=""_blank"">fshp971</a>",2025-12-03 22:39:25
Neurosymbolic hybrid approach to driver collision warning,"Kyongsik Yun, Thomas Lu, Alexander Huyen, Patrick Hammer, Pei Wang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.15076"" target=""_blank"">2203.15076</a>",,2025-12-03 22:39:25
Attacker Attribution of Audio Deepfakes,"Nicolas M. Müller, Franziska Dieckmann, Jennifer Williams",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.15563"" target=""_blank"">2203.15563</a>",,2025-12-03 22:39:25
Text Adversarial Purification as Defense against Adversarial Attacks,"Linyang Li, Demin Song, Xipeng Qiu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.14207"" target=""_blank"">2203.14207</a>",,2025-12-03 22:39:25
Adversarial Representation Sharing: A Quantitative and Secure Collaborative Learning Framework,"Jikun Chen, Feng Qiang, Na Ruan",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.14299"" target=""_blank"">2203.14299</a>",,2025-12-03 22:39:25
How to Robustify Black-Box ML Models? A Zeroth-Order Optimization Perspective,"Yimeng Zhang, Yuguang Yao, Jinghan Jia, Jinfeng Yi, Mingyi Hong, Shiyu Chang, Sijia Liu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.14195"" target=""_blank"">2203.14195</a>","<a href=""https://github.com/damon-demon/Black-Box-Defense"" target=""_blank"">damon-demon</a>",2025-12-03 22:39:25
Exploring High-Order Structure for Robust Graph Structure Learning,"Guangqian Yang, Yibing Zhan, Jinlong Li, Baosheng Yu, Liu Liu, Fengxiang He",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.11492"" target=""_blank"">2203.11492</a>",,2025-12-03 22:39:25
Recent improvements of ASR models in the face of adversarial attacks,"Raphael Olivier, Bhiksha Raj",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.16536"" target=""_blank"">2203.16536</a>",,2025-12-03 22:39:25
On the (Non-)Robustness of Two-Layer Neural Networks in Different Learning Regimes,"Elvis Dohmatob, Alberto Bietti",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.11864"" target=""_blank"">2203.11864</a>",,2025-12-03 22:39:25
Neural Predictor for Black-Box Adversarial Attacks on Speech Recognition,"Marie Biolková, Bac Nguyen",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.09849"" target=""_blank"">2203.09849</a>",,2025-12-03 22:39:25
Alleviating Adversarial Attacks on Variational Autoencoders with MCMC,"Anna Kuzina, Max Welling, Jakub M. Tomczak",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.09940"" target=""_blank"">2203.09940</a>",,2025-12-03 22:39:25
DTA: Physical Camouflage Attacks using Differentiable Transformation Network,"Naufal Suryanto, Yongsu Kim, Hyoeun Kang, Harashta Tatimma Larasati, Youngyeo Yun, Thi-Thu-Huong Le, Hunmin Yang, Se-Yoon Oh, Howon Kim",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.09831"" target=""_blank"">2203.09831</a>",,2025-12-03 22:39:25
AdIoTack: Quantifying and Refining Resilience of Decision Tree Ensemble Inference Models against Adversarial Volumetric Attacks on IoT Networks,"Arman Pashamokhtari, Gustavo Batista, Hassan Habibi Gharakheili",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.09792"" target=""_blank"">2203.09792</a>",,2025-12-03 22:39:25
Towards Robust 2D Convolution for Reliable Visual Recognition,"Lida Li, Shuai Li, Kun Wang, Xiangchu Feng, Lei Zhang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.09790"" target=""_blank"">2203.09790</a>",,2025-12-03 22:39:25
Improving the Transferability of Targeted Adversarial Examples through Object-Based Diverse Input,"Junyoung Byun, Seungju Cho, Myung-Joon Kwon, Hee-Seon Kim, Changick Kim",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.09123"" target=""_blank"">2203.09123</a>","<a href=""https://github.com/dreamflake/ODI"" target=""_blank"">dreamflake</a>",2025-12-03 22:39:25
Self-Ensemble Adversarial Training for Improved Robustness,"Hongjun Wang, Yisen Wang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.09678"" target=""_blank"">2203.09678</a>",,2025-12-03 22:39:25
Leveraging Adversarial Examples to Quantify Membership Information Leakage,"Grosso Ganesh Del, Hamid Jalalzai, Georg Pichler, Catuscia Palamidessi, Pablo Piantanida",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.09566"" target=""_blank"">2203.09566</a>",,2025-12-03 22:39:25
On the Properties of Adversarially-Trained CNNs,"Mattia Carletti, Matteo Terzi, Gian Antonio Susto",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.09243"" target=""_blank"">2203.09243</a>",,2025-12-03 22:39:25
PiDAn: A Coherence Optimization Approach for Backdoor Attack Detection and Mitigation in Deep Neural Networks,"Yue Wang, Wenqing Li, Esha Sarkar, Muhammad Shafique, Michail Maniatakos, Saif Eddin Jabari",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.09289"" target=""_blank"">2203.09289</a>",,2025-12-03 22:39:25
HDLock: Exploiting Privileged Encoding to Protect Hyperdimensional Computing Models against IP Stealing,"Shijin Duan, Shaolei Ren, Xiaolin Xu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.09681"" target=""_blank"">2203.09681</a>",,2025-12-03 22:39:25
Robustness through Cognitive Dissociation Mitigation in Contrastive Adversarial Training,"Adir Rahamim, Itay Naeh",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08959"" target=""_blank"">2203.08959</a>",,2025-12-03 22:39:25
Towards Practical Certifiable Patch Defense with Vision Transformer,"Zhaoyu Chen, Bo Li, Jianghe Xu, Shuang Wu, Shouhong Ding, Wenqiang Zhang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08519"" target=""_blank"">2203.08519</a>",,2025-12-03 22:39:25
Patch-Fool: Are Vision Transformers Always Robust Against Adversarial Perturbations? (97%),"Yonggan Fu, Shunyao Zhang, Shang Wu, Cheng Wan, Yingyan Lin",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08392"" target=""_blank"">2203.08392</a>",,2025-12-03 22:39:25
Provable Adversarial Robustness for Fractional Lp Threat Models,"Alexander Levine, Soheil Feizi",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08945"" target=""_blank"">2203.08945</a>","<a href=""https://github.com/alevine0/fractionalLpRobustness"" target=""_blank"">alevine0</a>",2025-12-03 22:39:25
COPA: Certifying Robust Policies for Offline Reinforcement Learning against Poisoning Attacks,"Fan Wu, Linyi Li, Chejian Xu, Huan Zhang, Bhavya Kailkhura, Krishnaram Kenthapadi, Ding Zhao, Bo Li",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08398"" target=""_blank"">2203.08398</a>","<a href=""https://copa-leaderboard.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Sniper Backdoor: Single Client Targeted Backdoor Attack in Federated Learning,"Gorka Abad, Servio Paguada, Oguzhan Ersoy, Stjepan Picek, Víctor Julio Ramírez-Durán, Aitor Urbieta",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08689"" target=""_blank"">2203.08689</a>",,2025-12-03 22:39:25
Reducing Flipping Errors in Deep Neural Networks,"Xiang Deng, Yun Xiao, Bo Long, Zhongfei Zhang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08390"" target=""_blank"">2203.08390</a>",,2025-12-03 22:39:25
Attacking deep networks with surrogate-based adversarial black-box methods is easy,"Nicholas A. Lord, Romain Mueller, Luca Bertinetto",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08725"" target=""_blank"">2203.08725</a>","<a href=""https://github.com/fiveai/GFCS"" target=""_blank"">fiveai</a>",2025-12-03 22:39:25
Semi-Targeted Model Poisoning Attack on Federated Learning via Backward Error Analysis,"Yuwei Sun, Hideya Ochiai, Jun Sakuma",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.11633"" target=""_blank"">2203.11633</a>",,2025-12-03 22:39:25
AutoAdversary: A Pixel Pruning Method for Sparse Adversarial Attack,"Jinqiao Li, Xiaotao Liu, Jian Zhao, Furao Shen",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.09756"" target=""_blank"">2203.09756</a>",,2025-12-03 22:39:25
What Do Adversarially trained Neural Networks Focus: A Fourier Domain-based Study,"Binxiao Huang, Chaofan Tao, Rui Lin, Ngai Wong",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.08739"" target=""_blank"">2203.08739</a>",,2025-12-03 22:39:25
Adversarial Attacks on Deep Learning-based Video Compression and Classification Systems,"Jung-Woo Chang, Mojan Javaheripi, Seira Hidano, Farinaz Koushanfar",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.10183"" target=""_blank"">2203.10183</a>",,2025-12-03 22:39:25
Adversarial Examples in Random Neural Networks with General Activations,"Andrea Montanari, Yuchen Wu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.17209"" target=""_blank"">2203.17209</a>",,2025-12-03 22:39:25
"A Girl Has A Name, And It's","Wanyue Zhai, Jonathan Rusert, Zubair Shafiq, Padmini Srinivasan",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.11849"" target=""_blank"">2203.11849</a>",,2025-12-03 22:39:25
Concept-based Adversarial Attacks: Tricking Humans and Classifiers Alike,"Johannes Schneider, Giovanni Apruzzese",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.10166"" target=""_blank"">2203.10166</a>",,2025-12-03 22:39:25
GradViT: Gradient Inversion of Vision Transformers,"Ali Hatamizadeh, Hongxu Yin, Holger Roth, Wenqi Li, Jan Kautz, Daguang Xu, Pavlo Molchanov",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.11894"" target=""_blank"">2203.11894</a>","<a href=""https://gradvit.github.io/"" target=""_blank"">gradvit.github.io</a>",2025-12-03 22:39:25
On Robust Classification using Contractive Hamiltonian Neural ODEs,"Muhammad Zakwan, Liang Xu, Giancarlo Ferrari-Trecate",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.11805"" target=""_blank"">2203.11805</a>",,2025-12-03 22:39:25
Integrity Fingerprinting of DNN with Double Black-box Design and Verification,"Shuo Wang, Sidharth Agarwal, Sharif Abuadbba, Kristen Moore, Surya Nepal, Salil Kanhere",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.10902"" target=""_blank"">2203.10902</a>",,2025-12-03 22:39:25
On The Robustness of Offensive Language Classifiers,"Jonathan Rusert, Zubair Shafiq, Padmini Srinivasan",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.11331"" target=""_blank"">2203.11331</a>",,2025-12-03 22:39:25
Defending against Co-residence Attack in Energy-Efficient Cloud: An Optimization based Real-time Secure VM Allocation Strategy,"Lu Cao, Ruiwen Li, Xiaojun Ruan, Yuhong Liu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.10734"" target=""_blank"">2203.10734</a>",,2025-12-03 22:39:25
An Intermediate-level Attack Framework on The Basis of Linear Regression,"Yiwen Guo, Qizhang Li, Wangmeng Zuo, Hao Chen",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.10723"" target=""_blank"">2203.10723</a>",,2025-12-03 22:39:25
Making DeepFakes more spurious: evading deep face forgery detection via trace removal attack,"Chi Liu, Huajie Chen, Tianqing Zhu, Jun Zhang, Wanlei Zhou",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.11433"" target=""_blank"">2203.11433</a>",,2025-12-03 22:39:25
A Prompting-based Approach for Adversarial Example Generation and Robustness Enhancement,"Yuting Yang, Pei Huang, Juan Cao, Jintao Li, Yun Lin, Jin Song Dong, Feifei Ma, Jian Zhang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.10714"" target=""_blank"">2203.10714</a>",,2025-12-03 22:39:25
"Deep Learning Generalization, Extrapolation, and Over-parameterization",Roozbeh Yousefzadeh,arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.10366"" target=""_blank"">2203.10366</a>",,2025-12-03 22:39:25
Leveraging Expert Guided Adversarial Augmentation For Improving Generalization in Named Entity Recognition,"Aaron Reich, Jiaao Chen, Aastha Agrawal, Yanzhe Zhang, Diyi Yang",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.10693"" target=""_blank"">2203.10693</a>","<a href=""https://github.com/GT-SALT/Guided-Adversarial-Augmentation"" target=""_blank"">GT-SALT</a>",2025-12-03 22:39:25
Adversarial Parameter Attack on Deep Neural Networks,"Lijia Yu, Yihan Wang, Xiao-Shan Gao",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.10502"" target=""_blank"">2203.10502</a>",,2025-12-03 22:39:25
Adversarial Defense via Image Denoising with Chaotic Encryption,"Shi Hu, Eric Nalisnick, Max Welling",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.10290"" target=""_blank"">2203.10290</a>",,2025-12-03 22:39:25
Perturbations in the Wild: Leveraging Human-Written Text Perturbations for Realistic Adversarial Attack and Defense,"Thai Le, Jooyoung Lee, Kevin Yen, Yifan Hu, Dongwon Lee",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.10346"" target=""_blank"">2203.10346</a>",,2025-12-03 22:39:25
On Robust Prefix-Tuning for Text Classification,"Zonghan Yang, Yang Liu",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.10378"" target=""_blank"">2203.10378</a>",,2025-12-03 22:39:25
Distinguishing Non-natural from Natural Adversarial Samples for More Robust Pre-trained Language Model,"Jiayi Wang, Rongzhou Bao, Zhuosheng Zhang, Hai Zhao",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.11199"" target=""_blank"">2203.11199</a>",,2025-12-03 22:39:25
Efficient Neural Network Analysis with Sum-of-Infeasibilities,"Haoze Wu, Aleksandar Zeljić, Guy Katz, Clark Barrett",arXiv,2022-03,"<a href=""http://arxiv.org/abs/2203.11201"" target=""_blank"">2203.11201</a>",,2025-12-03 22:39:25
CMW-Net: Learning a Class-Aware Sample Weighting Mapping for Robust Deep Learning,"Jun Shu, Xiang Yuan, Deyu Meng, Zongben Xu",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05613"" target=""_blank"">2202.05613</a>",,2025-12-03 22:39:25
FAAG: Fast Adversarial Audio Generation through Interactive Attack Optimisation,"Yuantian Miao, Chao Chen, Lei Pan, Jun Zhang, Yang Xiang",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05416"" target=""_blank"">2202.05416</a>",,2025-12-03 22:39:25
Towards Assessing and Characterizing the Semantic Robustness of Face Recognition,"Juan C. Pérez, Motasem Alfarra, Ali Thabet, Pablo Arbeláez, Bernard Ghanem",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.04978"" target=""_blank"">2202.04978</a>",,2025-12-03 22:39:25
Controlling the Complexity and Lipschitz Constant improves polynomial nets,"Zhenyu Zhu, Fabian Latorre, Grigorios G Chrysos, Volkan Cevher",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05068"" target=""_blank"">2202.05068</a>",,2025-12-03 22:39:25
FedAttack: Effective and Covert Poisoning Attack on Federated Recommendation via Hard Sampling,"Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang, Xing Xie",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.04975"" target=""_blank"">2202.04975</a>",,2025-12-03 22:39:25
A Field of Experts Prior for Adapting Neural Networks at Test Time,"Neerav Karani, Georg Brunner, Ertunc Erdil, Simin Fei, Kerem Tezcan, Krishna Chaitanya, Ender Konukoglu",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05271"" target=""_blank"">2202.05271</a>",,2025-12-03 22:39:25
Adversarial Attack and Defense of YOLO Detectors in Autonomous Driving Scenarios,"Jung Im Choi, Qing Tian",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.04781"" target=""_blank"">2202.04781</a>",,2025-12-03 22:39:25
False Memory Formation in Continual Learners Through Imperceptible Backdoor Trigger,"Muhammad Umer, Robi Polikar",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.04479"" target=""_blank"">2202.04479</a>",,2025-12-03 22:39:25
Gradient Methods Provably Converge to Non-Robust Networks,"Gal Vardi, Gilad Yehudai, Ohad Shamir",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.04347"" target=""_blank"">2202.04347</a>",,2025-12-03 22:39:25
Adversarial Detection without Model Information,"Abhishek Moitra, Youngeun Kim, Priyadarshini Panda",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.04271"" target=""_blank"">2202.04271</a>",,2025-12-03 22:39:25
ARIBA: Towards Accurate and Robust Identification of Backdoor Attacks in Federated Learning,"Yuxi Mi, Jihong Guan, Shuigeng Zhou",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.04311"" target=""_blank"">2202.04311</a>",,2025-12-03 22:39:25
L2B: Learning to Bootstrap Robust Models for Combating Label Noise,"Yuyin Zhou, Xianhang Li, Fengze Liu, Qingyue Wei, Xuxi Chen, Lequan Yu, Cihang Xie, Matthew P. Lungren, Lei Xing",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.04291"" target=""_blank"">2202.04291</a>","<a href=""https://github.com/yuyinzhou/l2b"" target=""_blank"">yuyinzhou</a>",2025-12-03 22:39:25
Model Architecture Adaption for Bayesian Neural Networks,"Duo Wang, Yiren Zhao, Ilia Shumailov, Robert Mullins",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.04392"" target=""_blank"">2202.04392</a>",,2025-12-03 22:39:25
Towards Compositional Adversarial Robustness: Generalizing Adversarial Training to Composite Semantic Perturbations,"Lei Hsiung, Yun-Yun Tsai, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.04235"" target=""_blank"">2202.04235</a>",,2025-12-03 22:39:25
On the Detection of Adaptive Adversarial Attacks in Speaker Verification Systems,Zesheng Chen,arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05725"" target=""_blank"">2202.05725</a>",,2025-12-03 22:39:25
Verification-Aided Deep Ensemble Selection,"Guy Amir, Guy Katz, Michael Schapira",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.03898"" target=""_blank"">2202.03898</a>",,2025-12-03 22:39:25
Improving Generalization via Uncertainty Driven Perturbations,"Matteo Pagliardini, Gilberto Manunza, Martin Jaggi, Michael I. Jordan, Tatjana Chavdarova",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05737"" target=""_blank"">2202.05737</a>",,2025-12-03 22:39:25
Excitement Surfeited Turns to Errors: Deep Learning Testing Framework Based on Excitable Neurons,"Haibo Jin, Ruoxi Chen, Haibin Zheng, Jinyin Chen, Yao Cheng, Yue Yu, Xianglong Liu",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.07464"" target=""_blank"">2202.07464</a>",,2025-12-03 22:39:25
White-Box Attacks on Hate-speech BERT Classifiers in German with Explicit and Implicit Character Level Defense,"Shahrukh Khan, Mahnoor Shahid, Navdeeppal Singh",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05778"" target=""_blank"">2202.05778</a>",,2025-12-03 22:39:25
SQuant: On-the-Fly Data-Free Quantization via Diagonal Hessian Approximation,"Cong Guo, Yuxian Qiu, Jingwen Leng, Xiaotian Gao, Chen Zhang, Yunxin Liu, Fan Yang, Yuhao Zhu, Minyi Guo",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.07471"" target=""_blank"">2202.07471</a>","<a href=""https://github.com/clevercool/SQuant"" target=""_blank"">clevercool</a>",2025-12-03 22:39:25
UA-FedRec: Untargeted Attack on Federated News Recommendation,"Jingwei Yi, Fangzhao Wu, Bin Zhu, Jing Yao, Zhulin Tao, Guangzhong Sun, Xing Xie",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.06701"" target=""_blank"">2202.06701</a>",,2025-12-03 22:39:25
"Robust, Deep, and Reinforcement Learning for Management of Communication and Power Networks",Alireza Sadeghi,arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05395"" target=""_blank"">2202.05395</a>",,2025-12-03 22:39:25
Progressive Backdoor Erasing via connecting Backdoor and Adversarial Attacks,"Bingxu Mu, Zhenxing Niu, Le Wang, Xue Wang, Rong Jin, Gang Hua",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.06312"" target=""_blank"">2202.06312</a>",,2025-12-03 22:39:25
Training with More Confidence: Mitigating Injected and Natural Backdoors During Training,"Zhenting Wang, Hailun Ding, Juan Zhai, Shiqing Ma",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.06382"" target=""_blank"">2202.06382</a>","<a href=""https://github.com/RU-System-Software-and-Security/NONE"" target=""_blank"">RU-System-Software-and-Security</a>",2025-12-03 22:39:25
Extracting Label-specific Key Input Features for Neural Code Intelligence Models,Md Rafiqul Islam Rabin,arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.06474"" target=""_blank"">2202.06474</a>",,2025-12-03 22:39:25
Defense Strategies Toward Model Poisoning Attacks in Federated Learning: A Survey,"Zhilin Wang, Qiao Kang, Xinyi Zhang, Qin Hu",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.06414"" target=""_blank"">2202.06414</a>",,2025-12-03 22:39:25
RoPGen: Towards Robust Code Authorship Attribution via Automatic Coding Style Transformation,"Zhen Qian Li, Qian Guenevere, Chen, Chen Chen, Yayi Zou, Shouhuai Xu",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.06043"" target=""_blank"">2202.06043</a>",,2025-12-03 22:39:25
Jigsaw Puzzle: Selective Backdoor Attack to Subvert Malware Classifiers,"Limin Yang, Zhi Chen, Jacopo Cortellazzi, Feargus Pendlebury, Kevin Tu, Fabio Pierazzi, Lorenzo Cavallaro, Gang Wang",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05470"" target=""_blank"">2202.05470</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defense Methods for Power Quality Recognition,"Jiwei Tian, Buhong Wang, Jing Li, Zhen Wang, Mete Ozay",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.07421"" target=""_blank"">2202.07421</a>",,2025-12-03 22:39:25
Towards Adversarially Robust Deepfake Detection: An Ensemble Approach,"Ashish Hooda, Neal Mangaokar, Ryan Feng, Kassem Fawaz, Somesh Jha, Atul Prakash",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05687"" target=""_blank"">2202.05687</a>",,2025-12-03 22:39:25
Open-set Adversarial Defense with Clean-Adversarial Mutual Learning,"Rui Shao, Pramuditha Perera, Pong C. Yuen, Vishal M. Patel",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05953"" target=""_blank"">2202.05953</a>",,2025-12-03 22:39:25
Using Random Perturbations to Mitigate Adversarial Attacks on Sentiment Analysis Models,"Abigail Swenor, Jugal Kalita",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05758"" target=""_blank"">2202.05758</a>",,2025-12-03 22:39:25
Fast Adversarial Training with Noise Augmentation: A Unified Perspective on RandStart and GradAlign,"Axi Niu, Kang Zhang, Chaoning Zhang, Chenshuang Zhang, In So Kweon, Chang D. Yoo, Yanning Zhang",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05488"" target=""_blank"">2202.05488</a>",,2025-12-03 22:39:25
Predicting Out-of-Distribution Error with the Projection Norm,"Yaodong Yu, Zitong Yang, Alexander Wei, Yi Ma, Jacob Steinhardt",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05834"" target=""_blank"">2202.05834</a>","<a href=""https://github.com/yaodongyu/ProjNorm"" target=""_blank"">yaodongyu</a>",2025-12-03 22:39:25
Towards Making a Trojan-horse Attack on Text-to-Image Retrieval,"Fan Hu, Aozhu Chen, Xirong Li",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.03861"" target=""_blank"">2202.03861</a>",,2025-12-03 22:39:25
Probabilistically Robust Learning: Balancing Average- and Worst-case Performance,"Alexander Robey, Luiz F. O. Chamon, George J. Pappas, Hamed Hassani",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.01136"" target=""_blank"">2202.01136</a>",,2025-12-03 22:39:25
Blind leads Blind: A Zero-Knowledge Attack on Federated Learning,"Jiyue Huang, Zilong Zhao, Lydia Y. Chen, Stefanie Roos",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.05877"" target=""_blank"">2202.05877</a>",,2025-12-03 22:39:25
On The Empirical Effectiveness of Unrealistic Adversarial Hardening Against Realistic Adversarial Attacks,"Salijona Dyrmishi, Salah Ghamizi, Thibault Simonetto, Yves Le Traon, Maxime Cordy",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.03277"" target=""_blank"">2202.03277</a>",,2025-12-03 22:39:25
Smoothed Embeddings for Certified Few-Shot Learning,"Mikhail Pautov, Olesya Kuznetsova, Nurislam Tursynbek, Aleksandr Petiushko, Ivan Oseledets",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.01186"" target=""_blank"">2202.01186</a>",,2025-12-03 22:39:25
Make Some Noise: Reliable and Efficient Single-Step Adversarial Training,"Jorge Pau de, Adel Bibi, Riccardo Volpi, Amartya Sanyal, Philip H. S. Torr, Grégory Rogez, Puneet K. Dokania",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.01181"" target=""_blank"">2202.01181</a>","<a href=""https://github.com/pdejorge/N-FGSM"" target=""_blank"">pdejorge</a>",2025-12-03 22:39:25
Robust Binary Models by Pruning Randomly-initialized Networks,"Chen Liu, Ziqi Zhao, Sabine Süsstrunk, Mathieu Salzmann",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.01341"" target=""_blank"">2202.01341</a>",,2025-12-03 22:39:25
"NoisyMix: Boosting Robustness by Combining Data Augmentations, Stability Training, and Noise Injections","N. Benjamin Erichson, Soon Hoe Lim, Francisco Utrera, Winnie Xu, Ziang Cao, Michael W. Mahoney",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.01263"" target=""_blank"">2202.01263</a>",,2025-12-03 22:39:25
Language Dependencies in Adversarial Attacks on Speech Recognition Systems,"Karla Markert, Donika Mirdita, Konstantin Böttinger",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.00399"" target=""_blank"">2202.00399</a>",,2025-12-03 22:39:25
Finding Biological Plausibility for Adversarially Robust Features via Metameric Tasks,"Anne Harrington, Arturo Deza",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.00838"" target=""_blank"">2202.00838</a>",,2025-12-03 22:39:25
Visualizing Automatic Speech Recognition -- Means for a Better Understanding? (64%),"Karla Markert, Romain Parracone, Mykhailo Kulakov, Philip Sperl, Ching-Yu Kao, Konstantin Böttinger",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.00673"" target=""_blank"">2202.00673</a>",,2025-12-03 22:39:25
Datamodels: Predicting Predictions from Training Data,"Andrew Ilyas, Sung Min Park, Logan Engstrom, Guillaume Leclerc, Aleksander Madry",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.00622"" target=""_blank"">2202.00622</a>","<a href=""https://github.com/MadryLab/datamodels-data"" target=""_blank"">MadryLab</a>",2025-12-03 22:39:25
Query Efficient Decision Based Sparse Attacks Against Black-Box Deep Learning Models,"Viet Quoc Vo, Ehsan Abbasnejad, Damith C. Ranasinghe",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.00091"" target=""_blank"">2202.00091</a>",,2025-12-03 22:39:25
"Rate Coding or Direct Coding: Which One is Better for Accurate, Robust, and Energy-efficient Spiking Neural Networks? (93%)","Youngeun Kim, Hyoungseob Park, Abhishek Moitra, Abhiroop Bhattacharjee, Yeshwanth Venkatesha, Priyadarshini Panda",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.03133"" target=""_blank"">2202.03133</a>","<a href=""https://github.com/Intelligent-Computing-Lab-Yale/Rate-vs-Direct"" target=""_blank"">Intelligent-Computing-Lab-Yale</a>",2025-12-03 22:39:25
AntidoteRT: Run-time Detection and Correction of Poison Attacks on Neural Networks,"Muhammad Usman, Youcheng Sun, Divya Gopinath, Corina S. Pasareanu",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.01179"" target=""_blank"">2202.01179</a>",,2025-12-03 22:39:25
MEGA: Model Stealing via Collaborative Generator-Substitute Networks,"Chi Hong, Jiyue Huang, Lydia Y. Chen",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.00008"" target=""_blank"">2202.00008</a>",,2025-12-03 22:39:25
Studying the Robustness of Anti-adversarial Federated Learning Models Detecting Cyberattacks in IoT Spectrum Sensors,"Pedro Miguel Sánchez Sánchez, Alberto Huertas Celdrán, Timo Schenk, Adrian Lars Benjamin Iten, Gérôme Bovet, Gregorio Martínez Pérez, Burkhard Stiller",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.00137"" target=""_blank"">2202.00137</a>",,2025-12-03 22:39:25
Gradient-guided Unsupervised Text Style Transfer via Contrastive Learning,"Chenghao Fan, Ziao Li, Wei wei",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.00469"" target=""_blank"">2202.00469</a>",,2025-12-03 22:39:25
"Recent Advances in Reliable Deep Graph Learning: Inherent Noise, Distribution Shift, and Adversarial Attack","Jintang Li, Bingzhe Wu, Chengbin Hou, Guoji Fu, Yatao Bian, Liang Chen, Junzhou Huang, Zibin Zheng",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.07114"" target=""_blank"">2202.07114</a>",,2025-12-03 22:39:25
An Eye for an Eye: Defending against Gradient-based Attacks with Gradients,"Hanbin Hong, Yuan Hong, Yu Kong",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.01117"" target=""_blank"">2202.01117</a>",,2025-12-03 22:39:25
ObjectSeeker: Certifiably Robust Object Detection against Patch Hiding Attacks via Patch-agnostic Masking,"Chong Xiang, Alexander Valtchanov, Saeed Mahloujifar, Prateek Mittal",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.01811"" target=""_blank"">2202.01811</a>",,2025-12-03 22:39:25
A Survey on Safety-Critical Driving Scenario Generation -- A Methodological Perspective,"Wenhao Ding, Chejian Xu, Mansur Arief, Haohong Lin, Bo Li, Ding Zhao",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.02215"" target=""_blank"">2202.02215</a>",,2025-12-03 22:39:25
Tubes Among Us: Analog Attack on Automatic Speaker Identification,"Shimaa Ahmed, Yash Wani, Ali Shahin Shamsabadi, Mohammad Yaghini, Ilia Shumailov, Nicolas Papernot, Kassem Fawaz",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.02751"" target=""_blank"">2202.02751</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defense for Non-Parametric Two-Sample Tests,"Xilie Xu, Jingfeng Zhang, Feng Liu, Masashi Sugiyama, Mohan Kankanhalli",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.03077"" target=""_blank"">2202.03077</a>",,2025-12-03 22:39:25
Evaluating Robustness of Cooperative MARL: A Model-based Approach,"Nhan H. Pham, Lam M. Nguyen, Jie Chen, Hoang Thanh Lam, Subhro Das, Tsui-Wei Weng",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.03558"" target=""_blank"">2202.03558</a>",,2025-12-03 22:39:25
More is Better (Mostly): On the Backdoor Attacks in Federated Graph Neural Networks,"Jing Xu, Rui Wang, Kaitai Liang, Stjepan Picek",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.03195"" target=""_blank"">2202.03195</a>",,2025-12-03 22:39:25
Membership Inference Attacks and Defenses in Neural Network Pruning,"Xiaoyong Yuan, Lan Zhang",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.03335"" target=""_blank"">2202.03335</a>",,2025-12-03 22:39:25
SimGRACE: A Simple Framework for Graph Contrastive Learning without Data Augmentation,"Jun Xia, Lirong Wu, Jintao Chen, Bozhen Hu, Stan Z. Li",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.03104"" target=""_blank"">2202.03104</a>",,2025-12-03 22:39:25
"Deletion Inference, Reconstruction, and Compliance in Machine (Un)Learning","Ji Gao, Sanjam Garg, Mohammad Mahmoody, Prashant Nalini Vasudevan",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.03460"" target=""_blank"">2202.03460</a>",,2025-12-03 22:39:25
Redactor: A Data-centric and Individualized Defense Against Inference Attacks,"Geon Heo, Steven Euijong Whang",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.02902"" target=""_blank"">2202.02902</a>",,2025-12-03 22:39:25
LTU Attacker for Membership Inference,"Joseph Pedersen, Rafael Muñoz-Gómez, Jiangnan Huang, Haozhe Sun, Wei-Wei Tu, Isabelle Guyon",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.02278"" target=""_blank"">2202.02278</a>",,2025-12-03 22:39:25
Layer-wise Regularized Adversarial Training using Layers Sustainability Analysis (LSA) framework,"Mohammad Khalooei, Mohammad Mehdi Homayounpour, Maryam Amirmazlaghani",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.02626"" target=""_blank"">2202.02626</a>","<a href=""https://github.com/khalooei/LSA"" target=""_blank"">khalooei</a>",2025-12-03 22:39:25
Adversarial Detector with Robust Classifier,"Takayuki Osakabe, Maungmaung Aprilpyone, Sayaka Shiota, Hitoshi Kiya",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.02503"" target=""_blank"">2202.02503</a>",,2025-12-03 22:39:25
Memory Defense: More Robust Classification via a Memory-Masking Autoencoder,"Eashan Lehigh University Adhikarla, Dan Lehigh University Luo, Brian D. Lehigh University Davison",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.02595"" target=""_blank"">2202.02595</a>",,2025-12-03 22:39:25
Improved Certified Defenses against Data Poisoning with (Deterministic) Finite Aggregation,"Wenxiao Wang, Alexander Levine, Soheil Feizi",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.02628"" target=""_blank"">2202.02628</a>",,2025-12-03 22:39:25
Pixle: a fast and effective black-box attack based on rearranging pixels,"Jary Pomponi, Simone Scardapane, Aurelio Uncini",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.02236"" target=""_blank"">2202.02236</a>",,2025-12-03 22:39:25
Backdoor Defense via Decoupling the Training Process,"Kunzhe Huang, Yiming Li, Baoyuan Wu, Zhan Qin, Kui Ren",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.03423"" target=""_blank"">2202.03423</a>","<a href=""https://github.com/SCLBD/DBD"" target=""_blank"">SCLBD</a>",2025-12-03 22:39:25
PFGE: Parsimonious Fast Geometric Ensembling of DNNs,"Hao Guo, Jiyong Jin, Bin Liu",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.06658"" target=""_blank"">2202.06658</a>","<a href=""https://github.com/ZJLAB-AMMI/PFGE"" target=""_blank"">ZJLAB-AMMI</a>",2025-12-03 22:39:25
Adversarially Robust Models may not Transfer Better: Sufficient Conditions for Domain Transferability from the View of Regularization,"Xiaojun Xu, Jacky Yibo Zhang, Evelyn Ma, Danny Son, Oluwasanmi Koyejo, Bo Li",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.01832"" target=""_blank"">2202.01832</a>",,2025-12-03 22:39:25
Finding Dynamics Preserving Adversarial Winning Tickets,"Xupeng Shi, Pengfei Zheng, A. Adam Ding, Yuan Gao, Weizhong Zhang",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.06488"" target=""_blank"">2202.06488</a>",,2025-12-03 22:39:25
Universal Adversarial Examples in Remote Sensing: Methodology and Benchmark,"Yonghao Xu, Pedram Ghamisi",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.07054"" target=""_blank"">2202.07054</a>",,2025-12-03 22:39:25
Measuring CLEVRness: Blackbox testing of Visual Reasoning Models,"Spyridon Mouselinos, Henryk Michalewski, Mateusz Malinowski",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.12162"" target=""_blank"">2202.12162</a>",,2025-12-03 22:39:25
Bounding Membership Inference,"Anvith Thudi, Ilia Shumailov, Franziska Boenisch, Nicolas Papernot",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.12232"" target=""_blank"">2202.12232</a>",,2025-12-03 22:39:25
Fourier-Based Augmentations for Improved Robustness and Uncertainty Calibration,"Ryan Soklaski, Michael Yee, Theodoros Tsiligkaridis",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.12412"" target=""_blank"">2202.12412</a>",,2025-12-03 22:39:25
Interpolation-based Contrastive Learning for Few-Label Semi-Supervised Learning,"Xihong Yang, Xiaochang Hu, Sihang Zhou, Xinwang Liu, En Zhu",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.11915"" target=""_blank"">2202.11915</a>",,2025-12-03 22:39:25
Improving Robustness of Convolutional Neural Networks Using Element-Wise Activation Scaling,"Zhi-Yuan Zhang, Di Liu",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.11898"" target=""_blank"">2202.11898</a>",,2025-12-03 22:39:25
Using calibrator to improve robustness in Machine Reading Comprehension,"Jing Jin, Houfeng Wang",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.11865"" target=""_blank"">2202.11865</a>",,2025-12-03 22:39:25
LPF-Defense: 3D Adversarial Defense based on Frequency Analysis,"Hanieh Naderi, Kimia Noorbakhsh, Arian Etemadi, Shohreh Kasaei",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.11287"" target=""_blank"">2202.11287</a>",,2025-12-03 22:39:25
Universal adversarial perturbation for remote sensing images,"Zhaoxia Yin, Qingyu Wang, Jin Tang, Bin Luo",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.10693"" target=""_blank"">2202.10693</a>",,2025-12-03 22:39:25
Seeing is Living? Rethinking the Security of Facial Liveness Verification in the Deepfake Era,"Changjiang Li, Li Wang, Shouling Ji, Xuhong Zhang, Zhaohan Xi, Shanqing Guo, Ting Wang",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.10673"" target=""_blank"">2202.10673</a>",,2025-12-03 22:39:25
Indiscriminate Poisoning Attacks on Unsupervised Contrastive Learning,"Hao He, Kaiwen Zha, Dina Katabi",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.11202"" target=""_blank"">2202.11202</a>",,2025-12-03 22:39:25
Adversarial Attacks on Speech Recognition Systems for Mission-Critical Applications: A Survey,"Ngoc Dung Huynh, Mohamed Reda Bouadjenek, Imran Razzak, Kevin Lee, Chetan Arora, Ali Hassani, Arkady Zaslavsky",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.10594"" target=""_blank"">2202.10594</a>",,2025-12-03 22:39:25
Semi-Implicit Hybrid Gradient Methods with Application to Adversarial Robustness,"Beomsu Kim, Junghoon Seo",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.10523"" target=""_blank"">2202.10523</a>",,2025-12-03 22:39:25
HoneyModels: Machine Learning Honeypots,"Ahmed Abdou, Ryan Sheatsley, Yohan Beugin, Tyler Shipp, Patrick McDaniel",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.10309"" target=""_blank"">2202.10309</a>",,2025-12-03 22:39:25
Transferring Adversarial Robustness Through Robust Representation Matching,"Pratik Vaishnavi, Kevin Eykholt, Amir Rahmati",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.09994"" target=""_blank"">2202.09994</a>",,2025-12-03 22:39:25
On the Effectiveness of Adversarial Training against Backdoor Attacks,"Yinghua Gao, Dongxian Wu, Jingfeng Zhang, Guanhao Gan, Shu-Tao Xia, Gang Niu, Masashi Sugiyama",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.10627"" target=""_blank"">2202.10627</a>",,2025-12-03 22:39:25
Understanding Adversarial Robustness from Feature Maps of Convolutional Layers,"Cong Xu, Min Yang",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.12435"" target=""_blank"">2202.12435</a>","<a href=""https://github.com/MTandHJ/rcm"" target=""_blank"">MTandHJ</a>",2025-12-03 22:39:25
Robust Probabilistic Time Series Forecasting,"TaeHo Yoon, Youngsuk Park, Ernest K. Ryu, Yuyang Wang",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.11910"" target=""_blank"">2202.11910</a>",,2025-12-03 22:39:25
A Tutorial on Adversarial Learning Attacks and Countermeasures,"Cato Pauling, Michael Gimson, Muhammed Qaid, Ahmad Kida, Basel Halak",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.10377"" target=""_blank"">2202.10377</a>",,2025-12-03 22:39:25
Towards Effective and Robust Neural Trojan Defenses via Input Filtering,"Kien Do, Haripriya Harikumar, Hung Le, Dung Nguyen, Truyen Tran, Santu Rana, Dang Nguyen, Willy Susilo, Svetha Venkatesh",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.12154"" target=""_blank"">2202.12154</a>",,2025-12-03 22:39:25
Towards Robust Stacked Capsule Autoencoder with Hybrid Adversarial Training,"Jiazhu Dai, Siwei Xiong",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.13755"" target=""_blank"">2202.13755</a>","<a href=""https://github.com/FrostbiteXSW/SCAE_Defense"" target=""_blank"">FrostbiteXSW</a>",2025-12-03 22:39:25
Evaluating the Adversarial Robustness of Adaptive Test-time Defenses,"Francesco Croce, Sven Gowal, Thomas Brunner, Evan Shelhamer, Matthias Hein, Taylan Cemgil",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.13711"" target=""_blank"">2202.13711</a>",,2025-12-03 22:39:25
MaMaDroid2,"Harel Berger, Chen Hajaj, Enrico Mariconti, Amit Dvir",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.13922"" target=""_blank"">2202.13922</a>",,2025-12-03 22:39:25
Improving Lexical Embeddings for Robust Question Answering,"Weiwen Xu, Bowei Zou, Wai Lam, Ai Ti Aw",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.13636"" target=""_blank"">2202.13636</a>",,2025-12-03 22:39:25
Robust Textual Embedding against Word-level Adversarial Attacks,"Yichen Yang, Xiaosen Wang, Kun He",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.13817"" target=""_blank"">2202.13817</a>",,2025-12-03 22:39:25
Artificial Intelligence for Cyber Security (AICS),"James Holt, Edward Raff, Ahmad Ridley, Dennis Ross, Arunesh Sinha, Diane Staheli, William Streilen, Milind Tambe, Yevgeniy Vorobeychik, Allan Wollaber",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.14010"" target=""_blank"">2202.14010</a>",,2025-12-03 22:39:25
Enhance transferability of adversarial examples with model architecture,"Mingyuan Fan, Wenzhong Guo, Shengxing Yu, Zuobin Ying, Ximeng Liu",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.13625"" target=""_blank"">2202.13625</a>",,2025-12-03 22:39:25
A Unified Wasserstein Distributional Robustness Framework for Adversarial Training,"Tuan Anh Bui, Trung Le, Quan Tran, He Zhao, Dinh Phung",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.13437"" target=""_blank"">2202.13437</a>",,2025-12-03 22:39:25
Robust Control of Partially Specified Boolean Networks,"Luboš Brim, Samuel Pastva, David Šafránek, Eva Šmijáková",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.13440"" target=""_blank"">2202.13440</a>",,2025-12-03 22:39:25
Adversarial robustness of sparse local Lipschitz predictors,"Ramchandran Muthukumar, Jeremias Sulam",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.13216"" target=""_blank"">2202.13216</a>",,2025-12-03 22:39:25
"Neuro-Inspired Deep Neural Networks with Sparse, Strong Activations","Metehan Cekic, Can Bakiskan, Upamanyu Madhow",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.13074"" target=""_blank"">2202.13074</a>",,2025-12-03 22:39:25
Automation of reversible steganographic coding with nonlinear discrete optimisation,Ching-Chun Chang,arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.13133"" target=""_blank"">2202.13133</a>",,2025-12-03 22:39:25
ARIA: Adversarially Robust Image Attribution for Content Provenance,"Maksym Andriushchenko, Xiaoyang Rebecca Li, Geoffrey Oxholm, Thomas Gittings, Tu Bui, Nicolas Flammarion, John Collomosse",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.12860"" target=""_blank"">2202.12860</a>",,2025-12-03 22:39:25
Projective Ranking-based GNN Evasion Attacks,"He Zhang, Xingliang Yuan, Chuan Zhou, Shirui Pan",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.12993"" target=""_blank"">2202.12993</a>",,2025-12-03 22:39:25
On the Effectiveness of Dataset Watermarking in Adversarial Settings,"Buse Gul Atli Tekgul, N. Asokan",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.12506"" target=""_blank"">2202.12506</a>",,2025-12-03 22:39:25
Poisoning Attacks and Defenses on Artificial Intelligence: A Survey,"Miguel A. Ramirez, Song-Kyoo Kim, Hussam Al Hamadi, Ernesto Damiani, Young-Ji Byon, Tae-Yeon Kim, Chung-Suk Cho, Chan Yeob Yeun",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.10276"" target=""_blank"">2202.10276</a>",,2025-12-03 22:39:25
Threading the Needle of On and Off-Manifold Value Functions for Shapley Explanations,"Chih-Kuan Yeh, Kuan-Yun Lee, Frederick Liu, Pradeep Ravikumar",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.11919"" target=""_blank"">2202.11919</a>",,2025-12-03 22:39:25
Backdoor Defense in Federated Learning Using Differential Testing and Outlier Detection,"Yein Kim, Huili Chen, Farinaz Koushanfar",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.11196"" target=""_blank"">2202.11196</a>",,2025-12-03 22:39:25
Synthetic Disinformation Attacks on Automated Fact Verification Systems,"Yibing Du, Antoine Bosselut, Christopher D. Manning",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.09381"" target=""_blank"">2202.09381</a>",,2025-12-03 22:39:25
Mitigating Closed-model Adversarial Examples with Bayesian Neural Modeling for Enhanced End-to-End Speech Recognition,"Chao-Han Huck Yang, Zeeshan Ahmed, Yile Gu, Joseph Szurley, Roger Ren, Linda Liu, Andreas Stolcke, Ivan Bulyko",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.08532"" target=""_blank"">2202.08532</a>",,2025-12-03 22:39:25
Developing Imperceptible Adversarial Patches to Camouflage Military Assets From Computer Vision Enabled Technologies,"Chris Wise, Jo Plested",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.08892"" target=""_blank"">2202.08892</a>",,2025-12-03 22:39:25
Fingerprinting Deep Neural Networks Globally via Universal Adversarial Perturbations,"Zirui Peng, Shaofeng Li, Guoxing Chen, Cheng Zhang, Haojin Zhu, Minhui Xue",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.08602"" target=""_blank"">2202.08602</a>",,2025-12-03 22:39:25
Understanding and Improving Graph Injection Attack by Promoting Unnoticeability,"Yongqiang Chen, Han Yang, Yonggang Zhang, Kaili Ma, Tongliang Liu, Bo Han, James Cheng",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.08057"" target=""_blank"">2202.08057</a>",,2025-12-03 22:39:25
Gradient Based Activations for Accurate Bias-Free Learning,"Vinod K Kurmi, Rishabh Sharma, Yash Vardhan Sharma, Vinay P. Namboodiri",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.10943"" target=""_blank"">2202.10943</a>",,2025-12-03 22:39:25
Unreasonable Effectiveness of Last Hidden Layer Activations,"Omer Faruk Tuna, Ferhat Ozgur Catak, M. Taner Eskil",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.07342"" target=""_blank"">2202.07342</a>",,2025-12-03 22:39:25
Exploring the Devil in Graph Spectral Domain for 3D Point Cloud Attacks,"Qianjiang Hu, Daizong Liu, Wei Hu",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.07261"" target=""_blank"">2202.07261</a>","<a href=""https://github.com/WoodwindHu/GSDA"" target=""_blank"">WoodwindHu</a>",2025-12-03 22:39:25
StratDef: Strategic Defense Against Adversarial Attacks in ML-based Malware Detection,"Aqib Rashid, Jose Such",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.07568"" target=""_blank"">2202.07568</a>",,2025-12-03 22:39:25
Random Walks for Adversarial Meshes,"Amir Belder, Gal Yefet, Ran Ben Izhak, Ayellet Tal",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.07453"" target=""_blank"">2202.07453</a>",,2025-12-03 22:39:25
Privacy Leakage of Adversarial Training Models in Federated Learning Systems,"Jingyang Zhang, Yiran Chen, Hai Li",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.10546"" target=""_blank"">2202.10546</a>","<a href=""https://github.com/zjysteven/PrivayAttack_AT_FL"" target=""_blank"">zjysteven</a>",2025-12-03 22:39:25
Generative Adversarial Network-Driven Detection of Adversarial Tasks in Mobile Crowdsensing,"Zhiyan Chen, Burak Kantarci",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.07802"" target=""_blank"">2202.07802</a>",,2025-12-03 22:39:25
Applying adversarial networks to increase the data efficiency and reliability of Self-Driving Cars,Aakash Kumar,arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.07815"" target=""_blank"">2202.07815</a>",,2025-12-03 22:39:25
Improving the repeatability of deep learning models with Monte Carlo dropout,"Andreanne Lemay, Katharina Hoebel, Christopher P. Bridge, Brian Befano, Sanjosé Silvia De, Diden Egemen, Ana Cecilia Rodriguez, Mark Schiffman, John Peter Campbell, Jayashree Kalpathy-Cramer",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.07562"" target=""_blank"">2202.07562</a>",,2025-12-03 22:39:25
Taking a Step Back with KCal: Multi-Class Kernel-Based Calibration for Deep Neural Networks,"Zhen Lin, Shubhendu Trivedi, Jimeng Sun",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.07679"" target=""_blank"">2202.07679</a>",,2025-12-03 22:39:25
Holistic Adversarial Robustness of Deep Learning Models,"Pin-Yu Chen, Sijia Liu",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.07201"" target=""_blank"">2202.07201</a>",,2025-12-03 22:39:25
Rethinking Machine Learning Robustness via its Link with the Out-of-Distribution Problem,"Abderrahmen Amich, Birhanu Eshete",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.08944"" target=""_blank"">2202.08944</a>",,2025-12-03 22:39:25
The Adversarial Security Mitigations of mmWave Beamforming Prediction Models using Defensive Distillation and Adversarial Retraining,"Murat Kuzlu, Ferhat Ozgur Catak, Umit Cali, Evren Catak, Ozgur Guler",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.08185"" target=""_blank"">2202.08185</a>",,2025-12-03 22:39:25
"Attacks, Defenses, And Tools: A Framework To Facilitate Robust AI/ML Systems","Mohamad Fazelnia, Igor Khokhlov, Mehdi Mirakhorli",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.09465"" target=""_blank"">2202.09465</a>",,2025-12-03 22:39:25
Critical Checkpoints for Evaluating Defence Models Against Adversarial Attack and Robustness,"Kanak Tekwani, Manojkumar Parmar",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.09039"" target=""_blank"">2202.09039</a>",,2025-12-03 22:39:25
Real-time Over-the-air Adversarial Perturbations for Digital Communications using Deep Neural Networks,"Roman A. Sandler, Peter K. Relich, Cloud Cho, Sean Holloway",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.11197"" target=""_blank"">2202.11197</a>",,2025-12-03 22:39:25
Robustness and Accuracy Could Be Reconcilable by (Proper) Definition,"Tianyu Pang, Min Lin, Xiao Yang, Jun Zhu, Shuicheng Yan",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.10103"" target=""_blank"">2202.10103</a>",,2025-12-03 22:39:25
Sparsity Winning Twice: Better Robust Generaliztion from More Efficient Training,"Tianlong Chen, Zhenyu Zhang, Pengjun Wang, Santosh Balachandra, Haoyu Ma, Zehao Wang, Zhangyang Wang",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.09844"" target=""_blank"">2202.09844</a>","<a href=""https://github.com/VITA-Group/Sparsity-Win-Robust-Generalization"" target=""_blank"">VITA-Group</a>",2025-12-03 22:39:25
Overparametrization improves robustness against adversarial attacks: A replication study,Ali Borji,arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.09735"" target=""_blank"">2202.09735</a>",,2025-12-03 22:39:25
Robust Reinforcement Learning as a Stackelberg Game via Adaptively-Regularized Adversarial Training,"Peide Huang, Mengdi Xu, Fei Fang, Ding Zhao",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.09514"" target=""_blank"">2202.09514</a>",,2025-12-03 22:39:25
Exploring Adversarially Robust Training for Unsupervised Domain Adaptation,"Shao-Yuan Lo, Vishal M. Patel",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.09300"" target=""_blank"">2202.09300</a>","<a href=""https://github.com/shaoyuanlo/ARTUDA"" target=""_blank"">shaoyuanlo</a>",2025-12-03 22:39:25
Learning Representations Robust to Group Shifts and Adversarial Examples,"Ming-Chang Chiu, Xuezhe Ma",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.09446"" target=""_blank"">2202.09446</a>",,2025-12-03 22:39:25
Cyber-Physical Defense in the Quantum Era,"Michel Barbeau, Joaquin Garcia-Alfaro",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.10354"" target=""_blank"">2202.10354</a>",,2025-12-03 22:39:25
Resurrecting Trust in Facial Recognition: Mitigating Backdoor Attacks in Face Recognition to Prevent Potential Privacy Breaches,"Reena Zelenkova, Jack Swallow, M. A. P. Chamikara, Dongxi Liu, Mohan Baruwal Chhetri, Seyit Camtepe, Marthie Grobler, Mahathir Almashor",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.10320"" target=""_blank"">2202.10320</a>",,2025-12-03 22:39:25
Data-Driven Mitigation of Adversarial Text Perturbation,"Rasika Bhalerao, Mohammad Al-Rubaie, Anand Bhaskar, Igor Markov",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.09483"" target=""_blank"">2202.09483</a>",,2025-12-03 22:39:25
Debiasing Backdoor Attack: A Benign Application of Backdoor Attack in Eliminating Data Bias,"Shangxi Wu, Qiuyang He, Yi Zhang, Jitao Sang",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.10582"" target=""_blank"">2202.10582</a>",,2025-12-03 22:39:25
Label-Smoothed Backdoor Attack,"Minlong Peng, Zidi Xiong, Mingming Sun, Ping Li",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.11203"" target=""_blank"">2202.11203</a>","<a href=""https://github.com/v-mipeng/LabelSmoothedAttack"" target=""_blank"">v-mipeng</a>",2025-12-03 22:39:25
Stochastic Perturbations of Tabular Features for Non-Deterministic Inference with Automunge,Nicholas J. Teague,arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.09248"" target=""_blank"">2202.09248</a>",,2025-12-03 22:39:25
Black-box Node Injection Attack for Graph Neural Networks,"Mingxuan Ju, Yujie Fan, Yanfang Ye, Liang Zhao",arXiv,2022-02,"<a href=""http://arxiv.org/abs/2202.09389"" target=""_blank"">2202.09389</a>","<a href=""https://github.com/jumxglhf/GA2C"" target=""_blank"">jumxglhf</a>",2025-12-03 22:39:25
Towards Adversarially Robust Deep Image Denoising,"Hanshu Yan, Jingfeng Zhang, Jiashi Feng, Masashi Sugiyama, Vincent Y. F. Tan",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.04397"" target=""_blank"">2201.04397</a>",,2025-12-03 22:39:25
Reconstructing Training Data with Informed Adversaries,"Borja Balle, Giovanni Cherubin, Jamie Hayes",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.04845"" target=""_blank"">2201.04845</a>",,2025-12-03 22:39:25
On Adversarial Robustness of Trajectory Prediction for Autonomous Vehicles,"Qingzhao Zhang, Shengtuo Hu, Jiachen Sun, Qi Alfred Chen, Z. Morley Mao",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.05057"" target=""_blank"">2201.05057</a>","<a href=""https://github.com/zqzqz/AdvTrajectoryPrediction"" target=""_blank"">zqzqz</a>",2025-12-03 22:39:25
Adversarially Robust Classification by Conditional Generative Model Inversion,"Mitra Alirezaei, Tolga Tasdizen",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.04733"" target=""_blank"">2201.04733</a>",,2025-12-03 22:39:25
Jamming Attacks on Federated Learning in Wireless Networks,"Yi Shi, Yalin E. Sagduyu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.05172"" target=""_blank"">2201.05172</a>",,2025-12-03 22:39:25
Similarity-based Gray-box Adversarial Attack Against Deep Face Recognition,"Hanrui Wang, Shuo Wang, Zhe Jin, Yandan Wang, Cunjian Chen, Massimo Tistarell",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.04011"" target=""_blank"">2201.04011</a>",,2025-12-03 22:39:25
Get your Foes Fooled: Proximal Gradient Split Learning for Defense against Model Inversion Attacks on IoMT data,"Sunder Ali Khowaja, Ik Hyun Lee, Kapal Dev, Muhammad Aslam Jarwar, Nawab Muhammad Faseeh Qureshi",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.04569"" target=""_blank"">2201.04569</a>",,2025-12-03 22:39:25
"Security for Machine Learning-based Software Systems: a survey of threats, practices and challenges","Huaming Chen, M. Ali Babar",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.04736"" target=""_blank"">2201.04736</a>",,2025-12-03 22:39:25
Quantifying Robustness to Adversarial Word Substitutions,"Yuting Yang, Pei Huang, FeiFei Ma, Juan Cao, Meishan Zhang, Jian Zhang, Jintao Li",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.03829"" target=""_blank"">2201.03829</a>",,2025-12-03 22:39:25
Evaluation of Neural Networks Defenses and Attacks using NDCG and Reciprocal Rank Metrics,"Haya Brama, Lihi Dery, Tal Grinshpoun",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.05071"" target=""_blank"">2201.05071</a>",,2025-12-03 22:39:25
IoTGAN: GAN Powered Camouflage Against Machine Learning Based IoT Device Identification,"Tao Hou, Tao Wang, Zhuo Lu, Yao Liu, Yalin Sagduyu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.03281"" target=""_blank"">2201.03281</a>",,2025-12-03 22:39:25
Evaluation of Four Black-box Adversarial Attacks and Some Query-efficient Improvement Analysis,Rui Wang,arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.05001"" target=""_blank"">2201.05001</a>",,2025-12-03 22:39:25
The curse of overparametrization in adversarial training: Precise analysis of robust generalization for random features regression,"Hamed Hassani, Adel Javanmard",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.05149"" target=""_blank"">2201.05149</a>",,2025-12-03 22:39:25
Unveiling Project-Specific Bias in Neural Code Models,"Zhiming Li, Yanzhou Li, Tianlin Li, Mengnan Du, Bozhi Wu, Yushi Cao, Junzhe Jiang, Yang Liu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.07381"" target=""_blank"">2201.07381</a>",,2025-12-03 22:39:25
"Security Orchestration, Automation, and Response Engine for Deployment of Behavioural Honeypots","Upendra Bartwal, Subhasis Mukhopadhyay, Rohit Negi, Sandeep Shukla",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.05326"" target=""_blank"">2201.05326</a>",,2025-12-03 22:39:25
CommonsenseQA 2,"Alon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bhagavatula, Yoav Goldberg, Yejin Choi, Jonathan Berant",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.05320"" target=""_blank"">2201.05320</a>",,2025-12-03 22:39:25
StolenEncoder: Stealing Pre-trained Encoders,"Yupei Liu, Jinyuan Jia, Hongbin Liu, Neil Zhenqiang Gong",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.05889"" target=""_blank"">2201.05889</a>",,2025-12-03 22:39:25
Interpretable and Effective Reinforcement Learning for Attacking against Graph-based Rumor Detection,"Yuefei Lyu, Xiaoyu Yang, Jiaxin Liu, Philip S. Yu, Sihong Xie, Xi Zhang",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.05819"" target=""_blank"">2201.05819</a>",,2025-12-03 22:39:25
Neighboring Backdoor Attacks on Graph Convolutional Network,"Liang Chen, Qibiao Peng, Jintang Li, Yang Liu, Jiawei Chen, Yong Li, Zibin Zheng",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.06202"" target=""_blank"">2201.06202</a>",,2025-12-03 22:39:25
Adversarial Machine Learning Threat Analysis in Open Radio Access Networks,"Ron Bitton, Dan Avraham, Eitan Klevansky, Dudu Mimran, Oleg Brodt, Heiko Lehmann, Yuval Elovici, Asaf Shabtai",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.06093"" target=""_blank"">2201.06093</a>",,2025-12-03 22:39:25
ALA: Naturalness-aware Adversarial Lightness Attack,"Yihao Huang, Liangru Sun, Qing Guo, Felix Juefei-Xu, Jiayi Zhu, Jincao Feng, Yang Liu, Geguang Pu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.06070"" target=""_blank"">2201.06070</a>",,2025-12-03 22:39:25
Fooling the Eyes of Autonomous Vehicles: Robust Physical Adversarial Examples Against Traffic Sign Recognition Systems,"Wei Jia, Zhaojun Lu, Haichun Zhang, Zhenglin Liu, Jie Wang, Gang Qu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.06192"" target=""_blank"">2201.06192</a>",,2025-12-03 22:39:25
AugLy: Data Augmentations for Robustness,"Zoe Papakipos, Joanna Bitton",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.06494"" target=""_blank"">2201.06494</a>","<a href=""https://github.com/facebookresearch/AugLy"" target=""_blank"">facebookresearch</a>",2025-12-03 22:39:25
Cyberbullying Classifiers are Sensitive to Model-Agnostic Perturbations,"Chris Emmery, Ákos Kádár, Grzegorz Chrupała, Walter Daelemans",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.06384"" target=""_blank"">2201.06384</a>","<a href=""https://github.com/cmry/augtox"" target=""_blank"">cmry</a>",2025-12-03 22:39:25
Masked Faces with Faced Masks,"Jiayi Zhu, Qing Guo, Felix Juefei-Xu, Yihao Huang, Yang Liu, Geguang Pu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.06427"" target=""_blank"">2201.06427</a>",,2025-12-03 22:39:25
Lung Swapping Autoencoder: Learning a Disentangled Structure-texture Representation of Chest Radiographs,"Lei Zhou, Joseph Bae, Huidong Liu, Gagandeep Singh, Jeremy Green, Amit Gupta, Dimitris Samaras, Prateek Prasanna",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.07344"" target=""_blank"">2201.07344</a>",,2025-12-03 22:39:25
Secure IoT Routing: Selective Forwarding Attacks and Trust-based Defenses in RPL Network,"Jun Jiang, Yuhong Liu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.06937"" target=""_blank"">2201.06937</a>",,2025-12-03 22:39:25
GMFIM: A Generative Mask-guided Facial Image Manipulation Model for Privacy Preservation,"Mohammad Hossein Khojaste, Nastaran Moradzadeh Farid, Ahmad Nickabadi",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.03353"" target=""_blank"">2201.03353</a>",,2025-12-03 22:39:25
Reciprocal Adversarial Learning for Brain Tumor Segmentation: A Solution to BraTS Challenge 2021 Segmentation Task,"Himashi Peiris, Zhaolin Chen, Gary Egan, Mehrtash Harandi",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.03777"" target=""_blank"">2201.03777</a>","<a href=""https://github.com/himashi92/vizviva_brats_2021"" target=""_blank"">himashi92</a>",2025-12-03 22:39:25
Repairing Adversarial Texts through Perturbation,"Guoliang Dong, Jingyi Wang, Jun Sun, Sudipta Chattopadhyay, Xinyu Wang, Ting Dai, Jie Shi, Jin Song Dong",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.02504"" target=""_blank"">2201.02504</a>",,2025-12-03 22:39:25
Towards Group Robustness in the presence of Partial Group Labels,"Vishnu Suresh Lokhande, Kihyuk Sohn, Jinsung Yoon, Madeleine Udell, Chen-Yu Lee, Tomas Pfister",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.03668"" target=""_blank"">2201.03668</a>",,2025-12-03 22:39:25
Rethink Stealthy Backdoor Attacks in Natural Language Processing,"Lingfeng Shen, Haiyun Jiang, Lemao Liu, Shuming Shi",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.02993"" target=""_blank"">2201.02993</a>",,2025-12-03 22:39:25
A General Framework for Evaluating Robustness of Combinatorial Optimization Solvers on Graphs,"Han Lu, Zenan Li, Runzhong Wang, Qibing Ren, Junchi Yan, Xiaokang Yang",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.00402"" target=""_blank"">2201.00402</a>",,2025-12-03 22:39:25
MetaV: A Meta-Verifier Approach to Task-Agnostic Model Fingerprinting,"Xudong Pan, Yifan Yan, Mi Zhang, Min Yang",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.07391"" target=""_blank"">2201.07391</a>",,2025-12-03 22:39:25
Adversarial Attack via Dual-Stage Network Erosion,"Yexin Duan, Junhua Zou, Xingyu Zhou, Wu Zhang, Jin Zhang, Zhisong Pan",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.00097"" target=""_blank"">2201.00097</a>",,2025-12-03 22:39:25
Generating Adversarial Samples For Training Wake-up Word Detection Systems Against Confusing Words,"Haoxu Wang, Yan Jia, Zeqing Zhao, Xuyang Wang, Junjie Wang, Ming Li",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.00167"" target=""_blank"">2201.00167</a>",,2025-12-03 22:39:25
Revisiting Neuron Coverage Metrics and Quality of Deep Neural Networks,"Zhou Yang, Jieke Shi, Muhammad Hilmi Asyrofi, David Lo",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.00191"" target=""_blank"">2201.00191</a>",,2025-12-03 22:39:25
Rethinking Feature Uncertainty in Stochastic Neural Networks for Adversarial Robustness,"Hao Yang, Min Wang, Zhengfei Yu, Yun Zhou",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.00148"" target=""_blank"">2201.00148</a>",,2025-12-03 22:39:25
On Sensitivity of Deep Learning Based Text Classification Algorithms to Practical Input Perturbations,"Aamir Miyajiwala, Arnav Ladkat, Samiksha Jagadale, Raviraj Joshi",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.00318"" target=""_blank"">2201.00318</a>",,2025-12-03 22:39:25
Actor-Critic Network for Q&A in an Adversarial Environment,Bejan Sadeghian,arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.00455"" target=""_blank"">2201.00455</a>",,2025-12-03 22:39:25
Revisiting PGD Attacks for Stability Analysis of Large-Scale Nonlinear Systems and Perception-Based Control,"Aaron Havens, Darioush Keivan, Peter Seiler, Geir Dullerud, Bin Hu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.00801"" target=""_blank"">2201.00801</a>",,2025-12-03 22:39:25
DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection,"Phillip Rieger, Thien Duc Nguyen, Markus Miettinen, Ahmad-Reza Sadeghi",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.00763"" target=""_blank"">2201.00763</a>",,2025-12-03 22:39:25
Compression-Resistant Backdoor Attack against Deep Neural Networks,"Mingfu Xue, Xin Wang, Shichang Sun, Yushu Zhang, Jian Wang, Weiqiang Liu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.00672"" target=""_blank"">2201.00672</a>",,2025-12-03 22:39:25
Corrupting Data to Remove Deceptive Perturbation: Using Preprocessing Method to Improve System Robustness,"Hieu Le, Hans Walker, Dung Tran, Peter Chin",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.01399"" target=""_blank"">2201.01399</a>",,2025-12-03 22:39:25
Towards Understanding Quality Challenges of the Federated Learning for Neural Networks: A First Look from the Lens of Robustness,"Amin Eslami Abyane, Derui Zhu, Roberto Souza, Lei Ma, Hadi Hemmati",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.01409"" target=""_blank"">2201.01409</a>",,2025-12-03 22:39:25
On the Minimal Adversarial Perturbation for Deep Neural Networks with Provable Estimation Error,"Fabio Brau, Giulio Rossolini, Alessandro Biondi, Giorgio Buttazzo",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.01235"" target=""_blank"">2201.01235</a>",,2025-12-03 22:39:25
Towards Understanding and Harnessing the Effect of Image Transformation in Adversarial Detection,"Hui Liu, Bo Zhao, Yuefeng Peng, Weidong Li, Peng Liu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.01080"" target=""_blank"">2201.01080</a>",,2025-12-03 22:39:25
Towards Transferable Unrestricted Adversarial Examples with Minimum Changes,"Fangcheng Liu, Chao Zhang, Hongyang Zhang",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.01102"" target=""_blank"">2201.01102</a>","<a href=""https://github.com/Equationliu/GA-Attack"" target=""_blank"">Equationliu</a>",2025-12-03 22:39:25
Adversarial Robustness in Cognitive Radio Networks,Makan Zamanipour,arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.01842"" target=""_blank"">2201.01842</a>",,2025-12-03 22:39:25
ROOM: Adversarial Machine Learning Attacks Under Real-Time Constraints,"Amira Guesmi, Khaled N. Khasawneh, Nael Abu-Ghazaleh, Ihsen Alouani",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.01621"" target=""_blank"">2201.01621</a>",,2025-12-03 22:39:25
On the Real-World Adversarial Robustness of Real-Time Semantic Segmentation Models for Autonomous Driving,"Giulio Rossolini, Federico Nesti, Gianluca D'Amico, Saasha Nair, Alessandro Biondi, Giorgio Buttazzo",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.01850"" target=""_blank"">2201.01850</a>",,2025-12-03 22:39:25
Efficient Global Optimization of Two-Layer ReLU Networks: Quadratic-Time Algorithms and Adversarial Training,"Yatong Bai, Tanmay Gautam, Somayeh Sojoudi",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.01965"" target=""_blank"">2201.01965</a>",,2025-12-03 22:39:25
Learning to be adversarially robust and differentially private,"Jamie Hayes, Borja Balle, M. Pawan Kumar",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.02265"" target=""_blank"">2201.02265</a>",,2025-12-03 22:39:25
PAEG: Phrase-level Adversarial Example Generation for Neural Machine Translation,"Juncheng Wan, Jian Yang, Shuming Ma, Dongdong Zhang, Weinan Zhang, Yong Yu, Zhoujun Li",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.02009"" target=""_blank"">2201.02009</a>",,2025-12-03 22:39:25
Negative Evidence Matters in Interpretable Histology Image Classification,"Soufiane Belharbi, Marco Pedersoli, Ismail Ben Ayed, Luke McCaffrey, Eric Granger",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.02445"" target=""_blank"">2201.02445</a>",,2025-12-03 22:39:25
Asymptotic Security using Bayesian Defense Mechanisms with Application to Cyber Deception,"Hampei Sasahara, Henrik Sandberg",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.02351"" target=""_blank"">2201.02351</a>",,2025-12-03 22:39:25
iDECODe: In-distribution Equivariance for Conformal Out-of-distribution Detection,"Ramneet Kaur, Susmit Jha, Anirban Roy, Sangdon Park, Edgar Dobriban, Oleg Sokolsky, Insup Lee",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.02331"" target=""_blank"">2201.02331</a>",,2025-12-03 22:39:25
PocketNN: Integer-only Training and Inference of Neural Networks via Direct Feedback Alignment and Pocket Activations in Pure C++,"Jaewoo Song, Fangzhen Lin",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.02863"" target=""_blank"">2201.02863</a>",,2025-12-03 22:39:25
LoMar: A Local Defense Against Poisoning Attack on Federated Learning,"Xingyu Li, Zhe Qu, Shangqing Zhao, Bo Tang, Zhuo Lu, Yao Liu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.02873"" target=""_blank"">2201.02873</a>",,2025-12-03 22:39:25
Privacy-aware Early Detection of COVID-19 through Adversarial Training,"Omid Rohanian, Samaneh Kouchaki, Andrew Soltan, Jenny Yang, Morteza Rohanian, Yang Yang, David Clifton",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.03004"" target=""_blank"">2201.03004</a>",,2025-12-03 22:39:25
A Retrospective and Futurespective of Rowhammer Attacks and Defenses on DRAM,"Zhi Zhang, Jiahao Qi, Yueqiang Cheng, Shijie Jiang, Yiyang Lin, Yansong Gao, Surya Nepal, Yi Zou",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.02986"" target=""_blank"">2201.02986</a>",,2025-12-03 22:39:25
Adversarial vulnerability of powerful near out-of-distribution detection,Stanislav Fort,arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.07012"" target=""_blank"">2201.07012</a>","<a href=""https://github.com/stanislavfort/adversaries_to_OOD_detection"" target=""_blank"">stanislavfort</a>",2025-12-03 22:39:25
How to Backdoor HyperNetwork in Personalized Federated Learning? (13%),"Phung Lai, NhatHai Phan, Issa Khalil, Abdallah Khreishah, Xintao Wu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.07063"" target=""_blank"">2201.07063</a>",,2025-12-03 22:39:25
Can't Steal? Cont-Steal! Contrastive Stealing Attacks Against Image Encoders,"Zeyang Sha, Xinlei He, Ning Yu, Michael Backes, Yang Zhang",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.07513"" target=""_blank"">2201.07513</a>",,2025-12-03 22:39:25
Robustness of Deep Recommendation Systems to Untargeted Interaction Perturbations,"Sejoon Oh, Srijan Kumar",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.12686"" target=""_blank"">2201.12686</a>",,2025-12-03 22:39:25
Boosting 3D Adversarial Attacks with Attacking On Frequency,"Binbin Liu, Jinlai Zhang, Lyujie Chen, Jihong Zhu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.10937"" target=""_blank"">2201.10937</a>",,2025-12-03 22:39:25
CacheFX: A Framework for Evaluating Cache Security,"Daniel Genkin, William Kosasih, Fangfei Liu, Anna Trikalinou, Thomas Unterluggauer, Yuval Yarom",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.11377"" target=""_blank"">2201.11377</a>",,2025-12-03 22:39:25
SSLGuard: A Watermarking Scheme for Self-supervised Learning Pre-trained Encoders,"Tianshuo Cong, Xinlei He, Yang Zhang",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.11692"" target=""_blank"">2201.11692</a>",,2025-12-03 22:39:25
Vision Checklist: Towards Testable Error Analysis of Image Models to Help System Designers Interrogate Model Capabilities,"Xin Du, Benedicte Legastelois, Bhargavi Ganesh, Ajitha Rajan, Hana Chockler, Vaishak Belle, Stuart Anderson, Subramanian Ramamoorthy",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.11674"" target=""_blank"">2201.11674</a>",,2025-12-03 22:39:25
Beyond ImageNet Attack: Towards Crafting Adversarial Examples for Black-box Domains,"Qilong Zhang, Xiaodan Li, Yuefeng Chen, Jingkuan Song, Lianli Gao, Yuan He, Hui Xue",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.11528"" target=""_blank"">2201.11528</a>","<a href=""https://github.com/qilong-zhang/Beyond-ImageNet-Attack"" target=""_blank"">qilong-zhang</a>",2025-12-03 22:39:25
Toward Training at ImageNet Scale with Differential Privacy,"Alexey Kurakin, Shuang Song, Steve Chien, Roxana Geambasu, Andreas Terzis, Abhradeep Thakurta",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.12328"" target=""_blank"">2201.12328</a>","<a href=""https://github.com/google-research/dp-imagenet"" target=""_blank"">google-research</a>",2025-12-03 22:39:25
Backdoors Stuck At The Frontdoor: Multi-Agent Backdoor Attacks That Backfire,"Siddhartha Datta, Nigel Shadbolt",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.12211"" target=""_blank"">2201.12211</a>",,2025-12-03 22:39:25
Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks,"Lukas Struppek, Dominik Hintersdorf, Antonio De Almeida Correia, Antonia Adler, Kristian Kersting",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.12179"" target=""_blank"">2201.12179</a>",,2025-12-03 22:39:25
Benchmarking Robustness of 3D Point Cloud Recognition Against Common Corruptions,"Jiachen Sun, Qingzhao Zhang, Bhavya Kailkhura, Zhiding Yu, Chaowei Xiao, Z. Morley Mao",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.12296"" target=""_blank"">2201.12296</a>","<a href=""https://github.com/jiachens/ModelNet40-C"" target=""_blank"">jiachens</a>",2025-12-03 22:39:25
Certifying Model Accuracy under Distribution Shifts,"Aounon Kumar, Alexander Levine, Tom Goldstein, Soheil Feizi",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.12440"" target=""_blank"">2201.12440</a>",,2025-12-03 22:39:25
Feature Visualization within an Automated Design Assessment leveraging Explainable Artificial Intelligence Methods,"Raoul Schönhof, Artem Werner, Jannes Elstner, Boldizsar Zopcsak, Ramez Awad, Marco Huber",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.12107"" target=""_blank"">2201.12107</a>",,2025-12-03 22:39:25
Adversarial Examples for Good: Adversarial Examples Guided Imbalanced Learning,"Jie Zhang, Lei Zhang, Gang Li, Chao Wu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.12356"" target=""_blank"">2201.12356</a>",,2025-12-03 22:39:25
Coordinated Attacks against Contextual Bandits: Fundamental Limits and Defense Mechanisms,"Jeongyeol Kwon, Yonathan Efroni, Constantine Caramanis, Shie Mannor",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.12700"" target=""_blank"">2201.12700</a>",,2025-12-03 22:39:25
Scale-Invariant Adversarial Attack for Evaluating and Enhancing Adversarial Defenses,"Mengting Xu, Tao Zhang, Zhongnian Li, Daoqiang Zhang",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.12527"" target=""_blank"">2201.12527</a>",,2025-12-03 22:39:25
Autonomous Cyber Defense Introduces Risk: Can We Manage the Risk? (2%),"Alexandre K. Ligo, Alexander Kott, Igor Linkov",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.11148"" target=""_blank"">2201.11148</a>",,2025-12-03 22:39:25
GARNET: Reduced-Rank Topology Learning for Robust and Scalable Graph Neural Networks,"Chenhui Deng, Xiuyu Li, Zhuo Feng, Zhiru Zhang",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.12741"" target=""_blank"">2201.12741</a>",,2025-12-03 22:39:25
Improving Corruption and Adversarial Robustness by Enhancing Weak Subnets,"Yong Guo, David Stutz, Bernt Schiele",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.12765"" target=""_blank"">2201.12765</a>",,2025-12-03 22:39:25
Securing Federated Sensitive Topic Classification against Poisoning Attacks,"Tianyue Chu, Alvaro Garcia-Recuero, Costas Iordanou, Georgios Smaragdakis, Nikolaos Laoutaris",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.13086"" target=""_blank"">2201.13086</a>",,2025-12-03 22:39:25
Few-Shot Backdoor Attacks on Visual Object Tracking,"Yiming Li, Haoxiang Zhong, Xingjun Ma, Yong Jiang, Shu-Tao Xia",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.13178"" target=""_blank"">2201.13178</a>",,2025-12-03 22:39:25
UQGAN: A Unified Model for Uncertainty Quantification of Deep Classifiers trained via Conditional GANs,"Philipp Oberdiek, Gernot A. Fink, Matthias Rottmann",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.13279"" target=""_blank"">2201.13279</a>",,2025-12-03 22:39:25
Learning Robust Representation through Graph Adversarial Contrastive Learning,"Jiayan Guo, Shangyang Li, Yue Zhao, Yan Zhang",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.13025"" target=""_blank"">2201.13025</a>",,2025-12-03 22:39:25
On the Robustness of Quality Measures for GANs,"Motasem Alfarra, Juan C. Pérez, Anna Frühstück, Philip H. S. Torr, Peter Wonka, Bernard Ghanem",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.13019"" target=""_blank"">2201.13019</a>",,2025-12-03 22:39:25
Imperceptible and Multi-channel Backdoor Attack against Deep Neural Networks,"Mingfu Xue, Shifeng Ni, Yinghao Wu, Yushu Zhang, Jian Wang, Weiqiang Liu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.13164"" target=""_blank"">2201.13164</a>",,2025-12-03 22:39:25
GADoT: GAN-based Adversarial Training for Robust DDoS Attack Detection,"Maged Abdelaty, Sandra Scott-Hayward, Roberto Doriguzzi-Corin, Domenico Siracusa",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.13102"" target=""_blank"">2201.13102</a>",,2025-12-03 22:39:25
Can Adversarial Training Be Manipulated By Non-Robust Features? (98%),"Lue Tao, Lei Feng, Hongxin Wei, Jinfeng Yi, Sheng-Jun Huang, Songcan Chen",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.13329"" target=""_blank"">2201.13329</a>",,2025-12-03 22:39:25
Boundary Defense Against Black-box Adversarial Attacks,"Manjushree B. Aithal, Xiaohua Li",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.13444"" target=""_blank"">2201.13444</a>",,2025-12-03 22:39:25
Adversarial Robustness in Deep Learning: Attacks on Fragile Neurons,"Chandresh Pravin, Ivan Martino, Giuseppe Nicosia, Varun Ojha",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.12347"" target=""_blank"">2201.12347</a>",,2025-12-03 22:39:25
Unsupervised Graph Poisoning Attack via Contrastive Loss Back-propagation,"Sixiao Zhang, Hongxu Chen, Xiangguo Sun, Yicong Li, Guandong Xu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.07986"" target=""_blank"">2201.07986</a>",,2025-12-03 22:39:25
How Robust are Discriminatively Trained Zero-Shot Learning Models? (98%),"Mehmet Kerim Yucel, Ramazan Gokberk Cinbis, Pinar Duygulu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.10972"" target=""_blank"">2201.10972</a>",,2025-12-03 22:39:25
TPC: Transformation-Specific Smoothing for Point Cloud Models,"Wenda Chu, Linyi Li, Bo Li",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.12733"" target=""_blank"">2201.12733</a>",,2025-12-03 22:39:25
Automatic detection of access control vulnerabilities via API specification processing,"Alexander Barabanov, Denis Dergunov, Denis Makrushin, Aleksey Teplov",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.10833"" target=""_blank"">2201.10833</a>",,2025-12-03 22:39:25
Toward Enhanced Robustness in Unsupervised Graph Representation Learning: A Graph Information Bottleneck Perspective,"Jihong Wang, Minnan Luo, Jundong Li, Ziqi Liu, Jun Zhou, Qinghua Zheng",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08557"" target=""_blank"">2201.08557</a>",,2025-12-03 22:39:25
DeepGalaxy: Testing Neural Network Verifiers via Two-Dimensional Input Space Exploration,"Xuan Xie, Fuyuan Zhang",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08087"" target=""_blank"">2201.08087</a>",,2025-12-03 22:39:25
Black-box Prompt Learning for Pre-trained Language Models,"Shizhe Diao, Zhichao Huang, Ruijia Xu, Xuechun Li, Yong Lin, Xiao Zhou, Tong Zhang",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08531"" target=""_blank"">2201.08531</a>","<a href=""https://github.com/shizhediao/Black-Box-Prompt-Learning"" target=""_blank"">shizhediao</a>",2025-12-03 22:39:25
Virtual Adversarial Training for Semi-supervised Breast Mass Classification,"Xuxin Chen, Ximin Wang, Ke Zhang, Kar-Ming Fung, Theresa C. Thai, Kathleen Moore, Robert S. Mannel, Hong Liu, Bin Zheng, Yuchen Qiu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.10675"" target=""_blank"">2201.10675</a>",,2025-12-03 22:39:25
Steerable Pyramid Transform Enables Robust Left Ventricle Quantification,"Xiangyang Zhu, Kede Ma, Wufeng Xue",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08388"" target=""_blank"">2201.08388</a>",,2025-12-03 22:39:25
Adversarial Jamming for a More Effective Constellation Attack,"Haidong Xie, Yizhou Xu, Yuanqing Chen, Nan Ji, Shuai Yuan, Naijin Liu, Xueshuang Xiang",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08052"" target=""_blank"">2201.08052</a>",,2025-12-03 22:39:25
Post-Training Detection of Backdoor Attacks for Two-Class and Multi-Attack Scenarios,"Zhen Xiang, David J. Miller, George Kesidis",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08474"" target=""_blank"">2201.08474</a>",,2025-12-03 22:39:25
Low-Interception Waveform: To Prevent the Recognition of Spectrum Waveform Modulation via Adversarial Examples,"Haidong Xie, Jia Tan, Xiaoying Zhang, Nan Ji, Haihua Liao, Zuguo Yu, Xueshuang Xiang, Naijin Liu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08731"" target=""_blank"">2201.08731</a>",,2025-12-03 22:39:25
Cheating Automatic Short Answer Grading: On the Adversarial Usage of Adjectives and Adverbs,"Anna Filighera, Sebastian Ochs, Tim Steuer, Thomas Tregel",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08318"" target=""_blank"">2201.08318</a>",,2025-12-03 22:39:25
TextHacker: Learning based Hybrid Local Search Algorithm for Text Hard-label Adversarial Attack,"Zhen Yu, Xiaosen Wang, Wanxiang Che, Kun He",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08193"" target=""_blank"">2201.08193</a>",,2025-12-03 22:39:25
The Many Faces of Adversarial Risk,"Muni Sreenivas Pydi, Varun Jog",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08956"" target=""_blank"">2201.08956</a>",,2025-12-03 22:39:25
Identifying Adversarial Attacks on Text Classifiers,"Zhouhang Xie, Jonathan Brophy, Adam Noack, Wencong You, Kalyani Asthana, Carter Perkins, Sabrina Reis, Sameer Singh, Daniel Lowd",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08555"" target=""_blank"">2201.08555</a>",,2025-12-03 22:39:25
Dangerous Cloaking: Natural Trigger based Backdoor Attacks on Object Detectors in the Physical World,"Hua Ma, Yinshan Li, Yansong Gao, Alsharif Abuadbba, Zhi Zhang, Anmin Fu, Hyoungshick Kim, Said F. Al-Sarawi, Nepal Surya, Derek Abbott",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08619"" target=""_blank"">2201.08619</a>",,2025-12-03 22:39:25
The Security of Deep Learning Defences for Medical Imaging,"Moshe Levy, Guy Amit, Yuval Elovici, Yisroel Mirsky",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08661"" target=""_blank"">2201.08661</a>",,2025-12-03 22:39:25
"Survey on Federated Learning Threats: concepts, taxonomy on attacks and defences, experimental study and challenges","Nuria Rodríguez-Barroso, Daniel Jiménez López, M. Victoria Luzón, Francisco Herrera, Eugenio Martínez-Cámara",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08135"" target=""_blank"">2201.08135</a>",,2025-12-03 22:39:25
Natural Attack for Pre-trained Models of Code,"Zhou Yang, Jieke Shi, Junda He, David Lo",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08698"" target=""_blank"">2201.08698</a>",,2025-12-03 22:39:25
Efficient and Robust Classification for Sparse Attacks,"Mark Beliaev, Payam Delgosha, Hamed Hassani, Ramtin Pedarsani",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.09369"" target=""_blank"">2201.09369</a>",,2025-12-03 22:39:25
SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training,"Wenyong Huang, Zhenhe Zhang, Yu Ting Yeung, Xin Jiang, Qun Liu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.10207"" target=""_blank"">2201.10207</a>",,2025-12-03 22:39:25
What You See is Not What the Network Infers: Detecting Adversarial Examples Based on Semantic Contradiction,"Yijun Yang, Ruiyuan Gao, Yu Li, Qiuxia Lai, Qiang Xu",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.09650"" target=""_blank"">2201.09650</a>",,2025-12-03 22:39:25
Identifying a Training-Set Attack's Target Using Renormalized Influence Estimation,"Zayd Hammoudeh, Daniel Lowd",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.10055"" target=""_blank"">2201.10055</a>","<a href=""https://github.com/ZaydH/target_identification"" target=""_blank"">ZaydH</a>",2025-12-03 22:39:25
Backdoor Defense with Machine Unlearning,"Yang Liu, Mingyuan Fan, Cen Chen, Ximeng Liu, Zhuo Ma, Li Wang, Jianfeng Ma",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.09538"" target=""_blank"">2201.09538</a>",,2025-12-03 22:39:25
On the Complexity of Attacking Elliptic Curve Based Authentication Chips,"Ievgen Kabin, Zoya Dyka, Dan Klann, Jan Schaeffner, Peter Langendoerfer",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.09631"" target=""_blank"">2201.09631</a>",,2025-12-03 22:39:25
Attacks and Defenses for Free-Riders in Multi-Discriminator GAN,"Zilong Zhao, Jiyue Huang, Stefanie Roos, Lydia Y. Chen",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.09967"" target=""_blank"">2201.09967</a>",,2025-12-03 22:39:25
Are Your Sensitive Attributes Private? Novel Model Inversion Attribute Inference Attacks on Classification Models,"Shagufta Mehnaz, Sayanton V. Dibbo, Ehsanul Kabir, Ninghui Li, Elisa Bertino",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.09370"" target=""_blank"">2201.09370</a>",,2025-12-03 22:39:25
Increasing the Cost of Model Extraction with Calibrated Proof of Work,"Adam Dziedzic, Muhammad Ahmad Kaleem, Yu Shen Lu, Nicolas Papernot",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.09243"" target=""_blank"">2201.09243</a>",,2025-12-03 22:39:25
Parallel Rectangle Flip Attack: A Query-based Black-box Attack against Object Detection,"Siyuan Liang, Baoyuan Wu, Yanbo Fan, Xingxing Wei, Xiaochun Cao",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.08970"" target=""_blank"">2201.08970</a>",,2025-12-03 22:39:25
Robust Unpaired Single Image Super-Resolution of Faces,"Saurabh Goswami, Rajagopalan A. N",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.09109"" target=""_blank"">2201.09109</a>",,2025-12-03 22:39:25
On the Robustness of Counterfactual Explanations to Adverse Perturbations,"Marco Virgolin, Saverio Fracaros",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.09051"" target=""_blank"">2201.09051</a>","<a href=""https://github.com/marcovirgolin/robust-counterfactuals"" target=""_blank"">marcovirgolin</a>",2025-12-03 22:39:25
Class-Aware Adversarial Transformers for Medical Image Segmentation,"Chenyu You, Ruihan Zhao, Fenglin Liu, Siyuan Dong, Sandeep Chinchali, Ufuk Topcu, Lawrence Staib, James S. Duncan",arXiv,2022-01,"<a href=""http://arxiv.org/abs/2201.10737"" target=""_blank"">2201.10737</a>",,2025-12-03 22:39:25
RamBoAttack: A Robust Query Efficient Deep Neural Network Decision Exploit,"Viet Quoc Vo, Ehsan Abbasnejad, Damith C. Ranasinghe",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.05282"" target=""_blank"">2112.05282</a>",,2025-12-03 22:39:25
On visual self-supervision and its effect on model robustness,"Michal Kucer, Diane Oyen, Garrett Kenyon",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.04367"" target=""_blank"">2112.04367</a>",,2025-12-03 22:39:25
Spinning Language Models: Risks of Propaganda-As-A-Service and Countermeasures,"Eugene Bagdasaryan, Vitaly Shmatikov",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.05224"" target=""_blank"">2112.05224</a>",,2025-12-03 22:39:25
Robustness Certificates for Implicit Neural Networks: A Mixed Monotone Contractive Approach,"Saber Jafarpour, Matthew Abate, Alexander Davydov, Francesco Bullo, Samuel Coogan",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.05310"" target=""_blank"">2112.05310</a>",,2025-12-03 22:39:25
PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures,"Dan Hendrycks, Andy Zou, Mantas Mazeika, Leonard Tang, Dawn Song, Jacob Steinhardt",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.05135"" target=""_blank"">2112.05135</a>",,2025-12-03 22:39:25
Are We There Yet? Timing and Floating-Point Attacks on Differential Privacy Systems,"Jiankai Jin, Eleanor McMurtry, Benjamin I. P. Rubinstein, Olga Ohrimenko",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.05307"" target=""_blank"">2112.05307</a>",,2025-12-03 22:39:25
3D-VField: Learning to Adversarially Deform Point Clouds for Robust 3D Object Detection,"Alexander Lehner, Stefano Gasperini, Alvaro Marcos-Ramiro, Michael Schmidt, Mohammad-Ali Nikouei Mahani, Nassir Navab, Benjamin Busam, Federico Tombari",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.04764"" target=""_blank"">2112.04764</a>","<a href=""https://crashd-cars.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Segment and Complete: Defending Object Detectors against Adversarial Patch Attacks with Robust Patch Detection,"Jiang Liu, Alexander Levine, Chun Pong Lau, Rama Chellappa, Soheil Feizi",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.04532"" target=""_blank"">2112.04532</a>",,2025-12-03 22:39:25
"Vehicle trajectory prediction works, but not everywhere","Mohammadhossein Bahari, Saeed Saadatnejad, Ahmad Rahimi, Mohammad Shaverdikondori, Mohammad Shahidzadeh, Seyed-Mohsen Moosavi-Dezfooli, Alexandre Alahi",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.03909"" target=""_blank"">2112.03909</a>","<a href=""https://s-attack.github.io/"" target=""_blank"">s-attack.github.io</a>",2025-12-03 22:39:25
SNEAK: Synonymous Sentences-Aware Adversarial Attack on Natural Language Video Localization,"Wenbo Gou, Wen Shi, Jian Lou, Lijie Huang, Pan Zhou, Ruixuan Li",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.04154"" target=""_blank"">2112.04154</a>",,2025-12-03 22:39:25
Revisiting Contrastive Learning through the Lens of Neighborhood Component Analysis: an Integrated Framework,"Ching-Yun Ko, Jeet Mohapatra, Sijia Liu, Pin-Yu Chen, Luca Daniel, Lily Weng",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.04468"" target=""_blank"">2112.04468</a>",,2025-12-03 22:39:25
Saliency Diversified Deep Ensemble for Robustness to Adversaries,"Alex Bogun, Dimche Kostadinov, Damian Borth",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.03615"" target=""_blank"">2112.03615</a>",,2025-12-03 22:39:25
Presentation Attack Detection Methods based on Gaze Tracking and Pupil Dynamic: A Comprehensive Survey,Jalil Nourmohammadi Khiarak,arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.04038"" target=""_blank"">2112.04038</a>",,2025-12-03 22:39:25
Lightning: Striking the Secure Isolation on GPU Clouds with Transient Hardware Faults,"Rihui Sun, Pefei Qiu, Yongqiang Lyu, Donsheng Wang, Jiang Dong, Gang Qu",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.03662"" target=""_blank"">2112.03662</a>",,2025-12-03 22:39:25
Membership Inference Attacks From First Principles,"Nicholas Carlini, Steve Chien, Milad Nasr, Shuang Song, Andreas Terzis, Florian Tramer",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.03570"" target=""_blank"">2112.03570</a>",,2025-12-03 22:39:25
Training Deep Models to be Explained with Fewer Examples,"Tomoharu Iwata, Yuya Yoshikawa",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.03508"" target=""_blank"">2112.03508</a>",,2025-12-03 22:39:25
Mutual Adversarial Training: Learning together is better than going alone,"Jiang Liu, Chun Pong Lau, Hossein Souri, Soheil Feizi, Rama Chellappa",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.05005"" target=""_blank"">2112.05005</a>",,2025-12-03 22:39:25
PARL: Enhancing Diversity of Ensemble Networks to Resist Adversarial Attacks via Pairwise Adversarially Robust Loss Function,"Manaar Alam, Shubhajit Datta, Debdeep Mukhopadhyay, Arijit Mondal, Partha Pratim Chakrabarti",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.04948"" target=""_blank"">2112.04948</a>",,2025-12-03 22:39:25
MedAttacker: Exploring Black-Box Adversarial Attacks on Risk Prediction Models in Healthcare,"Muchao Ye, Junyu Luo, Guanjie Zheng, Cao Xiao, Ting Wang, Fenglong Ma",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.06063"" target=""_blank"">2112.06063</a>",,2025-12-03 22:39:25
Amicable Aid: Turning Adversarial Attack to Benefit Classification,"Juyeop Kim, Jun-Ho Choi, Soobeom Jang, Jong-Seok Lee",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.04720"" target=""_blank"">2112.04720</a>",,2025-12-03 22:39:25
SoK: On the Security & Privacy in Federated Learning,"Gorka Abad, Stjepan Picek, Aitor Urbieta",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.05423"" target=""_blank"">2112.05423</a>",,2025-12-03 22:39:25
Decision-based Black-box Attack Against Vision Transformers via Patch-wise Adversarial Removal,"Yucheng Shi, Yahong Han, Yu-an Tan, Xiaohui Kuang",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.03492"" target=""_blank"">2112.03492</a>",,2025-12-03 22:39:25
Interpolated Joint Space Adversarial Training for Robust and Generalizable Defenses,"Chun Pong Lau, Jiang Liu, Hossein Souri, Wei-An Lin, Soheil Feizi, Rama Chellappa",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.06323"" target=""_blank"">2112.06323</a>",,2025-12-03 22:39:25
Quantifying and Understanding Adversarial Examples in Discrete Input Spaces,"Volodymyr Kuleshov, Evgenii Nikishin, Shantanu Thakoor, Tingfung Lau, Stefano Ermon",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.06276"" target=""_blank"">2112.06276</a>",,2025-12-03 22:39:25
SparseFed: Mitigating Model Poisoning Attacks in Federated Learning with Sparsification,"Ashwinee Panda, Saeed Mahloujifar, Arjun N. Bhagoji, Supriyo Chakraborty, Prateek Mittal",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.06274"" target=""_blank"">2112.06274</a>",,2025-12-03 22:39:25
WOOD: Wasserstein-based Out-of-Distribution Detection,"Yinan Wang, Wenbo Sun, Jionghua ""Judy"" Jin, Zhenyu ""James"" Kong, Xiaowei Yue",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.06384"" target=""_blank"">2112.06384</a>",,2025-12-03 22:39:25
"Improving the Transferability of Adversarial Examples with Resized-Diverse-Inputs, Diversity-Ensemble and Region Fitting","Junhua Zou, Zhisong Pan, Junyang Qiu, Xin Liu, Ting Rui, Wei Li",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.06011"" target=""_blank"">2112.06011</a>","<a href=""https://github.com/278287847/DEM"" target=""_blank"">278287847</a>",2025-12-03 22:39:25
Stereoscopic Universal Perturbations across Different Architectures and Datasets,"Zachary Berger, Parth Agrawal, Tian Yu Liu, Stefano Soatto, Alex Wong",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.06116"" target=""_blank"">2112.06116</a>",,2025-12-03 22:39:25
Learning to Learn Transferable Attack,"Shuman Fang, Jie Li, Xianming Lin, Rongrong Ji",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.06658"" target=""_blank"">2112.06658</a>",,2025-12-03 22:39:25
Cross-Modal Transferable Adversarial Attacks from Images to Videos,"Zhipeng Wei, Jingjing Chen, Zuxuan Wu, Yu-Gang Jiang",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.05379"" target=""_blank"">2112.05379</a>",,2025-12-03 22:39:25
Attacking Point Cloud Segmentation with Color-only Perturbation,"Jiacen Xu, Zhe Zhou, Boyuan Feng, Yufei Ding, Zhou Li",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.05871"" target=""_blank"">2112.05871</a>",,2025-12-03 22:39:25
Preemptive Image Robustification for Protecting Users against Man-in-the-Middle Adversarial Attacks,"Seungyong Moon, Gaon An, Hyun Oh Song",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.05634"" target=""_blank"">2112.05634</a>",,2025-12-03 22:39:25
Batch Label Inference and Replacement Attacks in Black-Boxed Vertical Federated Learning,"Yang Liu, Tianyuan Zou, Yan Kang, Wenhan Liu, Yuanqin He, Zhihao Yi, Qiang Yang",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.05409"" target=""_blank"">2112.05409</a>",,2025-12-03 22:39:25
"Copy, Right? A Testing Framework for Copyright Protection of Deep Learning Models","Jialuo Chen, Jingyi Wang, Tinglan Peng, Youcheng Sun, Peng Cheng, Shouling Ji, Xingjun Ma, Bo Li, Dawn Song",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.05588"" target=""_blank"">2112.05588</a>",,2025-12-03 22:39:25
Efficient Action Poisoning Attacks on Linear Contextual Bandits,"Guanlin Liu, Lifeng Lai",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.05367"" target=""_blank"">2112.05367</a>",,2025-12-03 22:39:25
How Private Is Your RL Policy? An Inverse RL Based Analysis Framework,"Kritika Prakash, Fiza Husain, Praveen Paruchuri, Sujit P. Gujar",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.05495"" target=""_blank"">2112.05495</a>",,2025-12-03 22:39:25
Adversarial Machine Learning In Network Intrusion Detection Domain: A Systematic Review,"Huda Ali Alatwi, Charles Morisset",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.03315"" target=""_blank"">2112.03315</a>",,2025-12-03 22:39:25
Robustness in Deep Learning for Computer Vision: Mind the gap? (31%),"Nathan Drenkow, Numair Sani, Ilya Shpitser, Mathias Unberath",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.00639"" target=""_blank"">2112.00639</a>",,2025-12-03 22:39:25
ML Attack Models: Adversarial Attacks and Data Poisoning Attacks,"Jing Lin, Long Dang, Mohamed Rahouti, Kaiqi Xiong",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.02797"" target=""_blank"">2112.02797</a>",,2025-12-03 22:39:25
Adv-4-Adv: Thwarting Changing Adversarial Perturbations via Adversarial Domain Adaptation,"Tianyue Zheng, Zhe Chen, Shuya Ding, Chao Cai, Jun Luo",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.00428"" target=""_blank"">2112.00428</a>",,2025-12-03 22:39:25
FIBA: Frequency-Injection based Backdoor Attack in Medical Image Analysis,"Yu Feng, Benteng Ma, Jing Zhang, Shanshan Zhao, Yong Xia, Dacheng Tao",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.01148"" target=""_blank"">2112.01148</a>","<a href=""https://github.com/HazardFY/FIBA"" target=""_blank"">HazardFY</a>",2025-12-03 22:39:25
On the Existence of the Adversarial Bayes Classifier (Extended Version),"Pranjal Awasthi, Natalie S. Frank, Mehryar Mohri",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.01694"" target=""_blank"">2112.01694</a>",,2025-12-03 22:39:25
Editing a classifier by rewriting its prediction rules,"Shibani Santurkar, Dimitris Tsipras, Mahalaxmi Elango, David Bau, Antonio Torralba, Aleksander Madry",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.01008"" target=""_blank"">2112.01008</a>","<a href=""https://github.com/MadryLab/EditingClassifiers"" target=""_blank"">MadryLab</a>",2025-12-03 22:39:25
Adversarial Robustness of Deep Reinforcement Learning based Dynamic Recommender Systems,"Siyu Wang, Yuanjiang Cao, Xiaocong Chen, Lina Yao, Xianzhi Wang, Quan Z. Sheng",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.00973"" target=""_blank"">2112.00973</a>",,2025-12-03 22:39:25
Push Stricter to Decide Better: A Class-Conditional Feature Adaptive Framework for Improving Adversarial Robustness,"Jia-Li Yin, Lehui Xie, Wanqing Zhu, Ximeng Liu, Bo-Hao Chen",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.00323"" target=""_blank"">2112.00323</a>","<a href=""https://github.com/VisionFlow/FAAT"" target=""_blank"">VisionFlow</a>",2025-12-03 22:39:25
$\ell_\infty$-Robustness and Beyond: Unleashing Efficient Adversarial Training,"Hadi M. Dolatabadi, Sarah Erfani, Christopher Leckie",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.00378"" target=""_blank"">2112.00378</a>",,2025-12-03 22:39:25
Certified Adversarial Defenses Meet Out-of-Distribution Corruptions: Benchmarking Robustness and Simple Baselines,"Jiachen Sun, Akshay Mehra, Bhavya Kailkhura, Pin-Yu Chen, Dan Hendrycks, Jihun Hamm, Z. Morley Mao",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.00659"" target=""_blank"">2112.00659</a>",,2025-12-03 22:39:25
Detecting Audio Adversarial Examples with Logit Noising,"Namgyu Park, Sangwoo Ji, Jong Kim",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.06443"" target=""_blank"">2112.06443</a>",,2025-12-03 22:39:25
Test-Time Detection of Backdoor Triggers for Poisoned Deep Neural Networks,"Xi Li, Zhen Xiang, David J. Miller, George Kesidis",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.03350"" target=""_blank"">2112.03350</a>",,2025-12-03 22:39:25
CYBORG: Blending Human Saliency Into the Loss Improves Deep Learning,"Aidan Boyd, Patrick Tinsley, Kevin Bowyer, Adam Czajka",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.00686"" target=""_blank"">2112.00686</a>",,2025-12-03 22:39:25
Evaluating Gradient Inversion Attacks and Defenses in Federated Learning,"Yangsibo Huang, Samyak Gupta, Zhao Song, Kai Li, Sanjeev Arora",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.00059"" target=""_blank"">2112.00059</a>","<a href=""https://github.com/Princeton-SysML/GradAttack"" target=""_blank"">Princeton-SysML</a>",2025-12-03 22:39:25
Adversarial Attacks Against Deep Generative Models on Data: A Survey,"Hui Sun, Tianqing Zhu, Zhiqiu Zhang, Dawei Jin. Ping Xiong, Wanlei Zhou",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.00247"" target=""_blank"">2112.00247</a>",,2025-12-03 22:39:25
Reliability Assessment and Safety Arguments for Machine Learning Components in Assuring Learning-Enabled Autonomous Systems,"Xingyu Zhao, Wei Huang, Vibhav Bharti, Yi Dong, Victoria Cox, Alec Banks, Sen Wang, Sven Schewe, Xiaowei Huang",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.00646"" target=""_blank"">2112.00646</a>",,2025-12-03 22:39:25
Gradient Inversion Attack: Leaking Private Labels in Two-Party Split Learning,"Sanjay Kariyappa, Moinuddin K Qureshi",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.01299"" target=""_blank"">2112.01299</a>",,2025-12-03 22:39:25
How to Build Robust FAQ Chatbot with Controllable Question Generator? (80%),"Yan Pan, Mingyang Ma, Bernhard Pflugfelder, Georg Groh",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.03007"" target=""_blank"">2112.03007</a>",,2025-12-03 22:39:25
Sequential Randomized Smoothing for Adversarially Robust Speech Recognition,"Raphael Olivier, Bhiksha Raj",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.03000"" target=""_blank"">2112.03000</a>",,2025-12-03 22:39:25
FedRAD: Federated Robust Adaptive Distillation,"Stefán Páll Sturluson, Samuel Trew, Luis Muñoz-González, Matei Grama, Jonathan Passerat-Palmbach, Daniel Rueckert, Amir Alansary",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.01405"" target=""_blank"">2112.01405</a>",,2025-12-03 22:39:25
Training Efficiency and Robustness in Deep Learning,Fartash Faghri,arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.01423"" target=""_blank"">2112.01423</a>",,2025-12-03 22:39:25
Is RobustBench/AutoAttack a suitable Benchmark for Adversarial Robustness? (75%),"Peter Lorenz, Dominik Strassel, Margret Keuper, Janis Keuper",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.01601"" target=""_blank"">2112.01601</a>",,2025-12-03 22:39:25
Is Approximation Universally Defensive Against Adversarial Attacks in Deep Neural Networks? (93%),"Ayesha Siddique, Khaza Anuarul Hoque",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.01555"" target=""_blank"">2112.01555</a>",,2025-12-03 22:39:25
When the Curious Abandon Honesty: Federated Learning Is Not Private,"Franziska Boenisch, Adam Dziedzic, Roei Schuster, Ali Shahin Shamsabadi, Ilia Shumailov, Nicolas Papernot",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.02918"" target=""_blank"">2112.02918</a>",,2025-12-03 22:39:25
Defending against Model Stealing via Verifying Embedded External Features,"Yiming Li, Linghui Zhu, Xiaojun Jia, Yong Jiang, Shu-Tao Xia, Xiaochun Cao",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.03476"" target=""_blank"">2112.03476</a>",,2025-12-03 22:39:25
Context-Aware Transfer Attacks for Object Detection,"Zikui Cai, Xinxin Xie, Shasha Li, Mingjun Yin, Chengyu Song, Srikanth V. Krishnamurthy, Amit K. Roy-Chowdhury, M. Salman Asif",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.03223"" target=""_blank"">2112.03223</a>",,2025-12-03 22:39:25
Robust Active Learning: Sample-Efficient Training of Robust Deep Learning Models,"Yuejun Guo, Qiang Hu, Maxime Cordy, Mike Papadakis, Yves Le Traon",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.02542"" target=""_blank"">2112.02542</a>",,2025-12-03 22:39:25
Stochastic Local Winner-Takes-All Networks Enable Profound Adversarial Robustness,"Konstantinos P. Panousis, Sotirios Chatzis, Sergios Theodoridis",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.02671"" target=""_blank"">2112.02671</a>",,2025-12-03 22:39:25
Beyond Robustness: Resilience Verification of Tree-Based Classifiers,"Stefano Calzavara, Lorenzo Cazzaro, Claudio Lucchese, Federico Marcuzzi, Salvatore Orlando",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.02705"" target=""_blank"">2112.02705</a>",,2025-12-03 22:39:25
On Impact of Semantically Similar Apps in Android Malware Datasets,Roopak Surendran,arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.02606"" target=""_blank"">2112.02606</a>",,2025-12-03 22:39:25
RADA: Robust Adversarial Data Augmentation for Camera Localization in Challenging Weather,"Jialu Wang, Muhamad Risqi U. Saputra, Chris Xiaoxuan Lu, Niki Trigon, Andrew Markham",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.02469"" target=""_blank"">2112.02469</a>",,2025-12-03 22:39:25
Single-Shot Black-Box Adversarial Attacks Against Malware Detectors: A Causal Language Model Approach,"James Lee Hu, Mohammadreza Ebrahimi, Hsinchun Chen",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.01724"" target=""_blank"">2112.01724</a>",,2025-12-03 22:39:25
Generalized Likelihood Ratio Test for Adversarially Robust Hypothesis Testing,"Bhagyashree Puranik, Upamanyu Madhow, Ramtin Pedarsani",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.02209"" target=""_blank"">2112.02209</a>",,2025-12-03 22:39:25
Blackbox Untargeted Adversarial Testing of Automatic Speech Recognition Systems,"Xiaoliang Wu, Ajitha Rajan",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.01821"" target=""_blank"">2112.01821</a>",,2025-12-03 22:39:25
Attack-Centric Approach for Evaluating Transferability of Adversarial Samples in Machine Learning Models,"Tochukwu Idika, Ismail Akturk",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.01777"" target=""_blank"">2112.01777</a>",,2025-12-03 22:39:25
Adversarial Attacks against a Satellite-borne Multispectral Cloud Detector,"Andrew Du, Yee Wei Law, Michele Sasdelli, Bo Chen, Ken Clarke, Michael Brown, Tat-Jun Chin",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.01723"" target=""_blank"">2112.01723</a>",,2025-12-03 22:39:25
A Game-Theoretic Approach for AI-based Botnet Attack Defence,"Hooman Alavizadeh, Julian Jang-Jaccard, Tansu Alpcan, Seyit A. Camtepe",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.02223"" target=""_blank"">2112.02223</a>",,2025-12-03 22:39:25
A Unified Framework for Adversarial Attack and Defense in Constrained Feature Space,"Thibault Simonetto, Salijona Dyrmishi, Salah Ghamizi, Maxime Cordy, Yves Le Traon",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.01156"" target=""_blank"">2112.01156</a>",,2025-12-03 22:39:25
Triangle Attack: A Query-efficient Decision-based Adversarial Attack,"Xiaosen Wang, Zeliang Zhang, Kangheng Tong, Dihong Gong, Kun He, Zhifeng Li, Wei Liu",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.06569"" target=""_blank"">2112.06569</a>",,2025-12-03 22:39:25
Stealthy Attack on Algorithmic-Protected DNNs via Smart Bit Flipping,"Behnam Ghavami, Seyd Movi, Zhenman Fang, Lesley Shannon",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.13162"" target=""_blank"">2112.13162</a>",,2025-12-03 22:39:25
MuxLink: Circumventing Learning-Resilient MUX-Locking Using Graph Neural Network-based Link Prediction,"Lilas Alrahis, Satwik Patnaik, Muhammad Shafique, Ozgur Sinanoglu",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.07178"" target=""_blank"">2112.07178</a>",,2025-12-03 22:39:25
Adversarial Attacks against Windows PE Malware Detection: A Survey of the State-of-the-Art,"Xiang Ling, Lingfei Wu, Jiangyu Zhang, Zhenqing Qu, Wei Deng, Xiang Chen, Yaguan Qian, Chunming Wu, Shouling Ji, Tianyue Luo, Jingzheng Wu, Yanjun Wu",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.12310"" target=""_blank"">2112.12310</a>","<a href=""https://github.com/ryderling/adversarial-attacks-and-defenses-for-windows-pe-malware-detection"" target=""_blank"">ryderling</a>",2025-12-03 22:39:25
CatchBackdoor: Backdoor Testing by Critical Trojan Neural Path Identification via Differential Fuzzing,"Haibo Jin, Ruoxi Chen, Jinyin Chen, Yao Cheng, Chong Fu, Ting Wang, Yue Yu, Zhaoyan Ming",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.13064"" target=""_blank"">2112.13064</a>",,2025-12-03 22:39:25
SoK: A Study of the Security on Voice Processing Systems,"Robert Chang, Logan Kuo, Arthur Liu, Nader Sehatbakhsh",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.13144"" target=""_blank"">2112.13144</a>",,2025-12-03 22:39:25
Gradient Leakage Attack Resilient Deep Learning,"Wenqi Wei, Ling Liu",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.13178"" target=""_blank"">2112.13178</a>",,2025-12-03 22:39:25
Adaptive Modeling Against Adversarial Attacks,"Zhiwen Yan, Teck Khim Ng",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.12431"" target=""_blank"">2112.12431</a>",,2025-12-03 22:39:25
Revisiting and Advancing Fast Adversarial Training Through The Lens of Bi-Level Optimization,"Yihua Zhang, Guanhua Zhang, Prashant Khanduri, Mingyi Hong, Shiyu Chang, Sijia Liu",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.12376"" target=""_blank"">2112.12376</a>",,2025-12-03 22:39:25
Robust Secretary and Prophet Algorithms for Packing Integer Programs,"C. J. Argue, Anupam Gupta, Marco Molinaro, Sahil Singla",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.12920"" target=""_blank"">2112.12920</a>",,2025-12-03 22:39:25
Counterfactual Memorization in Neural Language Models,"Chiyuan Zhang, Daphne Ippolito, Katherine Lee, Matthew Jagielski, Florian Tramèr, Nicholas Carlini",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.12938"" target=""_blank"">2112.12938</a>",,2025-12-03 22:39:25
How Should Pre-Trained Language Models Be Fine-Tuned Towards Adversarial Robustness? (98%),"Xinhsuai Dong, Luu Anh Tuan, Min Lin, Shuicheng Yan, Hanwang Zhang",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.11668"" target=""_blank"">2112.11668</a>",,2025-12-03 22:39:25
Input-Specific Robustness Certification for Randomized Smoothing,"Ruoxin Chen, Jie Li, Junchi Yan, Ping Li, Bin Sheng",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.12084"" target=""_blank"">2112.12084</a>","<a href=""https://github.com/roy-ch/Input-Specific-Certification"" target=""_blank"">roy-ch</a>",2025-12-03 22:39:25
Detect & Reject for Transferability of Black-box Adversarial Attacks Against Network Intrusion Detection Systems,"Islam Debicha, Thibault Debatty, Jean-Michel Dricot, Wim Mees, Tayeb Kenaza",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.12095"" target=""_blank"">2112.12095</a>",,2025-12-03 22:39:25
Adversarial Deep Reinforcement Learning for Improving the Robustness of Multi-agent Autonomous Driving Policies,"Aizaz Sharif, Dusica Marijan",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.11937"" target=""_blank"">2112.11937</a>",,2025-12-03 22:39:25
Understanding and Measuring Robustness of Multimodal Learning,"Nishant Vishwamitra, Hongxin Hu, Ziming Zhao, Long Cheng, Feng Luo",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.12792"" target=""_blank"">2112.12792</a>",,2025-12-03 22:39:25
Evaluating the Robustness of Deep Reinforcement Learning for Autonomous and Adversarial Policies in a Multi-agent Urban Driving Environment,"Aizaz Sharif, Dusica Marijan",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.11947"" target=""_blank"">2112.11947</a>",,2025-12-03 22:39:25
A Theoretical View of Linear Backpropagation and Its Convergence,"Ziang Li, Yiwen Guo, Haodi Liu, Changshui Zhang",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.11018"" target=""_blank"">2112.11018</a>",,2025-12-03 22:39:25
AED: An black-box NLP classifier model attacker,"Yueyang Liu, Yan Huang, Zhipeng Cai",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.11660"" target=""_blank"">2112.11660</a>",,2025-12-03 22:39:25
Covert Communications via Adversarial Machine Learning and Reconfigurable Intelligent Surfaces,"Brian Kim, Tugba Erpek, Yalin E. Sagduyu, Sennur Ulukus",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.11414"" target=""_blank"">2112.11414</a>",,2025-12-03 22:39:25
Fight Perturbations with Perturbations: Defending Adversarial Attacks via Neuron Influence,"Ruoxi Chen, Haibo Jin, Haibin Zheng, Jinyin Chen, Zhenguang Liu",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.13060"" target=""_blank"">2112.13060</a>",,2025-12-03 22:39:25
On Distinctive Properties of Universal Perturbations,"Sung Min Park, Kuo-An Wei, Kai Xiao, Jerry Li, Aleksander Madry",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.15329"" target=""_blank"">2112.15329</a>",,2025-12-03 22:39:25
NeuronFair: Interpretable White-Box Fairness Testing through Biased Neuron Identification,"Haibin Zheng, Zhiqing Chen, Tianyu Du, Xuhong Zhang, Yao Cheng, Shouling Ji, Jingyi Wang, Yue Yu, Jinyin Chen",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.13214"" target=""_blank"">2112.13214</a>",,2025-12-03 22:39:25
Task and Model Agnostic Adversarial Attack on Graph Neural Networks,"Kartik Sharma, Samidha Verma, Sourav Medya, Sayan Ranu, Arnab Bhattacharya",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.13267"" target=""_blank"">2112.13267</a>",,2025-12-03 22:39:25
Invertible Image Dataset Protection,"Kejiang Chen, Xianhan Zeng, Qichao Ying, Sheng Li, Zhenxing Qian, Xinpeng Zhang",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.14420"" target=""_blank"">2112.14420</a>",,2025-12-03 22:39:25
Benign Overfitting in Adversarially Robust Linear Classification,"Jinghui Chen, Yuan Cao, Quanquan Gu",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.15250"" target=""_blank"">2112.15250</a>",,2025-12-03 22:39:25
Dual-Key Multimodal Backdoors for Visual Question Answering,"Matthew Walmer, Karan Sikka, Indranil Sur, Abhinav Shrivastava, Susmit Jha",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.07668"" target=""_blank"">2112.07668</a>",,2025-12-03 22:39:25
Challenges and Approaches for Mitigating Byzantine Attacks in Federated Learning,"Junyu Shi, Wei Wan, Shengshan Hu, Jianrong Lu, Leo Yu Zhang",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.14468"" target=""_blank"">2112.14468</a>",,2025-12-03 22:39:25
Causal Attention for Interpretable and Generalizable Graph Classification,"Yongduo Sui, Xiang Wang, Jiancan Wu, Min Lin, Xiangnan He, Tat-Seng Chua",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.15089"" target=""_blank"">2112.15089</a>",,2025-12-03 22:39:25
Constrained Gradient Descent: A Powerful and Principled Evasion Attack Against Neural Networks,"Weiran Lin, Keane Lucas, Lujo Bauer, Michael K. Reiter, Mahmood Sharif",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.14232"" target=""_blank"">2112.14232</a>",,2025-12-03 22:39:25
Closer Look at the Transferability of Adversarial Examples: How They Fool Different Models Differently,"Futa Waseda, Sosuke Nishikawa, Trung-Nghia Le, Huy H. Nguyen, Isao Echizen",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.14337"" target=""_blank"">2112.14337</a>",,2025-12-03 22:39:25
DeepAdversaries: Examining the Robustness of Deep Learning Models for Galaxy Morphology Classification,"Aleksandra Ćiprijanović, Diana Kafkes, Gregory Snyder, F. Javier Sánchez, Gabriel Nathan Perdue, Kevin Pedro, Brian Nord, Sandeep Madireddy, Stefan M. Wild",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.14299"" target=""_blank"">2112.14299</a>",,2025-12-03 22:39:25
Super-Efficient Super Resolution for Fast Adversarial Defense at the Edge,"Kartikeya Bhardwaj, Dibakar Gope, James Ward, Paul Whatmough, Danny Loh",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.14340"" target=""_blank"">2112.14340</a>",,2025-12-03 22:39:25
Gas Gauge: A Security Analysis Tool for Smart Contract Out-of-Gas Vulnerabilities,"Behkish Nassirzadeh, Huaiying Sun, Sebastian Banescu, Vijay Ganesh",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.14771"" target=""_blank"">2112.14771</a>",,2025-12-03 22:39:25
Adversarial Attack for Asynchronous Event-based Data,"Wooju Lee, Hyun Myung",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.13534"" target=""_blank"">2112.13534</a>",,2025-12-03 22:39:25
PRIME: A Few Primitives Can Boost Robustness to Common Corruptions,"Apostolos Modas, Rahul Rade, Guillermo Ortiz-Jiménez, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.13547"" target=""_blank"">2112.13547</a>",,2025-12-03 22:39:25
Associative Adversarial Learning Based on Selective Attack,"Runqi Wang, Xiaoyue Duan, Baochang Zhang, Song Xue, Wentao Zhu, David Doermann, Guodong Guo",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.13989"" target=""_blank"">2112.13989</a>",,2025-12-03 22:39:25
Learning Robust and Lightweight Model through Separable Structured Transformations,"Yanhui Huang, Yangyu Xu, Xian Wei",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.13551"" target=""_blank"">2112.13551</a>",,2025-12-03 22:39:25
Perlin Noise Improve Adversarial Robustness,"Chengjun Tang, Kun Zhang, Chunfang Xing, Yong Ding, Zengmin Xu",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.13408"" target=""_blank"">2112.13408</a>",,2025-12-03 22:39:25
Mind the Gap! A Study on the Transferability of Virtual vs Physical-world Testing of Autonomous Driving Systems,"Andrea Stocco, Brian Pulfer, Paolo Tonella",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.11255"" target=""_blank"">2112.11255</a>",,2025-12-03 22:39:25
DP-UTIL: Comprehensive Utility Analysis of Differential Privacy in Machine Learning,"Ismat Jarin, Birhanu Eshete",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.12998"" target=""_blank"">2112.12998</a>",,2025-12-03 22:39:25
Improving Robustness with Image Filtering,"Matteo Terzi, Mattia Carletti, Gian Antonio Susto",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.11235"" target=""_blank"">2112.11235</a>",,2025-12-03 22:39:25
Pure Noise to the Rescue of Insufficient Data: Improving Imbalanced Classification by Training on Random Noise Images,"Shiran Zada, Itay Benou, Michal Irani",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.08810"" target=""_blank"">2112.08810</a>",,2025-12-03 22:39:25
Towards Robust Neural Image Compression: Adversarial Attack and Model Finetuning,"Tong Chen, Zhan Ma",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.08691"" target=""_blank"">2112.08691</a>","<a href=""https://njuvision.github.io/RobustNIC"" target=""_blank"">njuvision.github.io</a>",2025-12-03 22:39:25
All You Need is RAW: Defending Against Adversarial Attacks with Camera Image Pipelines,"Yuxuan Zhang, Bo Dong, Felix Heide",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.09219"" target=""_blank"">2112.09219</a>",,2025-12-03 22:39:25
Robust Upper Bounds for Adversarial Training,"Dimitris Bertsimas, Xavier Boix, Kimberly Villalobos Carballo, Dick den Hertog",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.09279"" target=""_blank"">2112.09279</a>",,2025-12-03 22:39:25
TAFIM: Targeted Adversarial Attacks against Facial Image Manipulations,"Shivangi Aneja, Lev Markhasin, Matthias Niessner",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.09151"" target=""_blank"">2112.09151</a>",,2025-12-03 22:39:25
"APTSHIELD: A Stable, Efficient and Real-time APT Detection System for Linux Hosts","Tiantian Zhu, Jinkai Yu, Tieming Chen, Jiayu Wang, Jie Ying, Ye Tian, Mingqi Lv, Yan Chen, Yuan Fan, Ting Wang",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.09008"" target=""_blank"">2112.09008</a>",,2025-12-03 22:39:25
Correlation inference attacks against machine learning models,"Ana-Maria Creţu, Florent Guépin, Montjoye Yves-Alexandre de",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.08806"" target=""_blank"">2112.08806</a>",,2025-12-03 22:39:25
Models in the Loop: Aiding Crowdworkers with Generative Annotation Assistants,"Max Bartolo, Tristan Thrush, Sebastian Riedel, Pontus Stenetorp, Robin Jia, Douwe Kiela",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.09062"" target=""_blank"">2112.09062</a>",,2025-12-03 22:39:25
On the Convergence and Robustness of Adversarial Training,"Yisen Wang, Xingjun Ma, James Bailey, Jinfeng Yi, Bowen Zhou, Quanquan Gu",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.08304"" target=""_blank"">2112.08304</a>",,2025-12-03 22:39:25
Domain Adaptation on Point Clouds via Geometry-Aware Implicits,"Yuefan Shen, Yanchao Yang, Mi Yan, He Wang, Youyi Zheng, Leonidas Guibas",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.09343"" target=""_blank"">2112.09343</a>",,2025-12-03 22:39:25
On the Adversarial Robustness of Causal Algorithmic Recourse,"Ricardo Dominguez-Olmedo, Amir-Hossein Karimi, Bernhard Schölkopf",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.11313"" target=""_blank"">2112.11313</a>",,2025-12-03 22:39:25
Temporal Shuffling for Defending Deep Action Recognition Models against Adversarial Attacks,"Jaehui Hwang, Huan Zhang, Jun-Ho Choi, Cho-Jui Hsieh, Jong-Seok Lee",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.07921"" target=""_blank"">2112.07921</a>",,2025-12-03 22:39:25
DuQM: A Chinese Dataset of Linguistically Perturbed Natural Questions for Evaluating the Robustness of Question Matching Models,"Hongyu Zhu, Yan Chen, Jing Yan, Jing Liu, Yu Hong, Ying Chen, Hua Wu, Haifeng Wang",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.08609"" target=""_blank"">2112.08609</a>",,2025-12-03 22:39:25
Robust Neural Network Classification via Double Regularization,"Olof Zetterqvist, Rebecka Jörnsten, Johan Jonasson",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.08102"" target=""_blank"">2112.08102</a>",,2025-12-03 22:39:25
Adversarial Examples for Extreme Multilabel Text Classification,"Mohammadreza Qaraei, Rohit Babbar",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.07512"" target=""_blank"">2112.07512</a>","<a href=""https://github.com/xmc-aalto/adv-xmtc"" target=""_blank"">xmc-aalto</a>",2025-12-03 22:39:25
On the Impact of Hard Adversarial Instances on Overfitting in Adversarial Training,"Chen Liu, Zhichao Huang, Mathieu Salzmann, Tong Zhang, Sabine Süsstrunk",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.07324"" target=""_blank"">2112.07324</a>",,2025-12-03 22:39:25
Robustifying automatic speech recognition by extracting slowly varying features,"Matías Pizarro, Dorothea Kolossa, Asja Fischer",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.07400"" target=""_blank"">2112.07400</a>",,2025-12-03 22:39:25
Addressing Adversarial Machine Learning Attacks in Smart Healthcare Perspectives,"Arawinkumaar Selvakkumar, Shantanu Pal, Zahra Jadidi",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.08862"" target=""_blank"">2112.08862</a>",,2025-12-03 22:39:25
Sharpness-Aware Minimization with Dynamic Reweighting,"Wenxuan Zhou, Fangyu Liu, Huan Zhang, Muhao Chen",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.08772"" target=""_blank"">2112.08772</a>",,2025-12-03 22:39:25
Provable Adversarial Robustness in the Quantum Model,"Khashayar Barooti, Grzegorz Głuch, Ruediger Urbanke",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.09625"" target=""_blank"">2112.09625</a>",,2025-12-03 22:39:25
Adversarially Robust Stability Certificates can be Sample-Efficient,"Thomas T. C. K. Zhang, Stephen Tu, Nicholas M. Boffi, Jean-Jacques E. Slotine, Nikolai Matni",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.10690"" target=""_blank"">2112.10690</a>",,2025-12-03 22:39:25
Longitudinal Study of the Prevalence of Malware Evasive Techniques,"Lorenzo Maffia, Dario Nisi, Platon Kotzias, Giovanni Lagorio, Simone Aonzo, Davide Balzarotti",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.11289"" target=""_blank"">2112.11289</a>",,2025-12-03 22:39:25
Certified Federated Adversarial Training,"Giulio Zizzo, Ambrish Rawat, Mathieu Sinn, Sergio Maffeis, Chris Hankin",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.10525"" target=""_blank"">2112.10525</a>",,2025-12-03 22:39:25
Energy-bounded Learning for Robust Models of Code,"Nghi D. Q. Bui, Yijun Yu",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.11226"" target=""_blank"">2112.11226</a>",,2025-12-03 22:39:25
Dynamics-aware Adversarial Attack of 3D Sparse Convolution Network,"An Tao, Yueqi Duan, He Wang, Ziyi Wu, Pengliang Ji, Haowen Sun, Jie Zhou, Jiwen Lu",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.09428"" target=""_blank"">2112.09428</a>",,2025-12-03 22:39:25
Black-Box Testing of Deep Neural Networks through Test Case Diversity,"Zohreh Aghababaeyan, Manel Abdellatif, Lionel Briand, Ramesh S, Mojtaba Bagherzadeh",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.12591"" target=""_blank"">2112.12591</a>",,2025-12-03 22:39:25
Unifying Model Explainability and Robustness for Joint Text Classification and Rationale Extraction,"Dongfang Li, Baotian Hu, Qingcai Chen, Tujie Xu, Jingcong Tao, Yunan Zhang",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.10424"" target=""_blank"">2112.10424</a>",,2025-12-03 22:39:25
MIA-Former: Efficient and Robust Vision Transformers via Multi-grained Input-Adaptation,"Zhongzhi Yu, Yonggan Fu, Sicheng Li, Chaojian Li, Yingyan Lin",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.11542"" target=""_blank"">2112.11542</a>",,2025-12-03 22:39:25
Exploring Credibility Scoring Metrics of Perception Systems for Autonomous Driving,"Viren Khandal, Arth Vidyarthi",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.11643"" target=""_blank"">2112.11643</a>",,2025-12-03 22:39:25
Adversarial Gradient Driven Exploration for Deep Click-Through Rate Prediction,"Kailun Wu, Zhangming Chan, Weijie Bian, Lejian Ren, Shiming Xiang, Shuguang Han, Hongbo Deng, Bo Zheng",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.11136"" target=""_blank"">2112.11136</a>",,2025-12-03 22:39:25
Initiative Defense against Facial Manipulation,"Qidong Huang, Jie Zhang, Wenbo Zhou, WeimingZhang, Nenghai Yu",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.10098"" target=""_blank"">2112.10098</a>",,2025-12-03 22:39:25
Being Friends Instead of Adversaries: Deep Networks Learn from Data Simplified by Other Networks,"Simone Marullo, Matteo Tiezzi, Marco Gori, Stefano Melacci",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.09968"" target=""_blank"">2112.09968</a>",,2025-12-03 22:39:25
Android-COCO: Android Malware Detection with Graph Neural Network for Byte- and Native-Code,Peng Xu,arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.10038"" target=""_blank"">2112.10038</a>",,2025-12-03 22:39:25
Reasoning Chain Based Adversarial Attack for Multi-hop Question Answering,"Jiayu Fudan University Ding, Siyuan Fudan University Wang, Qin East China Normal University Chen, Zhongyu Fudan University Wei",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.09658"" target=""_blank"">2112.09658</a>",,2025-12-03 22:39:25
Deep Bayesian Learning for Car Hacking Detection,"Laha Ale, Scott A. King, Ning Zhang",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.09333"" target=""_blank"">2112.09333</a>",,2025-12-03 22:39:25
"Explain, Edit, and Understand: Rethinking User Study Design for Evaluating Model Explanations","Siddhant Arora, Danish Pruthi, Norman Sadeh, William W. Cohen, Zachary C. Lipton, Graham Neubig",arXiv,2021-12,"<a href=""http://arxiv.org/abs/2112.09669"" target=""_blank"">2112.09669</a>",,2025-12-03 22:39:25
On the Equivalence between Neural Network and Support Vector Machine,"Yilan Chen, Wei Huang, Lam M. Nguyen, Tsui-Wei Weng",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.06063"" target=""_blank"">2111.06063</a>","<a href=""https://github.com/leslie-CH/equiv-nn-svm"" target=""_blank"">leslie-CH</a>",2025-12-03 22:39:25
A Bayesian Nash equilibrium-based moving target defense against stealthy sensor attacks,"David Umsonst, Serkan Sarıtaş, György Dán, Henrik Sandberg",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.06682"" target=""_blank"">2111.06682</a>",,2025-12-03 22:39:25
On Transferability of Prompt Tuning for Natural Language Processing,"Yusheng Su, Xiaozhi Wang, Yujia Qin, Chi-Min Chan, Yankai Lin, Huadong Wang, Kaiyue Wen, Zhiyuan Liu, Peng Li, Juanzi Li, Lei Hou, Maosong Sun, Jie Zhou",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.06719"" target=""_blank"">2111.06719</a>","<a href=""https://github.com/thunlp/Prompt-Transferability"" target=""_blank"">thunlp</a>",2025-12-03 22:39:25
Trustworthy Medical Segmentation with Uncertainty Estimation,"Giuseppina Carannante, Dimah Dera, Nidhal C. Bouaynaya, Ghulam Rasool, Hassan M. Fathallah-Shaykh",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.05978"" target=""_blank"">2111.05978</a>",,2025-12-03 22:39:25
Robust Learning via Ensemble Density Propagation in Deep Neural Networks,"Giuseppina Carannante, Dimah Dera, Ghulam Rasool, Nidhal C. Bouaynaya, Lyudmila Mihaylova",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.05953"" target=""_blank"">2111.05953</a>",,2025-12-03 22:39:25
Resilient Consensus-based Multi-agent Reinforcement Learning,"Martin Figura, Yixuan Lin, Ji Liu, Vijay Gupta",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.06776"" target=""_blank"">2111.06776</a>",,2025-12-03 22:39:25
Sparse Adversarial Video Attacks with Spatial Transformations,"Ronghui Mu, Wenjie Ruan, Leandro Soriano Marcolino, Qiang Ni",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.05468"" target=""_blank"">2111.05468</a>",,2025-12-03 22:39:25
Tightening the Approximation Error of Adversarial Risk with Auto Loss Function Search,"Pengfei Xia, Ziqiang Li, Bin Li",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.05063"" target=""_blank"">2111.05063</a>",,2025-12-03 22:39:25
MixACM: Mixup-Based Robustness Transfer via Distillation of Activated Channel Maps,"Muhammad Awais, Fengwei Zhou, Chuanlong Xie, Jiawei Li, Sung-Ho Bae, Zhenguo Li",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.05073"" target=""_blank"">2111.05073</a>",,2025-12-03 22:39:25
A Statistical Difference Reduction Method for Escaping Backdoor Detection,"Pengfei Xia, Hongjing Niu, Ziqiang Li, Bin Li",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.05077"" target=""_blank"">2111.05077</a>",,2025-12-03 22:39:25
Data Augmentation Can Improve Robustness,"Sylvestre-Alvise Rebuffi, Sven Gowal, Dan A. Calian, Florian Stimberg, Olivia Wiles, Timothy Mann",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.05328"" target=""_blank"">2111.05328</a>",,2025-12-03 22:39:25
Are Transformers More Robust Than CNNs? (67%),"Yutong Bai, Jieru Mei, Alan Yuille, Cihang Xie",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.05464"" target=""_blank"">2111.05464</a>","<a href=""https://github.com/ytongbai/ViTs-vs-CNNs"" target=""_blank"">ytongbai</a>",2025-12-03 22:39:25
Measuring the Contribution of Multiple Model Representations in Detecting Adversarial Instances,"Daniel Steinberg, Paul Munro",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.07035"" target=""_blank"">2111.07035</a>",,2025-12-03 22:39:25
Geometrically Adaptive Dictionary Attack on Face Recognition,"Junyoung Byun, Hyojun Go, Changick Kim",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.04371"" target=""_blank"">2111.04371</a>",,2025-12-03 22:39:25
Adversarially Robust Learning for Security-Constrained Optimal Power Flow,"Priya L. Donti, Aayushya Agarwal, Neeraj Vijay Bedmutha, Larry Pileggi, J. Zico Kolter",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.06961"" target=""_blank"">2111.06961</a>",,2025-12-03 22:39:25
Adversarial Tradeoffs in Linear Inverse Problems and Robust StateEstimation,"Bruce D. Lee, Thomas T. C. K. Zhang, Hamed Hassani, Nikolai Matni",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.08864"" target=""_blank"">2111.08864</a>",,2025-12-03 22:39:25
Neural Population Geometry Reveals the Role of Stochasticity in Robust Perception,"Joel Dapello, Jenelle Feather, Hang Le, Tiago Marques, David D. Cox, Josh H. McDermott, James J. DiCarlo, SueYeon Chung",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.06979"" target=""_blank"">2111.06979</a>",,2025-12-03 22:39:25
UNTANGLE: Unlocking Routing and Logic Obfuscation Using Graph Neural Networks-based Link Prediction,"Lilas Alrahis, Satwik Patnaik, Muhammad Abdullah Hanif, Muhammad Shafique, Ozgur Sinanoglu",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.07062"" target=""_blank"">2111.07062</a>",,2025-12-03 22:39:25
DeepSteal: Advanced Model Extractions Leveraging Efficient Weight Stealing in Memories,"Adnan Siraj Rakin, Md Hafizul Islam Chowdhuryy, Fan Yao, Deliang Fan",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.04625"" target=""_blank"">2111.04625</a>",,2025-12-03 22:39:25
Robustness of Bayesian Neural Networks to White-Box Adversarial Attacks,"Adaku Uchendu, Daniel Campoy, Christopher Menart, Alexandra Hildenbrandt",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.08591"" target=""_blank"">2111.08591</a>",,2025-12-03 22:39:25
Improving the robustness and accuracy of biomedical language models through adversarial training,"Milad Moradi, Matthias Samwald",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.08529"" target=""_blank"">2111.08529</a>",,2025-12-03 22:39:25
Detecting AutoAttack Perturbations in the Frequency Domain,"Peter Lorenz, Paula Harder, Dominik Strassel, Margret Keuper, Janis Keuper",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.08785"" target=""_blank"">2111.08785</a>",,2025-12-03 22:39:25
Consistent Semantic Attacks on Optical Flow,"Tom Koren, Lior Talker, Michael Dinerstein, Roy J Jevnisek",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.08485"" target=""_blank"">2111.08485</a>",,2025-12-03 22:39:25
An Overview of Backdoor Attacks Against Deep Neural Networks and Possible Defences,"Wei Guo, Benedetta Tondi, Mauro Barni",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.08429"" target=""_blank"">2111.08429</a>",,2025-12-03 22:39:25
Enabling equivariance for arbitrary Lie groups,"Lachlan Ewen MacDonald, Sameera Ramasinghe, Simon Lucey",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.08251"" target=""_blank"">2111.08251</a>",,2025-12-03 22:39:25
Triggerless Backdoor Attack for NLP Tasks with Clean Labels,"Leilei Gan, Jiwei Li, Tianwei Zhang, Xiaoya Li, Yuxian Meng, Fei Wu, Shangwei Guo, Chun Fan",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.07970"" target=""_blank"">2111.07970</a>",,2025-12-03 22:39:25
Property Inference Attacks Against GANs,"Junhao Zhou, Yufei Chen, Chao Shen, Yang Zhang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.07608"" target=""_blank"">2111.07608</a>",,2025-12-03 22:39:25
FedCG: Leverage Conditional GAN for Protecting Privacy and Maintaining Competitive Performance in Federated Learning,"Yuezhou Wu, Yan Kang, Jiahuan Luo, Yuanqin He, Qiang Yang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.08211"" target=""_blank"">2111.08211</a>","<a href=""https://github.com/yankang18/FedCG"" target=""_blank"">yankang18</a>",2025-12-03 22:39:25
Generating Band-Limited Adversarial Surfaces Using Neural Networks,"Roee Ben-Shlomo, Yevgeniy Men, Ido Imanuel",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.07424"" target=""_blank"">2111.07424</a>",,2025-12-03 22:39:25
Finding Optimal Tangent Points for Reducing Distortions of Hard-label Attacks,"Chen Ma, Xiangyu Guo, Li Chen, Jun-Hai Yong, Yisen Wang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.07492"" target=""_blank"">2111.07492</a>","<a href=""https://github.com/machanic/TangentAttack"" target=""_blank"">machanic</a>",2025-12-03 22:39:25
Towards Interpretability of Speech Pause in Dementia Detection using Adversarial Learning,"Youxiang Zhu, Bang Tran, Xiaohui Liang, John A. Batsis, Robert M. Roth",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.07454"" target=""_blank"">2111.07454</a>",,2025-12-03 22:39:25
Improving Compound Activity Classification via Deep Transfer and Representation Learning,"Vishal Dey, Raghu Machiraju, Xia Ning",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.07439"" target=""_blank"">2111.07439</a>",,2025-12-03 22:39:25
Robust and Accurate Object Detection via Self-Knowledge Distillation,"Weipeng Xu, Pengzhi Chu, Renhao Xie, Xiongziyan Xiao, Hongcheng Huang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.07239"" target=""_blank"">2111.07239</a>","<a href=""https://github.com/grispeut/udfa"" target=""_blank"">grispeut</a>",2025-12-03 22:39:25
Defense Against Explanation Manipulation,"Ruixiang Tang, Ninghao Liu, Fan Yang, Na Zou, Xia Hu",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.04303"" target=""_blank"">2111.04303</a>",,2025-12-03 22:39:25
Backdoor Pre-trained Models Can Transfer to All,"Lujia Shen, Shouling Ji, Xuhong Zhang, Jinfeng Li, Jing Chen, Jie Shi, Chengfang Fang, Jianwei Yin, Ting Wang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.00197"" target=""_blank"">2111.00197</a>",,2025-12-03 22:39:25
On Assessing The Safety of Reinforcement Learning algorithms Using Formal Methods,"Paulina Stevia Nouwou Mindom, Amin Nikanjam, Foutse Khomh, John Mullins",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.04865"" target=""_blank"">2111.04865</a>",,2025-12-03 22:39:25
Meta-Learning the Search Distribution of Black-Box Random Search Based Adversarial Attacks,"Maksym Yatsura, Jan Hendrik Metzen, Matthias Hein",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.01714"" target=""_blank"">2111.01714</a>",,2025-12-03 22:39:25
Pareto Adversarial Robustness: Balancing Spatial Robustness and Sensitivity-based Robustness,"Ke Sun, Mingjie Li, Zhouchen Lin",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.01996"" target=""_blank"">2111.01996</a>",,2025-12-03 22:39:25
Knowledge Cross-Distillation for Membership Privacy,"Rishav Chourasia, Batnyam Enkhtaivan, Kunihiro Ito, Junki Mori, Isamu Teranishi, Hikaru Tsuchida",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.01363"" target=""_blank"">2111.01363</a>",,2025-12-03 22:39:25
Adversarially Perturbed Wavelet-based Morphed Face Generation,"Kelsey O'Haire, Sobhan Soleymani, Baaria Chaudhary, Poorya Aghdaie, Jeremy Dawson, Nasser M. Nasrabadi",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.01965"" target=""_blank"">2111.01965</a>",,2025-12-03 22:39:25
Graph Structural Attack by Spectral Distance,"Lu Lin, Ethan Blaser, Hongning Wang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.00684"" target=""_blank"">2111.00684</a>",,2025-12-03 22:39:25
Availability Attacks Create Shortcuts,"Da Yu, Huishuai Zhang, Wei Chen, Jian Yin, Tie-Yan Liu",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.00898"" target=""_blank"">2111.00898</a>","<a href=""https://github.com/dayu11/Availability-Attacks-Create-Shortcuts"" target=""_blank"">dayu11</a>",2025-12-03 22:39:25
Robustness of deep learning algorithms in astronomy -- galaxy morphology studies,"A. Ćiprijanović, D. Kafkes, G. N. Perdue, K. Pedro, G. Snyder, F. J. Sánchez, S. Madireddy, S. Wild, B. Nord",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.00961"" target=""_blank"">2111.00961</a>",,2025-12-03 22:39:25
When Does Contrastive Learning Preserve Adversarial Robustness from Pretraining to Finetuning? (69%),"Lijie Fan, Sijia Liu, Pin-Yu Chen, Gaoyuan Zhang, Chuang Gan",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.01124"" target=""_blank"">2111.01124</a>",,2025-12-03 22:39:25
ZeBRA: Precisely Destroying Neural Networks with Zero-Data Based Repeated Bit Flip Attack,"Dahoon Park, Kon-Woo Kwon, Sunghoon Im, Jaeha Kung",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.01080"" target=""_blank"">2111.01080</a>",,2025-12-03 22:39:25
An Actor-Critic Method for Simulation-Based Optimization,"Kuo Li, Qing-Shan Jia, Jiaqi Yan",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.00435"" target=""_blank"">2111.00435</a>",,2025-12-03 22:39:25
Get Fooled for the Right Reason: Improving Adversarial Robustness through a Teacher-guided Curriculum Learning Approach,"Anindya Sarkar, Anirban Sarkar, Sowrya Gali, Vineeth N Balasubramanian",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.00295"" target=""_blank"">2111.00295</a>",,2025-12-03 22:39:25
AdvCodeMix: Adversarial Attack on Code-Mixed Data,"Sourya Dipta Das, Ayan Basak, Soumil Mandal, Dipankar Das",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.00350"" target=""_blank"">2111.00350</a>",,2025-12-03 22:39:25
Attacking Deep Learning AI Hardware with Universal Adversarial Perturbation,"Mehdi Sadi, B. M. S. Bahar Talukder, Kaniz Mishty, Md Tauhidur Rahman",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.09488"" target=""_blank"">2111.09488</a>",,2025-12-03 22:39:25
Trojan Source: Invisible Vulnerabilities,"Nicholas Boucher, Ross Anderson",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.00169"" target=""_blank"">2111.00169</a>",,2025-12-03 22:39:25
You are caught stealing my winning lottery ticket! Making a lottery ticket claim its ownership,"Xuxi Chen, Tianlong Chen, Zhenyu Zhang, Zhangyang Wang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.00162"" target=""_blank"">2111.00162</a>","<a href=""https://github.com/VITA-Group/NO-stealing-LTH"" target=""_blank"">VITA-Group</a>",2025-12-03 22:39:25
A Frequency Perspective of Adversarial Robustness,"Shishira R Maiya, Max Ehrlich, Vatsal Agarwal, Ser-Nam Lim, Tom Goldstein, Abhinav Shrivastava",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.00861"" target=""_blank"">2111.00861</a>",,2025-12-03 22:39:25
Training Certifiably Robust Neural Networks with Efficient Local Lipschitz Bounds,"Yujia Huang, Huan Zhang, Yuanyuan Shi, J Zico Kolter, Anima Anandkumar",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.01395"" target=""_blank"">2111.01395</a>",,2025-12-03 22:39:25
Effective and Imperceptible Adversarial Textual Attack via Multi-objectivization,"Shengcai Liu, Ning Lu, Wenjing Hong, Chao Qian, Ke Tang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.01528"" target=""_blank"">2111.01528</a>",,2025-12-03 22:39:25
Get a Model! Model Hijacking Attack Against Machine Learning Models,"Ahmed Salem, Michael Backes, Yang Zhang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.04394"" target=""_blank"">2111.04394</a>",,2025-12-03 22:39:25
Multi-Glimpse Network: A Robust and Efficient Classification Architecture based on Recurrent Downsampled Attention,"Sia Huat Tan, Runpei Dong, Kaisheng Ma",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.02018"" target=""_blank"">2111.02018</a>","<a href=""https://github.com/siahuat0727/MGNet"" target=""_blank"">siahuat0727</a>",2025-12-03 22:39:25
Robust and Information-theoretically Safe Bias Classifier against Adversarial Attacks,"Lijia Yu, Xiao-Shan Gao",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.04404"" target=""_blank"">2111.04404</a>",,2025-12-03 22:39:25
Characterizing the adversarial vulnerability of speech self-supervised learning,"Haibin Wu, Bo Zheng, Xu Li, Xixin Wu, Hung-yi Lee, Helen Meng",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.04330"" target=""_blank"">2111.04330</a>",,2025-12-03 22:39:25
HAPSSA: Holistic Approach to PDF Malware Detection Using Signal and Statistical Analysis,"Tajuddin Manhar Mohammed, Lakshmanan Nataraj, Satish Chikkagoudar, Shivkumar Chandrasekaran, B. S. Manjunath",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.04703"" target=""_blank"">2111.04703</a>",,2025-12-03 22:39:25
Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of Graph Machine Learning,"Qinkai Zheng, Xu Zou, Yuxiao Dong, Yukuo Cen, Da Yin, Jiarong Xu, Yang Yang, Jie Tang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.04314"" target=""_blank"">2111.04314</a>",,2025-12-03 22:39:25
BARFED: Byzantine Attack-Resistant Federated Averaging Based on Outlier Elimination,"Ece Isik-Polat, Gorkem Polat, Altan Kocyigit",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.04550"" target=""_blank"">2111.04550</a>",,2025-12-03 22:39:25
Generative Dynamic Patch Attack,"Xiang Li, Shihao Ji",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.04266"" target=""_blank"">2111.04266</a>","<a href=""https://github.com/lxuniverse/gdpa"" target=""_blank"">lxuniverse</a>",2025-12-03 22:39:25
Natural Adversarial Objects,"Felix Lau, Nishant Subramani, Sasha Harrison, Aerin Kim, Elliot Branson, Rosanne Liu",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.04204"" target=""_blank"">2111.04204</a>",,2025-12-03 22:39:25
"""How Does It Detect A Malicious App?"" Explaining the Predictions of AI-based Android Malware Detector","Zhi Lu, Vrizlynn L. L. Thing",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.05108"" target=""_blank"">2111.05108</a>",,2025-12-03 22:39:25
A Unified Game-Theoretic Interpretation of Adversarial Robustness,"Jie Ren, Die Zhang, Yisen Wang, Lu Chen, Zhanpeng Zhou, Yiting Chen, Xu Cheng, Xin Wang, Meng Zhou, Jie Shi, Quanshi Zhang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.03536"" target=""_blank"">2111.03536</a>",,2025-12-03 22:39:25
"Federated Learning Attacks Revisited: A Critical Discussion of Gaps, Assumptions, and Evaluation Setups","Aidmar Wainakh, Ephraim Zimmer, Sandeep Subedi, Jens Keim, Tim Grube, Shankar Karuppayah, Alejandro Sanchez Guinea, Max Mühlhäuser",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.03363"" target=""_blank"">2111.03363</a>",,2025-12-03 22:39:25
Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models,"Boxin Wang, Chejian Xu, Shuohang Wang, Zhe Gan, Yu Cheng, Jianfeng Gao, Ahmed Hassan Awadallah, Bo Li",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.02840"" target=""_blank"">2111.02840</a>","<a href=""https://adversarialglue.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
Adversarial Attacks on Graph Classification via Bayesian Optimisation,"Xingchen Wan, Henry Kenlay, Binxin Ru, Arno Blaas, Michael A. Osborne, Xiaowen Dong",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.02842"" target=""_blank"">2111.02842</a>",,2025-12-03 22:39:25
Adversarial Attacks on Knowledge Graph Embeddings via Instance Attribution Methods,"Peru Bhardwaj, John Kelleher, Luca Costabello, Declan O'Sullivan",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.03120"" target=""_blank"">2111.03120</a>",,2025-12-03 22:39:25
Attacking Deep Reinforcement Learning-Based Traffic Signal Control Systems with Colluding Vehicles,"Ao Qu, Yihong Tang, Wei Ma",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.02845"" target=""_blank"">2111.02845</a>",,2025-12-03 22:39:25
LTD: Low Temperature Distillation for Robust Adversarial Training,"Erh-Chung Chen, Che-Rung Lee",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.02331"" target=""_blank"">2111.02331</a>",,2025-12-03 22:39:25
Do Not Trust Prediction Scores for Membership Inference Attacks,"Dominik Hintersdorf, Lukas Struppek, Kristian Kersting",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.09076"" target=""_blank"">2111.09076</a>",,2025-12-03 22:39:25
A Survey on Adversarial Attacks for Malware Analysis,"Kshitiz Aryal, Maanak Gupta, Mahmoud Abdelsalam",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.08223"" target=""_blank"">2111.08223</a>",,2025-12-03 22:39:25
SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness,"Jongheon Jeong, Sejun Park, Minkyu Kim, Heung-Chang Lee, Doguk Kim, Jinwoo Shin",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.09277"" target=""_blank"">2111.09277</a>",,2025-12-03 22:39:25
ExCon: Explanation-driven Supervised Contrastive Learning for Image Classification,"Zhibo Zhang, Jongseong Jang, Chiheb Trabelsi, Ruiwen Li, Scott Sanner, Yeonjeong Jeong, Dongsub Shim",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.14271"" target=""_blank"">2111.14271</a>",,2025-12-03 22:39:25
Adaptive Perturbation for Adversarial Attack,"Zheng Yuan, Jie Zhang, Zhaoyan Jiang, Liangliang Li, Shiguang Shan",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.13841"" target=""_blank"">2111.13841</a>",,2025-12-03 22:39:25
Statically Detecting Adversarial Malware through Randomised Chaining,"Matthew Crawford, Wei Wang, Ruoxi Sun, Minhui Xue",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.14037"" target=""_blank"">2111.14037</a>",,2025-12-03 22:39:25
Dissecting Malware in the Wild,"Hamish Spencer, Wei Wang, Ruoxi Sun, Minhui Xue",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.14035"" target=""_blank"">2111.14035</a>",,2025-12-03 22:39:25
ArchRepair: Block-Level Architecture-Oriented Repairing for Deep Neural Networks,"Hua Qi, Zhijie Wang, Qing Guo, Jianlang Chen, Felix Juefei-Xu, Lei Ma, Jianjun Zhao",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.13330"" target=""_blank"">2111.13330</a>",,2025-12-03 22:39:25
Natural & Adversarial Bokeh Rendering via Circle-of-Confusion Predictive Network,"Yihao Huang, Felix Juefei-Xu, Qing Guo, Geguang Pu, Yang Liu",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.12971"" target=""_blank"">2111.12971</a>",,2025-12-03 22:39:25
Clustering Effect of (Linearized) Adversarial Robust Models,"Yang Bai, Xin Yan, Yong Jiang, Shu-Tao Xia, Yisen Wang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.12922"" target=""_blank"">2111.12922</a>",,2025-12-03 22:39:25
Simple Contrastive Representation Adversarial Learning for NLP Tasks,"Deshui Miao, Jiaqi Zhang, Wenbo Xie, Jian Song, Xin Li, Lijuan Jia, Ning Guo",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.13301"" target=""_blank"">2111.13301</a>",,2025-12-03 22:39:25
Going Grayscale: The Road to Understanding and Improving Unlearnable Examples,"Zhuoran Liu, Zhengyu Zhao, Alex Kolmus, Tijn Berns, Laarhoven Twan van, Tom Heskes, Martha Larson",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.13244"" target=""_blank"">2111.13244</a>",,2025-12-03 22:39:25
Towards Practical Deployment-Stage Backdoor Attack on Deep Neural Networks,"Xiangyu Qi, Tinghao Xie, Ruizhe Pan, Jifeng Zhu, Yong Yang, Kai Bu",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.12965"" target=""_blank"">2111.12965</a>",,2025-12-03 22:39:25
Joint inference and input optimization in equilibrium networks,"Swaminathan Gurumurthy, Shaojie Bai, Zachary Manchester, J. Zico Kolter",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.13236"" target=""_blank"">2111.13236</a>",,2025-12-03 22:39:25
Unity is strength: Improving the Detection of Adversarial Examples with Ensemble Approaches,"Francesco Craighero, Fabrizio Angaroni, Fabio Stella, Chiara Damiani, Marco Antoniotti, Alex Graudenzi",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.12631"" target=""_blank"">2111.12631</a>",,2025-12-03 22:39:25
Thundernna: a white box adversarial attack,"Linfeng Ye, Shayan Mohajer Hamidi",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.12305"" target=""_blank"">2111.12305</a>",,2025-12-03 22:39:25
Robustness against Adversarial Attacks in Neural Networks using Incremental Dissipativity,"Bernardo Aquino, Arash Rahnama, Peter Seiler, Lizhen Lin, Vijay Gupta",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.12906"" target=""_blank"">2111.12906</a>",,2025-12-03 22:39:25
WFDefProxy: Modularly Implementing and Empirically Evaluating Website Fingerprinting Defenses,"Jiajun Gong, Wuqi Zhang, Charles Zhang, Tao Wang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.12629"" target=""_blank"">2111.12629</a>",,2025-12-03 22:39:25
Sharpness-aware Quantization for Deep Neural Networks,"Jing Liu, Jianfei Cai, Bohan Zhuang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.12273"" target=""_blank"">2111.12273</a>",,2025-12-03 22:39:25
Adaptive Image Transformations for Transfer-based Adversarial Attack,"Zheng Yuan, Jie Zhang, Shiguang Shan",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.13844"" target=""_blank"">2111.13844</a>",,2025-12-03 22:39:25
Automated Runtime-Aware Scheduling for Multi-Tenant DNN Inference on GPU,"Fuxun Yu, Shawn Bray, Di Wang, Longfei Shangguan, Xulong Tang, Chenchen Liu, Xiang Chen",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.14255"" target=""_blank"">2111.14255</a>",,2025-12-03 22:39:25
An Attack on Facial Soft-biometric Privacy Enhancement,"Dailé Osorio-Roig, Christian Rathgeb, Pawel Drozdowski, Philipp Terhörst, Vitomir Štruc, Christoph Busch",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.12405"" target=""_blank"">2111.12405</a>",,2025-12-03 22:39:25
MALIGN: Explainable Static Raw-byte Based Malware Family Classification using Sequence Alignment,"Shoumik Saha, Sadia Afroz, Atif Rahman",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.14185"" target=""_blank"">2111.14185</a>",,2025-12-03 22:39:25
Using a GAN to Generate Adversarial Examples to Facial Image Recognition,"Andrew Merrigan, Alan F. Smeaton",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.15213"" target=""_blank"">2111.15213</a>",,2025-12-03 22:39:25
Generating Unrestricted 3D Adversarial Point Clouds,"Xuelong Dai, Yanjie Li, Hua Dai, Bin Xiao",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.08973"" target=""_blank"">2111.08973</a>",,2025-12-03 22:39:25
Mitigating Adversarial Attacks by Distributing Different Copies to Different Users,"Jiyi Zhang, Wesley Joon-Wie Tann, Ee-Chien Chang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.15160"" target=""_blank"">2111.15160</a>",,2025-12-03 22:39:25
Human Imperceptible Attacks and Applications to Improve Fairness,"Xinru Hua, Huanzhong Xu, Jose Blanchet, Viet Nguyen",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.15603"" target=""_blank"">2111.15603</a>",,2025-12-03 22:39:25
FROB: Few-shot ROBust Model for Classification and Out-of-Distribution Detection,Nikolaos Dionelis,arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.15487"" target=""_blank"">2111.15487</a>",,2025-12-03 22:39:25
COREATTACK: Breaking Up the Core Structure of Graphs,"Bo Zhou, Yuqian Lv, Jinhuan Wang, Jian Zhang, Qi Xuan",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.15276"" target=""_blank"">2111.15276</a>",,2025-12-03 22:39:25
"A Face Recognition System's Worst Morph Nightmare, Theoretically","Una M. Kelly, Raymond Veldhuis, Luuk Spreeuwers",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.15416"" target=""_blank"">2111.15416</a>",,2025-12-03 22:39:25
New Datasets for Dynamic Malware Classification,"Berkant Düzgün, Aykut Çayır, Ferhat Demirkıran, Ceyda Nur Kayha, Buket Gençaydın, Hasan Dağ",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.15205"" target=""_blank"">2111.15205</a>",,2025-12-03 22:39:25
MedRDF: A Robust and Retrain-Less Diagnostic Framework for Medical Pretrained Models Against Adversarial Attack,"Mengting Xu, Tao Zhang, Daoqiang Zhang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.14564"" target=""_blank"">2111.14564</a>",,2025-12-03 22:39:25
Adversarial Attacks in Cooperative AI,"Ted Fujimoto, Arthur Paul Pedersen",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.14833"" target=""_blank"">2111.14833</a>",,2025-12-03 22:39:25
Living-Off-The-Land Command Detection Using Active Learning,"Talha Ongun, Jack W. Stokes, Jonathan Bar Or, Ke Tian, Farid Tajaddodianfar, Joshua Neil, Christian Seifert, Alina Oprea, John C. Platt",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.15039"" target=""_blank"">2111.15039</a>",,2025-12-03 22:39:25
Do Invariances in Deep Neural Networks Align with Human Perception? (9%),"Vedant Nanda, Ayan Majumdar, Camila Kolling, John P. Dickerson, Krishna P. Gummadi, Bradley C. Love, Adrian Weller",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.14726"" target=""_blank"">2111.14726</a>",,2025-12-03 22:39:25
A Simple Long-Tailed Recognition Baseline via Vision-Language Model,"Teli Ma, Shijie Geng, Mengmeng Wang, Jing Shao, Jiasen Lu, Hongsheng Li, Peng Gao, Yu Qiao",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.14745"" target=""_blank"">2111.14745</a>","<a href=""https://github.com/gaopengcuhk/BALLAD"" target=""_blank"">gaopengcuhk</a>",2025-12-03 22:39:25
ROBIN : A Benchmark for Robustness to Individual Nuisances in Real-World Out-of-Distribution Shifts,"Bingchen Zhao, Shaozuo Yu, Wufei Ma, Mingxin Yu, Shenxiao Mei, Angtian Wang, Ju He, Alan Yuille, Adam Kortylewski",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.14341"" target=""_blank"">2111.14341</a>",,2025-12-03 22:39:25
"Detecting Adversaries, yet Faltering to Noise? Leveraging Conditional Variational AutoEncoders for Adversary Detection in the Presence of Noisy Images","Dvij Kalaria, Aritra Hazra, Partha Pratim Chakrabarti",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.15518"" target=""_blank"">2111.15518</a>",,2025-12-03 22:39:25
SLA$^2$P: Self-supervised Anomaly Detection with Adversarial Perturbation,"Yizhou Wang, Can Qin, Rongzhe Wei, Yi Xu, Yue Bai, Yun Fu",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.12896"" target=""_blank"">2111.12896</a>",,2025-12-03 22:39:25
Pyramid Adversarial Training Improves ViT Performance,"Charles Herrmann, Kyle Sargent, Lu Jiang, Ramin Zabih, Huiwen Chang, Ce Liu, Dilip Krishnan, Deqing Sun",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.15121"" target=""_blank"">2111.15121</a>",,2025-12-03 22:39:25
Accelerating Deep Learning with Dynamic Data Pruning,"Ravi S Raju, Kyle Daruwalla, Mikko Lipasti",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.12621"" target=""_blank"">2111.12621</a>",,2025-12-03 22:39:25
Are Vision Transformers Robust to Patch Perturbations? (98%),"Jindong Gu, Volker Tresp, Yao Qin",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10659"" target=""_blank"">2111.10659</a>",,2025-12-03 22:39:25
Meta Adversarial Perturbations,"Chia-Hung Yuan, Pin-Yu Chen, Chia-Mu Yu",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10291"" target=""_blank"">2111.10291</a>",,2025-12-03 22:39:25
Resilience from Diversity: Population-based approach to harden models against adversarial attacks,"Jasser Jasser, Ivan Garibay",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10272"" target=""_blank"">2111.10272</a>",,2025-12-03 22:39:25
Enhanced countering adversarial attacks via input denoising and feature restoring,"Yanni Li, Wenhui Zhang, Jiawei Liu, Xiaoli Kou, Hui Li, Jiangtao Cui",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10075"" target=""_blank"">2111.10075</a>","<a href=""https://github.com/ID-FR/IDFR"" target=""_blank"">ID-FR</a>",2025-12-03 22:39:25
PatchCensor: Patch Robustness Certification for Transformers via Exhaustive Testing,"Yuheng Huang, Lei Ma, Yuanchun Li",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10481"" target=""_blank"">2111.10481</a>",,2025-12-03 22:39:25
Fooling Adversarial Training with Inducing Noise,"Zhirui Wang, Yifei Wang, Yisen Wang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10130"" target=""_blank"">2111.10130</a>",,2025-12-03 22:39:25
Exposing Weaknesses of Malware Detectors with Explainability-Guided Evasion Attacks,"Wei Wang, Ruoxi Sun, Tian Dong, Shaofeng Li, Minhui Xue, Gareth Tyson, Haojin Zhu",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10085"" target=""_blank"">2111.10085</a>",,2025-12-03 22:39:25
TnT Attacks! Universal Naturalistic Adversarial Patches Against Deep Neural Network Systems,"Bao Gia Doan, Minhui Xue, Shiqing Ma, Ehsan Abbasnejad, Damith C. Ranasinghe",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.09999"" target=""_blank"">2111.09999</a>",,2025-12-03 22:39:25
Robust Person Re-identification with Multi-Modal Joint Defence,"Yunpeng Gong, Lifei Chen",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.09571"" target=""_blank"">2111.09571</a>","<a href=""https://github.com/finger-monkey/multi-modal_joint_defence"" target=""_blank"">finger-monkey</a>",2025-12-03 22:39:25
Enhancing the Insertion of NOP Instructions to Obfuscate Malware via Deep Reinforcement Learning,"Daniel Gibert, Matt Fredrikson, Carles Mateu, Jordi Planes, Quan Le",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.09626"" target=""_blank"">2111.09626</a>",,2025-12-03 22:39:25
Adversarial attacks on voter model dynamics in complex networks,"Katsumi Chiyomaru, Kazuhiro Takemoto",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.09561"" target=""_blank"">2111.09561</a>",,2025-12-03 22:39:25
Enhanced Membership Inference Attacks against Machine Learning Models,"Jiayuan Ye, Aadyaa Maddi, Sasi Kumar Murakonda, Reza Shokri",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.09679"" target=""_blank"">2111.09679</a>",,2025-12-03 22:39:25
Wiggling Weights to Improve the Robustness of Classifiers,"Sadaf Gulshad, Ivan Sosnovik, Arnold Smeulders",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.09779"" target=""_blank"">2111.09779</a>",,2025-12-03 22:39:25
Adversarial machine learning for protecting against online manipulation,"Stefano Cresci, Marinella Petrocchi, Angelo Spognardi, Stefano Tognazzi",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.12034"" target=""_blank"">2111.12034</a>",,2025-12-03 22:39:25
Improving Transferability of Representations via Augmentation-Aware Self-Supervision,"Hankook Lee, Kibok Lee, Kimin Lee, Honglak Lee, Jinwoo Shin",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.09613"" target=""_blank"">2111.09613</a>","<a href=""https://github.com/hankook/AugSelf"" target=""_blank"">hankook</a>",2025-12-03 22:39:25
TraSw: Tracklet-Switch Adversarial Attacks against Multi-Object Tracking,"Delv Lin, Qi Chen, Chengyu Zhou, Kun He",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.08954"" target=""_blank"">2111.08954</a>","<a href=""https://github.com/DerryHub/FairMOT-attack"" target=""_blank"">DerryHub</a>",2025-12-03 22:39:25
Towards Efficiently Evaluating the Robustness of Deep Neural Networks in IoT Systems: A GAN-based Method,"Tao Bai, Jun Zhao, Jinlin Zhu, Shoudong Han, Jiefeng Chen, Bo Li, Alex Kot",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10055"" target=""_blank"">2111.10055</a>",,2025-12-03 22:39:25
A Review of Adversarial Attack and Defense for Classification Methods,"Yao Li, Minhao Cheng, Cho-Jui Hsieh, Thomas C. M. Lee",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.09961"" target=""_blank"">2111.09961</a>",,2025-12-03 22:39:25
Denoised Internal Models: a Brain-Inspired Autoencoder against Adversarial Attacks,"Kaiyuan Liu, Xingyu Li, Yi Zhou, Jisong Guan, Yurui Lai, Ge Zhang, Hang Su, Jiachen Wang, Chunxu Guo",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10844"" target=""_blank"">2111.10844</a>",,2025-12-03 22:39:25
A Comparison of State-of-the-Art Techniques for Generating Adversarial Malware Binaries,"Prithviraj Dasgupta, Zachariah Osman",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.11487"" target=""_blank"">2111.11487</a>",,2025-12-03 22:39:25
HERO: Hessian-Enhanced Robust Optimization for Unifying and Improving Generalization and Quantization Performance,"Huanrui Yang, Xiaoxuan Yang, Neil Zhenqiang Gong, Yiran Chen",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.11986"" target=""_blank"">2111.11986</a>",,2025-12-03 22:39:25
Local Linearity and Double Descent in Catastrophic Overfitting,"Varun Sivashankar, Nikil Selvam",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10754"" target=""_blank"">2111.10754</a>",,2025-12-03 22:39:25
Adversarial Examples on Segmentation Models Can be Easy to Transfer,"Jindong Gu, Hengshuang Zhao, Volker Tresp, Philip Torr",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.11368"" target=""_blank"">2111.11368</a>",,2025-12-03 22:39:25
Evaluating Adversarial Attacks on ImageNet: A Reality Check on Misclassification Classes,"Utku Ozbulak, Maura Pintor, Messem Arnout Van, Neve Wesley De",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.11056"" target=""_blank"">2111.11056</a>",,2025-12-03 22:39:25
Backdoor Attack through Frequency Domain,"Tong Wang, Yuan Yao, Feng Xu, Shengwei An, Hanghang Tong, Ting Wang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10991"" target=""_blank"">2111.10991</a>",,2025-12-03 22:39:25
NTD: Non-Transferability Enabled Backdoor Detection,"Yinshan Li, Hua Ma, Zhi Zhang, Yansong Gao, Alsharif Abuadbba, Anmin Fu, Yifeng Zheng, Said F. Al-Sarawi, Derek Abbott",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.11157"" target=""_blank"">2111.11157</a>",,2025-12-03 22:39:25
Fixed Points in Cyber Space: Rethinking Optimal Evasion Attacks in the Age of AI-NIDS,"Witt Christian Schroeder de, Yongchao Huang, Philip H. S. Torr, Martin Strohmeier",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.12197"" target=""_blank"">2111.12197</a>",,2025-12-03 22:39:25
Imperceptible Transfer Attack and Defense on 3D Point Cloud Classification,"Daizong Liu, Wei Hu",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10990"" target=""_blank"">2111.10990</a>",,2025-12-03 22:39:25
Poisoning Attacks to Local Differential Privacy Protocols for Key-Value Data,"Yongji Wu, Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.11534"" target=""_blank"">2111.11534</a>",,2025-12-03 22:39:25
Stochastic Variance Reduced Ensemble Adversarial Attack for Boosting the Adversarial Transferability,"Yifeng Xiong, Jiadong Lin, Min Zhang, John E. Hopcroft, Kun He",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10752"" target=""_blank"">2111.10752</a>","<a href=""https://github.com/JHL-HUST/SVRE"" target=""_blank"">JHL-HUST</a>",2025-12-03 22:39:25
Medical Aegis: Robust adversarial protectors for medical images,"Qingsong Yao, Zecheng He, S. Kevin Zhou",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10969"" target=""_blank"">2111.10969</a>",,2025-12-03 22:39:25
Automatic Mapping of the Best-Suited DNN Pruning Schemes for Real-Time Mobile Acceleration,"Yifan Gong, Geng Yuan, Zheng Zhan, Wei Niu, Zhengang Li, Pu Zhao, Yuxuan Cai, Sijia Liu, Bin Ren, Xue Lin, Xulong Tang, Yanzhi Wang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.11581"" target=""_blank"">2111.11581</a>",,2025-12-03 22:39:25
Adversarial Mask: Real-World Universal Adversarial Attack on Face Recognition Model,"Alon Zolfi, Shai Avidan, Yuval Elovici, Asaf Shabtai",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.10759"" target=""_blank"">2111.10759</a>",,2025-12-03 22:39:25
Electric Vehicle Attack Impact on Power Grid Operation,"Mohammad Ali Sayed, Ribal Atallah, Chadi Assi, Mourad Debbabi",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.11317"" target=""_blank"">2111.11317</a>",,2025-12-03 22:39:25
Subspace Adversarial Training,"Tao Li, Yingwen Wu, Sizhe Chen, Kun Fang, Xiaolin Huang",arXiv,2021-11,"<a href=""http://arxiv.org/abs/2111.12229"" target=""_blank"">2111.12229</a>","<a href=""https://github.com/nblt/Sub-AT"" target=""_blank"">nblt</a>",2025-12-03 22:39:25
SEPP: Similarity Estimation of Predicted Probabilities for Defending and Detecting Adversarial Text,"Hoang-Quoc Nguyen-Son, Seira Hidano, Kazuhide Fukushima, Shinsaku Kiyomoto",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.05748"" target=""_blank"">2110.05748</a>",,2025-12-03 22:39:25
On the Security Risks of AutoML,"Ren Pang, Zhaohan Xi, Shouling Ji, Xiapu Luo, Ting Wang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.06018"" target=""_blank"">2110.06018</a>",,2025-12-03 22:39:25
Zero-bias Deep Neural Network for Quickest RF Signal Surveillance,"Yongxin Liu, Yingjie Chen, Jian Wang, Shuteng Niu, Dahai Liu, Houbing Song",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.05797"" target=""_blank"">2110.05797</a>",,2025-12-03 22:39:25
Hiding Images into Images with Real-world Robustness,"Qichao Ying, Hang Zhou, Xianhan Zeng, Haisheng Xu, Zhenxing Qian, Xinpeng Zhang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.05689"" target=""_blank"">2110.05689</a>",,2025-12-03 22:39:25
Graph-Fraudster: Adversarial Attacks on Graph Neural Network Based Vertical Federated Learning,"Jinyin Chen, Guohan Huang, Haibin Zheng, Shanqing Yu, Wenrong Jiang, Chen Cui",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.06468"" target=""_blank"">2110.06468</a>","<a href=""https://github.com/hgh0545/Graph-Fraudster"" target=""_blank"">hgh0545</a>",2025-12-03 22:39:25
Boosting Fast Adversarial Training with Learnable Adversarial Initialization,"Xiaojun Jia, Yong Zhang, Baoyuan Wu, Jue Wang, Xiaochun Cao",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.05007"" target=""_blank"">2110.05007</a>","<a href=""https://github.com//jiaxiaojunQAQ//FGSM-SDI"" target=""_blank""></a>",2025-12-03 22:39:25
Parameterizing Activation Functions for Adversarial Robustness,"Sihui Dai, Saeed Mahloujifar, Prateek Mittal",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.05626"" target=""_blank"">2110.05626</a>",,2025-12-03 22:39:25
Amicable examples for informed source separation,"Naoya Takahashi, Yuki Mitsufuji",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.05059"" target=""_blank"">2110.05059</a>",,2025-12-03 22:39:25
Doubly-Trained Adversarial Data Augmentation for Neural Machine Translation,"Weiting Tan, Shuoyang Ding, Huda Khayrallah, Philipp Koehn",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.05691"" target=""_blank"">2110.05691</a>",,2025-12-03 22:39:25
Intriguing Properties of Input-dependent Randomized Smoothing,"Peter Súkeník, Aleksei Kuvshinov, Stephan Günnemann",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.05365"" target=""_blank"">2110.05365</a>",,2025-12-03 22:39:25
Adversarial Attacks in a Multi-view Setting: An Empirical Study of the Adversarial Patches Inter-view Transferability,"Bilel Tarchoun, Ihsen Alouani, Anouar Ben Khalifa, Mohamed Ali Mahjoub",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.04887"" target=""_blank"">2110.04887</a>",,2025-12-03 22:39:25
Source Mixing and Separation Robust Audio Steganography,"Naoya Takahashi, Mayank Kumar Singh, Yuki Mitsufuji",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.05054"" target=""_blank"">2110.05054</a>",,2025-12-03 22:39:25
Homogeneous Learning: Self-Attention Decentralized Deep Learning,"Yuwei Sun, Hideya Ochiai",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.05290"" target=""_blank"">2110.05290</a>",,2025-12-03 22:39:25
Large Language Models Can Be Strong Differentially Private Learners,"Xuechen Li, Florian Tramèr, Percy Liang, Tatsunori Hashimoto",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.05679"" target=""_blank"">2110.05679</a>",,2025-12-03 22:39:25
A Closer Look at Prototype Classifier for Few-shot Image Classification,"Mingcheng Hou, Issei Sato",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.05076"" target=""_blank"">2110.05076</a>",,2025-12-03 22:39:25
Certified Patch Robustness via Smoothed Vision Transformers,"Hadi Salman, Saachi Jain, Eric Wong, Aleksander Mądry",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07719"" target=""_blank"">2110.07719</a>","<a href=""https://github.com/MadryLab/smoothed-vit"" target=""_blank"">MadryLab</a>",2025-12-03 22:39:25
Universal Adversarial Attacks on Neural Networks for Power Allocation in a Massive MIMO System,"Pablo Millán Santos, B. R. Manoj, Meysam Sadeghi, Erik G. Larsson",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.04731"" target=""_blank"">2110.04731</a>",,2025-12-03 22:39:25
Demystifying the Transferability of Adversarial Attacks in Computer Networks,"Ehsan Nowroozi, Yassine Mekdad, Mohammad Hajian Berenjestanaki, Mauro Conti, Abdeslam EL Fergougui",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.04488"" target=""_blank"">2110.04488</a>",,2025-12-03 22:39:25
Provably Efficient Black-Box Action Poisoning Attacks Against Reinforcement Learning,"Guanlin Liu, Lifeng Lai",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.04471"" target=""_blank"">2110.04471</a>",,2025-12-03 22:39:25
Benchmarking the Robustness of Spatial-Temporal Models Against Corruptions,"Chenyu Yi, Siyuan Yang, Haoliang Li, Yap-peng Tan, Alex Kot",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.06513"" target=""_blank"">2110.06513</a>",,2025-12-03 22:39:25
Widen The Backdoor To Let More Attackers In,"Siddhartha Datta, Giulio Lovisotto, Ivan Martinovic, Nigel Shadbolt",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.04571"" target=""_blank"">2110.04571</a>",,2025-12-03 22:39:25
Adversarial Attack across Datasets,"Yunxiao Qin, Yuanhao Xiong, Jinfeng Yi, Cho-Jui Hsieh",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07718"" target=""_blank"">2110.07718</a>",,2025-12-03 22:39:25
RAP: Robustness-Aware Perturbations for Defending against Backdoor Attacks on NLP Models,"Wenkai Yang, Yankai Lin, Peng Li, Jie Zhou, Xu Sun",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07831"" target=""_blank"">2110.07831</a>","<a href=""https://github.com/lancopku/RAP"" target=""_blank"">lancopku</a>",2025-12-03 22:39:25
Boosting the Certified Robustness of L-infinity Distance Nets,"Bohang Zhang, Du Jiang, Di He, Liwei Wang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.06850"" target=""_blank"">2110.06850</a>","<a href=""https://github.com/zbh2047/L_inf-dist-net-v2"" target=""_blank"">zbh2047</a>",2025-12-03 22:39:25
On Adversarial Vulnerability of PHM algorithms: An Initial Study,"Weizhong Yan, Zhaoyuan Yang, Jianwei Qiu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07462"" target=""_blank"">2110.07462</a>",,2025-12-03 22:39:25
Game Theory for Adversarial Attacks and Defenses,Shorya Sharma,arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.06166"" target=""_blank"">2110.06166</a>",,2025-12-03 22:39:25
Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks,"Yangyi Chen, Fanchao Qi, Zhiyuan Liu, Maosong Sun",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08247"" target=""_blank"">2110.08247</a>",,2025-12-03 22:39:25
Understanding and Improving Robustness of Vision Transformers through Patch-based Negative Augmentation,"Yao Qin, Chiyuan Zhang, Ting Chen, Balaji Lakshminarayanan, Alex Beutel, Xuezhi Wang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07858"" target=""_blank"">2110.07858</a>",,2025-12-03 22:39:25
Hand Me Your PIN! Inferring ATM PINs of Users Typing with a Covered Hand,"Matteo Cardaioli, Stefano Cecconello, Mauro Conti, Simone Milani, Stjepan Picek, Eugen Saraci",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08113"" target=""_blank"">2110.08113</a>",,2025-12-03 22:39:25
Adversarial examples by perturbing high-level features in intermediate decoder layers,"Vojtěch Čermák, Lukáš Adam",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07182"" target=""_blank"">2110.07182</a>",,2025-12-03 22:39:25
DI-AA: An Interpretable White-box Attack for Fooling Deep Neural Networks,"Yixiang Wang, Jiqiang Liu, Xiaolin Chang, Jianhua Wang, Ricardo J. Rodríguez",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07305"" target=""_blank"">2110.07305</a>",,2025-12-03 22:39:25
Adversarial Purification through Representation Disentanglement,"Tao Bai, Jun Zhao, Lanqing Guo, Bihan Wen",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07801"" target=""_blank"">2110.07801</a>",,2025-12-03 22:39:25
An Optimization Perspective on Realizing Backdoor Injection Attacks on Deep Neural Networks in Hardware,"M. Caner Tol, Saad Islam, Berk Sunar, Ziming Zhang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07683"" target=""_blank"">2110.07683</a>",,2025-12-03 22:39:25
Interactive Analysis of CNN Robustness,"Stefan Sietzen, Mathias Lechner, Judy Borowski, Ramin Hasani, Manuela Waldner",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07667"" target=""_blank"">2110.07667</a>",,2025-12-03 22:39:25
Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,"Tianlu Wang, Diyi Yang, Xuezhi Wang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07736"" target=""_blank"">2110.07736</a>",,2025-12-03 22:39:25
Poison Forensics: Traceback of Data Poisoning Attacks in Neural Networks,"Shawn Shan, Arjun Nitin Bhagoji, Haitao Zheng, Ben Y. Zhao",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.06904"" target=""_blank"">2110.06904</a>",,2025-12-03 22:39:25
Toward Degradation-Robust Voice Conversion,"Chien-yu Huang, Kai-Wei Chang, Hung-yi Lee",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07537"" target=""_blank"">2110.07537</a>",,2025-12-03 22:39:25
Interpreting the Robustness of Neural NLP Models to Textual Perturbations,"Yunxiang Zhang, Liangming Pan, Samson Tan, Min-Yen Kan",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07159"" target=""_blank"">2110.07159</a>",,2025-12-03 22:39:25
Retrieval-guided Counterfactual Generation for QA,"Bhargavi Paranjape, Matthew Lamm, Ian Tenney",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07596"" target=""_blank"">2110.07596</a>",,2025-12-03 22:39:25
Effective Certification of Monotone Deep Equilibrium Models,"Mark Niklas Müller, Robin Staab, Marc Fischer, Martin Vechev",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08260"" target=""_blank"">2110.08260</a>",,2025-12-03 22:39:25
A Framework for Verification of Wasserstein Adversarial Robustness,"Tobias Wegel, Felix Assion, David Mickisch, Florens Greßner",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.06816"" target=""_blank"">2110.06816</a>",,2025-12-03 22:39:25
Identification of Attack-Specific Signatures in Adversarial Examples,"Hossein Souri, Pirazh Khorramshahi, Chun Pong Lau, Micah Goldblum, Rama Chellappa",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.06802"" target=""_blank"">2110.06802</a>",,2025-12-03 22:39:25
Model-Agnostic Meta-Attack: Towards Reliable Evaluation of Adversarial Robustness,"Xiao Yang, Yinpeng Dong, Wenzhao Xiang, Tianyu Pang, Hang Su, Jun Zhu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08256"" target=""_blank"">2110.08256</a>",,2025-12-03 22:39:25
Mind the Style of Text! Adversarial and Backdoor Attacks Based on Text Style Transfer,"Fanchao Qi, Yangyi Chen, Xurui Zhang, Mukai Li, Zhiyuan Liu, Maosong Sun",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07139"" target=""_blank"">2110.07139</a>","<a href=""https://github.com/thunlp/StyleAttack"" target=""_blank"">thunlp</a>",2025-12-03 22:39:25
Brittle interpretations: The Vulnerability of TCAV and Other Concept-based Explainability Tools to Adversarial Attack,"Davis Brown, Henry Kvinge",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.07120"" target=""_blank"">2110.07120</a>",,2025-12-03 22:39:25
Explainability-Aware One Point Attack for Point Cloud Neural Networks,"Hanxiao Tan, Helena Kotthaus",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.04158"" target=""_blank"">2110.04158</a>","<a href=""https://github.com/Explain3D/Exp-One-Point-Atk-PC"" target=""_blank"">Explain3D</a>",2025-12-03 22:39:25
CADA: Multi-scale Collaborative Adversarial Domain Adaptation for Unsupervised Optic Disc and Cup Segmentation,"Peng Liu, Charlie T. Tran, Bin Kong, Ruogu Fang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02417"" target=""_blank"">2110.02417</a>",,2025-12-03 22:39:25
Graphs as Tools to Improve Deep Learning Methods,"Carlos Lassance, Myriam Bontonou, Mounia Hamidouche, Bastien Pasdeloup, Lucas Drumetz, Vincent Gripon",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03999"" target=""_blank"">2110.03999</a>",,2025-12-03 22:39:25
Spectral Bias in Practice: The Role of Function Frequency in Generalization,"Sara Fridovich-Keil, Raphael Gontijo-Lopes, Rebecca Roelofs",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02424"" target=""_blank"">2110.02424</a>",,2025-12-03 22:39:25
Efficient Sharpness-aware Minimization for Improved Training of Neural Networks,"Jiawei Du, Hanshu Yan, Jiashi Feng, Joey Tianyi Zhou, Liangli Zhen, Rick Siow Mong Goh, Vincent Y. F. Tan",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03141"" target=""_blank"">2110.03141</a>",,2025-12-03 22:39:25
"Stegomalware: A Systematic Survey of MalwareHiding and Detection in Images, Machine LearningModels and Research Challenges","Rajasekhar Chaganti, Vinayakumar Ravi, Mamoun Alazab, Tuan D. Pham",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02504"" target=""_blank"">2110.02504</a>",,2025-12-03 22:39:25
Exploring the Common Principal Subspace of Deep Features in Neural Networks,"Haoran Liu, Haoyi Xiong, Yaqing Wang, Haozhe An, Dongrui Wu, Dejing Dou",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02863"" target=""_blank"">2110.02863</a>",,2025-12-03 22:39:25
Generalizing Neural Networks by Reflecting Deviating Data in Production,"Yan Xiao, Yun Lin, Ivan Beschastnikh, Changsheng Sun, David S. Rosenblum, Jin Song Dong",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02718"" target=""_blank"">2110.02718</a>",,2025-12-03 22:39:25
Adversarial Robustness Verification and Attack Synthesis in Stochastic Systems,"Lisa Oakley, Alina Oprea, Stavros Tripakis",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02125"" target=""_blank"">2110.02125</a>",,2025-12-03 22:39:25
Adversarial Attacks on Black Box Video Classifiers: Leveraging the Power of Geometric Transformations,"Shasha Li, Abhishek Aich, Shitong Zhu, M. Salman Asif, Chengyu Song, Amit K. Roy-Chowdhury, Srikanth Krishnamurthy",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.01823"" target=""_blank"">2110.01823</a>",,2025-12-03 22:39:25
Adversarial defenses via a mixture of generators,"Maciej Żelaszczyk, Jacek Mańdziuk",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02364"" target=""_blank"">2110.02364</a>",,2025-12-03 22:39:25
Neural Network Adversarial Attack Method Based on Improved Genetic Algorithm,"Dingming Yang, Yanrong Cui, Hongqiang Yuan",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.01818"" target=""_blank"">2110.01818</a>",,2025-12-03 22:39:25
BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models,"Kangjie Chen, Yuxian Meng, Xiaofei Sun, Shangwei Guo, Tianwei Zhang, Jiwei Li, Chun Fan",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02467"" target=""_blank"">2110.02467</a>",,2025-12-03 22:39:25
Noisy Feature Mixup,"Soon Hoe Lim, N. Benjamin Erichson, Francisco Utrera, Winnie Xu, Michael W. Mahoney",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02180"" target=""_blank"">2110.02180</a>",,2025-12-03 22:39:25
IHOP: Improved Statistical Query Recovery against Searchable Symmetric Encryption through Quadratic Optimization,"Simon Oya, Florian Kerschbaum",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.04180"" target=""_blank"">2110.04180</a>",,2025-12-03 22:39:25
Benchmarking Safety Monitors for Image Classifiers with Machine Learning,"Raul Sena LAAS Ferreira, Jean LAAS Arlat, Jeremie LAAS Guiochet, Hélène LAAS Waeselynck",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.01232"" target=""_blank"">2110.01232</a>",,2025-12-03 22:39:25
Adversarial Examples Generation for Reducing Implicit Gender Bias in Pre-trained Models,"Wenqian Ye, Fei Xu, Yaojia Huang, Cassie Huang, Ji A",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.01094"" target=""_blank"">2110.01094</a>",,2025-12-03 22:39:25
Evaluating Deep Learning Models and Adversarial Attacks on Accelerometer-Based Gesture Authentication,"Elliu Huang, Troia Fabio Di, Mark Stamp",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14597"" target=""_blank"">2110.14597</a>",,2025-12-03 22:39:25
Anti-aliasing Deep Image Classifiers using Novel Depth Adaptive Blurring and Activation Function,"Md Tahmid Hossain, Shyh Wei Teng, Ferdous Sohel, Guojun Lu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.00899"" target=""_blank"">2110.00899</a>",,2025-12-03 22:39:25
Calibrated Adversarial Training,"Tianjin Huang, Vlado Menkovski, Yulong Pei, Mykola Pechenizkiy",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.00623"" target=""_blank"">2110.00623</a>",,2025-12-03 22:39:25
Universal Adversarial Spoofing Attacks against Face Recognition,"Takuma Amada, Seng Pei Liew, Kazuya Kakizaki, Toshinori Araki",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.00708"" target=""_blank"">2110.00708</a>",,2025-12-03 22:39:25
Score-Based Generative Classifiers,"Roland S. Zimmermann, Lukas Schott, Yang Song, Benjamin A. Dunn, David A. Klindt",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.00473"" target=""_blank"">2110.00473</a>",,2025-12-03 22:39:25
One Timestep is All You Need: Training Spiking Neural Networks with Ultra Low Latency,"Sayeed Shafayet Chowdhury, Nitin Rathi, Kaushik Roy",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.05929"" target=""_blank"">2110.05929</a>",,2025-12-03 22:39:25
HAT4RD: Hierarchical Adversarial Training for Rumor Detection on Social Media,"Shiwen Ni, Jiawen Li, Hung-Yu Kao",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.00425"" target=""_blank"">2110.00425</a>",,2025-12-03 22:39:25
On The Vulnerability of Recurrent Neural Networks to Membership Inference Attacks,"Yunhao Yang, Parham Gohari, Ufuk Topcu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03054"" target=""_blank"">2110.03054</a>",,2025-12-03 22:39:25
Data-driven behavioural biometrics for continuous and adaptive user verification using Smartphone and Smartwatch,"Akriti Verma, Valeh Moghaddam, Adnan Anwar",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03149"" target=""_blank"">2110.03149</a>",,2025-12-03 22:39:25
Inference Attacks Against Graph Neural Networks,"Zhikun Zhang, Min Chen, Michael Backes, Yun Shen, Yang Zhang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02631"" target=""_blank"">2110.02631</a>","<a href=""https://github.com/Zhangzhk0819/GNN-Embedding-Leaks"" target=""_blank"">Zhangzhk0819</a>",2025-12-03 22:39:25
DoubleStar: Long-Range Attack Towards Depth Estimation based Obstacle Avoidance in Autonomous Systems,"Ce Michigan State University Zhou, Qiben Michigan State University Yan, Yan Michigan State University Shi, Lichao Lehigh University Sun",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03154"" target=""_blank"">2110.03154</a>",,2025-12-03 22:39:25
A Wireless Intrusion Detection System for 802,"Neil Dalal, Nadeem Akhtar, Anubhav Gupta, Nikhil Karamchandani, Gaurav S. Kasbekar, Jatin Parekh",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.04259"" target=""_blank"">2110.04259</a>",,2025-12-03 22:39:25
Salient ImageNet: How to discover spurious features in Deep Learning? (1%),"Sahil Singla, Soheil Feizi",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.04301"" target=""_blank"">2110.04301</a>",,2025-12-03 22:39:25
Robust Feature-Level Adversaries are Interpretability Tools,"Stephen Casper, Max Nadeau, Dylan Hadfield-Menell, Gabriel Kreiman",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03605"" target=""_blank"">2110.03605</a>","<a href=""https://github.com/thestephencasper/feature_level_adv"" target=""_blank"">thestephencasper</a>",2025-12-03 22:39:25
EvadeDroid: A Practical Evasion Attack on Machine Learning for Black-box Android Malware Detection,"Hamid Bostani, Veelasha Moonsamy",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03301"" target=""_blank"">2110.03301</a>",,2025-12-03 22:39:25
Adversarial Attack by Limited Point Cloud Surface Modifications,"Atrin Arya, Hanieh Naderi, Shohreh Kasaei",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03745"" target=""_blank"">2110.03745</a>",,2025-12-03 22:39:25
Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks,"Hanxun Huang, Yisen Wang, Sarah Monazam Erfani, Quanquan Gu, James Bailey, Xingjun Ma",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03825"" target=""_blank"">2110.03825</a>","<a href=""https://github.com/HanxunH/RobustWRN"" target=""_blank"">HanxunH</a>",2025-12-03 22:39:25
Dyn-Backdoor: Backdoor Attack on Dynamic Link Prediction,"Jinyin Chen, Haiyang Xiong, Haibin Zheng, Jian Zhang, Guodong Jiang, Yi Liu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03875"" target=""_blank"">2110.03875</a>",,2025-12-03 22:39:25
Robustness of different loss functions and their impact on networks learning capability,Vishal Rajput,arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08322"" target=""_blank"">2110.08322</a>",,2025-12-03 22:39:25
Adversarial Unlearning of Backdoors via Implicit Hypergradient,"Yi Zeng, Si Chen, Won Park, Z. Morley Mao, Ming Jin, Ruoxi Jia",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03735"" target=""_blank"">2110.03735</a>",,2025-12-03 22:39:25
MPSN: Motion-aware Pseudo Siamese Network for Indoor Video Head Detection in Buildings,"Kailai Sun, Xiaoteng Ma, Peng Liu, Qianchuan Zhao",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03302"" target=""_blank"">2110.03302</a>","<a href=""https://github.com/pl-share/MPSN"" target=""_blank"">pl-share</a>",2025-12-03 22:39:25
HIRE-SNN: Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Training with Crafted Input Noise,"Souvik Kundu, Massoud Pedram, Peter A. Beerel",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11417"" target=""_blank"">2110.11417</a>",,2025-12-03 22:39:25
Reversible adversarial examples against local visual perturbation,"Zhaoxia Yin, Li Chen, Shaowei Zhu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02700"" target=""_blank"">2110.02700</a>",,2025-12-03 22:39:25
Attack as the Best Defense: Nullifying Image-to-image Translation GANs via Limit-aware Adversarial Attack,"Chin-Yuan Yeh, Hsi-Wen Chen, Hong-Han Shuai, De-Nian Yang, Ming-Syan Chen",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02516"" target=""_blank"">2110.02516</a>",,2025-12-03 22:39:25
Adversarial Robustness Comparison of Vision Transformer and MLP-Mixer to CNNs,"Philipp Benz, Soomin Ham, Chaoning Zhang, Adil Karjauv, In So Kweon",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02797"" target=""_blank"">2110.02797</a>",,2025-12-03 22:39:25
Adversarial Attacks on Machinery Fault Diagnosis,"Jiahao Chen, Diqun Yan",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02498"" target=""_blank"">2110.02498</a>",,2025-12-03 22:39:25
Adversarial Attacks on Spiking Convolutional Networks for Event-based Vision,"Julian Büchel, Gregor Lenz, Yalun Hu, Sadique Sheik, Martino Sorbaro",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.02929"" target=""_blank"">2110.02929</a>",,2025-12-03 22:39:25
A Uniform Framework for Anomaly Detection in Deep Neural Networks,"Fangzhen Zhao, Chenyi Zhang, Naipeng Dong, Zefeng You, Zhenxin Wu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03092"" target=""_blank"">2110.03092</a>",,2025-12-03 22:39:25
Double Descent in Adversarial Training: An Implicit Label Noise Perspective,"Chengyu Dong, Liyuan Liu, Jingbo Shang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03135"" target=""_blank"">2110.03135</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness for Free with Snapshot Ensemble,Yihao Wang,arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03124"" target=""_blank"">2110.03124</a>",,2025-12-03 22:39:25
Chunked-Cache: On-Demand and Scalable Cache Isolation for Security Architectures,"Ghada Dessouky, Alexander Gruler, Pouya Mahmoody, Ahmad-Reza Sadeghi, Emmanuel Stapf",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08139"" target=""_blank"">2110.08139</a>",,2025-12-03 22:39:25
Fingerprinting Multi-exit Deep Neural Network Models via Inference Time,"Tian Dong, Han Qiu, Tianwei Zhang, Jiwei Li, Hewu Li, Jialiang Lu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.03175"" target=""_blank"">2110.03175</a>",,2025-12-03 22:39:25
Mitigating Membership Inference Attacks by Self-Distillation Through a Novel Ensemble Architecture,"Xinyu Tang, Saeed Mahloujifar, Liwei Song, Virat Shejwalkar, Milad Nasr, Amir Houmansadr, Prateek Mittal",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08324"" target=""_blank"">2110.08324</a>",,2025-12-03 22:39:25
Stable Neural ODE with Lyapunov-Stable Equilibrium Points for Defending Against Adversarial Attacks,"Qiyu Kang, Yang Song, Qinxu Ding, Wee Peng Tay",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.12976"" target=""_blank"">2110.12976</a>",,2025-12-03 22:39:25
Adversarial Robustness in Multi-Task Learning: Promises and Illusions,"Salah Ghamizi, Maxime Cordy, Mike Papadakis, Yves Le Traon",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.15053"" target=""_blank"">2110.15053</a>",,2025-12-03 22:39:25
AugMax: Adversarial Composition of Random Augmentations for Robust Training,"Haotao Wang, Chaowei Xiao, Jean Kossaifi, Zhiding Yu, Anima Anandkumar, Zhangyang Wang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.13771"" target=""_blank"">2110.13771</a>","<a href=""https://github.com/VITA-Group/AugMax"" target=""_blank"">VITA-Group</a>",2025-12-03 22:39:25
Qu-ANTI-zation: Exploiting Quantization Artifacts for Achieving Adversarial Outcomes,"Sanghyun Hong, Michael-Andrei Panaitescu-Liess, Yiğitcan Kaya, Tudor Dumitraş",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.13541"" target=""_blank"">2110.13541</a>","<a href=""https://github.com/Secure-AI-Systems-Group/Qu-ANTI-zation"" target=""_blank"">Secure-AI-Systems-Group</a>",2025-12-03 22:39:25
Semantic Host-free Trojan Attack,"Haripriya Harikumar, Kien Do, Santu Rana, Sunil Gupta, Svetha Venkatesh",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.13414"" target=""_blank"">2110.13414</a>",,2025-12-03 22:39:25
CAFE: Catastrophic Data Leakage in Vertical Federated Learning,"Xiao Jin, Pin-Yu Chen, Chia-Yi Hsu, Chia-Mu Yu, Tianyi Chen",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.15122"" target=""_blank"">2110.15122</a>","<a href=""https://github.com/DeRafael/CAFE"" target=""_blank"">DeRafael</a>",2025-12-03 22:39:25
MEST: Accurate and Fast Memory-Economic Sparse Training Framework on the Edge,"Geng Yuan, Xiaolong Ma, Wei Niu, Zhengang Li, Zhenglun Kong, Ning Liu, Yifan Gong, Zheng Zhan, Chaoyang He, Qing Jin, Siyue Wang, Minghai Qin, Bin Ren, Yanzhi Wang, Sijia Liu, Xue Lin",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14032"" target=""_blank"">2110.14032</a>","<a href=""https://github.com/boone891214/MEST"" target=""_blank"">boone891214</a>",2025-12-03 22:39:25
Reliable and Trustworthy Machine Learning for Health Using Dataset Shift Detection,"Chunjong Park, Anas Awadalla, Tadayoshi Kohno, Shwetak Patel",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14019"" target=""_blank"">2110.14019</a>",,2025-12-03 22:39:25
Defensive Tensorization,"Adrian Bulat, Jean Kossaifi, Sourav Bhattacharya, Yannis Panagakis, Timothy Hospedales, Georgios Tzimiropoulos, Nicholas D Lane, Maja Pantic",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.13859"" target=""_blank"">2110.13859</a>",,2025-12-03 22:39:25
Task-Aware Meta Learning-based Siamese Neural Network for Classifying Obfuscated Malware,"Jinting Zhu, Julian Jang-Jaccard, Amardeep Singh, Paul A. Watters, Seyit Camtepe",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.13409"" target=""_blank"">2110.13409</a>",,2025-12-03 22:39:25
Generating Watermarked Adversarial Texts,"Mingjie Li, Hanzhou Wu, Xinpeng Zhang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.12948"" target=""_blank"">2110.12948</a>",,2025-12-03 22:39:25
Robustness of Graph Neural Networks at Scale,"Simon Geisler, Tobias Schmidt, Hakan Şirin, Daniel Zügner, Aleksandar Bojchevski, Stephan Günnemann",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14038"" target=""_blank"">2110.14038</a>",,2025-12-03 22:39:25
Beyond $L_p$ clipping: Equalization-based Psychoacoustic Attacks against ASRs,"Hadi Abdullah, Muhammad Sajidur Rahman, Christian Peeters, Cassidy Gibson, Washington Garcia, Vincent Bindschaedler, Thomas Shrimpton, Patrick Traynor",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.13250"" target=""_blank"">2110.13250</a>",,2025-12-03 22:39:25
Fast Gradient Non-sign Methods,"Yaya Cheng, Jingkuan Song, Xiaosu Zhu, Qilong Zhang, Lianli Gao, Heng Tao Shen",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.12734"" target=""_blank"">2110.12734</a>","<a href=""https://github.com/yaya-cheng/FGNM"" target=""_blank"">yaya-cheng</a>",2025-12-03 22:39:25
Ensemble Federated Adversarial Training with Non-IID data,"Shuang Luo, Didi Zhu, Zexi Li, Chao Wu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14814"" target=""_blank"">2110.14814</a>",,2025-12-03 22:39:25
GANash -- A GAN approach to steganography,"Venkatesh Subramaniyan, Vignesh Sivakumar, A. K. Vagheesan, S. Sakthivelan, K. J. Jegadish Kumar, K. K. Nagarajan",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.13650"" target=""_blank"">2110.13650</a>",,2025-12-03 22:39:25
A Dynamical System Perspective for Lipschitz Neural Networks,"Laurent Meunier, Blaise Delattre, Alexandre Araujo, Alexandre Allauzen",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.12690"" target=""_blank"">2110.12690</a>",,2025-12-03 22:39:25
An Adaptive Structural Learning of Deep Belief Network for Image-based Crack Detection in Concrete Structures Using SDNET2018,"Shin Kamada, Takumi Ichimura, Takashi Iwasaki",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.12700"" target=""_blank"">2110.12700</a>",,2025-12-03 22:39:25
Towards A Conceptually Simple Defensive Approach for Few-shot classifiers Against Adversarial Support Samples,"Yi Xiang Marcus Tan, Penny Chong, Jiamei Sun, Ngai-man Cheung, Yuval Elovici, Alexander Binder",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.12357"" target=""_blank"">2110.12357</a>",,2025-12-03 22:39:25
ADC: Adversarial attacks against object Detection that evade Context consistency checks,"Mingjun Yin, Shasha Li, Chengyu Song, M. Salman Asif, Amit K. Roy-Chowdhury, Srikanth V. Krishnamurthy",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.12321"" target=""_blank"">2110.12321</a>",,2025-12-03 22:39:25
A Layer-wise Adversarial-aware Quantization Optimization for Improving Robustness,"Chang Song, Riya Ranjan, Hai Li",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.12308"" target=""_blank"">2110.12308</a>",,2025-12-03 22:39:25
"Adversarial Attacks and Defenses for Social Network Text Processing Applications: Techniques, Challenges and Future Research Directions","Izzat Alsmadi, Kashif Ahmad, Mahmoud Nazzal, Firoj Alam, Ala Al-Fuqaha, Abdallah Khreishah, Abdulelah Algosaibi",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.13980"" target=""_blank"">2110.13980</a>",,2025-12-03 22:39:25
Improving Local Effectiveness for Global robust training,"Jingyue Lu, M. Pawan Kumar",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14030"" target=""_blank"">2110.14030</a>",,2025-12-03 22:39:25
How and When Adversarial Robustness Transfers in Knowledge Distillation? (91%),"Rulin Shao, Jinfeng Yi, Pin-Yu Chen, Cho-Jui Hsieh",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.12072"" target=""_blank"">2110.12072</a>",,2025-12-03 22:39:25
Towards Robust Reasoning over Knowledge Graphs,"Zhaohan Xi, Ren Pang, Changjiang Li, Shouling Ji, Xiapu Luo, Xusheng Xiao, Ting Wang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14693"" target=""_blank"">2110.14693</a>",,2025-12-03 22:39:25
Attacking Video Recognition Models with Bullet-Screen Comments,"Kai Chen, Zhipeng Wei, Jingjing Chen, Zuxuan Wu, Yu-Gang Jiang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.15629"" target=""_blank"">2110.15629</a>","<a href=""https://github.com/kay-ck/BSC-attack"" target=""_blank"">kay-ck</a>",2025-12-03 22:39:25
Adversarial Attacks on ML Defense Models Competition,"Yinpeng Dong, Qi-An Fu, Xiao Yang, Wenzhao Xiang, Tianyu Pang, Hang Su, Jun Zhu, Jiayu Tang, Yuefeng Chen, XiaoFeng Mao, Yuan He, Hui Xue, Chao Li, Ye Liu, Qilong Zhang, Lianli Gao, Yunrui Yu, Xitong Gao, Zhe Zhao, Daquan Lin, Jiadong Lin, Chuanbiao Song, Zihao Wang, Zhennan Wu, Yang Guo, Jiequan Cui, Xiaogang Xu, Pengguang Chen",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08042"" target=""_blank"">2110.08042</a>","<a href=""https://aisecure-workshop.github.io/amlcvpr2021/"" target=""_blank"">amlcvpr2021</a>",2025-12-03 22:39:25
Adversarial Robustness with Semi-Infinite Constrained Learning,"Alexander Robey, Luiz F. O. Chamon, George J. Pappas, Hamed Hassani, Alejandro Ribeiro",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.15767"" target=""_blank"">2110.15767</a>","<a href=""https://github.com/arobey1/advbench"" target=""_blank"">arobey1</a>",2025-12-03 22:39:25
{\epsilon}-weakened Robustness of Deep Neural Networks,"Pei Huang, Yuting Yang, Minghao Liu, Fuqi Jia, Feifei Ma, Jian Zhang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.15764"" target=""_blank"">2110.15764</a>",,2025-12-03 22:39:25
Bridge the Gap Between CV and NLP! A Gradient-based Textual Adversarial Attack Framework,"Lifan Yuan, Yichi Zhang, Yangyi Chen, Wei Wei",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.15317"" target=""_blank"">2110.15317</a>","<a href=""https://github.com/Phantivia/T-PGD"" target=""_blank"">Phantivia</a>",2025-12-03 22:39:25
AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value Analysis,"Junfeng Guo, Ang Li, Cong Liu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14880"" target=""_blank"">2110.14880</a>",,2025-12-03 22:39:25
The magnitude vector of images,"Michael F. Adamer, Leslie O'Bray, Brouwer Edward De, Bastian Rieck, Karsten Borgwardt",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.15188"" target=""_blank"">2110.15188</a>",,2025-12-03 22:39:25
Towards Evaluating the Robustness of Neural Networks Learned by Transduction,"Jiefeng Chen, Xi Wu, Yang Guo, Yingyu Liang, Somesh Jha",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14735"" target=""_blank"">2110.14735</a>",,2025-12-03 22:39:25
CAP: Co-Adversarial Perturbation on Weights and Features for Improving Generalization of Graph Neural Networks,"Haotian Xue, Kaixiong Zhou, Tianlong Chen, Kai Guo, Xia Hu, Yi Chang, Xin Wang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14855"" target=""_blank"">2110.14855</a>",,2025-12-03 22:39:25
Binarized ResNet: Enabling Robust Automatic Modulation Classification at the resource-constrained Edge,"Deepsayan Sadhukhan, Nitin Priyadarshini Shankar, Nancy Nayak, Thulasi Tholeti, Sheetal Kalyani",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14357"" target=""_blank"">2110.14357</a>",,2025-12-03 22:39:25
Disrupting Deep Uncertainty Estimation Without Harming Accuracy,"Ido Galil, Ran El-Yaniv",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.13741"" target=""_blank"">2110.13741</a>",,2025-12-03 22:39:25
Generalized Depthwise-Separable Convolutions for Adversarially Robust and Efficient Neural Networks,"Hassan Dbouk, Naresh R. Shanbhag",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14871"" target=""_blank"">2110.14871</a>","<a href=""https://github.com/hsndbk4/GDWS"" target=""_blank"">hsndbk4</a>",2025-12-03 22:39:25
Adversarial Neuron Pruning Purifies Backdoored Deep Models,"Dongxian Wu, Yisen Wang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14430"" target=""_blank"">2110.14430</a>",,2025-12-03 22:39:25
From Intrinsic to Counterfactual: On the Explainability of Contextualized Recommender Systems,"Yao Zhou, Haonan Wang, Jingrui He, Haixun Wang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14844"" target=""_blank"">2110.14844</a>",,2025-12-03 22:39:25
Robust Contrastive Learning Using Negative Samples with Diminished Semantics,"Songwei Ge, Shlok Mishra, Haohan Wang, Chun-Liang Li, David Jacobs",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14189"" target=""_blank"">2110.14189</a>","<a href=""https://github.com/SongweiGe/Contrastive-Learning-with-Non-Semantic-Negatives"" target=""_blank"">SongweiGe</a>",2025-12-03 22:39:25
RoMA: Robust Model Adaptation for Offline Model-based Optimization,"Sihyun Yu, Sungsoo Ahn, Le Song, Jinwoo Shin",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14188"" target=""_blank"">2110.14188</a>",,2025-12-03 22:39:25
Frequency Centric Defense Mechanisms against Adversarial Examples,"Sanket B. Shah, Param Raval, Harin Khakhi, Mehul S. Raval",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.13935"" target=""_blank"">2110.13935</a>",,2025-12-03 22:39:25
ScaleCert: Scalable Certified Defense against Adversarial Patches with Sparse Superficial Layers,"Husheng Han, Kaidi Xu, Xing Hu, Xiaobing Chen, Ling Liang, Zidong Du, Qi Guo, Yanzhi Wang, Yunji Chen",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14120"" target=""_blank"">2110.14120</a>",,2025-12-03 22:39:25
Drawing Robust Scratch Tickets: Subnetworks with Inborn Robustness Are Found within Randomly Initialized Networks,"Yonggan Fu, Qixuan Yu, Yang Zhang, Shang Wu, Xu Ouyang, David Cox, Yingyan Lin",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.14068"" target=""_blank"">2110.14068</a>",,2025-12-03 22:39:25
FL-WBC: Enhancing Robustness against Model Poisoning Attacks in Federated Learning from a Client Perspective,"Jingwei Sun, Ang Li, Louis DiValentin, Amin Hassanzadeh, Yiran Chen, Hai Li",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.13864"" target=""_blank"">2110.13864</a>",,2025-12-03 22:39:25
Improving Robustness of Malware Classifiers using Adversarial Strings Generated from Perturbed Latent Representations,"Marek Galovic, Branislav Bosansky, Viliam Lisy",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11987"" target=""_blank"">2110.11987</a>",,2025-12-03 22:39:25
Can't Fool Me: Adversarially Robust Transformer for Video Understanding,"Divya Choudhary, Palash Goyal, Saurabh Sahu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.13950"" target=""_blank"">2110.13950</a>",,2025-12-03 22:39:25
Fairness Degrading Adversarial Attacks Against Clustering Algorithms,"Anshuman Chhabra, Adish Singla, Prasant Mohapatra",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.12020"" target=""_blank"">2110.12020</a>",,2025-12-03 22:39:25
Unrestricted Adversarial Attacks on ImageNet Competition,"Yuefeng Chen, Xiaofeng Mao, Yuan He, Hui Xue, Chao Li, Yinpeng Dong, Qi-An Fu, Xiao Yang, Wenzhao Xiang, Tianyu Pang, Hang Su, Jun Zhu, Fangcheng Liu, Chao Zhang, Hongyang Zhang, Yichi Zhang, Shilong Liu, Chang Liu, Wenzhao Xiang, Yajie Wang, Huipeng Zhou, Haoran Lyu, Yidan Xu, Zixuan Xu, Taoyu Zhu, Wenjun Li, Xianfeng Gao, Guoqiu Wang, Huanqian Yan, Ying Guo, Chaoning Zhang, Zheng Fang, Yang Wang, Bingyang Fu, Yunfei Zheng, Yekui Wang, Haorong Luo, Zhen Yang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.09903"" target=""_blank"">2110.09903</a>",,2025-12-03 22:39:25
Understanding Convolutional Neural Networks from Theoretical Perspective via Volterra Convolution,"Tenghui Li, Guoxu Zhou, Yuning Qiu, Qibin Zhao",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.09902"" target=""_blank"">2110.09902</a>",,2025-12-03 22:39:25
Detecting Backdoor Attacks Against Point Cloud Classifiers,"Zhen Xiang, David J. Miller, Siheng Chen, Xi Li, George Kesidis",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.10354"" target=""_blank"">2110.10354</a>",,2025-12-03 22:39:25
Speech Pattern based Black-box Model Watermarking for Automatic Speech Recognition,"Haozhe Chen, Weiming Zhang, Kunlin Liu, Kejiang Chen, Han Fang, Nenghai Yu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.09814"" target=""_blank"">2110.09814</a>",,2025-12-03 22:39:25
A Deeper Look into RowHammer`s Sensitivities: Experimental Analysis of Real DRAM Chips and Implications on Future Attacks and Defenses,"Lois Orosa, Abdullah Giray Yağlıkçı, Haocong Luo, Ataberk Olgun, Jisung Park, Hasan Hassan, Minesh Patel, Jeremie S. Kim, Onur Mutlu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.10291"" target=""_blank"">2110.10291</a>",,2025-12-03 22:39:25
Boosting the Transferability of Video Adversarial Examples via Temporal Translation,"Zhipeng Wei, Jingjing Chen, Zuxuan Wu, Yu-Gang Jiang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.09075"" target=""_blank"">2110.09075</a>",,2025-12-03 22:39:25
Black-box Adversarial Attacks on Commercial Speech Platforms with Minimal Information,"Baolin Zheng, Peipei Jiang, Qian Wang, Qi Li, Chao Shen, Cong Wang, Yunjie Ge, Qingyang Teng, Shenyi Zhang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.09714"" target=""_blank"">2110.09714</a>",,2025-12-03 22:39:25
Improving Robustness using Generated Data,"Sven Gowal, Sylvestre-Alvise Rebuffi, Olivia Wiles, Florian Stimberg, Dan Andrei Calian, Timothy Mann",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.09468"" target=""_blank"">2110.09468</a>",,2025-12-03 22:39:25
MEMO: Test Time Robustness via Adaptation and Augmentation,"Marvin Zhang, Sergey Levine, Chelsea Finn",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.09506"" target=""_blank"">2110.09506</a>",,2025-12-03 22:39:25
Minimal Multi-Layer Modifications of Deep Neural Networks,"Idan Refaeli, Guy Katz",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.09929"" target=""_blank"">2110.09929</a>",,2025-12-03 22:39:25
Improving Robustness of Reinforcement Learning for Power System Control with Adversarial Training,"Alexander Daniel Pan, Daniel Yongkyun, Lee, Huan Zhang, Yize Chen, Yuanyuan Shi",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08956"" target=""_blank"">2110.08956</a>",,2025-12-03 22:39:25
A Regularization Method to Improve Adversarial Robustness of Neural Networks for ECG Signal Classification,"Linhai Ma, Liang Liang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.09759"" target=""_blank"">2110.09759</a>",,2025-12-03 22:39:25
Adapting Membership Inference Attacks to GNN for Graph Classification: Approaches and Implications,"Bang Wu, Xiangwen Yang, Shirui Pan, Xingliang Yuan",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08760"" target=""_blank"">2110.08760</a>",,2025-12-03 22:39:25
Poisoning Attacks on Fair Machine Learning,"Minh-Hao Van, Wei Du, Xintao Wu, Aidong Lu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08932"" target=""_blank"">2110.08932</a>",,2025-12-03 22:39:25
Black-box Adversarial Attacks on Network-wide Multi-step Traffic State Prediction Models,"Bibek Poudel, Weizi Li",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08712"" target=""_blank"">2110.08712</a>",,2025-12-03 22:39:25
Analyzing Dynamic Adversarial Training Data in the Limit,"Eric Wallace, Adina Williams, Robin Jia, Douwe Kiela",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08514"" target=""_blank"">2110.08514</a>",,2025-12-03 22:39:25
Characterizing Improper Input Validation Vulnerabilities of Mobile Crowdsourcing Services,"Sojhal Ismail Khan, Dominika Woszczyk, Chengzeng You, Soteris Demetriou, Muhammad Naveed",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08517"" target=""_blank"">2110.08517</a>",,2025-12-03 22:39:25
Tackling the Imbalance for GNNs,"Rui Wang, Weixuan Xiong, Qinghu Hou, Ou Wu",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08690"" target=""_blank"">2110.08690</a>",,2025-12-03 22:39:25
Adversarial Attacks on Gaussian Process Bandits,"Eric Han, Jonathan Scarlett",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08449"" target=""_blank"">2110.08449</a>",,2025-12-03 22:39:25
Generating Natural Language Adversarial Examples through An Improved Beam Search Algorithm,"Tengfei Zhao, Zhaocheng Ge, Hanping Hu, Dingmeng Shi",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.08036"" target=""_blank"">2110.08036</a>",,2025-12-03 22:39:25
Adversarial robustness for latent models: Revisiting the robust-standard accuracies tradeoff,"Adel Javanmard, Mohammad Mehrabi",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11950"" target=""_blank"">2110.11950</a>",,2025-12-03 22:39:25
TESSERACT: Gradient Flip Score to Secure Federated Learning Against Model Poisoning Attacks,"Atul Sharma, Wei Chen, Joshua Zhao, Qiang Qiu, Somali Chaterji, Saurabh Bagchi",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.10108"" target=""_blank"">2110.10108</a>",,2025-12-03 22:39:25
ECG-ATK-GAN: Robustness against Adversarial Attacks on ECGs using Conditional Generative Adversarial Networks,"Khondker Fariha Hossain, Sharif Amit Kamran, Alireza Tavakkoli, Xingjun Ma",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.09983"" target=""_blank"">2110.09983</a>",,2025-12-03 22:39:25
Multi-concept adversarial attacks,"Vibha Belavadi, Yan Zhou, Murat Kantarcioglu, Bhavani M. Thuraisingham",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.10287"" target=""_blank"">2110.10287</a>",,2025-12-03 22:39:25
Anti-Backdoor Learning: Training Clean Models on Poisoned Data,"Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li, Xingjun Ma",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11571"" target=""_blank"">2110.11571</a>","<a href=""https://github.com/bboylyg/ABL"" target=""_blank"">bboylyg</a>",2025-12-03 22:39:25
PRECAD: Privacy-Preserving and Robust Federated Learning via Crypto-Aided Differential Privacy,"Xiaolan Gu, Ming Li, Li Xiong",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11578"" target=""_blank"">2110.11578</a>",,2025-12-03 22:39:25
No One Representation to Rule Them All: Overlapping Features of Training Methods,"Raphael Gontijo-Lopes, Yann Dauphin, Ekin D. Cubuk",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.12899"" target=""_blank"">2110.12899</a>",,2025-12-03 22:39:25
ProtoShotXAI: Using Prototypical Few-Shot Architecture for Explainable AI,"Samuel Hess, Gregory Ditzler",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11597"" target=""_blank"">2110.11597</a>",,2025-12-03 22:39:25
Spoofing Detection on Hand Images Using Quality Assessment,"Asish Bera, Ratnadeep Dey, Debotosh Bhattacharjee, Mita Nasipuri, Hubert P. H. Shum",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.12923"" target=""_blank"">2110.12923</a>",,2025-12-03 22:39:25
Text Counterfactuals via Latent Optimization and Shapley-Guided Search,"Quintin Pope, Xiaoli Z. Fern",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11589"" target=""_blank"">2110.11589</a>",,2025-12-03 22:39:25
On the Necessity of Auditable Algorithmic Definitions for Machine Unlearning,"Anvith Thudi, Hengrui Jia, Ilia Shumailov, Nicolas Papernot",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11891"" target=""_blank"">2110.11891</a>",,2025-12-03 22:39:25
CAPTIVE: Constrained Adversarial Perturbations to Thwart IC Reverse Engineering,"Amir Hosein Afandizadeh Zargari, Marzieh AshrafiAmiri, Minjun Seo, Sai Manoj Pudukotai Dinakarrao, Mohammed E. Fouda, Fadi Kurdahi",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11459"" target=""_blank"">2110.11459</a>",,2025-12-03 22:39:25
PROVES: Establishing Image Provenance using Semantic Signatures,"Mingyang Xie, Manav Kulshrestha, Shaojie Wang, Jinghan Yang, Ayan Chakrabarti, Ning Zhang, Yevgeniy Vorobeychik",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11411"" target=""_blank"">2110.11411</a>",,2025-12-03 22:39:25
RoMA: a Method for Neural Network Robustness Measurement and Assessment,"Natan Levy, Guy Katz",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11088"" target=""_blank"">2110.11088</a>",,2025-12-03 22:39:25
MANDERA: Malicious Node Detection in Federated Learning via Ranking,"Wanchuang Zhu, Benjamin Zi Hao Zhao, Simon Luo, Tongliang Liu, Ke Deng",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11736"" target=""_blank"">2110.11736</a>",,2025-12-03 22:39:25
PipAttack: Poisoning Federated Recommender Systems forManipulating Item Promotion,"Shijie Zhang, Hongzhi Yin, Tong Chen, Zi Huang, Quoc Viet Hung Nguyen, Lizhen Cui",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.10926"" target=""_blank"">2110.10926</a>",,2025-12-03 22:39:25
Robustness through Data Augmentation Loss Consistency,"Tianjian Huang, Shaunak Halbe, Chinnadhurai Sankar, Pooyan Amini, Satwik Kottur, Alborz Geramifard, Meisam Razaviyayn, Ahmad Beirami",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11205"" target=""_blank"">2110.11205</a>","<a href=""https://github.com/optimization-for-data-driven-science/DAIR"" target=""_blank"">optimization-for-data-driven-science</a>",2025-12-03 22:39:25
Generalization of Neural Combinatorial Solvers Through the Lens of Adversarial Robustness,"Simon Geisler, Johanna Sommer, Jan Schuchardt, Aleksandar Bojchevski, Stephan Günnemann",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.10942"" target=""_blank"">2110.10942</a>",,2025-12-03 22:39:25
Watermarking Graph Neural Networks based on Backdoor Attacks,"Jing Xu, Stjepan Picek",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11024"" target=""_blank"">2110.11024</a>",,2025-12-03 22:39:25
Physical Side-Channel Attacks on Embedded Neural Networks: A Survey,"Maria Méndez Real, Rubén Salvador",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.11290"" target=""_blank"">2110.11290</a>",,2025-12-03 22:39:25
Adversarial Socialbot Learning via Multi-Agent Deep Hierarchical Reinforcement Learning,"Thai Le, Long Tran-Thanh, Dongwon Lee",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.10655"" target=""_blank"">2110.10655</a>",,2025-12-03 22:39:25
Surrogate Representation Learning with Isometric Mapping for Gray-box Graph Adversarial Attacks,"Zihan Liul, Yun Luo, Zelin Zang, Stan Z. Li",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.10482"" target=""_blank"">2110.10482</a>",,2025-12-03 22:39:25
Adversarial attacks against Bayesian forecasting dynamic models,Roi Naveiro,arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.10783"" target=""_blank"">2110.10783</a>",,2025-12-03 22:39:25
Moir\'e Attack (MA): A New Potential Risk of Screen Photos,"Dantong Niu, Ruohao Guo, Yisen Wang",arXiv,2021-10,"<a href=""http://arxiv.org/abs/2110.10444"" target=""_blank"">2110.10444</a>","<a href=""https://github.com/Dantong88/Moire_Attack"" target=""_blank"">Dantong88</a>",2025-12-03 22:39:25
2-in-1 Accelerator: Enabling Random Precision Switch for Winning Both Adversarial Robustness and Efficiency,"Yonggan Fu, Yang Zhao, Qixuan Yu, Chaojian Li, Yingyan Lin",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05223"" target=""_blank"">2109.05223</a>",,2025-12-03 22:39:25
Check Your Other Door! Creating Backdoor Attacks in the Frequency Domain,"Hasan Abed Al Kader Hammoud, Bernard Ghanem",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05507"" target=""_blank"">2109.05507</a>",,2025-12-03 22:39:25
RockNER: A Simple Method to Create Adversarial Examples for Evaluating the Robustness of Named Entity Recognition Models,"Bill Yuchen Lin, Wenyang Gao, Jun Yan, Ryan Moreno, Xiang Ren",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05620"" target=""_blank"">2109.05620</a>",,2025-12-03 22:39:25
Shape-Biased Domain Generalization via Shock Graph Embeddings,"Maruthi Narayanan, Vickram Rajendran, Benjamin Kimia",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05671"" target=""_blank"">2109.05671</a>",,2025-12-03 22:39:25
Source Inference Attacks in Federated Learning,"Hongsheng Hu, Zoran Salcic, Lichao Sun, Gillian Dobbie, Xuyun Zhang",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05659"" target=""_blank"">2109.05659</a>",,2025-12-03 22:39:25
RobustART: Benchmarking Robustness on Architecture Design and Training Techniques,"Shiyu Tang, Ruihao Gong, Yan Wang, Aishan Liu, Jiakai Wang, Xinyun Chen, Fengwei Yu, Xianglong Liu, Dawn Song, Alan Yuille, Philip H. S. Torr, Dacheng Tao",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05211"" target=""_blank"">2109.05211</a>",,2025-12-03 22:39:25
Energy Attack: On Transferring Adversarial Examples,"Ruoxi Shi, Borui Yang, Yangzhou Jiang, Chenglong Zhao, Bingbing Ni",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.04300"" target=""_blank"">2109.04300</a>",,2025-12-03 22:39:25
A Strong Baseline for Query Efficient Attacks in a Black Box Setting,"Rishabh Maheshwary, Saket Maheshwary, Vikram Pudi",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.04775"" target=""_blank"">2109.04775</a>",,2025-12-03 22:39:25
Contrasting Human- and Machine-Generated Word-Level Adversarial Examples for Text Classification,"Maximilian Mozes, Max Bartolo, Pontus Stenetorp, Bennett Kleinberg, Lewis D. Griffin",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.04385"" target=""_blank"">2109.04385</a>",,2025-12-03 22:39:25
Towards Transferable Adversarial Attacks on Vision Transformers,"Zhipeng Wei, Jingjing Chen, Micah Goldblum, Zuxuan Wu, Tom Goldstein, Yu-Gang Jiang",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.04176"" target=""_blank"">2109.04176</a>",,2025-12-03 22:39:25
Protein Folding Neural Networks Are Not Robust,"Sumit Kumar Jha, Arvind Ramanathan, Rickard Ewetz, Alvaro Velasquez, Susmit Jha",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.04460"" target=""_blank"">2109.04460</a>",,2025-12-03 22:39:25
Multi-granularity Textual Adversarial Attack with Behavior Cloning,"Yangyi Chen, Jin Su, Wei Wei",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.04367"" target=""_blank"">2109.04367</a>","<a href=""https://github.com/Yangyi-Chen/MAYA"" target=""_blank"">Yangyi-Chen</a>",2025-12-03 22:39:25
TREATED:Towards Universal Defense against Textual Adversarial Attacks,"Bin Zhu, Zhaoquan Gu, Le Wang, Zhihong Tian",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.06176"" target=""_blank"">2109.06176</a>",,2025-12-03 22:39:25
CoG: a Two-View Co-training Framework for Defending Adversarial Attacks on Graph,"Xugang Wu, Huijun Wu, Xu Zhou, Kai Lu",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05558"" target=""_blank"">2109.05558</a>",,2025-12-03 22:39:25
Adversarial Examples for Evaluating Math Word Problem Solvers,"Vivek Kumar, Rishabh Maheshwary, Vikram Pudi",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05925"" target=""_blank"">2109.05925</a>",,2025-12-03 22:39:25
Detecting Safety Problems of Multi-Sensor Fusion in Autonomous Driving,"Ziyuan Zhong, Zhisheng Hu, Shengjian Guo, Xinyang Zhang, Zhenyu Zhong, Baishakhi Ray",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.06404"" target=""_blank"">2109.06404</a>",,2025-12-03 22:39:25
How to Select One Among All? An Extensive Empirical Study Towards the Robustness of Knowledge Distillation in Natural Language Understanding,"Tianda Li, Ahmad Rashid, Aref Jafari, Pranav Sharma, Ali Ghodsi, Mehdi Rezagholizadeh",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05696"" target=""_blank"">2109.05696</a>",,2025-12-03 22:39:25
Perturbation CheckLists for Evaluating NLG Evaluation Metrics,"Ananya B. Sai, Tanay Dixit, Dev Yashpal Sheth, Sreyas Mohan, Mitesh M. Khapra",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05771"" target=""_blank"">2109.05771</a>",,2025-12-03 22:39:25
Adversarially Trained Object Detector for Unsupervised Domain Adaptation,"Kazuma Fujii, Hiroshi Kera, Kazuhiko Kawamoto",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05751"" target=""_blank"">2109.05751</a>",,2025-12-03 22:39:25
Sensor Adversarial Traits: Analyzing Robustness of 3D Object Detection Sensor Fusion Models,"Won Park, Nan Li, Qi Alfred Chen, Z. Morley Mao",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.06363"" target=""_blank"">2109.06363</a>",,2025-12-03 22:39:25
Virtual Data Augmentation: A Robust and General Framework for Fine-tuning Pre-trained Models,"Kun Zhou, Wayne Xin Zhao, Sirui Wang, Fuzheng Zhang, Wei Wu, Ji-Rong Wen",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05793"" target=""_blank"">2109.05793</a>","<a href=""https://github.com/RUCAIBox/VDA"" target=""_blank"">RUCAIBox</a>",2025-12-03 22:39:25
Formalizing and Estimating Distribution Inference Risks,"Anshuman Suri, David Evans",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.06024"" target=""_blank"">2109.06024</a>",,2025-12-03 22:39:25
Byzantine-robust Federated Learning through Collaborative Malicious Gradient Filtering,"Jian Xu, Shao-Lun Huang, Linqi Song, Tian Lan",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05872"" target=""_blank"">2109.05872</a>","<a href=""https://github.com/JianXu95/SignGuard"" target=""_blank"">JianXu95</a>",2025-12-03 22:39:25
PAT: Pseudo-Adversarial Training For Detecting Adversarial Videos,"Nupur Thakur, Baoxin Li",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05695"" target=""_blank"">2109.05695</a>",,2025-12-03 22:39:25
A Practical Adversarial Attack on Contingency Detection of Smart Energy Systems,"Moein Sabounchi, Jin Wei-Kocsis",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.06358"" target=""_blank"">2109.06358</a>",,2025-12-03 22:39:25
Evolving Architectures with Gradient Misalignment toward Low Adversarial Transferability,"Kevin Richard G. Operiano, Wanchalerm Pora, Hitoshi Iba, Hiroshi Kera",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05919"" target=""_blank"">2109.05919</a>",,2025-12-03 22:39:25
Improving the Robustness of Adversarial Attacks Using an Affine-Invariant Gradient Estimator,"Wenzhao Xiang, Hang Su, Chang Liu, Yandong Guo, Shibao Zheng",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05820"" target=""_blank"">2109.05820</a>",,2025-12-03 22:39:25
Differential Privacy in Personalized Pricing with Nonparametric Demand Models,"Xi Chen, Sentao Miao, Yining Wang",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.04615"" target=""_blank"">2109.04615</a>",,2025-12-03 22:39:25
Randomized Substitution and Vote for Textual Adversarial Example Detection,"Xiaosen Wang, Yifeng Xiong, Kun He",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05698"" target=""_blank"">2109.05698</a>",,2025-12-03 22:39:25
Spatially Focused Attack against Spatiotemporal Graph Neural Networks,"Fuqiang Liu, Luis Miranda-Moreno, Lijun Sun",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.04608"" target=""_blank"">2109.04608</a>",,2025-12-03 22:39:25
Towards Improving Adversarial Training of NLP Models,"Jin Yong Yoo, Yanjun Qi",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.00544"" target=""_blank"">2109.00544</a>","<a href=""http://github.com/jinyongyoo/A2T"" target=""_blank"">jinyongyoo</a>",2025-12-03 22:39:25
EvilModel 2,"Zhi Wang, Chaoge Liu, Xiang Cui, Jie Yin, Xutong Wang",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.04344"" target=""_blank"">2109.04344</a>",,2025-12-03 22:39:25
SEC4SR: A Security Analysis Platform for Speaker Recognition,"Guangke Chen, Zhe Zhao, Fu Song, Sen Chen, Lingling Fan, Yang Liu",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.01766"" target=""_blank"">2109.01766</a>",,2025-12-03 22:39:25
ARCH: Efficient Adversarial Regularized Training with Caching,"Simiao Zuo, Chen Liang, Haoming Jiang, Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen, Tuo Zhao",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.07048"" target=""_blank"">2109.07048</a>",,2025-12-03 22:39:25
Black-Box Attacks on Sequential Recommenders via Data-Free Model Extraction,"Zhenrui Yue, Zhankui He, Huimin Zeng, Julian McAuley",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.01165"" target=""_blank"">2109.01165</a>",,2025-12-03 22:39:25
DPA: Learning Robust Physical Adversarial Camouflages for Object Detectors,"Yexin Duan, Jialin Chen, Xingyu Zhou, Junhua Zou, Zhengyun He, Wu Zhang, Jin Zhang, Zhisong Pan",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.00124"" target=""_blank"">2109.00124</a>",,2025-12-03 22:39:25
Guarding Machine Learning Hardware Against Physical Side-Channel Attacks,"Anuj Dubey, Rosario Cammarota, Vikram Suresh, Aydin Aysu",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.00187"" target=""_blank"">2109.00187</a>",,2025-12-03 22:39:25
Proof Transfer for Neural Network Verification,"Christian Sprecher, Marc Fischer, Dimitar I. Dimitrov, Gagandeep Singh, Martin Vechev",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.00542"" target=""_blank"">2109.00542</a>",,2025-12-03 22:39:25
R-SNN: An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversarial Attacks through Noise Filters for Dynamic Vision Sensors,"Alberto Marchisio, Giacomo Pira, Maurizio Martina, Guido Masera, Muhammad Shafique",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.00533"" target=""_blank"">2109.00533</a>",,2025-12-03 22:39:25
Regional Adversarial Training for Better Robust Generalization,"Chuanbiao Song, Yanbo Fan, Yicheng Yang, Baoyuan Wu, Yiming Li, Zhifeng Li, Kun He",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.00678"" target=""_blank"">2109.00678</a>",,2025-12-03 22:39:25
Excess Capacity and Backdoor Poisoning,"Naren Sarayu Manoj, Avrim Blum",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.00685"" target=""_blank"">2109.00685</a>",,2025-12-03 22:39:25
Building Compact and Robust Deep Neural Networks with Toeplitz Matrices,Alexandre Araujo,arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.00959"" target=""_blank"">2109.00959</a>",,2025-12-03 22:39:25
Real World Robustness from Systematic Noise,"Yan Wang, Yuhang Li, Ruihao Gong",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.00864"" target=""_blank"">2109.00864</a>",,2025-12-03 22:39:25
Impact of Attention on Adversarial Robustness of Image Classification Models,"Prachi Agrawal, Narinder Singh Punn, Sanjay Kumar Sonbhadra, Sonali Agarwal",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.00936"" target=""_blank"">2109.00936</a>",,2025-12-03 22:39:25
A Synergetic Attack against Neural Network Classifiers combining Backdoor and Adversarial Examples,"Guanxiong Liu, Issa Khalil, Abdallah Khreishah, NhatHai Phan",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.01275"" target=""_blank"">2109.01275</a>",,2025-12-03 22:39:25
Risk Assessment for Connected Vehicles under Stealthy Attacks on Vehicle-to-Vehicle Networks,"Tianci Yang, Carlos Murguia, Chen Lv",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.01553"" target=""_blank"">2109.01553</a>",,2025-12-03 22:39:25
Training Meta-Surrogate Model for Transferable Adversarial Attack,"Yunxiao Qin, Yuanhao Xiong, Jinfeng Yi, Cho-Jui Hsieh",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.01983"" target=""_blank"">2109.01983</a>",,2025-12-03 22:39:25
Membership Inference Attacks Against Temporally Correlated Data in Deep Reinforcement Learning,"Maziar Gomrokchi, Susan Amin, Hossein Aboutalebi, Alexander Wong, Doina Precup",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.03975"" target=""_blank"">2109.03975</a>",,2025-12-03 22:39:25
Utilizing Adversarial Targeted Attacks to Boost Adversarial Robustness,"Uriya Pesso, Koby Bibas, Meir Feder",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.01945"" target=""_blank"">2109.01945</a>",,2025-12-03 22:39:25
Real-World Adversarial Examples involving Makeup Application,"Chang-Sheng Lin, Chia-Yi Hsu, Pin-Yu Chen, Chia-Mu Yu",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.03329"" target=""_blank"">2109.03329</a>",,2025-12-03 22:39:25
"DexRay: A Simple, yet Effective Deep Learning Approach to Android Malware Detection based on Image Representation of Bytecode","Nadia Daoudi, Jordan Samhi, Abdoul Kader Kabore, Kevin Allix, Tegawendé F. Bissyandé, Jacques Klein",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.03326"" target=""_blank"">2109.03326</a>",,2025-12-03 22:39:25
Tolerating Adversarial Attacks and Byzantine Faults in Distributed Machine Learning,"Yusen Wu, Hao Chen, Xin Wang, Chao Liu, Phuong Nguyen, Yelena Yesha",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.02018"" target=""_blank"">2109.02018</a>",,2025-12-03 22:39:25
Efficient Combinatorial Optimization for Word-level Adversarial Textual Attack,"Shengcai Liu, Ning Lu, Cheng Chen, Ke Tang",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.02229"" target=""_blank"">2109.02229</a>",,2025-12-03 22:39:25
Exposing Length Divergence Bias of Textual Matching Models,"Lan Jiang, Tianshu Lyu, Chong Meng, Xiaoyong Lyu, Dawei Yin",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.02431"" target=""_blank"">2109.02431</a>",,2025-12-03 22:39:25
Automated Robustness with Adversarial Training as a Post-Processing Step,"Ambrish Rawat, Mathieu Sinn, Beat Buesser",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.02532"" target=""_blank"">2109.02532</a>",,2025-12-03 22:39:25
Trojan Signatures in DNN Weights,"Greg Fields, Mohammad Samragh, Mojan Javaheripi, Farinaz Koushanfar, Tara Javidi",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.02836"" target=""_blank"">2109.02836</a>",,2025-12-03 22:39:25
Robustness and Generalization via Generative Adversarial Training,"Omid Poursaeed, Tianxing Jiang, Harry Yang, Serge Belongie, SerNam Lim",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.02765"" target=""_blank"">2109.02765</a>",,2025-12-03 22:39:25
Unpaired Adversarial Learning for Single Image Deraining with Rain-Space Contrastive Constraints,"Xiang Chen, Jinshan Pan, Kui Jiang, Yufeng Huang, Caihua Kong, Longgang Dai, Yufeng Li",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.02973"" target=""_blank"">2109.02973</a>",,2025-12-03 22:39:25
POW-HOW: An enduring timing side-channel to evade online malware sandboxes,"Antonio Nappa, Panagiotis Papadopoulos, Matteo Varvello, Daniel Aceituno Gomez, Juan Tapiador, Andrea Lanzi",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.02979"" target=""_blank"">2109.02979</a>",,2025-12-03 22:39:25
Adversarial Parameter Defense by Multi-Step Risk Minimization,"Zhiyuan Zhang, Ruixuan Luo, Xuancheng Ren, Qi Su, Liangyou Li, Xu Sun",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.02889"" target=""_blank"">2109.02889</a>",,2025-12-03 22:39:25
Robust Optimal Classification Trees Against Adversarial Examples,"Daniël Vos, Sicco Verwer",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.03857"" target=""_blank"">2109.03857</a>",,2025-12-03 22:39:25
Adversarial Bone Length Attack on Action Recognition,"Nariki Tanaka, Hiroshi Kera, Kazuhiko Kawamoto",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.05830"" target=""_blank"">2109.05830</a>",,2025-12-03 22:39:25
Adversarial Robustness for Unsupervised Domain Adaptation,"Muhammad Awais, Fengwei Zhou, Hang Xu, Lanqing Hong, Ping Luo, Sung-Ho Bae, Zhenguo Li",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.00946"" target=""_blank"">2109.00946</a>",,2025-12-03 22:39:25
Avengers Ensemble! Improving Transferability of Authorship Obfuscation,"Muhammad Haroon, Muhammad Fareed Zaffar, Padmini Srinivasan, Zubair Shafiq",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.07028"" target=""_blank"">2109.07028</a>",,2025-12-03 22:39:25
Backdoor Attacks on Federated Learning with Lottery Ticket Hypothesis,"Zeyuan Yin, Ye Yuan, Panfeng Guo, Pan Zhou",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.10512"" target=""_blank"">2109.10512</a>",,2025-12-03 22:39:25
Adversarial Transfer Attacks With Unknown Data and Class Overlap,"Luke E. Richards, André Nguyen, Ryan Capps, Steven Forsythe, Cynthia Matuszek, Edward Raff",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.11125"" target=""_blank"">2109.11125</a>",,2025-12-03 22:39:25
Security Analysis of Capsule Network Inference using Horizontal Collaboration,"Adewale Adeyemo, Faiq Khalid, Tolulope A. Odetola, Syed Rafay Hasan",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.11041"" target=""_blank"">2109.11041</a>",,2025-12-03 22:39:25
CC-Cert: A Probabilistic Approach to Certify General Robustness of Neural Networks,"Mikhail Pautov, Nurislam Tursynbek, Marina Munkhoeva, Nikita Muravev, Aleksandr Petiushko, Ivan Oseledets",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.10696"" target=""_blank"">2109.10696</a>",,2025-12-03 22:39:25
Exploring Adversarial Examples for Efficient Active Learning in Machine Learning Classifiers,"Honggang Yu, Shihfeng Zeng, Teng Zhang, Ing-Chao Lin, Yier Jin",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.10770"" target=""_blank"">2109.10770</a>",,2025-12-03 22:39:25
DeepAID: Interpreting and Improving Deep Learning-based Anomaly Detection in Security Applications,"Dongqi Han, Zhiliang Wang, Wenqi Chen, Ying Zhong, Su Wang, Han Zhang, Jiahai Yang, Xingang Shi, Xia Yin",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.11495"" target=""_blank"">2109.11495</a>",,2025-12-03 22:39:25
AES Systems Are Both Overstable And Oversensitive: Explaining Why And Proposing Defenses,"Yaman Kumar Singla, Swapnil Parekh, Somesh Singh, Junyi Jessy Li, Rajiv Ratn Shah, Changyou Chen",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.11728"" target=""_blank"">2109.11728</a>",,2025-12-03 22:39:25
FooBaR: Fault Fooling Backdoor Attack on Neural Network Training,"Jakub Breier, Xiaolu Hou, Martín Ochoa, Jesus Solano",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.11249"" target=""_blank"">2109.11249</a>",,2025-12-03 22:39:25
Breaking BERT: Understanding its Vulnerabilities for Biomedical Named Entity Recognition through Adversarial Attack,"Anne Dirkson, Suzan Verberne, Wessel Kraaij",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.11308"" target=""_blank"">2109.11308</a>",,2025-12-03 22:39:25
Local Intrinsic Dimensionality Signals Adversarial Perturbations,"Sandamal Weerasinghe, Tansu Alpcan, Sarah M. Erfani, Christopher Leckie, Benjamin I. P. Rubinstein",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.11803"" target=""_blank"">2109.11803</a>",,2025-12-03 22:39:25
MINIMAL: Mining Models for Data Free Universal Adversarial Triggers,"Swapnil Parekh, Yaman Singla Kumar, Somesh Singh, Changyou Chen, Balaji Krishnamurthy, Rajiv Ratn Shah",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.12406"" target=""_blank"">2109.12406</a>",,2025-12-03 22:39:25
Contributions to Large Scale Bayesian Inference and Adversarial Machine Learning,Víctor Gallego,arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.13232"" target=""_blank"">2109.13232</a>",,2025-12-03 22:39:25
Two Souls in an Adversarial Image: Towards Universal Adversarial Example Detection using Multi-view Inconsistency,"Sohaib Kiani, Sana Awan, Chao Lan, Fengjun Li, Bo Luo",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.12459"" target=""_blank"">2109.12459</a>","<a href=""https://github.com/sohaib730/Argos-Adversarial_Detection"" target=""_blank"">sohaib730</a>",2025-12-03 22:39:25
Distributionally Robust Multiclass Classification and Applications in Deep CNN Image Classifiers,"Ruidi Chen, Boran Hao, Ioannis Paschalidis",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.12772"" target=""_blank"">2109.12772</a>",,2025-12-03 22:39:25
Improving Uncertainty of Deep Learning-based Object Classification on Radar Spectra using Label Smoothing,"Kanil Patel, William Beluch, Kilian Rambach, Michael Pfeiffer, Bin Yang",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.12851"" target=""_blank"">2109.12851</a>",,2025-12-03 22:39:25
Distributionally Robust Multi-Output Regression Ranking,"Shahabeddin Sotudian, Ruidi Chen, Ioannis Paschalidis",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.12803"" target=""_blank"">2109.12803</a>",,2025-12-03 22:39:25
GANG-MAM: GAN based enGine for Modifying Android Malware,"Renjith G, Sonia Laudanna, Aji S, Corrado Aaron Visaggio, Vinod P",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.13297"" target=""_blank"">2109.13297</a>",,2025-12-03 22:39:25
Dodging Attack Using Carefully Crafted Natural Makeup,"Nitzan Guetta, Asaf Shabtai, Inderjeet Singh, Satoru Momiyama, Yuval Elovici",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.06467"" target=""_blank"">2109.06467</a>",,2025-12-03 22:39:25
Classification and Adversarial examples in an Overparameterized Linear Model: A Signal Processing Perspective,"Adhyyan Narang, Vidya Muthukumar, Anant Sahai",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.13215"" target=""_blank"">2109.13215</a>",,2025-12-03 22:39:25
Cluster Attack: Query-based Adversarial Attacks on Graphs with Graph-Dependent Priors,"Zhengyi Wang, Zhongkai Hao, Ziqiao Wang, Hang Su, Jun Zhu",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.13069"" target=""_blank"">2109.13069</a>",,2025-12-03 22:39:25
MUTEN: Boosting Gradient-Based Adversarial Attacks via Mutant-Based Ensembles,"Yuejun Guo, Qiang Hu, Maxime Cordy, Michail Papadakis, Yves Le Traon",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.12838"" target=""_blank"">2109.12838</a>",,2025-12-03 22:39:25
slimTrain -- A Stochastic Approximation Method for Training Separable Deep Neural Networks,"Elizabeth Newman, Julianne Chung, Matthias Chung, Lars Ruthotto",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.14002"" target=""_blank"">2109.14002</a>",,2025-12-03 22:39:25
Mitigation of Adversarial Policy Imitation via Constrained Randomization of Policy (CRoP),"Nancirose Piazza, Vahid Behzadan",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.14678"" target=""_blank"">2109.14678</a>",,2025-12-03 22:39:25
BulletTrain: Accelerating Robust Neural Network Training via Boundary Example Mining,"Weizhe Hua, Yichi Zhang, Chuan Guo, Zhiru Zhang, G. Edward Suh",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.14707"" target=""_blank"">2109.14707</a>",,2025-12-03 22:39:25
Back in Black: A Comparative Evaluation of Recent State-Of-The-Art Black-Box Attacks,"Kaleel Mahmood, Rigel Mahmood, Ethan Rathbun, Dijk Marten van",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.15031"" target=""_blank"">2109.15031</a>",,2025-12-03 22:39:25
On Brightness Agnostic Adversarial Examples Against Face Recognition Systems,"Inderjeet Singh, Satoru Momiyama, Kazuya Kakizaki, Toshinori Araki",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.14205"" target=""_blank"">2109.14205</a>",,2025-12-03 22:39:25
Mitigating Black-Box Adversarial Attacks via Output Noise Perturbation,"Manjushree B. Aithal, Xiaohua Li",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.15160"" target=""_blank"">2109.15160</a>",,2025-12-03 22:39:25
From Zero-Shot Machine Learning to Zero-Day Attack Detection,"Mohanad Sarhan, Siamak Layeghy, Marcus Gallagher, Marius Portmann",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.14868"" target=""_blank"">2109.14868</a>",,2025-12-03 22:39:25
Adversarial Semantic Contour for Object Detection,"Yichi Zhang, Zijian Zhu, Xiao Yang, Jun Zhu",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.15009"" target=""_blank"">2109.15009</a>",,2025-12-03 22:39:25
You Cannot Easily Catch Me: A Low-Detectable Adversarial Patch for Object Detectors,"Zijian Zhu, Hang Su, Chang Liu, Wenzhao Xiang, Shibao Zheng",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.15177"" target=""_blank"">2109.15177</a>",,2025-12-03 22:39:25
Pushing the Right Buttons: Adversarial Evaluation of Quality Estimation,"Diptesh Kanojia, Marina Fomicheva, Tharindu Ranasinghe, Frédéric Blain, Constantin Orăsan, Lucia Specia",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.10859"" target=""_blank"">2109.10859</a>",,2025-12-03 22:39:25
Federated Deep Learning with Bayesian Privacy,"Hanlin Gu, Lixin Fan, Bowen Li, Yan Kang, Yuan Yao, Qiang Yang",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.13012"" target=""_blank"">2109.13012</a>",,2025-12-03 22:39:25
Attacks on Visualization-Based Malware Detection: Balancing Effectiveness and Executability,"Hadjer Benkraouda, Jingyu Qian, Hung Quoc Tran, Berkay Kaplan",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.10417"" target=""_blank"">2109.10417</a>",,2025-12-03 22:39:25
Harnessing Perceptual Adversarial Patches for Crowd Counting,"Shunchang Liu, Jiakai Wang, Aishan Liu, Yingwei Li, Yijie Gao, Xianglong Liu, Dacheng Tao",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.07986"" target=""_blank"">2109.07986</a>",,2025-12-03 22:39:25
3D Point Cloud Completion with Geometric-Aware Adversarial Augmentation,"Mengxi Wu, Hao Huang, Yi Fang",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.10161"" target=""_blank"">2109.10161</a>",,2025-12-03 22:39:25
PETGEN: Personalized Text Generation Attack on Deep Sequence Embedding-based Classification Models,"Bing He, Mustaque Ahamad, Srijan Kumar",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.06777"" target=""_blank"">2109.06777</a>",,2025-12-03 22:39:25
Improving Gradient-based Adversarial Training for Text Classification by Contrastive Learning and Auto-Encoder,"Yao Qiu, Jinchao Zhang, Jie Zhou",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.06536"" target=""_blank"">2109.06536</a>",,2025-12-03 22:39:25
A Novel Data Encryption Method Inspired by Adversarial Attacks,"Praveen Fernando, Jin Wei-Kocsis",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.06634"" target=""_blank"">2109.06634</a>",,2025-12-03 22:39:25
Can one hear the shape of a neural network?: Snooping the GPU via Magnetic Side Channel,"Henrique Teles Maia, Chang Xiao, Dingzeyu Li, Eitan Grinspun, Changxi Zheng",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.07395"" target=""_blank"">2109.07395</a>",,2025-12-03 22:39:25
Adversarial Mixing Policy for Relaxing Locally Linear Constraints in Mixup,"Guang Liu, Yuzhao Mao, Hailong Huang, Weiguo Gao, Xuan Li",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.07177"" target=""_blank"">2109.07177</a>",,2025-12-03 22:39:25
BERT is Robust! A Case Against Synonym-Based Adversarial Examples in Text Classification,"Jens Hauser, Zhao Meng, Damián Pascual, Roger Wattenhofer",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.07403"" target=""_blank"">2109.07403</a>",,2025-12-03 22:39:25
FCA: Learning a 3D Full-coverage Vehicle Camouflage for Multi-view Physical Adversarial Attack,"DonghuaWang, Tingsong Jiang, Jialiang Sun, Weien Zhou, Xiaoya Zhang, Zhiqiang Gong, Wen Yao, Xiaoqian Chen",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.07193"" target=""_blank"">2109.07193</a>",,2025-12-03 22:39:25
Universal Adversarial Attack on Deep Learning Based Prognostics,"Arghya Basak, Pradeep Rathore, Sri Harsha Nistala, Sagar Srinivas, Venkataramana Runkana",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.07142"" target=""_blank"">2109.07142</a>",,2025-12-03 22:39:25
Membership Inference Attacks Against Recommender Systems,"Minxing Zhang, Zhaochun Ren, Zihan Wang, Pengjie Ren, Zhumin Chen, Pengfei Hu, Yang Zhang",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.08045"" target=""_blank"">2109.08045</a>",,2025-12-03 22:39:25
Don't Search for a Search Method -- Simple Heuristics Suffice for Adversarial Text Attacks,"Nathaniel Berger, Stefan Riezler, Artem Sokolov, Sebastian Ebert",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.07926"" target=""_blank"">2109.07926</a>",,2025-12-03 22:39:25
Adversarial Attacks against Deep Learning Based Power Control in Wireless Communications,"Brian Kim, Yi Shi, Yalin E. Sagduyu, Tugba Erpek, Sennur Ulukus",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.08139"" target=""_blank"">2109.08139</a>",,2025-12-03 22:39:25
Targeted Attack on Deep RL-based Autonomous Driving with Learned Visual Patterns,"Prasanth Buddareddygari, Travis Zhang, Yezhou Yang, Yi Ren",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.07723"" target=""_blank"">2109.07723</a>",,2025-12-03 22:39:25
KATANA: Simple Post-Training Robustness Using Test Time Augmentations,"Gilad Cohen, Raja Giryes",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.08191"" target=""_blank"">2109.08191</a>","<a href=""https://github.com/giladcohen/KATANA"" target=""_blank"">giladcohen</a>",2025-12-03 22:39:25
Balancing detectability and performance of attacks on the control channel of Markov Decision Processes,"Alessio Russo, Alexandre Proutiere",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.07171"" target=""_blank"">2109.07171</a>",,2025-12-03 22:39:25
DeSMP: Differential Privacy-exploited Stealthy Model Poisoning Attacks in Federated Learning,"Md Tamjid Hossain, Shafkat Islam, Shahriar Badsha, Haoting Shen",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.09955"" target=""_blank"">2109.09955</a>",,2025-12-03 22:39:25
"""Hello, It's Me"": Deep Learning-based Speech Synthesis Attacks in the Real World","Emily Wenger, Max Bronckers, Christian Cianfarani, Jenna Cryan, Angela Sha, Haitao Zheng, Ben Y. Zhao",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.09598"" target=""_blank"">2109.09598</a>",,2025-12-03 22:39:25
Exploring the Training Robustness of Distributional Reinforcement Learning against Noisy State Observations,"Ke Sun, Yingnan Zhao, Shangling Jui, Linglong Kong",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.08776"" target=""_blank"">2109.08776</a>",,2025-12-03 22:39:25
"Privacy, Security, and Utility Analysis of Differentially Private CPES Data","Md Tamjid Hossain, Shahriar Badsha, Haoting Shen",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.09963"" target=""_blank"">2109.09963</a>",,2025-12-03 22:39:25
Robust Physical-World Attacks on Face Recognition,"Xin Zheng, Yanbo Fan, Baoyuan Wu, Yong Zhang, Jue Wang, Shirui Pan",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.09320"" target=""_blank"">2109.09320</a>",,2025-12-03 22:39:25
Modeling Adversarial Noise for Adversarial Defense,"Dawei Zhou, Nannan Wang, Bo Han, Tongliang Liu",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.09901"" target=""_blank"">2109.09901</a>",,2025-12-03 22:39:25
Can We Leverage Predictive Uncertainty to Detect Dataset Shift and Adversarial Examples in Android Malware Detection? (99%),"Deqiang Li, Tian Qiu, Shuo Chen, Qianmu Li, Shouhuai Xu",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.09654"" target=""_blank"">2109.09654</a>",,2025-12-03 22:39:25
Robustness Analysis of Deep Learning Frameworks on Mobile Platforms,"Amin Eslami Abyane, Hadi Hemmati",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.09869"" target=""_blank"">2109.09869</a>",,2025-12-03 22:39:25
EVAGAN: Evasion Generative Adversarial Network for Low Data Regimes,"Rizwan Hamid Randhawa, Nauman Aslam, Muhammad Alauthman, Husnain Rafiq, Muhammad Khalid",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.08026"" target=""_blank"">2109.08026</a>","<a href=""https://github.com/rhr407/EVAGAN"" target=""_blank"">rhr407</a>",2025-12-03 22:39:25
Towards Energy-Efficient and Secure Edge AI: A Cross-Layer Framework,"Muhammad Shafique, Alberto Marchisio, Rachmad Vidya Wicaksana Putra, Muhammad Abdullah Hanif",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.09829"" target=""_blank"">2109.09829</a>",,2025-12-03 22:39:25
On the Noise Stability and Robustness of Adversarially Trained Networks on NVM Crossbars,"Chun Tao, Deboleena Roy, Indranil Chakraborty, Kaushik Roy",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.09060"" target=""_blank"">2109.09060</a>",,2025-12-03 22:39:25
Adversarial Training with Contrastive Learning in NLP,"Daniela N. Rim, DongNyeong Heo, Heeyoul Choi",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.09075"" target=""_blank"">2109.09075</a>",,2025-12-03 22:39:25
Clean-label Backdoor Attack against Deep Hashing based Retrieval,"Kuofeng Gao, Jiawang Bai, Bin Chen, Dongxian Wu, Shu-Tao Xia",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.08868"" target=""_blank"">2109.08868</a>",,2025-12-03 22:39:25
Messing Up 3D Virtual Environments: Transferable Adversarial 3D Objects,"Enrico Meloni, Matteo Tiezzi, Luca Pasqualini, Marco Gori, Stefano Melacci",arXiv,2021-09,"<a href=""http://arxiv.org/abs/2109.08465"" target=""_blank"">2109.08465</a>",,2025-12-03 22:39:25
Meta Gradient Adversarial Attack,"Zheng Yuan, Jie Zhang, Yunpei Jia, Chuanqi Tan, Tao Xue, Shiguang Shan",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04204"" target=""_blank"">2108.04204</a>",,2025-12-03 22:39:25
Simple black-box universal adversarial attacks on medical image classification based on deep neural networks,"Kazuki Koga, Kazuhiro Takemoto",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04979"" target=""_blank"">2108.04979</a>",,2025-12-03 22:39:25
On the Effect of Pruning on Adversarial Robustness,"Artur Jordao, Helio Pedrini",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04890"" target=""_blank"">2108.04890</a>",,2025-12-03 22:39:25
SoK: How Robust is Image Classification Deep Neural Network Watermarking? (Extended Version),"Nils Lukas, Edward Jiang, Xinda Li, Florian Kerschbaum",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04974"" target=""_blank"">2108.04974</a>",,2025-12-03 22:39:25
Perturbing Inputs for Fragile Interpretations in Deep Natural Language Processing,"Sanchit Sinha, Hanjie Chen, Arshdeep Sekhon, Yangfeng Ji, Yanjun Qi",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04990"" target=""_blank"">2108.04990</a>",,2025-12-03 22:39:25
UniNet: A Unified Scene Understanding Network and Exploring Multi-Task Relationships through the Lens of Adversarial Attacks,"NareshKumar Gurulingan, Elahe Arani, Bahram Zonooz",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04584"" target=""_blank"">2108.04584</a>",,2025-12-03 22:39:25
Instance-wise Hard Negative Example Generation for Contrastive Learning in Unpaired Image-to-Image Translation,"Weilun Wang, Wengang Zhou, Jianmin Bao, Dong Chen, Houqiang Li",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04547"" target=""_blank"">2108.04547</a>",,2025-12-03 22:39:25
Neural Network Repair with Reachability Analysis,"Xiaodong Yang, Tom Yamaguchi, Hoang-Dung Tran, Bardh Hoxha, Taylor T Johnson, Danil Prokhorov",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04214"" target=""_blank"">2108.04214</a>",,2025-12-03 22:39:25
On Procedural Adversarial Noise Attack And Defense,"Jun Yan, Xiaoyang Deng, Huilin Yin, Wancheng Ge",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04409"" target=""_blank"">2108.04409</a>",,2025-12-03 22:39:25
Enhancing Knowledge Tracing via Adversarial Training,"Xiaopeng Guo, Zhijie Huang, Jie Gao, Mingyu Shang, Maojing Shu, Jun Sun",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04430"" target=""_blank"">2108.04430</a>","<a href=""https://github.com/xiaopengguo/ATKT"" target=""_blank"">xiaopengguo</a>",2025-12-03 22:39:25
Logic Explained Networks,"Gabriele Ciravegna, Pietro Barbiero, Francesco Giannini, Marco Gori, Pietro Lió, Marco Maggini, Stefano Melacci",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.05149"" target=""_blank"">2108.05149</a>",,2025-12-03 22:39:25
Classification Auto-Encoder based Detector against Diverse Data Poisoning Attacks,"Fereshteh Razmi, Li Xiong",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04206"" target=""_blank"">2108.04206</a>",,2025-12-03 22:39:25
Mis-spoke or mis-lead: Achieving Robustness in Multi-Agent Communicative Reinforcement Learning,"Wanqi Xue, Wei Qiu, Bo An, Zinovi Rabinovich, Svetlana Obraztsova, Chai Kiat Yeo",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.03803"" target=""_blank"">2108.03803</a>",,2025-12-03 22:39:25
"Privacy-Preserving Machine Learning: Methods, Challenges and Directions","Runhua Xu, Nathalie Baracaldo, James Joshi",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04417"" target=""_blank"">2108.04417</a>",,2025-12-03 22:39:25
Explainable AI and susceptibility to adversarial attacks: a case study in classification of breast ultrasound images,"Hamza Rasaee, Hassan Rivaz",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04345"" target=""_blank"">2108.04345</a>",,2025-12-03 22:39:25
Jointly Attacking Graph Neural Network and its Explanations,"Wenqi Fan, Wei Jin, Xiaorui Liu, Han Xu, Xianfeng Tang, Suhang Wang, Qing Li, Jiliang Tang, Jianping Wang, Charu Aggarwal",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.03388"" target=""_blank"">2108.03388</a>",,2025-12-03 22:39:25
Neural Architecture Dilation for Adversarial Robustness,"Yanxi Li, Zhaohui Yang, Yunhe Wang, Chang Xu",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.06885"" target=""_blank"">2108.06885</a>",,2025-12-03 22:39:25
Are Neural Ranking Models Robust? (4%),"Chen Wu, Ruqing Zhang, Jiafeng Guo, Yixing Fan, Xueqi Cheng",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.05018"" target=""_blank"">2108.05018</a>",,2025-12-03 22:39:25
Attacks against Ranking Algorithms with Text Embeddings: a Case Study on Recruitment Algorithms,"Anahita Samadi, Debapriya Banerjee, Shirin Nilizadeh",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.05490"" target=""_blank"">2108.05490</a>",,2025-12-03 22:39:25
Turning Your Strength against You: Detecting and Mitigating Robust and Universal Adversarial Patch Attacks,"Zitao Chen, Pritam Dash, Karthik Pattabiraman",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.05075"" target=""_blank"">2108.05075</a>",,2025-12-03 22:39:25
Hatemoji: A Test Suite and Adversarially-Generated Dataset for Benchmarking and Detecting Emoji-based Hate,"Hannah Rose Kirk, Bertram Vidgen, Paul Röttger, Tristan Thrush, Scott A. Hale",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.05921"" target=""_blank"">2108.05921</a>",,2025-12-03 22:39:25
Deep adversarial attack on target detection systems,"Uche M. Osahor, Nasser M. Nasrabadi",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.05948"" target=""_blank"">2108.05948</a>",,2025-12-03 22:39:25
AGKD-BML: Defense Against Adversarial Attack by Attention Guided Knowledge Distillation and Bi-directional Metric Learning,"Hong Wang, Yuefan Deng, Shinjae Yoo, Haibin Ling, Yuewei Lin",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.06017"" target=""_blank"">2108.06017</a>","<a href=""https://github.com/hongw579/AGKD-BML"" target=""_blank"">hongw579</a>",2025-12-03 22:39:25
The Forgotten Threat of Voltage Glitching: A Case Study on Nvidia Tegra X2 SoCs,"Otto Bittner, Thilo Krachenfels, Andreas Galauner, Jean-Pierre Seifert",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.06131"" target=""_blank"">2108.06131</a>",,2025-12-03 22:39:25
Understanding Structural Vulnerability in Graph Convolutional Networks,"Liang Chen, Jintang Li, Qibiao Peng, Yang Liu, Zibin Zheng, Carl Yang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.06280"" target=""_blank"">2108.06280</a>",,2025-12-03 22:39:25
Optical Adversarial Attack,"Abhiram Gnanasambandam, Alex M. Sherman, Stanley H. Chan",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.06247"" target=""_blank"">2108.06247</a>",,2025-12-03 22:39:25
Evaluating the Robustness of Semantic Segmentation for Autonomous Driving against Real-World Adversarial Patch Attacks,"Federico Nesti, Giulio Rossolini, Saasha Nair, Alessandro Biondi, Giorgio Buttazzo",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.06179"" target=""_blank"">2108.06179</a>",,2025-12-03 22:39:25
LinkTeller: Recovering Private Edges from Graph Neural Networks via Influence Analysis,"Fan Wu, Yunhui Long, Ce Zhang, Bo Li",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.06504"" target=""_blank"">2108.06504</a>",,2025-12-03 22:39:25
IADA: Iterative Adversarial Data Augmentation Using Formal Verification and Expert Guidance,"Ruixuan Liu, Changliu Liu",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.06871"" target=""_blank"">2108.06871</a>",,2025-12-03 22:39:25
Deep Adversarially-Enhanced k-Nearest Neighbors,"Ren Wang, Tianqi Chen",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.06797"" target=""_blank"">2108.06797</a>",,2025-12-03 22:39:25
On the Opportunities and Risks of Foundation Models,"Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Arx Sydney von, Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, Erik Brynjolfsson, Shyamal Buch, Dallas Card, Rodrigo Castellon, Niladri Chatterji, Annie Chen, Kathleen Creel, Jared Quincy Davis, Dora Demszky, Chris Donahue, Moussa Doumbouya, Esin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh, Li Fei-Fei, Chelsea Finn, Trevor Gale, Lauren Gillespie, Karan Goel, Noah Goodman, Shelby Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson, John Hewitt, Daniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil Jain, Dan Jurafsky, Pratyusha Kalluri, Siddharth Karamcheti, Geoff Keeling, Fereshte Khani, Omar Khattab, Pang Wei Koh, Mark Krass, Ranjay Krishna, Rohith Kuditipudi, Ananya Kumar, Faisal Ladhak, Mina Lee, Tony Lee, Jure Leskovec, Isabelle Levent, Xiang Lisa Li, Xuechen Li, Tengyu Ma, Ali Malik, Christopher D. Manning, Suvir Mirchandani, Eric Mitchell, Zanele Munyikwa, Suraj Nair, Avanika Narayan, Deepak Narayanan, Ben Newman, Allen Nie, Juan Carlos Niebles, Hamed Nilforoshan, Julian Nyarko, Giray Ogut, Laurel Orr, Isabel Papadimitriou, Joon Sung Park, Chris Piech, Eva Portelance, Christopher Potts, Aditi Raghunathan, Rob Reich, Hongyu Ren, Frieda Rong, Yusuf Roohani, Camilo Ruiz, Jack Ryan, Christopher Ré, Dorsa Sadigh, Shiori Sagawa, Keshav Santhanam, Andy Shih, Krishnan Srinivasan, Alex Tamkin, Rohan Taori, Armin W. Thomas, Florian Tramèr, Rose E. Wang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai Wu, Sang Michael Xie, Michihiro Yasunaga, Jiaxuan You, Matei Zaharia, Michael Zhang, Tianyi Zhang, Xikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn Zhou, Percy Liang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.07258"" target=""_blank"">2108.07258</a>",,2025-12-03 22:39:25
Information Bottleneck Approach to Spatial Attention Learning,"Qiuxia Lai, Yu Li, Ailing Zeng, Minhao Liu, Hanqiu Sun, Qiang Xu",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.03418"" target=""_blank"">2108.03418</a>","<a href=""https://github.com/ashleylqx/AIB"" target=""_blank"">ashleylqx</a>",2025-12-03 22:39:25
Membership Inference Attacks on Lottery Ticket Networks,"Aadesh Bagmar, Shishira R Maiya, Shruti Bidwalka, Amol Deshpande",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.03506"" target=""_blank"">2108.03506</a>",,2025-12-03 22:39:25
BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning,"Jinyuan Jia, Yupei Liu, Neil Zhenqiang Gong",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.00352"" target=""_blank"">2108.00352</a>","<a href=""https://github.com/jjy1994/BadEncoder"" target=""_blank"">jjy1994</a>",2025-12-03 22:39:25
Evaluating Adversarial Attacks on Driving Safety in Vision-Based Autonomous Vehicles,"Jindi Zhang, Yang Lou, Jianping Wang, Kui Wu, Kejie Lu, Xiaohua Jia",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.02940"" target=""_blank"">2108.02940</a>",,2025-12-03 22:39:25
Delving into Deep Image Prior for Adversarial Defense: A Novel Reconstruction-based Defense Framework,"Li Ding, Yongwei Wang, Xin Ding, Kaiwen Yuan, Ping Wang, Hua Huang, Z. Jane Wang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.00180"" target=""_blank"">2108.00180</a>",,2025-12-03 22:39:25
Information Stealing in Federated Learning Systems Based on Generative Adversarial Networks,"Yuwei Sun, Ng Chong, Hideya Ochiai",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.00701"" target=""_blank"">2108.00701</a>",,2025-12-03 22:39:25
Efficacy of Statistical and Artificial Intelligence-based False Information Cyberattack Detection Models for Connected Vehicles,"Sakib Mahmud Khan, Gurcan Comert, Mashrur Chowdhury",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.01124"" target=""_blank"">2108.01124</a>",,2025-12-03 22:39:25
Advances in adversarial attacks and defenses in computer vision: A survey,"Naveed Akhtar, Ajmal Mian, Navid Kardan, Mubarak Shah",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.00401"" target=""_blank"">2108.00401</a>",,2025-12-03 22:39:25
Certified Defense via Latent Space Randomized Smoothing with Orthogonal Encoders,"Huimin Zeng, Jiahao Su, Furong Huang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.00491"" target=""_blank"">2108.00491</a>",,2025-12-03 22:39:25
An Effective and Robust Detector for Logo Detection,"Xiaojun Jia, Huanqian Yan, Yonglin Wu, Xingxing Wei, Xiaochun Cao, Yong Zhang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.00422"" target=""_blank"">2108.00422</a>","<a href=""https://github.com/jiaxiaojunQAQ/Robust-Logo-Detection"" target=""_blank"">jiaxiaojunQAQ</a>",2025-12-03 22:39:25
Style Curriculum Learning for Robust Medical Image Segmentation,"Zhendong Liu, Van Manh, Xin Yang, Xiaoqiong Huang, Karim Lekadir, Víctor Campello, Nishant Ravikumar, Alejandro F Frangi, Dong Ni",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.00402"" target=""_blank"">2108.00402</a>",,2025-12-03 22:39:25
Adversarial Robustness of Deep Code Comment Generation,"Yu Zhou, Xiaoqing Zhang, Juanjuan Shen, Tingting Han, Taolue Chen, Harald Gall",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.00213"" target=""_blank"">2108.00213</a>",,2025-12-03 22:39:25
Ensemble Augmentation for Deep Neural Networks Using 1-D Time Series Vibration Data,"Atik Faysal, Ngui Wai Keng, M. H. Lim",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.03288"" target=""_blank"">2108.03288</a>",,2025-12-03 22:39:25
Towards Adversarially Robust and Domain Generalizable Stereo Matching by Rethinking DNN Feature Backbones,"Kelvin Cheng, Christopher Healey, Tianfu Wu",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.00335"" target=""_blank"">2108.00335</a>",,2025-12-03 22:39:25
T$_k$ML-AP: Adversarial Attacks to Top-$k$ Multi-Label Learning,"Shu Hu, Lipeng Ke, Xin Wang, Siwei Lyu",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.00146"" target=""_blank"">2108.00146</a>",,2025-12-03 22:39:25
NeuraCrypt is not private,"Nicholas Carlini, Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody, Florian Tramer",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.07256"" target=""_blank"">2108.07256</a>",,2025-12-03 22:39:25
Fair Representation Learning using Interpolation Enabled Disentanglement,"Akshita Jha, Bhanukiran Vinzamuri, Chandan K. Reddy",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.00295"" target=""_blank"">2108.00295</a>",,2025-12-03 22:39:25
ROPUST: Improving Robustness through Fine-tuning with Photonic Processors and Synthetic Gradients,"Alessandro Cappelli, Julien Launay, Laurent Meunier, Ruben Ohana, Iacopo Poli",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04217"" target=""_blank"">2108.04217</a>",,2025-12-03 22:39:25
Generative Adversarial Neural Cellular Automata,"Maximilian Otte, Quentin Delfosse, Johannes Czech, Kristian Kersting",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04328"" target=""_blank"">2108.04328</a>",,2025-12-03 22:39:25
Adversarial Attacks Against Deep Reinforcement Learning Framework in Internet of Vehicles,"Anum Talpur, Mohan Gurusamy",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.00833"" target=""_blank"">2108.00833</a>",,2025-12-03 22:39:25
Hybrid Classical-Quantum Deep Learning Models for Autonomous Vehicle Traffic Image Classification Under Adversarial Attack,"Reek Majumder, Sakib Mahmud Khan, Fahim Ahmed, Zadid Khan, Frank Ngeni, Gurcan Comert, Judith Mwakalonge, Dimitra Michalaka, Mashrur Chowdhury",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.01125"" target=""_blank"">2108.01125</a>",,2025-12-03 22:39:25
Tutorials on Testing Neural Networks,"Nicolas Berthier, Youcheng Sun, Wei Huang, Yanghao Zhang, Wenjie Ruan, Xiaowei Huang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.01734"" target=""_blank"">2108.01734</a>",,2025-12-03 22:39:25
DeepFreeze: Cold Boot Attacks and High Fidelity Model Recovery on Commercial EdgeML Device,"Yoo-Seung Won, Soham Chatterjee, Dirmanto Jap, Arindam Basu, Shivam Bhasin",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.01281"" target=""_blank"">2108.01281</a>",,2025-12-03 22:39:25
The Devil is in the GAN: Backdoor Attacks and Defenses in Deep Generative Models,"Ambrish Rawat, Killian Levacher, Mathieu Sinn",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.01644"" target=""_blank"">2108.01644</a>",,2025-12-03 22:39:25
AdvRush: Searching for Adversarially Robust Neural Architectures,"Jisoo Mok, Byunggook Na, Hyeokjun Choe, Sungroh Yoon",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.01289"" target=""_blank"">2108.01289</a>",,2025-12-03 22:39:25
On the Exploitability of Audio Machine Learning Pipelines to Surreptitious Adversarial Examples,"Adelin Travers, Lorna Licollari, Guanghan Wang, Varun Chandrasekaran, Adam Dziedzic, David Lie, Nicolas Papernot",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.02010"" target=""_blank"">2108.02010</a>",,2025-12-03 22:39:25
On the Robustness of Domain Adaption to Adversarial Attacks,"Liyuan Zhang, Yuhang Zhou, Lei Zhang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.01807"" target=""_blank"">2108.01807</a>",,2025-12-03 22:39:25
Semi-supervised Conditional GAN for Simultaneous Generation and Detection of Phishing URLs: A Game theoretic Perspective,"Sharif Amit Kamran, Shamik Sengupta, Alireza Tavakkoli",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.01852"" target=""_blank"">2108.01852</a>",,2025-12-03 22:39:25
Robust Transfer Learning with Pretrained Language Models through Adapters,"Wenjuan Han, Bo Pang, Yingnian Wu",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.02340"" target=""_blank"">2108.02340</a>",,2025-12-03 22:39:25
Locally Interpretable One-Class Anomaly Detection for Credit Card Fraud Detection,"Tungyu Wu, Youting Wang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.02501"" target=""_blank"">2108.02501</a>",,2025-12-03 22:39:25
Exploring Structure Consistency for Deep Model Watermarking,"Jie Zhang, Dongdong Chen, Jing Liao, Han Fang, Zehua Ma, Weiming Zhang, Gang Hua, Nenghai Yu",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.02360"" target=""_blank"">2108.02360</a>",,2025-12-03 22:39:25
Fairness Properties of Face Recognition and Obfuscation Systems,"Harrison Rosenberg, Brian Tang, Kassem Fawaz, Somesh Jha",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.02707"" target=""_blank"">2108.02707</a>",,2025-12-03 22:39:25
Householder Activations for Provable Robustness against Adversarial Attacks,"Sahil Singla, Surbhi Singla, Soheil Feizi",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.04062"" target=""_blank"">2108.04062</a>",,2025-12-03 22:39:25
Imperceptible Adversarial Examples by Spatial Chroma-Shift,"Ayberk Aydin, Deniz Sen, Berat Tuna Karli, Oguz Hanoglu, Alptekin Temizel",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.02502"" target=""_blank"">2108.02502</a>",,2025-12-03 22:39:25
Poison Ink: Robust and Invisible Backdoor Attack,"Jie Zhang, Dongdong Chen, Jing Liao, Qidong Huang, Gang Hua, Weiming Zhang, Nenghai Yu",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.02488"" target=""_blank"">2108.02488</a>",,2025-12-03 22:39:25
BOSS: Bidirectional One-Shot Synthesis of Adversarial Examples,"Ismail Alkhouri, Alvaro Velasquez, George Atia",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.02756"" target=""_blank"">2108.02756</a>",,2025-12-03 22:39:25
Identifying and Exploiting Structures for Reliable Deep Learning,Amartya Sanyal,arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.07083"" target=""_blank"">2108.07083</a>",,2025-12-03 22:39:25
Interpreting Attributions and Interactions of Adversarial Attacks,"Xin Wang, Shuyun Lin, Hao Zhang, Yufei Zhu, Quanshi Zhang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.06895"" target=""_blank"">2108.06895</a>",,2025-12-03 22:39:25
Patch Attack Invariance: How Sensitive are Patch Attacks to 3D Pose? (62%),"Max Lennon, Nathan Drenkow, Philippe Burlina",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.07229"" target=""_blank"">2108.07229</a>",,2025-12-03 22:39:25
"Why Adversarial Reprogramming Works, When It Fails, and How to Tell the Difference","Yang Zheng, Xiaoyi Feng, Zhaoqiang Xia, Xiaoyue Jiang, Ambra Demontis, Maura Pintor, Battista Biggio, Fabio Roli",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.11673"" target=""_blank"">2108.11673</a>",,2025-12-03 22:39:25
Disrupting Adversarial Transferability in Deep Neural Networks,"Christopher Wiedeman, Ge Wang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.12492"" target=""_blank"">2108.12492</a>",,2025-12-03 22:39:25
Evaluating the Robustness of Neural Language Models to Input Perturbations,"Milad Moradi, Matthias Samwald",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.12237"" target=""_blank"">2108.12237</a>",,2025-12-03 22:39:25
Deep learning models are not robust against noise in clinical text,"Milad Moradi, Kathrin Blagec, Matthias Samwald",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.12242"" target=""_blank"">2108.12242</a>",,2025-12-03 22:39:25
Understanding the Logit Distributions of Adversarially-Trained Deep Neural Networks,"Landan Seguin, Anthony Ndirango, Neeli Mishra, SueYeon Chung, Tyler Lee",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.12001"" target=""_blank"">2108.12001</a>",,2025-12-03 22:39:25
A Hierarchical Assessment of Adversarial Severity,"Guillaume Jeanneret, Juan C Perez, Pablo Arbelaez",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.11785"" target=""_blank"">2108.11785</a>",,2025-12-03 22:39:25
Physical Adversarial Attacks on an Aerial Imagery Object Detector,"Andrew Du, Bo Chen, Tat-Jun Chin, Yee Wei Law, Michele Sasdelli, Ramesh Rajasegaran, Dillon Campbell",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.11765"" target=""_blank"">2108.11765</a>",,2025-12-03 22:39:25
Detection and Continual Learning of Novel Face Presentation Attacks,"Mohammad Rostami, Leonidas Spinoulas, Mohamed Hussein, Joe Mathai, Wael Abd-Almageed",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.12081"" target=""_blank"">2108.12081</a>",,2025-12-03 22:39:25
StyleAugment: Learning Texture De-biased Representations by Style Augmentation without Pre-defined Textures,"Sanghyuk Chun, Song Park",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.10549"" target=""_blank"">2108.10549</a>",,2025-12-03 22:39:25
Adversarially Robust One-class Novelty Detection,"Shao-Yuan Lo, Poojan Oza, Vishal M. Patel",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.11168"" target=""_blank"">2108.11168</a>","<a href=""https://github.com/shaoyuanlo/PrincipaLS"" target=""_blank"">shaoyuanlo</a>",2025-12-03 22:39:25
Certifiers Make Neural Networks Vulnerable to Availability Attacks,"Tobias Lorenz, Marta Kwiatkowska, Mario Fritz",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.11299"" target=""_blank"">2108.11299</a>",,2025-12-03 22:39:25
Bridged Adversarial Training,"Hoki Kim, Woojin Lee, Sungyoon Lee, Jaewook Lee",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.11135"" target=""_blank"">2108.11135</a>",,2025-12-03 22:39:25
Generalized Real-World Super-Resolution through Adversarial Robustness,"Angela Castillo, María Escobar, Juan C. Pérez, Andrés Romero, Radu Timofte, Gool Luc Van, Pablo Arbeláez",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.11505"" target=""_blank"">2108.11505</a>",,2025-12-03 22:39:25
Improving Visual Quality of Unrestricted Adversarial Examples with Wavelet-VAE,"Wenzhao Xiang, Chang Liu, Shibao Zheng",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.11032"" target=""_blank"">2108.11032</a>",,2025-12-03 22:39:25
Are socially-aware trajectory prediction models really socially-aware? (92%),"Saeed Saadatnejad, Mohammadhossein Bahari, Pedram Khorsandi, Mohammad Saneian, Seyed-Mohsen Moosavi-Dezfooli, Alexandre Alahi",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.10879"" target=""_blank"">2108.10879</a>","<a href=""https://s-attack.github.io/"" target=""_blank"">s-attack.github.io</a>",2025-12-03 22:39:25
Mal2GCN: A Robust Malware Detection Approach Using Deep Graph Convolutional Networks With Non-Negative Weights,"Omid Kargarnovin, Amir Mahdi Sadeghzadeh, Rasool Jalili",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.12473"" target=""_blank"">2108.12473</a>",,2025-12-03 22:39:25
DropAttack: A Masked Weight Adversarial Training Method to Improve Generalization of Neural Networks,"Shiwen Ni, Jiawen Li, Hung-Yu Kao",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.12805"" target=""_blank"">2108.12805</a>","<a href=""https://github.com/nishiwen1214/DropAttack"" target=""_blank"">nishiwen1214</a>",2025-12-03 22:39:25
Reinforcement Learning Based Sparse Black-box Adversarial Attack on Video Recognition Models,"Zeyuan Wang, Chaofeng Sha, Su Yang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13872"" target=""_blank"">2108.13872</a>",,2025-12-03 22:39:25
Searching for an Effective Defender: Benchmarking Defense against Adversarial Word Substitution,"Zongyi Li, Jianhan Xu, Jiehang Zeng, Linyang Li, Xiaoqing Zheng, Qi Zhang, Kai-Wei Chang, Cho-Jui Hsieh",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.12777"" target=""_blank"">2108.12777</a>",,2025-12-03 22:39:25
DuTrust: A Sentiment Analysis Dataset for Trustworthiness Evaluation,"Lijie Wang, Hao Liu, Shuyuan Peng, Hongxuan Tang, Xinyan Xiao, Ying Chen, Hua Wu, Haifeng Wang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13140"" target=""_blank"">2108.13140</a>",,2025-12-03 22:39:25
ML-based IoT Malware Detection Under Adversarial Settings: A Systematic Evaluation,"Ahmed Abusnaina, Afsah Anwar, Sultan Alshamrani, Abdulrahman Alabduljabbar, RhongHo Jang, Daehun Nyang, David Mohaisen",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13373"" target=""_blank"">2108.13373</a>",,2025-12-03 22:39:25
How Does Adversarial Fine-Tuning Benefit BERT? (33%),"Javid Ebrahimi, Hao Yang, Wei Zhang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13602"" target=""_blank"">2108.13602</a>",,2025-12-03 22:39:25
Adaptive perturbation adversarial training: based on reinforcement learning,"Zhishen Nie, Ying Lin, Sp Ren, Lan Zhang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13239"" target=""_blank"">2108.13239</a>",,2025-12-03 22:39:25
Benchmarking the Accuracy and Robustness of Feedback Alignment Algorithms,"Albert Jiménez Sanfiz, Mohamed Akrout",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13446"" target=""_blank"">2108.13446</a>",,2025-12-03 22:39:25
Single Node Injection Attack against Graph Neural Networks,"Shuchang Tao, Qi Cao, Huawei Shen, Junjie Huang, Yunfan Wu, Xueqi Cheng",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13049"" target=""_blank"">2108.13049</a>",,2025-12-03 22:39:25
Adversarial Example Devastation and Detection on Speech Recognition System by Adding Random Noise,"Mingyu Dong, Diqun Yan, Yongkang Gong, Rangding Wang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13562"" target=""_blank"">2108.13562</a>",,2025-12-03 22:39:25
Investigating Vulnerabilities of Deep Neural Policies,Ezgi Korkmaz,arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13093"" target=""_blank"">2108.13093</a>",,2025-12-03 22:39:25
Sample Efficient Detection and Classification of Adversarial Attacks via Self-Supervised Embeddings,"Mazda Moayeri, Soheil Feizi",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13797"" target=""_blank"">2108.13797</a>",,2025-12-03 22:39:25
Backdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning,"Linyang Li, Demin Song, Xiaonan Li, Jiehang Zeng, Ruotian Ma, Xipeng Qiu",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13888"" target=""_blank"">2108.13888</a>",,2025-12-03 22:39:25
Exploring Transferable and Robust Adversarial Perturbation Generation from the Perspective of Network Hierarchy,"Ruikui Wang, Yuanfang Guo, Ruijie Yang, Yunhong Wang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.07033"" target=""_blank"">2108.07033</a>",,2025-12-03 22:39:25
Morphence: Moving Target Defense Against Adversarial Examples,"Abderrahmen Amich, Birhanu Eshete",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13952"" target=""_blank"">2108.13952</a>",,2025-12-03 22:39:25
EG-Booster: Explanation-Guided Booster of ML Evasion Attacks,"Abderrahmen Amich, Birhanu Eshete",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13930"" target=""_blank"">2108.13930</a>",,2025-12-03 22:39:25
OOWL500: Overcoming Dataset Collection Bias in the Wild,"Brandon Leung, Chih-Hui Ho, Amir Persekian, David Orozco, Yen Chang, Erik Sandstrom, Bo Liu, Nuno Vasconcelos",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.10992"" target=""_blank"">2108.10992</a>",,2025-12-03 22:39:25
Segmentation Fault: A Cheap Defense Against Adversarial Machine Learning,"Doha Al Bared, Mohamed Nassar",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13617"" target=""_blank"">2108.13617</a>",,2025-12-03 22:39:25
"Adversarial Robustness of Deep Learning: Theory, Algorithms, and Applications","Wenjie Ruan, Xinping Yi, Xiaowei Huang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.10451"" target=""_blank"">2108.10451</a>",,2025-12-03 22:39:25
Detecting and Segmenting Adversarial Graphics Patterns from Images,"Xiangyu Purdue University Qu, Stanley H. Purdue University Chan",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.09383"" target=""_blank"">2108.09383</a>",,2025-12-03 22:39:25
Appearance Based Deep Domain Adaptation for the Classification of Aerial Images,"Dennis Wittich, Franz Rottensteiner",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.07779"" target=""_blank"">2108.07779</a>",,2025-12-03 22:39:25
Coalesced Multi-Output Tsetlin Machines with Clause Sharing,"Sondre Glimsdal, Ole-Christoffer Granmo",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.07594"" target=""_blank"">2108.07594</a>",,2025-12-03 22:39:25
Semantic Perturbations with Normalizing Flows for Improved Generalization,"Oguz Kaan Yuksel, Sebastian U. Stich, Martin Jaggi, Tatjana Chavdarova",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.07958"" target=""_blank"">2108.07958</a>",,2025-12-03 22:39:25
Adversarial Relighting Against Face Recognition,"Qian Zhang, Qing Guo, Ruijun Gao, Felix Juefei-Xu, Hongkai Yu, Wei Feng",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.07920"" target=""_blank"">2108.07920</a>",,2025-12-03 22:39:25
When Should You Defend Your Classifier -- A Game-theoretical Analysis of Countermeasures against Adversarial Examples,"Maximilian Samsinger, Florian Merkle, Pascal Schöttle, Tomas Pevny",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.07602"" target=""_blank"">2108.07602</a>",,2025-12-03 22:39:25
Proceedings of the 1st International Workshop on Adaptive Cyber Defense,"Damian Marriott, Kimberly Ferguson-Walter, Sunny Fugate, Marco Carvalho",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.08476"" target=""_blank"">2108.08476</a>",,2025-12-03 22:39:25
MBRS : Enhancing Robustness of DNN-based Watermarking by Mini-Batch of Real and Simulated JPEG Compression,"Zhaoyang Jia, Han Fang, Weiming Zhang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.08211"" target=""_blank"">2108.08211</a>","<a href=""https://github.com/jzyustc/MBRS"" target=""_blank"">jzyustc</a>",2025-12-03 22:39:25
Exploiting Multi-Object Relationships for Detecting Adversarial Attacks in Complex Scenes,"Mingjun Yin, Shasha Li, Zikui Cai, Chengyu Song, M. Salman Asif, Amit K. Roy-Chowdhury, Srikanth V. Krishnamurthy",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.08421"" target=""_blank"">2108.08421</a>",,2025-12-03 22:39:25
Revisiting Adversarial Robustness Distillation: Robust Soft Labels Make Student Better,"Bojia Zi, Shihao Zhao, Xingjun Ma, Yu-Gang Jiang",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.07969"" target=""_blank"">2108.07969</a>",,2025-12-03 22:39:25
ASAT: Adaptively Scaled Adversarial Training in Time Series,"Zhiyuan Zhang, Wei Li, Ruihan Bao, Keiko Harimoto, Yunfang Wu, Xu Sun",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.08976"" target=""_blank"">2108.08976</a>",,2025-12-03 22:39:25
Pruning in the Face of Adversaries,"Florian Merkle, Maximilian Samsinger, Pascal Schöttle",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.08560"" target=""_blank"">2108.08560</a>",,2025-12-03 22:39:25
Application of Adversarial Examples to Physical ECG Signals,"Taiga Waseda University Ono, Takeshi The University of Electro-Communications Sugawara, Jun University of Tsukuba Sakuma, Tatsuya Waseda University RIKEN AIP Mori",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.08972"" target=""_blank"">2108.08972</a>",,2025-12-03 22:39:25
Early-exit deep neural networks for distorted images: providing an efficient edge offloading,"Roberto G. Pacheco, Fernanda D. V. R. Oliveira, Rodrigo S. Couto",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.09343"" target=""_blank"">2108.09343</a>",,2025-12-03 22:39:25
"UnSplit: Data-Oblivious Model Inversion, Model Stealing, and Label Inference Attacks Against Split Learning","Ege Erdogan, Alptekin Kupcu, A. Ercument Cicek",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.09033"" target=""_blank"">2108.09033</a>",,2025-12-03 22:39:25
Amplitude-Phase Recombination: Rethinking Robustness of Convolutional Neural Networks in Frequency Domain,"Guangyao Chen, Peixi Peng, Li Ma, Jia Li, Lin Du, Yonghong Tian",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.08487"" target=""_blank"">2108.08487</a>",,2025-12-03 22:39:25
Towards Understanding the Generative Capability of Adversarially Robust Classifiers,"Yao Zhu, Jiacheng Ma, Jiacheng Sun, Zewei Chen, Rongxin Jiang, Zhenguo Li",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.09093"" target=""_blank"">2108.09093</a>",,2025-12-03 22:39:25
Multi-Expert Adversarial Attack Detection in Person Re-identification Using Context Inconsistency,"Xueping Wang, Shasha Li, Min Liu, Yaonan Wang, Amit K. Roy-Chowdhury",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.09891"" target=""_blank"">2108.09891</a>",,2025-12-03 22:39:25
Deep Bayesian Image Set Classification: A Defence Approach against Adversarial Attacks,"Nima Mirnateghi, Syed Afaq Ali Shah, Mohammed Bennamoun",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.10217"" target=""_blank"">2108.10217</a>",,2025-12-03 22:39:25
Kryptonite: An Adversarial Attack Using Regional Focus,"Yogesh Kulkarni, Krisha Bhambani",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.10251"" target=""_blank"">2108.10251</a>",,2025-12-03 22:39:25
Integer-arithmetic-only Certified Robustness for Quantized Neural Networks,"Haowen Lin, Jian Lou, Li Xiong, Cyrus Shahabi",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.09413"" target=""_blank"">2108.09413</a>",,2025-12-03 22:39:25
Back to the Drawing Board: A Critical Evaluation of Poisoning Attacks on Federated Learning,"Virat Shejwalkar, Amir Houmansadr, Peter Kairouz, Daniel Ramage",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.10241"" target=""_blank"">2108.10241</a>",,2025-12-03 22:39:25
SegMix: Co-occurrence Driven Mixup for Semantic Segmentation and Adversarial Robustness,"Md Amirul Islam, Matthew Kowal, Konstantinos G. Derpanis, Neil D. B. Bruce",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.09929"" target=""_blank"">2108.09929</a>",,2025-12-03 22:39:25
Robustness-via-Synthesis: Robust Training with Generative Adversarial Perturbations,"Inci M. Baytas, Debayan Deb",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.09713"" target=""_blank"">2108.09713</a>",,2025-12-03 22:39:25
Semantic-Preserving Adversarial Text Attacks,"Xinghao Yang, Weifeng Liu, James Bailey, Tianqing Zhu, Dacheng Tao, Wei Liu",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.10015"" target=""_blank"">2108.10015</a>",,2025-12-03 22:39:25
Relating CNNs with brain: Challenges and findings,Reem Abdel-Salam,arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.09768"" target=""_blank"">2108.09768</a>",,2025-12-03 22:39:25
"""Adversarial Examples"" for Proof-of-Learning","Rui Zhang, Jian Liu, Yuan Ding, Qingbiao Wu, Kui Ren",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.09454"" target=""_blank"">2108.09454</a>",,2025-12-03 22:39:25
PatchCleanser: Certifiably Robust Defense against Adversarial Patches for Any Image Classifier,"Chong Xiang, Saeed Mahloujifar, Prateek Mittal",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.09135"" target=""_blank"">2108.09135</a>",,2025-12-03 22:39:25
Regularizing Instabilities in Image Reconstruction Arising from Learned Denoisers,Abinash Nayak,arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.13551"" target=""_blank"">2108.13551</a>",,2025-12-03 22:39:25
AdvDrop: Adversarial Attack to DNNs by Dropping Information,"Ranjie Duan, Yuefeng Chen, Dantong Niu, Yun Yang, A. K. Qin, Yuan He",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.09034"" target=""_blank"">2108.09034</a>",,2025-12-03 22:39:25
A Hard Label Black-box Adversarial Attack Against Graph Neural Networks,"Jiaming Mu, Binghui Wang, Qi Li, Kun Sun, Mingwei Xu, Zhuotao Liu",arXiv,2021-08,"<a href=""http://arxiv.org/abs/2108.09513"" target=""_blank"">2108.09513</a>",,2025-12-03 22:39:25
Learning to Detect Adversarial Examples Based on Class Scores,"Tobias Uelwer, Felix Michels, Candido Oliver De",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.04435"" target=""_blank"">2107.04435</a>",,2025-12-03 22:39:25
HOMRS: High Order Metamorphic Relations Selector for Deep Neural Networks,"Florian Tambon, Giulio Antoniol, Foutse Khomh",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.04863"" target=""_blank"">2107.04863</a>",,2025-12-03 22:39:25
Identifying Layers Susceptible to Adversarial Attacks,"Shoaib Ahmed Siddiqui, Thomas Breuel",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.04827"" target=""_blank"">2107.04827</a>",,2025-12-03 22:39:25
Out of Distribution Detection and Adversarial Attacks on Deep Neural Networks for Robust Medical Image Analysis,"Anisie Uwimana1, Ransalu Senanayake",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.04882"" target=""_blank"">2107.04882</a>",,2025-12-03 22:39:25
Cyber-Security Challenges in Aviation Industry: A Review of Current and Future Trends,"Elochukwu Ukwandu, Mohamed Amine Ben Farah, Hanan Hindy, Miroslav Bures, Robert Atkinson, Christos Tachtatzis, Xavier Bellekens",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.04910"" target=""_blank"">2107.04910</a>",,2025-12-03 22:39:25
GGT: Graph-Guided Testing for Adversarial Sample Detection of Deep Neural Network,"Zuohui Chen, Renxuan Wang, Jingyang Xiang, Yue Yu, Xin Xia, Shouling Ji, Qi Xuan, Xiaoniu Yang",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.07043"" target=""_blank"">2107.07043</a>",,2025-12-03 22:39:25
Resilience of Autonomous Vehicle Object Category Detection to Universal Adversarial Perturbations,"Mohammad Nayeem Teli, Seungwon Oh",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.04749"" target=""_blank"">2107.04749</a>",,2025-12-03 22:39:25
Universal 3-Dimensional Perturbations for Black-Box Attacks on Video Recognition Systems,"Shangyu Xie, Han Wang, Yu Kong, Yuan Hong",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.04284"" target=""_blank"">2107.04284</a>",,2025-12-03 22:39:25
Towards Robust General Medical Image Segmentation,"Laura Daza, Juan C. Pérez, Pablo Arbeláez",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.04263"" target=""_blank"">2107.04263</a>",,2025-12-03 22:39:25
ARC: Adversarially Robust Control Policies for Autonomous Vehicles,"Sampo Kuutti, Saber Fallah, Richard Bowden",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.04487"" target=""_blank"">2107.04487</a>",,2025-12-03 22:39:25
Improving Model Robustness with Latent Distribution Locally and Globally,"Zhuang Qian, Shufei Zhang, Kaizhu Huang, Qiufeng Wang, Rui Zhang, Xinping Yi",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.04401"" target=""_blank"">2107.04401</a>","<a href=""https://github.com/LitterQ/ATLD-pytorch"" target=""_blank"">LitterQ</a>",2025-12-03 22:39:25
Hack The Box: Fooling Deep Learning Abstraction-Based Monitors,"Sara Hajj Ibrahim, Mohamed Nassar",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.04764"" target=""_blank"">2107.04764</a>",,2025-12-03 22:39:25
Output Randomization: A Novel Defense for both White-box and Black-box Adversarial Models,"Daniel Park, Haidar Khan, Azer Khan, Alex Gittens, Bülent Yener",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.03806"" target=""_blank"">2107.03806</a>",,2025-12-03 22:39:25
Conservative Objective Models for Effective Offline Model-Based Optimization,"Brandon Trabucco, Aviral Kumar, Xinyang Geng, Sergey Levine",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.06882"" target=""_blank"">2107.06882</a>",,2025-12-03 22:39:25
Attack Rules: An Adversarial Approach to Generate Attacks for Industrial Control Systems using Machine Learning,"Muhammad Azmi Umer, Chuadhry Mujeeb Ahmed, Muhammad Taha Jilani, Aditya P. Mathur",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.05127"" target=""_blank"">2107.05127</a>",,2025-12-03 22:39:25
Adversarial for Good? How the Adversarial ML Community's Values Impede Socially Beneficial Uses of Attacks,"Kendra Albert, Maggie Delano, Bogdan Kulynych, Ram Shankar Siva Kumar",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.10302"" target=""_blank"">2107.10302</a>",,2025-12-03 22:39:25
SoftHebb: Bayesian inference in unsupervised Hebbian soft winner-take-all networks,"Timoleon Moraitis, Dmitry Toichkin, Yansong Chua, Qinghai Guo",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.05747"" target=""_blank"">2107.05747</a>",,2025-12-03 22:39:25
Shifts: A Dataset of Real Distributional Shift Across Multiple Large-Scale Tasks,"Andrey Malinin, Neil Band, Ganshin, Alexander, German Chesnokov, Yarin Gal, Mark J. F. Gales, Alexey Noskov, Andrey Ploskonosov, Liudmila Prokhorenkova, Ivan Provilkov, Vatsal Raina, Vyas Raina, Roginskiy, Denis, Mariya Shmatova, Panos Tigas, Boris Yangel",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.07455"" target=""_blank"">2107.07455</a>",,2025-12-03 22:39:25
A Closer Look at the Adversarial Robustness of Information Bottleneck Models,"Iryna Korshunova, David Stutz, Alexander A. Alemi, Olivia Wiles, Sven Gowal",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.05712"" target=""_blank"">2107.05712</a>",,2025-12-03 22:39:25
Putting words into the system's mouth: A targeted attack on neural machine translation using monolingual data poisoning,"Jun Wang, Chang Xu, Francisco Guzman, Ahmed El-Kishky, Yuqing Tang, Benjamin I. P. Rubinstein, Trevor Cohn",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.05243"" target=""_blank"">2107.05243</a>",,2025-12-03 22:39:25
Perceptual-based deep-learning denoiser as a defense against adversarial attacks on ASR systems,"Anirudh Sreeram, Nicholas Mehlman, Raghuveer Peri, Dillon Knox, Shrikanth Narayanan",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.05222"" target=""_blank"">2107.05222</a>",,2025-12-03 22:39:25
Detect and Defense Against Adversarial Examples in Deep Learning using Natural Scene Statistics and Adaptive Denoising,"Anouar Kherchouche, Sid Ahmed Fezza, Wassim Hamidouche",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.05780"" target=""_blank"">2107.05780</a>","<a href=""https://github.com/kherchouche-anouar/2DAE"" target=""_blank"">kherchouche-anouar</a>",2025-12-03 22:39:25
EvoBA: An Evolution Strategy as a Strong Baseline forBlack-Box Adversarial Attacks,"Andrei Ilie, Marius Popescu, Alin Stefanescu",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.05754"" target=""_blank"">2107.05754</a>",,2025-12-03 22:39:25
What classifiers know what they don't? (1%),"Mohamed Ishmael Belghazi, David Lopez-Paz",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.06217"" target=""_blank"">2107.06217</a>",,2025-12-03 22:39:25
Correlation Analysis between the Robustness of Sparse Neural Networks and their Random Hidden Structural Priors,"M. Ben Amor, J. Stier, M. Granitzer",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.06158"" target=""_blank"">2107.06158</a>",,2025-12-03 22:39:25
Using BERT Encoding to Tackle the Mad-lib Attack in SMS Spam Detection,Sergio Rojas-Galeano,arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.06400"" target=""_blank"">2107.06400</a>",,2025-12-03 22:39:25
AID-Purifier: A Light Auxiliary Network for Boosting Adversarial Defense,"Duhun Hwang, Eunjung Lee, Wonjong Rhee",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.06456"" target=""_blank"">2107.06456</a>",,2025-12-03 22:39:25
Understanding the Limits of Unsupervised Domain Adaptation via Data Poisoning,"Akshay Mehra, Bhavya Kailkhura, Pin-Yu Chen, Jihun Hamm",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.03919"" target=""_blank"">2107.03919</a>",,2025-12-03 22:39:25
Analytically Tractable Hidden-States Inference in Bayesian Neural Networks,"Luong-Ha Nguyen, James-A. Goulet",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.03759"" target=""_blank"">2107.03759</a>",,2025-12-03 22:39:25
Confidence Conditioned Knowledge Distillation,"Sourav Mishra, Suresh Sundaram",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.06993"" target=""_blank"">2107.06993</a>",,2025-12-03 22:39:25
Controlled Caption Generation for Images Through Adversarial Attacks,"Nayyer Aafaq, Naveed Akhtar, Wei Liu, Mubarak Shah, Ajmal Mian",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.03050"" target=""_blank"">2107.03050</a>",,2025-12-03 22:39:25
Demiguise Attack: Crafting Invisible Semantic Adversarial Perturbations with Perceptual Similarity,"Yajie Wang, Shangbo Wu, Wenyi Jiang, Shengang Hao, Yu-an Tan, Quanxin Zhang",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.01396"" target=""_blank"">2107.01396</a>",,2025-12-03 22:39:25
EEG-based Cross-Subject Driver Drowsiness Recognition with an Interpretable Convolutional Neural Network,"Jian Cui, Zirui Lan, Olga Sourina, Wolfgang Müller-Wittig",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.09507"" target=""_blank"">2107.09507</a>",,2025-12-03 22:39:25
Immuno-mimetic Deep Neural Networks (Immuno-Net),"Ren Wang, Tianqi Chen, Stephen Lindsly, Cooper Stansbury, Indika Rajapakse, Alfred Hero",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.02842"" target=""_blank"">2107.02842</a>",,2025-12-03 22:39:25
RAILS: A Robust Adversarial Immune-inspired Learning System,"Ren Wang, Tianqi Chen, Stephen Lindsly, Cooper Stansbury, Alnawaz Rehemtulla, Indika Rajapakse, Alfred Hero",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.02840"" target=""_blank"">2107.02840</a>","<a href=""https://github.com/wangren09/RAILS"" target=""_blank"">wangren09</a>",2025-12-03 22:39:25
Bio-Inspired Adversarial Attack Against Deep Neural Networks,"Bowei Xi, Yujie Chen, Fan Fei, Zhan Tu, Xinyan Deng",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.02895"" target=""_blank"">2107.02895</a>",,2025-12-03 22:39:25
Understanding Adversarial Examples Through Deep Neural Network's Response Surface and Uncertainty Regions,"Juan Shu, Bowei Xi, Charles Kamhoua",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.00003"" target=""_blank"">2107.00003</a>",,2025-12-03 22:39:25
Adversarial Machine Learning for Cybersecurity and Computer Vision: Current Developments and Challenges,Bowei Xi,arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.02894"" target=""_blank"">2107.02894</a>",,2025-12-03 22:39:25
Bi-Level Poisoning Attack Model and Countermeasure for Appliance Consumption Data of Smart Homes,"Mustain Billah, Adnan Anwar, Ziaur Rahman, Syed Md. Galib",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.02897"" target=""_blank"">2107.02897</a>",,2025-12-03 22:39:25
Reinforcement Learning for Feedback-Enabled Cyber Resilience,"Yunhan Huang, Linan Huang, Quanyan Zhu",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.00783"" target=""_blank"">2107.00783</a>",,2025-12-03 22:39:25
The Interplay between Distribution Parameters and the Accuracy-Robustness Tradeoff in Classification,"Alireza Mousavi Hosseini, Amir Mohammad Abouei, Mohammad Hossein Rohban",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.00247"" target=""_blank"">2107.00247</a>",,2025-12-03 22:39:25
Adversarial Sample Detection for Speaker Verification by Neural Vocoders,"Haibin Wu, Po-chun Hsu, Ji Gao, Shanshan Zhang, Shen Huang, Jian Kang, Zhiyong Wu, Helen Meng, Hung-yi Lee",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.00309"" target=""_blank"">2107.00309</a>",,2025-12-03 22:39:25
CLINE: Contrastive Learning with Semantic Negative Examples for Natural Language Understanding,"Dong Wang, Ning Ding, Piji Li, Hai-Tao Zheng",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.00440"" target=""_blank"">2107.00440</a>",,2025-12-03 22:39:25
DVS-Attacks: Adversarial Attacks on Dynamic Vision Sensors for Spiking Neural Networks,"Alberto Marchisio, Giacomo Pira, Maurizio Martina, Guido Masera, Muhammad Shafique",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.00415"" target=""_blank"">2107.00415</a>","<a href=""https://github.com/albertomarchisio/DVS-Attacks"" target=""_blank"">albertomarchisio</a>",2025-12-03 22:39:25
"Using Anomaly Feature Vectors for Detecting, Classifying and Warning of Outlier Adversarial Examples","Nelson Manohar-Alers, Ryan Feng, Sahib Singh, Jiguo Song, Atul Prakash",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.00561"" target=""_blank"">2107.00561</a>",,2025-12-03 22:39:25
Mirror Mirror on the Wall: Next-Generation Wireless Jamming Attacks Based on Software-Controlled Surfaces,"Paul Staat, Harald Elders-Boll, Christian Zenger, Christof Paar",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.01709"" target=""_blank"">2107.01709</a>",,2025-12-03 22:39:25
Incorporating Label Uncertainty in Understanding Adversarial Robustness,"Xiao Zhang, David Evans",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.03250"" target=""_blank"">2107.03250</a>",,2025-12-03 22:39:25
Certifiably Robust Interpretation via Renyi Differential Privacy,"Ao Liu, Xiaoyu Chen, Sijia Liu, Lirong Xia, Chuang Gan",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.01561"" target=""_blank"">2107.01561</a>",,2025-12-03 22:39:25
Poisoning Attack against Estimating from Pairwise Comparisons,"Ke Ma, Qianqian Xu, Jinshan Zeng, Xiaochun Cao, Qingming Huang",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.01854"" target=""_blank"">2107.01854</a>",,2025-12-03 22:39:25
"Evaluating the Cybersecurity Risk of Real World, Machine Learning Production Systems","Ron Bitton, Nadav Maman, Inderjeet Singh, Satoru Momiyama, Yuval Elovici, Asaf Shabtai",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.01806"" target=""_blank"">2107.01806</a>",,2025-12-03 22:39:25
Understanding the Security of Deepfake Detection,"Xiaoyu Cao, Neil Zhenqiang Gong",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.02045"" target=""_blank"">2107.02045</a>",,2025-12-03 22:39:25
Dealing with Adversarial Player Strategies in the Neural Network Game iNNk through Ensemble Learning,"Mathias Löwe, Jennifer Villareale, Evan Freed, Aleksanteri Sladek, Jichen Zhu, Sebastian Risi",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.02052"" target=""_blank"">2107.02052</a>",,2025-12-03 22:39:25
Adversarial Robustness of Probabilistic Network Embedding for Link Prediction,"Xi Chen, Bo Kang, Jefrey Lijffijt, Bie Tijl De",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.01936"" target=""_blank"">2107.01936</a>",,2025-12-03 22:39:25
Boosting Transferability of Targeted Adversarial Examples via Hierarchical Generative Networks,"Xiao Yang, Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.01809"" target=""_blank"">2107.01809</a>",,2025-12-03 22:39:25
When and How to Fool Explainable Models (and Humans) with Adversarial Examples,"Jon Vadillo, Roberto Santana, Jose A. Lozano",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.01943"" target=""_blank"">2107.01943</a>",,2025-12-03 22:39:25
On Robustness of Lane Detection Models to Physical-World Adversarial Attacks in Autonomous Driving,"Takami Sato, Qi Alfred Chen",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.02488"" target=""_blank"">2107.02488</a>",,2025-12-03 22:39:25
On Generalization of Graph Autoencoders with Adversarial Training,"Tianjin huang, Yulong Pei, Vlado Menkovski, Mykola Pechenizkiy",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.02658"" target=""_blank"">2107.02658</a>",,2025-12-03 22:39:25
Self-Adversarial Training incorporating Forgery Attention for Image Forgery Localization,"Long Zhuo, Shunquan Tan, Bin Li, Jiwu Huang",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.02434"" target=""_blank"">2107.02434</a>",,2025-12-03 22:39:25
GradDiv: Adversarial Robustness of Randomized Neural Networks via Gradient Diversity Regularization,"Sungyoon Lee, Hoki Kim, Jaewook Lee",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.02425"" target=""_blank"">2107.02425</a>",,2025-12-03 22:39:25
RoFL: Attestable Robustness for Secure Federated Learning,"Lukas Burkhalter, Hidde Lycklama, Alexander Viand, Nicolas Küchler, Anwar Hithnawi",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.03311"" target=""_blank"">2107.03311</a>",,2025-12-03 22:39:25
AdvFilter: Predictive Perturbation-aware Filtering against Adversarial Attack via Multi-domain Learning,"Yihao Huang, Qing Guo, Felix Juefei-Xu, Lei Ma, Weikai Miao, Yang Liu, Geguang Pu",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.06501"" target=""_blank"">2107.06501</a>",,2025-12-03 22:39:25
Stateful Detection of Model Extraction Attacks,"Soham Pal, Yash Gupta, Aditya Kanade, Shirish Shevade",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.05166"" target=""_blank"">2107.05166</a>",,2025-12-03 22:39:25
Tailor: Generating and Perturbing Text with Semantic Controls,"Alexis Ross, Tongshuang Wu, Hao Peng, Matthew E. Peters, Matt Gardner",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.07150"" target=""_blank"">2107.07150</a>",,2025-12-03 22:39:25
Membership Inference Attack and Defense for Wireless Signal Classifiers with Deep Learning,"Yi Shi, Yalin E. Sagduyu",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.12173"" target=""_blank"">2107.12173</a>",,2025-12-03 22:39:25
On the Certified Robustness for Ensemble Models and Beyond,"Zhuolin Yang, Linyi Li, Xiaojun Xu, Bhavya Kailkhura, Tao Xie, Bo Li",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.10873"" target=""_blank"">2107.10873</a>",,2025-12-03 22:39:25
Clipped Hyperbolic Classifiers Are Super-Hyperbolic Classifiers,"Yunhui Guo, Xudong Wang, Yubei Chen, Stella X. Yu",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.11472"" target=""_blank"">2107.11472</a>",,2025-12-03 22:39:25
Adversarial Reinforced Instruction Attacker for Robust Vision-Language Navigation,"Bingqian Lin, Yi Zhu, Yanxin Long, Xiaodan Liang, Qixiang Ye, Liang Lin",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.11252"" target=""_blank"">2107.11252</a>","<a href=""https://github.com/expectorlin/DR-Attacker"" target=""_blank"">expectorlin</a>",2025-12-03 22:39:25
Structack: Structure-based Adversarial Attacks on Graph Neural Networks,"Hussain Hussain, Tomislav Duricic, Elisabeth Lex, Denis Helic, Markus Strohmaier, Roman Kern",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.11327"" target=""_blank"">2107.11327</a>",,2025-12-03 22:39:25
A Differentiable Language Model Adversarial Attack on Text Classifiers,"Ivan Fursov, Alexey Zaytsev, Pavel Burnyshev, Ekaterina Dmitrieva, Nikita Klyuchnikov, Andrey Kravchenko, Ekaterina Artemova, Evgeny Burnaev",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.11275"" target=""_blank"">2107.11275</a>",,2025-12-03 22:39:25
X-GGM: Graph Generative Modeling for Out-of-Distribution Generalization in Visual Question Answering,"Jingjing Jiang, Ziyi Liu, Yifan Liu, Zhixiong Nan, Nanning Zheng",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.11576"" target=""_blank"">2107.11576</a>","<a href=""https://github.com/jingjing12110/x-ggm"" target=""_blank"">jingjing12110</a>",2025-12-03 22:39:25
Stress Test Evaluation of Biomedical Word Embeddings,"Vladimir Araujo, Andrés Carvallo, Carlos Aspillaga, Camilo Thorne, Denis Parra",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.11652"" target=""_blank"">2107.11652</a>",,2025-12-03 22:39:25
Detecting Adversarial Examples Is (Nearly) As Hard As Classifying Them,Florian Tramèr,arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.11630"" target=""_blank"">2107.11630</a>",,2025-12-03 22:39:25
Adversarial training may be a double-edged sword,"Ali Rahmati, Seyed-Mohsen Moosavi-Dezfooli, Huaiyu Dai",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.11671"" target=""_blank"">2107.11671</a>",,2025-12-03 22:39:25
Adversarial Attacks with Time-Scale Representations,"Alberto Santamaria-Pang, Jianwei Qiu, Aritra Chowdhury, James Kubricht, Peter Tu, Iyer Naresh, Nurali Virani",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.12473"" target=""_blank"">2107.12473</a>",,2025-12-03 22:39:25
Learning to Adversarially Blur Visual Object Tracking,"Qing Guo, Ziyi Cheng, Felix Juefei-Xu, Lei Ma, Xiaofei Xie, Yang Liu, Jianjun Zhao",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.12085"" target=""_blank"">2107.12085</a>","<a href=""https://github.com/tsingqguo/ABA"" target=""_blank"">tsingqguo</a>",2025-12-03 22:39:25
Benign Adversarial Attack: Tricking Models for Goodness,"Jitao Sang, Xian Zhao, Jiaming Zhang, Zhiyu Lin",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.11986"" target=""_blank"">2107.11986</a>",,2025-12-03 22:39:25
"PDF-Malware: An Overview on Threats, Detection and Evasion Attacks","Nicolas Fleury, Theo Dubrunquez, Ihsen Alouani",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.12873"" target=""_blank"">2107.12873</a>",,2025-12-03 22:39:25
Poisoning Online Learning Filters: DDoS Attacks and Countermeasures,"Wesley Joon-Wie Tann, Ee-Chien Chang",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.12612"" target=""_blank"">2107.12612</a>",,2025-12-03 22:39:25
Towards Black-box Attacks on Deep Learning Apps,"Hongchen Cao, Shuai Li, Yuming Zhou, Ming Fan, Xuejiao Zhao, Yutian Tang",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.12732"" target=""_blank"">2107.12732</a>",,2025-12-03 22:39:25
TableGAN-MCA: Evaluating Membership Collisions of GAN-Synthesized Tabular Data Releasing,"Aoting Hu, Renjie Xie, Zhigang Lu, Aiqun Hu, Minhui Xue",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.13190"" target=""_blank"">2107.13190</a>",,2025-12-03 22:39:25
WaveCNet: Wavelet Integrated CNNs to Suppress Aliasing Effect for Noise-Robust Image Classification,"Qiufu Li, Linlin Shen, Sheng Guo, Zhihui Lai",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.13335"" target=""_blank"">2107.13335</a>","<a href=""https://github.com/CVI-SZU/WaveCNet"" target=""_blank"">CVI-SZU</a>",2025-12-03 22:39:25
Models of Computational Profiles to Study the Likelihood of DNN Metamorphic Test Cases,"Ettore Merlo, Mira Marhaba, Foutse Khomh, Houssem Ben Braiek, Giuliano Antoniol",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.13491"" target=""_blank"">2107.13491</a>",,2025-12-03 22:39:25
Towards Robustness Against Natural Language Word Substitutions,"Xinshuai Dong, Anh Tuan Luu, Rongrong Ji, Hong Liu",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.13541"" target=""_blank"">2107.13541</a>",,2025-12-03 22:39:25
Towards robust vision by multi-task learning on monkey visual cortex,"Shahd Safarani, Arne Nix, Konstantin Willeke, Santiago A. Cadena, Kelli Restivo, George Denfield, Andreas S. Tolias, Fabian H. Sinz",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.14344"" target=""_blank"">2107.14344</a>",,2025-12-03 22:39:25
Understanding the Effects of Adversarial Personalized Ranking Optimization Method on Recommendation Quality,"Vito Walter Anelli, Yashar Deldjoo, Noia Tommaso Di, Felice Antonio Merra",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.13876"" target=""_blank"">2107.13876</a>",,2025-12-03 22:39:25
Who's Afraid of Thomas Bayes? (92%),Erick Galinkin,arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.14601"" target=""_blank"">2107.14601</a>",,2025-12-03 22:39:25
The Robustness of Graph k-shell Structure under Adversarial Attacks,"B. Zhou, Y. Q. Lv, Y. C. Mao, J. H. Wang, S. Q. Yu, Q. Xuan",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.13962"" target=""_blank"">2107.13962</a>",,2025-12-03 22:39:25
Enhancing Adversarial Robustness via Test-time Transformation Ensembling,"Juan C. Pérez, Motasem Alfarra, Guillaume Jeanneret, Laura Rueda, Ali Thabet, Bernard Ghanem, Pablo Arbeláez",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.14110"" target=""_blank"">2107.14110</a>",,2025-12-03 22:39:25
Feature Importance-aware Transferable Adversarial Attacks,"Zhibo Wang, Hengchang Guo, Zhifei Zhang, Wenxin Liu, Zhan Qin, Kui Ren",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.14185"" target=""_blank"">2107.14185</a>","<a href=""https://github.com/hcguoO0/FIA"" target=""_blank"">hcguoO0</a>",2025-12-03 22:39:25
Unveiling the potential of Graph Neural Networks for robust Intrusion Detection,"David Pujol-Perich, José Suárez-Varela, Albert Cabellos-Aparicio, Pere Barlet-Ros",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.14756"" target=""_blank"">2107.14756</a>",,2025-12-03 22:39:25
Subnet Replacement: Deployment-stage backdoor attack against deep neural networks in gray-box setting,"Xiangyu Qi, Jifeng Zhu, Chulin Xie, Yong Yang",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.07240"" target=""_blank"">2107.07240</a>",,2025-12-03 22:39:25
Can You Hear It? Backdoor Attacks via Ultrasonic Triggers,"Stefanos Koffas, Jing Xu, Mauro Conti, Stjepan Picek",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.14569"" target=""_blank"">2107.14569</a>",,2025-12-03 22:39:25
Practical Attacks on Voice Spoofing Countermeasures,"Andre Kassis, Urs Hengartner",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.14642"" target=""_blank"">2107.14642</a>",,2025-12-03 22:39:25
Unsupervised Detection of Adversarial Examples with Model Explanations,"Gihyuk Ko, Gyumin Lim",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.10480"" target=""_blank"">2107.10480</a>",,2025-12-03 22:39:25
Imbalanced Adversarial Training with Reweighting,"Wentao Wang, Han Xu, Xiaorui Liu, Yaxin Li, Bhavani Thuraisingham, Jiliang Tang",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.13639"" target=""_blank"">2107.13639</a>",,2025-12-03 22:39:25
Towards Explaining Adversarial Examples Phenomenon in Artificial Neural Networks,"Ramin Barati, Reza Safabakhsh, Mohammad Rahmati",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.10599"" target=""_blank"">2107.10599</a>",,2025-12-03 22:39:25
Examining the Human Perceptibility of Black-Box Adversarial Attacks on Face Recognition,"Benjamin Spetter-Goldstein, Nataniel Ruiz, Sarah Adel Bargal",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.09126"" target=""_blank"">2107.09126</a>",,2025-12-03 22:39:25
Estimating Predictive Uncertainty Under Program Data Distribution Shift,"Yufei Li, Simin Chen, Wei Yang",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.10989"" target=""_blank"">2107.10989</a>",,2025-12-03 22:39:25
Self-Supervised Contrastive Learning with Adversarial Perturbations for Defending Word Substitution-based Attacks,"Zhao Meng, Yihan Dong, Mrinmaya Sachan, Roger Wattenhofer",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.07610"" target=""_blank"">2107.07610</a>",,2025-12-03 22:39:25
"Proceedings of ICML 2021 Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI","Quanshi Zhang, Tian Han, Lixin Fan, Zhanxing Zhu, Hang Su, Ying Nian Wu, Jie Ren, Hao Zhang",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.08821"" target=""_blank"">2107.08821</a>",,2025-12-03 22:39:25
EGC2: Enhanced Graph Classification with Easy Graph Compression,"Jinyin Chen, Haiyang Xiong, Haibin Zhenga, Dunjie Zhang, Jian Zhang, Mingwei Jia, Yi Liu",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.07737"" target=""_blank"">2107.07737</a>",,2025-12-03 22:39:25
Adversarial Attacks on Multi-task Visual Perception for Autonomous Driving,"Ibrahim Sobh, Ahmed Hamed, Varun Ravi Kumar, Senthil Yogamani",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.07449"" target=""_blank"">2107.07449</a>",,2025-12-03 22:39:25
BEDS-Bench: Behavior of EHR-models under Distributional Shift--A Benchmark,"Anand Avati, Martin Seneviratne, Emily Xue, Zhen Xu, Balaji Lakshminarayanan, Andrew M. Dai",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.08189"" target=""_blank"">2107.08189</a>",,2025-12-03 22:39:25
Adversarial Attack for Uncertainty Estimation: Identifying Critical Regions in Neural Networks,"Ismail Alarab, Simant Prakoonwit",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.07618"" target=""_blank"">2107.07618</a>",,2025-12-03 22:39:25
RobustFed: A Truth Inference Approach for Robust Federated Learning,"Farnaz Tahmasebian, Jian Lou, Li Xiong",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.08402"" target=""_blank"">2107.08402</a>",,2025-12-03 22:39:25
Just Train Twice: Improving Group Robustness without Training Group Information,"Evan Zheran Liu, Behzad Haghgoo, Annie S. Chen, Aditi Raghunathan, Pang Wei Koh, Shiori Sagawa, Percy Liang, Chelsea Finn",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.09044"" target=""_blank"">2107.09044</a>",,2025-12-03 22:39:25
Improving Interpretability of Deep Neural Networks in Medical Diagnosis by Investigating the Individual Units,"Woo-Jeoung Nam, Seong-Whan Lee",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.08767"" target=""_blank"">2107.08767</a>",,2025-12-03 22:39:25
ECG-Adv-GAN: Detecting ECG Adversarial Examples with Conditional Generative Adversarial Networks,"Khondker Fariha Hossain, Sharif Amit Kamran, Alireza Tavakkoli, Lei Pan, Xingjun Ma, Sutharshan Rajasegarar, Chandan Karmaker",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.07677"" target=""_blank"">2107.07677</a>",,2025-12-03 22:39:25
MEGEX: Data-Free Model Extraction Attack against Gradient-Based Explainable AI,"Takayuki Miura, Satoshi Hasegawa, Toshiki Shibahara",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.08909"" target=""_blank"">2107.08909</a>",,2025-12-03 22:39:25
"On the Veracity of Local, Model-agnostic Explanations in Audio Classification: Targeted Investigations with Adversarial Examples","Verena Praher, Katharina Prinz, Arthur Flexer, Gerhard Widmer",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.09045"" target=""_blank"">2107.09045</a>",,2025-12-03 22:39:25
Structural Watermarking to Deep Neural Networks via Network Channel Pruning,"Xiangyu Zhao, Yinzhe Yao, Hanzhou Wu, Xinpeng Zhang",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.08688"" target=""_blank"">2107.08688</a>",,2025-12-03 22:39:25
Feature-Filter: Detecting Adversarial Examples through Filtering off Recessive Features,"Hui Liu, Bo Zhao, Yuefeng Peng, Jiabao Guo, Peng Liu",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.09502"" target=""_blank"">2107.09502</a>",,2025-12-03 22:39:25
A Tandem Framework Balancing Privacy and Security for Voice User Interfaces,"Ranya Aloufi, Hamed Haddadi, David Boyle",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.10045"" target=""_blank"">2107.10045</a>",,2025-12-03 22:39:25
Ready for Emerging Threats to Recommender Systems? A Graph Convolution-based Generative Shilling Attack,"Fan Wu, Min Gao, Junliang Yu, Zongwei Wang, Kecheng Liu, Xu Wange",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.10457"" target=""_blank"">2107.10457</a>",,2025-12-03 22:39:25
Fast and Scalable Adversarial Training of Kernel SVM via Doubly Stochastic Gradients,"Huimin Wu, Zhengmian Hu, Bin Gu",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.09937"" target=""_blank"">2107.09937</a>",,2025-12-03 22:39:25
Improved Text Classification via Contrastive Adversarial Training,"Lin Pan, Chung-Wei Hang, Avirup Sil, Saloni Potdar",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.10137"" target=""_blank"">2107.10137</a>",,2025-12-03 22:39:25
Black-box Probe for Unsupervised Domain Adaptation without Model Transferring,"Kunhong Wu, Yucheng Shi, Yahong Han, Yunfeng Shao, Bingshuai Li",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.10174"" target=""_blank"">2107.10174</a>",,2025-12-03 22:39:25
Defending against Reconstruction Attack in Vertical Federated Learning,"Jiankai Sun, Yuanshun Yao, Weihao Gao, Junyuan Xie, Chong Wang",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.09898"" target=""_blank"">2107.09898</a>",,2025-12-03 22:39:25
Discriminator-Free Generative Adversarial Attack,"Shaohao Lu, Yuqiao Xian, Ke Yan, Yi Hu, Xing Sun, Xiaowei Guo, Feiyue Huang, Wei-Shi Zheng",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.09225"" target=""_blank"">2107.09225</a>","<a href=""https://github.com/BravoLu/SSAE"" target=""_blank"">BravoLu</a>",2025-12-03 22:39:25
"Generative Models for Security: Attacks, Defenses, and Opportunities","Luke A. Bauer, Vincent Bindschaedler",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.10139"" target=""_blank"">2107.10139</a>",,2025-12-03 22:39:25
Spinning Sequence-to-Sequence Models with Meta-Backdoors,"Eugene Bagdasaryan, Vitaly Shmatikov",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.10443"" target=""_blank"">2107.10443</a>",,2025-12-03 22:39:25
On the Convergence of Prior-Guided Zeroth-Order Optimization Algorithms,"Shuyu Cheng, Guoqiang Wu, Jun Zhu",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.10110"" target=""_blank"">2107.10110</a>",,2025-12-03 22:39:25
Using Undervolting as an On-Device Defense Against Adversarial Machine Learning Attacks,"Saikat Majumdar, Mohammad Hossein Samavatian, Kristin Barber, Radu Teodorescu",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.09804"" target=""_blank"">2107.09804</a>",,2025-12-03 22:39:25
A Markov Game Model for AI-based Cyber Security Attack Mitigation,"Hooman Alavizadeh, Julian Jang-Jaccard, Tansu Alpcan, Seyit A. Camtepe",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.09258"" target=""_blank"">2107.09258</a>",,2025-12-03 22:39:25
Leaking Secrets through Modern Branch Predictor in the Speculative World,"Md Hafizul Islam Chowdhuryy, Fan Yao",arXiv,2021-07,"<a href=""http://arxiv.org/abs/2107.09833"" target=""_blank"">2107.09833</a>",,2025-12-03 22:39:25
Adversarial purification with Score-based generative models,"Jongmin Yoon, Sung Ju Hwang, Juho Lee",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.06041"" target=""_blank"">2106.06041</a>",,2025-12-03 22:39:25
Relaxing Local Robustness,"Klas Leino, Matt Fredrikson",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.06624"" target=""_blank"">2106.06624</a>",,2025-12-03 22:39:25
TDGIA:Effective Injection Attacks on Graph Neural Networks,"Xu Zou, Qinkai Zheng, Yuxiao Dong, Xinyu Guan, Evgeny Kharlamov, Jialiang Lu, Jie Tang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.06663"" target=""_blank"">2106.06663</a>",,2025-12-03 22:39:25
Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution,"Fanchao Qi, Yuan Yao, Sophia Xu, Zhiyuan Liu, Maosong Sun",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.06361"" target=""_blank"">2106.06361</a>","<a href=""https://github.com/thunlp/BkdAtk-LWS"" target=""_blank"">thunlp</a>",2025-12-03 22:39:25
CARTL: Cooperative Adversarially-Robust Transfer Learning,"Dian Chen, Hongxin Hu, Qian Wang, Yinli Li, Cong Wang, Chao Shen, Qi Li",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.06667"" target=""_blank"">2106.06667</a>",,2025-12-03 22:39:25
A Shuffling Framework for Local Differential Privacy,"Casey Meehan, Amrita Roy Chowdhury, Kamalika Chaudhuri, Somesh Jha",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.06603"" target=""_blank"">2106.06603</a>",,2025-12-03 22:39:25
Deep neural network loses attention to adversarial images,"Shashank Kotyan, Danilo Vasconcellos Vargas",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.05657"" target=""_blank"">2106.05657</a>",,2025-12-03 22:39:25
Sparse and Imperceptible Adversarial Attack via a Homotopy Algorithm,"Mingkang Zhu, Tianlong Chen, Zhangyang Wang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.06027"" target=""_blank"">2106.06027</a>","<a href=""https://github.com/VITA-Group/SparseADV_Homotopy"" target=""_blank"">VITA-Group</a>",2025-12-03 22:39:25
Improving White-box Robustness of Pre-processing Defenses via Joint Adversarial Training,"Dawei Zhou, Nannan Wang, Xinbo Gao, Bo Han, Jun Yu, Xiaoyu Wang, Tongliang Liu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.05453"" target=""_blank"">2106.05453</a>",,2025-12-03 22:39:25
Verifying Quantized Neural Networks using SMT-Based Model Checking,"Luiz Sena, Xidan Song, Erickson Alves, Iury Bessa, Edoardo Manino, Lucas Cordeiro, Eddie de Lima Filho",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.05997"" target=""_blank"">2106.05997</a>",,2025-12-03 22:39:25
Progressive-Scale Boundary Blackbox Attack via Projective Gradient Estimation,"Jiawei Zhang, Linyi Li, Huichen Li, Xiaolu Zhang, Shuang Yang, Bo Li",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.06056"" target=""_blank"">2106.06056</a>","<a href=""https://github.com/AI-secure/PSBA"" target=""_blank"">AI-secure</a>",2025-12-03 22:39:25
An Ensemble Approach Towards Adversarial Robustness,Haifeng Qian,arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.05996"" target=""_blank"">2106.05996</a>",,2025-12-03 22:39:25
Towards an Automated Pipeline for Detecting and Classifying Malware through Machine Learning,"Nicola Loi, Claudio Borile, Daniele Ucci",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.05625"" target=""_blank"">2106.05625</a>",,2025-12-03 22:39:25
Fair Classification with Adversarial Perturbations,"L. Elisa Celis, Anay Mehrotra, Nisheeth K. Vishnoi",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.05964"" target=""_blank"">2106.05964</a>",,2025-12-03 22:39:25
"HASI: Hardware-Accelerated Stochastic Inference, A Defense Against Adversarial Machine Learning Attacks","Mohammad Hossein Samavatian, Saikat Majumdar, Kristin Barber, Radu Teodorescu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.05825"" target=""_blank"">2106.05825</a>",,2025-12-03 22:39:25
Towards Defending against Adversarial Examples via Attack-Invariant Features,"Dawei Zhou, Tongliang Liu, Bo Han, Nannan Wang, Chunlei Peng, Xinbo Gao",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.05036"" target=""_blank"">2106.05036</a>",,2025-12-03 22:39:25
Attacking Adversarial Attacks as A Defense,"Boxi Wu, Heng Pan, Li Shen, Jindong Gu, Shuai Zhao, Zhifeng Li, Deng Cai, Xiaofei He, Wei Liu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.04938"" target=""_blank"">2106.04938</a>",,2025-12-03 22:39:25
We Can Always Catch You: Detecting Adversarial Patched Objects WITH or WITHOUT Signature,"Bin Liang, Jiachun Li, Jianjun Huang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.05261"" target=""_blank"">2106.05261</a>",,2025-12-03 22:39:25
Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL,"Yanchao Sun, Ruijie Zheng, Yongyuan Liang, Furong Huang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.05087"" target=""_blank"">2106.05087</a>",,2025-12-03 22:39:25
Knowledge Enhanced Machine Learning Pipeline against Diverse Adversarial Attacks,"Nezihe Merve Gürel, Xiangyu Qi, Luka Rimanic, Ce Zhang, Bo Li",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.06235"" target=""_blank"">2106.06235</a>",,2025-12-03 22:39:25
Resilient Control of Platooning Networked Robitic Systems via Dynamic Watermarking,"Matthew Porter, Arnav Joshi, Sidhartha Dey, Qirui Wu, Pedro Hespanhol, Anil Aswani, Matthew Johnson-Roberson, Ram Vasudevan",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07541"" target=""_blank"">2106.07541</a>",,2025-12-03 22:39:25
CausalAdv: Adversarial Robustness through the Lens of Causality,"Yonggang Zhang, Mingming Gong, Tongliang Liu, Gang Niu, Xinmei Tian, Bo Han, Bernhard Schölkopf, Kun Zhang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.06196"" target=""_blank"">2106.06196</a>",,2025-12-03 22:39:25
FeSHI: Feature Map Based Stealthy Hardware Intrinsic Attack,"Tolulope Odetola, Faiq Khalid, Travis Sandefur, Hawzhin Mohammed, Syed Rafay Hasan",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.06895"" target=""_blank"">2106.06895</a>",,2025-12-03 22:39:25
ZoPE: A Fast Optimizer for ReLU Networks with Low-Dimensional Inputs,"Christopher A. Strong, Sydney M. Katz, Anthony L. Corso, Mykel J. Kochenderfer",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.05325"" target=""_blank"">2106.05325</a>",,2025-12-03 22:39:25
PopSkipJump: Decision-Based Attack for Probabilistic Classifiers,"Carl-Johann Simon-Gabriel, Noman Ahmed Sheikh, Andreas Krause",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07445"" target=""_blank"">2106.07445</a>","<a href=""https://github.com/cjsg/PopSkipJump"" target=""_blank"">cjsg</a>",2025-12-03 22:39:25
"Now You See It, Now You Dont: Adversarial Vulnerabilities in Computational Pathology","Alex Foote, Amina Asif, Ayesha Azam, Tim Marshall-Cox, Nasir Rajpoot, Fayyaz Minhas",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.08153"" target=""_blank"">2106.08153</a>",,2025-12-03 22:39:25
Audio Attacks and Defenses against AED Systems -- A Practical Study,"Rodrigo dos Santos, Shirin Nilizadeh",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07428"" target=""_blank"">2106.07428</a>",,2025-12-03 22:39:25
Backdoor Learning Curves: Explaining Backdoor Poisoning Beyond Influence Functions,"Antonio Emanuele Cinà, Kathrin Grosse, Sebastiano Vascon, Ambra Demontis, Battista Biggio, Fabio Roli, Marcello Pelillo",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07214"" target=""_blank"">2106.07214</a>",,2025-12-03 22:39:25
Evading Malware Classifiers via Monte Carlo Mutant Feature Discovery,"John Boutsikas, Maksim E. Eren, Charles Varga, Edward Raff, Cynthia Matuszek, Charles Nicholas",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07860"" target=""_blank"">2106.07860</a>",,2025-12-03 22:39:25
On the Relationship between Heterophily and Robustness of Graph Neural Networks,"Jiong Zhu, Junchen Jin, Donald Loveland, Michael T. Schaub, Danai Koutra",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07767"" target=""_blank"">2106.07767</a>",,2025-12-03 22:39:25
Partial success in closing the gap between human and machine vision,"Robert Geirhos, Kantharaju Narayanappa, Benjamin Mitzkus, Tizian Thieringer, Matthias Bethge, Felix A. Wichmann, Wieland Brendel",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07411"" target=""_blank"">2106.07411</a>","<a href=""https://github.com/bethgelab/model-vs-human/"" target=""_blank"">model-vs-human</a>",2025-12-03 22:39:25
Text Generation with Efficient (Soft) Q-Learning,"Han Guo, Bowen Tan, Zhengzhong Liu, Eric P. Xing, Zhiting Hu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07704"" target=""_blank"">2106.07704</a>",,2025-12-03 22:39:25
Self-training Guided Adversarial Domain Adaptation For Thermal Imagery,"Ibrahim Batuhan Akkaya, Fazil Altinel, Ugur Halici",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07165"" target=""_blank"">2106.07165</a>",,2025-12-03 22:39:25
Code Integrity Attestation for PLCs using Black Box Neural Network Predictions,"Yuqi Chen, Christopher M. Poskitt, Jun Sun",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07851"" target=""_blank"">2106.07851</a>",,2025-12-03 22:39:25
Target Model Agnostic Adversarial Attacks with Query Budgets on Language Understanding Models,"Jatin Chauhan, Karan Bhukar, Manohar Kaul",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07047"" target=""_blank"">2106.07047</a>",,2025-12-03 22:39:25
Selection of Source Images Heavily Influences the Effectiveness of Adversarial Attacks,"Utku Ozbulak, Esla Timothy Anzaku, Neve Wesley De, Messem Arnout Van",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07141"" target=""_blank"">2106.07141</a>",,2025-12-03 22:39:25
ATRAS: Adversarially Trained Robust Architecture Search,"Yigit Alparslan, Edward Kim",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.06917"" target=""_blank"">2106.06917</a>",,2025-12-03 22:39:25
Security Analysis of Camera-LiDAR Semantic-Level Fusion Against Black-Box Attacks on Autonomous Vehicles,"R. Spencer Hallyburton, Yupei Liu, Miroslav Pajic",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07098"" target=""_blank"">2106.07098</a>",,2025-12-03 22:39:25
Weakly-supervised High-resolution Segmentation of Mammography Images for Breast Cancer Diagnosis,"Kangning Liu, Yiqiu Shen, Nan Wu, Jakub Chłędowski, Carlos Fernandez-Granda, Krzysztof J. Geras",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07049"" target=""_blank"">2106.07049</a>","<a href=""https://github.com/nyukat/GLAM"" target=""_blank"">nyukat</a>",2025-12-03 22:39:25
HistoTransfer: Understanding Transfer Learning for Histopathology,"Yash Sharma, Lubaina Ehsan, Sana Syed, Donald E. Brown",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07068"" target=""_blank"">2106.07068</a>",,2025-12-03 22:39:25
Adversarial Robustness via Fisher-Rao Regularization,"Marine Picot, Francisco Messina, Malik Boudiaf, Fabrice Labeau, Ismail Ben Ayed, Pablo Piantanida",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.06685"" target=""_blank"">2106.06685</a>",,2025-12-03 22:39:25
What can linearized neural networks actually say about generalization? (31%),"Guillermo Ortiz-Jiménez, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.06770"" target=""_blank"">2106.06770</a>",,2025-12-03 22:39:25
URLTran: Improving Phishing URL Detection Using Transformers,"Pranav Maneriker, Jack W. Stokes, Edir Garcia Lazo, Diana Carutasu, Farid Tajaddodianfar, Arun Gururajan",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.05256"" target=""_blank"">2106.05256</a>",,2025-12-03 22:39:25
Transferable Adversarial Examples for Anchor Free Object Detection,"Quanyu Liao, Xin Wang, Bin Kong, Siwei Lyu, Bin Zhu, Youbing Yin, Qi Song, Xi Wu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.01618"" target=""_blank"">2106.01618</a>",,2025-12-03 22:39:25
Practical Machine Learning Safety: A Survey and Primer,"Sina Mohseni, Haotao Wang, Zhiding Yu, Chaowei Xiao, Zhangyang Wang, Jay Yadawa",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.04823"" target=""_blank"">2106.04823</a>",,2025-12-03 22:39:25
PDPGD: Primal-Dual Proximal Gradient Descent Adversarial Attack,"Alexander Matyasko, Lap-Pui Chau",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.01538"" target=""_blank"">2106.01538</a>",,2025-12-03 22:39:25
Teaching keyword spotters to spot new keywords with limited examples,"Abhijeet Awasthi, Kevin Kilgour, Hassan Rom",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.02443"" target=""_blank"">2106.02443</a>",,2025-12-03 22:39:25
Improving the Transferability of Adversarial Examples with New Iteration Framework and Input Dropout,"Pengfei Xie, Linyuan Wang, Ruoxi Qin, Kai Qiao, Shuhao Shi, Guoen Hu, Bin Yan",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.01617"" target=""_blank"">2106.01617</a>",,2025-12-03 22:39:25
Imperceptible Adversarial Examples for Fake Image Detection,"Quanyu Liao, Yuezun Li, Xin Wang, Bin Kong, Bin Zhu, Siwei Lyu, Youbing Yin, Qi Song, Xi Wu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.01615"" target=""_blank"">2106.01615</a>",,2025-12-03 22:39:25
Probabilistic Margins for Instance Reweighting in Adversarial Training,"Qizhou Wang, Feng Liu, Bo Han, Tongliang Liu, Chen Gong, Gang Niu, Mingyuan Zhou, Masashi Sugiyama",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07904"" target=""_blank"">2106.07904</a>",,2025-12-03 22:39:25
Exploring Memorization in Adversarial Training,"Yinpeng Dong, Ke Xu, Xiao Yang, Tianyu Pang, Zhijie Deng, Hang Su, Jun Zhu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.01606"" target=""_blank"">2106.01606</a>",,2025-12-03 22:39:25
Improving Neural Network Robustness via Persistency of Excitation,"Kaustubh Sridhar, Oleg Sokolsky, Insup Lee, James Weimer",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.02078"" target=""_blank"">2106.02078</a>",,2025-12-03 22:39:25
Defending against Backdoor Attacks in Natural Language Generation,"Chun Fan, Xiaoya Li, Yuxian Meng, Xiaofei Sun, Xiang Ao, Fei Wu, Jiwei Li, Tianwei Zhang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.01810"" target=""_blank"">2106.01810</a>","<a href=""https://github.com/ShannonAI/backdoor_nlg"" target=""_blank"">ShannonAI</a>",2025-12-03 22:39:25
Sneak Attack against Mobile Robotic Networks under Formation Control,"Yushan Li, Jianping He, Xuda Ding, Lin Cai, Xinping Guan",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.02240"" target=""_blank"">2106.02240</a>",,2025-12-03 22:39:25
Towards Robustness of Text-to-SQL Models against Synonym Substitution,"Yujian Gan, Xinyun Chen, Qiuping Huang, Matthew Purver, John R. Woodward, Jinxia Xie, Pengsheng Huang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.01065"" target=""_blank"">2106.01065</a>",,2025-12-03 22:39:25
Predify: Augmenting deep neural networks with brain-inspired predictive coding dynamics,"Bhavin Choksi, Milad Mozafari, Callum Biggs O'May, Benjamin Ador, Andrea Alamia, Rufin VanRullen",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.02749"" target=""_blank"">2106.02749</a>",,2025-12-03 22:39:25
BERT-Defense: A Probabilistic Model Based on BERT to Combat Cognitively Inspired Orthographic Adversarial Attacks,"Yannik Keller, Jan Mackensen, Steffen Eger",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.01452"" target=""_blank"">2106.01452</a>",,2025-12-03 22:39:25
Adversarial Defense for Automatic Speaker Verification by Self-Supervised Learning,"Haibin Wu, Xu Li, Andy T. Liu, Zhiyong Wu, Helen Meng, Hung-yi Lee",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.00273"" target=""_blank"">2106.00273</a>",,2025-12-03 22:39:25
Improving Compositionality of Neural Networks by Decoding Representations to Inputs,"Mike Wu, Noah Goodman, Stefano Ermon",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.00769"" target=""_blank"">2106.00769</a>",,2025-12-03 22:39:25
Markpainting: Adversarial Machine Learning meets Inpainting,"David Khachaturov, Ilia Shumailov, Yiren Zhao, Nicolas Papernot, Ross Anderson",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.00660"" target=""_blank"">2106.00660</a>",,2025-12-03 22:39:25
On the Efficacy of Adversarial Data Collection for Question Answering: Results from a Large-Scale Randomized Study,"Divyansh Kaushik, Douwe Kiela, Zachary C. Lipton, Wen-tau Yih",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.00872"" target=""_blank"">2106.00872</a>",,2025-12-03 22:39:25
Adversarial VQA: A New Benchmark for Evaluating the Robustness of VQA Models,"Linjie Li, Jie Lei, Zhe Gan, Jingjing Liu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.00245"" target=""_blank"">2106.00245</a>",,2025-12-03 22:39:25
Memory Wrap: a Data-Efficient and Interpretable Extension to Image Classification Models,"Rosa Biagio La, Roberto Capobianco, Daniele Nardi",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.01440"" target=""_blank"">2106.01440</a>",,2025-12-03 22:39:25
Concurrent Adversarial Learning for Large-Batch Training,"Yong Liu, Xiangning Chen, Minhao Cheng, Cho-Jui Hsieh, Yang You",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.00221"" target=""_blank"">2106.00221</a>",,2025-12-03 22:39:25
DOCTOR: A Simple Method for Detecting Misclassification Errors,"Federica Granese, Marco Romanelli, Daniele Gorla, Catuscia Palamidessi, Pablo Piantanida",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.02395"" target=""_blank"">2106.02395</a>",,2025-12-03 22:39:25
Human-Adversarial Visual Question Answering,"Sasha Sheng, Amanpreet Singh, Vedanuj Goswami, Jose Alberto Lopez Magana, Wojciech Galuba, Devi Parikh, Douwe Kiela",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.02280"" target=""_blank"">2106.02280</a>",,2025-12-03 22:39:25
Network insensitivity to parameter noise via adversarial regularization,"Julian Büchel, Fynn Faber, Dylan R. Muir",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.05009"" target=""_blank"">2106.05009</a>",,2025-12-03 22:39:25
Position Bias Mitigation: A Knowledge-Aware Graph Model for Emotion Cause Extraction,"Hanqi Yan, Lin Gui, Gabriele Pergola, Yulan He",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.03518"" target=""_blank"">2106.03518</a>",,2025-12-03 22:39:25
On Improving Adversarial Transferability of Vision Transformers,"Muzammal Naseer, Kanchana Ranasinghe, Salman Khan, Fahad Shahbaz Khan, Fatih Porikli",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.04169"" target=""_blank"">2106.04169</a>",,2025-12-03 22:39:25
Simulated Adversarial Testing of Face Recognition Models,"Nataniel Ruiz, Adam Kortylewski, Weichao Qiu, Cihang Xie, Sarah Adel Bargal, Alan Yuille, Stan Sclaroff",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.04569"" target=""_blank"">2106.04569</a>",,2025-12-03 22:39:25
Towards the Memorization Effect of Neural Networks in Adversarial Training,"Han Xu, Xiaorui Liu, Wentao Wang, Wenbiao Ding, Zhongqin Wu, Zitao Liu, Anil Jain, Jiliang Tang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.04794"" target=""_blank"">2106.04794</a>",,2025-12-03 22:39:25
Handcrafted Backdoors in Deep Neural Networks,"Sanghyun Hong, Nicholas Carlini, Alexey Kurakin",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.04690"" target=""_blank"">2106.04690</a>",,2025-12-03 22:39:25
Enhancing Robustness of Neural Networks through Fourier Stabilization,"Netanel Raviv, Aidan Kelley, Michael Guo, Yevgeny Vorobeychik",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.04435"" target=""_blank"">2106.04435</a>",,2025-12-03 22:39:25
Provably Robust Detection of Out-of-distribution Data (almost) for free,"Alexander Meinke, Julian Bitterwolf, Matthias Hein",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.04260"" target=""_blank"">2106.04260</a>",,2025-12-03 22:39:25
Adversarial Attack and Defense in Deep Ranking,"Mo Zhou, Le Wang, Zhenxing Niu, Qilin Zhang, Nanning Zheng, Gang Hua",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.03614"" target=""_blank"">2106.03614</a>",,2025-12-03 22:39:25
Reveal of Vision Transformers Robustness against Adversarial Attacks,"Ahmed Aldahdooh, Wassim Hamidouche, Olivier Deforges",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.03734"" target=""_blank"">2106.03734</a>",,2025-12-03 22:39:25
3DB: A Framework for Debugging Computer Vision Models,"Guillaume Leclerc, Hadi Salman, Andrew Ilyas, Sai Vemprala, Logan Engstrom, Vibhav Vineet, Kai Xiao, Pengchuan Zhang, Shibani Santurkar, Greg Yang, Ashish Kapoor, Aleksander Madry",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.03805"" target=""_blank"">2106.03805</a>","<a href=""https://github.com/3db/3db"" target=""_blank"">3db</a>",2025-12-03 22:39:25
BO-DBA: Query-Efficient Decision-Based Adversarial Attacks via Bayesian Optimization,"Zhuosheng Zhang, Shucheng Yu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.02732"" target=""_blank"">2106.02732</a>",,2025-12-03 22:39:25
RoSearch: Search for Robust Student Architectures When Distilling Pre-trained Language Models,"Xin Guo, Jianlei Yang, Haoyi Zhou, Xucheng Ye, Jianxin Li",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.03613"" target=""_blank"">2106.03613</a>",,2025-12-03 22:39:25
Semantically Adversarial Scenario Generation with Explicit Knowledge Guidance,"Wenhao Ding, Haohong Lin, Bo Li, Ding Zhao",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.04066"" target=""_blank"">2106.04066</a>",,2025-12-03 22:39:25
A Primer on Multi-Neuron Relaxation-based Adversarial Robustness Certification,Kevin Roth,arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.03099"" target=""_blank"">2106.03099</a>",,2025-12-03 22:39:25
Zero-Shot Knowledge Distillation from a Decision-Based Black-Box Model,Zi Wang,arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.03310"" target=""_blank"">2106.03310</a>","<a href=""https://github.com/zwang84/zsdb3kd"" target=""_blank"">zwang84</a>",2025-12-03 22:39:25
Ensemble Defense with Data Diversity: Weak Correlation Implies Strong Robustness,"Renjue Li, Hanwei Zhang, Pengfei Yang, Cheng-Chao Huang, Aimin Zhou, Bai Xue, Lijun Zhang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.02867"" target=""_blank"">2106.02867</a>",,2025-12-03 22:39:25
Robust Stochastic Linear Contextual Bandits Under Adversarial Attacks,"Qin Ding, Cho-Jui Hsieh, James Sharpnack",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.02978"" target=""_blank"">2106.02978</a>",,2025-12-03 22:39:25
RDA: Robust Domain Adaptation via Fourier Adversarial Attacking,"Jiaxing Huang, Dayan Guan, Aoran Xiao, Shijian Lu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.02874"" target=""_blank"">2106.02874</a>",,2025-12-03 22:39:25
Revisiting Hilbert-Schmidt Information Bottleneck for Adversarial Robustness,"Zifeng Wang, Tong Jian, Aria Masoomi, Stratis Ioannidis, Jennifer Dy",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.02734"" target=""_blank"">2106.02734</a>",,2025-12-03 22:39:25
CAN-LOC: Spoofing Detection and Physical Intrusion Localization on an In-Vehicle CAN Bus Based on Deep Features of Voltage Signals,"Efrat Levy, Asaf Shabtai, Bogdan Groza, Pal-Stefan Murvay, Yuval Elovici",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07895"" target=""_blank"">2106.07895</a>",,2025-12-03 22:39:25
A Little Robustness Goes a Long Way: Leveraging Universal Features for Targeted Transfer Attacks,"Jacob M. Springer, Melanie Mitchell, Garrett T. Kenyon",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.02105"" target=""_blank"">2106.02105</a>",,2025-12-03 22:39:25
Securing Face Liveness Detection Using Unforgeable Lip Motion Patterns,"Man Senior Member, IEEE Zhou, Qian Senior Member, IEEE Wang, Qi Senior Member, IEEE Li, Peipei Senior Member, IEEE Jiang, Jingxiao Senior Member, IEEE Yang, Chao Senior Member, IEEE Shen, Cong Fellow, IEEE Wang, Shouhong Ding",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.08013"" target=""_blank"">2106.08013</a>",,2025-12-03 22:39:25
Who is Responsible for Adversarial Defense? (93%),"Kishor Datta Gupta, Dipankar Dasgupta",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.14152"" target=""_blank"">2106.14152</a>",,2025-12-03 22:39:25
Stabilizing Equilibrium Models by Jacobian Regularization,"Shaojie Bai, Vladlen Koltun, J. Zico Kolter",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.14342"" target=""_blank"">2106.14342</a>","<a href=""https://github.com/locuslab/deq"" target=""_blank"">locuslab</a>",2025-12-03 22:39:25
Multi-stage Optimization based Adversarial Training,"Xiaosen Wang, Chuanbiao Song, Liwei Wang, Kun He",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15357"" target=""_blank"">2106.15357</a>",,2025-12-03 22:39:25
The Feasibility and Inevitability of Stealth Attacks,"Ivan Y. Tyukin, Desmond J. Higham, Eliyas Woldegeorgis, Alexander N. Gorban",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.13997"" target=""_blank"">2106.13997</a>",,2025-12-03 22:39:25
On the (Un-)Avoidability of Adversarial Examples,"Sadia Chowdhury, Ruth Urner",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.13326"" target=""_blank"">2106.13326</a>",,2025-12-03 22:39:25
Countering Adversarial Examples: Combining Input Transformation and Noisy Training,"Cheng Zhang, Pan Gao",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.13394"" target=""_blank"">2106.13394</a>",,2025-12-03 22:39:25
"Break it, Fix it: Attack and Defense for ""Add-on'' Access Control Solutions in Distributed Data Analytics Platforms","Fahad Data Security Technologies Shaon, Sazzadur University of Arizona Rahaman, Murat Data Security Technologies Kantarcioglu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.13123"" target=""_blank"">2106.13123</a>",,2025-12-03 22:39:25
Adversarial Examples in Multi-Layer Random ReLU Networks,"Peter L. Bartlett, Sébastien Bubeck, Yeshwanth Cherapanamjeri",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.12611"" target=""_blank"">2106.12611</a>",,2025-12-03 22:39:25
Teacher Model Fingerprinting Attacks Against Transfer Learning,"Yufei Chen, Chao Shen, Cong Wang, Yang Zhang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.12478"" target=""_blank"">2106.12478</a>",,2025-12-03 22:39:25
Meaningfully Explaining Model Mistakes Using Conceptual Counterfactuals,"Abubakar Abid, Mert Yuksekgonul, James Zou",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.12723"" target=""_blank"">2106.12723</a>",,2025-12-03 22:39:25
Feature Attributions and Counterfactual Explanations Can Be Manipulated,"Dylan Slack, Sophie Hilgard, Sameer Singh, Himabindu Lakkaraju",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.12563"" target=""_blank"">2106.12563</a>",,2025-12-03 22:39:25
DetectX -- Adversarial Input Detection using Current Signatures in Memristive XBar Arrays,"Abhishek Moitra, Priyadarshini Panda",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.12021"" target=""_blank"">2106.12021</a>","<a href=""https://github.com/Intelligent-Computing-Lab-Yale/DetectX"" target=""_blank"">Intelligent-Computing-Lab-Yale</a>",2025-12-03 22:39:25
Self-Supervised Iterative Contextual Smoothing for Efficient Adversarial Defense against Gray- and Black-Box Attack,"Sungmin Cha, Naeun Ko, Youngjoon Yoo, Taesup Moon",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.11644"" target=""_blank"">2106.11644</a>",,2025-12-03 22:39:25
Long-term Cross Adversarial Training: A Robust Meta-learning Method for Few-shot Classification Tasks,"Fan Liu, Shuyu Zhao, Xuelong Dai, Bin Xiao",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.12900"" target=""_blank"">2106.12900</a>",,2025-12-03 22:39:25
On Adversarial Robustness of Synthetic Code Generation,"Mrinal Anand, Pratik Kayal, Mayank Singh",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.11629"" target=""_blank"">2106.11629</a>",,2025-12-03 22:39:25
NetFense: Adversarial Defenses against Privacy Attacks on Neural Networks for Graph Data,"I-Chung Hsieh, Cheng-Te Li",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.11865"" target=""_blank"">2106.11865</a>",,2025-12-03 22:39:25
FLEA: Provably Robust Fair Multisource Learning from Unreliable Training Data,"Eugenia Iofinova, Nikola Konstantinov, Christoph H. Lampert",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.11732"" target=""_blank"">2106.11732</a>","<a href=""https://github.com/ISTAustria-CVML/FLEA"" target=""_blank"">ISTAustria-CVML</a>",2025-12-03 22:39:25
Policy Smoothing for Provably Robust Reinforcement Learning,"Aounon Kumar, Alexander Levine, Soheil Feizi",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.11420"" target=""_blank"">2106.11420</a>",,2025-12-03 22:39:25
Delving into the pixels of adversarial samples,Blerta Lindqvist,arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.10996"" target=""_blank"">2106.10996</a>",,2025-12-03 22:39:25
HODA: Hardness-Oriented Detection of Model Extraction Attacks,"Amir Mahdi Sadeghzadeh, Amir Mohammad Sobhanian, Faezeh Dehghan, Rasool Jalili",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.11424"" target=""_blank"">2106.11424</a>",,2025-12-03 22:39:25
ASK: Adversarial Soft k-Nearest Neighbor Attack and Defense,"Ren Wang, Tianqi Chen, Philip Yao, Sijia Liu, Indika Rajapakse, Alfred Hero",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.14300"" target=""_blank"">2106.14300</a>",,2025-12-03 22:39:25
Realtime Robust Malicious Traffic Detection via Frequency Domain Analysis,"Chuanpu Fu, Qi Li, Meng Shen, Ke Xu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.14707"" target=""_blank"">2106.14707</a>",,2025-12-03 22:39:25
Membership Inference on Word Embedding and Beyond,"Saeed Mahloujifar, Huseyin A. Inan, Melissa Chase, Esha Ghosh, Marcello Hasegawa",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.11384"" target=""_blank"">2106.11384</a>",,2025-12-03 22:39:25
Certified Robustness via Randomized Smoothing over Multiplicative Parameters,"Nikita Muravev, Aleksandr Petiushko",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.14432"" target=""_blank"">2106.14432</a>",,2025-12-03 22:39:25
CRFL: Certifiably Robust Federated Learning against Backdoor Attacks,"Chulin Xie, Minghao Chen, Pin-Yu Chen, Bo Li",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.08283"" target=""_blank"">2106.08283</a>","<a href=""https://github.com/AI-secure/CRFL"" target=""_blank"">AI-secure</a>",2025-12-03 22:39:25
In-distribution adversarial attacks on object recognition models using gradient-free search,"Spandan Madan, Tomotake Sasaki, Hanspeter Pfister, Tzu-Mao Li, Xavier Boix",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.16198"" target=""_blank"">2106.16198</a>","<a href=""https://github.com/Spandan-Madan/in_distribution_adversarial_examples"" target=""_blank"">Spandan-Madan</a>",2025-12-03 22:39:25
Single-Step Adversarial Training for Semantic Segmentation,"Daniel Wiens, Barbara Hammer",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15998"" target=""_blank"">2106.15998</a>",,2025-12-03 22:39:25
Understanding Adversarial Attacks on Observations in Deep Reinforcement Learning,"You Qiaoben, Chengyang Ying, Xinning Zhou, Hang Su, Jun Zhu, Bo Zhang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15860"" target=""_blank"">2106.15860</a>",,2025-12-03 22:39:25
Explanation-Guided Diagnosis of Machine Learning Evasion Attacks,"Abderrahmen Amich, Birhanu Eshete",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15820"" target=""_blank"">2106.15820</a>",,2025-12-03 22:39:25
Exploring Robustness of Neural Networks through Graph Measures,"Asim Rowan University Waqas, Ghulam Rowan University Rasool, Hamza University of Minnesota Farooq, Nidhal C. Rowan University Bouaynaya",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15850"" target=""_blank"">2106.15850</a>",,2025-12-03 22:39:25
A Context-Aware Information-Based Clone Node Attack Detection Scheme in Internet of Things,"Khizar Hameed, Saurabh Garg, Muhammad Bilal Amin, Byeong Kang, Abid Khan",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15890"" target=""_blank"">2106.15890</a>",,2025-12-03 22:39:25
Understanding and Improving Early Stopping for Learning with Noisy Labels,"Yingbin Bai, Erkun Yang, Bo Han, Yanhua Yang, Jiatong Li, Yinian Mao, Gang Niu, Tongliang Liu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15853"" target=""_blank"">2106.15853</a>",,2025-12-03 22:39:25
Attack Transferability Characterization for Adversarially Robust Multi-label Classification,"Zhuo Yang, Yufei Han, Xiangliang Zhang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15360"" target=""_blank"">2106.15360</a>",,2025-12-03 22:39:25
Inconspicuous Adversarial Patches for Fooling Image Recognition Systems on Mobile Devices,"Tao Bai, Jinqi Luo, Jun Zhao",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15202"" target=""_blank"">2106.15202</a>",,2025-12-03 22:39:25
The Threat of Offensive AI to Organizations,"Yisroel Mirsky, Ambra Demontis, Jaidip Kotak, Ram Shankar, Deng Gelei, Liu Yang, Xiangyu Zhang, Wenke Lee, Yuval Elovici, Battista Biggio",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15764"" target=""_blank"">2106.15764</a>",,2025-12-03 22:39:25
Local Reweighting for Adversarial Training,"Ruize Gao, Feng Liu, Kaiwen Zhou, Gang Niu, Bo Han, James Cheng",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15776"" target=""_blank"">2106.15776</a>",,2025-12-03 22:39:25
On the Interaction of Belief Bias and Explanations,"Ana Valeria Gonzalez, Anna Rogers, Anders Søgaard",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15355"" target=""_blank"">2106.15355</a>",,2025-12-03 22:39:25
Feature Importance Guided Attack: A Model Agnostic Adversarial Attack,"Gilad Gressel, Niranjan Hegde, Archana Sreekumar, Michael Darling",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.14815"" target=""_blank"">2106.14815</a>",,2025-12-03 22:39:25
Evading Adversarial Example Detection Defenses with Orthogonal Projected Gradient Descent,"Oliver Bryniarski, Nabeel Hingun, Pedro Pachuca, Vincent Wang, Nicholas Carlini",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15023"" target=""_blank"">2106.15023</a>",,2025-12-03 22:39:25
Improving Transferability of Adversarial Patches on Face Recognition with Generative Models,"Zihao Xiao, Xianfeng Gao, Chilin Fu, Yinpeng Dong, Wei Gao, Xiaolu Zhang, Jun Zhou, Jun Zhu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15058"" target=""_blank"">2106.15058</a>",,2025-12-03 22:39:25
Data Poisoning Won't Save You From Facial Recognition,"Evani Radiya-Dixit, Florian Tramèr",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.14851"" target=""_blank"">2106.14851</a>",,2025-12-03 22:39:25
Adversarial Robustness of Streaming Algorithms through Importance Sampling,"Vladimir Braverman, Avinatan Hassidim, Yossi Matias, Mariano Schain, Sandeep Silwal, Samson Zhou",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.14952"" target=""_blank"">2106.14952</a>",,2025-12-03 22:39:25
Test-Time Adaptation to Distribution Shift by Confidence Maximization and Input Transformation,"Chaithanya Kumar Mummadi, Robin Hutmacher, Kilian Rambach, Evgeny Levinkov, Thomas Brox, Jan Hendrik Metzen",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.14999"" target=""_blank"">2106.14999</a>",,2025-12-03 22:39:25
Friendly Training: Neural Networks Can Adapt Data To Make Learning Easier,"Simone Marullo, Matteo Tiezzi, Marco Gori, Stefano Melacci",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.10974"" target=""_blank"">2106.10974</a>",,2025-12-03 22:39:25
Do Not Deceive Your Employer with a Virtual Background: A Video Conferencing Manipulation-Detection System,"Mauro Conti, Simone Milani, Ehsan Nowroozi, Gabriele Orazi",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.15130"" target=""_blank"">2106.15130</a>",,2025-12-03 22:39:25
An Alternative Auxiliary Task for Enhancing Image Classification,Chen Liu,arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.11478"" target=""_blank"">2106.11478</a>",,2025-12-03 22:39:25
Adversarial Detection Avoidance Attacks: Evaluating the robustness of perceptual hashing-based client-side scanning,"Shubham Jain, Ana-Maria Cretu, Montjoye Yves-Alexandre de",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09820"" target=""_blank"">2106.09820</a>",,2025-12-03 22:39:25
Modeling Realistic Adversarial Attacks against Network Intrusion Detection Systems,"Giovanni Apruzzese, Mauro Andreolini, Luca Ferretti, Mirco Marchetti, Michele Colajanni",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09380"" target=""_blank"">2106.09380</a>",,2025-12-03 22:39:25
Poisoning and Backdooring Contrastive Learning,"Nicholas Carlini, Andreas Terzis",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09667"" target=""_blank"">2106.09667</a>",,2025-12-03 22:39:25
CROP: Certifying Robust Policies for Reinforcement Learning through Functional Smoothing,"Fan Wu, Linyi Li, Zijian Huang, Yevgeniy Vorobeychik, Ding Zhao, Bo Li",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09292"" target=""_blank"">2106.09292</a>","<a href=""https://crop-leaderboard.github.io"" target=""_blank""></a>",2025-12-03 22:39:25
CoCoFuzzing: Testing Neural Code Models with Coverage-Guided Fuzzing,"Moshi Wei, Yuchao Huang, Jinqiu Yang, Junjie Wang, Song Wang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09242"" target=""_blank"">2106.09242</a>",,2025-12-03 22:39:25
On Deep Neural Network Calibration by Regularization and its Impact on Refinement,"Aditya Singh, Alessandro Bay, Biswa Sengupta, Andrea Mirabile",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09385"" target=""_blank"">2106.09385</a>",,2025-12-03 22:39:25
Effective Model Sparsification by Scheduled Grow-and-Prune Methods,"Xiaolong Ma, Minghai Qin, Fei Sun, Zejiang Hou, Kun Yuan, Yi Xu, Yanzhi Wang, Yen-Kuang Chen, Rong Jin, Yuan Xie",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09857"" target=""_blank"">2106.09857</a>",,2025-12-03 22:39:25
Real-time Adversarial Perturbations against Deep Reinforcement Learning Policies: Attacks and Defenses,"Buse G. A. Tekgul, Shelly Wang, Samuel Marchal, N. Asokan",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.08746"" target=""_blank"">2106.08746</a>",,2025-12-03 22:39:25
Localized Uncertainty Attacks,"Ousmane Amadou Dia, Theofanis Karaletsos, Caner Hazirbas, Cristian Canton Ferrer, Ilknur Kaynar Kabul, Erik Meijer",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09222"" target=""_blank"">2106.09222</a>",,2025-12-03 22:39:25
Evaluating the Robustness of Bayesian Neural Networks Against Different Types of Attacks,"Yutian Pang, Sheng Cheng, Jueming Hu, Yongming Liu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09223"" target=""_blank"">2106.09223</a>",,2025-12-03 22:39:25
Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch,"Hossein Souri, Liam Fowl, Rama Chellappa, Micah Goldblum, Tom Goldstein",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.08970"" target=""_blank"">2106.08970</a>","<a href=""https://github.com/hsouri/Sleeper-Agent"" target=""_blank"">hsouri</a>",2025-12-03 22:39:25
Explainable AI for Natural Adversarial Images,"Tomas Folke, ZhaoBin Li, Ravi B. Sojitra, Scott Cheng-Hsin Yang, Patrick Shafto",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09106"" target=""_blank"">2106.09106</a>",,2025-12-03 22:39:25
A Winning Hand: Compressing Deep Networks Can Improve Out-Of-Distribution Robustness,"James Diffenderfer, Brian R. Bartoldson, Shreya Chaganti, Jize Zhang, Bhavya Kailkhura",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09129"" target=""_blank"">2106.09129</a>",,2025-12-03 22:39:25
Scaling-up Diverse Orthogonal Convolutional Networks with a Paraunitary Framework,"Jiahao Su, Wonmin Byeon, Furong Huang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09121"" target=""_blank"">2106.09121</a>",,2025-12-03 22:39:25
Adversarial Attacks on Deep Models for Financial Transaction Records,"Ivan Fursov, Matvey Morozov, Nina Kaploukhaya, Elizaveta Kovtun, Rodrigo Rivera-Castro, Gleb Gusev, Dmitry Babaev, Ivan Kireev, Alexey Zaytsev, Evgeny Burnaev",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.08361"" target=""_blank"">2106.08361</a>",,2025-12-03 22:39:25
Model Extraction and Adversarial Attacks on Neural Networks using Switching Power Information,"Tommy Li, Cory Merkel",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.08299"" target=""_blank"">2106.08299</a>",,2025-12-03 22:39:25
Towards Adversarial Robustness via Transductive Learning,"Jiefeng Chen, Yang Guo, Xi Wu, Tianqi Li, Qicheng Lao, Yingyu Liang, Somesh Jha",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.08387"" target=""_blank"">2106.08387</a>",,2025-12-03 22:39:25
Detect and remove watermark in deep neural networks via generative adversarial networks,"Haoqi Wang, Mingfu Xue, Shichang Sun, Yushu Zhang, Jian Wang, Weiqiang Liu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.08104"" target=""_blank"">2106.08104</a>",,2025-12-03 22:39:25
Zero-shot learning approach to adaptive Cybersecurity using Explainable AI,"Dattaraj Rao, Shraddha Mane",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.14647"" target=""_blank"">2106.14647</a>",,2025-12-03 22:39:25
Voting for the right answer: Adversarial defense for speaker verification,"Haibin Wu, Yang Zhang, Zhiyong Wu, Dong Wang, Hung-yi Lee",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.07868"" target=""_blank"">2106.07868</a>",,2025-12-03 22:39:25
Invisible for both Camera and LiDAR: Security of Multi-Sensor Fusion based Perception in Autonomous Driving Under Physical-World Attacks,"Yulong *co-first authors Cao*, Ningfei *co-first authors Wang*, Chaowei *co-first authors Xiao*, Dawei *co-first authors Yang*, Jin *co-first authors Fang, Ruigang *co-first authors Yang, Qi Alfred *co-first authors Chen, Mingyan *co-first authors Liu, Bo *co-first authors Li",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09249"" target=""_blank"">2106.09249</a>",,2025-12-03 22:39:25
Loki: Hardening Code Obfuscation Against Automated Attacks,"Moritz Schloegel, Tim Blazytko, Moritz Contag, Cornelius Aschermann, Julius Basler, Thorsten Holz, Ali Abbasi",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.08913"" target=""_blank"">2106.08913</a>",,2025-12-03 22:39:25
Adversarial Visual Robustness by Causal Intervention,"Kaihua Tang, Mingyuan Tao, Hanwang Zhang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09534"" target=""_blank"">2106.09534</a>",,2025-12-03 22:39:25
Light Lies: Optical Adversarial Attack,"Kyulim Kim, JeongSoo Kim, Seungri Song, Jun-Ho Choi, Chulmin Joo, Jong-Seok Lee",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09908"" target=""_blank"">2106.09908</a>",,2025-12-03 22:39:25
Adversarial Examples Make Strong Poisons,"Liam Fowl, Micah Goldblum, Ping-yeh Chiang, Jonas Geiping, Wojtek Czaja, Tom Goldstein",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.10807"" target=""_blank"">2106.10807</a>",,2025-12-03 22:39:25
Adversarial Attack on Graph Neural Networks as An Influence Maximization Problem,"Jiaqi Ma, Junwei Deng, Qiaozhu Mei",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.10785"" target=""_blank"">2106.10785</a>",,2025-12-03 22:39:25
DeepInsight: Interpretability Assisting Detection of Adversarial Samples on Graphs,"Junhao Zhu, Yalu Shan, Jinhuan Wang, Shanqing Yu, Guanrong Chen, Qi Xuan",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09501"" target=""_blank"">2106.09501</a>",,2025-12-03 22:39:25
Attack to Fool and Explain Deep Networks,"Naveed Akhtar, Muhammad A. A. K. Jalwana, Mohammed Bennamoun, Ajmal Mian",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.10606"" target=""_blank"">2106.10606</a>",,2025-12-03 22:39:25
A Stealthy and Robust Fingerprinting Scheme for Generative Models,"Li Guanlin, Guo Shangwei, Wang Run, Xu Guowen, Zhang Tianwei",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.11760"" target=""_blank"">2106.11760</a>",,2025-12-03 22:39:25
Residual Error: a New Performance Measure for Adversarial Robustness,"Hossein Aboutalebi, Mohammad Javad Shafiee, Michelle Karg, Christian Scharfenberger, Alexander Wong",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.10212"" target=""_blank"">2106.10212</a>",,2025-12-03 22:39:25
Indicators of Attack Failure: Debugging and Improving Optimization of Adversarial Examples,"Maura Pintor, Luca Demetrio, Angelo Sotgiu, Ambra Demontis, Nicholas Carlini, Battista Biggio, Fabio Roli",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09947"" target=""_blank"">2106.09947</a>","<a href=""https://github.com/pralab/IndicatorsOfAttackFailure"" target=""_blank"">pralab</a>",2025-12-03 22:39:25
The Dimpled Manifold Model of Adversarial Examples in Machine Learning,"Adi Shamir, Odelia Melamed, Oriel BenShmuel",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.10151"" target=""_blank"">2106.10151</a>",,2025-12-03 22:39:25
Exploring Counterfactual Explanations Through the Lens of Adversarial Examples: A Theoretical and Empirical Analysis,"Martin Pawelczyk, Chirag Agarwal, Shalmali Joshi, Sohini Upadhyay, Himabindu Lakkaraju",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09992"" target=""_blank"">2106.09992</a>",,2025-12-03 22:39:25
Generative Model Adversarial Training for Deep Compressed Sensing,Ashkan Esmaeili,arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.10696"" target=""_blank"">2106.10696</a>",,2025-12-03 22:39:25
Analyzing Adversarial Robustness of Deep Neural Networks in Pixel Space: a Semantic Perspective,"Lina Wang, Xingshu Chen, Yulong Wang, Yawei Yue, Yi Zhu, Xuemei Zeng, Wei Wang",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09872"" target=""_blank"">2106.09872</a>",,2025-12-03 22:39:25
Less is More: Feature Selection for Adversarial Robustness with Compressive Counter-Adversarial Attacks,"Emre Ozfatura, Muhammad Zaid Hameed, Kerem Ozfatura, Deniz Gunduz",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.10252"" target=""_blank"">2106.10252</a>",,2025-12-03 22:39:25
Bad Characters: Imperceptible NLP Attacks,"Nicholas Boucher, Ilia Shumailov, Ross Anderson, Nicolas Papernot",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09898"" target=""_blank"">2106.09898</a>",,2025-12-03 22:39:25
Group-Structured Adversarial Training,"Farzan Farnia, Amirali Aghazadeh, James Zou, David Tse",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.10324"" target=""_blank"">2106.10324</a>",,2025-12-03 22:39:25
Accumulative Poisoning Attacks on Real-time Data,"Tianyu Pang, Xiao Yang, Yinpeng Dong, Hang Su, Jun Zhu",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09993"" target=""_blank"">2106.09993</a>",,2025-12-03 22:39:25
Evaluating the Robustness of Trigger Set-Based Watermarks Embedded in Deep Neural Networks,"Suyoung Lee, Wonho Song, Suman Jana, Meeyoung Cha, Sooel Son",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.10147"" target=""_blank"">2106.10147</a>",,2025-12-03 22:39:25
BinarizedAttack: Structural Poisoning Attacks to Graph-based Anomaly Detection,"Yulin Zhu, Yuni Lai, Kaifa Zhao, Xiapu Luo, Mingquan Yuan, Jian Ren, Kai Zhou",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.09989"" target=""_blank"">2106.09989</a>",,2025-12-03 22:39:25
Federated Robustness Propagation: Sharing Adversarial Robustness in Federated Learning,"Junyuan Hong, Haotao Wang, Zhangyang Wang, Jiayu Zhou",arXiv,2021-06,"<a href=""http://arxiv.org/abs/2106.10196"" target=""_blank"">2106.10196</a>",,2025-12-03 22:39:25
Poisoning MorphNet for Clean-Label Backdoor Attack to Point Clouds,"Guiyu Tian, Wenhao Jiang, Wei Liu, Yadong Mu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.04839"" target=""_blank"">2105.04839</a>",,2025-12-03 22:39:25
"Biometrics: Trust, but Verify","Anil K. Jain, Debayan Deb, Joshua J. Engelsma",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.06625"" target=""_blank"">2105.06625</a>",,2025-12-03 22:39:25
AVA: Adversarial Vignetting Attack against Visual Recognition,"Binyu Tian, Felix Juefei-Xu, Qing Guo, Xiaofei Xie, Xiaohong Li, Yang Liu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.05558"" target=""_blank"">2105.05558</a>",,2025-12-03 22:39:25
OutFlip: Generating Out-of-Domain Samples for Unknown Intent Detection with Natural Language Attack,"DongHyun Choi, Myeong Cheol Shin, EungGyun Kim, Dong Ryeol Shin",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.05601"" target=""_blank"">2105.05601</a>",,2025-12-03 22:39:25
Adversarial Reinforcement Learning in Dynamic Channel Access and Power Control,"Feng Wang, M. Cenk Gursoy, Senem Velipasalar",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.05817"" target=""_blank"">2105.05817</a>",,2025-12-03 22:39:25
A Statistical Threshold for Adversarial Classification in Laplace Mechanisms,"Ayşe Ünsal, Melek Önen",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.05610"" target=""_blank"">2105.05610</a>",,2025-12-03 22:39:25
Accuracy-Privacy Trade-off in Deep Ensemble: A Membership Inference Perspective,"Shahbaz Rezaei, Zubair Shafiq, Xin Liu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.05381"" target=""_blank"">2105.05381</a>",,2025-12-03 22:39:25
Improving Adversarial Transferability with Gradient Refining,"Guoqiu Wang, Huanqian Yan, Ying Guo, Xingxing Wei",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.04834"" target=""_blank"">2105.04834</a>",,2025-12-03 22:39:25
When Human Pose Estimation Meets Robustness: Adversarial Algorithms and Benchmarks,"Jiahang Wang, Sheng Jin, Wentao Liu, Weizhong Liu, Chen Qian, Ping Luo",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.06152"" target=""_blank"">2105.06152</a>",,2025-12-03 22:39:25
Adversarial examples attack based on random warm restart mechanism and improved Nesterov momentum,Tiangang Li,arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.05029"" target=""_blank"">2105.05029</a>",,2025-12-03 22:39:25
Examining and Mitigating Kernel Saturation in Convolutional Neural Networks using Negative Images,"Nidhi Gowdra, Roopak Sinha, Stephen MacDonell",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.04128"" target=""_blank"">2105.04128</a>",,2025-12-03 22:39:25
Automated Decision-based Adversarial Attacks,"Qi-An Fu, Yinpeng Dong, Hang Su, Jun Zhu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.03931"" target=""_blank"">2105.03931</a>",,2025-12-03 22:39:25
Efficiency-driven Hardware Optimization for Adversarially Robust Neural Networks,"Abhiroop Bhattacharjee, Abhishek Moitra, Priyadarshini Panda",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.04003"" target=""_blank"">2105.04003</a>",,2025-12-03 22:39:25
Security Concerns on Machine Learning Solutions for 6G Networks in mmWave Beam Prediction,"Ferhat Ozgur Catak, Evren Catak, Murat Kuzlu, Umit Cali",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.03905"" target=""_blank"">2105.03905</a>",,2025-12-03 22:39:25
Robust Training Using Natural Transformation,"Shuo Wang, Lingjuan Lyu, Surya Nepal, Carsten Rudolph, Marthie Grobler, Kristen Moore",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.04070"" target=""_blank"">2105.04070</a>",,2025-12-03 22:39:25
DeepObliviate: A Powerful Charm for Erasing Data Residual Memory in Deep Neural Networks,"Yingzhe He, Guozhu Meng, Kai Chen, Jinwen He, Xingbo Hu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.06209"" target=""_blank"">2105.06209</a>",,2025-12-03 22:39:25
Fighting Gradients with Gradients: Dynamic Defenses against Adversarial Attacks,"Dequan Wang, An Ju, Evan Shelhamer, David Wagner, Trevor Darrell",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.08714"" target=""_blank"">2105.08714</a>",,2025-12-03 22:39:25
Stochastic-Shield: A Probabilistic Approach Towards Training-Free Adversarial Defense in Quantized CNNs,"Lorena Qendro, Sangwon Ha, Jong René de, Partha Maji",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.06512"" target=""_blank"">2105.06512</a>",,2025-12-03 22:39:25
A Fusion-Denoising Attack on InstaHide with Data Augmentation,"Xinjian Luo, Xiaokui Xiao, Yuncheng Wu, Juncheng Liu, Beng Chin Ooi",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.07754"" target=""_blank"">2105.07754</a>",,2025-12-03 22:39:25
Combining Time-Dependent Force Perturbations in Robot-Assisted Surgery Training,"Yarden Sharon, Daniel Naftalovich, Lidor Bahar, Yael Refaely, Ilana Nisky",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.03917"" target=""_blank"">2105.03917</a>",,2025-12-03 22:39:25
On the Robustness of Domain Constraints,"Ryan Sheatsley, Blaine Hoak, Eric Pauley, Yohan Beugin, Michael J. Weisman, Patrick McDaniel",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.08619"" target=""_blank"">2105.08619</a>",,2025-12-03 22:39:25
Learning and Certification under Instance-targeted Poisoning,"Ji Gao, Amin Karbasi, Mohammad Mahmoody",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.08709"" target=""_blank"">2105.08709</a>",,2025-12-03 22:39:25
Towards Robust Vision Transformer,"Xiaofeng Mao, Gege Qi, Yuefeng Chen, Xiaodan Li, Ranjie Duan, Shaokai Ye, Yuan He, Hui Xue",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.07926"" target=""_blank"">2105.07926</a>",,2025-12-03 22:39:25
Gradient Masking and the Underestimated Robustness Threats of Differential Privacy in Deep Learning,"Franziska Boenisch, Philip Sperl, Konstantin Böttinger",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.07985"" target=""_blank"">2105.07985</a>",,2025-12-03 22:39:25
"An SDE Framework for Adversarial Training, with Convergence and Robustness Analysis","Haotian Gu, Xin Guo",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.08037"" target=""_blank"">2105.08037</a>",,2025-12-03 22:39:25
Vision Transformers are Robust Learners,"Sayak Paul, Pin-Yu Chen",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.07581"" target=""_blank"">2105.07581</a>",,2025-12-03 22:39:25
Iterative Algorithms for Assessing Network Resilience Against Structured Perturbations,"Shenyu Liu, Sonia Martinez, Jorge Cortes",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.07080"" target=""_blank"">2105.07080</a>",,2025-12-03 22:39:25
Prototype-supervised Adversarial Network for Targeted Attack of Deep Hashing,"Xunguang Wang, Zheng Zhang, Baoyuan Wu, Fumin Shen, Guangming Lu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.07553"" target=""_blank"">2105.07553</a>","<a href=""https://github.com/xunguangwang/ProS-GAN"" target=""_blank"">xunguangwang</a>",2025-12-03 22:39:25
SoundFence: Securing Ultrasonic Sensors in Vehicles Using Physical-Layer Defense,"Jianzhi Lou, Qiben Yan, Qing Hui, Huacheng Zeng",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.07574"" target=""_blank"">2105.07574</a>",,2025-12-03 22:39:25
Real-time Detection of Practical Universal Adversarial Perturbations,"Kenneth T. Co, Luis Muñoz-González, Leslie Kanthan, Emil C. Lupu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.07334"" target=""_blank"">2105.07334</a>",,2025-12-03 22:39:25
Salient Feature Extractor for Adversarial Defense on Deep Neural Networks,"Jinyin Chen, Ruoxi Chen, Haibin Zheng, Zhaoyan Ming, Wenrong Jiang, Chen Cui",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.06807"" target=""_blank"">2105.06807</a>",,2025-12-03 22:39:25
"High-Robustness, Low-Transferability Fingerprinting of Neural Networks","Siyue Wang, Xiao Wang, Pin-Yu Chen, Pu Zhao, Xue Lin",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.07078"" target=""_blank"">2105.07078</a>",,2025-12-03 22:39:25
Information-theoretic Evolution of Model Agnostic Global Explanations,"Sukriti Verma, Nikaash Puri, Piyush Gupta, Balaji Krishnamurthy",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.06956"" target=""_blank"">2105.06956</a>",,2025-12-03 22:39:25
Learning Image Attacks toward Vision Guided Autonomous Vehicles,"Hyung-Jin Yoon, Hamidreza Jafarnejadsani, Petros Voulgaris",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.03834"" target=""_blank"">2105.03834</a>",,2025-12-03 22:39:25
Black-Box Dissector: Towards Erasing-based Hard-Label Model Stealing Attack,"Yixu Wang, Jie Li, Hong Liu, Yan Wang, Yongjian Wu, Feiyue Huang, Rongrong Ji",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00623"" target=""_blank"">2105.00623</a>",,2025-12-03 22:39:25
Self-Supervised Adversarial Example Detection by Disentangled Representation,"Zhaoxi Zhang, Leo Yu Zhang, Xufei Zheng, Shengshan Hu, Jinyu Tian, Jiantao Zhou",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.03689"" target=""_blank"">2105.03689</a>",,2025-12-03 22:39:25
On the Adversarial Robustness of Quantized Neural Networks,"Micah Gorsline, James Smith, Cory Merkel",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00227"" target=""_blank"">2105.00227</a>",,2025-12-03 22:39:25
Who's Afraid of Adversarial Transferability? (99%),"Ziv Katzir, Yuval Elovici",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00433"" target=""_blank"">2105.00433</a>",,2025-12-03 22:39:25
Multi-Robot Coordination and Planning in Uncertain and Adversarial Environments,"Lifeng Zhou, Pratap Tokekar",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00389"" target=""_blank"">2105.00389</a>",,2025-12-03 22:39:25
GRNN: Generative Regression Neural Network -- A Data Leakage Attack for Federated Learning,"Hanchi Ren, Jingjing Deng, Xianghua Xie",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00529"" target=""_blank"">2105.00529</a>",,2025-12-03 22:39:25
Spinner: Automated Dynamic Command Subsystem Perturbation,"Meng Wang, Chijung Jung, Ali Ahad, Yonghwi Kwon",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00391"" target=""_blank"">2105.00391</a>",,2025-12-03 22:39:25
Adversarial Example Detection for DNN Models: A Review and Experimental Comparison,"Ahmed Aldahdooh, Wassim Hamidouche, Sid Ahmed Fezza, Olivier Deforges",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00203"" target=""_blank"">2105.00203</a>",,2025-12-03 22:39:25
A Perceptual Distortion Reduction Framework: Towards Generating Adversarial Examples with High Perceptual Quality and Attack Success Rate,"Ruijie Yang, Yunhong Wang, Ruikui Wang, Yuanfang Guo",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00278"" target=""_blank"">2105.00278</a>",,2025-12-03 22:39:25
Hidden Backdoors in Human-Centric Language Models,"Shaofeng Li, Hui Liu, Tian Dong, Benjamin Zi Hao Zhao, Minhui Xue, Haojin Zhu, Jialiang Lu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00164"" target=""_blank"">2105.00164</a>",,2025-12-03 22:39:25
Physical world assistive signals for deep neural network classifiers -- neither defense nor attack,"Camilo Pestana, Wei Liu, David Glance, Robyn Owens, Ajmal Mian",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00622"" target=""_blank"">2105.00622</a>",,2025-12-03 22:39:25
One Detector to Rule Them All: Towards a General Deepfake Attack Detection Framework,"Shahroz Tariq, Sangyup Lee, Simon S. Woo",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00187"" target=""_blank"">2105.00187</a>",,2025-12-03 22:39:25
A Master Key Backdoor for Universal Impersonation Attack against DNN-based Face Verification,"Wei Guo, Benedetta Tondi, Mauro Barni",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00249"" target=""_blank"">2105.00249</a>",,2025-12-03 22:39:25
Load Oscillating Attacks of Smart Grids: Demand Strategies and Vulnerability Analysis,"Falah Alanazi, Jinsub Kim, Eduardo Cotilla-Sanchez",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00350"" target=""_blank"">2105.00350</a>",,2025-12-03 22:39:25
RATT: Leveraging Unlabeled Data to Guarantee Generalization,"Saurabh Garg, Sivaraman Balakrishnan, J. Zico Kolter, Zachary C. Lipton",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00303"" target=""_blank"">2105.00303</a>",,2025-12-03 22:39:25
IPatch: A Remote Adversarial Patch,Yisroel Mirsky,arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00113"" target=""_blank"">2105.00113</a>",,2025-12-03 22:39:25
Sparta: Spatially Attentive and Adversarially Robust Activation,"Qing Guo, Felix Juefei-Xu, Changqing Zhou, Wei Feng, Yang Liu, Song Wang",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.08269"" target=""_blank"">2105.08269</a>",,2025-12-03 22:39:25
"BAARD: Blocking Adversarial Examples by Testing for Applicability, Reliability and Decidability","Xinglong Chang, Katharina Dost, Kaiqi Zhao, Ambra Demontis, Fabio Roli, Gill Dobbie, Jörg Wicker",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.00495"" target=""_blank"">2105.00495</a>",,2025-12-03 22:39:25
An Overview of Laser Injection against Embedded Neural Network Models,"Mathieu Dumont, Pierre-Alain Moellic, Raphael Viera, Jean-Max Dutertre, Rémi Bernhard",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.01403"" target=""_blank"">2105.01403</a>",,2025-12-03 22:39:25
De-Pois: An Attack-Agnostic Defense against Data Poisoning Attacks,"Jian Chen, Xuxin Zhang, Rui Zhang, Chen Wang, Ling Liu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.03592"" target=""_blank"">2105.03592</a>",,2025-12-03 22:39:25
A Simple and Strong Baseline for Universal Targeted Attacks on Siamese Visual Tracking,"Zhenbang Li, Yaya Shi, Jin Gao, Shaoru Wang, Bing Li, Pengpeng Liang, Weiming Hu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.02480"" target=""_blank"">2105.02480</a>",,2025-12-03 22:39:25
Certified Robustness to Text Adversarial Attacks by Randomized [MASK],"Jiehang Zeng, Xiaoqing Zheng, Jianhan Xu, Linyang Li, Liping Yuan, Xuanjing Huang",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.03743"" target=""_blank"">2105.03743</a>",,2025-12-03 22:39:25
Provable Guarantees against Data Poisoning Using Self-Expansion and Compatibility,"Charles Jin, Melinda Sun, Martin Rinard",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.03692"" target=""_blank"">2105.03692</a>",,2025-12-03 22:39:25
Mental Models of Adversarial Machine Learning,"Lukas Bieringer, Kathrin Grosse, Michael Backes, Battista Biggio, Katharina Krombholz",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.03726"" target=""_blank"">2105.03726</a>",,2025-12-03 22:39:25
Adv-Makeup: A New Imperceptible and Transferable Attack on Face Recognition,"Bangjie Yin, Wenxuan Wang, Taiping Yao, Junfeng Guo, Zelun Kong, Shouhong Ding, Jilin Li, Cong Liu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.03162"" target=""_blank"">2105.03162</a>",,2025-12-03 22:39:25
"Uniform Convergence, Adversarial Spheres and a Simple Remedy","Gregor Bachmann, Seyed-Mohsen Moosavi-Dezfooli, Thomas Hofmann",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.03491"" target=""_blank"">2105.03491</a>",,2025-12-03 22:39:25
Dynamic Defense Approach for Adversarial Robustness in Deep Neural Networks via Stochastic Ensemble Smoothed Model,"Ruoxi Qin, Linyuan Wang, Xingyuan Chen, Xuehui Du, Bin Yan",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.02803"" target=""_blank"">2105.02803</a>",,2025-12-03 22:39:25
Understanding Catastrophic Overfitting in Adversarial Training,"Peilin Kang, Seyed-Mohsen Moosavi-Dezfooli",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.02942"" target=""_blank"">2105.02942</a>",,2025-12-03 22:39:25
Broadly Applicable Targeted Data Sample Omission Attacks,"Guy Barash, Eitan Farchi, Sarit Kraus, Onn Shehory",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.01560"" target=""_blank"">2105.01560</a>",,2025-12-03 22:39:25
Attestation Waves: Platform Trust via Remote Power Analysis,"Ignacio M. Delgado-Lozano, Macarena C. Martínez-Rodríguez, Alexandros Bakas, Billy Bob Brumley, Antonis Michalas",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.02435"" target=""_blank"">2105.02435</a>",,2025-12-03 22:39:25
Attack-agnostic Adversarial Detection on Medical Data Using Explainable Machine Learning,"Matthew Durham University, Durham, UK Watson, Noura Al Durham University, Durham, UK Moubayed",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.01959"" target=""_blank"">2105.01959</a>",,2025-12-03 22:39:25
Exploiting Vulnerabilities in Deep Neural Networks: Adversarial and Fault-Injection Attacks,"Faiq Khalid, Muhammad Abdullah Hanif, Muhammad Shafique",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.03251"" target=""_blank"">2105.03251</a>",,2025-12-03 22:39:25
Contrastive Learning and Self-Training for Unsupervised Domain Adaptation in Semantic Segmentation,"Robert A. Marsden, Alexander Bartler, Mario Döbler, Bin Yang",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.02001"" target=""_blank"">2105.02001</a>",,2025-12-03 22:39:25
A Theoretical-Empirical Approach to Estimating Sample Complexity of DNNs,"Devansh Bisla, Apoorva Nandini Saridena, Anna Choromanska",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.01867"" target=""_blank"">2105.01867</a>",,2025-12-03 22:39:25
Poisoning the Unlabeled Dataset of Semi-Supervised Learning,Nicholas Carlini,arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.01622"" target=""_blank"">2105.01622</a>",,2025-12-03 22:39:25
Detecting Adversarial Examples with Bayesian Neural Network,"Yao Li, Tongyi Tang, Cho-Jui Hsieh, Thomas C. M. Lee",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.08620"" target=""_blank"">2105.08620</a>",,2025-12-03 22:39:25
Simple Transparent Adversarial Examples,"Jaydeep Borkar, Pin-Yu Chen",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.09685"" target=""_blank"">2105.09685</a>",,2025-12-03 22:39:25
Hunter in the Dark: Deep Ensemble Networks for Discovering Anomalous Activity from Smart Networks,"Shiyi Yang, Nour Moustafa, Hui Guo",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.09157"" target=""_blank"">2105.09157</a>",,2025-12-03 22:39:25
Visualizing Representations of Adversarially Perturbed Inputs,"Daniel Steinberg, Paul Munro",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14116"" target=""_blank"">2105.14116</a>",,2025-12-03 22:39:25
Demotivate adversarial defense in remote sensing,"Adrien Chan-Hon-Tong, Gaston Lenczner, Aurelien Plyer",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.13902"" target=""_blank"">2105.13902</a>",,2025-12-03 22:39:25
AdvParams: An Active DNN Intellectual Property Protection Technique via Adversarial Perturbation Based Parameter Encryption,"Mingfu Xue, Zhiyu Wu, Jian Wang, Yushu Zhang, Weiqiang Liu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.13697"" target=""_blank"">2105.13697</a>",,2025-12-03 22:39:25
Robust Regularization with Adversarial Labelling of Perturbed Samples,"Xiaohui Guo, Richong Zhang, Yaowei Zheng, Yongyi Mao",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.13745"" target=""_blank"">2105.13745</a>",,2025-12-03 22:39:25
SafeAMC: Adversarial training for robust modulation recognition models,"Javier Maroto, Gérôme Bovet, Pascal Frossard",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.13746"" target=""_blank"">2105.13746</a>",,2025-12-03 22:39:25
Towards optimally abstaining from prediction,"Adam Tauman Kalai, Varun Kanade",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14119"" target=""_blank"">2105.14119</a>",,2025-12-03 22:39:25
Rethinking Noisy Label Models: Labeler-Dependent Noise with Adversarial Awareness,"Glenn Dawson, Robi Polikar",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14083"" target=""_blank"">2105.14083</a>",,2025-12-03 22:39:25
Chromatic and spatial analysis of one-pixel attacks against an image classifier,"Janne Alatalo, Joni Korpihalkola, Tuomo Sipola, Tero Kokkonen",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.13771"" target=""_blank"">2105.13771</a>",,2025-12-03 22:39:25
Detecting Backdoor in Deep Neural Networks via Intentional Adversarial Perturbations,"Mingfu Xue, Yinghao Wu, Zhiyu Wu, Jian Wang, Yushu Zhang, Weiqiang Liu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14259"" target=""_blank"">2105.14259</a>",,2025-12-03 22:39:25
FoveaTer: Foveated Transformer for Image Classification,"Aditya Jonnalagadda, William Yang Wang, B. S. Manjunath, Miguel P. Eckstein",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14173"" target=""_blank"">2105.14173</a>",,2025-12-03 22:39:25
DeepMoM: Robust Deep Learning With Median-of-Means,"Shih-Ting Huang, Johannes Lederer",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14035"" target=""_blank"">2105.14035</a>",,2025-12-03 22:39:25
A BIC-based Mixture Model Defense against Data Poisoning Attacks on Classifiers,"Xi Li, David J. Miller, Zhen Xiang, George Kesidis",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.13530"" target=""_blank"">2105.13530</a>",,2025-12-03 22:39:25
Deep Repulsive Prototypes for Adversarial Robustness,"Alex Serban, Erik Poll, Joost Visser",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.12427"" target=""_blank"">2105.12427</a>",,2025-12-03 22:39:25
Adversarial Attack Framework on Graph Embedding Models with Limited Knowledge,"Heng Chang, Yu Rong, Tingyang Xu, Wenbing Huang, Honglei Zhang, Peng Cui, Xin Wang, Wenwu Zhu, Junzhou Huang",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.12419"" target=""_blank"">2105.12419</a>",,2025-12-03 22:39:25
Adversarial robustness against multiple $l_p$-threat models at the price of one and how to quickly fine-tune robust models to another threat model,"Francesco Croce, Matthias Hein",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.12508"" target=""_blank"">2105.12508</a>",,2025-12-03 22:39:25
Analysis and Applications of Class-wise Robustness in Adversarial Training,"Qi Tian, Kun Kuang, Kelu Jiang, Fei Wu, Yisen Wang",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14240"" target=""_blank"">2105.14240</a>",,2025-12-03 22:39:25
DAAIN: Detection of Anomalous and Adversarial Input using Normalizing Flows,"Baußnern Samuel von, Johannes Otterbach, Adrian Loy, Mathieu Salzmann, Thomas Wollmann",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14638"" target=""_blank"">2105.14638</a>",,2025-12-03 22:39:25
Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger,"Fanchao Qi, Mukai Li, Yangyi Chen, Zhengyan Zhang, Zhiyuan Liu, Yasheng Wang, Maosong Sun",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.12400"" target=""_blank"">2105.12400</a>","<a href=""https://github.com/thunlp/HiddenKiller"" target=""_blank"">thunlp</a>",2025-12-03 22:39:25
Dominant Patterns: Critical Features Hidden in Deep Neural Networks,"Zhixing Ye, Shaofei Qin, Sizhe Chen, Xiaolin Huang",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.15057"" target=""_blank"">2105.15057</a>",,2025-12-03 22:39:25
Adaptive Feature Alignment for Adversarial Training,"Tao Wang, Ruixin Zhang, Xingyu Chen, Kai Zhao, Xiaolin Huang, Yuge Huang, Shaoxin Li, Jilin Li, Feiyue Huang",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.15157"" target=""_blank"">2105.15157</a>",,2025-12-03 22:39:25
User Label Leakage from Gradients in Federated Learning,"Aidmar Wainakh, Fabrizio Ventola, Till Müßig, Jens Keim, Carlos Garcia Cordero, Ephraim Zimmer, Tim Grube, Kristian Kersting, Max Mühlhäuser",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.09369"" target=""_blank"">2105.09369</a>",,2025-12-03 22:39:25
QueryNet: An Efficient Attack Framework with Surrogates Carrying Multiple Identities,"Sizhe Chen, Zhehao Huang, Qinghua Tao, Xiaolin Huang",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.15010"" target=""_blank"">2105.15010</a>",,2025-12-03 22:39:25
Transferable Sparse Adversarial Attack,"Ziwen He, Wei Wang, Jing Dong, Tieniu Tan",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14727"" target=""_blank"">2105.14727</a>","<a href=""https://github.com/shaguopohuaizhe/TSAA"" target=""_blank"">shaguopohuaizhe</a>",2025-12-03 22:39:25
Adversarial Training with Rectified Rejection,"Tianyu Pang, Huishuai Zhang, Di He, Yinpeng Dong, Hang Su, Wei Chen, Jun Zhu, Tie-Yan Liu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14785"" target=""_blank"">2105.14785</a>",,2025-12-03 22:39:25
Robustifying $\ell_\infty$ Adversarial Training to the Union of Perturbation Models,"Ameya D. Patil, Michael Tuttle, Alexander G. Schwing, Naresh R. Shanbhag",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14710"" target=""_blank"">2105.14710</a>",,2025-12-03 22:39:25
Exploration and Exploitation: Two Ways to Improve Chinese Spelling Correction Models,"Chong Li, Cenyuan Zhang, Xiaoqing Zheng, Xuanjing Huang",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14813"" target=""_blank"">2105.14813</a>",,2025-12-03 22:39:25
Evaluating Resilience of Encrypted Traffic Classification Against Adversarial Evasion Attacks,"Ramy Maarouf, Danish Sattar, Ashraf Matrawy",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14564"" target=""_blank"">2105.14564</a>",,2025-12-03 22:39:25
Gradient-based Data Subversion Attack Against Binary Classifiers,"Rosni K Vasu, Sanjay Seetharaman, Shubham Malaviya, Manish Shukla, Sachin Lodha",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14803"" target=""_blank"">2105.14803</a>",,2025-12-03 22:39:25
DISSECT: Disentangled Simultaneous Explanations via Concept Traversals,"Asma Ghandeharioun, Been Kim, Chun-Liang Li, Brendan Jou, Brian Eoff, Rosalind W. Picard",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.15164"" target=""_blank"">2105.15164</a>",,2025-12-03 22:39:25
The effectiveness of feature attribution methods and its correlation with automatic evaluation scores,"Giang Nguyen, Daeyoung Kim, Anh Nguyen",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14944"" target=""_blank"">2105.14944</a>",,2025-12-03 22:39:25
Generating Adversarial Examples with Graph Neural Networks,"Florian Jaeckle, M. Pawan Kumar",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14644"" target=""_blank"">2105.14644</a>",,2025-12-03 22:39:25
Defending Pre-trained Language Models from Adversarial Word Substitutions Without Performance Sacrifice,"Rongzhou Bao, Jiayi Wang, Hai Zhao",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14553"" target=""_blank"">2105.14553</a>","<a href=""https://github.com/LilyNLP/ADFAR"" target=""_blank"">LilyNLP</a>",2025-12-03 22:39:25
NoiLIn: Do Noisy Labels Always Hurt Adversarial Training? (62%),"Jingfeng Zhang, Xilie Xu, Bo Han, Tongliang Liu, Gang Niu, Lizhen Cui, Masashi Sugiyama",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14676"" target=""_blank"">2105.14676</a>",,2025-12-03 22:39:25
Can Linear Programs Have Adversarial Examples? A Causal Perspective,"Matej Zečević, Devendra Singh Dhami, Kristian Kersting",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.12697"" target=""_blank"">2105.12697</a>",,2025-12-03 22:39:25
A Measurement Study on the (In)security of End-of-Life (EoL) Embedded Devices,"Dingding Wang, Muhui Jiang, Rui Chang, Yajin Zhou, Baolei Hou, Xiapu Luo, Lei Wu, Kui Ren",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.14298"" target=""_blank"">2105.14298</a>",,2025-12-03 22:39:25
Fooling Partial Dependence via Data Poisoning,"Hubert Baniecki, Wojciech Kretowicz, Przemyslaw Biecek",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.12837"" target=""_blank"">2105.12837</a>",,2025-12-03 22:39:25
Preventing Machine Learning Poisoning Attacks Using Authentication and Provenance,"Jack W. Stokes, Paul England, Kevin Kane",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.10051"" target=""_blank"">2105.10051</a>",,2025-12-03 22:39:25
Securing Optical Networks using Quantum-secured Blockchain: An Overview,"Purva Sharma, Vimal Bhatia, Shashi Prakash",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.10663"" target=""_blank"">2105.10663</a>",,2025-12-03 22:39:25
ReLUSyn: Synthesizing Stealthy Attacks for Deep Neural Network Based Cyber-Physical Systems,"Aarti Kashyap, Syed Mubashir Iqbal, Karthik Pattabiraman, Margo Seltzer",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.10393"" target=""_blank"">2105.10393</a>",,2025-12-03 22:39:25
Exploring Misclassifications of Robust Neural Networks to Enhance Adversarial Attacks,"Leo Schwinn, René Raab, An Nguyen, Dario Zanca, Bjoern Eskofier",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.10304"" target=""_blank"">2105.10304</a>",,2025-12-03 22:39:25
Backdoor Attacks on Self-Supervised Learning,"Aniruddha Saha, Ajinkya Tejankar, Soroush Abbasi Koohpayegani, Hamed Pirsiavash",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.10123"" target=""_blank"">2105.10123</a>","<a href=""https://github.com/UMBCvision/SSL-Backdoor"" target=""_blank"">UMBCvision</a>",2025-12-03 22:39:25
Explainable Enterprise Credit Rating via Deep Feature Crossing Network,"Weiyu Guo, Zhijiang Yang, Shu Wu, Fu Chen",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.13843"" target=""_blank"">2105.13843</a>",,2025-12-03 22:39:25
Anomaly Detection of Adversarial Examples using Class-conditional Generative Adversarial Networks,"Hang Wang, David J. Miller, George Kesidis",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.10101"" target=""_blank"">2105.10101</a>",,2025-12-03 22:39:25
TestRank: Bringing Order into Unlabeled Test Instances for Deep Learning Tasks,"Yu Li, Min Li, Qiuxia Lai, Yannan Liu, Qiang Xu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.10113"" target=""_blank"">2105.10113</a>",,2025-12-03 22:39:25
Adversarial Attacks and Mitigation for Anomaly Detectors of Cyber-Physical Systems,"Yifan Jia, Jingyi Wang, Christopher M. Poskitt, Sudipta Chattopadhyay, Jun Sun, Yuqi Chen",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.10707"" target=""_blank"">2105.10707</a>",,2025-12-03 22:39:25
Attack on practical speaker verification system using universal adversarial perturbations,"Weiyi Zhang, Shuning Zhao, Le Liu, Jianmin Li, Xingliang Cheng, Thomas Fang Zheng, Xiaolin Hu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.09022"" target=""_blank"">2105.09022</a>",,2025-12-03 22:39:25
Local Aggressive Adversarial Attacks on 3D Point Cloud,"Yiming Sun, Feng Chen, Zhiyu Chen, Mingjie Wang",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.09090"" target=""_blank"">2105.09090</a>",,2025-12-03 22:39:25
An Orthogonal Classifier for Improving the Adversarial Robustness of Neural Networks,"Cong Xu, Xiang Li, Min Yang",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.09109"" target=""_blank"">2105.09109</a>","<a href=""https://github.com/MTandHJ/roboc"" target=""_blank"">MTandHJ</a>",2025-12-03 22:39:25
Balancing Robustness and Sensitivity using Feature Contrastive Learning,"Seungyeon Kim, Daniel Glasner, Srikumar Ramalingam, Cho-Jui Hsieh, Kishore Papineni, Sanjiv Kumar",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.09394"" target=""_blank"">2105.09394</a>",,2025-12-03 22:39:25
Practical Convex Formulation of Robust One-hidden-layer Neural Network Training,"Yatong Bai, Tanmay Gautam, Yu Gai, Somayeh Sojoudi",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.12237"" target=""_blank"">2105.12237</a>",,2025-12-03 22:39:25
DeepStrike: Remotely-Guided Fault Injection Attacks on DNN Accelerator in Cloud-FPGA,"Yukui Luo, Cheng Gongye, Yunsi Fei, Xiaolin Xu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.09453"" target=""_blank"">2105.09453</a>",,2025-12-03 22:39:25
Exploring Robustness of Unsupervised Domain Adaptation in Semantic Segmentation,"Jinyu Yang, Chunyuan Li, Weizhi An, Hehuan Ma, Yuzhi Guo, Yu Rong, Peilin Zhao, Junzhou Huang",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.10843"" target=""_blank"">2105.10843</a>",,2025-12-03 22:39:25
Intriguing Properties of Vision Transformers,"Muzammal Naseer, Kanchana Ranasinghe, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, Ming-Hsuan Yang",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.10497"" target=""_blank"">2105.10497</a>",,2025-12-03 22:39:25
Regularization Can Help Mitigate Poisoning Attacks,"Javier Carnerero-Cano, Luis Muñoz-González, Phillippa Spencer, Emil C. Lupu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.10948"" target=""_blank"">2105.10948</a>",,2025-12-03 22:39:25
Out-of-Distribution Detection in Dermatology using Input Perturbation and Subset Scanning,"Hannah Kim, Girmaw Abebe Tadesse, Celia Cintas, Skyler Speakman, Kush Varshney",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.11160"" target=""_blank"">2105.11160</a>",,2025-12-03 22:39:25
Adversarial Attack Driven Data Augmentation for Accurate And Robust Medical Image Segmentation,"Mst. Tasnim Pervin, Linmi Tao, Aminul Huq, Zuoxiang He, Li Huo",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.12106"" target=""_blank"">2105.12106</a>",,2025-12-03 22:39:25
CMUA-Watermark: A Cross-Model Universal Adversarial Watermark for Combating Deepfakes,"Hao Huang, Yongtao Wang, Zhaoyu Chen, Yuheng Li, Zhi Tang, Wei Chu, Jingdong Chen, Weisi Lin, Kai-Kuang Ma",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.10872"" target=""_blank"">2105.10872</a>",,2025-12-03 22:39:25
Robust Value Iteration for Continuous Control Tasks,"Michael Lutter, Shie Mannor, Jan Peters, Dieter Fox, Animesh Garg",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.12189"" target=""_blank"">2105.12189</a>",,2025-12-03 22:39:25
OFEI: A Semi-black-box Android Adversarial Sample Attack Framework Against DLaaS,"Guangquan Xu, GuoHua Xin, Litao Jiao, Jian Liu, Shaoying Liu, Meiqi Feng, Xi Zheng",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.11593"" target=""_blank"">2105.11593</a>",,2025-12-03 22:39:25
Learning Security Classifiers with Verified Global Robustness Properties,"Yizheng Chen, Shiqi Wang, Yue Qin, Xiaojing Liao, Suman Jana, David Wagner",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.11363"" target=""_blank"">2105.11363</a>",,2025-12-03 22:39:25
Feature Space Targeted Attacks by Statistic Alignment,"Lianli Gao, Yaya Cheng, Qilong Zhang, Xing Xu, Jingkuan Song",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.11645"" target=""_blank"">2105.11645</a>","<a href=""https://github.com/yaya-cheng/PAA-GAA"" target=""_blank"">yaya-cheng</a>",2025-12-03 22:39:25
Improved OOD Generalization via Adversarial Training and Pre-training,"Mingyang Yi, Lu Hou, Jiacheng Sun, Lifeng Shang, Xin Jiang, Qun Liu, Zhi-Ming Ma",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.11144"" target=""_blank"">2105.11144</a>",,2025-12-03 22:39:25
Honest-but-Curious Nets: Sensitive Attributes of Private Inputs Can Be Secretly Coded into the Classifiers' Outputs,"Mohammad Malekzadeh, Anastasia Borovykh, Deniz Gündüz",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.12049"" target=""_blank"">2105.12049</a>",,2025-12-03 22:39:25
AirNet: Neural Network Transmission over the Air,"Mikolaj Jankowski, Deniz Gunduz, Krystian Mikolajczyk",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.11166"" target=""_blank"">2105.11166</a>",,2025-12-03 22:39:25
Using Adversarial Attacks to Reveal the Statistical Bias in Machine Reading Comprehension Models,"Jieyu Lin, Jiajie Zou, Nai Ding",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.11136"" target=""_blank"">2105.11136</a>",,2025-12-03 22:39:25
Dissecting Click Fraud Autonomy in the Wild,"Tong Zhu, Yan Meng, Haotian Hu, Xiaokuan Zhang, Minhui Xue, Haojin Zhu",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.11103"" target=""_blank"">2105.11103</a>",,2025-12-03 22:39:25
Killing Two Birds with One Stone: Stealing Model and Inferring Attribute from BERT-based APIs,"Lingjuan Lyu, Xuanli He, Fangzhao Wu, Lichao Sun",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.10909"" target=""_blank"">2105.10909</a>",,2025-12-03 22:39:25
Every Byte Matters: Traffic Analysis of Bluetooth Wearable Devices,"Ludovic Barman, Alexandre Dumur, Apostolos Pyrgelis, Jean-Pierre Hubaux",arXiv,2021-05,"<a href=""http://arxiv.org/abs/2105.11172"" target=""_blank"">2105.11172</a>",,2025-12-03 22:39:25
Explainability-based Backdoor Attacks Against Graph Neural Networks,"Jing Jason Xu, Jason Minhui, Xue, Stjepan Picek",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.03674"" target=""_blank"">2104.03674</a>",,2025-12-03 22:39:25
Disentangled Contrastive Learning for Learning Robust Textual Representations,"Xiang Chen, Xin Xie, Zhen Bi, Hongbin Ye, Shumin Deng, Ningyu Zhang, Huajun Chen",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.04907"" target=""_blank"">2104.04907</a>","<a href=""https://github.com/zxlzr/DCL"" target=""_blank"">zxlzr</a>",2025-12-03 22:39:25
Relating Adversarially Robust Generalization to Flat Minima,"David Stutz, Matthias Hein, Bernt Schiele",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.04448"" target=""_blank"">2104.04448</a>",,2025-12-03 22:39:25
SPoTKD: A Protocol for Symmetric Key Distribution over Public Channels Using Self-Powered Timekeeping Devices,"Mustafizur Rahman, Liang Zhou, Shantanu Chakrabartty",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.04553"" target=""_blank"">2104.04553</a>",,2025-12-03 22:39:25
Are Multilingual BERT models robust? A Case Study on Adversarial Attacks for Multilingual Question Answering,"Sara Rosenthal, Mihaela Bornea, Avirup Sil",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.07646"" target=""_blank"">2104.07646</a>",,2025-12-03 22:39:25
Learning Sampling Policy for Faster Derivative Free Optimization,"Zhou Zhai, Bin Gu, Heng Huang",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.04405"" target=""_blank"">2104.04405</a>",,2025-12-03 22:39:25
FACESEC: A Fine-grained Robustness Evaluation Framework for Face Recognition Systems,"Liang Tong, Zhengzhang Chen, Jingchao Ni, Wei Cheng, Dongjin Song, Haifeng Chen, Yevgeniy Vorobeychik",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.04107"" target=""_blank"">2104.04107</a>",,2025-12-03 22:39:25
Universal Adversarial Training with Class-Wise Perturbations,"Philipp Benz, Chaoning Zhang, Adil Karjauv, In So Kweon",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.03000"" target=""_blank"">2104.03000</a>",,2025-12-03 22:39:25
A single gradient step finds adversarial examples on random two-layers neural networks,"Sébastien Bubeck, Yeshwanth Cherapanamjeri, Gauthier Gidel, Rémi Tachet des Combes",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.03863"" target=""_blank"">2104.03863</a>",,2025-12-03 22:39:25
Adversarial Learning Inspired Emerging Side-Channel Attacks and Defenses,Abhijitt Dhavlle,arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.04054"" target=""_blank"">2104.04054</a>",,2025-12-03 22:39:25
The art of defense: letting networks fool the attacker,"Jinlai Zhang, Yinpeng Dong, Binbin Liu, Bo Ouyang, Jihong Zhu, Minchi Kuang, Houqing Wang, Yanmei Meng",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.02963"" target=""_blank"">2104.02963</a>","<a href=""https://github.com/cuge1995/IT-Defense"" target=""_blank"">cuge1995</a>",2025-12-03 22:39:25
Universal Spectral Adversarial Attacks for Deformable Shapes,"Arianna Rampini, Franco Pestarini, Luca Cosmo, Simone Melzi, Emanuele Rodolà",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.03356"" target=""_blank"">2104.03356</a>",,2025-12-03 22:39:25
Rethinking the Backdoor Attacks' Triggers: A Frequency Perspective,"Yi Zeng, Won Park, Z. Morley Mao, Ruoxi Jia",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.03413"" target=""_blank"">2104.03413</a>",,2025-12-03 22:39:25
Adversarial Robustness Guarantees for Gaussian Processes,"Andrea Patane, Arno Blaas, Luca Laurenti, Luca Cardelli, Stephen Roberts, Marta Kwiatkowska",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.03180"" target=""_blank"">2104.03180</a>",,2025-12-03 22:39:25
Fool Me Twice: Entailment from Wikipedia Gamification,"Julian Martin Eisenschlos, Bhuwan Dhingra, Jannis Bulian, Benjamin Börschinger, Jordan Boyd-Graber",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.04725"" target=""_blank"">2104.04725</a>",,2025-12-03 22:39:25
Adversarial Regularization as Stackelberg Game: An Unrolled Optimization Approach,"Simiao Zuo, Chen Liang, Haoming Jiang, Xiaodong Liu, Pengcheng He, Jianfeng Gao, Weizhu Chen, Tuo Zhao",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.04886"" target=""_blank"">2104.04886</a>",,2025-12-03 22:39:25
Meaningful Adversarial Stickers for Face Recognition in Physical World,"Ying Guo, Xingxing Wei, Guoqiu Wang, Bo Zhang",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.06728"" target=""_blank"">2104.06728</a>",,2025-12-03 22:39:25
Distributed Estimation over Directed Graphs Resilient to Sensor Spoofing,"Shamik Bhattacharyya, Kiran Rokade, Rachel Kalpana Kalaimani",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.04680"" target=""_blank"">2104.04680</a>",,2025-12-03 22:39:25
Pay attention to your loss: understanding misconceptions about 1-Lipschitz neural networks,"Louis Béthune, Thibaut Boissin, Mathieu Serrurier, Franck Mamalet, Corentin Friedrich, Alberto González-Sanz",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.05097"" target=""_blank"">2104.05097</a>",,2025-12-03 22:39:25
Achieving Model Robustness through Discrete Adversarial Training,"Maor Ivgi, Jonathan Berant",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.05062"" target=""_blank"">2104.05062</a>",,2025-12-03 22:39:25
"Thief, Beware of What Get You There: Towards Understanding Model Extraction Attack","Xinyi Zhang, Chengfang Fang, Jie Shi",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.05921"" target=""_blank"">2104.05921</a>",,2025-12-03 22:39:25
Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,"Chong Zhang, Jieyu Zhao, Huan Zhang, Kai-Wei Chang, Cho-Jui Hsieh",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.05232"" target=""_blank"">2104.05232</a>","<a href=""https://github.com/chong-z/nlp-second-order-attack"" target=""_blank"">chong-z</a>",2025-12-03 22:39:25
Plot-guided Adversarial Example Construction for Evaluating Open-domain Story Generation,"Sarik Ghazarian, Zixi Liu, Akash SM, Ralph Weischedel, Aram Galstyan, Nanyun Peng",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.05801"" target=""_blank"">2104.05801</a>",,2025-12-03 22:39:25
A Backdoor Attack against 3D Point Cloud Classifiers,"Zhen Xiang, David J. Miller, Siheng Chen, Xi Li, George Kesidis",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.05808"" target=""_blank"">2104.05808</a>",,2025-12-03 22:39:25
Sparse Coding Frontend for Robust Neural Networks,"Can Bakiskan, Metehan Cekic, Ahmet Dundar Sezer, Upamanyu Madhow",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.05353"" target=""_blank"">2104.05353</a>",,2025-12-03 22:39:25
Fall of Giants: How popular text-based MLaaS fall against a simple evasion attack,"Luca Pajola, Mauro Conti",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.05996"" target=""_blank"">2104.05996</a>",,2025-12-03 22:39:25
Detecting Operational Adversarial Examples for Reliable Deep Learning,"Xingyu Zhao, Wei Huang, Sven Schewe, Yi Dong, Xiaowei Huang",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.06015"" target=""_blank"">2104.06015</a>",,2025-12-03 22:39:25
Mitigating Adversarial Attack for Compute-in-Memory Accelerator Utilizing On-chip Finetune,"Shanshi Huang, Hongwu Jiang, Shimeng Yu",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.06377"" target=""_blank"">2104.06377</a>",,2025-12-03 22:39:25
Improved Branch and Bound for Neural Network Verification via Lagrangian Decomposition,"Palma Alessandro De, Rudy Bunel, Alban Desmaison, Krishnamurthy Dvijotham, Pushmeet Kohli, Philip H. S. Torr, M. Pawan Kumar",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.06718"" target=""_blank"">2104.06718</a>",,2025-12-03 22:39:25
Defending Against Adversarial Denial-of-Service Data Poisoning Attacks,"Nicolas M. Müller, Simon Roschmann, Konstantin Böttinger",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.06744"" target=""_blank"">2104.06744</a>",,2025-12-03 22:39:25
Orthogonalizing Convolutional Layers with the Cayley Transform,"Asher Trockman, J. Zico Kolter",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.07167"" target=""_blank"">2104.07167</a>","<a href=""https://github.com/locuslab/orthogonal-convolutions"" target=""_blank"">locuslab</a>",2025-12-03 22:39:25
Sparse Oblique Decision Trees: A Tool to Understand and Manipulate Neural Net Features,"Suryabhan Singh Hada, Miguel Á. Carreira-Perpiñán, Arman Zharmagambetov",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.02922"" target=""_blank"">2104.02922</a>",,2025-12-03 22:39:25
Improving Robustness of Deep Reinforcement Learning Agents: Environment Attacks based on Critic Networks,"Lucas Schott, Manon Césaire, Hatem Hajri, Sylvain Lamprier",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.03154"" target=""_blank"">2104.03154</a>",,2025-12-03 22:39:25
On the Robustness of Vision Transformers to Adversarial Examples,"Kaleel Mahmood, Rigel Mahmood, Dijk Marten van",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.02610"" target=""_blank"">2104.02610</a>",,2025-12-03 22:39:25
An Object Detection based Solver for Google's Image reCAPTCHA v2,"Md Imran Hossen, Yazhou Tu, Md Fazle Rabby, Md Nazmul Islam, Hui Cao, Xiali Hei",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.03366"" target=""_blank"">2104.03366</a>",,2025-12-03 22:39:25
Gradient-based Adversarial Deep Modulation Classification with Data-driven Subsampling,"Jinho Yi, Aly El Gamal",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.06375"" target=""_blank"">2104.06375</a>",,2025-12-03 22:39:25
Too Expensive to Attack: A Joint Defense Framework to Mitigate Distributed Attacks for the Internet of Things Grid,"Jianhua Li, Ximeng Liu, Jiong Jin, Shui Yu",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.00236"" target=""_blank"">2104.00236</a>",,2025-12-03 22:39:25
Fast Jacobian-Vector Product for Deep Networks,"Randall Balestriero, Richard Baraniuk",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.00219"" target=""_blank"">2104.00219</a>",,2025-12-03 22:39:25
Adversarial Heart Attack: Neural Networks Fooled to Segment Heart Symbols in Chest X-Ray Images,"Gerda Bortsova, Florian Dubost, Laurens Hogeweg, Ioannis Katramados, Bruijne Marleen de",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.00139"" target=""_blank"">2104.00139</a>",,2025-12-03 22:39:25
Learning from Noisy Labels via Dynamic Loss Thresholding,"Hao Yang, Youzhi Jin, Ziyin Li, Deng-Bao Wang, Lei Miao, Xin Geng, Min-Ling Zhang",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.02570"" target=""_blank"">2104.02570</a>",,2025-12-03 22:39:25
Augmenting Zero Trust Architecture to Endpoints Using Blockchain: A Systematic Review,"Lampis Alevizos, Vinh Thong Ta, Max Hashem Eiza",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.00460"" target=""_blank"">2104.00460</a>",,2025-12-03 22:39:25
Towards Evaluating and Training Verifiably Robust Neural Networks,"Zhaoyang Lyu, Minghao Guo, Tong Wu, Guodong Xu, Kehuan Zhang, Dahua Lin",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.00447"" target=""_blank"">2104.00447</a>","<a href=""https://github.com/ZhaoyangLyu/VerifiablyRobustNN"" target=""_blank"">ZhaoyangLyu</a>",2025-12-03 22:39:25
Normal vs,"Luoqiu Li, Xiang Chen, Ningyu Zhang, Shumin Deng, Xin Xie, Chuanqi Tan, Mosha Chen, Fei Huang, Huajun Chen",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.00312"" target=""_blank"">2104.00312</a>",,2025-12-03 22:39:25
Domain Invariant Adversarial Learning,"Matan Levi, Idan Attias, Aryeh Kontorovich",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.00322"" target=""_blank"">2104.00322</a>",,2025-12-03 22:39:25
TRS: Transferability Reduced Ensemble via Encouraging Gradient Diversity and Model Smoothness,"Zhuolin Yang, Linyi Li, Xiaojun Xu, Shiliang Zuo, Qian Chen, Benjamin Rubinstein, Pan Zhou, Ce Zhang, Bo Li",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.00671"" target=""_blank"">2104.00671</a>",,2025-12-03 22:39:25
Fast-adapting and Privacy-preserving Federated Recommender System,"Qinyong Wang, Hongzhi Yin, Tong Chen, Junliang Yu, Alexander Zhou, Xiangliang Zhang",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.00919"" target=""_blank"">2104.00919</a>",,2025-12-03 22:39:25
Diverse Gaussian Noise Consistency Regularization for Robustness and Uncertainty Calibration under Noise Domain Shifts,"Athanasios Tsiligkaridis, Theodoros Tsiligkaridis",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.01231"" target=""_blank"">2104.01231</a>",,2025-12-03 22:39:25
RABA: A Robust Avatar Backdoor Attack on Deep Neural Network,"Ying He, Zhili Shen, Chang Xia, Jingyu Hua, Wei Tong, Sheng Zhong",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.01026"" target=""_blank"">2104.01026</a>",,2025-12-03 22:39:25
Defending Against Image Corruptions Through Adversarial Augmentations,"Dan A. Calian, Florian Stimberg, Olivia Wiles, Sylvestre-Alvise Rebuffi, Andras Gyorgy, Timothy Mann, Sven Gowal",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.01086"" target=""_blank"">2104.01086</a>",,2025-12-03 22:39:25
Property-driven Training: All You (N)Ever Wanted to Know About,"Marco Casadio, Matthew Daggitt, Ekaterina Komendantskaya, Wen Kokke, Daniel Kienitz, Rob Stewart",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.01396"" target=""_blank"">2104.01396</a>",,2025-12-03 22:39:25
Mitigating Gradient-based Adversarial Attacks via Denoising and Compression,"Rehana Mahfuz, Rajeev Sahay, Aly El Gamal",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.01494"" target=""_blank"">2104.01494</a>",,2025-12-03 22:39:25
Exploring Targeted Universal Adversarial Perturbations to End-to-end ASR Models,"Zhiyun Lu, Wei Han, Yu Zhang, Liangliang Cao",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.02757"" target=""_blank"">2104.02757</a>",,2025-12-03 22:39:25
Reliably fast adversarial training via latent adversarial perturbation,"Geon Yeong Park, Sang Wan Lee",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.01575"" target=""_blank"">2104.01575</a>",,2025-12-03 22:39:25
Semantically Stealthy Adversarial Attacks against Segmentation Models,"Zhenhua Chen, Chuhua Wang, David J. Crandall",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.01732"" target=""_blank"">2104.01732</a>",,2025-12-03 22:39:25
Rethinking Perturbations in Encoder-Decoders for Fast Training,"Sho Takase, Shun Kiyono",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.01853"" target=""_blank"">2104.01853</a>","<a href=""https://github.com/takase/rethink_perturbations"" target=""_blank"">takase</a>",2025-12-03 22:39:25
Beyond Categorical Label Representations for Image Classification,"Boyuan Chen, Yu Li, Sunand Raghupathi, Hod Lipson",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.02226"" target=""_blank"">2104.02226</a>",,2025-12-03 22:39:25
Unified Detection of Digital and Physical Face Attacks,"Debayan Deb, Xiaoming Liu, Anil K. Jain",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.02156"" target=""_blank"">2104.02156</a>",,2025-12-03 22:39:25
Jekyll: Attacking Medical Image Diagnostics using Deep Generative Models,"Neal Mangaokar, Jiameng Pu, Parantapa Bhattacharya, Chandan K. Reddy, Bimal Viswanath",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.02107"" target=""_blank"">2104.02107</a>",,2025-12-03 22:39:25
Can audio-visual integration strengthen robustness under multimodal attacks? (68%),"Yapeng Tian, Chenliang Xu",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.02000"" target=""_blank"">2104.02000</a>",,2025-12-03 22:39:25
Deep Learning-Based Autonomous Driving Systems: A Survey of Attacks and Defenses,"Yao Deng, Tiehua Zhang, Guannan Lou, Xi Zheng, Jiong Jin, Qing-Long Han",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.01789"" target=""_blank"">2104.01789</a>",,2025-12-03 22:39:25
BBAEG: Towards BERT-based Biomedical Adversarial Example Generation for Text Classification,Ishani Mondal,arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.01782"" target=""_blank"">2104.01782</a>",,2025-12-03 22:39:25
Adaptive Clustering of Robust Semantic Representations for Adversarial Image Purification,"Samuel Henrique Silva, Arun Das, Ian Scarff, Peyman Najafirad",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.02155"" target=""_blank"">2104.02155</a>",,2025-12-03 22:39:25
Robust Classification Under $\ell_0$ Attack for the Gaussian Mixture Model,"Payam Delgosha, Hamed Hassani, Ramtin Pedarsani",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.02189"" target=""_blank"">2104.02189</a>",,2025-12-03 22:39:25
Backdoor Attack in the Physical World,"Yiming Li, Tongqing Zhai, Yong Jiang, Zhifeng Li, Shu-Tao Xia",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.02361"" target=""_blank"">2104.02361</a>",,2025-12-03 22:39:25
Robust Adversarial Classification via Abstaining,"Abed AlRahman Al Makdah, Vaibhav Katewa, Fabio Pasqualetti",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.02334"" target=""_blank"">2104.02334</a>",,2025-12-03 22:39:25
Adversarial Robustness under Long-Tailed Distribution,"Tong Wu, Ziwei Liu, Qingqiu Huang, Yu Wang, Dahua Lin",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.02703"" target=""_blank"">2104.02703</a>","<a href=""https://github.com/wutong16/Adversarial_Long-Tail"" target=""_blank"">wutong16</a>",2025-12-03 22:39:25
Federated Learning for Malware Detection in IoT Devices,"Valerian Rey, Pedro Miguel Sánchez Sánchez, Alberto Huertas Celdrán, Gérôme Bovet, Martin Jaggi",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.09994"" target=""_blank"">2104.09994</a>",,2025-12-03 22:39:25
Reversible Watermarking in Deep Convolutional Neural Networks for Integrity Authentication,"Xiquan Guan, Huamin Feng, Weiming Zhang, Hang Zhou, Jie Zhang, Nenghai Yu",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.04268"" target=""_blank"">2104.04268</a>",,2025-12-03 22:39:25
Robust Backdoor Attacks against Deep Neural Networks in Real Physical World,"Mingfu Xue, Can He, Shichang Sun, Jian Wang, Weiqiang Liu",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.07395"" target=""_blank"">2104.07395</a>",,2025-12-03 22:39:25
Theoretical Study of Random Noise Defense against Query-Based Black-Box Attacks,"Zeyu Qin, Yanbo Fan, Hongyuan Zha, Baoyuan Wu",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.11470"" target=""_blank"">2104.11470</a>",,2025-12-03 22:39:25
"Good Artists Copy, Great Artists Steal: Model Extraction Attacks Against Image Translation Generative Adversarial Networks","Sebastian Szyller, Vasisht Duddu, Tommi Gröndahl, N. Asokan",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.12623"" target=""_blank"">2104.12623</a>",,2025-12-03 22:39:25
Impact of Spatial Frequency Based Constraints on Adversarial Robustness,"Rémi Bernhard, Pierre-Alain Moellic, Martial Mermillod, Yannick Bourrier, Romain Cohendet, Miguel Solinas, Marina Reyboz",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.12679"" target=""_blank"">2104.12679</a>",,2025-12-03 22:39:25
PatchGuard++: Efficient Provable Attack Detection against Adversarial Patches,"Chong Xiang, Prateek Mittal",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.12609"" target=""_blank"">2104.12609</a>",,2025-12-03 22:39:25
3D Adversarial Attacks Beyond Point Cloud,"Jinlai Zhang, Lyujie Chen, Binbin Liu, Bo Ouyang, Qizhi Xie, Jihong Zhu, Weiming Li, Yanmei Meng",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.12146"" target=""_blank"">2104.12146</a>","<a href=""https://github.com/cuge1995/Mesh-Attack"" target=""_blank"">cuge1995</a>",2025-12-03 22:39:25
Making Generated Images Hard To Spot: A Transferable Attack On Synthetic Image Detectors,"Xinwei Zhao, Matthew C. Stamm",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.12069"" target=""_blank"">2104.12069</a>",,2025-12-03 22:39:25
Influence Based Defense Against Data Poisoning Attacks in Online Learning,"Sanjay Seetharaman, Shubham Malaviya, Rosni KV, Manish Shukla, Sachin Lodha",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.13230"" target=""_blank"">2104.13230</a>",,2025-12-03 22:39:25
Evaluating Deception Detection Model Robustness To Linguistic Variation,"Maria Glenski, Ellyn Ayton, Robin Cosbey, Dustin Arendt, Svitlana Volkova",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.11729"" target=""_blank"">2104.11729</a>",,2025-12-03 22:39:25
Dual Head Adversarial Training,"Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, James Bailey",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.10377"" target=""_blank"">2104.10377</a>",,2025-12-03 22:39:25
Lightweight Detection of Out-of-Distribution and Adversarial Samples via Channel Mean Discrepancy,"Xin Dong, Junfeng Guo, Wei-Te Ting, H. T. Kung",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.11408"" target=""_blank"">2104.11408</a>",,2025-12-03 22:39:25
Improving Neural Silent Speech Interface Models by Adversarial Training,"Amin Honarmandi Shandiz, László Tóth, Gábor Gosztolya, Alexandra Markó, Tamás Gábor Csapó",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.11601"" target=""_blank"">2104.11601</a>",,2025-12-03 22:39:25
Towards Adversarial Patch Analysis and Certified Defense against Crowd Counting,"Qiming Wu, Zhikang Zou, Pan Zhou, Xiaoqing Ye, Binghui Wang, Ang Li",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.10868"" target=""_blank"">2104.10868</a>",,2025-12-03 22:39:25
Learning Transferable 3D Adversarial Cloaks for Deep Trained Detectors,"Arman Maesumi, Mingkang Zhu, Yi Wang, Tianlong Chen, Zhangyang Wang, Chandrajit Bajaj",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.11101"" target=""_blank"">2104.11101</a>",,2025-12-03 22:39:25
Performance Evaluation of Adversarial Attacks: Discrepancies and Solutions,"Jing Wu, Mingyi Zhou, Ce Zhu, Yipeng Liu, Mehrtash Harandi, Li Li",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.11103"" target=""_blank"">2104.11103</a>",,2025-12-03 22:39:25
Operator Shifting for General Noisy Matrix Systems,"Philip Etter, Lexing Ying",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.11294"" target=""_blank"">2104.11294</a>",,2025-12-03 22:39:25
secml-malware: Pentesting Windows Malware Classifiers with Adversarial EXEmples in Python,"Luca Demetrio, Battista Biggio",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.12848"" target=""_blank"">2104.12848</a>","<a href=""https://github.com/pralab/secml_malware"" target=""_blank"">pralab</a>",2025-12-03 22:39:25
Delving into Data: Effectively Substitute Training for Black-box Attack,"Wenxuan Wang, Bangjie Yin, Taiping Yao, Li Zhang, Yanwei Fu, Shouhong Ding, Jilin Li, Feiyue Huang, Xiangyang Xue",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.12378"" target=""_blank"">2104.12378</a>",,2025-12-03 22:39:25
Launching Adversarial Attacks against Network Intrusion Detection Systems for IoT,"Pavlos Papadopoulos, Essen Oliver Thornewill von, Nikolaos Pitropakis, Christos Chrysoulas, Alexios Mylonas, William J. Buchanan",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.12426"" target=""_blank"">2104.12426</a>",,2025-12-03 22:39:25
Property Inference Attacks on Convolutional Neural Networks: Influence and Implications of Target Model's Complexity,"Mathias P. M. Parisot, Balazs Pejo, Dayana Spagnuelo",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.13061"" target=""_blank"">2104.13061</a>",,2025-12-03 22:39:25
Structure-Aware Hierarchical Graph Pooling using Information Bottleneck,"Kashob Kumar Roy, Amit Roy, A K M Mahbubur Rahman, M Ashraful Amin, Amin Ahsan Ali",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.13012"" target=""_blank"">2104.13012</a>",,2025-12-03 22:39:25
Improved and Efficient Text Adversarial Attacks using Target Information,"Mahmoud Hossam, Trung Le, He Zhao, Viet Huynh, Dinh Phung",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.13484"" target=""_blank"">2104.13484</a>",,2025-12-03 22:39:25
AdvHaze: Adversarial Haze Attack,"Ruijun Gao, Qing Guo, Felix Juefei-Xu, Hongkai Yu, Wei Feng",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.13673"" target=""_blank"">2104.13673</a>",,2025-12-03 22:39:25
Learning Robust Variational Information Bottleneck with Reference,"Weizhu Qian, Bowei Chen, Xiaowei Huang",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.14379"" target=""_blank"">2104.14379</a>",,2025-12-03 22:39:25
Analytical bounds on the local Lipschitz constants of ReLU networks,"Trevor Avant, Kristi A. Morgansen",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.14672"" target=""_blank"">2104.14672</a>",,2025-12-03 22:39:25
A neural anisotropic view of underspecification in deep learning,"Guillermo Ortiz-Jimenez, Itamar Franco Salazar-Reque, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.14372"" target=""_blank"">2104.14372</a>",,2025-12-03 22:39:25
GasHis-Transformer: A Multi-scale Visual Transformer Approach for Gastric Histopathology Image Classification,"Haoyuan Chen, Chen Li, Xiaoyan Li, Ge Wang, Weiming Hu, Yixin Li, Wanli Liu, Changhao Sun, Yudong Yao, Yueyang Teng, Marcin Grzegorzek",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.14528"" target=""_blank"">2104.14528</a>",,2025-12-03 22:39:25
FIPAC: Thwarting Fault- and Software-Induced Control-Flow Attacks with ARM Pointer Authentication,"Robert Schilling, Pascal Nasahl, Stefan Mangard",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.14993"" target=""_blank"">2104.14993</a>",,2025-12-03 22:39:25
DeFiRanger: Detecting Price Manipulation Attacks on DeFi Applications,"Siwei Wu, Dabao Wang, Jianting He, Yajin Zhou, Lei Wu, Xingliang Yuan, Qinming He, Kui Ren",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.15068"" target=""_blank"">2104.15068</a>",,2025-12-03 22:39:25
Gradient-based Adversarial Attacks against Text Transformers,"Chuan Guo, Alexandre Sablayrolles, Hervé Jégou, Douwe Kiela",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.13733"" target=""_blank"">2104.13733</a>",,2025-12-03 22:39:25
Black-box adversarial attacks using Evolution Strategies,"Hao Qiu, Leonardo Lucio Custode, Giovanni Iacca",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.15064"" target=""_blank"">2104.15064</a>",,2025-12-03 22:39:25
Black-box Gradient Attack on Graph Neural Networks: Deeper Insights in Graph-based Attack and Defense,"Haoxi Zhan, Xiaobing Pei",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.15061"" target=""_blank"">2104.15061</a>",,2025-12-03 22:39:25
Deep Image Destruction: A Comprehensive Study on Vulnerability of Deep Image-to-Image Models against Adversarial Attacks,"Jun-Ho Choi, Huan Zhang, Jun-Hyuk Kim, Cho-Jui Hsieh, Jong-Seok Lee",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.15022"" target=""_blank"">2104.15022</a>",,2025-12-03 22:39:25
SPECTRE: Defending Against Backdoor Attacks Using Robust Statistics,"Jonathan Hayase, Weihao Kong, Raghav Somani, Sewoong Oh",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.11315"" target=""_blank"">2104.11315</a>","<a href=""https://github.com/SewoongLab/spectre-defense"" target=""_blank"">SewoongLab</a>",2025-12-03 22:39:25
Metamorphic Detection of Repackaged Malware,"Shirish Singh, Gail Kaiser",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.13295"" target=""_blank"">2104.13295</a>",,2025-12-03 22:39:25
Mixture of Robust Experts (MoRE): A Flexible Defense Against Multiple Perturbations,"Kaidi Xu, Chenan Wang, Xue Lin, Bhavya Kailkhura, Ryan Goldhahn",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.10586"" target=""_blank"">2104.10586</a>",,2025-12-03 22:39:25
Improving Question Answering Model Robustness with Synthetic Adversarial Data Generation,"Max Bartolo, Tristan Thrush, Robin Jia, Sebastian Riedel, Pontus Stenetorp, Douwe Kiela",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.08678"" target=""_blank"">2104.08678</a>",,2025-12-03 22:39:25
Semi-Supervised Domain Adaptation with Prototypical Alignment and Consistency Learning,"Kai Li, Chang Liu, Handong Zhao, Yulun Zhang, Yun Fu",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.09136"" target=""_blank"">2104.09136</a>","<a href=""https://github.com/kailigo/pacl"" target=""_blank"">kailigo</a>",2025-12-03 22:39:25
"Best Practices for Noise-Based Augmentation to Improve the Performance of Emotion Recognition ""In the Wild""","Mimansa Jaiswal, Emily Mower Provost",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.08806"" target=""_blank"">2104.08806</a>",,2025-12-03 22:39:25
Making Attention Mechanisms More Robust and Interpretable with Virtual Adversarial Training,"Shunsuke Kitada, Hitoshi Iyatomi",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.08763"" target=""_blank"">2104.08763</a>",,2025-12-03 22:39:25
On the Sensitivity and Stability of Model Interpretations in NLP,"Fan Yin, Zhouxing Shi, Cho-Jui Hsieh, Kai-Wei Chang",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.08782"" target=""_blank"">2104.08782</a>",,2025-12-03 22:39:25
Attacking Text Classifiers via Sentence Rewriting Sampler,"Lei Xu, Kalyan Veeramachaneni",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.08453"" target=""_blank"">2104.08453</a>",,2025-12-03 22:39:25
Rethinking Image-Scaling Attacks: The Interplay Between Vulnerabilities in Machine Learning Systems,"Yue Gao, Ilia Shumailov, Kassem Fawaz",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.08690"" target=""_blank"">2104.08690</a>",,2025-12-03 22:39:25
AM2iCo: Evaluating Word Meaning in Context across Low-ResourceLanguages with Adversarial Examples,"Qianchu Liu, Edoardo M. Ponti, Diana McCarthy, Ivan Vulić, Anna Korhonen",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.08639"" target=""_blank"">2104.08639</a>",,2025-12-03 22:39:25
Provable Robustness of Adversarial Training for Learning Halfspaces with Noise,"Difan Zou, Spencer Frei, Quanquan Gu",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.09437"" target=""_blank"">2104.09437</a>",,2025-12-03 22:39:25
Fashion-Guided Adversarial Attack on Person Segmentation,"Marc Treu, Trung-Nghia Le, Huy H. Nguyen, Junichi Yamagishi, Isao Echizen",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.08422"" target=""_blank"">2104.08422</a>","<a href=""https://github.com/nii-yamagishilab/fashion_adv"" target=""_blank"">nii-yamagishilab</a>",2025-12-03 22:39:25
Towards Variable-Length Textual Adversarial Attacks,"Junliang Guo, Zhirui Zhang, Linlin Zhang, Linli Xu, Boxing Chen, Enhong Chen, Weihua Luo",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.08139"" target=""_blank"">2104.08139</a>",,2025-12-03 22:39:25
An Adversarially-Learned Turing Test for Dialog Generation Models,"Xiang Gao, Yizhe Zhang, Michel Galley, Bill Dolan",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.08231"" target=""_blank"">2104.08231</a>",,2025-12-03 22:39:25
Random and Adversarial Bit Error Robustness: Energy-Efficient and Secure DNN Accelerators,"David Stutz, Nandhini Chandramoorthy, Matthias Hein, Bernt Schiele",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.08323"" target=""_blank"">2104.08323</a>",,2025-12-03 22:39:25
Lower Bounds on Cross-Entropy Loss in the Presence of Test-time Adversaries,"Arjun Nitin Bhagoji, Daniel Cullina, Vikash Sehwag, Prateek Mittal",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.08382"" target=""_blank"">2104.08382</a>",,2025-12-03 22:39:25
Robust Certification for Laplace Learning on Geometric Graphs,"Matthew Thorpe, Bao Wang",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.10837"" target=""_blank"">2104.10837</a>",,2025-12-03 22:39:25
Protecting the Intellectual Properties of Deep Neural Networks with an Additional Class and Steganographic Images,"Shichang Sun, Mingfu Xue, Jian Wang, Weiqiang Liu",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.09203"" target=""_blank"">2104.09203</a>",,2025-12-03 22:39:25
Improving Zero-Shot Cross-Lingual Transfer Learning via Robust Training,"Kuan-Hao Huang, Wasi Uddin Ahmad, Nanyun Peng, Kai-Wei Chang",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.08645"" target=""_blank"">2104.08645</a>",,2025-12-03 22:39:25
Manipulating SGD with Data Ordering Attacks,"Ilia Shumailov, Zakhar Shumaylov, Dmitry Kazhdan, Yiren Zhao, Nicolas Papernot, Murat A. Erdogdu, Ross Anderson",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.09667"" target=""_blank"">2104.09667</a>",,2025-12-03 22:39:25
Robust Sensor Fusion Algorithms Against Voice Command Attacks in Autonomous Vehicles,"Jiwei Guan, Xi Zheng, Chen Wang, Yipeng Zhou, Alireza Jolfa",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.09872"" target=""_blank"">2104.09872</a>","<a href=""https://github.com/ITSEG-MQ/Sensor-Fusion-Against-VoiceCommand-Attacks"" target=""_blank"">ITSEG-MQ</a>",2025-12-03 22:39:25
Jacobian Regularization for Mitigating Universal Adversarial Perturbations,"Kenneth T. Co, David Martinez Rego, Emil C. Lupu",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.10459"" target=""_blank"">2104.10459</a>",,2025-12-03 22:39:25
Direction-Aggregated Attack for Transferable Adversarial Examples,"Tianjin Huang, Vlado Menkovski, Yulong Pei, YuHao Wang, Mykola Pechenizkiy",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.09172"" target=""_blank"">2104.09172</a>",,2025-12-03 22:39:25
Dataset Inference: Ownership Resolution in Machine Learning,"Pratyush Maini, Mohammad Yaghini, Nicolas Papernot",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.10706"" target=""_blank"">2104.10706</a>",,2025-12-03 22:39:25
Adversarial Training for Deep Learning-based Intrusion Detection Systems,"Islam Debicha, Thibault Debatty, Jean-Michel Dricot, Wim Mees",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.09852"" target=""_blank"">2104.09852</a>",,2025-12-03 22:39:25
MixDefense: A Defense-in-Depth Framework for Adversarial Example Detection Based on Statistical and Semantic Analysis,"Yijun Yang, Ruiyuan Gao, Yu Li, Qiuxia Lai, Qiang Xu",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.10076"" target=""_blank"">2104.10076</a>",,2025-12-03 22:39:25
Does enhanced shape bias improve neural network robustness to common corruptions? (26%),"Chaithanya Kumar Mummadi, Ranjitha Subramaniam, Robin Hutmacher, Julien Vitay, Volker Fischer, Jan Hendrik Metzen",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.09789"" target=""_blank"">2104.09789</a>",,2025-12-03 22:39:25
MagicPai at SemEval-2021 Task 7: Method for Detecting and Rating Humor Based on Multi-Task Adversarial Training,"Jian Ma, Shuyi Xie, Haiqin Yang, Lianxin Jiang, Mengyuan Zhou, Xiaoyi Ruan, Yang Mo",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.10336"" target=""_blank"">2104.10336</a>",,2025-12-03 22:39:25
Network Defense is Not a Game,"Andres Molina-Markham, Ransom K. Winder, Ahmad Ridley",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.10262"" target=""_blank"">2104.10262</a>",,2025-12-03 22:39:25
Staircase Sign Method for Boosting Adversarial Attacks,"Qilong Zhang, Xiaosu Zhu, Jingkuan Song, Lianli Gao, Heng Tao Shen",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.09722"" target=""_blank"">2104.09722</a>","<a href=""https://github.com/qilong-zhang/Staircase-sign-method"" target=""_blank"">qilong-zhang</a>",2025-12-03 22:39:25
Improving Adversarial Robustness Using Proxy Distributions,"Vikash Sehwag, Saeed Mahloujifar, Tinashe Handina, Sihui Dai, Chong Xiang, Mung Chiang, Prateek Mittal",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.09425"" target=""_blank"">2104.09425</a>",,2025-12-03 22:39:25
Adversarial Diffusion Attacks on Graph-based Traffic Prediction Models,"Lyuyi Zhu, Kairui Feng, Ziyuan Pu, Wei Ma",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.09369"" target=""_blank"">2104.09369</a>","<a href=""https://github.com/LYZ98/Adversarial-Diffusion-Attacks-on-Graph-based-Traffic-Prediction-Models"" target=""_blank"">LYZ98</a>",2025-12-03 22:39:25
LAFEAT: Piercing Through Adversarial Defenses with Latent Features,"Yunrui Yu, Xitong Gao, Cheng-Zhong Xu",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.09284"" target=""_blank"">2104.09284</a>",,2025-12-03 22:39:25
Removing Adversarial Noise in Class Activation Feature Space,"Dawei Zhou, Nannan Wang, Chunlei Peng, Xinbo Gao, Xiaoyu Wang, Jun Yu, Tongliang Liu",arXiv,2021-04,"<a href=""http://arxiv.org/abs/2104.09197"" target=""_blank"">2104.09197</a>",,2025-12-03 22:39:25
Revisiting Model's Uncertainty and Confidences for Adversarial Example Detection,"Ahmed Aldahdooh, Wassim Hamidouche, Olivier Déforges",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.05354"" target=""_blank"">2103.05354</a>",,2025-12-03 22:39:25
Improving Transformation-based Defenses against Adversarial Examples with First-order Perturbations,"Haimin Zhang, Min Xu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.04565"" target=""_blank"">2103.04565</a>",,2025-12-03 22:39:25
Practical Relative Order Attack in Deep Ranking,"Mo Zhou, Le Wang, Zhenxing Niu, Qilin Zhang, Yinghui Xu, Nanning Zheng, Gang Hua",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.05248"" target=""_blank"">2103.05248</a>",,2025-12-03 22:39:25
BASAR:Black-box Attack on Skeletal Action Recognition,"Yunfeng Diao, Tianjia Shao, Yong-Liang Yang, Kun Zhou, He Wang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.05266"" target=""_blank"">2103.05266</a>",,2025-12-03 22:39:25
Stabilized Medical Image Attacks,"Gege Qi, Lijun Gong, Yibing Song, Kai Ma, Yefeng Zheng",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.05232"" target=""_blank"">2103.05232</a>",,2025-12-03 22:39:25
Understanding the Robustness of Skeleton-based Action Recognition under Adversarial Attack,"He Wang, Feixiang He, Zhexi Peng, Tianjia Shao, Yong-Liang Yang, Kun Zhou, David Hogg",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.05347"" target=""_blank"">2103.05347</a>",,2025-12-03 22:39:25
Deep Learning for Android Malware Defenses: a Systematic Literature Review,"Yue Liu, Chakkrit Tantithamthavorn, Li Li, Yepang Liu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.05292"" target=""_blank"">2103.05292</a>",,2025-12-03 22:39:25
Robust Black-box Watermarking for Deep NeuralNetwork using Inverse Document Frequency,"Mohammad Mehdi Yadollahi, Farzaneh Shoeleh, Sajjad Dadkhah, Ali A. Ghorbani",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.05590"" target=""_blank"">2103.05590</a>",,2025-12-03 22:39:25
Towards Strengthening Deep Learning-based Side Channel Attacks with Mixup,"Zhimin Luo, Mengce Zheng, Ping Wang, Minhui Jin, Jiajia Zhang, Honggang Hu, Nenghai Yu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.05833"" target=""_blank"">2103.05833</a>",,2025-12-03 22:39:25
Packet-Level Adversarial Network Traffic Crafting using Sequence Generative Adversarial Networks,"Qiumei Cheng, Shiying Zhou, Yi Shen, Dezhang Kong, Chunming Wu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.04794"" target=""_blank"">2103.04794</a>",,2025-12-03 22:39:25
Detecting Adversarial Examples from Sensitivity Inconsistency of Spatial-Transform Domain,"Jinyu Tian, Jiantao Zhou, Yuanman Li, Jia Duan",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.04302"" target=""_blank"">2103.04302</a>",,2025-12-03 22:39:25
Contemplating real-world object classification,Ali Borji,arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.05137"" target=""_blank"">2103.05137</a>",,2025-12-03 22:39:25
Consistency Regularization for Adversarial Robustness,"Jihoon Tack, Sihyun Yu, Jongheon Jeong, Minseon Kim, Sung Ju Hwang, Jinwoo Shin",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.04623"" target=""_blank"">2103.04623</a>","<a href=""https://github.com/alinlab/consistency-adversarial"" target=""_blank"">alinlab</a>",2025-12-03 22:39:25
"Prime+Probe 1, JavaScript 0: Overcoming Browser-based Side-Channel Defenses","Anatoly Shusterman, Ayush Agarwal, Sioli O'Connell, Daniel Genkin, Yossi Oren, Yuval Yarom",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.04952"" target=""_blank"">2103.04952</a>",,2025-12-03 22:39:25
Deeply Unsupervised Patch Re-Identification for Pre-training Object Detectors,"Jian Ding, Enze Xie, Hang Xu, Chenhan Jiang, Zhenguo Li, Ping Luo, Gui-Song Xia",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.04814"" target=""_blank"">2103.04814</a>",,2025-12-03 22:39:25
Deep Model Intellectual Property Protection via Deep Watermarking,"Jie Zhang, Dongdong Chen, Jing Liao, Weiming Zhang, Huamin Feng, Gang Hua, Nenghai Yu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.04980"" target=""_blank"">2103.04980</a>",,2025-12-03 22:39:25
Universal Adversarial Perturbations and Image Spam Classifiers,"Andy Phung, Mark Stamp",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.05469"" target=""_blank"">2103.05469</a>",,2025-12-03 22:39:25
Improving Global Adversarial Robustness Generalization With Adversarially Trained GAN,"Desheng School of Electrical Engineering, Southwest Jiaotong University, Chengdu, P. R. China Wang, Weidong School of Electrical Engineering, Southwest Jiaotong University, Chengdu, P. R. China Jin, Yunpu School of Electrical Engineering, Southwest Jiaotong University, Chengdu, P. R. China Wu, Aamir School of Electrical Engineering, Southwest Jiaotong University, Chengdu, P. R. China Khan",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.04513"" target=""_blank"">2103.04513</a>",,2025-12-03 22:39:25
Insta-RS: Instance-wise Randomized Smoothing for Improved Robustness and Accuracy,"Chen Chen, Kezhi Kong, Peihong Yu, Juan Luque, Tom Goldstein, Furong Huang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.04436"" target=""_blank"">2103.04436</a>",,2025-12-03 22:39:25
VideoMoCo: Contrastive Video Representation Learning with Temporally Adversarial Examples,"Tian Pan, Yibing Song, Tianyu Yang, Wenhao Jiang, Wei Liu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.05905"" target=""_blank"">2103.05905</a>",,2025-12-03 22:39:25
Hidden Backdoor Attack against Semantic Segmentation Models,"Yiming Li, Yanjie Li, Yalei Lv, Yong Jiang, Shu-Tao Xia",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.04038"" target=""_blank"">2103.04038</a>",,2025-12-03 22:39:25
Fine-tuning of Pre-trained End-to-end Speech Recognition with Generative Adversarial Networks,"Md Akmal Haidar, Mehdi Rezagholizadeh",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.13329"" target=""_blank"">2103.13329</a>",,2025-12-03 22:39:25
Generating Unrestricted Adversarial Examples via Three Parameters,"Hanieh Naderi, Leili Goli, Shohreh Kasaei",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.07640"" target=""_blank"">2103.07640</a>",,2025-12-03 22:39:25
TANTRA: Timing-Based Adversarial Network Traffic Reshaping Attack,"Yam Sharon, David Berend, Yang Liu, Asaf Shabtai, Yuval Elovici",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.06297"" target=""_blank"">2103.06297</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness via Channel-wise Activation Suppressing,"Yang Bai, Yuyuan Zeng, Yong Jiang, Shu-Tao Xia, Xingjun Ma, Yisen Wang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.08307"" target=""_blank"">2103.08307</a>",,2025-12-03 22:39:25
Don't Forget to Sign the Gradients! (10%),"Omid Aramoon, Pin-Yu Chen, Gang Qu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.03701"" target=""_blank"">2103.03701</a>",,2025-12-03 22:39:25
Towards Robust Speech-to-Text Adversarial Attack,"Mohammad Esmaeilpour, Patrick Cardinal, Alessandro Lameiras Koerich",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.08095"" target=""_blank"">2103.08095</a>",,2025-12-03 22:39:25
BreakingBED -- Breaking Binary and Efficient Deep Neural Networks by Adversarial Attacks,"Manoj Rohit Vemparala, Alexander Frickenstein, Nael Fasfous, Lukas Frickenstein, Qi Zhao, Sabine Kuhn, Daniel Ehrhardt, Yuankai Wu, Christian Unger, Naveen Shankar Nagaraja, Walter Stechele",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.08031"" target=""_blank"">2103.08031</a>",,2025-12-03 22:39:25
Multi-Discriminator Sobolev Defense-GAN Against Adversarial Attacks for End-to-End Speech Systems,"Mohammad Esmaeilpour, Patrick Cardinal, Alessandro Lameiras Koerich",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.08086"" target=""_blank"">2103.08086</a>",,2025-12-03 22:39:25
Membership Inference Attacks on Machine Learning: A Survey,"Hongsheng Hu, Zoran Salcic, Lichao Sun, Gillian Dobbie, Philip S. Yu, Xuyun Zhang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.07853"" target=""_blank"">2103.07853</a>","<a href=""https://github.com/HongshengHu/membership-inference-machine-learning-literature"" target=""_blank"">HongshengHu</a>",2025-12-03 22:39:25
Attack as Defense: Characterizing Adversarial Examples using Robustness,"Zhe Zhao, Guangke Chen, Jingyi Wang, Yiwei Yang, Fu Song, Jun Sun",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.07633"" target=""_blank"">2103.07633</a>",,2025-12-03 22:39:25
Simeon -- Secure Federated Machine Learning Through Iterative Filtering,"Nicholas Malecki, Hye-young Paik, Aleksandar Ignjatovic, Alan Blair, Elisa Bertino",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.07704"" target=""_blank"">2103.07704</a>",,2025-12-03 22:39:25
Learning Defense Transformers for Counterattacking Adversarial Examples,"Jincheng Li, Jiezhang Cao, Yifan Zhang, Jian Chen, Mingkui Tan",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.07595"" target=""_blank"">2103.07595</a>",,2025-12-03 22:39:25
Internal Wasserstein Distance for Adversarial Attack and Defense,"Mingkui Tan, Shuhai Zhang, Jiezhang Cao, Jincheng Li, Yanwu Xu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.07598"" target=""_blank"">2103.07598</a>",,2025-12-03 22:39:25
A Unified Game-Theoretic Interpretation of Adversarial Robustness,"Jie Ren, Die Zhang, Yisen Wang, Lu Chen, Zhanpeng Zhou, Yiting Chen, Xu Cheng, Xin Wang, Meng Zhou, Jie Shi, Quanshi Zhang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.07364"" target=""_blank"">2103.07364</a>",,2025-12-03 22:39:25
Adversarial Machine Learning Security Problems for 6G: mmWave Beam Prediction Use-Case,"Evren Catak, Ferhat Ozgur Catak, Arild Moldsvor",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.07268"" target=""_blank"">2103.07268</a>",,2025-12-03 22:39:25
Network Environment Design for Autonomous Cyberdefense,"Andres Molina-Markham, Cory Miniter, Becky Powell, Ahmad Ridley",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.07583"" target=""_blank"">2103.07583</a>",,2025-12-03 22:39:25
Stochastic-HMDs: Adversarial Resilient Hardware Malware Detectors through Voltage Over-scaling,"Md Shohidul Islam, Ihsen Alouani, Khaled N. Khasawneh",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.06936"" target=""_blank"">2103.06936</a>",,2025-12-03 22:39:25
Beta-CROWN: Efficient Bound Propagation with Per-neuron Split Constraints for Complete and Incomplete Neural Network Verification,"Shiqi Wang, Huan Zhang, Kaidi Xu, Xue Lin, Suman Jana, Cho-Jui Hsieh, J. Zico Kolter",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.06624"" target=""_blank"">2103.06624</a>","<a href=""https://github.com/KaidiXu/Beta-CROWN"" target=""_blank"">KaidiXu</a>",2025-12-03 22:39:25
Adversarial Laser Beam: Effective Physical-World Attack to DNNs in a Blink,"Ranjie Duan, Xiaofeng Mao, A. K. Qin, Yun Yang, Yuefeng Chen, Shaokai Ye, Yuan He",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.06504"" target=""_blank"">2103.06504</a>",,2025-12-03 22:39:25
DAFAR: Detecting Adversaries by Feedback-Autoencoder Reconstruction,"Haowen Liu, Ping Yi, Hsiao-Ying Lin, Jie Shi",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.06487"" target=""_blank"">2103.06487</a>",,2025-12-03 22:39:25
ReinforceBug: A Framework to Generate Adversarial Textual Examples,"Bushra Sabir, M. Ali Babar, Raj Gaire",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.08306"" target=""_blank"">2103.08306</a>",,2025-12-03 22:39:25
Multi-Task Federated Reinforcement Learning with Adversaries,"Aqeel Anwar, Arijit Raychowdhury",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.06473"" target=""_blank"">2103.06473</a>",,2025-12-03 22:39:25
BODAME: Bilevel Optimization for Defense Against Model Extraction,"Yuto Mori, Atsushi Nitanda, Akiko Takeda",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.06797"" target=""_blank"">2103.06797</a>",,2025-12-03 22:39:25
"Cyber Threat Intelligence Model: An Evaluation of Taxonomies, Sharing Standards, and Ontologies within Cyber Threat Intelligence","Vasileios Mavroeidis, Siri Bromander",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.03530"" target=""_blank"">2103.03530</a>",,2025-12-03 22:39:25
"Counterfactual Explanations for Oblique Decision Trees: Exact, Efficient Algorithms","Miguel Á. Carreira-Perpiñán, Suryabhan Singh Hada",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.01096"" target=""_blank"">2103.01096</a>",,2025-12-03 22:39:25
Tor circuit fingerprinting defenses using adaptive padding,"George Kadianakis, Theodoros Polyzos, Mike Perry, Kostas Chatzikokolakis",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.03831"" target=""_blank"">2103.03831</a>",,2025-12-03 22:39:25
Am I a Real or Fake Celebrity? Measuring Commercial Face Recognition Web APIs under Deepfake Impersonation Attack,"Shahroz Tariq, Sowon Jeon, Simon S. Woo",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.00847"" target=""_blank"">2103.00847</a>",,2025-12-03 22:39:25
Group-wise Inhibition based Feature Regularization for Robust Classification,"Haozhe Liu, Haoqian Wu, Weicheng Xie, Feng Liu, Linlin Shen",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.02152"" target=""_blank"">2103.02152</a>","<a href=""https://github.com/LinusWu/TENET_Training"" target=""_blank"">LinusWu</a>",2025-12-03 22:39:25
DP-InstaHide: Provably Defusing Poisoning and Backdoor Attacks with Differentially Private Data Augmentations,"Eitan Borgnia, Jonas Geiping, Valeriia Cherepanova, Liam Fowl, Arjun Gupta, Amin Ghiasi, Furong Huang, Micah Goldblum, Tom Goldstein",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.02079"" target=""_blank"">2103.02079</a>",,2025-12-03 22:39:25
Dual Attention Suppression Attack: Generate Adversarial Camouflage in Physical World,"Jiakai Wang, Aishan Liu, Zixin Yin, Shunchang Liu, Shiyu Tang, Xianglong Liu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.01050"" target=""_blank"">2103.01050</a>",,2025-12-03 22:39:25
Brain Programming is Immune to Adversarial Attacks: Towards Accurate and Robust Image Classification using Symbolic Learning,"Gerardo Ibarra-Vazquez, Gustavo Olague, Mariana Chan-Ley, Cesar Puente, Carlos Soubervielle-Montalvo",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.01359"" target=""_blank"">2103.01359</a>",,2025-12-03 22:39:25
Smoothness Analysis of Adversarial Training,"Sekitoshi Kanai, Masanori Yamada, Hiroshi Takahashi, Yuki Yamanaka, Yasutoshi Ida",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.01400"" target=""_blank"">2103.01400</a>",,2025-12-03 22:39:25
Explaining Adversarial Vulnerability with a Data Sparsity Hypothesis,"Mahsa Paknezhad, Cuong Phuc Ngo, Amadeus Aristo Winarto, Alistair Cheong, Beh Chuen Yang, Wu Jiayang, Lee Hwee Kuan",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.00778"" target=""_blank"">2103.00778</a>","<a href=""https://github.com/MahsaPaknezhad/AdversariallyRobustTraining"" target=""_blank"">MahsaPaknezhad</a>",2025-12-03 22:39:25
Mind the box: $l_1$-APGD for sparse adversarial attacks on image classifiers,"Francesco Croce, Matthias Hein",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.01208"" target=""_blank"">2103.01208</a>",,2025-12-03 22:39:25
Adversarial training in communication constrained federated learning,"Devansh Shah, Parijat Dube, Supriyo Chakraborty, Ashish Verma",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.01319"" target=""_blank"">2103.01319</a>",,2025-12-03 22:39:25
Understanding invariance via feedforward inversion of discriminatively trained classifiers,"Piotr Teterwak, Chiyuan Zhang, Dilip Krishnan, Michael C. Mozer",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.07470"" target=""_blank"">2103.07470</a>",,2025-12-03 22:39:25
A Multiclass Boosting Framework for Achieving Fast and Provable Adversarial Robustness,"Jacob Abernethy, Pranjal Awasthi, Satyen Kale",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.01276"" target=""_blank"">2103.01276</a>",,2025-12-03 22:39:25
Hard-label Manifolds: Unexpected Advantages of Query Efficiency for Finding On-manifold Adversarial Examples,"Washington Garcia, Pin-Yu Chen, Somesh Jha, Scott Clouse, Kevin R. B. Butler",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.03325"" target=""_blank"">2103.03325</a>",,2025-12-03 22:39:25
Benchmarking Robustness of Deep Learning Classifiers Using Two-Factor Perturbation,"Wei Dai, Daniel Berleant",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.03102"" target=""_blank"">2103.03102</a>","<a href=""https://github.com/daiweiworking/RobustDeepLearningUsingPerturbations"" target=""_blank"">daiweiworking</a>",2025-12-03 22:39:25
Model-Agnostic Defense for Lane Detection against Adversarial Attack,"Henry Xu, An Ju, David Wagner",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.00663"" target=""_blank"">2103.00663</a>",,2025-12-03 22:39:25
Robust learning under clean-label attack,"Avrim Blum, Steve Hanneke, Jian Qian, Han Shao",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.00671"" target=""_blank"">2103.00671</a>",,2025-12-03 22:39:25
Effective Universal Unrestricted Adversarial Attacks using a MOE Approach,"A. E. Baia, Bari G. Di, V. Poggioni",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.00250"" target=""_blank"">2103.00250</a>",,2025-12-03 22:39:25
Tiny Adversarial Mulit-Objective Oneshot Neural Architecture Search,"Guoyang Xie, Jinbao Wang, Guo Yu, Feng Zheng, Yaochu Jin",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.00363"" target=""_blank"">2103.00363</a>",,2025-12-03 22:39:25
End-to-end Uncertainty-based Mitigation of Adversarial Attacks to Automated Lane Centering,"Ruochen Jiao, Hengyi Liang, Takami Sato, Junjie Shen, Qi Alfred Chen, Qi Zhu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.00345"" target=""_blank"">2103.00345</a>",,2025-12-03 22:39:25
Adversarial Information Bottleneck,"Pemhlong Zhai, Shihua Zhang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.00381"" target=""_blank"">2103.00381</a>",,2025-12-03 22:39:25
Neuron Coverage-Guided Domain Generalization,"Chris Xing Tian, Haoliang Li, Xiaofei Xie, Yang Liu, Shiqi Wang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.00229"" target=""_blank"">2103.00229</a>",,2025-12-03 22:39:25
NEUROSPF: A tool for the Symbolic Analysis of Neural Networks,"Muhammad Usman, Yannic Noller, Corina Pasareanu, Youcheng Sun, Divya Gopinath",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.00124"" target=""_blank"">2103.00124</a>",,2025-12-03 22:39:25
A Brief Survey on Deep Learning Based Data Hiding,"Chaoning Zhang, Chenguo Lin, Philipp Benz, Kejiang Chen, Weiming Zhang, In So Kweon",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.01607"" target=""_blank"">2103.01607</a>",,2025-12-03 22:39:25
Fixing Data Augmentation to Improve Adversarial Robustness,"Sylvestre-Alvise Rebuffi, Sven Gowal, Dan A. Calian, Florian Stimberg, Olivia Wiles, Timothy Mann",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.01946"" target=""_blank"">2103.01946</a>",,2025-12-03 22:39:25
ActiveGuard: An Active DNN IP Protection Technique via Adversarial Examples,"Mingfu Xue, Shichang Sun, Can He, Yushu Zhang, Jian Wang, Weiqiang Liu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.01527"" target=""_blank"">2103.01527</a>",,2025-12-03 22:39:25
DeepCert: Verification of Contextually Relevant Robustness for Neural Network Image Classifiers,"Colin Paterson, Haoze Wu, John Grese, Radu Calinescu, Corina S. Pasareanu, Clark Barrett",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.01629"" target=""_blank"">2103.01629</a>",,2025-12-03 22:39:25
WaveGuard: Understanding and Mitigating Audio Adversarial Examples,"Shehzeen Hussain, Paarth Neekhara, Shlomo Dubnov, Julian McAuley, Farinaz Koushanfar",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.03344"" target=""_blank"">2103.03344</a>",,2025-12-03 22:39:25
Towards Evaluating the Robustness of Deep Diagnostic Models by Adversarial Attack,"Mengting Xu, Tao Zhang, Zhongnian Li, Mingxia Liu, Daoqiang Zhang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.03438"" target=""_blank"">2103.03438</a>",,2025-12-03 22:39:25
QAIR: Practical Query-efficient Black-Box Attacks for Image Retrieval,"Xiaodan Li, Jinfeng Li, Yuefeng Chen, Shaokai Ye, Yuan He, Shuhui Wang, Hang Su, Hui Xue",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.02927"" target=""_blank"">2103.02927</a>",,2025-12-03 22:39:25
SpectralDefense: Detecting Adversarial Attacks on CNNs in the Fourier Domain,"Paula Harder, Franz-Josef Pfreundt, Margret Keuper, Janis Keuper",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.03000"" target=""_blank"">2103.03000</a>",,2025-12-03 22:39:25
Gradient-Guided Dynamic Efficient Adversarial Training,"Fu Wang, Yanghao Zhang, Yanbin Zheng, Wenjie Ruan",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.03076"" target=""_blank"">2103.03076</a>",,2025-12-03 22:39:25
PointGuard: Provably Robust 3D Point Cloud Classification,"Hongbin Liu, Jinyuan Jia, Neil Zhenqiang Gong",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.03046"" target=""_blank"">2103.03046</a>",,2025-12-03 22:39:25
Defending Medical Image Diagnostics against Privacy Attacks using Generative Methods,"William Paul, Yinzhi Cao, Miaomiao Zhang, Phil Burlina",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.03078"" target=""_blank"">2103.03078</a>",,2025-12-03 22:39:25
A Novel Framework for Threat Analysis of Machine Learning-based Smart Healthcare Systems,"Nur Imtiazul Haque, Mohammad Ashiqur Rahman, Md Hasan Shahriar, Alvi Ataur Khalil, Selcuk Uluagac",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.03472"" target=""_blank"">2103.03472</a>",,2025-12-03 22:39:25
On the privacy-utility trade-off in differentially private hierarchical text classification,"Dominik Wunderlich, Daniel Bernau, Francesco Aldà, Javier Parra-Arnau, Thorsten Strufe",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.02895"" target=""_blank"">2103.02895</a>",,2025-12-03 22:39:25
Structure-Preserving Progressive Low-rank Image Completion for Defending Adversarial Attacks,"Zhiqun Zhao, Hengyou Wang, Hao Sun, Zhihai He",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.02781"" target=""_blank"">2103.02781</a>",,2025-12-03 22:39:25
A Modified Drake Equation for Assessing Adversarial Risk to Machine Learning Models,"Josh Kalin, David Noever, Matthew Ciolino",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.02718"" target=""_blank"">2103.02718</a>",,2025-12-03 22:39:25
Shift Invariance Can Reduce Adversarial Robustness,"Songwei Ge, Vasu Singla, Ronen Basri, David Jacobs",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.02695"" target=""_blank"">2103.02695</a>",,2025-12-03 22:39:25
A Robust Adversarial Network-Based End-to-End Communications System With Strong Generalization Ability Against Adversarial Attacks,"Yudi Dong, Huaxia Wang, Yu-Dong Yao",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.02654"" target=""_blank"">2103.02654</a>",,2025-12-03 22:39:25
On the effectiveness of adversarial training against common corruptions,"Klim Kireev, Maksym Andriushchenko, Nicolas Flammarion",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.02325"" target=""_blank"">2103.02325</a>","<a href=""https://github.com/tml-epfl/adv-training-corruptions"" target=""_blank"">tml-epfl</a>",2025-12-03 22:39:25
Formalizing Generalization and Robustness of Neural Networks to Weight Perturbations,"Yu-Lin Tsai, Chia-Yi Hsu, Chia-Mu Yu, Pin-Yu Chen",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.02200"" target=""_blank"">2103.02200</a>",,2025-12-03 22:39:25
Evaluating the Robustness of Geometry-Aware Instance-Reweighted Adversarial Training,"Dorjan Hitaj, Giulio Pagnotta, Iacopo Masi, Luigi V. Mancini",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.01914"" target=""_blank"">2103.01914</a>","<a href=""https://github.com/giuxhub/GAIRAT-LSA"" target=""_blank"">giuxhub</a>",2025-12-03 22:39:25
A Survey On Universal Adversarial Attack,"Chaoning Zhang, Philipp Benz, Chenguo Lin, Adil Karjauv, Jing Wu, In So Kweon",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.01498"" target=""_blank"">2103.01498</a>",,2025-12-03 22:39:25
Online Adversarial Attacks,"Andjela Mladenovic, Avishek Joey Bose, Hugo Berard, William L. Hamilton, Simon Lacoste-Julien, Pascal Vincent, Gauthier Gidel",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.02014"" target=""_blank"">2103.02014</a>",,2025-12-03 22:39:25
Adversarial Examples for Unsupervised Machine Learning Models,"Chia-Yi Hsu, Pin-Yu Chen, Songtao Lu, Sijia Liu, Chia-Mu Yu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.01895"" target=""_blank"">2103.01895</a>","<a href=""https://github.com/IBM/UAE"" target=""_blank"">IBM</a>",2025-12-03 22:39:25
Meta-Solver for Neural Ordinary Differential Equations,"Julia Gusak, Alexandr Katrutsa, Talgat Daulbaev, Andrzej Cichocki, Ivan Oseledets",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.08561"" target=""_blank"">2103.08561</a>","<a href=""https://github.com/juliagusak/neural-ode-metasolver"" target=""_blank"">juliagusak</a>",2025-12-03 22:39:25
T-Miner: A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification,"Ahmadreza Azizi, Ibrahim Asadullah Tahmid, Asim Waheed, Neal Mangaokar, Jiameng Pu, Mobin Javed, Chandan K. Reddy, Bimal Viswanath",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.04264"" target=""_blank"">2103.04264</a>",,2025-12-03 22:39:25
HDTest: Differential Fuzz Testing of Brain-Inspired Hyperdimensional Computing,"Dongning Ma, Jianmin Guo, Yu Jiang, Xun Jiao",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.08668"" target=""_blank"">2103.08668</a>",,2025-12-03 22:39:25
Deep-RBF Networks for Anomaly Detection in Automotive Cyber-Physical Systems,"Matthew Burruss, Shreyas Ramakrishna, Abhishek Dubey",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14172"" target=""_blank"">2103.14172</a>",,2025-12-03 22:39:25
Combating Adversaries with Anti-Adversaries,"Motasem Alfarra, Juan C. Pérez, Ali Thabet, Adel Bibi, Philip H. S. Torr, Bernard Ghanem",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14347"" target=""_blank"">2103.14347</a>",,2025-12-03 22:39:25
On Generating Transferable Targeted Perturbations,"Muzammal Naseer, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, Fatih Porikli",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14641"" target=""_blank"">2103.14641</a>","<a href=""https://github.com/Muzammal-Naseer/TTP"" target=""_blank"">Muzammal-Naseer</a>",2025-12-03 22:39:25
Building Reliable Explanations of Unreliable Neural Networks: Locally Smoothing Perspective of Model Interpretation,"Dohun Lim, Hyeonseok Lee, Sungchan Kim",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14332"" target=""_blank"">2103.14332</a>",,2025-12-03 22:39:25
Ensemble-in-One: Learning Ensemble within Random Gated Networks for Enhanced Adversarial Robustness,"Yi Cai, Xuefei Ning, Huazhong Yang, Yu Wang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14795"" target=""_blank"">2103.14795</a>",,2025-12-03 22:39:25
Visual Explanations from Spiking Neural Networks using Interspike Intervals,"Youngeun Kim, Priyadarshini Panda",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14441"" target=""_blank"">2103.14441</a>",,2025-12-03 22:39:25
Unsupervised Robust Domain Adaptation without Source Data,"Peshal Agarwal, Danda Pani Paudel, Jan-Nico Zaech, Gool Luc Van",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14577"" target=""_blank"">2103.14577</a>",,2025-12-03 22:39:25
Adversarial Attacks are Reversible with Natural Supervision,"Chengzhi Mao, Mia Chiquier, Hao Wang, Junfeng Yang, Carl Vondrick",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14222"" target=""_blank"">2103.14222</a>",,2025-12-03 22:39:25
Adversarial Attacks on Deep Learning Based mmWave Beam Prediction in 5G and Beyond,"Brian Kim, Yalin E. Sagduyu, Tugba Erpek, Sennur Ulukus",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.13989"" target=""_blank"">2103.13989</a>",,2025-12-03 22:39:25
MagDR: Mask-guided Detection and Reconstruction for Defending Deepfakes,"Zhikai Chen, Lingxi Xie, Shanmin Pang, Yong He, Bo Zhang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14211"" target=""_blank"">2103.14211</a>",,2025-12-03 22:39:25
Orthogonal Projection Loss,"Kanchana Ranasinghe, Muzammal Naseer, Munawar Hayat, Salman Khan, Fahad Shahbaz Khan",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14021"" target=""_blank"">2103.14021</a>","<a href=""https://github.com/kahnchana/opl"" target=""_blank"">kahnchana</a>",2025-12-03 22:39:25
LiBRe: A Practical Bayesian Approach to Adversarial Detection,"Zhijie Deng, Xiao Yang, Shizhen Xu, Hang Su, Jun Zhu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14835"" target=""_blank"">2103.14835</a>",,2025-12-03 22:39:25
THAT: Two Head Adversarial Training for Improving Robustness at Scale,"Zuxuan Wu, Tom Goldstein, Larry S. Davis, Ser-Nam Lim",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.13612"" target=""_blank"">2103.13612</a>",,2025-12-03 22:39:25
"A Survey of Microarchitectural Side-channel Vulnerabilities, Attacks and Defenses in Cryptography","Xiaoxuan Lou, Tianwei Zhang, Jun Jiang, Yinqian Zhang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14244"" target=""_blank"">2103.14244</a>",,2025-12-03 22:39:25
HufuNet: Embedding the Left Piece as Watermark and Keeping the Right Piece for Ownership Verification in Deep Neural Networks,"Peizhuo Lv, Pan Li, Shengzhi Zhang, Kai Chen, Ruigang Liang, Yue Zhao, Yingjiu Li",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.13628"" target=""_blank"">2103.13628</a>",,2025-12-03 22:39:25
The Geometry of Over-parameterized Regression and Adversarial Perturbations,"Jason W. Rocks, Pankaj Mehta",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14108"" target=""_blank"">2103.14108</a>",,2025-12-03 22:39:25
Synthesize-It-Classifier: Learning a Generative Classifier through RecurrentSelf-analysis,"Arghya Pal, Rapha Phan, KokSheik Wong",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14212"" target=""_blank"">2103.14212</a>",,2025-12-03 22:39:25
Spirit Distillation: Precise Real-time Prediction with Insufficient Data,"Zhiyuan Wu, Hong Qi, Yu Jiang, Chupeng Cui, Zongmin Yang, Xinhui Xue",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.13733"" target=""_blank"">2103.13733</a>",,2025-12-03 22:39:25
Recent Advances in Large Margin Learning,"Yiwen Guo, Changshui Zhang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.13598"" target=""_blank"">2103.13598</a>",,2025-12-03 22:39:25
Towards Both Accurate and Robust Neural Networks without Extra Data,"Faqiang Liu, Rong Zhao",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.13124"" target=""_blank"">2103.13124</a>",,2025-12-03 22:39:25
Vulnerability of Appearance-based Gaze Estimation,"Mingjie Xu, Haofei Wang, Yunfei Liu, Feng Lu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.13134"" target=""_blank"">2103.13134</a>",,2025-12-03 22:39:25
Cyclic Defense GAN Against Speech Adversarial Attacks,"Mohammad Esmaeilpour, Patrick Cardinal, Alessandro Lameiras Koerich",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14717"" target=""_blank"">2103.14717</a>",,2025-12-03 22:39:25
IoU Attack: Towards Temporally Coherent Black-Box Adversarial Attack for Visual Object Tracking,"Shuai Jia, Yibing Song, Chao Ma, Xiaokang Yang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14938"" target=""_blank"">2103.14938</a>","<a href=""https://github.com/VISION-SJTU/IoUattack"" target=""_blank"">VISION-SJTU</a>",2025-12-03 22:39:25
Deepfake Forensics via An Adversarial Game,"Zhi Wang, Yiwen Guo, Wangmeng Zuo",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.13567"" target=""_blank"">2103.13567</a>",,2025-12-03 22:39:25
Lagrangian Objective Function Leads to Improved Unforeseen Attack Generalization in Adversarial Training,"Mohammad Azizmalayeri, Mohammad Hossein Rohban",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.15385"" target=""_blank"">2103.15385</a>",,2025-12-03 22:39:25
Adversarial Training is Not Ready for Robot Learning,"Mathias Lechner, Ramin Hasani, Radu Grosu, Daniela Rus, Thomas A. Henzinger",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.08187"" target=""_blank"">2103.08187</a>",,2025-12-03 22:39:25
Fast Certified Robust Training with Short Warmup,"Zhouxing Shi, Yihan Wang, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.17268"" target=""_blank"">2103.17268</a>","<a href=""https://github.com/shizhouxing/Fast-Certified-Robust-Training"" target=""_blank"">shizhouxing</a>",2025-12-03 22:39:25
Digital Forensics vs,"Jean-Paul A. Yaacoub, Hassan N. Noura, Ola Salman, Ali Chehab",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.17028"" target=""_blank"">2103.17028</a>",,2025-12-03 22:39:25
Class-Aware Robust Adversarial Training for Object Detection,"Pin-Chun Chen, Bo-Han Kung, Jun-Cheng Chen",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.16148"" target=""_blank"">2103.16148</a>",,2025-12-03 22:39:25
PointBA: Towards Backdoor Attacks in 3D Point Cloud,"Xinke Li, Zhiru Chen, Yue Zhao, Zekun Tong, Yabang Zhao, Andrew Lim, Joey Tianyi Zhou",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.16074"" target=""_blank"">2103.16074</a>",,2025-12-03 22:39:25
What Causes Optical Flow Networks to be Vulnerable to Physical Adversarial Attacks,"Simon Schrodi, Tonmoy Saikia, Thomas Brox",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.16255"" target=""_blank"">2103.16255</a>",,2025-12-03 22:39:25
Statistical inference for individual fairness,"Subha Maity, Songkai Xue, Mikhail Yurochkin, Yuekai Sun",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.16714"" target=""_blank"">2103.16714</a>",,2025-12-03 22:39:25
"Learning Lipschitz Feedback Policies from Expert Demonstrations: Closed-Loop Guarantees, Generalization and Robustness","Abed AlRahman Al Makdah, Vishaal Krishnan, Fabio Pasqualetti",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.16629"" target=""_blank"">2103.16629</a>",,2025-12-03 22:39:25
Improving robustness against common corruptions with frequency biased models,"Tonmoy Saikia, Cordelia Schmid, Thomas Brox",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.16241"" target=""_blank"">2103.16241</a>",,2025-12-03 22:39:25
Enhancing the Transferability of Adversarial Attacks through Variance Tuning,"Xiaosen Wang, Kun He",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.15571"" target=""_blank"">2103.15571</a>","<a href=""https://github.com/JHL-HUST/VT"" target=""_blank"">JHL-HUST</a>",2025-12-03 22:39:25
On the benefits of robust models in modulation recognition,"Javier Maroto, Gérôme Bovet, Pascal Frossard",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.14977"" target=""_blank"">2103.14977</a>",,2025-12-03 22:39:25
On the Adversarial Robustness of Vision Transformers,"Rulin Shao, Zhouxing Shi, Jinfeng Yi, Pin-Yu Chen, Cho-Jui Hsieh",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.15670"" target=""_blank"">2103.15670</a>",,2025-12-03 22:39:25
ZeroGrad : Mitigating and Explaining Catastrophic Overfitting in FGSM Adversarial Training,"Zeinab Golgooni, Mehrdad Saberi, Masih Eskandar, Mohammad Hossein Rohban",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.15476"" target=""_blank"">2103.15476</a>",,2025-12-03 22:39:25
Certifiably-Robust Federated Adversarial Learning via Randomized Smoothing,"Cheng Chen, Bhavya Kailkhura, Ryan Goldhahn, Yi Zhou",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.16031"" target=""_blank"">2103.16031</a>",,2025-12-03 22:39:25
Fooling LiDAR Perception via Adversarial Trajectory Perturbation,"Yiming Li, Congcong Wen, Felix Juefei-Xu, Chen Feng",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.15326"" target=""_blank"">2103.15326</a>","<a href=""https://ai4ce.github.io/FLAT/"" target=""_blank"">FLAT</a>",2025-12-03 22:39:25
Robust Reinforcement Learning under model misspecification,"Lebin Yu, Jian Wang, Xudong Zhang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.15370"" target=""_blank"">2103.15370</a>",,2025-12-03 22:39:25
Automating Defense Against Adversarial Attacks: Discovery of Vulnerabilities and Application of Multi-INT Imagery to Protect Deployed Models,"Josh Kalin, David Noever, Matthew Ciolino, Dominick Hambrick, Gerry Dozier",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.15897"" target=""_blank"">2103.15897</a>",,2025-12-03 22:39:25
MISA: Online Defense of Trojaned Models using Misattributions,"Panagiota Kiourti, Wenchao Li, Anirban Roy, Karan Sikka, Susmit Jha",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.15918"" target=""_blank"">2103.15918</a>",,2025-12-03 22:39:25
Selective Output Smoothing Regularization: Regularize Neural Networks by Softening Output Distributions,"Xuan Cheng, Tianshu Xie, Xiaomin Wang, Qifeng Weng, Minghui Liu, Jiali Deng, Ming Liu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.15383"" target=""_blank"">2103.15383</a>",,2025-12-03 22:39:25
Improved Autoregressive Modeling with Distribution Smoothing,"Chenlin Meng, Jiaming Song, Yang Song, Shengjia Zhao, Stefano Ermon",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.15089"" target=""_blank"">2103.15089</a>",,2025-12-03 22:39:25
Black-box Detection of Backdoor Attacks with Limited Information and Data,"Yinpeng Dong, Xiao Yang, Zhijie Deng, Tianyu Pang, Zihao Xiao, Hang Su, Jun Zhu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.13127"" target=""_blank"">2103.13127</a>",,2025-12-03 22:39:25
Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability of the Embedding Layers in NLP Models,"Wenkai Yang, Lei Li, Zhiyuan Zhang, Xuancheng Ren, Xu Sun, Bin He",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.15543"" target=""_blank"">2103.15543</a>","<a href=""https://github.com/lancopku/Embedding-Poisoning"" target=""_blank"">lancopku</a>",2025-12-03 22:39:25
Robust and Accurate Object Detection via Adversarial Learning,"Xiangning Chen, Cihang Xie, Mingxing Tan, Li Zhang, Cho-Jui Hsieh, Boqing Gong",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.13886"" target=""_blank"">2103.13886</a>",,2025-12-03 22:39:25
Can Targeted Adversarial Examples Transfer When the Source and Target Models Have No Label Space Overlap? (99%),"Nathan Inkawhich, Kevin J Liang, Jingyang Zhang, Huanrui Yang, Hai Li, Yiran Chen",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.09916"" target=""_blank"">2103.09916</a>",,2025-12-03 22:39:25
Generating Adversarial Computer Programs using Optimized Obfuscations,"Shashank Srikant, Sijia Liu, Tamara Mitrovska, Shiyu Chang, Quanfu Fan, Gaoyuan Zhang, Una-May O'Reilly",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.11882"" target=""_blank"">2103.11882</a>",,2025-12-03 22:39:25
Boosting Adversarial Transferability through Enhanced Momentum,"Xiaosen Wang, Jiadong Lin, Han Hu, Jingdong Wang, Kun He",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.10609"" target=""_blank"">2103.10609</a>",,2025-12-03 22:39:25
Explainable Adversarial Attacks in Deep Neural Networks Using Activation Profiles,"Gabriel D. Cantareira, Rodrigo F. Mello, Fernando V. Paulovich",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.10229"" target=""_blank"">2103.10229</a>",,2025-12-03 22:39:25
Enhancing Transformer for Video Understanding Using Gated Multi-Level Attention and Temporal Adversarial Training,"Saurabh Sahu, Palash Goyal",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.10043"" target=""_blank"">2103.10043</a>",,2025-12-03 22:39:25
"Model Extraction and Adversarial Transferability, Your BERT is Vulnerable! (69%)","Xuanli He, Lingjuan Lyu, Qiongkai Xu, Lichao Sun",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.10013"" target=""_blank"">2103.10013</a>",,2025-12-03 22:39:25
TOP: Backdoor Detection in Neural Networks via Transferability of Perturbation,"Todd Huster, Emmanuel Ekwedike",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.10274"" target=""_blank"">2103.10274</a>",,2025-12-03 22:39:25
Noise Modulation: Let Your Model Interpret Itself,"Haoyang Li, Xinggang Wang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.10603"" target=""_blank"">2103.10603</a>",,2025-12-03 22:39:25
KoDF: A Large-scale Korean DeepFake Detection Dataset,"Patrick Kwon, Jaeseong You, Gyuhyeon Nam, Sungwoo Park, Gyeongsu Chae",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.10094"" target=""_blank"">2103.10094</a>","<a href=""https://moneybrain-research.github.io/kodf"" target=""_blank"">moneybrain-research.github.io</a>",2025-12-03 22:39:25
Reading Isn't Believing: Adversarial Attacks On Multi-Modal Neurons,"David A. Noever, Samantha E. Miller Noever",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.10480"" target=""_blank"">2103.10480</a>",,2025-12-03 22:39:25
"Improved, Deterministic Smoothing for L1 Certified Robustness","Alexander Levine, Soheil Feizi",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.10834"" target=""_blank"">2103.10834</a>",,2025-12-03 22:39:25
Attribution of Gradient Based Adversarial Attacks for Reverse Engineering of Deceptions,"Michael Goebel, Jason Bunk, Srinjoy Chattopadhyay, Lakshmanan Nataraj, Shivkumar Chandrasekaran, B. S. Manjunath",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.11002"" target=""_blank"">2103.11002</a>","<a href=""https://github.com/michael-goebel/ei_red"" target=""_blank"">michael-goebel</a>",2025-12-03 22:39:25
Understanding Generalization in Adversarial Training via the Bias-Variance Decomposition,"Yaodong Yu, Zitong Yang, Edgar Dobriban, Jacob Steinhardt, Yi Ma",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.09947"" target=""_blank"">2103.09947</a>",,2025-12-03 22:39:25
Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots,"Samson Tan, Shafiq Joty",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.09593"" target=""_blank"">2103.09593</a>",,2025-12-03 22:39:25
Cyber Intrusion Detection by Using Deep Neural Networks with Attack-sharing Loss,"Boxiang Wendy Dong, Wendy Hui, Wang, Aparna S. Varde, Dawei Li, Bharath K. Samanthula, Weifeng Sun, Liang Zhao",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.09713"" target=""_blank"">2103.09713</a>",,2025-12-03 22:39:25
Adversarial Driving: Attacking End-to-End Autonomous Driving,"Han Wu, Syed Yunas, Sareh Rowlands, Wenjie Ruan, Johan Wahlstrom",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.09151"" target=""_blank"">2103.09151</a>",,2025-12-03 22:39:25
Adversarial YOLO: Defense Human Detection Patch Attacks via Detecting Adversarial Patches,"Nan Ji, YanFei Feng, Haidong Xie, Xueshuang Xiang, Naijin Liu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.08860"" target=""_blank"">2103.08860</a>",,2025-12-03 22:39:25
Anti-Adversarially Manipulated Attributions for Weakly and Semi-Supervised Semantic Segmentation,"Jungbeom Lee, Eunji Kim, Sungroh Yoon",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.08896"" target=""_blank"">2103.08896</a>",,2025-12-03 22:39:25
Bio-inspired Robustness: A Review,"Harshitha Machiraju, Oh-Hyeon Choung, Pascal Frossard, Michael. H Herzog",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.09265"" target=""_blank"">2103.09265</a>",,2025-12-03 22:39:25
CLIP: Cheap Lipschitz Training of Neural Networks,"Leon Bungert, René Raab, Tim Roith, Leo Schwinn, Daniel Tenbrinck",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.12531"" target=""_blank"">2103.12531</a>",,2025-12-03 22:39:25
Constant Random Perturbations Provide Adversarial Robustness with Minimal Effect on Accuracy,"Bronya Roni Chernyak, Bhiksha Raj, Tamir Hazan, Joseph Keshet",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.08265"" target=""_blank"">2103.08265</a>",,2025-12-03 22:39:25
"Interpretable Deep Learning: Interpretation, Interpretability, Trustworthiness, and Beyond","Xuhong Li, Haoyi Xiong, Xingjian Li, Xuanyu Wu, Xiao Zhang, Ji Liu, Jiang Bian, Dejing Dou",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.10689"" target=""_blank"">2103.10689</a>",,2025-12-03 22:39:25
Adversarial Attacks on Camera-LiDAR Models for 3D Car Detection,"Mazen Abdelfattah, Kaiwen Yuan, Z. Jane Wang, Rabab Ward",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.09448"" target=""_blank"">2103.09448</a>",,2025-12-03 22:39:25
SoK: A Modularized Approach to Study the Security of Automatic Speech Recognition Systems,"Yuxuan Chen, Jiangshan Zhang, Xuejing Yuan, Shengzhi Zhang, Kai Chen, Xiaofeng Wang, Shanqing Guo",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.10651"" target=""_blank"">2103.10651</a>",,2025-12-03 22:39:25
Fast Approximate Spectral Normalization for Robust Deep Neural Networks,"Zhixin Pan, Prabhat Mishra",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.13815"" target=""_blank"">2103.13815</a>",,2025-12-03 22:39:25
The Hammer and the Nut: Is Bilevel Optimization Really Needed to Poison Linear Classifiers? (92%),"Antonio Emanuele Cinà, Sebastiano Vascon, Ambra Demontis, Battista Biggio, Fabio Roli, Marcello Pelillo",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.12399"" target=""_blank"">2103.12399</a>",,2025-12-03 22:39:25
LSDAT: Low-Rank and Sparse Decomposition for Decision-based Adversarial Attack,"Ashkan Esmaeili, Marzieh Edraki, Nazanin Rahnavard, Mubarak Shah, Ajmal Mian",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.10787"" target=""_blank"">2103.10787</a>",,2025-12-03 22:39:25
Characterizing and Improving the Robustness of Self-Supervised Learning through Background Augmentations,"Chaitanya K. Ryali, David J. Schwab, Ari S. Morcos",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.12719"" target=""_blank"">2103.12719</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defenses for Speech Recognition Systems,"Piotr Żelasko, Sonal Joshi, Yiwen Shao, Jesus Villalba, Jan Trmal, Najim Dehak, Sanjeev Khudanpur",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.17122"" target=""_blank"">2103.17122</a>",,2025-12-03 22:39:25
RPATTACK: Refined Patch Attack on General Object Detectors,"Hao Huang, Yongtao Wang, Zhaoyu Chen, Zhi Tang, Wenqiang Zhang, Kai-Kuang Ma",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.12469"" target=""_blank"">2103.12469</a>","<a href=""https://github.com/VDIGPKU/RPAttack"" target=""_blank"">VDIGPKU</a>",2025-12-03 22:39:25
NNrepair: Constraint-based Repair of Neural Network Classifiers,"Muhammad Usman, Divya Gopinath, Youcheng Sun, Yannic Noller, Corina Pasareanu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.12535"" target=""_blank"">2103.12535</a>",,2025-12-03 22:39:25
Improved Estimation of Concentration Under $\ell_p$-Norm Distance Metrics Using Half Spaces,"Jack Prescott, Xiao Zhang, David Evans",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.12913"" target=""_blank"">2103.12913</a>",,2025-12-03 22:39:25
ESCORT: Ethereum Smart COntRacTs Vulnerability Detection using Deep Neural Network and Transfer Learning,"Oliver Lutz, Huili Chen, Hossein Fereidooni, Christoph Sendner, Alexandra Dmitrienko, Ahmad Reza Sadeghi, Farinaz Koushanfar",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.12607"" target=""_blank"">2103.12607</a>",,2025-12-03 22:39:25
Grey-box Adversarial Attack And Defence For Sentiment Classification,"Ying Xu, Xu Zhong, Antonio Jimeno Yepes, Jey Han Lau",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.11576"" target=""_blank"">2103.11576</a>","<a href=""https://github.com/ibm-aur-nlp/adv-def-text-dist"" target=""_blank"">ibm-aur-nlp</a>",2025-12-03 22:39:25
Are all outliers alike? On Understanding the Diversity of Outliers for Detecting OODs,"Ramneet Kaur, Susmit Jha, Anirban Roy, Oleg Sokolsky, Insup Lee",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.12628"" target=""_blank"">2103.12628</a>",,2025-12-03 22:39:25
Robust Models Are More Interpretable Because Attributions Look Normal,"Zifan Wang, Matt Fredrikson, Anupam Datta",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.11257"" target=""_blank"">2103.11257</a>","<a href=""https://github.com/zifanw/boundary"" target=""_blank"">zifanw</a>",2025-12-03 22:39:25
RA-BNN: Constructing Robust & Accurate Binary Neural Network to Simultaneously Defend Adversarial Bit-Flip Attack and Improve Accuracy,"Adnan Siraj Rakin, Li Yang, Jingtao Li, Fan Yao, Chaitali Chakrabarti, Yu Cao, Jae-sun Seo, Deliang Fan",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.13813"" target=""_blank"">2103.13813</a>",,2025-12-03 22:39:25
Adversarial Feature Augmentation and Normalization for Visual Recognition,"Tianlong Chen, Yu Cheng, Zhe Gan, Jianfeng Wang, Lijuan Wang, Zhangyang Wang, Jingjing Liu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.12171"" target=""_blank"">2103.12171</a>","<a href=""https://github.com/VITA-Group/CV_A-FAN"" target=""_blank"">VITA-Group</a>",2025-12-03 22:39:25
Adversarially Optimized Mixup for Robust Classification,"Jason Bunk, Srinjoy Chattopadhyay, B. S. Manjunath, Shivkumar Chandrasekaran",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.11589"" target=""_blank"">2103.11589</a>",,2025-12-03 22:39:25
ExAD: An Ensemble Approach for Explanation-based Adversarial Detection,"Raj Vardhan, Ninghao Liu, Phakpoom Chinprutthiwong, Weijie Fu, Zhenyu Hu, Xia Ben Hu, Guofei Gu",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.11526"" target=""_blank"">2103.11526</a>",,2025-12-03 22:39:25
TextFlint: Unified Multilingual Robustness Evaluation Toolkit for Natural Language Processing,"Tao Gui, Xiao Wang, Qi Zhang, Qin Liu, Yicheng Zou, Xin Zhou, Rui Zheng, Chong Zhang, Qinzhuo Wu, Jiacheng Ye, Zexiong Pang, Yongxin Zhang, Zhengyan Li, Ruotian Ma, Zichu Fei, Ruijian Cai, Jun Zhao, Xinwu Hu, Zhiheng Yan, Yiding Tan, Yuan Hu, Qiyuan Bian, Zhihua Liu, Bolin Zhu, Shan Qin, Xiaoyu Xing, Jinlan Fu, Yue Zhang, Minlong Peng, Xiaoqing Zheng, Yaqian Zhou, Zhongyu Wei, Xipeng Qiu, Xuanjing Huang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.11441"" target=""_blank"">2103.11441</a>",,2025-12-03 22:39:25
Natural Perturbed Training for General Robustness of Neural Network Classifiers,"Sadaf Gulshad, Arnold Smeulders",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.11372"" target=""_blank"">2103.11372</a>",,2025-12-03 22:39:25
Self adversarial attack as an augmentation method for immunohistochemical stainings,"Jelica Vasiljević, Friedrich Feuerhake, Cédric Wemmert, Thomas Lampert",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.11362"" target=""_blank"">2103.11362</a>",,2025-12-03 22:39:25
Spatio-Temporal Sparsification for General Robust Graph Convolution Networks,"Mingming Lu, Ya Zhang",arXiv,2021-03,"<a href=""http://arxiv.org/abs/2103.12256"" target=""_blank"">2103.12256</a>",,2025-12-03 22:39:25
Benford's law: what does it say on adversarial images?,"João G. Zago, Fabio L. Baldissera, Eric A. Antonelo, Rodrigo T. Saad",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.04615"" target=""_blank"">2102.04615</a>",,2025-12-03 22:39:25
Target Training Does Adversarial Training Without Adversarial Samples,Blerta Lindqvist,arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.04836"" target=""_blank"">2102.04836</a>",,2025-12-03 22:39:25
Security and Privacy for Artificial Intelligence: Opportunities and Challenges,"Ayodeji Oseni, Nour Moustafa, Helge Janicke, Peng Liu, Zahir Tari, Athanasios Vasilakos",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.04661"" target=""_blank"">2102.04661</a>",,2025-12-03 22:39:25
"""What's in the box?!"": Deflecting Adversarial Attacks by Randomly Deploying Adversarially-Disjoint Models","Sahar Abdelnabi, Mario Fritz",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.05104"" target=""_blank"">2102.05104</a>",,2025-12-03 22:39:25
Adversarial Perturbations Are Not So Weird: Entanglement of Robust and Non-Robust Features in Neural Network Classifiers,"Jacob M. Springer, Melanie Mitchell, Garrett T. Kenyon",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.05110"" target=""_blank"">2102.05110</a>",,2025-12-03 22:39:25
Detecting Localized Adversarial Examples: A Generic Approach using Critical Region Analysis,"Fengting Li, Xuankai Liu, Xiaoli Zhang, Qi Li, Kun Sun, Kang Li",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.05241"" target=""_blank"">2102.05241</a>",,2025-12-03 22:39:25
Efficient Certified Defenses Against Patch Attacks on Image Classifiers,"Jan Hendrik Metzen, Maksym Yatsura",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.04154"" target=""_blank"">2102.04154</a>",,2025-12-03 22:39:25
Making Paper Reviewing Robust to Bid Manipulation Attacks,"Ruihan Wu, Chuan Guo, Felix Wu, Rahul Kidambi, der Maaten Laurens van, Kilian Q. Weinberger",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.06020"" target=""_blank"">2102.06020</a>",,2025-12-03 22:39:25
Towards Bridging the gap between Empirical and Certified Robustness against Adversarial Examples,"Jay Nandy, Sudipan Saha, Wynne Hsu, Mong Li Lee, Xiao Xiang Zhu",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.05096"" target=""_blank"">2102.05096</a>",,2025-12-03 22:39:25
Exploiting epistemic uncertainty of the deep learning models to generate adversarial samples,"Omer Faruk Tuna, Ferhat Ozgur Catak, M. Taner Eskil",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.04150"" target=""_blank"">2102.04150</a>",,2025-12-03 22:39:25
A Real-time Defense against Website Fingerprinting Attacks,"Shawn Shan, Arjun Nitin Bhagoji, Haitao Zheng, Ben Y. Zhao",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.04291"" target=""_blank"">2102.04291</a>",,2025-12-03 22:39:25
RoBIC: A benchmark suite for assessing classifiers robustness,"Thibault Maho, Benoît Bonnet, Teddy Furon, Erwan Le Merrer",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.05368"" target=""_blank"">2102.05368</a>",,2025-12-03 22:39:25
Bayesian Inference with Certifiable Adversarial Robustness,"Matthew Wicker, Luca Laurenti, Andrea Patane, Zhoutong Chen, Zheng Zhang, Marta Kwiatkowska",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.05289"" target=""_blank"">2102.05289</a>",,2025-12-03 22:39:25
Adversarially robust deepfake media detection using fused convolutional neural network predictions,"Sohail Ahmed Khan, Alessandro Artusi, Hang Dai",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.05950"" target=""_blank"">2102.05950</a>",,2025-12-03 22:39:25
Towards Certifying L-infinity Robustness using Neural Networks with L-inf-dist Neurons,"Bohang Zhang, Tianle Cai, Zhou Lu, Di He, Liwei Wang",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.05363"" target=""_blank"">2102.05363</a>",,2025-12-03 22:39:25
Enhancing Real-World Adversarial Patches through 3D Modeling of Complex Target Scenes,"Yael Mathov, Lior Rokach, Yuval Elovici",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.05334"" target=""_blank"">2102.05334</a>",,2025-12-03 22:39:25
Dompteur: Taming Audio Adversarial Examples,"Thorsten Eisenhofer, Lea Schönherr, Joel Frank, Lars Speckemeier, Dorothea Kolossa, Thorsten Holz",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.05431"" target=""_blank"">2102.05431</a>",,2025-12-03 22:39:25
CIFS: Improving Adversarial Robustness of CNNs via Channel-wise Importance-based Feature Selection,"Hanshu Yan, Jingfeng Zhang, Gang Niu, Jiashi Feng, Vincent Y. F. Tan, Masashi Sugiyama",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.05311"" target=""_blank"">2102.05311</a>","<a href=""https://github.com/HanshuYAN/CIFS"" target=""_blank"">HanshuYAN</a>",2025-12-03 22:39:25
Adversarial Robustness: What fools you makes you stronger,"Grzegorz Głuch, Rüdiger Urbanke",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.05475"" target=""_blank"">2102.05475</a>",,2025-12-03 22:39:25
Meta Federated Learning,"Omid Aramoon, Pin-Yu Chen, Gang Qu, Yuan Tian",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.05561"" target=""_blank"">2102.05561</a>",,2025-12-03 22:39:25
RobOT: Robustness-Oriented Testing for Deep Learning Systems,"Jingyi Wang, Jialuo Chen, Youcheng Sun, Xingjun Ma, Dongxia Wang, Jun Sun, Peng Cheng",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.05913"" target=""_blank"">2102.05913</a>",,2025-12-03 22:39:25
Defuse: Harnessing Unrestricted Adversarial Examples for Debugging Models Beyond Test Accuracy,"Dylan Slack, Nathalie Rauschmayr, Krishnaram Kenthapadi",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.06162"" target=""_blank"">2102.06162</a>",,2025-12-03 22:39:25
On the Paradox of Certified Training,"Nikola Jovanović, Mislav Balunović, Maximilian Baader, Martin Vechev",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.06700"" target=""_blank"">2102.06700</a>",,2025-12-03 22:39:25
Universal Adversarial Perturbations for Malware,"Raphael Labaca-Castro, Luis Muñoz-González, Feargus Pendlebury, Gabi Dreo Rodosek, Fabio Pierazzi, Lorenzo Cavallaro",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.06747"" target=""_blank"">2102.06747</a>",,2025-12-03 22:39:25
Universal Adversarial Perturbations Through the Lens of Deep Steganography: Towards A Fourier Perspective,"Chaoning Zhang, Philipp Benz, Adil Karjauv, In So Kweon",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.06479"" target=""_blank"">2102.06479</a>",,2025-12-03 22:39:25
Adversarial Imaging Pipelines,"Buu Phan, Fahim Mannan, Felix Heide",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.03728"" target=""_blank"">2102.03728</a>",,2025-12-03 22:39:25
UAVs Path Deviation Attacks: Survey and Research Challenges,"Francesco Betti Sorbelli, Mauro Conti, Cristina M. Pinotti, Giulio Rigoni",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.06638"" target=""_blank"">2102.06638</a>",,2025-12-03 22:39:25
Adversarial example generation with AdaBelief Optimizer and Crop Invariance,"Bo Yang, Hengwei Zhang, Yuchen Zhang, Kaiyong Xu, Jindong Wang",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.03726"" target=""_blank"">2102.03726</a>",,2025-12-03 22:39:25
Robust Adversarial Attacks Against DNN-Based Wireless Communication Systems,"Alireza Bahramali, Milad Nasr, Amir Houmansadr, Dennis Goeckel, Don Towsley",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.00918"" target=""_blank"">2102.00918</a>",,2025-12-03 22:39:25
SPADE: A Spectral Method for Black-Box Adversarial Robustness Evaluation,"Wuxinlin Cheng, Chenhui Deng, Zhiqiang Zhao, Yaohui Cai, Zhiru Zhang, Zhuo Feng",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.03716"" target=""_blank"">2102.03716</a>",,2025-12-03 22:39:25
On Robustness of Neural Semantic Parsers,"Shuo Huang, Zhuang Li, Lizhen Qu, Lei Pan",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.01563"" target=""_blank"">2102.01563</a>",,2025-12-03 22:39:25
Mixed Nash Equilibria in the Adversarial Examples Game,"Laurent Meunier, Meyer Scetbon, Rafael Pinot, Jamal Atif, Yann Chevaleyre",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.06905"" target=""_blank"">2102.06905</a>",,2025-12-03 22:39:25
You Only Query Once: Effective Black Box Adversarial Attacks with Minimal Repeated Queries,"Devin Willmott, Anit Kumar Sahu, Fatemeh Sheikholeslami, Filipe Condessa, Zico Kolter",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.00029"" target=""_blank"">2102.00029</a>",,2025-12-03 22:39:25
Cortical Features for Defense Against Adversarial Audio Attacks,"Ilya Kavalerov, Ruijie Zheng, Wojciech Czaja, Rama Chellappa",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.00313"" target=""_blank"">2102.00313</a>","<a href=""https://github.com/ilyakava/py3fst"" target=""_blank"">ilyakava</a>",2025-12-03 22:39:25
Admix: Enhancing the Transferability of Adversarial Attacks,"Xiaosen Wang, Xuanran He, Jingdong Wang, Kun He",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.00436"" target=""_blank"">2102.00436</a>",,2025-12-03 22:39:25
Towards Imperceptible Query-limited Adversarial Attacks with Perceptual Feature Fidelity Loss,"Pengrui Quan, Ruiming Guo, Mani Srivastava",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.00449"" target=""_blank"">2102.00449</a>",,2025-12-03 22:39:25
Deep Deterministic Information Bottleneck with Matrix-based Entropy Functional,"Xi Yu, Shujian Yu, Jose C. Principe",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.00533"" target=""_blank"">2102.00533</a>","<a href=""https://github.com/yuxi120407/DIB"" target=""_blank"">yuxi120407</a>",2025-12-03 22:39:25
Comparing hundreds of machine learning classifiers and discrete choice models in predicting travel behavior: an empirical benchmark,"Shenhao Wang, Baichuan Mo, Yunhan Zheng, Stephane Hess, Jinhua Zhao",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.01130"" target=""_blank"">2102.01130</a>",,2025-12-03 22:39:25
Towards Speeding up Adversarial Training in Latent Spaces,"Yaguan Qian, Qiqi Shao, Tengteng Yao, Bin Wang, Shaoning Zeng, Zhaoquan Gu, Wassim Swaileh",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.00662"" target=""_blank"">2102.00662</a>",,2025-12-03 22:39:25
Fast Training of Provably Robust Neural Networks by SingleProp,"Akhilan Boopathy, Tsui-Wei Weng, Sijia Liu, Pin-Yu Chen, Gaoyuan Zhang, Luca Daniel",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.01208"" target=""_blank"">2102.01208</a>",,2025-12-03 22:39:25
Probabilistic Trust Intervals for Out of Distribution Detection,"Gagandeep Singh, Ishan Mishra, Deepak Mishra",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.01336"" target=""_blank"">2102.01336</a>",,2025-12-03 22:39:25
Recent Advances in Adversarial Training for Adversarial Robustness,"Tao Bai, Jinqi Luo, Jun Zhao, Bihan Wen, Qian Wang",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.01356"" target=""_blank"">2102.01356</a>",,2025-12-03 22:39:25
Towards Robust Neural Networks via Close-loop Control,"Zhuotong Chen, Qianxiao Li, Zheng Zhang",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.01862"" target=""_blank"">2102.01862</a>",,2025-12-03 22:39:25
IWA: Integrated Gradient based White-box Attacks for Fooling Deep Neural Networks,"Yixiang Wang, Jiqiang Liu, Xiaolin Chang, Jelena Mišić, Vojislav B. Mišić",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.02128"" target=""_blank"">2102.02128</a>",,2025-12-03 22:39:25
Corner Case Generation and Analysis for Safety Assessment of Autonomous Vehicles,"Haowei Sun, Shuo Feng, Xintao Yan, Henry X. Liu",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.03483"" target=""_blank"">2102.03483</a>",,2025-12-03 22:39:25
Adversarially Robust Learning with Unknown Perturbation Sets,"Omar Montasser, Steve Hanneke, Nathan Srebro",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.02145"" target=""_blank"">2102.02145</a>",,2025-12-03 22:39:25
ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models,"Yugeng Liu, Rui Wen, Xinlei He, Ahmed Salem, Zhikun Zhang, Michael Backes, Cristofaro Emiliano De, Mario Fritz, Yang Zhang",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.02551"" target=""_blank"">2102.02551</a>",,2025-12-03 22:39:25
Audio Adversarial Examples: Attacks Using Vocal Masks,"Lynnette Ng, Kai Yuan Tay, Wei Han Chua, Lucerne Loke, Danqi Ye, Melissa Chua",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.02417"" target=""_blank"">2102.02417</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defenses in Physiological Computing: A Systematic Review,"Dongrui Wu, Weili Fang, Yi Zhang, Liuqing Yang, Hanbin Luo, Lieyun Ding, Xiaodong Xu, Xiang Yu",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.02729"" target=""_blank"">2102.02729</a>",,2025-12-03 22:39:25
PredCoin: Defense against Query-based Hard-label Attack,"Junfeng Guo, Yaswanth Yadlapalli, Thiele Lothar, Ang Li, Cong Liu",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.02923"" target=""_blank"">2102.02923</a>",,2025-12-03 22:39:25
Adversarial Robustness Study of Convolutional Neural Network for Lumbar Disk Shape Reconstruction from MR images,"Jiasong Chen, Linchen Qian, Timur Urakov, Weiyong Gu, Liang Liang",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.02885"" target=""_blank"">2102.02885</a>",,2025-12-03 22:39:25
Adversarial Training Makes Weight Loss Landscape Sharper in Logistic Regression,"Masanori Yamada, Sekitoshi Kanai, Tomoharu Iwata, Tomokatsu Takahashi, Yuki Yamanaka, Hiroshi Takahashi, Atsutoshi Kumagai",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.02950"" target=""_blank"">2102.02950</a>",,2025-12-03 22:39:25
DetectorGuard: Provably Securing Object Detectors against Localized Patch Hiding Attacks,"Chong Xiang, Prateek Mittal",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.02956"" target=""_blank"">2102.02956</a>",,2025-12-03 22:39:25
Optimal Transport as a Defense Against Adversarial Attacks,"Quentin Bouniot, Romaric Audigier, Angélique Loesch",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.03156"" target=""_blank"">2102.03156</a>",,2025-12-03 22:39:25
Understanding the Interaction of Adversarial Training with Noisy Labels,"Jianing Zhu, Jingfeng Zhang, Bo Han, Tongliang Liu, Gang Niu, Hongxia Yang, Mohan Kankanhalli, Masashi Sugiyama",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.03482"" target=""_blank"">2102.03482</a>",,2025-12-03 22:39:25
Robust Single-step Adversarial Training with Regularizer,"Lehui Xie, Yaopeng Wang, Jia-Li Yin, Ximeng Liu",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.03381"" target=""_blank"">2102.03381</a>",,2025-12-03 22:39:25
Model Agnostic Answer Reranking System for Adversarial Question Answering,"Sagnik Majumder, Chinmoy Samant, Greg Durrett",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.03016"" target=""_blank"">2102.03016</a>",,2025-12-03 22:39:25
Adversarial defense for automatic speaker verification by cascaded self-supervised learning models,"Haibin Wu, Xu Li, Andy T. Liu, Zhiyong Wu, Helen Meng, Hung-yi Lee",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07047"" target=""_blank"">2102.07047</a>",,2025-12-03 22:39:25
Effective and Efficient Vote Attack on Capsule Networks,"Jindong Gu, Baoyuan Wu, Volker Tresp",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.10055"" target=""_blank"">2102.10055</a>",,2025-12-03 22:39:25
Cross-modal Adversarial Reprogramming,"Paarth Neekhara, Shehzeen Hussain, Jinglong Du, Shlomo Dubnov, Farinaz Koushanfar, Julian McAuley",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07325"" target=""_blank"">2102.07325</a>",,2025-12-03 22:39:25
Graphfool: Targeted Label Adversarial Attack on Graph Embedding,"Jinyin Chen, Xiang Lin, Dunjie Zhang, Wenrong Jiang, Guohan Huang, Hui Xiong, Yun Xiang",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.12284"" target=""_blank"">2102.12284</a>",,2025-12-03 22:39:25
Sandwich Batch Normalization: A Drop-In Replacement for Feature Distribution Heterogeneity,"Xinyu Gong, Wuyang Chen, Tianlong Chen, Zhangyang Wang",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.11382"" target=""_blank"">2102.11382</a>","<a href=""https://github.com/VITA-Group/Sandwich-Batch-Normalization"" target=""_blank"">VITA-Group</a>",2025-12-03 22:39:25
Man-in-The-Middle Attacks and Defense in a Power System Cyber-Physical Testbed,"Patrick Wlazlo, Abhijeet Sahu, Zeyu Mao, Hao Huang, Ana Goulart, Katherine Davis, Saman Zonouz",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.11455"" target=""_blank"">2102.11455</a>",,2025-12-03 22:39:25
Resilience of Bayesian Layer-Wise Explanations under Adversarial Attacks,"Ginevra Carbone, Guido Sanguinetti, Luca Bortolussi",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.11010"" target=""_blank"">2102.11010</a>",,2025-12-03 22:39:25
On the robustness of randomized classifiers to adversarial examples,"Rafael Pinot, Laurent Meunier, Florian Yger, Cédric Gouy-Pailler, Yann Chevaleyre, Jamal Atif",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.10875"" target=""_blank"">2102.10875</a>",,2025-12-03 22:39:25
Oriole: Thwarting Privacy against Trustworthy Deep Learning Models,"Liuqiao Chen, Hu Wang, Benjamin Zi Hao Zhao, Minhui Xue, Haifeng Qian",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.11502"" target=""_blank"">2102.11502</a>",,2025-12-03 22:39:25
Adversarial Examples Detection beyond Image Space,"Kejiang Chen, Yuefeng Chen, Hang Zhou, Chuan Qin, Xiaofeng Mao, Weiming Zhang, Nenghai Yu",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.11586"" target=""_blank"">2102.11586</a>",,2025-12-03 22:39:25
Enhancing Model Robustness By Incorporating Adversarial Knowledge Into Semantic Representation,"Jinfeng Li, Tianyu Du, Xiangyu Liu, Rong Zhang, Hui Xue, Shouling Ji",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.11584"" target=""_blank"">2102.11584</a>",,2025-12-03 22:39:25
Non-Singular Adversarial Robustness of Neural Networks,"Yu-Lin Tsai, Chia-Yi Hsu, Chia-Mu Yu, Pin-Yu Chen",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.11935"" target=""_blank"">2102.11935</a>",,2025-12-03 22:39:25
Adversarial Robustness with Non-uniform Perturbations,"Ecenaz Erdemir, Jeffrey Bickford, Luca Melis, Sergul Aydore",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.12002"" target=""_blank"">2102.12002</a>",,2025-12-03 22:39:25
Automated Discovery of Adaptive Attacks on Adversarial Defenses,"Chengyuan Yao, Pavol Bielik, Petar Tsankov, Martin Vechev",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.11860"" target=""_blank"">2102.11860</a>",,2025-12-03 22:39:25
Rethinking Natural Adversarial Examples for Classification Models,"Xiao Li, Jianmin Li, Ting Dai, Jie Shi, Jun Zhu, Xiaolin Hu",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.11731"" target=""_blank"">2102.11731</a>",,2025-12-03 22:39:25
The Sensitivity of Word Embeddings-based Author Detection Models to Semantic-preserving Adversarial Perturbations,"Jeremiah Duncan, Fabian Fallas, Chris Gropp, Emily Herron, Maria Mahbub, Paula Olaya, Eduardo Ponce, Tabitha K. Samuel, Daniel Schultz, Sudarshan Srinivasan, Maofeng Tang, Viktor Zenkov, Quan Zhou, Edmon Begoli",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.11917"" target=""_blank"">2102.11917</a>",,2025-12-03 22:39:25
Identifying Untrustworthy Predictions in Neural Networks by Geometric Gradient Analysis,"Leo Schwinn, An Nguyen, René Raab, Leon Bungert, Daniel Tenbrinck, Dario Zanca, Martin Burger, Bjoern Eskofier",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.12196"" target=""_blank"">2102.12196</a>",,2025-12-03 22:39:25
A Zeroth-Order Block Coordinate Descent Algorithm for Huge-Scale Black-Box Optimization,"HanQin Cai, Yuchen Lou, Daniel McKenzie, Wotao Yin",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.10707"" target=""_blank"">2102.10707</a>",,2025-12-03 22:39:25
Multiplicative Reweighting for Robust Neural Network Optimization,"Noga Bar, Tomer Koren, Raja Giryes",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.12192"" target=""_blank"">2102.12192</a>",,2025-12-03 22:39:25
Robust SleepNets,"Yigit Alparslan, Edward Kim",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.12555"" target=""_blank"">2102.12555</a>",,2025-12-03 22:39:25
Sketching Curvature for Efficient Out-of-Distribution Detection for Deep Neural Networks,"Apoorva Sharma, Navid Azizan, Marco Pavone",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.12567"" target=""_blank"">2102.12567</a>",,2025-12-03 22:39:25
Confidence Calibration with Bounded Error Using Transformations,"Sooyong Jang, Radoslav Ivanov, Insup lee, James Weimer",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.12680"" target=""_blank"">2102.12680</a>",,2025-12-03 22:39:25
CAP-GAN: Towards Adversarial Robustness with Cycle-consistent Attentional Purification,"Mingu Kang, Trung Quang Tran, Seungju Cho, Daeyoung Kim",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07304"" target=""_blank"">2102.07304</a>",,2025-12-03 22:39:25
Cybersecurity Threats in Connected and Automated Vehicles based Federated Learning Systems,"Ranwa Al Mallah, Godwin Badu-Marfo, Bilal Farooq",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.13256"" target=""_blank"">2102.13256</a>",,2025-12-03 22:39:25
Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints,"Maura Pintor, Fabio Roli, Wieland Brendel, Battista Biggio",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.12827"" target=""_blank"">2102.12827</a>",,2025-12-03 22:39:25
Understanding Robustness in Teacher-Student Setting: A New Perspective,"Zhuolin Yang, Zhaoxi Chen, Tiffany Cai, Xinyun Chen, Bo Li, Yuandong Tian",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.13170"" target=""_blank"">2102.13170</a>",,2025-12-03 22:39:25
Nonlinear Projection Based Gradient Estimation for Query Efficient Blackbox Attacks,"Huichen Li, Linyi Li, Xiaojun Xu, Xiaolu Zhang, Shuang Yang, Bo Li",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.13184"" target=""_blank"">2102.13184</a>","<a href=""https://github.com/AI-secure/NonLinear-BA"" target=""_blank"">AI-secure</a>",2025-12-03 22:39:25
Do Input Gradients Highlight Discriminative Features?,"Harshay Shah, Prateek Jain, Praneeth Netrapalli",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.12781"" target=""_blank"">2102.12781</a>",,2025-12-03 22:39:25
On Instabilities of Conventional Multi-Coil MRI Reconstruction to Small Adverserial Perturbations,"Chi Zhang, Jinghan Jia, Burhaneddin Yaman, Steen Moeller, Sijia Liu, Mingyi Hong, Mehmet Akçakaya",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.13066"" target=""_blank"">2102.13066</a>",,2025-12-03 22:39:25
What Doesn't Kill You Makes You Robust(er): Adversarial Training against Poisons and Backdoors,"Jonas Geiping, Liam Fowl, Gowthami Somepalli, Micah Goldblum, Michael Moeller, Tom Goldstein",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.13624"" target=""_blank"">2102.13624</a>",,2025-12-03 22:39:25
The Effects of Image Distribution and Task on Adversarial Robustness,"Owen Kunhardt, Arturo Deza, Tomaso Poggio",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.10534"" target=""_blank"">2102.10534</a>",,2025-12-03 22:39:25
A statistical framework for efficient out of distribution detection in deep neural networks,"Matan Haroush, Tzviel Frostig, Ruth Heller, Daniel Soudry",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.12967"" target=""_blank"">2102.12967</a>",,2025-12-03 22:39:25
Constrained Optimization to Train Neural Networks on Critical and Under-Represented Classes,"Sara Sangalli, Ertunc Erdil, Andreas Hoetker, Olivio Donati, Ender Konukoglu",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.12894"" target=""_blank"">2102.12894</a>",,2025-12-03 22:39:25
Just Noticeable Difference for Machine Perception and Generation of Regularized Adversarial Images with Minimal Perturbation,"Adil Kaan Akan, Emre Akbas, Fatos T. Yarman Vural",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.08079"" target=""_blank"">2102.08079</a>",,2025-12-03 22:39:25
On Fast Adversarial Robustness Adaptation in Model-Agnostic Meta-Learning,"Ren Wang, Kaidi Xu, Sijia Liu, Pin-Yu Chen, Tsui-Wei Weng, Chuang Gan, Meng Wang",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.10454"" target=""_blank"">2102.10454</a>",,2025-12-03 22:39:25
Perceptually Constrained Adversarial Attacks,"Muhammad Zaid Hameed, Andras Gyorgy",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07140"" target=""_blank"">2102.07140</a>",,2025-12-03 22:39:25
Adversarial Attack on Network Embeddings via Supervised Network Poisoning,"Viresh Gupta, Tanmoy Chakraborty",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07164"" target=""_blank"">2102.07164</a>",,2025-12-03 22:39:25
Exploring Adversarial Robustness of Deep Metric Learning,"Thomas Kobber Panum, Zi Wang, Pengyu Kan, Earlence Fernandes, Somesh Jha",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07265"" target=""_blank"">2102.07265</a>",,2025-12-03 22:39:25
Guided Interpolation for Adversarial Training,"Chen Chen, Jingfeng Zhang, Xilie Xu, Tianlei Hu, Gang Niu, Gang Chen, Masashi Sugiyama",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07327"" target=""_blank"">2102.07327</a>",,2025-12-03 22:39:25
Certifiably Robust Variational Autoencoders,"Ben Barrett, Alexander Camuto, Matthew Willetts, Tom Rainforth",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07559"" target=""_blank"">2102.07559</a>",,2025-12-03 22:39:25
And/or trade-off in artificial neurons: impact on adversarial robustness,Alessandro Fontana,arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07389"" target=""_blank"">2102.07389</a>",,2025-12-03 22:39:25
Low Curvature Activations Reduce Overfitting in Adversarial Training,"Vasu Singla, Sahil Singla, David Jacobs, Soheil Feizi",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07861"" target=""_blank"">2102.07861</a>",,2025-12-03 22:39:25
Universal Adversarial Examples and Perturbations for Quantum Classifiers,"Weiyuan Gong, Dong-Ling Deng",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07788"" target=""_blank"">2102.07788</a>",,2025-12-03 22:39:25
Generating Structured Adversarial Attacks Using Frank-Wolfe Method,"Ehsan Kazemi, Thomas Kerdreux, Liquang Wang",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07360"" target=""_blank"">2102.07360</a>",,2025-12-03 22:39:25
Certified Robustness to Programmable Transformations in LSTMs,"Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07818"" target=""_blank"">2102.07818</a>",,2025-12-03 22:39:25
Data Profiling for Adversarial Training: On the Ruin of Problematic Data,"Chengyu Dong, Liyuan Liu, Jingbo Shang",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07437"" target=""_blank"">2102.07437</a>",,2025-12-03 22:39:25
Resilient Machine Learning for Networked Cyber Physical Systems: A Survey for Machine Learning Security to Securing Machine Learning for CPS,"Felix Olowononi, Danda B. Rawat, Chunmei Liu",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.07244"" target=""_blank"">2102.07244</a>",,2025-12-03 22:39:25
A Law of Robustness for Weight-bounded Neural Networks,"Hisham Husain, Borja Balle",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.08093"" target=""_blank"">2102.08093</a>",,2025-12-03 22:39:25
Make Sure You're Unsure: A Framework for Verifying Probabilistic Specifications,"Leonard Berrada, Sumanth Dathathri, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Jonathan Uesato, Sven Gowal, M. Pawan Kumar",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.09479"" target=""_blank"">2102.09479</a>",,2025-12-03 22:39:25
Measuring $\ell_\infty$ Attacks by the $\ell_2$ Norm,"Sizhe Chen, Qinghua Tao, Zhixing Ye, Xiaolin Huang",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.10343"" target=""_blank"">2102.10343</a>",,2025-12-03 22:39:25
Globally-Robust Neural Networks,"Klas Leino, Zifan Wang, Matt Fredrikson",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.08452"" target=""_blank"">2102.08452</a>",,2025-12-03 22:39:25
A PAC-Bayes Analysis of Adversarial Robustness,"Guillaume IRIT Vidot, Paul LHC Viallard, Amaury LHC Habrard, Emilie LHC Morvant",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.11069"" target=""_blank"">2102.11069</a>",,2025-12-03 22:39:25
Fortify Machine Learning Production Systems: Detect and Classify Adversarial Attacks,"Matthew Ciolino, Josh Kalin, David Noever",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.09695"" target=""_blank"">2102.09695</a>",,2025-12-03 22:39:25
Random Projections for Improved Adversarial Robustness,"Ginevra Carbone, Guido Sanguinetti, Luca Bortolussi",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.09230"" target=""_blank"">2102.09230</a>",,2025-12-03 22:39:25
Center Smoothing: Provable Robustness for Functions with Metric-Space Outputs,"Aounon Kumar, Tom Goldstein",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.09701"" target=""_blank"">2102.09701</a>","<a href=""https://github.com/aounon/center-smoothing"" target=""_blank"">aounon</a>",2025-12-03 22:39:25
Improving Hierarchical Adversarial Robustness of Deep Neural Networks,"Avery Ma, Aladin Virmaux, Kevin Scaman, Juwei Lu",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.09012"" target=""_blank"">2102.09012</a>",,2025-12-03 22:39:25
Consistent Non-Parametric Methods for Maximizing Robustness,"Robi Bhattacharjee, Kamalika Chaudhuri",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.09086"" target=""_blank"">2102.09086</a>",,2025-12-03 22:39:25
Bridging the Gap Between Adversarial Robustness and Optimization Bias,"Fartash Faghri, Sven Gowal, Cristina Vasconcelos, David J. Fleet, Fabian Pedregosa, Nicolas Le Roux",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.08868"" target=""_blank"">2102.08868</a>",,2025-12-03 22:39:25
Towards Adversarial-Resilient Deep Neural Networks for False Data Injection Attack Detection in Power Grids,"Jiangnan Li, Yingyuan Yang, Jinyuan Stella Sun, Kevin Tomsovic, Hairong Qi",arXiv,2021-02,"<a href=""http://arxiv.org/abs/2102.09057"" target=""_blank"">2102.09057</a>",,2025-12-03 22:39:25
Image Steganography based on Iteratively Adversarial Samples of A Synchronized-directions Sub-image,"Xinghong Qin, Shunquan Tan, Bin Li, Weixuan Tang, Jiwu Huang",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.05209"" target=""_blank"">2101.05209</a>",,2025-12-03 22:39:25
Fundamental Tradeoffs in Distributionally Adversarial Training,"Mohammad Mehrabi, Adel Javanmard, Ryan A. Rossi, Anup Rao, Tung Mai",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.06309"" target=""_blank"">2101.06309</a>",,2025-12-03 22:39:25
"Untargeted, Targeted and Universal Adversarial Attacks and Defenses on Time Series","Pradeep Rathore, Arghya Basak, Sri Harsha Nistala, Venkataramana Runkana",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.05639"" target=""_blank"">2101.05639</a>",,2025-12-03 22:39:25
Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks,"Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li, Xingjun Ma",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.05930"" target=""_blank"">2101.05930</a>","<a href=""https://github.com/bboylyg/NAD"" target=""_blank"">bboylyg</a>",2025-12-03 22:39:25
Robusta: Robust AutoML for Feature Selection via Reinforcement Learning,"Xiaoyang Wang, Bo Li, Yibo Zhang, Bhavya Kailkhura, Klara Nahrstedt",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.05950"" target=""_blank"">2101.05950</a>",,2025-12-03 22:39:25
Context-Aware Image Denoising with Auto-Threshold Canny Edge Detection to Suppress Adversarial Perturbation,"Li-Yun Wang, Yeganeh Jalalpour, Wu-chi Feng",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.05833"" target=""_blank"">2101.05833</a>",,2025-12-03 22:39:25
Mining Data Impressions from Deep Models as Substitute for the Unavailable Training Data,"Gaurav Kumar Nayak, Konda Reddy Mopuri, Saksham Jain, Anirban Chakraborty",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.06069"" target=""_blank"">2101.06069</a>",,2025-12-03 22:39:25
"Heating up decision boundaries: isocapacitory saturation, adversarial scenarios and generalization bounds","Bogdan Georgiev, Lukas Franken, Mayukh Mukherjee",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.06061"" target=""_blank"">2101.06061</a>",,2025-12-03 22:39:25
Black-box Adversarial Attacks in Autonomous Vehicle Technology,"K Naveen Kumar, C Vishnu, Reshmi Mitra, C Krishna Mohan",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.06092"" target=""_blank"">2101.06092</a>",,2025-12-03 22:39:25
Adversarial Interaction Attack: Fooling AI to Misinterpret Human Intentions,"Nodens Koren, Qiuhong Ke, Yisen Wang, James Bailey, Xingjun Ma",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.06704"" target=""_blank"">2101.06704</a>",,2025-12-03 22:39:25
Adversarial Attacks On Multi-Agent Communication,"James Tu, Tsunhsuan Wang, Jingkang Wang, Sivabalan Manivasagam, Mengye Ren, Raquel Urtasun",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.06560"" target=""_blank"">2101.06560</a>",,2025-12-03 22:39:25
Multi-objective Search of Robust Neural Architectures against Multiple Types of Adversarial Attacks,"Jia Liu, Yaochu Jin",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.06507"" target=""_blank"">2101.06507</a>",,2025-12-03 22:39:25
Exploring Adversarial Robustness of Multi-Sensor Perception Systems in Self Driving,"James Tu, Huichen Li, Xinchen Yan, Mengye Ren, Yun Chen, Ming Liang, Eilyan Bitar, Ersin Yumer, Raquel Urtasun",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.06784"" target=""_blank"">2101.06784</a>",,2025-12-03 22:39:25
GraphAttacker: A General Multi-Task GraphAttack Framework,"Jinyin Chen, Dunjie Zhang, Zhaoyan Ming, Kejie Huang, Wenrong Jiang, Chen Cui",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.06855"" target=""_blank"">2101.06855</a>","<a href=""https://github.com/honoluluuuu/GraphAttacker"" target=""_blank"">honoluluuuu</a>",2025-12-03 22:39:25
Red Alarm for Pre-trained Models: Universal Vulnerability to Neuron-Level Backdoor Attacks,"Zhengyan Zhang, Guangxuan Xiao, Yongwei Li, Tian Lv, Fanchao Qi, Zhiyuan Liu, Yasheng Wang, Xin Jiang, Maosong Sun",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.06969"" target=""_blank"">2101.06969</a>","<a href=""https://github.com/thunlp/NeuBA"" target=""_blank"">thunlp</a>",2025-12-03 22:39:25
What Do Deep Nets Learn? Class-wise Patterns Revealed in the Input Space,"Shihao Zhao, Xingjun Ma, Yisen Wang, James Bailey, Bo Li, Yu-Gang Jiang",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.06898"" target=""_blank"">2101.06898</a>",,2025-12-03 22:39:25
Attention-Guided Black-box Adversarial Attacks with Large-Scale Multiobjective Evolutionary Optimization,"Jie Wang, Zhaoxia Yin, Jing Jiang, Yang Du",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.07512"" target=""_blank"">2101.07512</a>",,2025-12-03 22:39:25
PICA: A Pixel Correlation-based Attentional Black-box Adversarial Attack,"Jie Wang, Zhaoxia Yin, Jin Tang, Jing Jiang, Bin Luo",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.07538"" target=""_blank"">2101.07538</a>",,2025-12-03 22:39:25
Robustness of on-device Models: Adversarial Attack to Deep Learning Models on Android Apps,"Yujin Huang, Han Hu, Chunyang Chen",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.04401"" target=""_blank"">2101.04401</a>",,2025-12-03 22:39:25
Robustness Gym: Unifying the NLP Evaluation Landscape,"Karan Goel, Nazneen Rajani, Jesse Vig, Samson Tan, Jason Wu, Stephan Zheng, Caiming Xiong, Mohit Bansal, Christopher Ré",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.04840"" target=""_blank"">2101.04840</a>",,2025-12-03 22:39:25
Fooling Object Detectors: Adversarial Attacks by Half-Neighbor Masks,"Yanghao Zhang, Fu Wang, Wenjie Ruan",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.00989"" target=""_blank"">2101.00989</a>","<a href=""https://github.com/YanghaoZYH/HNM-PGD"" target=""_blank"">YanghaoZYH</a>",2025-12-03 22:39:25
Random Transformation of Image Brightness for Adversarial Attack,"Bo Yang, Kaiyong Xu, Hengjun Wang, Hengwei Zhang",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.04321"" target=""_blank"">2101.04321</a>",,2025-12-03 22:39:25
On the Effectiveness of Small Input Noise for Defending Against Query-based Black-Box Attacks,"Junyoung Byun, Hyojun Go, Changick Kim",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.04829"" target=""_blank"">2101.04829</a>",,2025-12-03 22:39:25
LowKey: Leveraging Adversarial Attacks to Protect Social Media Users from Facial Recognition,"Valeriia Cherepanova, Micah Goldblum, Harrison Foley, Shiyuan Duan, John Dickerson, Gavin Taylor, Tom Goldstein",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.07922"" target=""_blank"">2101.07922</a>",,2025-12-03 22:39:25
On the human-recognizability phenomenon of adversarially trained deep image classifiers,"Jonathan Helland, Nathan VanHoudnos",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.05219"" target=""_blank"">2101.05219</a>",,2025-12-03 22:39:25
Black-box Adversarial Attacks on Monocular Depth Estimation Using Evolutionary Multi-objective Optimization,"Renya Department of Information Science and Biomedical Engineering, Graduate School of Science and Engineering, Kagoshima University Daimo, Satoshi Department of Information Science and Biomedical Engineering, Graduate School of Science and Engineering, Kagoshima University Ono, Takahiro Department of Information Science and Biomedical Engineering, Graduate School of Science and Engineering, Kagoshima University Suzuki",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.10452"" target=""_blank"">2101.10452</a>",,2025-12-03 22:39:25
Improving DGA-Based Malicious Domain Classifiers for Malware Defense with Adversarial Machine Learning,"Ibrahim Yilmaz, Ambareen Siraj, Denis Ulybyshev",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.00521"" target=""_blank"">2101.00521</a>",,2025-12-03 22:39:25
"Robust Machine Learning Systems: Challenges, Current Trends, Perspectives, and the Road Ahead","Muhammad Shafique, Mahum Naseer, Theocharis Theocharides, Christos Kyrkou, Onur Mutlu, Lois Orosa, Jungwook Choi",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.02559"" target=""_blank"">2101.02559</a>",,2025-12-03 22:39:25
Local Black-box Adversarial Attacks: A Query Efficient Approach,"Tao Xiang, Hangcheng Liu, Shangwei Guo, Tianwei Zhang, Xiaofeng Liao",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.01032"" target=""_blank"">2101.01032</a>",,2025-12-03 22:39:25
Local Competition and Stochasticity for Adversarial Robustness in Deep Learning,"Konstantinos P. Panousis, Sotirios Chatzis, Antonios Alexos, Sergios Theodoridis",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.01121"" target=""_blank"">2101.01121</a>",,2025-12-03 22:39:25
Noise Sensitivity-Based Energy Efficient and Robust Adversary Detection in Neural Networks,"Rachel Sterneck, Abhishek Moitra, Priyadarshini Panda",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.01543"" target=""_blank"">2101.01543</a>",,2025-12-03 22:39:25
Understanding the Error in Evaluating Adversarial Robustness,"Pengfei Xia, Ziqiang Li, Hongjing Niu, Bin Li",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.02325"" target=""_blank"">2101.02325</a>",,2025-12-03 22:39:25
Adversarial Robustness by Design through Analog Computing and Synthetic Gradients,"Alessandro Cappelli, Ruben Ohana, Julien Launay, Laurent Meunier, Iacopo Poli, Florent Krzakala",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.02115"" target=""_blank"">2101.02115</a>","<a href=""https://github.com/lightonai/adversarial-robustness-by-design"" target=""_blank"">lightonai</a>",2025-12-03 22:39:25
Robust Text CAPTCHAs Using Adversarial Examples,"Rulin Shao, Zhouxing Shi, Jinfeng Yi, Pin-Yu Chen, Cho-Jui Hsieh",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.02483"" target=""_blank"">2101.02483</a>",,2025-12-03 22:39:25
The Effect of Prior Lipschitz Continuity on the Adversarial Robustness of Bayesian Neural Networks,"Arno Blaas, Stephen J. Roberts",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.02689"" target=""_blank"">2101.02689</a>",,2025-12-03 22:39:25
Exploring Adversarial Fake Images on Face Manifold,"Dongze Li, Wei Wang, Hongxing Fan, Jing Dong",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.03272"" target=""_blank"">2101.03272</a>",,2025-12-03 22:39:25
DiPSeN: Differentially Private Self-normalizing Neural Networks For Adversarial Robustness in Federated Learning,"Olakunle Ibitoye, M. Omair Shafiq, Ashraf Matrawy",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.03218"" target=""_blank"">2101.03218</a>",,2025-12-03 22:39:25
Adversarial Attack Attribution: Discovering Attributable Signals in Adversarial ML Attacks,"Marissa Dotter, Sherry Xie, Keith Manville, Josh Harguess, Colin Busho, Mikel Rodriguez",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.02899"" target=""_blank"">2101.02899</a>",,2025-12-03 22:39:25
Adversarially Robust and Explainable Model Compression with On-Device Personalization for Text Classification,"Yao Qiang, Supriya Tumkur Suresh Kumar, Marco Brocanelli, Dongxiao Zhu",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.05624"" target=""_blank"">2101.05624</a>",,2025-12-03 22:39:25
The Vulnerability of Semantic Segmentation Networks to Adversarial Attacks in Autonomous Driving: Enhancing Extensive Environment Sensing,"Andreas Bär, Jonas Löhdefink, Nikhil Kapoor, Serin J. Varghese, Fabian Hüger, Peter Schlicht, Tim Fingscheidt",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.03924"" target=""_blank"">2101.03924</a>",,2025-12-03 22:39:25
A Search-Based Testing Framework for Deep Neural Networks of Source Code Embedding,"Maryam Vahdat Pour, Zhuo Li, Lei Ma, Hadi Hemmati",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.07910"" target=""_blank"">2101.07910</a>",,2025-12-03 22:39:25
Adversarial Machine Learning Attacks on Condition-Based Maintenance Capabilities,Hamidreza Habibollahi Najaf Abadi,arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.12097"" target=""_blank"">2101.12097</a>",,2025-12-03 22:39:25
Fooling thermal infrared pedestrian detectors in real world using small bulbs,"Xiaopei Zhu, Xiao Li, Jianmin Li, Zheyao Wang, Xiaolin Hu",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.08154"" target=""_blank"">2101.08154</a>",,2025-12-03 22:39:25
Diverse Adversaries for Mitigating Bias in Training,"Xudong Han, Timothy Baldwin, Trevor Cohn",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.10001"" target=""_blank"">2101.10001</a>",,2025-12-03 22:39:25
Visual explanation of black-box model: Similarity Difference and Uniqueness (SIDU) method,"Satya M. Muddamsetty, Mohammad N. S. Jahromi, Andreea E. Ciontos, Laura M. Fenoy, Thomas B. Moeslund",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.10710"" target=""_blank"">2101.10710</a>","<a href=""https://github.com/satyamahesh84/SIDU_XAI_CODE"" target=""_blank"">satyamahesh84</a>",2025-12-03 22:39:25
Investigating the significance of adversarial attacks and their relation to interpretability for radar-based human activity recognition systems,"Utku Ozbulak, Baptist Vandersmissen, Azarakhsh Jalalvand, Ivo Couckuyt, Messem Arnout Van, Neve Wesley De",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.10562"" target=""_blank"">2101.10562</a>",,2025-12-03 22:39:25
Defenses Against Multi-Sticker Physical Domain Attacks on Classifiers,"Xinwei Zhao, Matthew C. Stamm",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.11060"" target=""_blank"">2101.11060</a>",,2025-12-03 22:39:25
The Effect of Class Definitions on the Transferability of Adversarial Attacks Against Forensic CNNs,"Xinwei Zhao, Matthew C. Stamm",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.11081"" target=""_blank"">2101.11081</a>",,2025-12-03 22:39:25
SkeletonVis: Interactive Visualization for Understanding Adversarial Attacks on Human Action Recognition Models,"Haekyu Park, Zijie J. Wang, Nilaksh Das, Anindya S. Paul, Pruthvi Perumalla, Zhiyan Zhou, Duen Horng Chau",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.10586"" target=""_blank"">2101.10586</a>",,2025-12-03 22:39:25
Adversarial Vulnerability of Active Transfer Learning,"Nicolas M. Müller, Konstantin Böttinger",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.10792"" target=""_blank"">2101.10792</a>",,2025-12-03 22:39:25
Property Inference From Poisoning,"Melissa Chase, Esha Ghosh, Saeed Mahloujifar",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.11073"" target=""_blank"">2101.11073</a>",,2025-12-03 22:39:25
Blind Image Denoising and Inpainting Using Robust Hadamard Autoencoders,"Rasika Karkare, Randy Paffenroth, Gunjan Mahindre",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.10876"" target=""_blank"">2101.10876</a>",,2025-12-03 22:39:25
Improving Neural Network Robustness through Neighborhood Preserving Layers,"Bingyuan Liu, Christopher Malon, Lingzhou Xue, Erik Kruus",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.11766"" target=""_blank"">2101.11766</a>",,2025-12-03 22:39:25
"Detecting Adversarial Examples by Input Transformations, Defense Perturbations, and Voting","Federico Nesti, Alessandro Biondi, Giorgio Buttazzo",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.11466"" target=""_blank"">2101.11466</a>",,2025-12-03 22:39:25
Adversarial Stylometry in the Wild: Transferable Lexical Substitution Attacks on Author Profiling,"Chris Emmery, Ákos Kádár, Grzegorz Chrupała",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.11310"" target=""_blank"">2101.11310</a>",,2025-12-03 22:39:25
Adversaries in Online Learning Revisited: with applications in Robust Optimization and Adversarial training,"Sebastian Pokutta, Huan Xu",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.11443"" target=""_blank"">2101.11443</a>",,2025-12-03 22:39:25
Robust Android Malware Detection System against Adversarial Attacks using Q-Learning,"Hemant Rathore, Sanjay K. Sahay, Piyush Nikam, Mohit Sewak",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.12031"" target=""_blank"">2101.12031</a>",,2025-12-03 22:39:25
Adversarial Learning with Cost-Sensitive Classes,"Haojing Shen, Sihong Chen, Ran Wang, Xizhao Wang",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.12372"" target=""_blank"">2101.12372</a>",,2025-12-03 22:39:25
"Invariance, encodings, and generalization: learning identity effects with neural networks","S. Brugiapaglia, M. Liu, P. Tupper",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.08386"" target=""_blank"">2101.08386</a>",,2025-12-03 22:39:25
Increasing the Confidence of Deep Neural Networks by Coverage Analysis,"Giulio Rossolini, Alessandro Biondi, Giorgio Carlo Buttazzo",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.12100"" target=""_blank"">2101.12100</a>",,2025-12-03 22:39:25
Adversarial Attacks on Deep Learning Based Power Allocation in a Massive MIMO Network,"B. R. Manoj, Meysam Sadeghi, Erik G. Larsson",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.12090"" target=""_blank"">2101.12090</a>",,2025-12-03 22:39:25
Towards Universal Physical Attacks On Cascaded Camera-Lidar 3D Object Detection Models,"Mazen Abdelfattah, Kaiwen Yuan, Z. Jane Wang, Rabab Ward",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.10747"" target=""_blank"">2101.10747</a>",,2025-12-03 22:39:25
Meta Adversarial Training against Universal Patches,"Jan Hendrik Metzen, Nicole Finnie, Robin Hutmacher",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.11453"" target=""_blank"">2101.11453</a>",,2025-12-03 22:39:25
They See Me Rollin': Inherent Vulnerability of the Rolling Shutter in CMOS Image Sensors,"Sebastian Köhler, Giulio Lovisotto, Simon Birnbach, Richard Baker, Ivan Martinovic",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.10011"" target=""_blank"">2101.10011</a>",,2025-12-03 22:39:25
Generating Black-Box Adversarial Examples in Sparse Domain,"Hadi Zanddizari, Behnam Zeinali, J. Morris Chang",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.09324"" target=""_blank"">2101.09324</a>",,2025-12-03 22:39:25
Adversarial Attacks for Tabular Data: Application to Fraud Detection and Imbalanced Data,"Francesco Cartella, Orlando Anunciacao, Yuki Funabiki, Daisuke Yamaguchi, Toru Akishita, Olivier Elshocht",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.08030"" target=""_blank"">2101.08030</a>",,2025-12-03 22:39:25
Generalizing Adversarial Examples by AdaBelief Optimizer,"Yixiang Wang, Jiqiang Liu, Xiaolin Chang",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.09930"" target=""_blank"">2101.09930</a>",,2025-12-03 22:39:25
A general multi-modal data learning method for Person Re-identification,Yunpeng Gong,arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.08533"" target=""_blank"">2101.08533</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defenses for Speaker Identification Systems,"Sonal Joshi, Jesús Villalba, Piotr Żelasko, Laureano Moro-Velázquez, Najim Dehak",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.08909"" target=""_blank"">2101.08909</a>",,2025-12-03 22:39:25
Self-Adaptive Training: Bridging Supervised and Self-Supervised Learning,"Lang Huang, Chao Zhang, Hongyang Zhang",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.08732"" target=""_blank"">2101.08732</a>","<a href=""https://github.com/LayneH/self-adaptive-training"" target=""_blank"">LayneH</a>",2025-12-03 22:39:25
Adv-OLM: Generating Textual Adversaries via OLM,"Vijit Malik, Ashwani Bhat, Ashutosh Modi",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.08523"" target=""_blank"">2101.08523</a>",,2025-12-03 22:39:25
Robust Reinforcement Learning on State Observations with Learned Optimal Adversary,"Huan Zhang, Hongge Chen, Duane Boning, Cho-Jui Hsieh",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.08452"" target=""_blank"">2101.08452</a>","<a href=""https://github.com/huanzhang12/ATLA_robust_RL"" target=""_blank"">huanzhang12</a>",2025-12-03 22:39:25
Adaptive Neighbourhoods for the Discovery of Adversarial Examples,"Jay Morgan, Adeline Paiement, Arno Pauly, Monika Seisenberger",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.09108"" target=""_blank"">2101.09108</a>",,2025-12-03 22:39:25
A Person Re-identification Data Augmentation Method with Adversarial Defense Effect,"Yunpeng Gong, Zhiyong Zeng, Liwen Chen, Yifan Luo, Bin Weng, Feng Ye",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.08783"" target=""_blank"">2101.08783</a>",,2025-12-03 22:39:25
Towards Optimal Branching of Linear and Semidefinite Relaxations for Neural Network Robustness Certification,"Brendon G. Anderson, Ziye Ma, Jingqi Li, Somayeh Sojoudi",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.09306"" target=""_blank"">2101.09306</a>",,2025-12-03 22:39:25
A Transferable Anti-Forensic Attack on Forensic CNNs Using A Generative Adversarial Network,"Xinwei Zhao, Chen Chen, Matthew C. Stamm",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.09568"" target=""_blank"">2101.09568</a>",,2025-12-03 22:39:25
Towards Practical Robustness Analysis for DNNs based on PAC-Model Learning,"Renjue Li, Pengfei Yang, Cheng-Chao Huang, Youcheng Sun, Bai Xue, Lijun Zhang",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.10102"" target=""_blank"">2101.10102</a>",,2025-12-03 22:39:25
Few-Shot Website Fingerprinting Attack,"Mantun Chen, Yongjun Wang, Zhiquan Qin, Xiatian Zhu",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.10063"" target=""_blank"">2101.10063</a>",,2025-12-03 22:39:25
Understanding and Achieving Efficient Robustness with Adversarial Supervised Contrastive Learning,"Anh Bui, Trung Le, He Zhao, Paul Montague, Seyit Camtepe, Dinh Phung",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.10027"" target=""_blank"">2101.10027</a>",,2025-12-03 22:39:25
Error Diffusion Halftoning Against Adversarial Examples,"Shao-Yuan Lo, Vishal M. Patel",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.09451"" target=""_blank"">2101.09451</a>","<a href=""https://github.com/shaoyuanlo/Halftoning-Defense"" target=""_blank"">shaoyuanlo</a>",2025-12-03 22:39:25
A Comprehensive Evaluation Framework for Deep Model Robustness,"Jun Guo, Wei Bao, Jiakai Wang, Yuqing Ma, Xinghai Gao, Gang Xiao, Aishan Liu, Jian Dong, Xianglong Liu, Wenjun Wu",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.09617"" target=""_blank"">2101.09617</a>",,2025-12-03 22:39:25
Online Adversarial Purification based on Self-Supervision,"Changhao Shi, Chester Holtz, Gal Mishne",arXiv,2021-01,"<a href=""http://arxiv.org/abs/2101.09387"" target=""_blank"">2101.09387</a>",,2025-12-03 22:39:25
Generating Out of Distribution Adversarial Attack using Latent Space Poisoning,"Ujjwal Upadhyay, Prerana Mukherjee",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.05027"" target=""_blank"">2012.05027</a>",,2025-12-03 22:39:25
Mitigating the Impact of Adversarial Attacks in Very Deep Networks,"Mohammed Hassanin, Ibrahim Radwan, Nour Moustafa, Murat Tahtali, Neeraj Kumar",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.04750"" target=""_blank"">2012.04750</a>",,2025-12-03 22:39:25
Overcomplete Representations Against Adversarial Videos,"Shao-Yuan Lo, Jeya Maria Jose Valanarasu, Vishal M. Patel",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.04262"" target=""_blank"">2012.04262</a>",,2025-12-03 22:39:25
EvaLDA: Efficient Evasion Attacks Towards Latent Dirichlet Allocation,"Qi Zhou, Haipeng Chen, Yitao Zheng, Zhen Wang",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.04864"" target=""_blank"">2012.04864</a>",,2025-12-03 22:39:25
Reinforcement Based Learning on Classification Task Could Yield Better Generalization and Adversarial Accuracy,Shashi Kant Gupta,arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.04353"" target=""_blank"">2012.04353</a>",,2025-12-03 22:39:25
Using Feature Alignment can Improve Clean Average Precision and Adversarial Robustness in Object Detection,"Weipeng Xu, Hongcheng Huang",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.04382"" target=""_blank"">2012.04382</a>","<a href=""https://github.com/grispeut/Feature-Alignment"" target=""_blank"">grispeut</a>",2025-12-03 22:39:25
A Deep Marginal-Contrastive Defense against Adversarial Attacks on 1D Models,"Mohammed Hassanin, Nour Moustafa, Murat Tahtali",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.04734"" target=""_blank"">2012.04734</a>",,2025-12-03 22:39:25
Locally optimal detection of stochastic targeted universal adversarial perturbations,"Amish Goel, Pierre Moulin",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.04692"" target=""_blank"">2012.04692</a>",,2025-12-03 22:39:25
On 1/n neural representation and robustness,"Josue Nassar, Piotr Aleksander Sokol, SueYeon Chung, Kenneth D. Harris, Il Memming Park",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.04729"" target=""_blank"">2012.04729</a>",,2025-12-03 22:39:25
Provable Defense against Privacy Leakage in Federated Learning from Representation Perspective,"Jingwei Sun, Ang Li, Binghui Wang, Huanrui Yang, Hai Li, Yiran Chen",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.06043"" target=""_blank"">2012.06043</a>",,2025-12-03 22:39:25
Composite Adversarial Attacks,"Xiaofeng Mao, Yuefeng Chen, Shuhui Wang, Hang Su, Yuan He, Hui Xue",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.05434"" target=""_blank"">2012.05434</a>",,2025-12-03 22:39:25
Securing Deep Spiking Neural Networks against Adversarial Attacks through Inherent Structural Parameters,"Rida El-Allami, Alberto Marchisio, Muhammad Shafique, Ihsen Alouani",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.05321"" target=""_blank"">2012.05321</a>",,2025-12-03 22:39:25
Detection of Adversarial Supports in Few-shot Classifiers Using Self-Similarity and Filtering,"Yi Xiang Marcus Tan, Penny Chong, Jiamei Sun, Ngai-Man Cheung, Yuval Elovici, Alexander Binder",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.06330"" target=""_blank"">2012.06330</a>",,2025-12-03 22:39:25
GNNUnlock: Graph Neural Networks-based Oracle-less Unlocking Scheme for Provably Secure Logic Locking,"Lilas Alrahis, Satwik Patnaik, Faiq Khalid, Muhammad Abdullah Hanif, Hani Saleh, Muhammad Shafique, Ozgur Sinanoglu",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.05948"" target=""_blank"">2012.05948</a>",,2025-12-03 22:39:25
SPAA: Stealthy Projector-based Adversarial Attacks on Deep Image Classifiers,"Bingyao Huang, Haibin Ling",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.05858"" target=""_blank"">2012.05858</a>",,2025-12-03 22:39:25
Geometric Adversarial Attacks and Defenses on 3D Point Clouds,"Itai Lang, Uriel Kotlicki, Shai Avidan",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.05657"" target=""_blank"">2012.05657</a>","<a href=""https://github.com/itailang/geometric_adv"" target=""_blank"">itailang</a>",2025-12-03 22:39:25
Robustness and Transferability of Universal Attacks on Compressed Models,"Alberto G. Matachana, Kenneth T. Co, Luis Muñoz-González, David Martinez, Emil C. Lupu",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.06024"" target=""_blank"">2012.06024</a>",,2025-12-03 22:39:25
An Empirical Review of Adversarial Defenses,Ayush Goel,arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.06332"" target=""_blank"">2012.06332</a>",,2025-12-03 22:39:25
I-GCN: Robust Graph Convolutional Network via Influence Mechanism,"Haoxi Zhan, Xiaobing Pei",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.06110"" target=""_blank"">2012.06110</a>",,2025-12-03 22:39:25
DSRNA: Differentiable Search of Robust Neural Architectures,"Ramtin Hosseini, Xingyi Yang, Pengtao Xie",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.06122"" target=""_blank"">2012.06122</a>",,2025-12-03 22:39:25
"Next Wave Artificial Intelligence: Robust, Explainable, Adaptable, Ethical, and Accountable","Odest Chadwicke Jenkins, Daniel Lopresti, Melanie Mitchell",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.06058"" target=""_blank"">2012.06058</a>",,2025-12-03 22:39:25
Analyzing and Improving Adversarial Training for Generative Modeling,"Xuwang Yin, Shiying Li, Gustavo K. Rohde",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.06568"" target=""_blank"">2012.06568</a>",,2025-12-03 22:39:25
Attack Agnostic Detection of Adversarial Examples via Random Subspace Analysis,"Nathan Drenkow, Neil Fendley, Philippe Burlina",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.06405"" target=""_blank"">2012.06405</a>",,2025-12-03 22:39:25
Query-free Black-box Adversarial Attacks on Graphs,"Jiarong Xu, Yizhou Sun, Xin Jiang, Yanhao Wang, Yang Yang, Chunping Wang, Jiangang Lu",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.06757"" target=""_blank"">2012.06757</a>",,2025-12-03 22:39:25
Achieving Adversarial Robustness Requires An Active Teacher,"Chao Ma, Lexing Ying",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.07233"" target=""_blank"">2012.07233</a>",,2025-12-03 22:39:25
Data Dependent Randomized Smoothing,"Motasem Alfarra, Adel Bibi, Philip H. S. Torr, Bernard Ghanem",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.04351"" target=""_blank"">2012.04351</a>",,2025-12-03 22:39:25
Poisoning Semi-supervised Federated Learning via Unlabeled Data: Attacks and Defenses,"Yi Liu, Xingliang Yuan, Ruihui Zhao, Cong Wang, Dusit Niyato, Yefeng Zheng",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.04432"" target=""_blank"">2012.04432</a>",,2025-12-03 22:39:25
FenceBox: A Platform for Defeating Adversarial Examples with Data Augmentation Techniques,"Han Qiu, Yi Zeng, Tianwei Zhang, Yong Jiang, Meikang Qiu",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.01701"" target=""_blank"">2012.01701</a>",,2025-12-03 22:39:25
A Singular Value Perspective on Model Robustness,"Malhar Jere, Maghav Kumar, Farinaz Koushanfar",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.03516"" target=""_blank"">2012.03516</a>",,2025-12-03 22:39:25
An Empirical Study of Derivative-Free-Optimization Algorithms for Targeted Black-Box Attacks in Deep Neural Networks,"Giuseppe Ughi, Vinayak Abrol, Jared Tanner",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.01901"" target=""_blank"">2012.01901</a>",,2025-12-03 22:39:25
Towards Imperceptible Adversarial Image Patches Based on Network Explanations,"Yaguan Qian, Jiamin Wang, Bin Wang, Zhaoquan Gu, Xiang Ling, Chunming Wu",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.00909"" target=""_blank"">2012.00909</a>",,2025-12-03 22:39:25
One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer,"Joni Korpihalkola, Tuomo Sipola, Samir Puuska, Tero Kokkonen",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.00517"" target=""_blank"">2012.00517</a>",,2025-12-03 22:39:25
Boosting Adversarial Attacks on Neural Networks with Better Optimizer,"Heng Yin, Hengwei Zhang, Jindong Wang, Ruiyu Dou",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.00567"" target=""_blank"">2012.00567</a>",,2025-12-03 22:39:25
Robustness Out of the Box: Compositional Representations Naturally Defend Against Black-Box Patch Attacks,"Christian Cosgrove, Adam Kortylewski, Chenglin Yang, Alan Yuille",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.00558"" target=""_blank"">2012.00558</a>",,2025-12-03 22:39:25
Adversarial Robustness Across Representation Spaces,"Pranjal Awasthi, George Yu, Chun-Sung Ferng, Andrew Tomkins, Da-Cheng Juan",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.00802"" target=""_blank"">2012.00802</a>",,2025-12-03 22:39:25
How Robust are Randomized Smoothing based Defenses to Data Poisoning?,"Akshay Mehra, Bhavya Kailkhura, Pin-Yu Chen, Jihun Hamm",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.01274"" target=""_blank"">2012.01274</a>",,2025-12-03 22:39:25
Content-Adaptive Pixel Discretization to Improve Model Robustness,"Ryan Feng, Wu-chi Feng, Atul Prakash",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.01699"" target=""_blank"">2012.01699</a>",,2025-12-03 22:39:25
Towards Defending Multiple $\ell_p$-norm Bounded Adversarial Perturbations via Gated Batch Normalization,"Aishan Liu, Shiyu Tang, Xinyun Chen, Lei Huang, Haotong Qin, Xianglong Liu, Dacheng Tao",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.01654"" target=""_blank"">2012.01654</a>",,2025-12-03 22:39:25
Binary Black-box Evasion Attacks Against Deep Learning-based Static Malware Detectors with Adversarial Byte-Level Language Model,"Mohammadreza Ebrahimi, Ning Zhang, James Hu, Muhammad Taqi Raza, Hsinchun Chen",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.07994"" target=""_blank"">2012.07994</a>",,2025-12-03 22:39:25
From a Fourier-Domain Perspective on Adversarial Examples to a Wiener Filter Defense for Semantic Segmentation,"Nikhil Kapoor, Andreas Bär, Serin Varghese, Jan David Schneider, Fabian Hüger, Peter Schlicht, Tim Fingscheidt",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.01558"" target=""_blank"">2012.01558</a>",,2025-12-03 22:39:25
Attribute-Guided Adversarial Training for Robustness to Natural Perturbations,"Tejas Gokhale, Rushil Anirudh, Bhavya Kailkhura, Jayaraman J. Thiagarajan, Chitta Baral, Yezhou Yang",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.01806"" target=""_blank"">2012.01806</a>",,2025-12-03 22:39:25
Channel Effects on Surrogate Models of Adversarial Attacks against Wireless Signal Classifiers,"Brian Kim, Yalin E. Sagduyu, Tugba Erpek, Kemal Davaslioglu, Sennur Ulukus",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.02160"" target=""_blank"">2012.02160</a>",,2025-12-03 22:39:25
FAT: Federated Adversarial Training,"Giulio Zizzo, Ambrish Rawat, Mathieu Sinn, Beat Buesser",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.01791"" target=""_blank"">2012.01791</a>",,2025-12-03 22:39:25
Backpropagating Linearly Improves Transferability of Adversarial Examples,"Yiwen Guo, Qizhang Li, Hao Chen",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.03528"" target=""_blank"">2012.03528</a>",,2025-12-03 22:39:25
Ethical Testing in the Real World: Evaluating Physical Testing of Adversarial Machine Learning,"Kendra Albert, Maggie Delano, Jonathon Penney, Afsaneh Rigot, Ram Shankar Siva Kumar",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.02048"" target=""_blank"">2012.02048</a>",,2025-12-03 22:39:25
Kernel-convoluted Deep Neural Networks with Data Augmentation,"Minjin Kim, Young-geun Kim, Dongha Kim, Yongdai Kim, Myunghee Cho Paik",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.02521"" target=""_blank"">2012.02521</a>",,2025-12-03 22:39:25
Unsupervised Adversarially-Robust Representation Learning on Graphs,"Jiarong Xu, Yang Yang, Junru Chen, Chunping Wang, Xin Jiang, Jiangang Lu, Yizhou Sun",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.02486"" target=""_blank"">2012.02486</a>",,2025-12-03 22:39:25
Towards Natural Robustness Against Adversarial Examples,"Haoyu Chu, Shikui Wei, Yao Zhao",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.02452"" target=""_blank"">2012.02452</a>",,2025-12-03 22:39:25
Practical No-box Adversarial Attacks against DNNs,"Qizhang Li, Yiwen Guo, Hao Chen",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.02525"" target=""_blank"">2012.02525</a>",,2025-12-03 22:39:25
Advocating for Multiple Defense Strategies against Adversarial Examples,"Alexandre Araujo, Laurent Meunier, Rafael Pinot, Benjamin Negrevergne",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.02632"" target=""_blank"">2012.02632</a>",,2025-12-03 22:39:25
Evaluating adversarial robustness in simulated cerebellum,"Liu Yuezhang, Bo Li, Qifeng Chen",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.02976"" target=""_blank"">2012.02976</a>",,2025-12-03 22:39:25
PAC-Learning for Strategic Classification,"Ravi Sundaram, Anil Vullikanti, Haifeng Xu, Fan Yao",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.03310"" target=""_blank"">2012.03310</a>",,2025-12-03 22:39:25
Black-box Model Inversion Attribute Inference Attacks on Classification Models,"Shagufta Mehnaz, Ninghui Li, Elisa Bertino",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.03404"" target=""_blank"">2012.03404</a>",,2025-12-03 22:39:25
Reprogramming Language Models for Molecular Representation Learning,"Ria Vinod, Pin-Yu Chen, Payel Das",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.03460"" target=""_blank"">2012.03460</a>",,2025-12-03 22:39:25
Are DNNs fooled by extremely unrecognizable images?,"Soichiro Kumano, Hiroshi Kera, Toshihiko Yamasaki",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.03843"" target=""_blank"">2012.03843</a>",,2025-12-03 22:39:25
Learning to Separate Clusters of Adversarial Representations for Robust Adversarial Detection,"Byunggill Joe, Jihun Hamm, Sung Ju Hwang, Sooel Son, Insik Shin",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.03483"" target=""_blank"">2012.03483</a>",,2025-12-03 22:39:25
Contrastive Learning with Adversarial Perturbations for Conditional Text Generation,"Seanie Lee, Dong Bok Lee, Sung Ju Hwang",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.07280"" target=""_blank"">2012.07280</a>",,2025-12-03 22:39:25
Closeness and Uncertainty Aware Adversarial Examples Detection in Adversarial Machine Learning,"Omer Faruk Tuna, Ferhat Ozgur Catak, M. Taner Eskil",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.06390"" target=""_blank"">2012.06390</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness via Probabilistically Compact Loss with Logit Constraints,"Xin Li, Xiangrui Li, Deng Pan, Dongxiao Zhu",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.07688"" target=""_blank"">2012.07688</a>","<a href=""https://github.com/xinli0928/PC-LC"" target=""_blank"">xinli0928</a>",2025-12-03 22:39:25
On Frank-Wolfe Optimization for Adversarial Robustness and Interpretability,"Theodoros Tsiligkaridis, Jay Roberts",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.12368"" target=""_blank"">2012.12368</a>",,2025-12-03 22:39:25
Unadversarial Examples: Designing Objects for Robust Vision,"Hadi Salman, Andrew Ilyas, Logan Engstrom, Sai Vemprala, Aleksander Madry, Ashish Kapoor",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.12235"" target=""_blank"">2012.12235</a>",,2025-12-03 22:39:25
Learning to Initialize Gradient Descent Using Gradient Descent,"Kartik Ahuja, Amit Dhurandhar, Kush R. Varshney",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.12141"" target=""_blank"">2012.12141</a>",,2025-12-03 22:39:25
Poisoning Attacks on Cyber Attack Detectors for Industrial Control Systems,"Moshe Kravchik, Battista Biggio, Asaf Shabtai",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.15740"" target=""_blank"">2012.15740</a>",,2025-12-03 22:39:25
SCOPE CPS: Secure Compiling of PLCs in Cyber-Physical Systems,"Eyasu Getahun Chekole, Martin Ochoa, Sudipta Chattopadhyay",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.12529"" target=""_blank"">2012.12529</a>",,2025-12-03 22:39:25
Gradient-Free Adversarial Attacks for Bayesian Neural Networks,"Matthew Yuan, Matthew Wicker, Luca Laurenti",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.12640"" target=""_blank"">2012.12640</a>",,2025-12-03 22:39:25
The Translucent Patch: A Physical and Universal Attack on Object Detectors,"Alon Zolfi, Moshe Kravchik, Yuval Elovici, Asaf Shabtai",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.12528"" target=""_blank"">2012.12528</a>",,2025-12-03 22:39:25
Learning Robust Representation for Clustering through Locality Preserving Variational Discriminative Network,"Ruixuan Luo, Wei Li, Zhiyuan Zhang, Ruihan Bao, Keiko Harimoto, Xu Sun",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.13489"" target=""_blank"">2012.13489</a>",,2025-12-03 22:39:25
Adversarial Momentum-Contrastive Pre-Training,"Cong Xu, Min Yang",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.13154"" target=""_blank"">2012.13154</a>","<a href=""https://github.com/MTandHJ/amoc"" target=""_blank"">MTandHJ</a>",2025-12-03 22:39:25
Improving the Certified Robustness of Neural Networks via Consistency Regularization,"Mengting Xu, Tao Zhang, Zhongnian Li, Daoqiang Zhang",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.13103"" target=""_blank"">2012.13103</a>",,2025-12-03 22:39:25
Exploring Adversarial Examples via Invertible Neural Networks,"Ruqi Bai, Saurabh Bagchi, David I. Inouye",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.13111"" target=""_blank"">2012.13111</a>",,2025-12-03 22:39:25
A Context Aware Approach for Generating Natural Language Attacks,"Rishabh Maheshwary, Saket Maheshwary, Vikram Pudi",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.13339"" target=""_blank"">2012.13339</a>",,2025-12-03 22:39:25
A Simple Fine-tuning Is All You Need: Towards Robust Deep Learning Via Adversarial Fine-tuning,"Ahmadreza Jeddi, Mohammad Javad Shafiee, Alexander Wong",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.13628"" target=""_blank"">2012.13628</a>",,2025-12-03 22:39:25
"Robustness, Privacy, and Generalization of Adversarial Training","Fengxiang He, Shaopeng Fu, Bohan Wang, Dacheng Tao",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.13573"" target=""_blank"">2012.13573</a>","<a href=""https://github.com/fshp971/RPG"" target=""_blank"">fshp971</a>",2025-12-03 22:39:25
Assessment of the Relative Importance of different hyper-parameters of LSTM for an IDS,"Mohit Sewak, Sanjay K. Sahay, Hemant Rathore",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.14427"" target=""_blank"">2012.14427</a>",,2025-12-03 22:39:25
Sparse Adversarial Attack to Object Detection,Jiayu Bao,arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.13692"" target=""_blank"">2012.13692</a>","<a href=""https://github.com/THUrssq/Tianchi04"" target=""_blank"">THUrssq</a>",2025-12-03 22:39:25
My Teacher Thinks The World Is Flat! Interpreting Automatic Essay Scoring Mechanism,"Swapnil Parekh, Yaman Kumar Singla, Changyou Chen, Junyi Jessy Li, Rajiv Ratn Shah",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.13872"" target=""_blank"">2012.13872</a>",,2025-12-03 22:39:25
Person Re-identification with Adversarial Triplet Embedding,Xinglu Wang,arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.14057"" target=""_blank"">2012.14057</a>",,2025-12-03 22:39:25
Analysis of Dominant Classes in Universal Adversarial Perturbations,"Jon Vadillo, Roberto Santana, Jose A. Lozano",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.14352"" target=""_blank"">2012.14352</a>",,2025-12-03 22:39:25
Enhanced Regularizers for Attributional Robustness,"Anindya Sarkar, Anirban Sarkar, Vineeth N Balasubramanian",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.14395"" target=""_blank"">2012.14395</a>",,2025-12-03 22:39:25
Generating Natural Language Attacks in a Hard Label Black Box Setting,"Rishabh Maheshwary, Saket Maheshwary, Vikram Pudi",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.14956"" target=""_blank"">2012.14956</a>",,2025-12-03 22:39:25
"With False Friends Like These, Who Can Have Self-Knowledge?","Lue Tao, Songcan Chen",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.14738"" target=""_blank"">2012.14738</a>",,2025-12-03 22:39:25
HaS-Nets: A Heal and Select Mechanism to Defend DNNs Against Backdoor Attacks for Data Collection Scenarios,"Hassan Ali, Surya Nepal, Salil S. Kanhere, Sanjay Jha",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.07474"" target=""_blank"">2012.07474</a>",,2025-12-03 22:39:25
Generating Adversarial Examples in Chinese Texts Using Sentence-Pieces,"Linyang Li, Yunfan Shao, Demin Song, Xipeng Qiu, Xuanjing Huang",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.14769"" target=""_blank"">2012.14769</a>",,2025-12-03 22:39:25
Beating Attackers At Their Own Games: Adversarial Example Detection Using Adversarial Gradient Directions,"Yuhang Wu, Sunpreet S. Arora, Yanhong Wu, Hao Yang",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.15386"" target=""_blank"">2012.15386</a>",,2025-12-03 22:39:25
"Temporally-Transferable Perturbations: Efficient, One-Shot Adversarial Attacks for Online Visual Object Trackers","Krishna Kanth Nakka, Mathieu Salzmann",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.15183"" target=""_blank"">2012.15183</a>",,2025-12-03 22:39:25
Patch-wise++ Perturbation for Adversarial Targeted Attacks,"Lianli Gao, Qilong Zhang, Jingkuan Song, Heng Tao Shen",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.15503"" target=""_blank"">2012.15503</a>",,2025-12-03 22:39:25
Better Robustness by More Coverage: Adversarial Training with Mixup Augmentation for Robust Fine-tuning,"Chenglei Si, Zhengyan Zhang, Fanchao Qi, Zhiyuan Liu, Yasheng Wang, Qun Liu, Maosong Sun",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.15699"" target=""_blank"">2012.15699</a>",,2025-12-03 22:39:25
Multi-shot NAS for Discovering Adversarially Robust Convolutional Neural Architectures at Targeted Capacities,"Xuefei Ning, Junbo Zhao, Wenshuo Li, Tianchen Zhao, Huazhong Yang, Yu Wang",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.11835"" target=""_blank"">2012.11835</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness in Weight-quantized Neural Networks,"Chang Song, Elias Fallon, Hai Li",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.14965"" target=""_blank"">2012.14965</a>",,2025-12-03 22:39:25
Genetic Adversarial Training of Decision Trees,"Francesco Ranzato, Marco Zanella",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.11352"" target=""_blank"">2012.11352</a>",,2025-12-03 22:39:25
AdvExpander: Generating Natural Language Adversarial Examples by Expanding Text,"Zhihong Shao, Zitao Liu, Jiyong Zhang, Zhongqin Wu, Minlie Huang",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.10235"" target=""_blank"">2012.10235</a>",,2025-12-03 22:39:25
Robustness Threats of Differential Privacy,"Nurislam Tursynbek, Aleksandr Petiushko, Ivan Oseledets",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.07828"" target=""_blank"">2012.07828</a>",,2025-12-03 22:39:25
Adaptive Verifiable Training Using Pairwise Class Similarity,"Shiqi Wang, Kevin Eykholt, Taesung Lee, Jiyong Jang, Ian Molloy",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.07887"" target=""_blank"">2012.07887</a>",,2025-12-03 22:39:25
Disentangled Information Bottleneck,"Ziqi Pan, Li Niu, Jianfu Zhang, Liqing Zhang",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.07372"" target=""_blank"">2012.07372</a>",,2025-12-03 22:39:25
Amata: An Annealing Mechanism for Adversarial Training Acceleration,"Nanyang Ye, Qianxiao Li, Xiao-Yun Zhou, Zhanxing Zhu",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.08112"" target=""_blank"">2012.08112</a>",,2025-12-03 22:39:25
FAWA: Fast Adversarial Watermark Attack on Optical Character Recognition (OCR) Systems,"Lu Chen, Jiao Sun, Wei Xu",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.08096"" target=""_blank"">2012.08096</a>",,2025-12-03 22:39:25
FoggySight: A Scheme for Facial Lookup Privacy,"Ivan Evtimov, Pascal Sturmfels, Tadayoshi Kohno",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.08588"" target=""_blank"">2012.08588</a>",,2025-12-03 22:39:25
On the Limitations of Denoising Strategies as Adversarial Defenses,"Zhonghan Niu, Zhaoxi Chen, Linyi Li, Yubin Yang, Bo Li, Jinfeng Yi",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.09384"" target=""_blank"">2012.09384</a>",,2025-12-03 22:39:25
Incremental Verification of Fixed-Point Implementations of Neural Networks,"Luiz Sena, Erickson Alves, Iury Bessa, Eddie Filho, Lucas Cordeiro",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.11220"" target=""_blank"">2012.11220</a>",,2025-12-03 22:39:25
Characterizing the Evasion Attackability of Multi-label Classifiers,"Zhuo Yang, Yufei Han, Xiangliang Zhang",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.09427"" target=""_blank"">2012.09427</a>",,2025-12-03 22:39:25
Efficient Training of Robust Decision Trees Against Adversarial Examples,"Daniël Vos, Sicco Verwer",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.10438"" target=""_blank"">2012.10438</a>",,2025-12-03 22:39:25
RAILS: A Robust Adversarial Immune-inspired Learning System,"Ren Wang, Tianqi Chen, Stephen Lindsly, Alnawaz Rehemtulla, Alfred Hero, Indika Rajapakse",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.10485"" target=""_blank"">2012.10485</a>",,2025-12-03 22:39:25
Adversarially Robust Estimate and Risk Analysis in Linear Regression,"Yue Xing, Ruizhi Zhang, Guang Cheng",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.10278"" target=""_blank"">2012.10278</a>",,2025-12-03 22:39:25
A Hierarchical Feature Constraint to Camouflage Medical Adversarial Attacks,"Qingsong Yao, Zecheng He, Yi Lin, Kai Ma, Yefeng Zheng, S. Kevin Zhou",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.09501"" target=""_blank"">2012.09501</a>",,2025-12-03 22:39:25
ROBY: Evaluating the Robustness of a Deep Model by its Decision Boundaries,"Jinyin Chen, Zhen Wang, Haibin Zheng, Jun Xiao, Zhaoyan Ming",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.10282"" target=""_blank"">2012.10282</a>","<a href=""https://github.com/baaaad/ROBY-Evaluating-the-Robustness-of-a-Deep-Model-by-its-Decision-Boundaries"" target=""_blank"">baaaad</a>",2025-12-03 22:39:25
Adjust-free adversarial example generation in speech recognition using evolutionary multi-objective optimization under black-box condition,"Shoma Ishida, Satoshi Ono",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.11138"" target=""_blank"">2012.11138</a>",,2025-12-03 22:39:25
Blurring Fools the Network -- Adversarial Attacks by Feature Peak Suppression and Gaussian Blurring,"Chenchen Zhao, Hao Li",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.11442"" target=""_blank"">2012.11442</a>",,2025-12-03 22:39:25
Semantics and explanation: why counterfactual explanations produce adversarial examples in deep neural networks,"Kieran Browne, Ben Swift",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.10076"" target=""_blank"">2012.10076</a>",,2025-12-03 22:39:25
Deep Feature Space Trojan Attack of Neural Networks by Controlled Detoxification,"Siyuan Cheng, Yingqi Liu, Shiqing Ma, Xiangyu Zhang",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.11212"" target=""_blank"">2012.11212</a>",,2025-12-03 22:39:25
Self-Progressing Robust Training,"Minhao Cheng, Pin-Yu Chen, Sijia Liu, Shiyu Chang, Cho-Jui Hsieh, Payel Das",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.11769"" target=""_blank"">2012.11769</a>",,2025-12-03 22:39:25
Exploiting Vulnerability of Pooling in Convolutional Neural Networks by Strict Layer-Output Manipulation for Adversarial Attacks,"Chenchen Zhao, Hao Li",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.11413"" target=""_blank"">2012.11413</a>",,2025-12-03 22:39:25
Defence against adversarial attacks using classical and quantum-enhanced Boltzmann machines,"Aidan Kehoe, Peter Wittek, Yanbo Xue, Alejandro Pozas-Kerstjens",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.11619"" target=""_blank"">2012.11619</a>",,2025-12-03 22:39:25
On Success and Simplicity: A Second Look at Transferable Targeted Attacks,"Zhengyu Zhao, Zhuoran Liu, Martha Larson",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.11207"" target=""_blank"">2012.11207</a>",,2025-12-03 22:39:25
Learning from What We Know: How to Perform Vulnerability Prediction using Noisy Historical Data,"Aayush Garg, Renzo Degiovanni, Matthieu Jimenez, Maxime Cordy, Mike Papadakis, Yves Le Traon",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.11701"" target=""_blank"">2012.11701</a>",,2025-12-03 22:39:25
Color Channel Perturbation Attacks for Fooling Convolutional Neural Networks and A Defense Against Such Attacks,"Jayendra Kantipudi, Shiv Ram Dubey, Soumendu Chakraborty",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.14456"" target=""_blank"">2012.14456</a>","<a href=""https://github.com/jayendrakantipudi/Color-Channel-Perturbation-Attack"" target=""_blank"">jayendrakantipudi</a>",2025-12-03 22:39:25
Sample Complexity of Adversarially Robust Linear Classification on Separated Data,"Robi Bhattacharjee, Somesh Jha, Kamalika Chaudhuri",arXiv,2020-12,"<a href=""http://arxiv.org/abs/2012.10794"" target=""_blank"">2012.10794</a>",,2025-12-03 22:39:25
Adversarial Black-Box Attacks On Text Classifiers Using Multi-Objective Genetic Optimization Guided By Deep Networks,"Alex Mathai, Shreya Khare, Srikanth Tamilselvam, Senthil Mani",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.03901"" target=""_blank"">2011.03901</a>",,2025-12-03 22:39:25
Solving Inverse Problems With Deep Neural Networks -- Robustness Included?,"Martin Genzel, Jan Macdonald, Maximilian März",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.04268"" target=""_blank"">2011.04268</a>",,2025-12-03 22:39:25
Efficient and Transferable Adversarial Examples from Bayesian Neural Networks,"Martin Gubri, Maxime Cordy, Mike Papadakis, Yves Le Traon, Koushik Sen",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.05074"" target=""_blank"">2011.05074</a>",,2025-12-03 22:39:25
Detecting Adversarial Patches with Class Conditional Reconstruction Networks,"Perry Deng, Mohammad Saidur Rahman, Matthew Wright",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.05850"" target=""_blank"">2011.05850</a>",,2025-12-03 22:39:25
Adversarial images for the primate brain,"Li Yuan, Will Xiao, Gabriel Kreiman, Francis E. H. Tay, Jiashi Feng, Margaret S. Livingstone",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.05623"" target=""_blank"">2011.05623</a>",,2025-12-03 22:39:25
"Sparse PCA: Algorithms, Adversarial Perturbations and Certificates","Tommaso d'Orsi, Pravesh K. Kothari, Gleb Novikov, David Steurer",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.06585"" target=""_blank"">2011.06585</a>",,2025-12-03 22:39:25
Adversarial Robustness Against Image Color Transformation within Parametric Filter Space,"Zhengyu Zhao, Zhuoran Liu, Martha Larson",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.06690"" target=""_blank"">2011.06690</a>",,2025-12-03 22:39:25
Query-based Targeted Action-Space Adversarial Policies on Deep Reinforcement Learning Agents,"Xian Yeow Lee, Yasaman Esfandiari, Kai Liang Tan, Soumik Sarkar",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.07114"" target=""_blank"">2011.07114</a>",,2025-12-03 22:39:25
Transformer-Encoder Detector Module: Using Context to Improve Robustness to Adversarial Attacks on Object Detection,"Faisal Alamri, Sinan Kalkan, Nicolas Pugeault",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.06978"" target=""_blank"">2011.06978</a>",,2025-12-03 22:39:25
Audio-Visual Event Recognition through the lens of Adversary,"Juncheng B Li, Kaixin Ma, Shuhui Qu, Po-Yao Huang, Florian Metze",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.07430"" target=""_blank"">2011.07430</a>",,2025-12-03 22:39:25
Power Side-Channel Attacks on BNN Accelerators in Remote FPGAs,"Shayan Moini, Shanquan Tian, Jakub Szefer, Daniel Holcomb, Russell Tessier",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.07603"" target=""_blank"">2011.07603</a>",,2025-12-03 22:39:25
Shaping Deep Feature Space towards Gaussian Mixture for Visual Classification,"Weitao Wan, Jiansheng Chen, Cheng Yu, Tong Wu, Yuanyi Zhong, Ming-Hsuan Yang",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.09066"" target=""_blank"">2011.09066</a>",,2025-12-03 22:39:25
Almost Tight L0-norm Certified Robustness of Top-k Predictions against Adversarial Perturbations,"Jinyuan Jia, Binghui Wang, Xiaoyu Cao, Hongbin Liu, Neil Zhenqiang Gong",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.07633"" target=""_blank"">2011.07633</a>",,2025-12-03 22:39:25
Ensemble of Models Trained by Key-based Transformed Images for Adversarially Robust Defense Against Black-box Attacks,"MaungMaung AprilPyone, Hitoshi Kiya",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.07697"" target=""_blank"">2011.07697</a>",,2025-12-03 22:39:25
Towards Understanding the Regularization of Adversarial Robustness on Neural Networks,"Yuxin Wen, Shuai Li, Kui Jia",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.07478"" target=""_blank"">2011.07478</a>",,2025-12-03 22:39:25
Extreme Value Preserving Networks,"Mingjie Sun, Jianguo Li, Changshui Zhang",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.08367"" target=""_blank"">2011.08367</a>",,2025-12-03 22:39:25
Combining GANs and AutoEncoders for Efficient Anomaly Detection,"Fabio ISTI CNR, Pisa, Italy Carrara, Giuseppe ISTI CNR, Pisa, Italy Amato, Luca ISTI CNR, Pisa, Italy Brombin, Fabrizio ISTI CNR, Pisa, Italy Falchi, Claudio ISTI CNR, Pisa, Italy Gennaro",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.08102"" target=""_blank"">2011.08102</a>",,2025-12-03 22:39:25
Adversarially Robust Classification based on GLRT,"Bhagyashree Puranik, Upamanyu Madhow, Ramtin Pedarsani",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.07835"" target=""_blank"">2011.07835</a>",,2025-12-03 22:39:25
Enforcing robust control guarantees within neural network policies,"Priya L. Donti, Melrose Roderick, Mahyar Fazlyab, J. Zico Kolter",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.08105"" target=""_blank"">2011.08105</a>",,2025-12-03 22:39:25
MAAC: Novel Alert Correlation Method To Detect Multi-step Attack,"Xiaoyu Wang, Lei Yu, Houhua He, Xiaorui Gong",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.07793"" target=""_blank"">2011.07793</a>",,2025-12-03 22:39:25
Probing Predictions on OOD Images via Nearest Categories,"Yao-Yuan Yang, Cyrus Rashtchian, Ruslan Salakhutdinov, Kamalika Chaudhuri",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.08485"" target=""_blank"">2011.08485</a>","<a href=""https://github.com/yangarbiter/nearest-category-generalization"" target=""_blank"">yangarbiter</a>",2025-12-03 22:39:25
Generating universal language adversarial examples by understanding and enhancing the transferability across neural models,"Liping Yuan, Xiaoqing Zheng, Yi Zhou, Cho-Jui Hsieh, Kai-wei Chang, Xuanjing Huang",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.08558"" target=""_blank"">2011.08558</a>",,2025-12-03 22:39:25
Single-Node Attacks for Fooling Graph Neural Networks,"Ben Finkelshtein, Chaim Baskin, Evgenii Zheltonozhskii, Uri Alon",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.03574"" target=""_blank"">2011.03574</a>","<a href=""https://github.com/benfinkelshtein/SINGLE"" target=""_blank"">benfinkelshtein</a>",2025-12-03 22:39:25
Bridging the Performance Gap between FGSM and PGD Adversarial Training,"Tianjin Huang, Vlado Menkovski, Yulong Pei, Mykola Pechenizkiy",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.05157"" target=""_blank"">2011.05157</a>",,2025-12-03 22:39:25
Frequency-based Automated Modulation Classification in the Presence of Adversaries,"Rajeev Sahay, Christopher G. Brinton, David J. Love",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.01132"" target=""_blank"">2011.01132</a>",,2025-12-03 22:39:25
A survey on practical adversarial examples for malware classifiers,"Daniel Park, Bülent Yener",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.05973"" target=""_blank"">2011.05973</a>",,2025-12-03 22:39:25
A Black-Box Attack Model for Visually-Aware Recommender Systems,"Rami Cohen, Oren Sar Shalom, Dietmar Jannach, Amihood Amir",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.02701"" target=""_blank"">2011.02701</a>",,2025-12-03 22:39:25
FoolHD: Fooling speaker identification by Highly imperceptible adversarial Disturbances,"Ali Shahin Shamsabadi, Francisco Sepúlveda Teixeira, Alberto Abad, Bhiksha Raj, Andrea Cavallaro, Isabel Trancoso",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.08483"" target=""_blank"">2011.08483</a>",,2025-12-03 22:39:25
Adversarial Robust Training of Deep Learning MRI Reconstruction Models,"Francesco Calivá, Kaiyang Cheng, Rutwik Shah, Valentina Pedoia",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.00070"" target=""_blank"">2011.00070</a>","<a href=""https://github.com/fcaliva/fastMRI_BB_abnormalities_annotation"" target=""_blank"">fcaliva</a>",2025-12-03 22:39:25
Perception Improvement for Free: Exploring Imperceptible Black-box Adversarial Attacks on Image Classification,"Yongwei Wang, Mingquan Feng, Rabab Ward, Z. Jane Wang, Lanjun Wang",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.05254"" target=""_blank"">2011.05254</a>",,2025-12-03 22:39:25
Adversarial Attacks on Optimization based Planners,"Sai Vemprala, Ashish Kapoor",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.00095"" target=""_blank"">2011.00095</a>",,2025-12-03 22:39:25
EEG-Based Brain-Computer Interfaces Are Vulnerable to Backdoor Attacks,"Lubin Meng, Jian Huang, Zhigang Zeng, Xue Jiang, Shan Yu, Tzyy-Ping Jung, Chin-Teng Lin, Ricardo Chavarriaga, Dongrui Wu",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.00101"" target=""_blank"">2011.00101</a>",,2025-12-03 22:39:25
Integer Programming-based Error-Correcting Output Code Design for Robust Classification,"Samarth Gupta, Saurabh Amin",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.00144"" target=""_blank"">2011.00144</a>",,2025-12-03 22:39:25
MAD-VAE: Manifold Awareness Defense Variational Autoencoder,"Frederick Morlock, Dingsu Wang",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.01755"" target=""_blank"">2011.01755</a>",,2025-12-03 22:39:25
Vulnerability of the Neural Networks Against Adversarial Examples: A Survey,Rui Zhao,arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.05976"" target=""_blank"">2011.05976</a>",,2025-12-03 22:39:25
LG-GAN: Label Guided Adversarial Network for Flexible Targeted Attack of Point Cloud-based Deep Networks,"Hang Zhou, Dongdong Chen, Jing Liao, Weiming Zhang, Kejiang Chen, Xiaoyi Dong, Kunlin Liu, Gang Hua, Nenghai Yu",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.00566"" target=""_blank"">2011.00566</a>",,2025-12-03 22:39:25
Trustworthy AI,"Richa Singh, Mayank Vatsa, Nalini Ratha",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.02272"" target=""_blank"">2011.02272</a>",,2025-12-03 22:39:25
Robust Algorithms for Online Convex Problems via Primal-Dual,Marco Molinaro,arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.01435"" target=""_blank"">2011.01435</a>",,2025-12-03 22:39:25
Adversarial Examples in Constrained Domains,"Ryan Sheatsley, Nicolas Papernot, Michael Weisman, Gunjan Verma, Patrick McDaniel",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.01183"" target=""_blank"">2011.01183</a>",,2025-12-03 22:39:25
MalFox: Camouflaged Adversarial Malware Example Generation Based on Conv-GANs Against Black-Box Detectors,"Fangtian Zhong, Xiuzhen Cheng, Dongxiao Yu, Bei Gong, Shuaiwen Song, Jiguo Yu",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.01509"" target=""_blank"">2011.01509</a>",,2025-12-03 22:39:25
A Tunable Robust Pruning Framework Through Dynamic Network Rewiring of DNNs,"Souvik Kundu, Mahdi Nazemi, Peter A. Beerel, Massoud Pedram",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.03083"" target=""_blank"">2011.03083</a>",,2025-12-03 22:39:25
Recent Advances in Understanding Adversarial Robustness of Deep Neural Networks,"Tao Bai, Jinqi Luo, Jun Zhao",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.01539"" target=""_blank"">2011.01539</a>",,2025-12-03 22:39:25
Penetrating RF Fingerprinting-based Authentication with a Generative Adversarial Attack,"Samurdhi Karunaratne, Enes Krijestorac, Danijela Cabric",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.01538"" target=""_blank"">2011.01538</a>",,2025-12-03 22:39:25
Detecting Word Sense Disambiguation Biases in Machine Translation for Model-Agnostic Adversarial Attacks,"Denis Emelin, Ivan Titov, Rico Sennrich",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.01846"" target=""_blank"">2011.01846</a>",,2025-12-03 22:39:25
You Do (Not) Belong Here: Detecting DPI Evasion Attacks with Context Learning,"Shitong Zhu, Shasha Li, Zhongjie Wang, Xun Chen, Zhiyun Qian, Srikanth V. Krishnamurthy, Kevin S. Chan, Ananthram Swami",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.01514"" target=""_blank"">2011.01514</a>",,2025-12-03 22:39:25
Dynamically Sampled Nonlocal Gradients for Stronger Adversarial Attacks,"Leo Schwinn, An Nguyen, René Raab, Dario Zanca, Bjoern Eskofier, Daniel Tenbrinck, Martin Burger",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.02707"" target=""_blank"">2011.02707</a>",,2025-12-03 22:39:25
Defense-friendly Images in Adversarial Attacks: Dataset and Metrics forPerturbation Difficulty,"Camilo Pestana, Wei Liu, David Glance, Ajmal Mian",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.02675"" target=""_blank"">2011.02675</a>",,2025-12-03 22:39:25
Data Augmentation via Structured Adversarial Perturbations,"Calvin Luo, Hossein Mobahi, Samy Bengio",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.03010"" target=""_blank"">2011.03010</a>",,2025-12-03 22:39:25
SIENA: Stochastic Multi-Expert Neural Patcher,"Thai Le, Noseong Park, Dongwon Lee",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.08908"" target=""_blank"">2011.08908</a>",,2025-12-03 22:39:25
3D Invisible Cloak,"Mingfu Xue, Can He, Zhiyu Wu, Jian Wang, Zhe Liu, Weiqiang Liu",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.13705"" target=""_blank"">2011.13705</a>",,2025-12-03 22:39:25
Adversarial Profiles: Detecting Out-Distribution & Adversarial Samples in Pre-trained CNNs,"Arezoo Rajabi, Rakesh B. Bobba",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.09123"" target=""_blank"">2011.09123</a>",,2025-12-03 22:39:25
Advancing diagnostic performance and clinical usability of neural networks via adversarial training and dual batch normalization,"Tianyu Han, Sven Nebelung, Federico Pedersoli, Markus Zimmermann, Maximilian Schulze-Hagen, Michael Ho, Christoph Haarburger, Fabian Kiessling, Christiane Kuhl, Volkmar Schulz, Daniel Truhn",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.13011"" target=""_blank"">2011.13011</a>",,2025-12-03 22:39:25
Adversarial Evaluation of Multimodal Models under Realistic Gray Box Assumption,"Ivan Evtimov, Russel Howes, Brian Dolhansky, Hamed Firooz, Cristian Canton Ferrer",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.12902"" target=""_blank"">2011.12902</a>",,2025-12-03 22:39:25
Adversarial Attack on Facial Recognition using Visible Light,"Morgan Frearson, Kien Nguyen",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.12680"" target=""_blank"">2011.12680</a>",,2025-12-03 22:39:25
Invisible Perturbations: Physical Adversarial Examples Exploiting the Rolling Shutter Effect,"Athena Sayles, Ashish Hooda, Mohit Gupta, Rahul Chatterjee, Earlence Fernandes",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.13375"" target=""_blank"">2011.13375</a>",,2025-12-03 22:39:25
Regularization with Latent Space Virtual Adversarial Training,"Genki Osada, Budrul Ahsan, Revoti Prasad Bora, Takashi Nishide",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.13181"" target=""_blank"">2011.13181</a>",,2025-12-03 22:39:25
Robust Attacks on Deep Learning Face Recognition in the Physical World,"Meng Shen, Hao Yu, Liehuang Zhu, Ke Xu, Qi Li, Xiaojiang Du",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.13526"" target=""_blank"">2011.13526</a>",,2025-12-03 22:39:25
Exposing the Robustness and Vulnerability of Hybrid 8T-6T SRAM Memory Architectures to Adversarial Attacks in Deep Neural Networks,"Abhishek Moitra, Priyadarshini Panda",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.13392"" target=""_blank"">2011.13392</a>",,2025-12-03 22:39:25
Rethinking Uncertainty in Deep Learning: Whether and How it Improves Robustness,"Yilun Jin, Lixin Fan, Kam Woh Ng, Ce Ju, Qiang Yang",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.13538"" target=""_blank"">2011.13538</a>",,2025-12-03 22:39:25
Use the Spear as a Shield: A Novel Adversarial Example based Privacy-Preserving Technique against Membership Inference Attacks,"Mingfu Xue, Chengxiang Yuan, Can He, Zhiyu Wu, Yushu Zhang, Zhe Liu, Weiqiang Liu",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.13696"" target=""_blank"">2011.13696</a>",,2025-12-03 22:39:25
SocialGuard: An Adversarial Example Based Privacy-Preserving Technique for Social Images,"Mingfu Xue, Shichang Sun, Zhiyu Wu, Can He, Jian Wang, Weiqiang Liu",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.13560"" target=""_blank"">2011.13560</a>",,2025-12-03 22:39:25
Robust and Natural Physical Adversarial Examples for Object Detectors,"Mingfu Xue, Chengxiang Yuan, Can He, Jian Wang, Weiqiang Liu",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.13692"" target=""_blank"">2011.13692</a>",,2025-12-03 22:39:25
Generalized Adversarial Examples: Attacks and Defenses,"Haojing Shen, Sihong Chen, Ran Wang, Xizhao Wang",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.14045"" target=""_blank"">2011.14045</a>",,2025-12-03 22:39:25
Voting based ensemble improves robustness of defensive models,"Devvrit, Minhao Cheng, Cho-Jui Hsieh, Inderjit Dhillon",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.14031"" target=""_blank"">2011.14031</a>",,2025-12-03 22:39:25
Fast and Complete: Enabling Complete Neural Network Verification with Rapid and Massively Parallel Incomplete Verifiers,"Kaidi Xu, Huan Zhang, Shiqi Wang, Yihan Wang, Suman Jana, Xue Lin, Cho-Jui Hsieh",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.13824"" target=""_blank"">2011.13824</a>",,2025-12-03 22:39:25
FaceGuard: A Self-Supervised Defense Against Adversarial Face Images,"Debayan Deb, Xiaoming Liu, Anil K. Jain",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.14218"" target=""_blank"">2011.14218</a>",,2025-12-03 22:39:25
Deterministic Certification to Adversarial Attacks via Bernstein Polynomial Approximation,"Ching-Chia Kao, Jhe-Bang Ko, Chun-Shien Lu",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.14085"" target=""_blank"">2011.14085</a>",,2025-12-03 22:39:25
SwitchX: Gmin-Gmax Switching for Energy-Efficient and Robust Implementation of Binary Neural Networks on ReRAM Xbars,"Abhiroop Bhattacharjee, Priyadarshini Panda",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.14498"" target=""_blank"">2011.14498</a>",,2025-12-03 22:39:25
A Targeted Universal Attack on Graph Convolutional Network,"Jiazhu Dai, Weifeng Zhu, Xiangfeng Luo",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.14365"" target=""_blank"">2011.14365</a>",,2025-12-03 22:39:25
Architectural Adversarial Robustness: The Case for Deep Pursuit,"George Cazenavette, Calvin Murdock, Simon Lucey",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.14427"" target=""_blank"">2011.14427</a>",,2025-12-03 22:39:25
Just One Moment: Structural Vulnerability of Deep Action Recognition against One Frame Attack,"Jaehui Hwang, Jun-Hyuk Kim, Jun-Ho Choi, Jong-Seok Lee",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.14585"" target=""_blank"">2011.14585</a>",,2025-12-03 22:39:25
Guided Adversarial Attack for Evaluating and Enhancing Adversarial Defenses,"Gaurang Sriramanan, Sravanti Addepalli, Arya Baburaj, R. Venkatesh Babu",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.14969"" target=""_blank"">2011.14969</a>",,2025-12-03 22:39:25
Self-Gradient Networks,"Hossein Aboutalebi, Mohammad Javad Shafiee Alexander Wong",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.09364"" target=""_blank"">2011.09364</a>",,2025-12-03 22:39:25
SurFree: a fast surrogate-free black-box attack,"Thibault Maho, Teddy Furon, Erwan Le Merrer",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.12807"" target=""_blank"">2011.12807</a>",,2025-12-03 22:39:25
Cyberbiosecurity: DNA Injection Attack in Synthetic Biology,"Dor Farbiash, Rami Puzis",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.14224"" target=""_blank"">2011.14224</a>",,2025-12-03 22:39:25
Probing Model Signal-Awareness via Prediction-Preserving Input Minimization,"Sahil Suneja, Yunhui Zheng, Yufan Zhuang, Jim Laredo, Alessandro Morari",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.14934"" target=""_blank"">2011.14934</a>",,2025-12-03 22:39:25
Are Chess Discussions Racist? An Adversarial Hate Speech Data Set,"Rupak Sarkar, Ashiqur R. KhudaBukhsh",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.10280"" target=""_blank"">2011.10280</a>",,2025-12-03 22:39:25
Adversarial Turing Patterns from Cellular Automata,"Nurislam Tursynbek, Ilya Vilkoviskiy, Maria Sindeeva, Ivan Oseledets",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.09393"" target=""_blank"">2011.09393</a>",,2025-12-03 22:39:25
Trust but Verify: Assigning Prediction Credibility by Counterfactual Constrained Learning,"Luiz F. O. Chamon, Santiago Paternain, Alejandro Ribeiro",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.12344"" target=""_blank"">2011.12344</a>",,2025-12-03 22:39:25
Contextual Fusion For Adversarial Robustness,"Aiswarya Akumalla, Seth Haney, Maksim Bazhenov",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.09526"" target=""_blank"">2011.09526</a>",,2025-12-03 22:39:25
Adversarial collision attacks on image hashing functions,"Brian Dolhansky, Cristian Canton Ferrer",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.09473"" target=""_blank"">2011.09473</a>",,2025-12-03 22:39:25
Robustified Domain Adaptation,"Jiajin Zhang, Hanqing Chao, Pingkun Yan",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.09563"" target=""_blank"">2011.09563</a>",,2025-12-03 22:39:25
Multi-Task Adversarial Attack,"Pengxin Guo, Yuancheng Xu, Baijiong Lin, Yu Zhang",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.09824"" target=""_blank"">2011.09824</a>",,2025-12-03 22:39:25
Adversarial Threats to DeepFake Detection: A Practical Perspective,"Paarth Neekhara, Brian Dolhansky, Joanna Bitton, Cristian Canton Ferrer",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.09957"" target=""_blank"">2011.09957</a>",,2025-12-03 22:39:25
Adversarial Examples for $k$-Nearest Neighbor Classifiers Based on Higher-Order Voronoi Diagrams,"Chawin Sitawarin, Evgenios M. Kornaropoulos, Dawn Song, David Wagner",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.09719"" target=""_blank"">2011.09719</a>",,2025-12-03 22:39:25
An Experimental Study of Semantic Continuity for Deep Learning Models,"Shangxi Wu, Jitao Sang, Xian Zhao, Lizhang Chen",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.09789"" target=""_blank"">2011.09789</a>",,2025-12-03 22:39:25
Detecting Universal Trigger's Adversarial Attack with Honeypot,"Thai Le, Noseong Park, Dongwon Lee",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.10492"" target=""_blank"">2011.10492</a>",,2025-12-03 22:39:25
Latent Adversarial Debiasing: Mitigating Collider Bias in Deep Neural Networks,"Luke Darlow, Stanisław Jastrzębski, Amos Storkey",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.11486"" target=""_blank"">2011.11486</a>",,2025-12-03 22:39:25
Robust Data Hiding Using Inverse Gradient Attention,"Honglei Zhang, Hu Wang, Yuanzhouhan Cao, Chunhua Shen, Yidong Li",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.10850"" target=""_blank"">2011.10850</a>",,2025-12-03 22:39:25
Stochastic sparse adversarial attacks,"Manon Césaire, Hatem Hajri, Sylvain Lamprier, Patrick Gallinari",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.12423"" target=""_blank"">2011.12423</a>",,2025-12-03 22:39:25
A Neuro-Inspired Autoencoding Defense Against Adversarial Perturbations,"Can Bakiskan, Metehan Cekic, Ahmet Dundar Sezer, Upamanyu Madhow",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.10867"" target=""_blank"">2011.10867</a>",,2025-12-03 22:39:25
Towards Imperceptible Universal Attacks on Texture Recognition,"Yingpeng Deng, Lina J. Karam",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.11957"" target=""_blank"">2011.11957</a>",,2025-12-03 22:39:25
Omni: Automated Ensemble with Unexpected Models against Adversarial Evasion Attack,"Rui Shu, Tianpei Xia, Laurie Williams, Tim Menzies",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.12720"" target=""_blank"">2011.12720</a>",,2025-12-03 22:39:25
Augmented Lagrangian Adversarial Attacks,"Jérôme Rony, Eric Granger, Marco Pedersoli, Ismail Ben Ayed",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.11857"" target=""_blank"">2011.11857</a>",,2025-12-03 22:39:25
Learnable Boundary Guided Adversarial Training,"Jiequan Cui, Shu Liu, Liwei Wang, Jiaya Jia",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.11164"" target=""_blank"">2011.11164</a>",,2025-12-03 22:39:25
Nudge Attacks on Point-Cloud DNNs,"Yiren Zhao, Ilia Shumailov, Robert Mullins, Ross Anderson",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.11637"" target=""_blank"">2011.11637</a>",,2025-12-03 22:39:25
Spatially Correlated Patterns in Adversarial Images,"Nandish Chattopadhyay, Lionell Yip En Zhi, Bryan Tan Bing Xing, Anupam Chattopadhyay",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.10794"" target=""_blank"">2011.10794</a>",,2025-12-03 22:39:25
On the Adversarial Robustness of 3D Point Cloud Classification,"Jiachen Sun, Karl Koenig, Yulong Cao, Qi Alfred Chen, Z. Morley Mao",arXiv,2020-11,"<a href=""http://arxiv.org/abs/2011.11922"" target=""_blank"">2011.11922</a>",,2025-12-03 22:39:25
A Unified Approach to Interpreting and Boosting Adversarial Transferability,"Xin Wang, Jie Ren, Shuyun Lin, Xiangming Zhu, Yisen Wang, Quanshi Zhang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.04055"" target=""_blank"">2010.04055</a>",,2025-12-03 22:39:25
Hiding the Access Pattern is Not Enough: Exploiting Search Pattern Leakage in Searchable Encryption,"Simon Oya, Florian Kerschbaum",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03465"" target=""_blank"">2010.03465</a>",,2025-12-03 22:39:25
Improved Techniques for Model Inversion Attacks,"Si Chen, Ruoxi Jia, Guo-Jun Qi",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.04092"" target=""_blank"">2010.04092</a>",,2025-12-03 22:39:25
Improve Adversarial Robustness via Weight Penalization on Classification Layer,"Cong Xu, Dan Li, Min Yang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03844"" target=""_blank"">2010.03844</a>",,2025-12-03 22:39:25
Affine-Invariant Robust Training,Oriol Barbany Mayor,arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.04216"" target=""_blank"">2010.04216</a>",,2025-12-03 22:39:25
Targeted Attention Attack on Deep Learning Models in Road Sign Recognition,"Xinghao Yang, Weifeng Liu, Shengli Zhang, Wei Liu, Dacheng Tao",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.04331"" target=""_blank"">2010.04331</a>","<a href=""https://github.com/AdvAttack/RoadSignAttack"" target=""_blank"">AdvAttack</a>",2025-12-03 22:39:25
Gaussian MRF Covariance Modeling for Efficient Black-Box Adversarial Attacks,"Anit Kumar Sahu, Satya Narayan Shukla, J. Zico Kolter",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.04205"" target=""_blank"">2010.04205</a>",,2025-12-03 22:39:25
Batch Normalization Increases Adversarial Vulnerability: Disentangling Usefulness and Robustness of Model Features,"Philipp Benz, Chaoning Zhang, In So Kweon",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03316"" target=""_blank"">2010.03316</a>",,2025-12-03 22:39:25
Learning Clusterable Visual Features for Zero-Shot Recognition,"Jingyi Xu, Zhixin Shu, Dimitris Samaras",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03245"" target=""_blank"">2010.03245</a>",,2025-12-03 22:39:25
Don't Trigger Me! A Triggerless Backdoor Attack Against Deep Neural Networks,"Ahmed Salem, Michael Backes, Yang Zhang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03282"" target=""_blank"">2010.03282</a>",,2025-12-03 22:39:25
Revisiting Batch Normalization for Improving Corruption Robustness,"Philipp Benz, Chaoning Zhang, Adil Karjauv, In So Kweon",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03630"" target=""_blank"">2010.03630</a>",,2025-12-03 22:39:25
Decamouflage: A Framework to Detect Image-Scaling Attacks on Convolutional Neural Networks,"Bedeuro Kim, Alsharif Abuadbba, Yansong Gao, Yifeng Zheng, Muhammad Ejaz Ahmed, Hyoungshick Kim, Surya Nepal",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03735"" target=""_blank"">2010.03735</a>",,2025-12-03 22:39:25
Global Optimization of Objective Functions Represented by ReLU Networks,"Christopher A. Strong, Haoze Wu, Aleksandar Zeljić, Kyle D. Julian, Guy Katz, Clark Barrett, Mykel J. Kochenderfer",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03258"" target=""_blank"">2010.03258</a>",,2025-12-03 22:39:25
How Does Mixup Help With Robustness and Generalization?,"Linjun Zhang, Zhun Deng, Kenji Kawaguchi, Amirata Ghorbani, James Zou",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.04819"" target=""_blank"">2010.04819</a>",,2025-12-03 22:39:25
CD-UAP: Class Discriminative Universal Adversarial Perturbation,"Chaoning Zhang, Philipp Benz, Tooba Imtiaz, In So Kweon",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03300"" target=""_blank"">2010.03300</a>",,2025-12-03 22:39:25
Not All Datasets Are Born Equal: On Heterogeneous Data and Adversarial Examples,"Eden Levy, Yael Mathov, Ziv Katzir, Asaf Shabtai, Yuval Elovici",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03180"" target=""_blank"">2010.03180</a>",,2025-12-03 22:39:25
Transcending Transcend: Revisiting Malware Classification with Conformal Evaluation,"Federico Barbero, Feargus Pendlebury, Fabio Pierazzi, Lorenzo Cavallaro",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03856"" target=""_blank"">2010.03856</a>",,2025-12-03 22:39:25
Learning to Attack with Fewer Pixels: A Probabilistic Post-hoc Framework for Refining Arbitrary Dense Adversarial Attacks,"He Zhao, Thanh Nguyen, Trung Le, Paul Montague, Vel Olivier De, Tamas Abraham, Dinh Phung",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.06131"" target=""_blank"">2010.06131</a>",,2025-12-03 22:39:25
Understanding Spatial Robustness of Deep Neural Networks,"Ziyuan Zhong, Yuchi Tian, Baishakhi Ray",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.04821"" target=""_blank"">2010.04821</a>",,2025-12-03 22:39:25
Regularizing Neural Networks via Adversarial Model Perturbation,"Yaowei Zheng, Richong Zhang, Yongyi Mao",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.04925"" target=""_blank"">2010.04925</a>","<a href=""https://github.com/hiyouga/AMP-Regularizer"" target=""_blank"">hiyouga</a>",2025-12-03 22:39:25
Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples,"Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, Pushmeet Kohli",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03593"" target=""_blank"">2010.03593</a>",,2025-12-03 22:39:25
GreedyFool: Multi-Factor Imperceptibility and Its Application to Designing Black-box Adversarial Example Attack,"Hui Liu, Bo Zhao, Jiabao Guo, Yang An, Peng Liu",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.06855"" target=""_blank"">2010.06855</a>",,2025-12-03 22:39:25
Toward Few-step Adversarial Training from a Frequency Perspective,"Hans Shih-Han Wang, Cory Cornelius, Brandon Edwards, Jason Martin",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.06545"" target=""_blank"">2010.06545</a>",,2025-12-03 22:39:25
Higher-Order Certification for Randomized Smoothing,"Jeet Mohapatra, Ching-Yun Ko, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, Luca Daniel",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.06651"" target=""_blank"">2010.06651</a>",,2025-12-03 22:39:25
Linking average- and worst-case perturbation robustness via class selectivity and dimensionality,"Matthew L. Leavitt, Ari Morcos",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.07693"" target=""_blank"">2010.07693</a>",,2025-12-03 22:39:25
Universal Model for 3D Medical Image Analysis,"Xiaoman Zhang, Ya Zhang, Xiaoyun Zhang, Yanfeng Wang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.06107"" target=""_blank"">2010.06107</a>","<a href=""https://github.com/xm-cmic/Universal-Model"" target=""_blank"">xm-cmic</a>",2025-12-03 22:39:25
To be Robust or to be Fair: Towards Fairness in Adversarial Training,"Han Xu, Xiaorui Liu, Yaxin Li, Jiliang Tang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.06121"" target=""_blank"">2010.06121</a>",,2025-12-03 22:39:25
Shape-Texture Debiased Neural Network Training,"Yingwei Li, Qihang Yu, Mingxing Tan, Jieru Mei, Peng Tang, Wei Shen, Alan Yuille, Cihang Xie",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.05981"" target=""_blank"">2010.05981</a>","<a href=""https://github.com/LiYingwei/ShapeTextureDebiasedTraining"" target=""_blank"">LiYingwei</a>",2025-12-03 22:39:25
On the Power of Abstention and Data-Driven Decision Making for Adversarial Robustness,"Maria-Florina Balcan, Avrim Blum, Dravyansh Sharma, Hongyang Zhang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.06154"" target=""_blank"">2010.06154</a>",,2025-12-03 22:39:25
From Hero to Z\'eroe: A Benchmark of Low-Level Adversarial Attacks,"Steffen Eger, Yannik Benz",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.05648"" target=""_blank"">2010.05648</a>",,2025-12-03 22:39:25
EFSG: Evolutionary Fooling Sentences Generator,"Giovanni Marco Di, Marco Brambilla",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.05736"" target=""_blank"">2010.05736</a>",,2025-12-03 22:39:25
Contrast and Classify: Training Robust VQA Models,"Yash Kant, Abhinav Moudgil, Dhruv Batra, Devi Parikh, Harsh Agrawal",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.06087"" target=""_blank"">2010.06087</a>",,2025-12-03 22:39:25
Gradient-based Analysis of NLP Models is Manipulable,"Junlin Wang, Jens Tuyls, Eric Wallace, Sameer Singh",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.05419"" target=""_blank"">2010.05419</a>","<a href=""http://ucinlp.github.io/facade"" target=""_blank"">ucinlp.github.io</a>",2025-12-03 22:39:25
IF-Defense: 3D Adversarial Point Cloud Defense via Implicit Function based Restoration,"Ziyi Wu, Yueqi Duan, He Wang, Qingnan Fan, Leonidas J. Guibas",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.05272"" target=""_blank"">2010.05272</a>",,2025-12-03 22:39:25
Is It Time to Redefine the Classification Task for Deep Neural Networks?,"Keji Han, Yun Li",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.05125"" target=""_blank"">2010.05125</a>",,2025-12-03 22:39:25
Double Targeted Universal Adversarial Perturbations,"Philipp Benz, Chaoning Zhang, Tooba Imtiaz, In So Kweon",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03288"" target=""_blank"">2010.03288</a>",,2025-12-03 22:39:25
Efficient Robust Training via Backward Smoothing,"Jinghui Chen, Yu Cheng, Zhe Gan, Quanquan Gu, Jingjing Liu",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01278"" target=""_blank"">2010.01278</a>",,2025-12-03 22:39:25
Adversarial Attacks to Machine Learning-Based Smart Healthcare Systems,"AKM Iqtidar Newaz, Nur Imtiazul Haque, Amit Kumar Sikder, Mohammad Ashiqur Rahman, A. Selcuk Uluagac",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03671"" target=""_blank"">2010.03671</a>",,2025-12-03 22:39:25
Unknown Presentation Attack Detection against Rational Attackers,"Ali Khodabakhsh, Zahid Akhtar",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01592"" target=""_blank"">2010.01592</a>",,2025-12-03 22:39:25
Multi-Step Adversarial Perturbations on Recommender Systems Embeddings,"Vito Walter Anelli, Alejandro Bellogín, Yashar Deldjoo, Noia Tommaso Di, Felice Antonio Merra",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01329"" target=""_blank"">2010.01329</a>",,2025-12-03 22:39:25
A Geometry-Inspired Attack for Generating Natural Language Adversarial Examples,"Zhao Meng, Roger Wattenhofer",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01345"" target=""_blank"">2010.01345</a>",,2025-12-03 22:39:25
Do Wider Neural Networks Really Help Adversarial Robustness?,"Boxi Wu, Jinghui Chen, Deng Cai, Xiaofei He, Quanquan Gu",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01279"" target=""_blank"">2010.01279</a>",,2025-12-03 22:39:25
Note: An alternative proof of the vulnerability of $k$-NN classifiers in high intrinsic dimensionality regions,Teddy Furon,arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.00990"" target=""_blank"">2010.00990</a>",,2025-12-03 22:39:25
An Empirical Study of DNNs Robustification Inefficacy in Protecting Visual Recommenders,"Vito Walter Anelli, Noia Tommaso Di, Daniele Malitesta, Felice Antonio Merra",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.00984"" target=""_blank"">2010.00984</a>",,2025-12-03 22:39:25
Block-wise Image Transformation with Secret Key for Adversarially Robust Defense,"MaungMaung AprilPyone, Hitoshi Kiya",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.00801"" target=""_blank"">2010.00801</a>",,2025-12-03 22:39:25
Query complexity of adversarial attacks,"Grzegorz Głuch, Rüdiger Urbanke",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01039"" target=""_blank"">2010.01039</a>",,2025-12-03 22:39:25
CorrAttack: Black-box Adversarial Attack with Structured Search,"Zhichao Huang, Yaowei Huang, Tong Zhang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01250"" target=""_blank"">2010.01250</a>",,2025-12-03 22:39:25
A Deep Genetic Programming based Methodology for Art Media Classification Robust to Adversarial Perturbations,"Gustavo Olague, Gerardo Ibarra-Vazquez, Mariana Chan-Ley, Cesar Puente, Carlos Soubervielle-Montalvo, Axel Martinez",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01238"" target=""_blank"">2010.01238</a>",,2025-12-03 22:39:25
Data-Driven Certification of Neural Networks with Random Input Noise,"Brendon G. Anderson, Somayeh Sojoudi",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01171"" target=""_blank"">2010.01171</a>",,2025-12-03 22:39:25
Assessing Robustness of Text Classification through Maximal Safe Radius Computation,"Malfa Emanuele La, Min Wu, Luca Laurenti, Benjie Wang, Anthony Hartshorn, Marta Kwiatkowska",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.02004"" target=""_blank"">2010.02004</a>",,2025-12-03 22:39:25
Bag of Tricks for Adversarial Training,"Tianyu Pang, Xiao Yang, Yinpeng Dong, Hang Su, Jun Zhu",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.00467"" target=""_blank"">2010.00467</a>",,2025-12-03 22:39:25
Erratum Concerning the Obfuscated Gradients Attack on Stochastic Activation Pruning,"Guneet S. Dhillon, Nicholas Carlini",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.00071"" target=""_blank"">2010.00071</a>",,2025-12-03 22:39:25
Torchattacks: A PyTorch Repository for Adversarial Attacks,Hoki Kim,arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01950"" target=""_blank"">2010.01950</a>","<a href=""https://github.com/Harry24k/adversarial-attacks-pytorch"" target=""_blank"">Harry24k</a>",2025-12-03 22:39:25
An Adversarial Attack against Stacked Capsule Autoencoder,"Jiazhu Dai, Siwei Xiong",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.07230"" target=""_blank"">2010.07230</a>",,2025-12-03 22:39:25
Adversarial and Natural Perturbations for General Robustness,"Sadaf Gulshad, Jan Hendrik Metzen, Arnold Smeulders",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01401"" target=""_blank"">2010.01401</a>",,2025-12-03 22:39:25
Geometry-aware Instance-reweighted Adversarial Training,"Jingfeng Zhang, Jianing Zhu, Gang Niu, Bo Han, Masashi Sugiyama, Mohan Kankanhalli",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01736"" target=""_blank"">2010.01736</a>",,2025-12-03 22:39:25
Adversarial attacks on audio source separation,"Naoya Takahashi, Shota Inoue, Yuki Mitsufuji",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03164"" target=""_blank"">2010.03164</a>",,2025-12-03 22:39:25
Adversarial Attack and Defense of Structured Prediction Models,"Wenjuan Han, Liwen Zhang, Yong Jiang, Kewei Tu",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01610"" target=""_blank"">2010.01610</a>",,2025-12-03 22:39:25
Constraining Logits by Bounded Function for Adversarial Robustness,"Sekitoshi Kanai, Masanori Yamada, Shin'ya Yamaguchi, Hiroshi Takahashi, Yasutoshi Ida",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.02558"" target=""_blank"">2010.02558</a>",,2025-12-03 22:39:25
Adversarial Patch Attacks on Monocular Depth Estimation Networks,"Koichiro Yamanaka, Ryutaroh Matsumoto, Keita Takahashi, Toshiaki Fujii",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03072"" target=""_blank"">2010.03072</a>",,2025-12-03 22:39:25
BAAAN: Backdoor Attacks Against Autoencoder and GAN-Based Machine Learning Models,"Ahmed Salem, Yannick Sautter, Michael Backes, Mathias Humbert, Yang Zhang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.03007"" target=""_blank"">2010.03007</a>",,2025-12-03 22:39:25
Detecting Misclassification Errors in Neural Networks with a Gaussian Process Model,"Xin Qiu, Risto Miikkulainen",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.02065"" target=""_blank"">2010.02065</a>",,2025-12-03 22:39:25
Adversarial Boot Camp: label free certified robustness in one epoch,"Ryan Campbell, Chris Finlay, Adam M Oberman",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.02508"" target=""_blank"">2010.02508</a>",,2025-12-03 22:39:25
Understanding Classifier Mistakes with Generative Models,"Laëtitia Shao, Yang Song, Stefano Ermon",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.02364"" target=""_blank"">2010.02364</a>",,2025-12-03 22:39:25
CAT-Gen: Improving Robustness in NLP Models via Controlled Adversarial Text Generation,"Tianlu Wang, Xuezhi Wang, Yao Qin, Ben Packer, Kang Li, Jilin Chen, Alex Beutel, Ed Chi",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.02338"" target=""_blank"">2010.02338</a>",,2025-12-03 22:39:25
Second-Order NLP Adversarial Examples,John X. Morris,arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01770"" target=""_blank"">2010.01770</a>","<a href=""https://github.com/jxmorris12/second-order-adversarial-examples"" target=""_blank"">jxmorris12</a>",2025-12-03 22:39:25
"A Panda? No, It's a Sloth: Slowdown Attacks on Adaptive Multi-Exit Neural Network Inference","Sanghyun Hong, Yiğitcan Kaya, Ionuţ-Vlad Modoranu, Tudor Dumitraş",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.02432"" target=""_blank"">2010.02432</a>","<a href=""https://github.com/sanghyun-hong/deepsloth"" target=""_blank"">sanghyun-hong</a>",2025-12-03 22:39:25
InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective,"Boxin Wang, Shuohang Wang, Yu Cheng, Zhe Gan, Ruoxi Jia, Bo Li, Jingjing Liu",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.02329"" target=""_blank"">2010.02329</a>","<a href=""https://github.com/AI-secure/InfoBERT"" target=""_blank"">AI-secure</a>",2025-12-03 22:39:25
Understanding Catastrophic Overfitting in Single-step Adversarial Training,"Hoki Kim, Woojin Lee, Jaewook Lee",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01799"" target=""_blank"">2010.01799</a>",,2025-12-03 22:39:25
Downscaling Attack and Defense: Turning What You See Back Into What You Get,Andrew J. Lohn,arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.02456"" target=""_blank"">2010.02456</a>",,2025-12-03 22:39:25
Metadata-Based Detection of Child Sexual Abuse Material,"Mayana Pereira, Rahul Dodhia, Hyrum Anderson, Richard Brown",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.02387"" target=""_blank"">2010.02387</a>",,2025-12-03 22:39:25
TextAttack: Lessons learned in designing Python frameworks for NLP,"John X. Morris, Jin Yong Yoo, Yanjun Qi",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01724"" target=""_blank"">2010.01724</a>",,2025-12-03 22:39:25
A Study for Universal Adversarial Attacks on Texture Recognition,"Yingpeng Deng, Lina J. Karam",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.01506"" target=""_blank"">2010.01506</a>",,2025-12-03 22:39:25
Explain2Attack: Text Adversarial Attacks via Cross-Domain Interpretability,"Mahmoud Hossam, Trung Le, He Zhao, Dinh Phung",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.06812"" target=""_blank"">2010.06812</a>",,2025-12-03 22:39:25
Visualizing Color-wise Saliency of Black-Box Image Classification Models,"Yuhki SenseTime Japan Hatakeyama, Hiroki SenseTime Japan Sakuma, Yoshinori SenseTime Japan Konishi, Kohei Kyoto University Suenaga",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.02468"" target=""_blank"">2010.02468</a>",,2025-12-03 22:39:25
Towards Resistant Audio Adversarial Examples,"Tom Dörr, Karla Markert, Nicolas M. Müller, Konstantin Böttinger",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.07190"" target=""_blank"">2010.07190</a>",,2025-12-03 22:39:25
Are Adversarial Examples Created Equal? A Learnable Weighted Minimax Risk for Robustness under Non-uniform Attacks,"Huimin Zeng, Chen Zhu, Tom Goldstein, Furong Huang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.12989"" target=""_blank"">2010.12989</a>",,2025-12-03 22:39:25
Versatile Verification of Tree Ensembles,"Laurens Devos, Wannes Meert, Jesse Davis",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.13880"" target=""_blank"">2010.13880</a>",,2025-12-03 22:39:25
Robustness May Be at Odds with Fairness: An Empirical Study on Class-wise Accuracy,"Philipp Benz, Chaoning Zhang, Adil Karjauv, In So Kweon",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.13365"" target=""_blank"">2010.13365</a>",,2025-12-03 22:39:25
Exploring the Security Boundary of Data Reconstruction via Neuron Exclusivity Analysis,"Xudong Pan, Mi Zhang, Yifan Yan, Jiaming Zhu, Min Yang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.13356"" target=""_blank"">2010.13356</a>",,2025-12-03 22:39:25
Attack Agnostic Adversarial Defense via Visual Imperceptible Bound,"Saheb Chhabra, Akshay Agarwal, Richa Singh, Mayank Vatsa",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.13247"" target=""_blank"">2010.13247</a>",,2025-12-03 22:39:25
Dynamic Adversarial Patch for Evading Object Detection Models,"Shahar Hoory, Tzvika Shapira, Asaf Shabtai, Yuval Elovici",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.13070"" target=""_blank"">2010.13070</a>",,2025-12-03 22:39:25
Asymptotic Behavior of Adversarial Training in Binary Classification,"Hossein Taheri, Ramtin Pedarsani, Christos Thrampoulidis",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.13275"" target=""_blank"">2010.13275</a>",,2025-12-03 22:39:25
ATRO: Adversarial Training with a Rejection Option,"Masahiro Kato, Zhenghang Cui, Yoshihiro Fukuhara",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.12905"" target=""_blank"">2010.12905</a>",,2025-12-03 22:39:25
Stop Bugging Me! Evading Modern-Day Wiretapping Using Adversarial Perturbations,"Yael Mathov, Tal Ben Senior, Asaf Shabtai, Yuval Elovici",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.12809"" target=""_blank"">2010.12809</a>",,2025-12-03 22:39:25
Enabling certification of verification-agnostic networks via memory-efficient semidefinite programming,"Sumanth Dathathri, Krishnamurthy Dvijotham, Alexey Kurakin, Aditi Raghunathan, Jonathan Uesato, Rudy Bunel, Shreya Shankar, Jacob Steinhardt, Ian Goodfellow, Percy Liang, Pushmeet Kohli",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.11645"" target=""_blank"">2010.11645</a>",,2025-12-03 22:39:25
Improving Robustness by Augmenting Training Sentences with Predicate-Argument Structures,"Nafise Sadat Moosavi, Boer Marcel de, Prasetya Ajie Utama, Iryna Gurevych",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.12510"" target=""_blank"">2010.12510</a>","<a href=""https://github.com/UKPLab/data-augmentation-for-robustness"" target=""_blank"">UKPLab</a>",2025-12-03 22:39:25
Towards Robust Neural Networks via Orthogonal Diversity,"Kun Fang, Qinghua Tao, Yingwen Wu, Tao Li, Jia Cai, Feipeng Cai, Xiaolin Huang, Jie Yang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.12190"" target=""_blank"">2010.12190</a>",,2025-12-03 22:39:25
Contrastive Learning with Adversarial Examples,"Chih-Hui Ho, Nuno Vasconcelos",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.12050"" target=""_blank"">2010.12050</a>",,2025-12-03 22:39:25
Adversarial Attacks on Binary Image Recognition Systems,"Eric Balkanski, Harrison Chase, Kojin Oshiba, Alexander Rilee, Yaron Singer, Richard Wang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.11782"" target=""_blank"">2010.11782</a>",,2025-12-03 22:39:25
Rewriting Meaningful Sentences via Conditional BERT Sampling and an application on fooling text classifiers,"Lei Xu, Ivan Ramirez, Kalyan Veeramachaneni",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.11869"" target=""_blank"">2010.11869</a>",,2025-12-03 22:39:25
An Efficient Adversarial Attack for Tree Ensembles,"Chong Zhang, Huan Zhang, Cho-Jui Hsieh",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.11598"" target=""_blank"">2010.11598</a>","<a href=""https://github.com/chong-z/tree-ensemble-attack"" target=""_blank"">chong-z</a>",2025-12-03 22:39:25
Leveraging Extracted Model Adversaries for Improved Black Box Attacks,"Naveen Jafer Nizar, Ari Kobren",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.16336"" target=""_blank"">2010.16336</a>",,2025-12-03 22:39:25
Robust Pre-Training by Adversarial Contrastive Learning,"Ziyu Jiang, Tianlong Chen, Ting Chen, Zhangyang Wang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.13337"" target=""_blank"">2010.13337</a>","<a href=""https://github.com/VITA-Group/Adversarial-Contrastive-Learning"" target=""_blank"">VITA-Group</a>",2025-12-03 22:39:25
GreedyFool: Distortion-Aware Sparse Adversarial Attack,"Xiaoyi Dong, Dongdong Chen, Jianmin Bao, Chuan Qin, Lu Yuan, Weiming Zhang, Nenghai Yu, Dong Chen",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.13773"" target=""_blank"">2010.13773</a>","<a href=""https://github.com/LightDXY/GreedyFool"" target=""_blank"">LightDXY</a>",2025-12-03 22:39:25
Robust and Verifiable Information Embedding Attacks to Deep Neural Networks via Error-Correcting Codes,"Jinyuan Jia, Binghui Wang, Neil Zhenqiang Gong",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.13751"" target=""_blank"">2010.13751</a>",,2025-12-03 22:39:25
Anti-perturbation of Online Social Networks by Graph Label Transition,"Jun Zhuang, Mohammad Al Hasan",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.14121"" target=""_blank"">2010.14121</a>",,2025-12-03 22:39:25
Capture the Bot: Using Adversarial Examples to Improve CAPTCHA Robustness to Bot Attacks,"Dorjan Hitaj, Briland Hitaj, Sushil Jajodia, Luigi V. Mancini",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.16204"" target=""_blank"">2010.16204</a>",,2025-12-03 22:39:25
Pair the Dots: Jointly Examining Training History and Test Stimuli for Model Interpretability,"Yuxian Meng, Chun Fan, Zijun Sun, Eduard Hovy, Fei Wu, Jiwei Li",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.06943"" target=""_blank"">2010.06943</a>",,2025-12-03 22:39:25
Volumetric Medical Image Segmentation: A 3D Deep Coarse-to-fine Framework and Its Adversarial Examples,"Yingwei Li, Zhuotun Zhu, Yuyin Zhou, Yingda Xia, Wei Shen, Elliot K. Fishman, Alan L. Yuille",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.16074"" target=""_blank"">2010.16074</a>",,2025-12-03 22:39:25
Perception Matters: Exploring Imperceptible and Transferable Anti-forensics for GAN-generated Fake Face Imagery Detection,"Yongwei Wang, Xin Ding, Li Ding, Rabab Ward, Z. Jane Wang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.15886"" target=""_blank"">2010.15886</a>",,2025-12-03 22:39:25
Can the state of relevant neurons in a deep neural networks serve as indicators for detecting adversarial attacks?,"Roger Granda, Tinne Tuytelaars, Jose Oramas",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.15974"" target=""_blank"">2010.15974</a>",,2025-12-03 22:39:25
Reliable Graph Neural Networks via Robust Aggregation,"Simon Geisler, Daniel Zügner, Stephan Günnemann",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.15651"" target=""_blank"">2010.15651</a>",,2025-12-03 22:39:25
Passport-aware Normalization for Deep Model Protection,"Jie Zhang, Dongdong Chen, Jing Liao, Weiming Zhang, Gang Hua, Nenghai Yu",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.15824"" target=""_blank"">2010.15824</a>","<a href=""https://github.com/ZJZAC/Passport-aware-Normalization"" target=""_blank"">ZJZAC</a>",2025-12-03 22:39:25
Robustifying Binary Classification to Adversarial Perturbation,"Fariborz Salehi, Babak Hassibi",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.15391"" target=""_blank"">2010.15391</a>",,2025-12-03 22:39:25
Beyond cross-entropy: learning highly separable feature distributions for robust and accurate classification,"Arslan Ali, Andrea Migliorati, Tiziano Bianchi, Enrico Magli",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.15487"" target=""_blank"">2010.15487</a>",,2025-12-03 22:39:25
WaveTransform: Crafting Adversarial Examples via Input Decomposition,"Divyam Anshumaan, Akshay Agarwal, Mayank Vatsa, Richa Singh",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.15773"" target=""_blank"">2010.15773</a>",,2025-12-03 22:39:25
Most ReLU Networks Suffer from $\ell^2$ Adversarial Perturbations,"Amit Daniely, Hadas Schacham",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.14927"" target=""_blank"">2010.14927</a>",,2025-12-03 22:39:25
Object Hider: Adversarial Patch Attack Against Object Detectors,"Yusheng Zhao, Huanqian Yan, Xingxing Wei",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.14974"" target=""_blank"">2010.14974</a>","<a href=""https://github.com/FenHua/DetDak"" target=""_blank"">FenHua</a>",2025-12-03 22:39:25
Evaluating Robustness of Predictive Uncertainty Estimation: Are Dirichlet-based Models Reliable?,"Anna-Kathrin Kopetzki, Bertrand Charpentier, Daniel Zügner, Sandhya Giri, Stephan Günnemann",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.14986"" target=""_blank"">2010.14986</a>",,2025-12-03 22:39:25
Transferable Universal Adversarial Perturbations Using Generative Models,"Atiye Sadat Hashemi, Andreas Bär, Saeed Mozaffari, Tim Fingscheidt",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.14919"" target=""_blank"">2010.14919</a>",,2025-12-03 22:39:25
Fast Local Attack: Generating Local Adversarial Examples for Object Detectors,"Quanyu Liao, Xin Wang, Bin Kong, Siwei Lyu, Youbing Yin, Qi Song, Xi Wu",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.14291"" target=""_blank"">2010.14291</a>",,2025-12-03 22:39:25
Adversarial Robustness of Supervised Sparse Coding,"Jeremias Sulam, Ramchandran Muthukumar, Raman Arora",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.12088"" target=""_blank"">2010.12088</a>",,2025-12-03 22:39:25
Machine Learning (In) Security: A Stream of Problems,"Fabrício Ceschin, Marcus Botacin, Albert Bifet, Bernhard Pfahringer, Luiz S. Oliveira, Heitor Murilo Gomes, André Grégio",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.16045"" target=""_blank"">2010.16045</a>",,2025-12-03 22:39:25
Defense-guided Transferable Adversarial Attacks,"Zifei Zhang, Kai Qiao, Jian Chen, Ningning Liang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.11535"" target=""_blank"">2010.11535</a>",,2025-12-03 22:39:25
FLAG: Adversarial Data Augmentation for Graph Neural Networks,"Kezhi Kong, Guohao Li, Mucong Ding, Zuxuan Wu, Chen Zhu, Bernard Ghanem, Gavin Taylor, Tom Goldstein",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.09891"" target=""_blank"">2010.09891</a>",,2025-12-03 22:39:25
"Poisoned classifiers are not only backdoored, they are fundamentally broken","Mingjie Sun, Siddhant Agarwal, J. Zico Kolter",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.09080"" target=""_blank"">2010.09080</a>",,2025-12-03 22:39:25
A Generative Model based Adversarial Security of Deep Learning and Linear Classifier Models,"erhat Ozgur Catak, Samed Sivaslioglu, Kevser Sahinbas",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.08546"" target=""_blank"">2010.08546</a>",,2025-12-03 22:39:25
Finding Physical Adversarial Examples for Autonomous Driving with Fast and Differentiable Image Compositing,"Jinghan Yang, Adith Boloor, Ayan Chakrabarti, Xuan Zhang, Yevgeniy Vorobeychik",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.08844"" target=""_blank"">2010.08844</a>",,2025-12-03 22:39:25
Weight-Covariance Alignment for Adversarially Robust Neural Networks,"Panagiotis Eustratiadis, Henry Gouk, Da Li, Timothy Hospedales",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.08852"" target=""_blank"">2010.08852</a>",,2025-12-03 22:39:25
DPAttack: Diffused Patch Attacks against Universal Object Detection,"Shudeng Wu, Tao Dai, Shu-Tao Xia",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.11679"" target=""_blank"">2010.11679</a>","<a href=""https://github.com/Wu-Shudeng/DPAttack"" target=""_blank"">Wu-Shudeng</a>",2025-12-03 22:39:25
Mischief: A Simple Black-Box Attack Against Transformer Architectures,Wynter Adrian de,arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.08542"" target=""_blank"">2010.08542</a>",,2025-12-03 22:39:25
Learning Robust Algorithms for Online Allocation Problems Using Adversarial Training,"Goran Zuzic, Di Wang, Aranyak Mehta, D. Sivakumar",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.08418"" target=""_blank"">2010.08418</a>",,2025-12-03 22:39:25
Adversarial Images through Stega Glasses,"Benoît CRIStAL Bonnet, Teddy CRIStAL Furon, Patrick CRIStAL Bas",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.07542"" target=""_blank"">2010.07542</a>",,2025-12-03 22:39:25
A Hamiltonian Monte Carlo Method for Probabilistic Adversarial Attack and Learning,"Hongjun Wang, Guanbin Li, Xiaobai Liu, Liang Lin",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.07849"" target=""_blank"">2010.07849</a>",,2025-12-03 22:39:25
Progressive Defense Against Adversarial Attacks for Deep Learning as a Service in Internet of Things,"Ling Wang, Cheng Zhang, Zejian Luo, Chenguang Liu, Jie Liu, Xi Zheng, Athanasios Vasilakos",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.11143"" target=""_blank"">2010.11143</a>",,2025-12-03 22:39:25
Certifying Neural Network Robustness to Random Input Noise from Samples,"Brendon G. Anderson, Somayeh Sojoudi",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.07532"" target=""_blank"">2010.07532</a>",,2025-12-03 22:39:25
Overfitting or Underfitting? Understand Robustness Drop in Adversarial Training,"Zichao Li, Liyuan Liu, Chengyu Dong, Jingbo Shang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.08034"" target=""_blank"">2010.08034</a>",,2025-12-03 22:39:25
Maximum-Entropy Adversarial Data Augmentation for Improved Generalization and Robustness,"Long Zhao, Ting Liu, Xi Peng, Dimitris Metaxas",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.08001"" target=""_blank"">2010.08001</a>",,2025-12-03 22:39:25
Exploiting Vulnerabilities of Deep Learning-based Energy Theft Detection in AMI through Adversarial Attacks,"Jiangnan Li, Yingyuan Yang, Jinyuan Stella Sun",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.09212"" target=""_blank"">2010.09212</a>",,2025-12-03 22:39:25
Once-for-All Adversarial Training: In-Situ Tradeoff between Robustness and Accuracy for Free,"Haotao Wang, Tianlong Chen, Shupeng Gui, Ting-Kuei Hu, Ji Liu, Zhangyang Wang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.11828"" target=""_blank"">2010.11828</a>","<a href=""https://github.com/VITA-Group/Once-for-All-Adversarial-Training"" target=""_blank"">VITA-Group</a>",2025-12-03 22:39:25
FADER: Fast Adversarial Example Rejection,"Francesco Crecchi, Marco Melis, Angelo Sotgiu, Davide Bacciu, Battista Biggio",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.09119"" target=""_blank"">2010.09119</a>",,2025-12-03 22:39:25
Generalizing Universal Adversarial Attacks Beyond Additive Perturbations,"Yanghao Zhang, Wenjie Ruan, Fu Wang, Xiaowei Huang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.07788"" target=""_blank"">2010.07788</a>","<a href=""https://github.com/TrustAI/GUAP"" target=""_blank"">TrustAI</a>",2025-12-03 22:39:25
When Bots Take Over the Stock Market: Evasion Attacks Against Algorithmic Traders,"Elior Nehemya, Yael Mathov, Asaf Shabtai, Yuval Elovici",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.09246"" target=""_blank"">2010.09246</a>",,2025-12-03 22:39:25
Towards Understanding the Dynamics of the First-Order Adversaries,"Zhun Deng, Hangfeng He, Jiaoyang Huang, Weijie J. Su",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.10650"" target=""_blank"">2010.10650</a>",,2025-12-03 22:39:25
Adversarial Attacks on Deep Algorithmic Trading Policies,"Yaser Faghan, Nancirose Piazza, Vahid Behzadan, Ali Fathi",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.11388"" target=""_blank"">2010.11388</a>",,2025-12-03 22:39:25
Verifying the Causes of Adversarial Examples,"Honglin Li, Yifei Fan, Frieder Ganz, Anthony Yezzi, Payam Barnaghi",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.09633"" target=""_blank"">2010.09633</a>",,2025-12-03 22:39:25
Maximum Mean Discrepancy is Aware of Adversarial Attacks,"Ruize Gao, Feng Liu, Jingfeng Zhang, Bo Han, Tongliang Liu, Gang Niu, Masashi Sugiyama",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.11415"" target=""_blank"">2010.11415</a>",,2025-12-03 22:39:25
Precise Statistical Analysis of Classification Accuracies for Adversarial Training,"Adel Javanmard, Mahdi Soltanolkotabi",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.11213"" target=""_blank"">2010.11213</a>",,2025-12-03 22:39:25
Class-Conditional Defense GAN Against End-to-End Speech Attacks,"Mohammad Esmaeilpour, Patrick Cardinal, Alessandro Lameiras Koerich",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.11352"" target=""_blank"">2010.11352</a>",,2025-12-03 22:39:25
A Distributional Robustness Certificate by Randomized Smoothing,"Jungang Yang, Liyao Xiang, Ruidong Chen, Yukun Wang, Wei Wang, Xinbing Wang",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.10987"" target=""_blank"">2010.10987</a>",,2025-12-03 22:39:25
Preventing Personal Data Theft in Images with Adversarial ML,"Thomas Cilloni, Wei Wang, Charles Walter, Charles Fleming",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.10242"" target=""_blank"">2010.10242</a>",,2025-12-03 22:39:25
Learning Black-Box Attackers with Transferable Priors and Query Feedback,"Jiancheng Yang, Yangzhou Jiang, Xiaoyang Huang, Bingbing Ni, Chenglong Zhao",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.11742"" target=""_blank"">2010.11742</a>","<a href=""https://github.com/TrustworthyDL/LeBA"" target=""_blank"">TrustworthyDL</a>",2025-12-03 22:39:25
Robust Neural Networks inspired by Strong Stability Preserving Runge-Kutta methods,"Byungjoo Kim, Bryce Chudomelka, Jinyoung Park, Jaewoo Kang, Youngjoon Hong, Hyunwoo J. Kim",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.10047"" target=""_blank"">2010.10047</a>",,2025-12-03 22:39:25
Tight Second-Order Certificates for Randomized Smoothing,"Alexander Levine, Aounon Kumar, Thomas Goldstein, Soheil Feizi",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.10549"" target=""_blank"">2010.10549</a>","<a href=""https://github.com/alevine0/smoothing_second_order"" target=""_blank"">alevine0</a>",2025-12-03 22:39:25
Optimism in the Face of Adversity: Understanding and Improving Deep Learning through Adversarial Robustness,"Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.09624"" target=""_blank"">2010.09624</a>",,2025-12-03 22:39:25
A Survey of Machine Learning Techniques in Adversarial Image Forensics,"Ehsan Nowroozi, Ali Dehghantanha, Reza M. Parizi, Kim-Kwang Raymond Choo",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.09680"" target=""_blank"">2010.09680</a>",,2025-12-03 22:39:25
Boosting Gradient for White-Box Adversarial Attacks,"Hongying Liu, Zhenyu Zhou, Fanhua Shang, Xiaoyu Qi, Yuanyuan Liu, Licheng Jiao",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.10712"" target=""_blank"">2010.10712</a>",,2025-12-03 22:39:25
Against All Odds: Winning the Defense Challenge in an Evasion Competition with Diversification,"Erwin Quiring, Lukas Pirch, Michael Reimsbach, Daniel Arp, Konrad Rieck",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.09569"" target=""_blank"">2010.09569</a>",,2025-12-03 22:39:25
RobustBench: a standardized adversarial robustness benchmark,"Francesco Croce, Maksym Andriushchenko, Vikash Sehwag, Nicolas Flammarion, Mung Chiang, Prateek Mittal, Matthias Hein",arXiv,2020-10,"<a href=""http://arxiv.org/abs/2010.09670"" target=""_blank"">2010.09670</a>","<a href=""http://robustbench.github.io/"" target=""_blank"">robustbench.github.io</a>",2025-12-03 22:39:25
Defending Against Multiple and Unforeseen Adversarial Videos,"Shao-Yuan Lo, Vishal M. Patel",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.05244"" target=""_blank"">2009.05244</a>",,2025-12-03 22:39:25
Hold Tight and Never Let Go: Security of Deep Learning based Automated Lane Centering under Physical-World Attack,"Takami Sato, Junjie Shen, Ningfei Wang, Yunhan Jack Jia, Xue Lin, Qi Alfred Chen",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.06701"" target=""_blank"">2009.06701</a>",,2025-12-03 22:39:25
Manifold attack,"Khanh-Hung Tran, Fred-Maurice Ngole-Mboula, Jean-Luc Starck",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.05965"" target=""_blank"">2009.05965</a>",,2025-12-03 22:39:25
Towards the Quantification of Safety Risks in Deep Neural Networks,"Peipei Xu, Wenjie Ruan, Xiaowei Huang",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.06114"" target=""_blank"">2009.06114</a>",,2025-12-03 22:39:25
Certified Robustness of Graph Classification against Topology Attack with Randomized Smoothing,"Zhidong Gao, Rui Hu, Yanmin Gong",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.05872"" target=""_blank"">2009.05872</a>",,2025-12-03 22:39:25
Robust Neural Machine Translation: Modeling Orthographic and Interpunctual Variation,"Toms Bergmanis, Artūrs Stafanovičs, Mārcis Pinnis",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.05460"" target=""_blank"">2009.05460</a>",,2025-12-03 22:39:25
Achieving Adversarial Robustness via Sparsity,"Shufan Wang, Ningyi Liao, Liyao Xiang, Nanyang Ye, Quanshi Zhang",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.05423"" target=""_blank"">2009.05423</a>",,2025-12-03 22:39:25
The Intriguing Relation Between Counterfactual Explanations and Adversarial Examples,Timo Freiesleben,arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.05487"" target=""_blank"">2009.05487</a>",,2025-12-03 22:39:25
Semantic-preserving Reinforcement Learning Attack Against Graph Neural Networks for Malware Detection,"Lan Zhang, Peng Liu, Yoon-Ho Choi",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.05602"" target=""_blank"">2009.05602</a>",,2025-12-03 22:39:25
Input Hessian Regularization of Neural Networks,"Waleed Mustafa, Robert A. Vandermeulen, Marius Kloft",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.06571"" target=""_blank"">2009.06571</a>",,2025-12-03 22:39:25
Second Order Optimization for Adversarial Robustness and Interpretability,"Theodoros Tsiligkaridis, Jay Roberts",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.04923"" target=""_blank"">2009.04923</a>",,2025-12-03 22:39:25
Robust Deep Learning Ensemble against Deception,"Wenqi Wei, Ling Liu",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.06589"" target=""_blank"">2009.06589</a>",,2025-12-03 22:39:25
Analysis of Generalizability of Deep Neural Networks Based on the Complexity of Decision Boundary,"Shuyue Guan, Murray Loew",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.07974"" target=""_blank"">2009.07974</a>",,2025-12-03 22:39:25
A Game Theoretic Analysis of Additive Adversarial Attacks and Defenses,"Ambar Pal, René Vidal",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.06530"" target=""_blank"">2009.06530</a>",,2025-12-03 22:39:25
Decision-based Universal Adversarial Attack,"Jing Wu, Mingyi Zhou, Shuaicheng Liu, Yipeng Liu, Ce Zhu",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.07024"" target=""_blank"">2009.07024</a>",,2025-12-03 22:39:25
Switching Gradient Directions for Query-Efficient Black-Box Adversarial Attacks,"Chen Ma, Shuyu Cheng, Li Chen, Junhai Yong",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.07191"" target=""_blank"">2009.07191</a>","<a href=""https://github.com/machanic/SWITCH"" target=""_blank"">machanic</a>",2025-12-03 22:39:25
Light Can Hack Your Face! Black-box Backdoor Attack on Face Recognition Systems,"Haoliang Nanyang Technological University, Singapore Li, Yufei Nanyang Technological University, Singapore Wang, Xiaofei Nanyang Technological University, Singapore Xie, Yang Nanyang Technological University, Singapore Liu, Shiqi City University of Hong Kong Wang, Renjie Nanyang Technological University, Singapore Wan, Lap-Pui Nanyang Technological University, Singapore Chau, Alex C. Nanyang Technological University, Singapore Kot",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.06996"" target=""_blank"">2009.06996</a>",,2025-12-03 22:39:25
Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup,"Jang-Hyun Kim, Wonho Choo, Hyun Oh Song",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.06962"" target=""_blank"">2009.06962</a>","<a href=""https://github.com/snu-mllab/PuzzleMix"" target=""_blank"">snu-mllab</a>",2025-12-03 22:39:25
Contextualized Perturbation for Textual Adversarial Attack,"Dianqi Li, Yizhe Zhang, Hao Peng, Liqun Chen, Chris Brockett, Ming-Ting Sun, Bill Dolan",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.07502"" target=""_blank"">2009.07502</a>",,2025-12-03 22:39:25
Malicious Network Traffic Detection via Deep Learning: An Information Theoretic View,Erick Galinkin,arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.07753"" target=""_blank"">2009.07753</a>",,2025-12-03 22:39:25
Multimodal Safety-Critical Scenarios Generation for Decision-Making Algorithms Evaluation,"Wenhao Ding, Baiming Chen, Bo Li, Kim Ji Eun, Ding Zhao",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.08311"" target=""_blank"">2009.08311</a>",,2025-12-03 22:39:25
Large Norms of CNN Layers Do Not Hurt Adversarial Robustness,"Youwei Liang, Dong Huang",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.08435"" target=""_blank"">2009.08435</a>","<a href=""https://github.com/youweiliang/norm_robustness"" target=""_blank"">youweiliang</a>",2025-12-03 22:39:25
On the Transferability of Minimal Prediction Preserving Inputs in Question Answering,"Shayne Longpre, Yi Lu, Christopher DuBois",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.08070"" target=""_blank"">2009.08070</a>",,2025-12-03 22:39:25
MultAV: Multiplicative Adversarial Videos,"Shao-Yuan Lo, Vishal M. Patel",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.08058"" target=""_blank"">2009.08058</a>",,2025-12-03 22:39:25
Online Alternate Generator against Adversarial Attacks,"Haofeng Li, Yirui Zeng, Guanbin Li, Liang Lin, Yizhou Yu",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.08110"" target=""_blank"">2009.08110</a>",,2025-12-03 22:39:25
Quantifying the Preferential Direction of the Model Gradient in Adversarial Training With Projected Gradient Descent,"Ricardo Bigolin Lanfredi, Joyce D. Schroeder, Tolga Tasdizen",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.04709"" target=""_blank"">2009.04709</a>",,2025-12-03 22:39:25
Open-set Adversarial Defense,"Rui Shao, Pramuditha Perera, Pong C. Yuen, Vishal M. Patel",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.00814"" target=""_blank"">2009.00814</a>","<a href=""https://github.com/rshaojimmy/ECCV2020-OSAD"" target=""_blank"">rshaojimmy</a>",2025-12-03 22:39:25
End-to-end Kernel Learning via Generative Random Fourier Features,"Kun Fang, Xiaolin Huang, Fanghui Liu, Jie Yang",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.04614"" target=""_blank"">2009.04614</a>",,2025-12-03 22:39:25
Searching for a Search Method: Benchmarking Search Algorithms for Generating NLP Adversarial Examples,"Jin Yong Yoo, John X. Morris, Eli Lifland, Yanjun Qi",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.06368"" target=""_blank"">2009.06368</a>","<a href=""https://github.com/QData/TextAttack"" target=""_blank"">QData</a>",2025-12-03 22:39:25
Vax-a-Net: Training-time Defence Against Adversarial Patch Attacks,"T. Gittings, S. Schneider, J. Collomosse",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.08194"" target=""_blank"">2009.08194</a>",,2025-12-03 22:39:25
Generating Image Adversarial Examples by Embedding Digital Watermarks,"Yuexin Xiang, Tiantian Li, Wei Ren, Tianqing Zhu, Kim-Kwang Raymond Choo",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.05107"" target=""_blank"">2009.05107</a>",,2025-12-03 22:39:25
Adversarial Eigen Attack on Black-Box Models,"Linjun Zhou, Peng Cui, Yinan Jiang, Shiqiang Yang",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.00097"" target=""_blank"">2009.00097</a>",,2025-12-03 22:39:25
"Efficient, Direct, and Restricted Black-Box Graph Evasion Attacks to Any-Layer Graph Neural Networks via Influence Function","Binghui Wang, Tianxiang Zhou, Minhua Lin, Pan Zhou, Ang Li, Meng Pang, Hai Li, Yiran Chen",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.00203"" target=""_blank"">2009.00203</a>","<a href=""https://github.com/ventr1c/InfAttack"" target=""_blank"">ventr1c</a>",2025-12-03 22:39:25
MALCOM: Generating Malicious Comments to Attack Neural Fake News Detection Models,"Thai Le, Suhang Wang, Dongwon Lee",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.01048"" target=""_blank"">2009.01048</a>",,2025-12-03 22:39:25
Defending against substitute model black box adversarial attacks with the 01 loss,"Yunzhe Xue, Meiyan Xie, Usman Roshan",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09803"" target=""_blank"">2009.09803</a>",,2025-12-03 22:39:25
Simulating Unknown Target Models for Query-Efficient Black-box Attacks,"Chen Ma, Li Chen, Jun-Hai Yong",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.00960"" target=""_blank"">2009.00960</a>","<a href=""https://github.com/machanic/SimulatorAttack"" target=""_blank"">machanic</a>",2025-12-03 22:39:25
Adversarial Attacks on Deep Learning Systems for User Identification based on Motion Sensors,"Cezara Benegui, Radu Tudor Ionescu",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.01109"" target=""_blank"">2009.01109</a>",,2025-12-03 22:39:25
Flow-based detection and proxy-based evasion of encrypted malware C2 traffic,"Carlos University of Porto and INESC TEC Novo, Ricardo University of Porto and INESC TEC Morla",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.01122"" target=""_blank"">2009.01122</a>",,2025-12-03 22:39:25
Adversarially Robust Neural Architectures,"Minjing Dong, Yanxi Li, Yunhe Wang, Chang Xu",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.00902"" target=""_blank"">2009.00902</a>",,2025-12-03 22:39:25
Perceptual Deep Neural Networks: Adversarial Robustness through Input Recreation,"Danilo Vasconcellos Vargas, Bingli Liao, Takahiro Kanzaki",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.01110"" target=""_blank"">2009.01110</a>",,2025-12-03 22:39:25
"Yet Meta Learning Can Adapt Fast, It Can Also Break Easily","Han Xu, Yaxin Li, Xiaorui Liu, Hui Liu, Jiliang Tang",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.01672"" target=""_blank"">2009.01672</a>",,2025-12-03 22:39:25
MIPGAN -- Generating Strong and High Quality Morphing Attacks Using Identity Prior Driven GAN,"Haoyu Zhang, Sushma Venkatesh, Raghavendra Ramachandra, Kiran Raja, Naser Damer, Christoph Busch",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.01729"" target=""_blank"">2009.01729</a>",,2025-12-03 22:39:25
Dual Manifold Adversarial Robustness: Defense against Lp and non-Lp Adversarial Attacks,"Wei-An Lin, Chun Pong Lau, Alexander Levine, Rama Chellappa, Soheil Feizi",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.02470"" target=""_blank"">2009.02470</a>",,2025-12-03 22:39:25
Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks,"Nilaksh Polo Das, Haekyu Polo Park, Zijie J. Polo Wang, Fred Polo Hohman, Robert Polo Firstman, Emily Polo Rogers, Duen Polo Horng, Chau",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.02608"" target=""_blank"">2009.02608</a>",,2025-12-03 22:39:25
Detection Defense Against Adversarial Attacks with Saliency Map,"Dengpan Ye, Chuanxi Chen, Changrui Liu, Hao Wang, Shunzhi Jiang",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.02738"" target=""_blank"">2009.02738</a>",,2025-12-03 22:39:25
Dynamically Computing Adversarial Perturbations for Recurrent Neural Networks,"Shankar A. Deka, Dušan M. Stipanović, Claire J. Tomlin",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.02874"" target=""_blank"">2009.02874</a>",,2025-12-03 22:39:25
A Game Theoretic Analysis of LQG Control under Adversarial Attack,"Zuxing Li, György Dán, Dong Liu",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.02877"" target=""_blank"">2009.02877</a>",,2025-12-03 22:39:25
Black Box to White Box: Discover Model Characteristics Based on Strategic Probing,"Josh Kalin, Matthew Ciolino, David Noever, Gerry Dozier",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.03136"" target=""_blank"">2009.03136</a>",,2025-12-03 22:39:25
Adversarial Attack on Large Scale Graph,"Jintang Li, Tao Xie, Liang Chen, Fenfang Xie, Xiangnan He, Zibin Zheng",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.03488"" target=""_blank"">2009.03488</a>",,2025-12-03 22:39:25
Adversarial attacks on deep learning models for fatty liver disease classification by modification of ultrasound image reconstruction method,"Michal Byra, Grzegorz Styczynski, Cezary Szmigielski, Piotr Kalinowski, Lukasz Michalowski, Rafal Paluszkiewicz, Bogna Ziarkiewicz-Wroblewska, Krzysztof Zieniewicz, Andrzej Nowicki",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.03364"" target=""_blank"">2009.03364</a>",,2025-12-03 22:39:25
Adversarial Machine Learning in Image Classification: A Survey Towards the Defender's Perspective,"Gabriel Resende Machado, Eugênio Silva, Ronaldo Ribeiro Goldschmidt",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.03728"" target=""_blank"">2009.03728</a>",,2025-12-03 22:39:25
Fuzzy Unique Image Transformation: Defense Against Adversarial Attacks On Deep COVID-19 Models,"Achyut Mani Tripathi, Ashish Mishra",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.04004"" target=""_blank"">2009.04004</a>",,2025-12-03 22:39:25
SoK: Certified Robustness for Deep Neural Networks,"Linyi Li, Tao Xie, Bo Li",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.04131"" target=""_blank"">2009.04131</a>",,2025-12-03 22:39:25
A black-box adversarial attack for poisoning clustering,"Antonio Emanuele Cinà, Alessandro Torcinovich, Marcello Pelillo",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.05474"" target=""_blank"">2009.05474</a>",,2025-12-03 22:39:25
Label Smoothing and Adversarial Robustness,"Chaohao Fu, Hongbin Chen, Na Ruan, Weijia Jia",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.08233"" target=""_blank"">2009.08233</a>",,2025-12-03 22:39:25
Improving Ensemble Robustness by Collaboratively Promoting and Demoting Adversarial Robustness,"Anh Bui, Trung Le, He Zhao, Paul Montague, Olivier deVel, Tamas Abraham, Dinh Phung",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09612"" target=""_blank"">2009.09612</a>",,2025-12-03 22:39:25
Generating Label Cohesive and Well-Formed Adversarial Claims,"Pepa Atanasova, Dustin Wright, Isabelle Augenstein",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.08205"" target=""_blank"">2009.08205</a>",,2025-12-03 22:39:25
Robustification of Segmentation Models Against Adversarial Perturbations In Medical Imaging,"Hanwool Park, Amirhossein Bayat, Mohammad Sabokrou, Jan S. Kirschke, Bjoern H. Menze",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.11090"" target=""_blank"">2009.11090</a>",,2025-12-03 22:39:25
A Partial Break of the Honeypots Defense to Catch Adversarial Attacks,Nicholas Carlini,arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.10975"" target=""_blank"">2009.10975</a>",,2025-12-03 22:39:25
Adversarial robustness via stochastic regularization of neural activation sensitivity,"Gil Fidel, Ron Bitton, Ziv Katzir, Asaf Shabtai",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.11349"" target=""_blank"">2009.11349</a>",,2025-12-03 22:39:25
Improving Dialog Evaluation with a Multi-reference Adversarial Dataset and Large Scale Pretraining,"Ananya B. Sai, Akash Kumar Mohankumar, Siddhartha Arora, Mitesh M. Khapra",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.11321"" target=""_blank"">2009.11321</a>",,2025-12-03 22:39:25
Enhancing Mixup-based Semi-Supervised Learning with Explicit Lipschitz Regularization,"Prashnna Kumar Gyawali, Sandesh Ghimire, Linwei Wang",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.11416"" target=""_blank"">2009.11416</a>","<a href=""https://github.com/Prasanna1991/Mixup-LR"" target=""_blank"">Prasanna1991</a>",2025-12-03 22:39:25
Improving Query Efficiency of Black-box Adversarial Attack,"Yang Bai, Yuyuan Zeng, Yong Jiang, Yisen Wang, Shu-Tao Xia, Weiwei Guo",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.11508"" target=""_blank"">2009.11508</a>",,2025-12-03 22:39:25
Adversarial Examples in Deep Learning for Multivariate Time Series Regression,"Gautam Raj Mode, Khaza Anuarul Hoque",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.11911"" target=""_blank"">2009.11911</a>",,2025-12-03 22:39:25
Advancing the Research and Development of Assured Artificial Intelligence and Machine Learning Capabilities,"Tyler J. Shipp, Daniel J. Clouse, Lucia Michael J. De, Metin B. Ahiskali, Kai Steverson, Jonathan M. Mullin, Nathaniel D. Bastian",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.13250"" target=""_blank"">2009.13250</a>",,2025-12-03 22:39:25
Attention Meets Perturbations: Robust and Interpretable Attention with Adversarial Training,"Shunsuke Kitada, Hitoshi Iyatomi",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.12064"" target=""_blank"">2009.12064</a>","<a href=""https://github.com/shunk031/attention-meets-perturbation"" target=""_blank"">shunk031</a>",2025-12-03 22:39:25
Training CNNs in Presence of JPEG Compression: Multimedia Forensics vs Computer Vision,"Sara Mandelli, Nicolò Bonettini, Paolo Bestagini, Stefano Tubaro",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.12088"" target=""_blank"">2009.12088</a>",,2025-12-03 22:39:25
Beneficial Perturbations Network for Defending Adversarial Examples,"Shixian Wen, Amanda Rios, Laurent Itti",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.12724"" target=""_blank"">2009.12724</a>",,2025-12-03 22:39:25
Differentially Private Adversarial Robustness Through Randomized Perturbations,"Nan Xu, Oluwaseyi Feyisetan, Abhinav Aggarwal, Zekun Xu, Nathanael Teissier",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.12718"" target=""_blank"">2009.12718</a>",,2025-12-03 22:39:25
Where Does the Robustness Come from? A Study of the Transformation-based Ensemble Defence,"Chang Liao, Yao Cheng, Chengfang Fang, Jie Shi",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.13033"" target=""_blank"">2009.13033</a>",,2025-12-03 22:39:25
RoGAT: a robust GNN combined revised GAT with adjusted graphs,"Xianchen Zhou, Yaoyun Zeng, Hongxia Wang",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.13038"" target=""_blank"">2009.13038</a>",,2025-12-03 22:39:25
Learning to Improve Image Compression without Changing the Standard Decoder,"Yannick Strümpler, Ren Yang, Radu Timofte",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.12927"" target=""_blank"">2009.12927</a>","<a href=""https://github.com/YannickStruempler/LearnedJPEG"" target=""_blank"">YannickStruempler</a>",2025-12-03 22:39:25
Certifying Confidence via Randomized Smoothing,"Aounon Kumar, Alexander Levine, Soheil Feizi, Tom Goldstein",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.08061"" target=""_blank"">2009.08061</a>",,2025-12-03 22:39:25
Generating End-to-End Adversarial Examples for Malware Classifiers Using Explainability,"Ishai Rosenberg, Shai Meir, Jonathan Berrebi, Ilay Gordon, Guillaume Sicard, Eli David",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.13243"" target=""_blank"">2009.13243</a>",,2025-12-03 22:39:25
Adversarial Robustness of Stabilized NeuralODEs Might be from Obfuscated Gradients,"Yifei Huang, Yaodong Yu, Hongyang Zhang, Yi Ma, Yuan Yao",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.13145"" target=""_blank"">2009.13145</a>",,2025-12-03 22:39:25
Graph Adversarial Networks: Protecting Information against Adversarial Attacks,"Peiyuan Liao, Han Zhao, Keyulu Xu, Tommi Jaakkola, Geoffrey Gordon, Stefanie Jegelka, Ruslan Salakhutdinov",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.13504"" target=""_blank"">2009.13504</a>",,2025-12-03 22:39:25
STRATA: Building Robustness with a Simple Method for Generating Black-box Adversarial Attacks for Models of Code,"Jacob M. Springer, Bryn Marie Reinstadler, Una-May O'Reilly",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.13562"" target=""_blank"">2009.13562</a>",,2025-12-03 22:39:25
Adversarial Attacks Against Deep Learning Systems for ICD-9 Code Assignment,"Sharan Raja, Rudraksh Tuwani",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.13720"" target=""_blank"">2009.13720</a>",,2025-12-03 22:39:25
Fast Fr\'echet Inception Distance,"Alexander Mathiasen, Frederik Hvilshøj",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.14075"" target=""_blank"">2009.14075</a>",,2025-12-03 22:39:25
Neural Topic Modeling with Cycle-Consistent Adversarial Training,"Xuemeng Hu, Rui Wang, Deyu Zhou, Yuxuan Xiong",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.13971"" target=""_blank"">2009.13971</a>",,2025-12-03 22:39:25
DVERGE: Diversifying Vulnerabilities for Enhanced Robust Generation of Ensembles,"Huanrui Yang, Jingyang Zhang, Hongliang Dong, Nathan Inkawhich, Andrew Gardner, Andrew Touchet, Wesley Wilkes, Heath Berry, Hai Li",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.14720"" target=""_blank"">2009.14720</a>","<a href=""https://github.com/zjysteven/DVERGE"" target=""_blank"">zjysteven</a>",2025-12-03 22:39:25
Uncertainty-Matching Graph Neural Networks to Defend Against Poisoning Attacks,"Uday Shankar Shanthamallu, Jayaraman J. Thiagarajan, Andreas Spanias",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.14455"" target=""_blank"">2009.14455</a>",,2025-12-03 22:39:25
Accurate and Robust Feature Importance Estimation under Distribution Shifts,"Jayaraman J. Thiagarajan, Vivek Narayanaswamy, Rushil Anirudh, Peer-Timo Bremer, Andreas Spanias",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.14454"" target=""_blank"">2009.14454</a>",,2025-12-03 22:39:25
Semantics-Preserving Adversarial Training,"Wonseok Lee, Hanbit Lee, Sang-goo Lee",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.10978"" target=""_blank"">2009.10978</a>",,2025-12-03 22:39:25
Learning to Generate Image Source-Agnostic Universal Adversarial Perturbations,"Pu Zhao, Parikshit Ram, Songtao Lu, Yuguang Yao, Djallel Bouneffouf, Xue Lin, Sijia Liu",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.13714"" target=""_blank"">2009.13714</a>",,2025-12-03 22:39:25
Detection of Iterative Adversarial Attacks via Counter Attack,"Matthias Rottmann, Kira Maag, Mathis Peyron, Natasa Krejic, Hanno Gottschalk",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.11397"" target=""_blank"">2009.11397</a>",,2025-12-03 22:39:25
Password Strength Signaling: A Counter-Intuitive Defense Against Password Cracking,"Wenjie Bai, Jeremiah Blocki, Ben Harsha",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.10060"" target=""_blank"">2009.10060</a>",,2025-12-03 22:39:25
Robust Decentralized Learning for Neural Networks,"Yao Zhou, Jun Wu, Jingrui He",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09026"" target=""_blank"">2009.09026</a>",,2025-12-03 22:39:25
What Do You See? Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors,"Yi-Shan Lin, Wen-Chuan Lee, Z. Berkay Celik",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.10639"" target=""_blank"">2009.10639</a>",,2025-12-03 22:39:25
MIRAGE: Mitigating Conflict-Based Cache Attacks with a Practical Fully-Associative Design,"Gururaj Saileshwar, Moinuddin Qureshi",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09090"" target=""_blank"">2009.09090</a>",,2025-12-03 22:39:25
EI-MTD:Moving Target Defense for Edge Intelligence against Adversarial Attacks,"Yaguan Qian, Qiqi Shao, Jiamin Wang, Xiang Lin, Yankai Guo, Zhaoquan Gu, Bin Wang, Chunming Wu",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.10537"" target=""_blank"">2009.10537</a>",,2025-12-03 22:39:25
Adversarial Exposure Attack on Diabetic Retinopathy Imagery Grading,"Yupeng Cheng, Qing Guo, Felix Juefei-Xu, Huazhu Fu, Shang-Wei Lin, Weisi Lin",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09231"" target=""_blank"">2009.09231</a>",,2025-12-03 22:39:25
Adversarial Rain Attack and Defensive Deraining for DNN Perception,"Liming Zhai, Felix Juefei-Xu, Qing Guo, Xiaofei Xie, Lei Ma, Wei Feng, Shengchao Qin, Yang Liu",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09205"" target=""_blank"">2009.09205</a>",,2025-12-03 22:39:25
Bias Field Poses a Threat to DNN-based X-Ray Recognition,"Binyu Tian, Qing Guo, Felix Juefei-Xu, Wen Le Chan, Yupeng Cheng, Xiaohong Li, Xiaofei Xie, Shengchao Qin",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09247"" target=""_blank"">2009.09247</a>",,2025-12-03 22:39:25
Making Images Undiscoverable from Co-Saliency Detection,"Ruijun Gao, Qing Guo, Felix Juefei-Xu, Hongkai Yu, Xuhong Ren, Wei Feng, Song Wang",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09258"" target=""_blank"">2009.09258</a>",,2025-12-03 22:39:25
OpenAttack: An Open-source Textual Adversarial Attack Toolkit,"Guoyang Zeng, Fanchao Qi, Qianrui Zhou, Tingji Zhang, Bairu Hou, Yuan Zang, Zhiyuan Liu, Maosong Sun",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09191"" target=""_blank"">2009.09191</a>","<a href=""https://github.com/thunlp/OpenAttack"" target=""_blank"">thunlp</a>",2025-12-03 22:39:25
Efficient Certification of Spatial Robustness,"Anian Ruoss, Maximilian Baader, Mislav Balunović, Martin Vechev",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09318"" target=""_blank"">2009.09318</a>",,2025-12-03 22:39:25
Improving Robustness and Generality of NLP Models Using Disentangled Representations,"Jiawei Wu, Xiaoya Li, Xiang Ao, Yuxian Meng, Fei Wu, Jiwei Li",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09587"" target=""_blank"">2009.09587</a>",,2025-12-03 22:39:25
Learning to Attack: Towards Textual Adversarial Attacking in Real-world Situations,"Yuan Zang, Bairu Hou, Fanchao Qi, Zhiyuan Liu, Xiaojun Meng, Maosong Sun",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09192"" target=""_blank"">2009.09192</a>",,2025-12-03 22:39:25
Optimal Provable Robustness of Quantum Classification via Quantum Hypothesis Testing,"Maurice Weber, Nana Liu, Bo Li, Ce Zhang, Zhikuan Zhao",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.10064"" target=""_blank"">2009.10064</a>",,2025-12-03 22:39:25
Adversarial Training with Stochastic Weight Average,"Joong-Won Hwang, Youngwan Lee, Sungchan Oh, Yuseok Bae",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.10526"" target=""_blank"">2009.10526</a>",,2025-12-03 22:39:25
Adversarial Attack Based Countermeasures against Deep Learning Side-Channel Attacks,"Ruizhe Gu, Ping Wang, Mengce Zheng, Honggang Hu, Nenghai Yu",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.10568"" target=""_blank"">2009.10568</a>",,2025-12-03 22:39:25
Stereopagnosia: Fooling Stereo Networks with Adversarial Perturbations,"Alex Wong, Mukund Mundhra, Stefano Soatto",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.10142"" target=""_blank"">2009.10142</a>",,2025-12-03 22:39:25
Uncertainty-aware Attention Graph Neural Network for Defending Adversarial Attacks,"Boyuan Feng, Yuke Wang, Zheng Wang, Yufei Ding",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.10235"" target=""_blank"">2009.10235</a>",,2025-12-03 22:39:25
Tailoring: encoding inductive biases by optimizing unsupervised objectives at prediction time,"Ferran Alet, Kenji Kawaguchi, Tomas Lozano-Perez, Leslie Pack Kaelbling",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.10623"" target=""_blank"">2009.10623</a>",,2025-12-03 22:39:25
Generating Adversarial yet Inconspicuous Patches with a Single Image,"Jinqi Luo, Tao Bai, Jun Zhao, Bo Li",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09774"" target=""_blank"">2009.09774</a>",,2025-12-03 22:39:25
Scalable Adversarial Attack on Graph Neural Networks with Alternating Direction Method of Multipliers,"Boyuan Feng, Yuke Wang, Xu Li, Yufei Ding",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.10233"" target=""_blank"">2009.10233</a>",,2025-12-03 22:39:25
DeepDyve: Dynamic Verification for Deep Neural Networks,"Yu Li, Min Li, Bo Luo, Ye Tian, Qiang Xu",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09663"" target=""_blank"">2009.09663</a>",,2025-12-03 22:39:25
Feature Distillation With Guided Adversarial Contrastive Learning,"Tao Bai, Jinnan Chen, Jun Zhao, Bihan Wen, Xudong Jiang, Alex Kot",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.09922"" target=""_blank"">2009.09922</a>",,2025-12-03 22:39:25
Crafting Adversarial Examples for Deep Learning Based Prognostics (Extended Version),"Gautam Raj Mode, Khaza Anuarul Hoque",arXiv,2020-09,"<a href=""http://arxiv.org/abs/2009.10149"" target=""_blank"">2009.10149</a>",,2025-12-03 22:39:25
FireBERT: Hardening BERT-based classifiers against adversarial attack,"Gunnar Mein, Kevin Hartman, Andrew Morris",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.04203"" target=""_blank"">2008.04203</a>",,2025-12-03 22:39:25
Enhancing Robustness Against Adversarial Examples in Network Intrusion Detection Systems,"Mohammad J. Hashemi, Eric Keller",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.03677"" target=""_blank"">2008.03677</a>",,2025-12-03 22:39:25
Informative Dropout for Robust Representation Learning: A Shape-bias Perspective,"Baifeng Shi, Dinghuai Zhang, Qi Dai, Zhanxing Zhu, Yadong Mu, Jingdong Wang",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.04254"" target=""_blank"">2008.04254</a>","<a href=""https://github.com/bfshi/InfoDrop"" target=""_blank"">bfshi</a>",2025-12-03 22:39:25
Revisiting Adversarially Learned Injection Attacks Against Recommender Systems,"Jiaxi Tang, Hongyi Wen, Ke Wang",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.04876"" target=""_blank"">2008.04876</a>",,2025-12-03 22:39:25
Semantics-preserving adversarial attacks in NLP,"Rahul Singh, Tarun Joshi, Vijayan N. Nair, Agus Sudjianto",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.05536"" target=""_blank"">2008.05536</a>",,2025-12-03 22:39:25
Feature Binding with Category-Dependant MixUp for Semantic Segmentation and Adversarial Robustness,"Md Amirul Islam, Matthew Kowal, Konstantinos G. Derpanis, Neil D. B. Bruce",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.05667"" target=""_blank"">2008.05667</a>",,2025-12-03 22:39:25
Defending Adversarial Examples via DNN Bottleneck Reinforcement,"Wenqing Liu, Miaojing Shi, Teddy Furon, Li Li",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.05230"" target=""_blank"">2008.05230</a>",,2025-12-03 22:39:25
Adversarial Training and Provable Robustness: A Tale of Two Objectives,"Jiameng Fan, Wenchao Li",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.06081"" target=""_blank"">2008.06081</a>",,2025-12-03 22:39:25
Learning to Learn from Mistakes: Robust Optimization for Adversarial Noise,"Alex Serban, Erik Poll, Joost Visser",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.05247"" target=""_blank"">2008.05247</a>",,2025-12-03 22:39:25
Continuous Patrolling Games,"Steve Alpern, Thuy Bui, Thomas Lidbetter, Katerina Papadaki",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.07369"" target=""_blank"">2008.07369</a>",,2025-12-03 22:39:25
Semantically Adversarial Learnable Filters,"Ali Shahin Shamsabadi, Changjae Oh, Andrea Cavallaro",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.06069"" target=""_blank"">2008.06069</a>",,2025-12-03 22:39:25
From Attack to Protection: Leveraging Watermarking Attack Network for Advanced Add-on Watermarking,"Seung-Hun Nam, Jihyeon Kang, Daesik Kim, Namhyuk Ahn, Wonhyuk Ahn",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.06255"" target=""_blank"">2008.06255</a>",,2025-12-03 22:39:25
On the Generalization Properties of Adversarial Training,"Yue Xing, Qifan Song, Guang Cheng",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.06631"" target=""_blank"">2008.06631</a>",,2025-12-03 22:39:25
Enhance CNN Robustness Against Noises for Classification of 12-Lead ECG with Variable Length,"Linhai Ma, Liang Liang",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.03609"" target=""_blank"">2008.03609</a>",,2025-12-03 22:39:25
Defending Adversarial Attacks without Adversarial Attacks in Deep Reinforcement Learning,"Xinghua Qu, Yew-Soon Ong, Abhishek Gupta, Zhu Sun",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.06199"" target=""_blank"">2008.06199</a>",,2025-12-03 22:39:25
Adversarial Training with Fast Gradient Projection Method against Synonym Substitution based Text Attacks,"Xiaosen Wang, Yichen Yang, Yihe Deng, Kun He",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.03709"" target=""_blank"">2008.03709</a>",,2025-12-03 22:39:25
Entropy Guided Adversarial Model for Weakly Supervised Object Localization,"Sabrina Narimene Benassou, Wuzhen Shi, Feng Jiang",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.01786"" target=""_blank"">2008.01786</a>",,2025-12-03 22:39:25
Visual Attack and Defense on Text,"Shengjun Liu, Ningkang Jiang, Yuanbin Wu",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.10356"" target=""_blank"">2008.10356</a>",,2025-12-03 22:39:25
Optimizing Information Loss Towards Robust Neural Networks,"Philip Sperl, Konstantin Böttinger",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.03072"" target=""_blank"">2008.03072</a>",,2025-12-03 22:39:25
TextDecepter: Hard Label Black Box Attack on Text Classifiers,Sachin Saxena,arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.06860"" target=""_blank"">2008.06860</a>",,2025-12-03 22:39:25
Attacking and Defending Machine Learning Applications of Public Cloud,"Dou Goodman, Hao Xin",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.02076"" target=""_blank"">2008.02076</a>",,2025-12-03 22:39:25
Vulnerability Under Adversarial Machine Learning: Bias or Variance?,"Hossein Aboutalebi, Mohammad Javad Shafiee, Michelle Karg, Christian Scharfenberger, Alexander Wong",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.00138"" target=""_blank"">2008.00138</a>",,2025-12-03 22:39:25
Trojaning Language Models for Fun and Profit,"Xinyang Zhang, Zheng Zhang, Shouling Ji, Ting Wang",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.00312"" target=""_blank"">2008.00312</a>",,2025-12-03 22:39:25
Efficient Adversarial Attacks for Visual Object Tracking,"Siyuan Liang, Xingxing Wei, Siyuan Yao, Xiaochun Cao",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.00217"" target=""_blank"">2008.00217</a>",,2025-12-03 22:39:25
Anti-Bandit Neural Architecture Search for Model Defense,"Hanlin Chen, Baochang Zhang, Song Xue, Xuan Gong, Hong Liu, Rongrong Ji, David Doermann",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.00698"" target=""_blank"">2008.00698</a>",,2025-12-03 22:39:25
Hardware Accelerator for Adversarial Attacks on Deep Learning Neural Networks,"Haoqiang Guo, Lu Peng, Jian Zhang, Fang Qi, Lide Duan",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.01219"" target=""_blank"">2008.01219</a>",,2025-12-03 22:39:25
Can Adversarial Weight Perturbations Inject Neural Backdoors?,"Siddhant Garg, Adarsh Kumar, Vibhor Goel, Yingyu Liang",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.01761"" target=""_blank"">2008.01761</a>",,2025-12-03 22:39:25
TREND: Transferability based Robust ENsemble Design,"Deepak Ravikumar, Sangamesh Kodge, Isha Garg, Kaushik Roy",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.01524"" target=""_blank"">2008.01524</a>",,2025-12-03 22:39:25
Adv-watermark: A Novel Watermark Perturbation for Adversarial Examples,"Xiaojun Jia, Xingxing Wei, Xiaochun Cao, Xiaoguang Han",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.01919"" target=""_blank"">2008.01919</a>",,2025-12-03 22:39:25
Robust Deep Reinforcement Learning through Adversarial Loss,"Tuomas Oikarinen, Wang Zhang, Alexandre Megretski, Luca Daniel, Tsui-Wei Weng",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.01976"" target=""_blank"">2008.01976</a>","<a href=""https://github.com/tuomaso/radial_rl_v2"" target=""_blank"">tuomaso</a>",2025-12-03 22:39:25
One word at a time: adversarial attacks on retrieval models,"Nisarg Raval, Manisha Verma",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.02197"" target=""_blank"">2008.02197</a>",,2025-12-03 22:39:25
Improve Generalization and Robustness of Neural Networks via Weight Scale Shifting Invariant Regularizations,"Ziquan Liu, Yufei Cui, Antoni B. Chan",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.02965"" target=""_blank"">2008.02965</a>",,2025-12-03 22:39:25
Stronger and Faster Wasserstein Adversarial Attacks,"Kaiwen Wu, Allen Houze Wang, Yaoliang Yu",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.02883"" target=""_blank"">2008.02883</a>",,2025-12-03 22:39:25
Adversarial Examples on Object Recognition: A Comprehensive Survey,"Alex Serban, Erik Poll, Joost Visser",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.04094"" target=""_blank"">2008.04094</a>",,2025-12-03 22:39:25
Relevance Attack on Detectors,"Sizhe Chen, Fan He, Xiaolin Huang, Kun Zhang",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.06822"" target=""_blank"">2008.06822</a>",,2025-12-03 22:39:25
Adversarial Concurrent Training: Optimizing Robustness and Accuracy Trade-off of Deep Neural Networks,"Elahe Arani, Fahad Sarfraz, Bahram Zonooz",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.07015"" target=""_blank"">2008.07015</a>",,2025-12-03 22:39:25
Adversarial Patch Camouflage against Aerial Detection,"Ajaya Adhikari, Richard den Hollander, Ioannis Tolios, Bekkum Michael van, Anneloes Bal, Stijn Hendriks, Maarten Kruithof, Dennis Gross, Nils Jansen, Guillermo Pérez, Kit Buurman, Stephan Raaijmakers",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.13671"" target=""_blank"">2008.13671</a>",,2025-12-03 22:39:25
Developing and Defeating Adversarial Examples,"Ian McDiarmid-Sterling, Allan Moser",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.10106"" target=""_blank"">2008.10106</a>","<a href=""https://github.com/ianmcdiarmidsterling/adversarial"" target=""_blank"">ianmcdiarmidsterling</a>",2025-12-03 22:39:25
An Adversarial Attack Defending System for Securing In-Vehicle Networks,"Yi Li, Jing Lin, Kaiqi Xiong",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.11278"" target=""_blank"">2008.11278</a>",,2025-12-03 22:39:25
Rethinking Non-idealities in Memristive Crossbars for Adversarial Robustness in Neural Networks,"Abhiroop Bhattacharjee, Priyadarshini Panda",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.11298"" target=""_blank"">2008.11298</a>",,2025-12-03 22:39:25
Two Sides of the Same Coin: White-box and Black-box Attacks for Transfer Learning,"Yinghua Zhang, Yangqiu Song, Jian Liang, Kun Bai, Qiang Yang",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.11089"" target=""_blank"">2008.11089</a>",,2025-12-03 22:39:25
Likelihood Landscapes: A Unifying Principle Behind Many Adversarial Defenses,"Fu Lin, Rohit Mittapalli, Prithvijit Chattopadhyay, Daniel Bolya, Judy Hoffman",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.11300"" target=""_blank"">2008.11300</a>",,2025-12-03 22:39:25
Adversarially Training for Audio Classifiers,"Raymel Alfonso Sallo, Mohammad Esmaeilpour, Patrick Cardinal",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.11618"" target=""_blank"">2008.11618</a>",,2025-12-03 22:39:25
Adversarially Robust Learning via Entropic Regularization,"Gauri Jagatap, Ameya Joshi, Animesh Basak Chowdhury, Siddharth Garg, Chinmay Hegde",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.12338"" target=""_blank"">2008.12338</a>",,2025-12-03 22:39:25
Color and Edge-Aware Adversarial Image Perturbations,"Robert Bassett, Mitchell Graves, Patrick Reilly",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.12454"" target=""_blank"">2008.12454</a>","<a href=""https://github.com/rbassett3/Color-and-Edge-Aware-Perturbations"" target=""_blank"">rbassett3</a>",2025-12-03 22:39:25
On the Intrinsic Robustness of NVM Crossbars Against Adversarial Attacks,"Deboleena Roy, Indranil Chakraborty, Timur Ibrayev, Kaushik Roy",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.12016"" target=""_blank"">2008.12016</a>",,2025-12-03 22:39:25
Minimal Adversarial Examples for Deep Learning on 3D Point Clouds,"Jaeyeon Kim, Binh-Son Hua, Duc Thanh Nguyen, Sai-Kit Yeung",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.12066"" target=""_blank"">2008.12066</a>",,2025-12-03 22:39:25
GhostBuster: Looking Into Shadows to Detect Ghost Objects in Autonomous Vehicle 3D Sensing,"Zhongyuan Hau, Soteris Demetriou, Luis Muñoz-González, Emil C. Lupu",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.12008"" target=""_blank"">2008.12008</a>",,2025-12-03 22:39:25
A Scene-Agnostic Framework with Adversarial Training for Abnormal Event Detection in Video,"Mariana-Iuliana Georgescu, Radu Tudor Ionescu, Fahad Shahbaz Khan, Marius Popescu, Mubarak Shah",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.12328"" target=""_blank"">2008.12328</a>",,2025-12-03 22:39:25
Shape Defense Against Adversarial Attacks,Ali Borji,arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.13336"" target=""_blank"">2008.13336</a>","<a href=""https://github.com/aliborji/Shapedefense"" target=""_blank"">aliborji</a>",2025-12-03 22:39:25
An Integrated Approach to Produce Robust Models with High Efficiency,"Zhijian Li, Bao Wang, Jack Xin",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.13305"" target=""_blank"">2008.13305</a>",,2025-12-03 22:39:25
Robustness Verification of Quantum Classifiers,"Ji Guan, Wang Fang, Mingsheng Ying",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.07230"" target=""_blank"">2008.07230</a>",,2025-12-03 22:39:25
Benchmarking adversarial attacks and defenses for time-series data,"Shoaib Ahmed Siddiqui, Andreas Dengel, Sheraz Ahmed",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.13261"" target=""_blank"">2008.13261</a>",,2025-12-03 22:39:25
Certified Robustness of Graph Neural Networks against Adversarial Structural Perturbation,"Binghui Wang, Jinyuan Jia, Xiaoyu Cao, Neil Zhenqiang Gong",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.10715"" target=""_blank"">2008.10715</a>",,2025-12-03 22:39:25
Improving Resistance to Adversarial Deformations by Regularizing Gradients,"Pengfei Xia, Bin Li",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.12997"" target=""_blank"">2008.12997</a>",,2025-12-03 22:39:25
Ptolemy: Architecture Support for Robust Deep Learning,"Yiming Gan, Yuxian Qiu, Jingwen Leng, Minyi Guo, Yuhao Zhu",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.09954"" target=""_blank"">2008.09954</a>",,2025-12-03 22:39:25
On $\ell_p$-norm Robustness of Ensemble Stumps and Trees,"Yihan Wang, Huan Zhang, Hongge Chen, Duane Boning, Cho-Jui Hsieh",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.08755"" target=""_blank"">2008.08755</a>",,2025-12-03 22:39:25
Adversarial Attack and Defense Strategies for Deep Speaker Recognition Systems,"Arindam Jati, Chin-Cheng Hsu, Monisankha Pal, Raghuveer Peri, Wael AbdAlmageed, Shrikanth Narayanan",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.07685"" target=""_blank"">2008.07685</a>",,2025-12-03 22:39:25
PermuteAttack: Counterfactual Explanation of Machine Learning Credit Scorecards,"Masoud Hashemi, Ali Fathi",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.10138"" target=""_blank"">2008.10138</a>",,2025-12-03 22:39:25
Adversarial EXEmples: A Survey and Experimental Evaluation of Practical Attacks on Machine Learning for Windows Malware Detection,"Luca Demetrio, Scott E. Coull, Battista Biggio, Giovanni Lagorio, Alessandro Armando, Fabio Roli",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.07125"" target=""_blank"">2008.07125</a>",,2025-12-03 22:39:25
Accelerated Zeroth-Order and First-Order Momentum Methods from Mini to Minimax Optimization,"Feihu Huang, Shangqian Gao, Jian Pei, Heng Huang",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.08170"" target=""_blank"">2008.08170</a>",,2025-12-03 22:39:25
Direct Adversarial Training for GANs,Ziqiang Li,arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.09041"" target=""_blank"">2008.09041</a>",,2025-12-03 22:39:25
Improving adversarial robustness of deep neural networks by using semantic information,"Lina Wang, Rui Tang, Yawei Yue, Xingshu Chen, Wei Wang, Yi Zhu, Xuemei Zeng",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.07838"" target=""_blank"">2008.07838</a>",,2025-12-03 22:39:25
Prototype-based interpretation of the functionality of neurons in winner-take-all neural networks,"Ramin Zarei Sabzevar, Kamaledin Ghiasi-Shirazi, Ahad Harati",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.08750"" target=""_blank"">2008.08750</a>",,2025-12-03 22:39:25
A Deep Dive into Adversarial Robustness in Zero-Shot Learning,"Mehmet Kerim Yucel, Ramazan Gokberk Cinbis, Pinar Duygulu",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.07651"" target=""_blank"">2008.07651</a>",,2025-12-03 22:39:25
Addressing Neural Network Robustness with Mixup and Targeted Labeling Adversarial Training,"Alfred Laugros, Alice Caplier, Matthieu Ospici",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.08384"" target=""_blank"">2008.08384</a>",,2025-12-03 22:39:25
$\beta$-Variational Classifiers Under Attack,"Marco Maggipinto, Matteo Terzi, Gian Antonio Susto",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.09010"" target=""_blank"">2008.09010</a>",,2025-12-03 22:39:25
Self-Competitive Neural Networks,"Iman Saberi, Fathiyeh Faghih",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.09824"" target=""_blank"">2008.09824</a>",,2025-12-03 22:39:25
On Attribution of Deepfakes,"Baiwu Zhang, Jin Peng Zhou, Ilia Shumailov, Nicolas Papernot",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.09194"" target=""_blank"">2008.09194</a>",,2025-12-03 22:39:25
Towards adversarial robustness with 01 loss neural networks,"Yunzhe Xue, Meiyan Xie, Usman Roshan",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.09148"" target=""_blank"">2008.09148</a>",,2025-12-03 22:39:25
Yet Another Intermediate-Level Attack,"Qizhang Li, Yiwen Guo, Hao Chen",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.08847"" target=""_blank"">2008.08847</a>","<a href=""https://github.com/qizhangli/ila-plus-plus"" target=""_blank"">qizhangli</a>",2025-12-03 22:39:25
"A Survey on Assessing the Generalization Envelope of Deep Neural Networks: Predictive Uncertainty, Out-of-distribution and Adversarial Samples","Julia Lust, Alexandru Paul Condurache",arXiv,2020-08,"<a href=""http://arxiv.org/abs/2008.09381"" target=""_blank"">2008.09381</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness by Enforcing Local and Global Compactness,"Anh Bui, Trung Le, He Zhao, Paul Montague, Olivier deVel, Tamas Abraham, Dinh Phung",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.05123"" target=""_blank"">2007.05123</a>",,2025-12-03 22:39:25
Adversarially-Trained Deep Nets Transfer Better: Illustration on Image Classification,"Francisco Utrera, Evan Kravitz, N. Benjamin Erichson, Rajiv Khanna, Michael W. Mahoney",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.05869"" target=""_blank"">2007.05869</a>",,2025-12-03 22:39:25
Improved Detection of Adversarial Images Using Deep Neural Networks,"Yutong Gao, Yi Pan",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.05573"" target=""_blank"">2007.05573</a>",,2025-12-03 22:39:25
Miss the Point: Targeted Adversarial Attack on Multiple Landmark Detection,"Qingsong Yao, Zecheng He, Hu Han, S. Kevin Zhou",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.05225"" target=""_blank"">2007.05225</a>","<a href=""https://github.com/qsyao/attack_landmark_detection"" target=""_blank"">qsyao</a>",2025-12-03 22:39:25
Generating Adversarial Inputs Using A Black-box Differential Technique,"João Batista Pereira Matos Juúnior, Lucas Carvalho Cordeiro, Marcelo d'Amorim, Xiaowei Huang",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.05315"" target=""_blank"">2007.05315</a>",,2025-12-03 22:39:25
Node Copying for Protection Against Graph Neural Network Topology Attacks,"Florence Regol, Soumyasundar Pal, Mark Coates",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.06704"" target=""_blank"">2007.06704</a>",,2025-12-03 22:39:25
Boundary thickness and robustness in learning models,"Yaoqing Yang, Rajiv Khanna, Yaodong Yu, Amir Gholami, Kurt Keutzer, Joseph E. Gonzalez, Kannan Ramchandran, Michael W. Mahoney",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.05086"" target=""_blank"">2007.05086</a>",,2025-12-03 22:39:25
Efficient detection of adversarial images,"Darpan Kumar Yadav, Kartik Mundra, Rahul Modpur, Arpan Chattopadhyay, Indra Narayan Kar",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.04564"" target=""_blank"">2007.04564</a>",,2025-12-03 22:39:25
How benign is benign overfitting?,"Amartya Sanyal, Puneet K Dokania, Varun Kanade, Philip H. S. Torr",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.04028"" target=""_blank"">2007.04028</a>",,2025-12-03 22:39:25
SLAP: Improving Physical Adversarial Examples with Short-Lived Adversarial Perturbations,"Giulio Lovisotto, Henry Turner, Ivo Sluganovic, Martin Strohmeier, Ivan Martinovic",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.04137"" target=""_blank"">2007.04137</a>",,2025-12-03 22:39:25
RobFR: Benchmarking Adversarial Robustness on Face Recognition,"Xiao Yang, Dingcheng Yang, Yinpeng Dong, Hang Su, Wenjian Yu, Jun Zhu",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.04118"" target=""_blank"">2007.04118</a>","<a href=""https://github.com/ShawnXYang/Face-Robustness-Benchmark"" target=""_blank"">ShawnXYang</a>",2025-12-03 22:39:25
A Critical Evaluation of Open-World Machine Learning,"Liwei Song, Vikash Sehwag, Arjun Nitin Bhagoji, Prateek Mittal",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.04391"" target=""_blank"">2007.04391</a>",,2025-12-03 22:39:25
ManiGen: A Manifold Aided Black-box Generator of Adversarial Examples,"Guanxiong Liu, Issa Khalil, Abdallah Khreishah, Abdulelah Algosaibi, Adel Aldalbahi, Mohammed Alaneem, Abdulaziz Alhumam, Mohammed Anan",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.05817"" target=""_blank"">2007.05817</a>",,2025-12-03 22:39:25
Hard Label Black-box Adversarial Attacks in Low Query Budget Regimes,"Satya Narayan Shukla, Anit Kumar Sahu, Devin Willmott, J. Zico Kolter",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.07210"" target=""_blank"">2007.07210</a>",,2025-12-03 22:39:25
Understanding Object Detection Through An Adversarial Lens,"Ka-Ho Chow, Ling Liu, Mehmet Emre Gursoy, Stacey Truex, Wenqi Wei, Yanzhao Wu",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.05828"" target=""_blank"">2007.05828</a>",,2025-12-03 22:39:25
Probabilistic Jacobian-based Saliency Maps Attacks,"Théo Combey, António Loison, Maxime Faucher, Hatem Hajri",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.06032"" target=""_blank"">2007.06032</a>","<a href=""https://github.com/probabilistic-jsmas/probabilistic-jsmas"" target=""_blank"">probabilistic-jsmas</a>",2025-12-03 22:39:25
Generating Fluent Adversarial Examples for Natural Languages,"Huangzhao Zhang, Hao Zhou, Ning Miao, Lei Li",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.06174"" target=""_blank"">2007.06174</a>",,2025-12-03 22:39:25
Patch-wise Attack for Fooling Deep Neural Network,"Lianli Gao, Qilong Zhang, Jingkuan Song, Xianglong Liu, Heng Tao Shen",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.06765"" target=""_blank"">2007.06765</a>","<a href=""https://github.com/qilong-zhang/Patch-wise-iterative-attack"" target=""_blank"">qilong-zhang</a>",2025-12-03 22:39:25
SoK: The Faults in our ASRs: An Overview of Attacks against Automatic Speech Recognition and Speaker Identification Systems,"Hadi Abdullah, Kevin Warren, Vincent Bindschaedler, Nicolas Papernot, Patrick Traynor",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.06622"" target=""_blank"">2007.06622</a>",,2025-12-03 22:39:25
Calling Out Bluff: Attacking the Robustness of Automatic Scoring Systems with Simple Adversarial Testing,"Yaman Kumar, Mehar Bhatia, Anubha Kabra, Jessy Junyi Li, Di Jin, Rajiv Ratn Shah",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.06796"" target=""_blank"">2007.06796</a>",,2025-12-03 22:39:25
Security and Machine Learning in the Real World,"Ivan Evtimov, Weidong Cui, Ece Kamar, Emre Kiciman, Tadayoshi Kohno, Jerry Li",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.07205"" target=""_blank"">2007.07205</a>",,2025-12-03 22:39:25
Adversarial robustness via robust low rank representations,"Pranjal Awasthi, Himanshu Jain, Ankit Singh Rawat, Aravindan Vijayaraghavan",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.06555"" target=""_blank"">2007.06555</a>",,2025-12-03 22:39:25
Understanding Adversarial Examples from the Mutual Influence of Images and Perturbations,"Chaoning Zhang, Philipp Benz, Tooba Imtiaz, In-So Kweon",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.06189"" target=""_blank"">2007.06189</a>",,2025-12-03 22:39:25
A simple defense against adversarial attacks on heatmap explanations,"Laura Rieger, Lars Kai Hansen",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.06381"" target=""_blank"">2007.06381</a>",,2025-12-03 22:39:25
Towards a Theoretical Understanding of the Robustness of Variational Autoencoders,"Alexander Camuto, Matthew Willetts, Stephen Roberts, Chris Holmes, Tom Rainforth",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.07365"" target=""_blank"">2007.07365</a>",,2025-12-03 22:39:25
Adversarial Attacks against Neural Networks in Audio Domain: Exploiting Principal Components,"Ken Alparslan, Yigit Alparslan, Matthew Burlick",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.07001"" target=""_blank"">2007.07001</a>",,2025-12-03 22:39:25
Pasadena: Perceptually Aware and Stealthy Adversarial Denoise Attack,"Yupeng Cheng, Qing Guo, Felix Juefei-Xu, Wei Feng, Shang-Wei Lin, Weisi Lin, Yang Liu",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.07097"" target=""_blank"">2007.07097</a>",,2025-12-03 22:39:25
Evaluation of Adversarial Training on Different Types of Neural Networks in Deep Learning-based IDSs,"Rana Abou Khamis, Ashraf Matrawy",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.04472"" target=""_blank"">2007.04472</a>",,2025-12-03 22:39:25
"On the relationship between class selectivity, dimensionality, and robustness","Matthew L. Leavitt, Ari S. Morcos",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.04440"" target=""_blank"">2007.04440</a>",,2025-12-03 22:39:25
Decoder-free Robustness Disentanglement without (Additional) Supervision,"Yifei Wang, Dan Peng, Furui Liu, Zhenguo Li, Zhitang Chen, Jiansheng Yang",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.01356"" target=""_blank"">2007.01356</a>",,2025-12-03 22:39:25
Robust Learning with Frequency Domain Regularization,"Weiyu Guo, Yidong Ouyang",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.03244"" target=""_blank"">2007.03244</a>",,2025-12-03 22:39:25
Adversarial Examples and Metrics,"Nico Döttling, Kathrin Grosse, Michael Backes, Ian Molloy",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.06993"" target=""_blank"">2007.06993</a>",,2025-12-03 22:39:25
Generating Adversarial Examples with an Optimized Quality,"Aminollah Khormali, DaeHun Nyang, David Mohaisen",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.00146"" target=""_blank"">2007.00146</a>",,2025-12-03 22:39:25
Neural Network Virtual Sensors for Fuel Injection Quantities with Provable Performance Specifications,"Eric Wong, Tim Schneider, Joerg Schmitt, Frank R. Schmidt, J. Zico Kolter",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.00147"" target=""_blank"">2007.00147</a>",,2025-12-03 22:39:25
Opportunities and Challenges in Deep Learning Adversarial Robustness: A Survey,"Samuel Henrique Silva, Peyman Najafirad",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.00753"" target=""_blank"">2007.00753</a>",,2025-12-03 22:39:25
A Le Cam Type Bound for Adversarial Learning and Applications,"Qiuling Xu, Kevin Bello, Jean Honorio",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.00289"" target=""_blank"">2007.00289</a>",,2025-12-03 22:39:25
Robustness against Relational Adversary,"Yizhen Wang, Xiaozhu Meng, Ke Wang, Mihai Christodorescu, Somesh Jha",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.00772"" target=""_blank"">2007.00772</a>",,2025-12-03 22:39:25
Adversarial Example Games,"Avishek Joey Bose, Gauthier Gidel, Hugo Berard, Andre Cianflone, Pascal Vincent, Simon Lacoste-Julien, William L. Hamilton",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.00720"" target=""_blank"">2007.00720</a>",,2025-12-03 22:39:25
Query-Free Adversarial Transfer via Undertrained Surrogates,"Chris Miller, Soroush Vosoughi",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.00806"" target=""_blank"">2007.00806</a>",,2025-12-03 22:39:25
Determining Sequence of Image Processing Technique (IPT) to Detect Adversarial Attacks,"Kishor Datta Gupta, Dipankar Dasgupta, Zahid Akhtar",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.00337"" target=""_blank"">2007.00337</a>",,2025-12-03 22:39:25
Measuring Robustness to Natural Distribution Shifts in Image Classification,"Rohan Taori, Achal Dave, Vaishaal Shankar, Nicholas Carlini, Benjamin Recht, Ludwig Schmidt",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.00644"" target=""_blank"">2007.00644</a>",,2025-12-03 22:39:25
Unifying Model Explainability and Robustness via Machine-Checkable Concepts,"Vedant Nanda, Till Speicher, John P. Dickerson, Krishna P. Gummadi, Muhammad Bilal Zafar",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.00251"" target=""_blank"">2007.00251</a>",,2025-12-03 22:39:25
Generating Adversarial Examples withControllable Non-transferability,"Renzhi Wang, Tianwei Zhang, Xiaofei Xie, Lei Ma, Cong Tian, Felix Juefei-Xu, Yang Liu",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.01299"" target=""_blank"">2007.01299</a>",,2025-12-03 22:39:25
Trace-Norm Adversarial Examples,"Ehsan Kazemi, Thomas Kerdreux, Liqiang Wang",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.01855"" target=""_blank"">2007.01855</a>",,2025-12-03 22:39:25
Increasing Trustworthiness of Deep Neural Networks via Accuracy Monitoring,"Zhihui Shao, Jianyi Yang, Shaolei Ren",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.01472"" target=""_blank"">2007.01472</a>",,2025-12-03 22:39:25
Deep Learning Defenses Against Adversarial Examples for Dynamic Risk Assessment,"Xabier Echeberria-Barrio, Amaia Gil-Lerchundi, Ines Goicoechea-Telleria, Raul Orduna-Urrutia",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.01017"" target=""_blank"">2007.01017</a>",,2025-12-03 22:39:25
Regional Image Perturbation Reduces $L_p$ Norms of Adversarial Examples While Maintaining Model-to-model Transferability,"Utku Ozbulak, Jonathan Peck, Neve Wesley De, Bart Goossens, Yvan Saeys, Messem Arnout Van",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.03198"" target=""_blank"">2007.03198</a>",,2025-12-03 22:39:25
Efficient Proximal Mapping of the 1-path-norm of Shallow Networks,"Fabian Latorre, Paul Rolland, Nadav Hallak, Volkan Cevher",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.01003"" target=""_blank"">2007.01003</a>",,2025-12-03 22:39:25
Towards Robust Deep Learning with Ensemble Networks and Noisy Layers,"Yuting Liang, Reza Samavi",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.01507"" target=""_blank"">2007.01507</a>",,2025-12-03 22:39:25
Deep Active Learning via Open Set Recognition,"Jaya Krishna Mandivarapu, Blake Camp, Rolando Estrada",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.02196"" target=""_blank"">2007.02196</a>",,2025-12-03 22:39:25
Relationship between manifold smoothness and adversarial vulnerability in deep learning with local errors,"Zijian Jiang, Jianwen Zhou, Haiping Huang",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.02047"" target=""_blank"">2007.02047</a>",,2025-12-03 22:39:25
On Connections between Regularizations for Improving DNN Robustness,"Yiwen Guo, Long Chen, Yurong Chen, Changshui Zhang",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.02209"" target=""_blank"">2007.02209</a>",,2025-12-03 22:39:25
Adversarial Learning in the Cyber Security Domain,"Ihai Rosenberg, Asaf Shabtai, Yuval Elovici, Lior Rokach",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.02407"" target=""_blank"">2007.02407</a>",,2025-12-03 22:39:25
Black-box Adversarial Example Generation with Normalizing Flows,"Hadi M. Dolatabadi, Sarah Erfani, Christopher Leckie",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.02734"" target=""_blank"">2007.02734</a>",,2025-12-03 22:39:25
Understanding and Improving Fast Adversarial Training,"Maksym Andriushchenko, Nicolas Flammarion",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.02617"" target=""_blank"">2007.02617</a>","<a href=""https://github.com/tml-epfl/understanding-fast-adv-training"" target=""_blank"">tml-epfl</a>",2025-12-03 22:39:25
On Data Augmentation and Adversarial Risk: An Empirical Analysis,"Hamid Eghbal-zadeh, Khaled Koutini, Paul Primus, Verena Haunschmid, Michal Lewandowski, Werner Zellinger, Bernhard A. Moser, Gerhard Widmer",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.02650"" target=""_blank"">2007.02650</a>",,2025-12-03 22:39:25
Certifying Decision Trees Against Evasion Attacks by Program Analysis,"Stefano Calzavara, Pietro Ferrara, Claudio Lucchese",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.02771"" target=""_blank"">2007.02771</a>",,2025-12-03 22:39:25
Detection as Regression: Certified Object Detection by Median Smoothing,"Ping-yeh Chiang, Michael J. Curry, Ahmed Abdelkader, Aounon Kumar, John Dickerson, Tom Goldstein",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.03730"" target=""_blank"">2007.03730</a>","<a href=""http://github.com/Ping-C/CertifiedObjectDetection"" target=""_blank"">Ping-C</a>",2025-12-03 22:39:25
Making Adversarial Examples More Transferable and Indistinguishable,"Junhua Zou, Yexin Duan, Boyu Li, Wu Zhang, Yu Pan, Zhisong Pan",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.03838"" target=""_blank"">2007.03838</a>",,2025-12-03 22:39:25
Fast Training of Deep Neural Networks Robust to Adversarial Perturbations,"Justin Goodwin, Olivia Brown, Victoria Helus",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.03832"" target=""_blank"">2007.03832</a>",,2025-12-03 22:39:25
AdvFlow: Inconspicuous Black-box Adversarial Attacks using Normalizing Flows,"Hadi M. Dolatabadi, Sarah Erfani, Christopher Leckie",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.07435"" target=""_blank"">2007.07435</a>","<a href=""https://github.com/hmdolatabadi/AdvFlow"" target=""_blank"">hmdolatabadi</a>",2025-12-03 22:39:25
Adversarial jamming attacks and defense strategies via adaptive deep reinforcement learning,"Feng Wang, Chen Zhong, M. Cenk Gursoy, Senem Velipasalar",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.06055"" target=""_blank"">2007.06055</a>",,2025-12-03 22:39:25
Multitask Learning Strengthens Adversarial Robustness,"Chengzhi Mao, Amogh Gupta, Vikram Nitin, Baishakhi Ray, Shuran Song, Junfeng Yang, Carl Vondrick",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.07236"" target=""_blank"">2007.07236</a>",,2025-12-03 22:39:25
Threat of Adversarial Attacks on Face Recognition: A Comprehensive Survey,"Fatemeh Vakhshiteh, Raghavendra Ramachandra, Ahmad Nickabadi",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.11709"" target=""_blank"">2007.11709</a>",,2025-12-03 22:39:25
Adversarial Training Reduces Information and Improves Transferability,"Matteo Terzi, Alessandro Achille, Marco Maggipinto, Gian Antonio Susto",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.11259"" target=""_blank"">2007.11259</a>",,2025-12-03 22:39:25
SOCRATES: Towards a Unified Platform for Neural Network Verification,"Long H. Pham, Jiaying Li, Jun Sun",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.11206"" target=""_blank"">2007.11206</a>",,2025-12-03 22:39:25
Provably Robust Adversarial Examples,"Dimitar I. Dimitrov, Gagandeep Singh, Timon Gehr, Martin Vechev",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.12133"" target=""_blank"">2007.12133</a>",,2025-12-03 22:39:25
Deep Co-Training with Task Decomposition for Semi-Supervised Domain Adaptation,"Luyu Yang, Yan Wang, Mingfei Gao, Abhinav Shrivastava, Kilian Q. Weinberger, Wei-Lun Chao, Ser-Nam Lim",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.12684"" target=""_blank"">2007.12684</a>","<a href=""https://github.com/LoyoYang/DeCoTa"" target=""_blank"">LoyoYang</a>",2025-12-03 22:39:25
MP3 Compression To Diminish Adversarial Noise in End-to-End Speech Recognition,"Iustina Andronic, Ludwig Kürzinger, Edgar Ricardo Chavez Rosas, Gerhard Rigoll, Bernhard U. Seeber",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.12892"" target=""_blank"">2007.12892</a>",,2025-12-03 22:39:25
Adversarial Privacy-preserving Filter,"Jiaming Zhang, Jitao Sang, Xian Zhao, Xiaowen Huang, Yanfeng Sun, Yongli Hu",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.12861"" target=""_blank"">2007.12861</a>",,2025-12-03 22:39:25
MirrorNet: Bio-Inspired Adversarial Attack for Camouflaged Object Segmentation,"Jinnan Yan, Trung-Nghia Le, Khanh-Duy Nguyen, Minh-Triet Tran, Thanh-Toan Do, Tam V. Nguyen",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.12881"" target=""_blank"">2007.12881</a>",,2025-12-03 22:39:25
Train Like a (Var)Pro: Efficient Training of Neural Networks with Variable Projection,"Elizabeth Newman, Lars Ruthotto, Joseph Hart, Bart van Bloemen Waanders",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.13171"" target=""_blank"">2007.13171</a>",,2025-12-03 22:39:25
Robust Collective Classification against Structural Attacks,"Kai Zhou, Yevgeniy Vorobeychik",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.13073"" target=""_blank"">2007.13073</a>",,2025-12-03 22:39:25
RANDOM MASK: Towards Robust Convolutional Neural Networks,"Tiange Luo, Tianle Cai, Mengxiao Zhang, Siyu Chen, Liwei Wang",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.14249"" target=""_blank"">2007.14249</a>",,2025-12-03 22:39:25
Towards Accuracy-Fairness Paradox: Adversarial Example-based Data Augmentation for Visual Debiasing,"Yi Zhang, Jitao Sang",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.13632"" target=""_blank"">2007.13632</a>",,2025-12-03 22:39:25
From Sound Representation to Model Robustness,"Mohamad Esmaeilpour, Patrick Cardinal, Alessandro Lameiras Koerich",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.13703"" target=""_blank"">2007.13703</a>",,2025-12-03 22:39:25
KOVIS: Keypoint-based Visual Servoing with Zero-Shot Sim-to-Real Transfer for Robotics Manipulation,"En Yen Puang, Keng Peng Tee, Wei Jing",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.13960"" target=""_blank"">2007.13960</a>",,2025-12-03 22:39:25
Reachable Sets of Classifiers and Regression Models: (Non-)Robustness Analysis and Robust Training,"Anna-Kathrin Kopetzki, Stephan Günnemann",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.14120"" target=""_blank"">2007.14120</a>",,2025-12-03 22:39:25
Derivation of Information-Theoretically Optimal Adversarial Attacks with Applications to Robust Machine Learning,"Jirong Yi, Raghu Mudumbai, Weiyu Xu",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.14042"" target=""_blank"">2007.14042</a>",,2025-12-03 22:39:25
Cassandra: Detecting Trojaned Networks from Adversarial Perturbations,"Xiaoyu Zhang, Ajmal Mian, Rohit Gupta, Nazanin Rahnavard, Mubarak Shah",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.14433"" target=""_blank"">2007.14433</a>",,2025-12-03 22:39:25
Detecting Anomalous Inputs to DNN Classifiers By Joint Statistical Testing at the Layers,"Jayaram Raghuram, Varun Chandrasekaran, Somesh Jha, Suman Banerjee",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.15147"" target=""_blank"">2007.15147</a>",,2025-12-03 22:39:25
Stylized Adversarial Defense,"Muzammal Naseer, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, Fatih Porikli",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.14672"" target=""_blank"">2007.14672</a>",,2025-12-03 22:39:25
Generative Classifiers as a Basis for Trustworthy Computer Vision,"Radek Mackowiak, Lynton Ardizzone, Ullrich Köthe, Carsten Rother",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.15036"" target=""_blank"">2007.15036</a>",,2025-12-03 22:39:25
Adversarial Robustness for Machine Learning Cyber Defenses Using Log Data,"Kai Steverson, Jonathan Mullin, Metin Ahiskali",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.14983"" target=""_blank"">2007.14983</a>",,2025-12-03 22:39:25
End-to-End Adversarial White Box Attacks on Music Instrument Classification,"Katharina Johannes Kepler University Linz Prinz, Arthur Johannes Kepler University Linz Flexer",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.14714"" target=""_blank"">2007.14714</a>",,2025-12-03 22:39:25
vWitness: Certifying Web Page Interactions with Computer Vision,"He Shuang, Lianying Zhao, David Lie",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.15805"" target=""_blank"">2007.15805</a>",,2025-12-03 22:39:25
A Data Augmentation-based Defense Method Against Adversarial Attacks in Neural Networks,"Yi Zeng, Han Qiu, Gerard Memmi, Meikang Qiu",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.15290"" target=""_blank"">2007.15290</a>",,2025-12-03 22:39:25
Black-box Adversarial Sample Generation Based on Differential Evolution,"Junyu Lin, Lei Xu, Yingqi Liu, Xiangyu Zhang",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.15310"" target=""_blank"">2007.15310</a>",,2025-12-03 22:39:25
TEAM: We Need More Powerful Adversarial Examples for DNNs,"Yaguan Qian, Ximin Zhang, Bin Wang, Wei Li, Zhaoquan Gu, Haijiang Wang, Wassim Swaileh",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.15836"" target=""_blank"">2007.15836</a>",,2025-12-03 22:39:25
Adversarial Attacks with Multiple Antennas Against Deep Learning-Based Modulation Classifiers,"Brian Kim, Yalin E. Sagduyu, Tugba Erpek, Kemal Davaslioglu, Sennur Ulukus",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.16204"" target=""_blank"">2007.16204</a>",,2025-12-03 22:39:25
Physical Adversarial Attack on Vehicle Detector in the Carla Simulator,"Tong Wu, Xuefei Ning, Wenshuo Li, Ranran Huang, Huazhong Yang, Yu Wang",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.16118"" target=""_blank"">2007.16118</a>",,2025-12-03 22:39:25
Robust Machine Learning via Privacy/Rate-Distortion Theory,"Ye Wang, Shuchin Aeron, Adnan Siraj Rakin, Toshiaki Koike-Akino, Pierre Moulin",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.11693"" target=""_blank"">2007.11693</a>",,2025-12-03 22:39:25
Label-Only Membership Inference Attacks,"Christopher A. Choquette-Choo, Florian Tramer, Nicholas Carlini, Nicolas Papernot",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.14321"" target=""_blank"">2007.14321</a>",,2025-12-03 22:39:25
Audio Adversarial Examples for Robust Hybrid CTC/Attention Speech Recognition,"Ludwig Kürzinger, Edgar Ricardo Chavez Rosas, Lujun Li, Tobias Watzel, Gerhard Rigoll",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.10723"" target=""_blank"">2007.10723</a>",,2025-12-03 22:39:25
Understanding and Diagnosing Vulnerability under Adversarial Attacks,"Haizhong Zheng, Ziqi Zhang, Honglak Lee, Atul Prakash",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.08716"" target=""_blank"">2007.08716</a>",,2025-12-03 22:39:25
Robustifying Reinforcement Learning Agents via Action Space Adversarial Training,"Kai Liang Tan, Yasaman Esfandiari, Xian Yeow Lee, Aakanksha, Soumik Sarkar",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.07176"" target=""_blank"">2007.07176</a>",,2025-12-03 22:39:25
Towards robust sensing for Autonomous Vehicles: An adversarial perspective,"Apostolos Modas, Ricardo Sanchez-Matilla, Pascal Frossard, Andrea Cavallaro",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.10115"" target=""_blank"">2007.10115</a>",,2025-12-03 22:39:25
Towards Visual Distortion in Black-Box Attacks,"Nannan Li, Zhenzhong Chen",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.10593"" target=""_blank"">2007.10593</a>","<a href=""https://github.com/Alina-1997/visual-distortion-in-attack"" target=""_blank"">Alina-1997</a>",2025-12-03 22:39:25
A Survey on Security Attacks and Defense Techniques for Connected and Autonomous Vehicles,"Minh Pham, Kaiqi Xiong",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.08041"" target=""_blank"">2007.08041</a>",,2025-12-03 22:39:25
Accelerating Robustness Verification of Deep Neural Networks Guided by Target Labels,"Wenjie Wan, Zhaodi Zhang, Yiwei Zhu, Min Zhang, Fu Song",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.08520"" target=""_blank"">2007.08520</a>",,2025-12-03 22:39:25
A Survey of Privacy Attacks in Machine Learning,"Maria Rigaki, Sebastian Garcia",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.07646"" target=""_blank"">2007.07646</a>",,2025-12-03 22:39:25
Less is More: A privacy-respecting Android malware classifier using Federated Learning,"Rafa Gálvez, Veelasha Moonsamy, Claudia Diaz",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.08319"" target=""_blank"">2007.08319</a>",,2025-12-03 22:39:25
On Robustness and Transferability of Convolutional Neural Networks,"Josip Djolonga, Jessica Yung, Michael Tschannen, Rob Romijnders, Lucas Beyer, Alexander Kolesnikov, Joan Puigcerver, Matthias Minderer, Alexander D'Amour, Dan Moldovan, Sylvain Gelly, Neil Houlsby, Xiaohua Zhai, Mario Lucic",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.08558"" target=""_blank"">2007.08558</a>",,2025-12-03 22:39:25
Learning perturbation sets for robust machine learning,"Eric Wong, J. Zico Kolter",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.08450"" target=""_blank"">2007.08450</a>","<a href=""https://github.com/locuslab/perturbation_learning"" target=""_blank"">locuslab</a>",2025-12-03 22:39:25
Do Adversarially Robust ImageNet Models Transfer Better?,"Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, Aleksander Madry",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.08489"" target=""_blank"">2007.08489</a>","<a href=""https://github.com/Microsoft/robust-models-transfer"" target=""_blank"">Microsoft</a>",2025-12-03 22:39:25
An Empirical Study on the Robustness of NAS based Architectures,"Chaitanya Devaguptapu, Devansh Agarwal, Gaurav Mittal, Vineeth N Balasubramanian",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.08428"" target=""_blank"">2007.08428</a>",,2025-12-03 22:39:25
Provable Worst Case Guarantees for the Detection of Out-of-Distribution Data,"Julian Bitterwolf, Alexander Meinke, Matthias Hein",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.08473"" target=""_blank"">2007.08473</a>",,2025-12-03 22:39:25
Accelerated Stochastic Gradient-free and Projection-free Methods,"Feihu Huang, Lue Tao, Songcan Chen",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.12625"" target=""_blank"">2007.12625</a>",,2025-12-03 22:39:25
Transfer Learning without Knowing: Reprogramming Black-box Machine Learning Models with Scarce Data and Limited Resources,"Yun-Yun Tsai, Pin-Yu Chen, Tsung-Yi Ho",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.08714"" target=""_blank"">2007.08714</a>",,2025-12-03 22:39:25
Bounding The Number of Linear Regions in Local Area for Neural Networks with ReLU Activations,"Rui Zhu, Bo Lin, Haixu Tang",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.06803"" target=""_blank"">2007.06803</a>",,2025-12-03 22:39:25
Evaluating a Simple Retraining Strategy as a Defense Against Adversarial Attacks,"Nupur Thakur, Yuzhen Ding, Baoxin Li",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.09916"" target=""_blank"">2007.09916</a>",,2025-12-03 22:39:25
Exploiting vulnerabilities of deep neural networks for privacy protection,"Ricardo Sanchez-Matilla, Chau Yi Li, Ali Shahin Shamsabadi, Riccardo Mazzon, Andrea Cavallaro",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.09766"" target=""_blank"">2007.09766</a>","<a href=""https://github.com/smartcameras/RP-FGSM/"" target=""_blank"">RP-FGSM</a>",2025-12-03 22:39:25
Neural Networks with Recurrent Generative Feedback,"Yujia Huang, James Gornet, Sihui Dai, Zhiding Yu, Tan Nguyen, Doris Y. Tsao, Anima Anandkumar",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.09200"" target=""_blank"">2007.09200</a>",,2025-12-03 22:39:25
DeepNNK: Explaining deep models and their generalization using polytope interpolation,"Sarath Shekkizhar, Antonio Ortega",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.10505"" target=""_blank"">2007.10505</a>",,2025-12-03 22:39:25
Robust Tracking against Adversarial Attacks,"Shuai Jia, Chao Ma, Yibing Song, Xiaokang Yang",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.09919"" target=""_blank"">2007.09919</a>",,2025-12-03 22:39:25
Scaling Polyhedral Neural Network Verification on GPUs,"Christoph Müller, François Serre, Gagandeep Singh, Markus Püschel, Martin Vechev",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.10868"" target=""_blank"">2007.10868</a>",,2025-12-03 22:39:25
Semantic Equivalent Adversarial Data Augmentation for Visual Question Answering,"Ruixue Tang, Chao Ma, Wei Emma Zhang, Qi Wu, Xiaokang Yang",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.09592"" target=""_blank"">2007.09592</a>","<a href=""https://github.com/zaynmi/seada-vqa"" target=""_blank"">zaynmi</a>",2025-12-03 22:39:25
AdvFoolGen: Creating Persistent Troubles for Deep Classifiers,"Yuzhen Ding, Nupur Thakur, Baoxin Li",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.10485"" target=""_blank"">2007.10485</a>",,2025-12-03 22:39:25
Connecting the Dots: Detecting Adversarial Perturbations Using Context Inconsistency,"Shasha Li, Shitong Zhu, Sudipta Paul, Amit Roy-Chowdhury, Chengyu Song, Srikanth Krishnamurthy, Ananthram Swami, Kevin S Chan",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.09763"" target=""_blank"">2007.09763</a>",,2025-12-03 22:39:25
Adversarial Immunization for Improving Certifiable Robustness on Graphs,"Shuchang Tao, Huawei Shen, Qi Cao, Liang Hou, Xueqi Cheng",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.09647"" target=""_blank"">2007.09647</a>",,2025-12-03 22:39:25
DDR-ID: Dual Deep Reconstruction Networks Based Image Decomposition for Anomaly Detection,"Dongyun Lin, Yiqun Li, Shudong Xie, Tin Lay Nwe, Sheng Dong",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.09431"" target=""_blank"">2007.09431</a>",,2025-12-03 22:39:25
Towards Quantum-Secure Authentication and Key Agreement via Abstract Multi-Agent Interaction,"Ibrahim H. Ahmed, Josiah P. Hanna, Elliot Fosong, Stefano V. Albrecht",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.09327"" target=""_blank"">2007.09327</a>",,2025-12-03 22:39:25
Anomaly Detection in Unsupervised Surveillance Setting Using Ensemble of Multimodal Data with Adversarial Defense,"Sayeed Shafayet Chowdhury, Kaji Mejbaul Islam, Rouhan Noor",arXiv,2020-07,"<a href=""http://arxiv.org/abs/2007.10812"" target=""_blank"">2007.10812</a>",,2025-12-03 22:39:25
Towards an Intrinsic Definition of Robustness for a Classifier,"Théo Giraudon, Vincent Gripon, Matthias Löwe, Franck Vermet",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.05095"" target=""_blank"">2006.05095</a>",,2025-12-03 22:39:25
Evaluating Graph Vulnerability and Robustness using TIGER,"Scott Freitas, Duen Horng Chau",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.05648"" target=""_blank"">2006.05648</a>","<a href=""https://github.com/safreita1/TIGER"" target=""_blank"">safreita1</a>",2025-12-03 22:39:25
Towards Robust Fine-grained Recognition by Maximal Separation of Discriminative Features,"Krishna Kanth Nakka, Mathieu Salzmann",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.06028"" target=""_blank"">2006.06028</a>",,2025-12-03 22:39:25
Deterministic Gaussian Averaged Neural Networks,"Ryan Campbell, Chris Finlay, Adam M Oberman",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.06061"" target=""_blank"">2006.06061</a>",,2025-12-03 22:39:25
Interpolation between Residual and Non-Residual Networks,"Zonghan Yang, Yang Liu, Chenglong Bao, Zuoqiang Shi",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.05749"" target=""_blank"">2006.05749</a>",,2025-12-03 22:39:25
Towards Certified Robustness of Metric Learning,"Xiaochen Yang, Yiwen Guo, Mingzhi Dong, Jing-Hao Xue",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.05945"" target=""_blank"">2006.05945</a>",,2025-12-03 22:39:25
A Self-supervised Approach for Adversarial Robustness,"Muzammal Naseer, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, Fatih Porikli",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.04924"" target=""_blank"">2006.04924</a>","<a href=""https://github.com/Muzammal-Naseer/NRP"" target=""_blank"">Muzammal-Naseer</a>",2025-12-03 22:39:25
Black-Box Adversarial Attacks on Graph Neural Networks with Limited Node Access,"Jiaqi Ma, Shuangrui Ding, Qiaozhu Mei",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.05057"" target=""_blank"">2006.05057</a>",,2025-12-03 22:39:25
GAP++: Learning to generate target-conditioned adversarial examples,"Xiaofeng Mao, Yuefeng Chen, Yuhong Li, Yuan He, Hui Xue",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.05097"" target=""_blank"">2006.05097</a>",,2025-12-03 22:39:25
Adversarial Attacks on Brain-Inspired Hyperdimensional Computing-Based Classifiers,"Fangfang Yang, Shaolei Ren",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.05594"" target=""_blank"">2006.05594</a>",,2025-12-03 22:39:25
Provable tradeoffs in adversarially robust classification,"Edgar Dobriban, Hamed Hassani, David Hong, Alexander Robey",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.05161"" target=""_blank"">2006.05161</a>",,2025-12-03 22:39:25
Achieving robustness in classification using optimal transport with hinge regularization,"Mathieu Serrurier, Franck Mamalet, Alberto González-Sanz, Thibaut Boissin, Jean-Michel Loubes, Barrio Eustasio del",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.06520"" target=""_blank"">2006.06520</a>",,2025-12-03 22:39:25
Distributional Robust Batch Contextual Bandits,"Nian Si, Fan Zhang, Zhengyuan Zhou, Jose Blanchet",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.05630"" target=""_blank"">2006.05630</a>",,2025-12-03 22:39:25
Calibrated neighborhood aware confidence measure for deep metric learning,"Maryna Karpusha, Sunghee Yun, Istvan Fehervari",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.04935"" target=""_blank"">2006.04935</a>",,2025-12-03 22:39:25
Backdoor Smoothing: Demystifying Backdoor Attacks on Deep Neural Networks,"Kathrin Grosse, Taesung Lee, Battista Biggio, Youngja Park, Michael Backes, Ian Molloy",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.06721"" target=""_blank"">2006.06721</a>",,2025-12-03 22:39:25
Large-Scale Adversarial Training for Vision-and-Language Representation Learning,"Zhe Gan, Yen-Chun Chen, Linjie Li, Chen Zhu, Yu Cheng, Jingjing Liu",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.06195"" target=""_blank"">2006.06195</a>",,2025-12-03 22:39:25
Adversarial Attack Vulnerability of Medical Image Analysis Systems: Unexplored Factors,"Suzanne C. Wetstein, Cristina González-Gonzalo, Gerda Bortsova, Bart Liefers, Florian Dubost, Ioannis Katramados, Laurens Hogeweg, Ginneken Bram van, Josien P. W. Pluim, Bruijne Marleen de, Clara I. Sánchez, Mitko Veta",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.06356"" target=""_blank"">2006.06356</a>",,2025-12-03 22:39:25
On the Tightness of Semidefinite Relaxations for Certifying Robustness to Adversarial Examples,Richard Y. Zhang,arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.06759"" target=""_blank"">2006.06759</a>",,2025-12-03 22:39:25
Robustness to Adversarial Attacks in Learning-Enabled Controllers,"Zikang Xiong, Joe Eappen, He Zhu, Suresh Jagannathan",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.06861"" target=""_blank"">2006.06861</a>",,2025-12-03 22:39:25
Investigating Robustness of Adversarial Samples Detection for Automatic Speaker Verification,"Xu Li, Na Li, Jinghua Zhong, Xixin Wu, Xunying Liu, Dan Su, Dong Yu, Helen Meng",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.06186"" target=""_blank"">2006.06186</a>",,2025-12-03 22:39:25
Protecting Against Image Translation Deepfakes by Leaking Universal Perturbations from Black-Box Neural Networks,"Nataniel Ruiz, Sarah Adel Bargal, Stan Sclaroff",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.06493"" target=""_blank"">2006.06493</a>",,2025-12-03 22:39:25
Smoothed Geometry for Robust Attribution,"Zifan Wang, Haofan Wang, Shakul Ramkumar, Matt Fredrikson, Piotr Mardziel, Anupam Datta",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.06643"" target=""_blank"">2006.06643</a>",,2025-12-03 22:39:25
Targeted Adversarial Perturbations for Monocular Depth Prediction,"Alex Wong, Safa Cicek, Stefano Soatto",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.08602"" target=""_blank"">2006.08602</a>",,2025-12-03 22:39:25
D-square-B: Deep Distribution Bound for Natural-looking Adversarial Attack,"Qiuling Xu, Guanhong Tao, Xiangyu Zhang",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.07258"" target=""_blank"">2006.07258</a>",,2025-12-03 22:39:25
Defending against GAN-based Deepfake Attacks via Transformation-aware Adversarial Faces,"Chaofei Yang, Lei Ding, Yiran Chen, Hai Li",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.07421"" target=""_blank"">2006.07421</a>",,2025-12-03 22:39:25
Provably Robust Metric Learning,"Lu Wang, Xuanqing Liu, Jinfeng Yi, Yuan Jiang, Cho-Jui Hsieh",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.07024"" target=""_blank"">2006.07024</a>","<a href=""https://github.com/wangwllu/provably_robust_metric_learning"" target=""_blank"">wangwllu</a>",2025-12-03 22:39:25
Defensive Approximation: Securing CNNs using Approximate Computing,"Amira Guesmi, Ihsen Alouani, Khaled Khasawneh, Mouna Baklouti, Tarek Frikha, Mohamed Abid, Nael Abu-Ghazaleh",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.07700"" target=""_blank"">2006.07700</a>",,2025-12-03 22:39:25
Rethinking Clustering for Robustness,"Motasem Alfarra, Juan C. Pérez, Adel Bibi, Ali Thabet, Pablo Arbeláez, Bernard Ghanem",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.07682"" target=""_blank"">2006.07682</a>",,2025-12-03 22:39:25
The Pitfalls of Simplicity Bias in Neural Networks,"Harshay Shah, Kaustav Tamuly, Aditi Raghunathan, Prateek Jain, Praneeth Netrapalli",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.07710"" target=""_blank"">2006.07710</a>",,2025-12-03 22:39:25
Duplicity Games for Deception Design with an Application to Insider Threat Mitigation,"Linan Huang, Quanyan Zhu",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.07942"" target=""_blank"">2006.07942</a>",,2025-12-03 22:39:25
Adversarial Self-Supervised Contrastive Learning,"Minseon Kim, Jihoon Tack, Sung Ju Hwang",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.07589"" target=""_blank"">2006.07589</a>",,2025-12-03 22:39:25
Adversarial Attacks and Detection on Reinforcement Learning-Based Interactive Recommender Systems,"Yuanjiang Cao, Xiaocong Chen, Lina Yao, Xianzhi Wang, Wei Emma Zhang",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.07934"" target=""_blank"">2006.07934</a>",,2025-12-03 22:39:25
Distributional Robustness with IPMs and links to Regularization and GANs,Hisham Husain,arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.04349"" target=""_blank"">2006.04349</a>",,2025-12-03 22:39:25
Pick-Object-Attack: Type-Specific Adversarial Attack for Object Detection,"Omid Mohamad Nezami, Akshay Chaturvedi, Mark Dras, Utpal Garain",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.03184"" target=""_blank"">2006.03184</a>",,2025-12-03 22:39:25
Adversarial Robustness of Deep Convolutional Candlestick Learner,"Jun-Hao Chen, Samuel Yen-Chi Chen, Yun-Cheng Tsai, Chih-Shiang Shur",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.03686"" target=""_blank"">2006.03686</a>",,2025-12-03 22:39:25
Exploring Model Robustness with Adaptive Networks and Improved Adversarial Training,"Zheng Xu, Ali Shafahi, Tom Goldstein",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.00387"" target=""_blank"">2006.00387</a>",,2025-12-03 22:39:25
Estimating Principal Components under Adversarial Perturbations,"Pranjal Awasthi, Xue Chen, Aravindan Vijayaraghavan",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.00602"" target=""_blank"">2006.00602</a>",,2025-12-03 22:39:25
Evaluations and Methods for Explanation through Robustness Analysis,"Cheng-Yu Hsieh, Chih-Kuan Yeh, Xuanqing Liu, Pradeep Ravikumar, Seungyeon Kim, Sanjiv Kumar, Cho-Jui Hsieh",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.00442"" target=""_blank"">2006.00442</a>",,2025-12-03 22:39:25
Rethinking Empirical Evaluation of Adversarial Robustness Using First-Order Attack Methods,"Kyungmi Lee, Anantha P. Chandrakasan",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.01304"" target=""_blank"">2006.01304</a>",,2025-12-03 22:39:25
Adversarial Attacks on Classifiers for Eye-based User Modelling,"Inken CISPA Helmholtz Center for Information Security Hagestedt, Michael CISPA Helmholtz Center for Information Security Backes, Andreas University of Stuttgart Bulling",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.00860"" target=""_blank"">2006.00860</a>",,2025-12-03 22:39:25
Adversarial Attacks on Reinforcement Learning based Energy Management Systems of Extended Range Electric Delivery Vehicles,"Pengyue Wang, Yan Li, Shashi Shekhar, William F. Northrop",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.00817"" target=""_blank"">2006.00817</a>",,2025-12-03 22:39:25
Second-Order Provable Defenses against Adversarial Attacks,"Sahil Singla, Soheil Feizi",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.00731"" target=""_blank"">2006.00731</a>",,2025-12-03 22:39:25
Detecting Audio Attacks on ASR Systems with Dropout Uncertainty,"Tejas Jayashankar, Jonathan Le Roux, Pierre Moulin",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.01906"" target=""_blank"">2006.01906</a>",,2025-12-03 22:39:25
Adversarial Item Promotion: Vulnerabilities at the Core of Top-N Recommenders that Use Images to Address Cold Start,"Zhuoran Liu, Martha Larson",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.01888"" target=""_blank"">2006.01888</a>",,2025-12-03 22:39:25
Perturbation Analysis of Gradient-based Adversarial Attacks,"Utku Ozbulak, Manvel Gasparyan, Neve Wesley De, Messem Arnout Van",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.01456"" target=""_blank"">2006.01456</a>",,2025-12-03 22:39:25
Exploring the role of Input and Output Layers of a Deep Neural Network in Adversarial Defense,"Jay N. Paranjape, Rahul Kumar Dubey, Vijendran V Gopalan",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.01408"" target=""_blank"">2006.01408</a>",,2025-12-03 22:39:25
SaliencyMix: A Saliency Guided Data Augmentation Strategy for Better Regularization,"A. F. M. Shahab Uddin, Mst. Sirazam Monira, Wheemyung Shin, TaeChoong Chung, Sung-Ho Bae",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.01791"" target=""_blank"">2006.01791</a>",,2025-12-03 22:39:25
Defense for Black-box Attacks on Anti-spoofing Models by Self-Supervised Learning,"Haibin Wu, Andy T. Liu, Hung-yi Lee",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.03214"" target=""_blank"">2006.03214</a>",,2025-12-03 22:39:25
On Universalized Adversarial and Invariant Perturbations,"Sandesh Kamath, Amit Deshpande, K V Subrahmanyam",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.04449"" target=""_blank"">2006.04449</a>",,2025-12-03 22:39:25
Towards Understanding Fast Adversarial Training,"Bai Li, Shiqi Wang, Suman Jana, Lawrence Carin",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.03089"" target=""_blank"">2006.03089</a>",,2025-12-03 22:39:25
Characterizing the Weight Space for Different Learning Models,"Saurav Musunuru, Jay N. Paranjape, Rahul Kumar Dubey, Vijendran G. Venkoparao",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.02724"" target=""_blank"">2006.02724</a>",,2025-12-03 22:39:25
Sponge Examples: Energy-Latency Attacks on Neural Networks,"Ilia Shumailov, Yiren Zhao, Daniel Bates, Nicolas Papernot, Robert Mullins, Ross Anderson",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.03463"" target=""_blank"">2006.03463</a>",,2025-12-03 22:39:25
Lipschitz Bounds and Provably Robust Training by Laplacian Smoothing,"Vishaal Krishnan, Abed AlRahman Al Makdah, Fabio Pasqualetti",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.03712"" target=""_blank"">2006.03712</a>",,2025-12-03 22:39:25
Adversarial Image Generation and Training for Deep Convolutional Neural Networks,"Ronghua Shi, Hai Shu, Hongtu Zhu, Ziqi Chen",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.03243"" target=""_blank"">2006.03243</a>",,2025-12-03 22:39:25
Can Domain Knowledge Alleviate Adversarial Attacks in Multi-Label Classifiers?,"Stefano Melacci, Gabriele Ciravegna, Angelo Sotgiu, Ambra Demontis, Battista Biggio, Marco Gori, Fabio Roli",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.03833"" target=""_blank"">2006.03833</a>",,2025-12-03 22:39:25
Unique properties of adversarially trained linear classifiers on Gaussian data,Jamie Hayes,arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.03873"" target=""_blank"">2006.03873</a>",,2025-12-03 22:39:25
Uncertainty-Aware Deep Classifiers using Generative Models,"Murat Sensoy, Lance Kaplan, Federico Cerutti, Maryam Saleki",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.04183"" target=""_blank"">2006.04183</a>",,2025-12-03 22:39:25
Extensions and limitations of randomized smoothing for robustness guarantees,Jamie Hayes,arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.04208"" target=""_blank"">2006.04208</a>",,2025-12-03 22:39:25
Adversarial Feature Desensitization,"Pouya Bashivan, Reza Bayat, Adam Ibrahim, Kartik Ahuja, Mojtaba Faramarzi, Touraj Laleh, Blake Aaron Richards, Irina Rish",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.04621"" target=""_blank"">2006.04621</a>",,2025-12-03 22:39:25
Trade-offs between membership privacy & adversarially robust learning,Jamie Hayes,arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.04622"" target=""_blank"">2006.04622</a>",,2025-12-03 22:39:25
Global Robustness Verification Networks,"Weidi Sun, Yuteng Lu, Xiyue Zhang, Zhanxing Zhu, Meng Sun",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.04403"" target=""_blank"">2006.04403</a>",,2025-12-03 22:39:25
Tricking Adversarial Attacks To Fail,Blerta Lindqvist,arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.04504"" target=""_blank"">2006.04504</a>",,2025-12-03 22:39:25
Sparsity Turns Adversarial: Energy and Latency Attacks on Deep Neural Networks,"Sarada Krithivasan, Sanchari Sen, Anand Raghunathan",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.08020"" target=""_blank"">2006.08020</a>",,2025-12-03 22:39:25
Stochastic Shortest Path with Adversarially Changing Costs,"Aviv Rosenberg, Yishay Mansour",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.11561"" target=""_blank"">2006.11561</a>",,2025-12-03 22:39:25
On the transferability of adversarial examples between convex and 01 loss models,"Yunzhe Xue, Meiyan Xie, Usman Roshan",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.07800"" target=""_blank"">2006.07800</a>",,2025-12-03 22:39:25
Local Convolutions Cause an Implicit Bias towards High Frequency Adversarial Examples,"Josue Ortega Caro, Yilong Ju, Ryan Pyle, Sourav Dey, Wieland Brendel, Fabio Anselmi, Ankit Patel",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.11440"" target=""_blank"">2006.11440</a>",,2025-12-03 22:39:25
How do SGD hyperparameters in natural training affect adversarial robustness?,"Sandesh Kamath, Amit Deshpande, K V Subrahmanyam",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.11604"" target=""_blank"">2006.11604</a>",,2025-12-03 22:39:25
Network Moments: Extensions and Sparse-Smooth Attacks,"Modar Alfadly, Adel Bibi, Emilio Botero, Salman Alsubaihi, Bernard Ghanem",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.11776"" target=""_blank"">2006.11776</a>",,2025-12-03 22:39:25
Perceptual Adversarial Robustness: Defense Against Unseen Threat Models,"Cassidy Laidlaw, Sahil Singla, Soheil Feizi",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.12655"" target=""_blank"">2006.12655</a>",,2025-12-03 22:39:25
Learning to Generate Noise for Multi-Attack Robustness,"Divyam Madaan, Jinwoo Shin, Sung Ju Hwang",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.12135"" target=""_blank"">2006.12135</a>",,2025-12-03 22:39:25
Adversarial Robustness of Deep Sensor Fusion Models,"Shaojie Wang, Tong Wu, Ayan Chakrabarti, Yevgeniy Vorobeychik",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.13192"" target=""_blank"">2006.13192</a>",,2025-12-03 22:39:25
Sparse-RS: a versatile framework for query-efficient sparse black-box adversarial attacks,"Francesco Croce, Maksym Andriushchenko, Naman D. Singh, Nicolas Flammarion, Matthias Hein",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.12834"" target=""_blank"">2006.12834</a>","<a href=""https://github.com/fra31/sparse-rs"" target=""_blank"">fra31</a>",2025-12-03 22:39:25
RayS: A Ray Searching Method for Hard-label Adversarial Attack,"Jinghui Chen, Quanquan Gu",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.12792"" target=""_blank"">2006.12792</a>",,2025-12-03 22:39:25
Imbalanced Gradients: A Subtle Cause of Overestimated Adversarial Robustness,"Xingjun Ma, Linxi Jiang, Hanxun Huang, Zejia Weng, James Bailey, Yu-Gang Jiang",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.13726"" target=""_blank"">2006.13726</a>","<a href=""https://github.com/HanxunH/MDAttack"" target=""_blank"">HanxunH</a>",2025-12-03 22:39:25
Blacklight: Defending Black-Box Adversarial Attacks on Deep Neural Networks,"Huiying Li, Shawn Shan, Emily Wenger, Jiayun Zhang, Haitao Zheng, Ben Y. Zhao",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.14042"" target=""_blank"">2006.14042</a>",,2025-12-03 22:39:25
Compositional Explanations of Neurons,"Jesse Mu, Jacob Andreas",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.14032"" target=""_blank"">2006.14032</a>",,2025-12-03 22:39:25
"Defending against adversarial attacks on medical imaging AI system, classification or detection?","Xin Li, Deng Pan, Dongxiao Zhu",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.13555"" target=""_blank"">2006.13555</a>",,2025-12-03 22:39:25
Can 3D Adversarial Logos Cloak Humans?,"Yi Wang, Jingyang Zhou, Tianlong Chen, Sijia Liu, Shiyu Chang, Chandrajit Bajaj, Zhangyang Wang",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.14655"" target=""_blank"">2006.14655</a>","<a href=""https://github.com/TAMU-VITA/3D_Adversarial_Logo"" target=""_blank"">TAMU-VITA</a>",2025-12-03 22:39:25
Uncovering the Connections Between Adversarial Transferability and Knowledge Transferability,"Kaizhao Liang, Jacky Y. Zhang, Boxin Wang, Zhuolin Yang, Oluwasanmi Koyejo, Bo Li",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.14512"" target=""_blank"">2006.14512</a>",,2025-12-03 22:39:25
Proper Network Interpretability Helps Adversarial Robustness in Classification,"Akhilan Boopathy, Sijia Liu, Gaoyuan Zhang, Cynthia Liu, Pin-Yu Chen, Shiyu Chang, Luca Daniel",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.14748"" target=""_blank"">2006.14748</a>",,2025-12-03 22:39:25
Smooth Adversarial Training,"Cihang Xie, Mingxing Tan, Boqing Gong, Alan Yuille, Quoc V. Le",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.14536"" target=""_blank"">2006.14536</a>","<a href=""https://github.com/cihangxie/SmoothAdversarialTraining"" target=""_blank"">cihangxie</a>",2025-12-03 22:39:25
Can We Mitigate Backdoor Attack Using Adversarial Detection Methods?,"Kaidi Jin, Tianwei Zhang, Chao Shen, Yufei Chen, Ming Fan, Chenhao Lin, Ting Liu",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.14871"" target=""_blank"">2006.14871</a>",,2025-12-03 22:39:25
Diverse Knowledge Distillation (DKD): A Solution for Improving The Robustness of Ensemble Models Against Adversarial Attacks,"Ali Mirzaeian, Jana Kosecka, Houman Homayoun, Tinoosh Mohsenin, Avesta Sasan",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.15127"" target=""_blank"">2006.15127</a>",,2025-12-03 22:39:25
Orthogonal Deep Models As Defense Against Black-Box Attacks,"Mohammad A. A. K. Jalwana, Naveed Akhtar, Mohammed Bennamoun, Ajmal Mian",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.14856"" target=""_blank"">2006.14856</a>",,2025-12-03 22:39:25
Geometry-Inspired Top-k Adversarial Perturbations,"Nurislam Tursynbek, Aleksandr Petiushko, Ivan Oseledets",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.15669"" target=""_blank"">2006.15669</a>",,2025-12-03 22:39:25
FDA3 : Federated Defense Against Adversarial Attacks for Cloud-Based IIoT Applications,"Yunfei Song, Tian Liu, Tongquan Wei, Xiangfeng Wang, Zhe Tao, Mingsong Chen",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.15632"" target=""_blank"">2006.15632</a>",,2025-12-03 22:39:25
Improving Uncertainty Estimates through the Relationship with Adversarial Robustness,"Yao Qin, Xuezhi Wang, Alex Beutel, Ed H. Chi",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.16375"" target=""_blank"">2006.16375</a>",,2025-12-03 22:39:25
Biologically Inspired Mechanisms for Adversarial Robustness,"Manish V. Reddy, Andrzej Banburski, Nishka Pant, Tomaso Poggio",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.16427"" target=""_blank"">2006.16427</a>",,2025-12-03 22:39:25
Legal Risks of Adversarial Machine Learning Research,"Ram Shankar Siva Kumar, Jonathon Penney, Bruce Schneier, Kendra Albert",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.16179"" target=""_blank"">2006.16179</a>",,2025-12-03 22:39:25
Sharp Statistical Guarantees for Adversarially Robust Gaussian Classification,"Chen Dan, Yuting Wei, Pradeep Ravikumar",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.16384"" target=""_blank"">2006.16384</a>",,2025-12-03 22:39:25
Harnessing Adversarial Distances to Discover High-Confidence Errors,"Walter Bennette, Karsten Maurer, Sean Sisti",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.16055"" target=""_blank"">2006.16055</a>",,2025-12-03 22:39:25
Black-box Certification and Learning under Adversarial Perturbations,"Hassan Ashtiani, Vinayak Pathak, Ruth Urner",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.16520"" target=""_blank"">2006.16520</a>",,2025-12-03 22:39:25
Adversarial Deep Ensemble: Evasion Attacks and Defenses for Malware Detection,"Deqiang Li, Qianmu Li",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.16545"" target=""_blank"">2006.16545</a>",,2025-12-03 22:39:25
On Saliency Maps and Adversarial Robustness,"Puneet Mangla, Vedant Singh, Vineeth N Balasubramanian",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.07828"" target=""_blank"">2006.07828</a>",,2025-12-03 22:39:25
Towards Robust LiDAR-based Perception in Autonomous Driving: General Black-box Adversarial Sensor Attack and Countermeasures,"Jiachen Sun, Yulong Cao, Qi Alfred Chen, Z. Morley Mao",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.16974"" target=""_blank"">2006.16974</a>",,2025-12-03 22:39:25
Defense against Adversarial Attacks in NLP via Dirichlet Neighborhood Ensemble,"Yi Zhou, Xiaoqing Zheng, Cho-Jui Hsieh, Kai-wei Chang, Xuanjing Huang",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.11627"" target=""_blank"">2006.11627</a>",,2025-12-03 22:39:25
Informative Outlier Matters: Robustifying Out-of-distribution Detection Using Outlier Mining,"Jiefeng Chen, Yixuan Li, Xi Wu, Yingyu Liang, Somesh Jha",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.15207"" target=""_blank"">2006.15207</a>",,2025-12-03 22:39:25
A general framework for defining and optimizing robustness,"Alessandro Tibo, Manfred Jaeger, Kim G. Larsen",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.11122"" target=""_blank"">2006.11122</a>",,2025-12-03 22:39:25
SPLASH: Learnable Activation Functions for Improving Accuracy and Adversarial Robustness,"Mohammadamin Tavakoli, Forest Agostinelli, Pierre Baldi",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.08947"" target=""_blank"">2006.08947</a>",,2025-12-03 22:39:25
Analyzing the Real-World Applicability of DGA Classifiers,"Arthur Drichel, Ulrike Meyer, Samuel Schüppen, Dominik Teubert",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.11103"" target=""_blank"">2006.11103</a>",,2025-12-03 22:39:25
PatchUp: A Regularization Technique for Convolutional Neural Networks,"Mojtaba Faramarzi, Mohammad Amini, Akilesh Badrinaaraayanan, Vikas Verma, Sarath Chandar",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.07794"" target=""_blank"">2006.07794</a>",,2025-12-03 22:39:25
GradAug: A New Regularization Method for Deep Neural Networks,"Taojiannan Yang, Sijie Zhu, Chen Chen",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.07989"" target=""_blank"">2006.07989</a>",,2025-12-03 22:39:25
Multiscale Deep Equilibrium Models,"Shaojie Bai, Vladlen Koltun, J. Zico Kolter",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.08656"" target=""_blank"">2006.08656</a>","<a href=""https://github.com/locuslab/mdeq"" target=""_blank"">locuslab</a>",2025-12-03 22:39:25
CG-ATTACK: Modeling the Conditional Distribution of Adversarial Perturbations to Boost Black-Box Attack,"Yan Feng, Baoyuan Wu, Yanbo Fan, Li Liu, Zhifeng Li, Shutao Xia",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.08538"" target=""_blank"">2006.08538</a>",,2025-12-03 22:39:25
GNNGuard: Defending Graph Neural Networks against Adversarial Attacks,"Xiang Zhang, Marinka Zitnik",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.08149"" target=""_blank"">2006.08149</a>",,2025-12-03 22:39:25
Fast & Accurate Method for Bounding the Singular Values of Convolutional Layers with Application to Lipschitz Regularization,"Alexandre Araujo, Benjamin Negrevergne, Yann Chevaleyre, Jamal Atif",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.08391"" target=""_blank"">2006.08391</a>",,2025-12-03 22:39:25
DefenseVGAE: Defending against Adversarial Attacks on Graph Data via a Variational Graph Autoencoder,"Ao Zhang, Jinwen Ma",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.08900"" target=""_blank"">2006.08900</a>","<a href=""https://github.com/zhangao520/defense-vgae"" target=""_blank"">zhangao520</a>",2025-12-03 22:39:25
Total Deep Variation: A Stable Regularizer for Inverse Problems,"Erich Kobler, Alexander Effland, Karl Kunisch, Thomas Pock",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.08789"" target=""_blank"">2006.08789</a>",,2025-12-03 22:39:25
The shape and simplicity biases of adversarially robust ImageNet-trained CNNs,"Peijie Chen, Chirag Agarwal, Anh Nguyen",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.09373"" target=""_blank"">2006.09373</a>",,2025-12-03 22:39:25
AdvMind: Inferring Adversary Intent of Black-Box Attacks,"Ren Pang, Xinyang Zhang, Shouling Ji, Xiapu Luo, Ting Wang",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.09539"" target=""_blank"">2006.09539</a>",,2025-12-03 22:39:25
"On sparse connectivity, adversarial robustness, and a novel model of the artificial neuron",Sergey Bochkanov,arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.09510"" target=""_blank"">2006.09510</a>",,2025-12-03 22:39:25
Debona: Decoupled Boundary Network Analysis for Tighter Bounds and Faster Adversarial Robustness Proofs,"Christopher Brix, Thomas Noll",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.09040"" target=""_blank"">2006.09040</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness via Unlabeled Out-of-Domain Data,"Zhun Deng, Linjun Zhang, Amirata Ghorbani, James Zou",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.08476"" target=""_blank"">2006.08476</a>",,2025-12-03 22:39:25
Calibrating Deep Neural Network Classifiers on Out-of-Distribution Datasets,"Zhihui Shao, Jianyi Yang, Shaolei Ren",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.08914"" target=""_blank"">2006.08914</a>",,2025-12-03 22:39:25
Beware the Black-Box: on the Robustness of Recent Defenses to Adversarial Examples,"Kaleel Mahmood, Deniz Gurevin, Dijk Marten van, Phuong Ha Nguyen",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.10876"" target=""_blank"">2006.10876</a>",,2025-12-03 22:39:25
Towards an Adversarially Robust Normalization Approach,"Muhammad Awais, Fahad Shamshad, Sung-Ho Bae",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.11007"" target=""_blank"">2006.11007</a>","<a href=""https://github.com/awaisrauf/RobustNorm"" target=""_blank"">awaisrauf</a>",2025-12-03 22:39:25
Differentiable Language Model Adversarial Attacks on Categorical Sequence Classifiers,"I. Fursov, A. Zaytsev, N. Kluchnikov, A. Kravchenko, E. Burnaev",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.11078"" target=""_blank"">2006.11078</a>",,2025-12-03 22:39:25
Fairness Through Robustness: Investigating Robustness Disparity in Deep Learning,"Vedant Nanda, Samuel Dooley, Sahil Singla, Soheil Feizi, John P. Dickerson",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.12621"" target=""_blank"">2006.12621</a>","<a href=""https://github.com/nvedant07/Fairness-Through-Robustness"" target=""_blank"">nvedant07</a>",2025-12-03 22:39:25
Adversarial Attacks for Multi-view Deep Models,"Xuli Sun, Shiliang Sun",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.11004"" target=""_blank"">2006.11004</a>",,2025-12-03 22:39:25
Local Competition and Uncertainty for Adversarial Robustness in Deep Learning,"Antonios Alexos, Konstantinos P. Panousis, Sotirios Chatzis",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.10620"" target=""_blank"">2006.10620</a>",,2025-12-03 22:39:25
The Dilemma Between Dimensionality Reduction and Adversarial Robustness,"Sheila Alemany, Niki Pissinou",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.10885"" target=""_blank"">2006.10885</a>",,2025-12-03 22:39:25
Dissecting Deep Networks into an Ensemble of Generative Classifiers for Robust Predictions,"Lokender Tiwari, Anish Madan, Saket Anand, Subhashis Banerjee",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.10679"" target=""_blank"">2006.10679</a>",,2025-12-03 22:39:25
Noise or Signal: The Role of Image Backgrounds in Object Recognition,"Kai Xiao, Logan Engstrom, Andrew Ilyas, Aleksander Madry",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.09994"" target=""_blank"">2006.09994</a>",,2025-12-03 22:39:25
Adversarial Examples Detection and Analysis with Layer-wise Autoencoders,"Bartosz Wójcik, Paweł Morawiecki, Marek Śmieja, Tomasz Krzyżek, Przemysław Spurek, Jacek Tabor",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.10013"" target=""_blank"">2006.10013</a>",,2025-12-03 22:39:25
Adversarial Defense by Latent Style Transformations,"Shuo Wang, Surya Nepal, Alsharif Abuadbba, Carsten Rudolph, Marthie Grobler",arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.09701"" target=""_blank"">2006.09701</a>",,2025-12-03 22:39:25
Disrupting Deepfakes with an Adversarial Attack that Survives Training,Eran Segalis,arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.12247"" target=""_blank"">2006.12247</a>",,2025-12-03 22:39:25
Universal Lower-Bounds on Classification Error under Adversarial Attacks and Random Corruption,Elvis Dohmatob,arXiv,2020-06,"<a href=""http://arxiv.org/abs/2006.09989"" target=""_blank"">2006.09989</a>",,2025-12-03 22:39:25
Efficient Exact Verification of Binarized Neural Networks,"Kai Jia, Martin Rinard",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.03597"" target=""_blank"">2005.03597</a>",,2025-12-03 22:39:25
Adversarial examples are useful too!,Ali Borji,arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.06107"" target=""_blank"">2005.06107</a>",,2025-12-03 22:39:25
Towards Robustness against Unsuspicious Adversarial Examples,"Liang Tong, Minzhe Guo, Atul Prakash, Yevgeniy Vorobeychik",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.04272"" target=""_blank"">2005.04272</a>",,2025-12-03 22:39:25
Class-Aware Domain Adaptation for Improving Adversarial Robustness,"Xianxu Hou, Jingxin Liu, Bolei Xu, Xiaolong Wang, Bozhi Liu, Guoping Qiu",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.04564"" target=""_blank"">2005.04564</a>",,2025-12-03 22:39:25
Projection & Probability-Driven Black-Box Attack,"Jie Li, Rongrong Ji, Hong Liu, Jianzhuang Liu, Bineng Zhong, Cheng Deng, Qi Tian",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.03837"" target=""_blank"">2005.03837</a>",,2025-12-03 22:39:25
It's Morphin' Time! Combating Linguistic Discrimination with Inflectional Perturbations,"Samson Tan, Shafiq Joty, Min-Yen Kan, Richard Socher",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.04364"" target=""_blank"">2005.04364</a>",,2025-12-03 22:39:25
Spanning Attack: Reinforce Black-box Attacks with Unlabeled Data,"Lu Wang, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh, Yuan Jiang",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.04871"" target=""_blank"">2005.04871</a>","<a href=""https://github.com/wangwllu/spanning_attack"" target=""_blank"">wangwllu</a>",2025-12-03 22:39:25
Channel-Aware Adversarial Attacks Against Deep Learning-Based Wireless Signal Classifiers,"Brian Kim, Yalin E. Sagduyu, Kemal Davaslioglu, Tugba Erpek, Sennur Ulukus",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.05321"" target=""_blank"">2005.05321</a>",,2025-12-03 22:39:25
Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients,"Chengcheng Ma, Baoyuan Wu, Shibiao Xu, Yanbo Fan, Yong Zhang, Xiaopeng Zhang, Zhifeng Li",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.05552"" target=""_blank"">2005.05552</a>",,2025-12-03 22:39:25
Towards Assessment of Randomized Mechanisms for Certifying Adversarial Robustness,"Tianhang Zheng, Di Wang, Baochun Li, Jinhui Xu",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.07347"" target=""_blank"">2005.07347</a>",,2025-12-03 22:39:25
Increased-confidence adversarial examples for improved transferability of Counter-Forensic attacks,"Wenjie Li, Benedetta Tondi, Rongrong Ni, Mauro Barni",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.06023"" target=""_blank"">2005.06023</a>",,2025-12-03 22:39:25
Evaluating Ensemble Robustness Against Adversarial Attacks,"George Adam, Romain Speciel",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.05750"" target=""_blank"">2005.05750</a>",,2025-12-03 22:39:25
DeepRobust: A PyTorch Library for Adversarial Attacks and Defenses,"Yaxin Li, Wei Jin, Han Xu, Jiliang Tang",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.06149"" target=""_blank"">2005.06149</a>","<a href=""https://github.com/DSE-MSU/DeepRobust"" target=""_blank"">DSE-MSU</a>",2025-12-03 22:39:25
A Deep Learning-based Fine-grained Hierarchical Learning Approach for Robust Malware Classification,"Ahmed Abusnaina, Mohammed Abuhamad, Hisham Alasmary, Afsah Anwar, Rhongho Jang, Saeed Salem, DaeHun Nyang, David Mohaisen",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.07145"" target=""_blank"">2005.07145</a>",,2025-12-03 22:39:25
Stealthy and Efficient Adversarial Attacks against Deep Reinforcement Learning,"Jianwen Sun, Tianwei Zhang, Xiaofei Xie, Lei Ma, Yan Zheng, Kangjie Chen, Yang Liu",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.07099"" target=""_blank"">2005.07099</a>",,2025-12-03 22:39:25
Initializing Perturbations in Multiple Directions for Fast Adversarial Training,"Xunguang Wang, Ship Peng Xu, Eric Ke Wang",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.07606"" target=""_blank"">2005.07606</a>",,2025-12-03 22:39:25
GraCIAS: Grassmannian of Corrupted Images for Adversarial Security,"Ankita Shukla, Pavan Turaga, Saket Anand",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.02936"" target=""_blank"">2005.02936</a>",,2025-12-03 22:39:25
Practical Traffic-space Adversarial Attacks on Learning-based NIDSs,"Dongqi Han, Zhiliang Wang, Ying Zhong, Wenqi Chen, Jiahai Yang, Shuqiang Lu, Xingang Shi, Xia Yin",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.07519"" target=""_blank"">2005.07519</a>",,2025-12-03 22:39:25
Defending Hardware-based Malware Detectors against Adversarial Attacks,"Abraham Peedikayil Kuruvila, Shamik Kundu, Kanad Basu",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.03644"" target=""_blank"">2005.03644</a>",,2025-12-03 22:39:25
Universal Adversarial Attacks with Natural Triggers for Text Classification,"Liwei Song, Xinwei Yu, Hsuan-Tung Peng, Karthik Narasimhan",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.00174"" target=""_blank"">2005.00174</a>",,2025-12-03 22:39:25
Training robust neural networks using Lipschitz bounds,"Patricia Pauli, Anne Koch, Julian Berberich, Paul Kohler, Frank Allgöwer",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.02929"" target=""_blank"">2005.02929</a>",,2025-12-03 22:39:25
Birds have four legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models,"Bill Yuchen Lin, Seyeon Lee, Rahul Khanna, Xiang Ren",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.00683"" target=""_blank"">2005.00683</a>",,2025-12-03 22:39:25
PatchGuard: Provable Defense against Adversarial Patches Using Masks on Small Receptive Fields,"Chong Xiang, Arjun Nitin Bhagoji, Vikash Sehwag, Prateek Mittal",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.10884"" target=""_blank"">2005.10884</a>",,2025-12-03 22:39:25
Printing and Scanning Attack for Image Counter Forensics,"Hailey James, Otkrist Gupta, Dan Raviv",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.02160"" target=""_blank"">2005.02160</a>",,2025-12-03 22:39:25
"TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP","John X. Morris, Eli Lifland, Jin Yong Yoo, Jake Grigsby, Di Jin, Yanjun Qi",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.05909"" target=""_blank"">2005.05909</a>","<a href=""https://github.com/QData/TextAttack"" target=""_blank"">QData</a>",2025-12-03 22:39:25
Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,"Pu Zhao, Pin-Yu Chen, Payel Das, Karthikeyan Natesan Ramamurthy, Xue Lin",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.00060"" target=""_blank"">2005.00060</a>",,2025-12-03 22:39:25
Evaluating Neural Machine Comprehension Model Robustness to Noisy Inputs and Adversarial Attacks,"Winston Wu, Dustin Arendt, Svitlana Volkova",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.00190"" target=""_blank"">2005.00190</a>",,2025-12-03 22:39:25
Defense of Word-level Adversarial Attacks via Random Substitution Encoding,"Zhaoyang Wang, Hongtao Wang",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.00446"" target=""_blank"">2005.00446</a>",,2025-12-03 22:39:25
Robust Deep Learning as Optimal Control: Insights and Convergence Guarantees,"Jacob H. Seidman, Mahyar Fazlyab, Victor M. Preciado, George J. Pappas",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.00616"" target=""_blank"">2005.00616</a>",,2025-12-03 22:39:25
"Jacks of All Trades, Masters Of None: Addressing Distributional Shift and Obtrusiveness via Transparent Patch Attacks","Neil Fendley, Max Lennon, I-Jeng Wang, Philippe Burlina, Nathan Drenkow",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.00656"" target=""_blank"">2005.00656</a>",,2025-12-03 22:39:25
Enhancing Intrinsic Adversarial Robustness via Feature Pyramid Decoder,"Guanlin Li, Shuya Ding, Jun Luo, Chang Liu",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.02552"" target=""_blank"">2005.02552</a>",,2025-12-03 22:39:25
On the Generalization Effects of Linear Transformations in Data Augmentation,"Sen Wu, Hongyang R. Zhang, Gregory Valiant, Christopher Ré",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.00695"" target=""_blank"">2005.00695</a>",,2025-12-03 22:39:25
Robust Encodings: A Framework for Combating Adversarial Typos,"Erik Jones, Robin Jia, Aditi Raghunathan, Percy Liang",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.01229"" target=""_blank"">2005.01229</a>",,2025-12-03 22:39:25
Do Gradient-based Explanations Tell Anything About Adversarial Robustness to Android Malware?,"Marco Melis, Michele Scalas, Ambra Demontis, Davide Maiorca, Battista Biggio, Giorgio Giacinto, Fabio Roli",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.01452"" target=""_blank"">2005.01452</a>",,2025-12-03 22:39:25
On the Benefits of Models with Perceptually-Aligned Gradients,"Gunjan Aggarwal, Abhishek Sinha, Nupur Kumari, Mayank Singh",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.01499"" target=""_blank"">2005.01499</a>",,2025-12-03 22:39:25
Measuring Adversarial Robustness using a Voronoi-Epsilon Adversary,"Hyeongji Kim, Pekka Parviainen, Ketil Malde",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.02540"" target=""_blank"">2005.02540</a>",,2025-12-03 22:39:25
Adversarial Training against Location-Optimized Adversarial Patches,"Sukrut Rao, David Stutz, Bernt Schiele",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.02313"" target=""_blank"">2005.02313</a>",,2025-12-03 22:39:25
Hacking the Waveform: Generalized Wireless Adversarial Deep Learning,"Francesco Restuccia, Salvatore D'Oro, Amani Al-Shawabka, Bruno Costa Rendon, Kaushik Chowdhury, Stratis Ioannidis, Tommaso Melodia",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.02270"" target=""_blank"">2005.02270</a>",,2025-12-03 22:39:25
"How to Make 5G Communications ""Invisible"": Adversarial Machine Learning for Wireless Privacy","Brian Kim, Yalin E. Sagduyu, Kemal Davaslioglu, Tugba Erpek, Sennur Ulukus",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.07675"" target=""_blank"">2005.07675</a>",,2025-12-03 22:39:25
Feature Purification: How Adversarial Training Performs Robust Deep Learning,"Zeyuan Allen-Zhu, Yuanzhi Li",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.10190"" target=""_blank"">2005.10190</a>",,2025-12-03 22:39:25
Encryption Inspired Adversarial Defense for Visual Classification,"MaungMaung AprilPyone, Hitoshi Kiya",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.07998"" target=""_blank"">2005.07998</a>",,2025-12-03 22:39:25
Vulnerability of deep neural networks for detecting COVID-19 cases from chest X-ray images to universal adversarial attacks,"Hokuto Hirano, Kazuki Koga, Kazuhiro Takemoto",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.11061"" target=""_blank"">2005.11061</a>",,2025-12-03 22:39:25
Adversarial Attack on Hierarchical Graph Pooling Neural Networks,"Haoteng Tang, Guixiang Ma, Yurong Chen, Lei Guo, Wei Wang, Bo Zeng, Liang Zhan",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.11560"" target=""_blank"">2005.11560</a>",,2025-12-03 22:39:25
ShapeAdv: Generating Shape-Aware Adversarial 3D Point Clouds,"Kibok Lee, Zhuoyuan Chen, Xinchen Yan, Raquel Urtasun, Ersin Yumer",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.11626"" target=""_blank"">2005.11626</a>",,2025-12-03 22:39:25
Adaptive Adversarial Logits Pairing,"Shangxi Wu, Jitao Sang, Kaiyuan Xu, Guanhua Zheng, Changsheng Xu",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.11904"" target=""_blank"">2005.11904</a>",,2025-12-03 22:39:25
SoK: Arms Race in Adversarial Malware Detection,"Deqiang Li, Qianmu Li, Yanfang Ye, Shouhuai Xu",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.11671"" target=""_blank"">2005.11671</a>",,2025-12-03 22:39:25
Detecting Adversarial Examples for Speech Recognition via Uncertainty Quantification,"Sina Däubener, Lea Schönherr, Asja Fischer, Dorothea Kolossa",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.14611"" target=""_blank"">2005.14611</a>",,2025-12-03 22:39:25
Generating Semantically Valid Adversarial Questions for TableQA,"Yi Zhu, Menglin Xia, Yiwei Zhou",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.12696"" target=""_blank"">2005.12696</a>",,2025-12-03 22:39:25
Investigating a Spectral Deception Loss Metric for Training Machine Learning-based Evasion Attacks,"Matthew DelVecchio, Vanessa Arndorfer, William C. Headley",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.13124"" target=""_blank"">2005.13124</a>",,2025-12-03 22:39:25
Effects of Forward Error Correction on Communications Aware Evasion Attacks,"Matthew DelVecchio, Bryse Flowers, William C. Headley",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.13123"" target=""_blank"">2005.13123</a>",,2025-12-03 22:39:25
Calibrated Surrogate Losses for Adversarially Robust Classification,"Han Bao, Clayton Scott, Masashi Sugiyama",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.13748"" target=""_blank"">2005.13748</a>",,2025-12-03 22:39:25
Stochastic Security: Adversarial Defense Using Long-Run Dynamics of Energy-Based Models,"Mitch Hill, Jonathan Mitchell, Song-Chun Zhu",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.13525"" target=""_blank"">2005.13525</a>","<a href=""https://github.com/point0bar1/ebm-defense"" target=""_blank"">point0bar1</a>",2025-12-03 22:39:25
Mitigating Advanced Adversarial Attacks with More Advanced Gradient Obfuscation Techniques,"Han Qiu, Yi Zeng, Qinkai Zheng, Tianwei Zhang, Meikang Qiu, Gerard Memmi",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.13712"" target=""_blank"">2005.13712</a>",,2025-12-03 22:39:25
Enhancing Resilience of Deep Learning Networks by Means of Transferable Adversaries,"Moritz Seiler, Heike Trautmann, Pascal Kerschke",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.13293"" target=""_blank"">2005.13293</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defense on Texts: A Survey,"Aminul Huq, Mst. Tasnim Pervin",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.14108"" target=""_blank"">2005.14108</a>",,2025-12-03 22:39:25
Universal Adversarial Perturbations: A Survey,"Ashutosh Chaubey, Nikhil Agrawal, Kavya Barnwal, Keerat K. Guliani, Pramod Mehta",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.08087"" target=""_blank"">2005.08087</a>",,2025-12-03 22:39:25
QEBA: Query-Efficient Boundary-Based Blackbox Attack,"Huichen Li, Xiaojun Xu, Xiaolu Zhang, Shuang Yang, Bo Li",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.14137"" target=""_blank"">2005.14137</a>",,2025-12-03 22:39:25
SAFER: A Structure-free Approach for Certified Robustness to Adversarial Word Substitutions,"Mao Ye, Chengyue Gong, Qiang Liu",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.14424"" target=""_blank"">2005.14424</a>",,2025-12-03 22:39:25
Monocular Depth Estimators: Vulnerabilities and Attacks,"Alwyn Mathew, Aditya Prakash Patra, Jimson Mathew",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.14302"" target=""_blank"">2005.14302</a>",,2025-12-03 22:39:25
Frontal Attack: Leaking Control-Flow in SGX via the CPU Frontend,"Ivan Puddu, Moritz Schneider, Miro Haller, Srdjan Čapkun",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.11516"" target=""_blank"">2005.11516</a>",,2025-12-03 22:39:25
Adversarial Feature Selection against Evasion Attacks,"Fei Zhang, Patrick P. K. Chan, Battista Biggio, Daniel S. Yeung, Fabio Roli",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.12154"" target=""_blank"">2005.12154</a>",,2025-12-03 22:39:25
Revisiting Role of Autoencoders in Adversarial Settings,"Byeong Cheon Kim, Jung Uk Kim, Hakmin Lee, Yong Man Ro",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.10750"" target=""_blank"">2005.10750</a>",,2025-12-03 22:39:25
Synthesizing Unrestricted False Positive Adversarial Objects Using Generative Models,"Martin Kotuliak, Sandro E. Schoenborn, Andrei Dan",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.09294"" target=""_blank"">2005.09294</a>",,2025-12-03 22:39:25
Spatiotemporal Attacks for Embodied Agents,"Aishan Liu, Tairan Huang, Xianglong Liu, Yitao Xu, Yuqing Ma, Xinyun Chen, Stephen J. Maybank, Dacheng Tao",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.09161"" target=""_blank"">2005.09161</a>",,2025-12-03 22:39:25
Increasing-Margin Adversarial (IMA) Training to Improve Adversarial Robustness of Neural Networks,"Linhai Ma, Liang Liang",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.09147"" target=""_blank"">2005.09147</a>",,2025-12-03 22:39:25
Robust Ensemble Model Training via Random Layer Sampling Against Adversarial Attack,"Hakmin Lee, Hong Joo Lee, Seong Tae Kim, Yong Man Ro",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.10757"" target=""_blank"">2005.10757</a>",,2025-12-03 22:39:25
Improve robustness of DNN for ECG signal classification:a noise-to-signal ratio perspective,"Linhai Ma, Liang Liang",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.09134"" target=""_blank"">2005.09134</a>",,2025-12-03 22:39:25
Reliability and Robustness analysis of Machine Learning based Phishing URL Detectors,"Bushra University of Adelaide, CREST - The Centre for Research on Engineering Software Technologies, CSIROs Data61 Sabir, M. Ali University of Adelaide, CREST - The Centre for Research on Engineering Software Technologies Babar, Raj CSIROs Data61 Gaire, Alsharif CSIROs DATA61 Abuadbba",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.08454"" target=""_blank"">2005.08454</a>",,2025-12-03 22:39:25
Defending Your Voice: Adversarial Attack on Voice Conversion,"Chien-yu Huang, Yist Y. Lin, Hung-yi Lee, Lin-shan Lee",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.08781"" target=""_blank"">2005.08781</a>",,2025-12-03 22:39:25
Universalization of any adversarial attack using very few test examples,"Sandesh Kamath, Amit Deshpande, K V Subrahmanyam",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.08632"" target=""_blank"">2005.08632</a>",,2025-12-03 22:39:25
Bias-based Universal Adversarial Patch Attack for Automatic Check-out,"Aishan Liu, Jiakai Wang, Xianglong Liu, Bowen Cao, Chongzhi Zhang, Hang Yu",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.09257"" target=""_blank"">2005.09257</a>",,2025-12-03 22:39:25
On Intrinsic Dataset Properties for Adversarial Machine Learning,"Jeffrey Z. Pan, Nicholas Zufelt",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.09170"" target=""_blank"">2005.09170</a>",,2025-12-03 22:39:25
A survey on Adversarial Recommender Systems: from Attack/Defense strategies to Generative Adversarial Networks,"Yashar Deldjoo, Noia Tommaso Di, Felice Antonio Merra",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.10322"" target=""_blank"">2005.10322</a>",,2025-12-03 22:39:25
An Adversarial Approach for Explaining the Predictions of Deep Neural Networks,"Arash Rahnama, Andrew Tseng",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.10284"" target=""_blank"">2005.10284</a>",,2025-12-03 22:39:25
"Model-Based Robust Deep Learning: Generalizing to Natural, Out-of-Distribution Data","Alexander Robey, Hamed Hassani, George J. Pappas",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.10247"" target=""_blank"">2005.10247</a>",,2025-12-03 22:39:25
Graph Structure Learning for Robust Graph Neural Networks,"Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, Jiliang Tang",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.10203"" target=""_blank"">2005.10203</a>","<a href=""https://github.com/DSE-MSU/DeepRobust"" target=""_blank"">DSE-MSU</a>",2025-12-03 22:39:25
Investigating Vulnerability to Adversarial Examples on Multimodal Data Fusion in Deep Learning,"Youngjoon Yu, Hong Joo Lee, Byeong Cheon Kim, Jung Uk Kim, Yong Man Ro",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.10987"" target=""_blank"">2005.10987</a>",,2025-12-03 22:39:25
Inaudible Adversarial Perturbations for Targeted Attack in Speaker Recognition,"Qing Wang, Pengcheng Guo, Lei Xie",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.10637"" target=""_blank"">2005.10637</a>",,2025-12-03 22:39:25
Toward Adversarial Robustness by Diversity in an Ensemble of Specialized Deep Neural Networks,"Mahdieh Abbasi, Arezoo Rajabi, Christian Gagne, Rakesh B. Bobba",arXiv,2020-05,"<a href=""http://arxiv.org/abs/2005.08321"" target=""_blank"">2005.08321</a>",,2025-12-03 22:39:25
Certified Adversarial Robustness for Deep Reinforcement Learning,"Michael Everett, Bjorn Lutjens, Jonathan P. How",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.06496"" target=""_blank"">2004.06496</a>",,2025-12-03 22:39:25
Adversarial Weight Perturbation Helps Robust Generalization,"Dongxian Wu, Shu-tao Xia, Yisen Wang",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.05884"" target=""_blank"">2004.05884</a>",,2025-12-03 22:39:25
Domain Adaptive Transfer Attack (DATA)-based Segmentation Networks for Building Extraction from Aerial Images,"Younghwan Na, Jun Hee Kim, Kyungsu Lee, Juhum Park, Jae Youn Hwang, Jihwan P. Choi",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.11819"" target=""_blank"">2004.11819</a>",,2025-12-03 22:39:25
Robust Large-Margin Learning in Hyperbolic Space,"Melanie Weber, Manzil Zaheer, Ankit Singh Rawat, Aditya Menon, Sanjiv Kumar",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.05465"" target=""_blank"">2004.05465</a>",,2025-12-03 22:39:25
PatchAttack: A Black-box Texture-based Attack with Reinforcement Learning,"Chenglin Yang, Adam Kortylewski, Cihang Xie, Yinzhi Cao, Alan Yuille",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.05682"" target=""_blank"">2004.05682</a>",,2025-12-03 22:39:25
Towards Transferable Adversarial Attack against Deep Face Recognition,"Yaoyao Zhong, Weihong Deng",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.05790"" target=""_blank"">2004.05790</a>",,2025-12-03 22:39:25
Towards Robust Classification with Image Quality Assessment,"Yeli Feng, Yiyu Cai",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.06288"" target=""_blank"">2004.06288</a>",,2025-12-03 22:39:25
Adversarial Augmentation Policy Search for Domain and Cross-Lingual Generalization in Reading Comprehension,"Adyasha Maharana, Mohit Bansal",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.06076"" target=""_blank"">2004.06076</a>",,2025-12-03 22:39:25
Targeted Attack for Deep Hashing based Retrieval,"Jiawang Bai, Bin Chen, Yiming Li, Dongxian Wu, Weiwei Guo, Shu-tao Xia, En-hui Yang",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.07955"" target=""_blank"">2004.07955</a>",,2025-12-03 22:39:25
Frequency-Guided Word Substitutions for Detecting Textual Adversarial Examples,"Maximilian Mozes, Pontus Stenetorp, Bennett Kleinberg, Lewis D. Griffin",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.05887"" target=""_blank"">2004.05887</a>",,2025-12-03 22:39:25
Adversarial Robustness Guarantees for Random Deep Neural Networks,"Palma Giacomo De, Bobak T. Kiani, Seth Lloyd",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.05923"" target=""_blank"">2004.05923</a>",,2025-12-03 22:39:25
On the Optimal Interaction Range for Multi-Agent Systems Under Adversarial Attack,Saad J Saleh,arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.06562"" target=""_blank"">2004.06562</a>",,2025-12-03 22:39:25
Advanced Evasion Attacks and Mitigations on Practical ML-Based Phishing Website Classifiers,"Yusi Lei, Sen Chen, Lingling Fan, Fu Song, Yang Liu",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.06954"" target=""_blank"">2004.06954</a>",,2025-12-03 22:39:25
A Framework for Enhancing Deep Neural Networks Against Adversarial Malware,"Deqiang Li, Qianmu Li, Yanfang Ye, Shouhuai Xu",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.07919"" target=""_blank"">2004.07919</a>",,2025-12-03 22:39:25
Shortcut Learning in Deep Neural Networks,"Robert Geirhos, Jörn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, Felix A. Wichmann",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.07780"" target=""_blank"">2004.07780</a>",,2025-12-03 22:39:25
Adversarial Attack on Deep Learning-Based Splice Localization,"Andras Rozsa, Zheng Zhong, Terrance E. Boult",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.08443"" target=""_blank"">2004.08443</a>",,2025-12-03 22:39:25
Adversarial Attacks on Machine Learning Cybersecurity Defences in Industrial Control Systems,"Eirini Anthi, Lowri Williams, Matilda Rhode, Pete Burnap, Adam Wedgbury",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.05005"" target=""_blank"">2004.05005</a>",,2025-12-03 22:39:25
Verification of Deep Convolutional Neural Networks Using ImageStars,"Hoang-Dung Tran, Stanley Bak, Weiming Xiang, Taylor T. Johnson",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.05511"" target=""_blank"">2004.05511</a>",,2025-12-03 22:39:25
Adversarial Attacks on Multivariate Time Series,"Samuel Harford, Fazle Karim, Houshang Darabi",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.00410"" target=""_blank"">2004.00410</a>",,2025-12-03 22:39:25
Luring of transferable adversarial perturbations in the black-box paradigm,"Rémi Bernhard, Pierre-Alain Moellic, Jean-Max Dutertre",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.04919"" target=""_blank"">2004.04919</a>",,2025-12-03 22:39:25
Understanding (Non-)Robust Feature Disentanglement and the Relationship Between Low- and High-Dimensional Adversarial Attacks,"Zuowen Wang, Leo Horne",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.01903"" target=""_blank"">2004.01903</a>",,2025-12-03 22:39:25
Protecting Classifiers From Attacks,"Victor Gallego, Roi Naveiro, Alberto Redondo, David Rios Insua, Fabrizio Ruggeri",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.08705"" target=""_blank"">2004.08705</a>",,2025-12-03 22:39:25
Investigating Image Applications Based on Spatial-Frequency Transform and Deep Learning Techniques,"Qinkai Zheng, Han Qiu, Gerard Memmi, Isabelle Bloch",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.02756"" target=""_blank"">2004.02756</a>",,2025-12-03 22:39:25
Physically Realizable Adversarial Examples for LiDAR Object Detection,"James Tu, Mengye Ren, Siva Manivasagam, Ming Liang, Bin Yang, Richard Du, Frank Cheng, Raquel Urtasun",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.00543"" target=""_blank"">2004.00543</a>",,2025-12-03 22:39:25
Towards Achieving Adversarial Robustness by Enforcing Feature Consistency Across Bit Planes,"Sravanti Addepalli, Vivek B. S., Arya Baburaj, Gaurang Sriramanan, R. Venkatesh Babu",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.00306"" target=""_blank"">2004.00306</a>",,2025-12-03 22:39:25
Evading Deepfake-Image Detectors with White- and Black-Box Attacks,"Nicholas Carlini, Hany Farid",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.00622"" target=""_blank"">2004.00622</a>",,2025-12-03 22:39:25
Adversarial Robustness through Regularization: A Second-Order Approach,"Avery Ma, Fartash Faghri, Amir-massoud Farahmand",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.01832"" target=""_blank"">2004.01832</a>",,2025-12-03 22:39:25
BAE: BERT-based Adversarial Examples for Text Classification,"Siddhant Garg, Goutham Ramakrishnan",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.01970"" target=""_blank"">2004.01970</a>",,2025-12-03 22:39:25
Approximate Manifold Defense Against Multiple Adversarial Perturbations,"Jay Nandy, Wynne Hsu, Mong Li Lee",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.02183"" target=""_blank"">2004.02183</a>",,2025-12-03 22:39:25
Blind Adversarial Training: Balance Accuracy and Robustness,"Haidong Xie, Xueshuang Xiang, Naijin Liu, Bin Dong",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.05914"" target=""_blank"">2004.05914</a>",,2025-12-03 22:39:25
Universal Adversarial Perturbations Generative Network for Speaker Recognition,"Jiguo Li, Xinfeng Zhang, Chuanmin Jia, Jizheng Xu, Li Zhang, Yue Wang, Siwei Ma, Wen Gao",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.03428"" target=""_blank"">2004.03428</a>",,2025-12-03 22:39:25
Learning to fool the speaker recognition,"Jiguo Li, Xinfeng Zhang, Jizheng Xu, Li Zhang, Yue Wang, Siwei Ma, Wen Gao",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.03434"" target=""_blank"">2004.03434</a>",,2025-12-03 22:39:25
Feature Partitioning for Robust Tree Ensembles and their Certification in Adversarial Scenarios,"Stefano Calzavara, Claudio Lucchese, Federico Marcuzzi, Salvatore Orlando",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.03295"" target=""_blank"">2004.03295</a>",,2025-12-03 22:39:25
Towards Evaluating the Robustness of Chinese BERT Classifiers,"Boxin Wang, Boyuan Pan, Xin Li, Bo Li",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.03742"" target=""_blank"">2004.03742</a>",,2025-12-03 22:39:25
"Transferable, Controllable, and Inconspicuous Adversarial Attacks on Person Re-identification With Deep Mis-Ranking","Hongjun Wang, Guangrun Wang, Ya Li, Dongyu Zhang, Liang Lin",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.04199"" target=""_blank"">2004.04199</a>","<a href=""https://github.com/whj363636/Adversarial-attack-on-Person-ReID-With-Deep-Mis-Ranking"" target=""_blank"">whj363636</a>",2025-12-03 22:39:25
On Adversarial Examples and Stealth Attacks in Artificial Intelligence Systems,"Ivan Y. Tyukin, Desmond J. Higham, Alexander N. Gorban",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.04479"" target=""_blank"">2004.04479</a>",,2025-12-03 22:39:25
"Blind Adversarial Pruning: Balance Accuracy, Efficiency and Robustness","Haidong Xie, Lixin Qian, Xueshuang Xiang, Naijin Liu",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.05913"" target=""_blank"">2004.05913</a>",,2025-12-03 22:39:25
Single-step Adversarial training with Dropout Scheduling,"Vivek B. S., R. Venkatesh Babu",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.08628"" target=""_blank"">2004.08628</a>",,2025-12-03 22:39:25
Extending Adversarial Attacks to Produce Adversarial Class Probability Distributions,"Jon Vadillo, Roberto Santana, Jose A. Lozano",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.06383"" target=""_blank"">2004.06383</a>",,2025-12-03 22:39:25
Headless Horseman: Adversarial Attacks on Transfer Learning Models,"Ahmed Abdelkader, Michael J. Curry, Liam Fowl, Tom Goldstein, Avi Schwarzschild, Manli Shu, Christoph Studer, Chen Zhu",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.09007"" target=""_blank"">2004.09007</a>",,2025-12-03 22:39:25
Transferable Perturbations of Deep Feature Distributions,"Nathan Inkawhich, Kevin J Liang, Lawrence Carin, Yiran Chen",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.12519"" target=""_blank"">2004.12519</a>",,2025-12-03 22:39:25
A Black-box Adversarial Attack Strategy with Adjustable Sparsity and Generalizability for Deep Image Classifiers,"Arka Ghosh, Sankha Subhra Mullick, Shounak Datta, Swagatam Das, Rammohan Mallipeddi, Asit Kr. Das",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.13002"" target=""_blank"">2004.13002</a>",,2025-12-03 22:39:25
Towards Characterizing Adversarial Defects of Deep Learning Software from the Lens of Uncertainty,"Xiyue Zhang, Xiaofei Xie, Lei Ma, Xiaoning Du, Qiang Hu, Yang Liu, Jianjun Zhao, Meng Sun",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.11573"" target=""_blank"">2004.11573</a>",,2025-12-03 22:39:25
Harnessing adversarial examples with a surprisingly simple defense,Ali Borji,arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.13013"" target=""_blank"">2004.13013</a>",,2025-12-03 22:39:25
Enabling Fast and Universal Audio Adversarial Attack Using Generative Model,"Yi Xie, Zhuohang Li, Cong Shi, Jian Liu, Yingying Chen, Bo Yuan",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.12261"" target=""_blank"">2004.12261</a>",,2025-12-03 22:39:25
Improved Adversarial Training via Learned Optimizer,"Yuanhao Xiong, Cho-Jui Hsieh",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.12227"" target=""_blank"">2004.12227</a>",,2025-12-03 22:39:25
Improved Image Wasserstein Attacks and Defenses,"Edward J. Hu, Adith Swaminathan, Hadi Salman, Greg Yang",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.12478"" target=""_blank"">2004.12478</a>","<a href=""https://github.com/edwardjhu/improved_wasserstein"" target=""_blank"">edwardjhu</a>",2025-12-03 22:39:25
Towards Feature Space Adversarial Attack,"Qiuling Xu, Guanhong Tao, Siyuan Cheng, Xiangyu Zhang",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.12385"" target=""_blank"">2004.12385</a>",,2025-12-03 22:39:25
"""Call me sexist, but","Mattia Samory, Indira Sen, Julian Kohne, Fabian Floeck, Claudia Wagner",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.12764"" target=""_blank"">2004.12764</a>",,2025-12-03 22:39:25
Adversarial Machine Learning in Network Intrusion Detection Systems,"Elie Alhajjar, Paul Maxwell, Nathaniel D. Bastian",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.11898"" target=""_blank"">2004.11898</a>",,2025-12-03 22:39:25
DeSePtion: Dual Sequence Prediction and Adversarial Examples for Improved Fact-Checking,"Christopher Hidey, Tuhin Chakrabarty, Tariq Alhindi, Siddharth Varia, Kriste Krstovski, Mona Diab, Smaranda Muresan",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.12864"" target=""_blank"">2004.12864</a>",,2025-12-03 22:39:25
Minority Reports Defense: Defending Against Adversarial Patches,"Michael McCoyd, Won Park, Steven Chen, Neil Shah, Ryan Roggenkemper, Minjune Hwang, Jason Xinyu Liu, David Wagner",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.13799"" target=""_blank"">2004.13799</a>",,2025-12-03 22:39:25
Adversarial Learning Guarantees for Linear Hypotheses and Neural Networks,"Pranjal Awasthi, Natalie Frank, Mehryar Mohri",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.13617"" target=""_blank"">2004.13617</a>",,2025-12-03 22:39:25
TAVAT: Token-Aware Virtual Adversarial Training for Language Understanding,"Linyang Li, Xipeng Qiu",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.14543"" target=""_blank"">2004.14543</a>",,2025-12-03 22:39:25
Perturbing Across the Feature Hierarchy to Improve Standard and Strict Blackbox Attack Transferability,"Nathan Inkawhich, Kevin J Liang, Binghui Wang, Matthew Inkawhich, Lawrence Carin, Yiran Chen",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.14861"" target=""_blank"">2004.14861</a>",,2025-12-03 22:39:25
Adversarial Training for Large Neural Language Models,"Xiaodong Liu, Hao Cheng, Pengcheng He, Weizhu Chen, Yu Wang, Hoifung Poon, Jianfeng Gao",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.08994"" target=""_blank"">2004.08994</a>","<a href=""https://github.com/namisan/mt-dnn"" target=""_blank"">namisan</a>",2025-12-03 22:39:25
Imitation Attacks and Defenses for Black-box Machine Translation Systems,"Eric Wallace, Mitchell Stern, Dawn Song",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.15015"" target=""_blank"">2004.15015</a>",,2025-12-03 22:39:25
Reevaluating Adversarial Examples in Natural Language,"John X. Morris, Eli Lifland, Jack Lanchantin, Yangfeng Ji, Yanjun Qi",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.14174"" target=""_blank"">2004.14174</a>",,2025-12-03 22:39:25
"Adversarial Fooling Beyond ""Flipping the Label""","Konda Reddy Mopuri, Vaisakh Shaj, R. Venkatesh Babu",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.12771"" target=""_blank"">2004.12771</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defenses: An Interpretation Perspective,"Ninghao Liu, Mengnan Du, Ruocheng Guo, Huan Liu, Xia Hu",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.11488"" target=""_blank"">2004.11488</a>",,2025-12-03 22:39:25
Scalable Attack on Graph Data by Injecting Vicious Nodes,"Jihong Wang, Minnan Luo, Fnu Suya, Jundong Li, Zijiang Yang, Qinghua Zheng",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.13825"" target=""_blank"">2004.13825</a>",,2025-12-03 22:39:25
Approximate exploitability: Learning a best response in large games,"Finbarr Timbers, Nolan Bard, Edward Lockhart, Marc Lanctot, Martin Schmid, Neil Burch, Julian Schrittwieser, Thomas Hubert, Michael Bowling",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.09677"" target=""_blank"">2004.09677</a>",,2025-12-03 22:39:25
Evaluating Adversarial Robustness for Deep Neural Network Interpretability using fMRI Decoding,"Patrick McClure, Dustin Moraczewski, Ka Chun Lam, Adam Thomas, Francisco Pereira",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.11114"" target=""_blank"">2004.11114</a>",,2025-12-03 22:39:25
GraN: An Efficient Gradient-Norm Based Detector for Adversarial and Misclassified Examples,"Julia Lust, Alexandru Paul Condurache",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.09179"" target=""_blank"">2004.09179</a>",,2025-12-03 22:39:25
Dynamic Knowledge Graph-based Dialogue Generation with Improved Adversarial Meta-Learning,"Hongcai Xu, Junpeng Bao, Gaojie Zhang",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.08833"" target=""_blank"">2004.08833</a>",,2025-12-03 22:39:25
EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness against Adversarial Attacks,"Sanchari Sen, Balaraman Ravindran, Anand Raghunathan",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.10162"" target=""_blank"">2004.10162</a>",,2025-12-03 22:39:25
Probabilistic Safety for Bayesian Neural Networks,"Matthew Wicker, Luca Laurenti, Andrea Patane, Marta Kwiatkowska",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.10281"" target=""_blank"">2004.10281</a>",,2025-12-03 22:39:25
Certifying Joint Adversarial Robustness for Model Ensembles,"Mainuddin Ahmad Jonas, David Evans",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.10250"" target=""_blank"">2004.10250</a>",,2025-12-03 22:39:25
BERT-ATTACK: Adversarial Attack Against BERT Using BERT,"Linyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue, Xipeng Qiu",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.09984"" target=""_blank"">2004.09984</a>",,2025-12-03 22:39:25
Adversarial examples and where to find them,"Niklas Risse, Christina Göpfert, Jan Philip Göpfert",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.10882"" target=""_blank"">2004.10882</a>",,2025-12-03 22:39:25
QUANOS- Adversarial Noise Sensitivity Driven Hybrid Quantization of Neural Networks,Priyadarshini Panda,arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.11233"" target=""_blank"">2004.11233</a>",,2025-12-03 22:39:25
Provably robust deep generative models,"Filipe Condessa, Zico Kolter",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.10608"" target=""_blank"">2004.10608</a>",,2025-12-03 22:39:25
CodNN -- Robust Neural Networks From Coded Classification,"Netanel Andrew Raviv, Siddharth Andrew Jain, Pulakesh Andrew Upadhyaya, Jehoshua Andrew Bruck, Andrew Anxiao, Jiang",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.10700"" target=""_blank"">2004.10700</a>",,2025-12-03 22:39:25
RAIN: A Simple Approach for Robust and Accurate Image Classification Networks,"Jiawei Du, Hanshu Yan, Vincent Y. F. Tan, Joey Tianyi Zhou, Rick Siow Mong Goh, Jiashi Feng",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.14798"" target=""_blank"">2004.14798</a>",,2025-12-03 22:39:25
Improved Noise and Attack Robustness for Semantic Segmentation by Using Multi-Task Training with Self-Supervised Depth Estimation,"Marvin Klingner, Andreas Bär, Tim Fingscheidt",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.11072"" target=""_blank"">2004.11072</a>",,2025-12-03 22:39:25
On Adversarial Examples for Biomedical NLP Tasks,"Vladimir Araujo, Andres Carvallo, Carlos Aspillaga, Denis Parra",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.11157"" target=""_blank"">2004.11157</a>",,2025-12-03 22:39:25
Ensemble Generative Cleaning with Feedback Loops for Defending Adversarial Attacks,"Jianhe Yuan, Zhihai He",arXiv,2020-04,"<a href=""http://arxiv.org/abs/2004.11273"" target=""_blank"">2004.11273</a>",,2025-12-03 22:39:25
Defense against adversarial attacks on spoofing countermeasures of ASV,"Haibin Wu, Songxiang Liu, Helen Meng, Hung-yi Lee",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.03065"" target=""_blank"">2003.03065</a>",,2025-12-03 22:39:25
No Surprises: Training Robust Lung Nodule Detection for Low-Dose CT Scans by Augmenting with Adversarial Attacks,"Siqi Liu, Arnaud Arindra Adiyoso Setio, Florin C. Ghesu, Eli Gibson, Sasa Grbic, Bogdan Georgescu, Dorin Comaniciu",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.03824"" target=""_blank"">2003.03824</a>",,2025-12-03 22:39:25
Dynamic Backdoor Attacks Against Machine Learning Models,"Ahmed Salem, Rui Wen, Michael Backes, Shiqing Ma, Yang Zhang",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.03675"" target=""_blank"">2003.03675</a>",,2025-12-03 22:39:25
Adversarial Machine Learning: Bayesian Perspectives,"David Rios Insua, Roi Naveiro, Victor Gallego, Jason Poulos",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.03546"" target=""_blank"">2003.03546</a>",,2025-12-03 22:39:25
Towards Practical Lottery Ticket Hypothesis for Adversarial Training,"Bai Li, Shiqi Wang, Yunhan Jia, Yantao Lu, Zhenyu Zhong, Lawrence Carin, Suman Jana",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.05733"" target=""_blank"">2003.05733</a>",,2025-12-03 22:39:25
Triple Memory Networks: a Brain-Inspired Method for Continual Learning,"Liyuan Wang, Bo Lei, Qian Li, Hang Su, Jun Zhu, Yi Zhong",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.03143"" target=""_blank"">2003.03143</a>",,2025-12-03 22:39:25
MAB-Malware: A Reinforcement Learning Framework for Attacking Static Malware Classifiers,"Wei Song, Xuezixiang Li, Sadia Afroz, Deepali Garg, Dmitry Kuznetsov, Heng Yin",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.03100"" target=""_blank"">2003.03100</a>",,2025-12-03 22:39:25
Detection and Recovery of Adversarial Attacks with Injected Attractors,"Jiyi Zhang, Ee-Chien Chang, Hwee Kuan Lee",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.02732"" target=""_blank"">2003.02732</a>",,2025-12-03 22:39:25
Exploiting Verified Neural Networks via Floating Point Numerical Error,"Kai Jia, Martin Rinard",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.03021"" target=""_blank"">2003.03021</a>",,2025-12-03 22:39:25
Adversarial Attacks on Probabilistic Autoregressive Forecasting Models,"Raphaël Dang-Nhu, Gagandeep Singh, Pavol Bielik, Martin Vechev",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.03778"" target=""_blank"">2003.03778</a>",,2025-12-03 22:39:25
Adversarial Camouflage: Hiding Physical-World Attacks with Natural Styles,"Ranjie Duan, Xingjun Ma, Yisen Wang, James Bailey, A. K. Qin, Yun Yang",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.08757"" target=""_blank"">2003.08757</a>",,2025-12-03 22:39:25
Domain Adaptation with Conditional Distribution Matching and Generalized Label Shift,"Remi Tachet des Combes, Han Zhao, Yu-Xiang Wang, Geoff Gordon",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.04475"" target=""_blank"">2003.04475</a>",,2025-12-03 22:39:25
On the Robustness of Cooperative Multi-Agent Reinforcement Learning,"Jieyu Lin, Kristina Dzeparoska, Sai Qian Zhang, Alberto Leon-Garcia, Nicolas Papernot",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.03722"" target=""_blank"">2003.03722</a>",,2025-12-03 22:39:25
An Empirical Evaluation on Robustness and Uncertainty of Regularization Methods,"Sanghyuk Chun, Seong Joon Oh, Sangdoo Yun, Dongyoon Han, Junsuk Choe, Youngjoon Yoo",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.03879"" target=""_blank"">2003.03879</a>",,2025-12-03 22:39:25
Security of Distributed Machine Learning: A Game-Theoretic Approach to Design Secure DSVM,"Rui Zhang, Quanyan Zhu",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.04735"" target=""_blank"">2003.04735</a>",,2025-12-03 22:39:25
Generating Natural Language Adversarial Examples on a Large Scale with Generative Models,"Yankun Ren, Jianbin Lin, Siliang Tang, Jun Zhou, Shuang Yang, Yuan Qi, Xiang Ren",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.10388"" target=""_blank"">2003.10388</a>",,2025-12-03 22:39:25
Manifold Regularization for Locally Stable Deep Neural Networks,"Charles Jin, Martin Rinard",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.04286"" target=""_blank"">2003.04286</a>",,2025-12-03 22:39:25
Towards Probabilistic Verification of Machine Unlearning,"David Marco Sommer, Liwei Song, Sameer Wagh, Prateek Mittal",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.04247"" target=""_blank"">2003.04247</a>",,2025-12-03 22:39:25
A Survey of Adversarial Learning on Graphs,"Liang Chen, Jintang Li, Jiaying Peng, Tao Xie, Zengxu Cao, Kun Xu, Xiangnan He, Zibin Zheng",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.05730"" target=""_blank"">2003.05730</a>","<a href=""https://github.com/gitgiter/Graph-Adversarial-Learning"" target=""_blank"">gitgiter</a>",2025-12-03 22:39:25
Cryptanalytic Extraction of Neural Network Models,"Nicholas Carlini, Matthew Jagielski, Ilya Mironov",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.04884"" target=""_blank"">2003.04884</a>","<a href=""https://github.com/google-research/cryptanalytic-model-extraction"" target=""_blank"">google-research</a>",2025-12-03 22:39:25
Using an ensemble color space model to tackle adversarial examples,"Shreyank N Gowda, Chun Yuan",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.05005"" target=""_blank"">2003.05005</a>",,2025-12-03 22:39:25
SAD: Saliency-based Defenses Against Adversarial Examples,"Richard Tran, David Patrick, Michael Geyer, Amanda Fernandez",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.04820"" target=""_blank"">2003.04820</a>",,2025-12-03 22:39:25
Adversarial Vertex Mixup: Toward Better Adversarially Robust Generalization,"Saehyung Lee, Hyungyu Lee, Sungroh Yoon",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.02484"" target=""_blank"">2003.02484</a>",,2025-12-03 22:39:25
Adversarial Robustness Through Local Lipschitzness,"Yao-Yuan Yang, Cyrus Rashtchian, Hongyang Zhang, Ruslan Salakhutdinov, Kamalika Chaudhuri",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.02460"" target=""_blank"">2003.02460</a>","<a href=""https://github.com/yangarbiter/robust-local-lipschitz"" target=""_blank"">yangarbiter</a>",2025-12-03 22:39:25
"Adversarial Attacks and Defenses on Graphs: A Review, A Tool and Empirical Studies","Wei Jin, Yaxin Li, Han Xu, Yiqi Wang, Shuiwang Ji, Charu Aggarwal, Jiliang Tang",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.00653"" target=""_blank"">2003.00653</a>","<a href=""https://github.com/DSE-MSU/DeepRobust/tree/master/deeprobust/graph"" target=""_blank"">deeprobust</a>",2025-12-03 22:39:25
Search Space of Adversarial Perturbations against Image Filters,"Dang Duy Thang, Toshihiro Matsui",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.02750"" target=""_blank"">2003.02750</a>",,2025-12-03 22:39:25
Disrupting Deepfakes: Adversarial Attacks Against Conditional Image Translation Networks and Facial Manipulation Systems,"Nataniel Ruiz, Sarah Adel Bargal, Stan Sclaroff",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.01279"" target=""_blank"">2003.01279</a>",,2025-12-03 22:39:25
Undersensitivity in Neural Reading Comprehension,"Johannes Welbl, Pasquale Minervini, Max Bartolo, Pontus Stenetorp, Sebastian Riedel",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.04808"" target=""_blank"">2003.04808</a>",,2025-12-03 22:39:25
Category-wise Attack: Transferable Adversarial Examples for Anchor Free Object Detection,"Quanyu Liao, Xin Wang, Bin Kong, Siwei Lyu, Youbing Yin, Qi Song, Xi Wu",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.04367"" target=""_blank"">2003.04367</a>",,2025-12-03 22:39:25
Adversarial Perturbations Prevail in the Y-Channel of the YCbCr Color Space,"Camilo Pestana, Naveed Akhtar, Wei Liu, David Glance, Ajmal Mian",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.00883"" target=""_blank"">2003.00883</a>",,2025-12-03 22:39:25
Adv-BERT: BERT is not robust on misspellings! Generating nature adversarial samples on BERT,"Lichao Sun, Kazuma Hashimoto, Wenpeng Yin, Akari Asai, Jia Li, Philip Yu, Caiming Xiong",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.04985"" target=""_blank"">2003.04985</a>",,2025-12-03 22:39:25
Improving Certified Robustness via Statistical Learning with Logical Reasoning,"Zhuolin Yang, Zhikuan Zhao, Boxin Wang, Jiawei Zhang, Linyi Li, Hengzhi Pei, Bojan Karlas, Ji Liu, Heng Guo, Ce Zhang, Bo Li",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.00120"" target=""_blank"">2003.00120</a>",,2025-12-03 22:39:25
Why is the Mahalanobis Distance Effective for Anomaly Detection?,"Ryo Kamoi, Kei Kobayashi",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.00402"" target=""_blank"">2003.00402</a>",,2025-12-03 22:39:25
Understanding the Intrinsic Robustness of Image Distributions using Conditional Generative Models,"Xiao Zhang, Jinghui Chen, Quanquan Gu, David Evans",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.00378"" target=""_blank"">2003.00378</a>","<a href=""https://github.com/xiaozhanguva/Intrinsic-Rob"" target=""_blank"">xiaozhanguva</a>",2025-12-03 22:39:25
ConAML: Constrained Adversarial Machine Learning for Cyber-Physical Systems,"Jiangnan Li, Yingyuan Yang, Jinyuan Stella Sun, Kevin Tomsovic, Hairong Qi",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.05631"" target=""_blank"">2003.05631</a>",,2025-12-03 22:39:25
Adversarial Network Traffic: Towards Evaluating the Robustness of Deep Learning-Based Network Traffic Classification,"Amir Mahdi Sadeghzadeh, Saeed Shiravi, Rasool Jalili",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.01261"" target=""_blank"">2003.01261</a>",,2025-12-03 22:39:25
Hidden Cost of Randomized Smoothing,"Jeet Lily Mohapatra, Ching-Yun Lily Ko, Lily Tsui-Wei, Weng, Sijia Liu, Pin-Yu Chen, Luca Daniel",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.01249"" target=""_blank"">2003.01249</a>",,2025-12-03 22:39:25
Learn2Perturb: an End-to-end Feature Perturbation Learning to Improve Adversarial Robustness,"Ahmadreza Jeddi, Mohammad Javad Shafiee, Michelle Karg, Christian Scharfenberger, Alexander Wong",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.01090"" target=""_blank"">2003.01090</a>",,2025-12-03 22:39:25
"Real-time, Universal, and Robust Adversarial Attacks Against Speaker Recognition Systems","Yi Xie, Cong Shi, Zhuohang Li, Jian Liu, Yingying Chen, Bo Yuan",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.02301"" target=""_blank"">2003.02301</a>",,2025-12-03 22:39:25
Data-Free Adversarial Perturbations for Practical Black-Box Attack,"ZhaoXin Huan, Yulong Wang, Xiaolu Zhang, Lin Shang, Chilin Fu, Jun Zhou",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.01295"" target=""_blank"">2003.01295</a>",,2025-12-03 22:39:25
Type I Attack for Generative Models,"Chengjin Sun, Sizhe Chen, Jia Cai, Xiaolin Huang",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.01872"" target=""_blank"">2003.01872</a>",,2025-12-03 22:39:25
Security of Deep Learning based Lane Keeping System under Physical-World Adversarial Attack,"Takami Sato, Junjie Shen, Ningfei Wang, Yunhan Jack Jia, Xue Lin, Qi Alfred Chen",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.01782"" target=""_blank"">2003.01782</a>",,2025-12-03 22:39:25
Discriminative Multi-level Reconstruction under Compact Latent Space for One-Class Novelty Detection,"Jaewoo Park, Yoon Gyo Jung, Andrew Beng Jin Teoh",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.01665"" target=""_blank"">2003.01665</a>",,2025-12-03 22:39:25
Analyzing Accuracy Loss in Randomized Smoothing Defenses,"Yue Gao, Harrison Rosenberg, Kassem Fawaz, Somesh Jha, Justin Hsu",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.01595"" target=""_blank"">2003.01595</a>",,2025-12-03 22:39:25
Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks,"Francesco Croce, Matthias Hein",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.01690"" target=""_blank"">2003.01690</a>",,2025-12-03 22:39:25
Metrics and methods for robustness evaluation of neural networks with generative models,"Igor Buzhinsky, Arseny Nerinovsky, Stavros Tripakis",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.01993"" target=""_blank"">2003.01993</a>",,2025-12-03 22:39:25
Black-box Smoothing: A Provable Defense for Pretrained Classifiers,"Hadi Salman, Mingjie Sun, Greg Yang, Ashish Kapoor, J. Zico Kolter",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.01908"" target=""_blank"">2003.01908</a>","<a href=""https://github.com/microsoft/blackbox-smoothing"" target=""_blank"">microsoft</a>",2025-12-03 22:39:25
Double Backpropagation for Training Autoencoders against Adversarial Attack,"Chengjin Sun, Sizhe Chen, Xiaolin Huang",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.01895"" target=""_blank"">2003.01895</a>",,2025-12-03 22:39:25
Colored Noise Injection for Training Adversarially Robust Neural Networks,"Evgenii Zheltonozhskii, Chaim Baskin, Yaniv Nemcovsky, Brian Chmiel, Avi Mendelson, Alex M. Bronstein",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.02188"" target=""_blank"">2003.02188</a>",,2025-12-03 22:39:25
Frequency-Tuned Universal Adversarial Attacks,"Yingpeng Deng, Lina J. Karam",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.05549"" target=""_blank"">2003.05549</a>",,2025-12-03 22:39:25
Gradient-based adversarial attacks on categorical sequence models via traversing an embedded world,"Ivan Fursov, Alexey Zaytsev, Nikita Kluchnikov, Andrey Kravchenko, Evgeny Burnaev",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.04173"" target=""_blank"">2003.04173</a>",,2025-12-03 22:39:25
ARAE: Adversarially Robust Training of Autoencoders Improves Novelty Detection,"Mohammadreza Salehi, Atrin Arya, Barbod Pajoum, Mohammad Otoofi, Amirreza Shaeiri, Mohammad Hossein Rohban, Hamid R. Rabiee",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.05669"" target=""_blank"">2003.05669</a>",,2025-12-03 22:39:25
Plausible Counterfactuals: Auditing Deep Learning Classifiers with Realistic Adversarial Examples,"Alejandro Barredo-Arrieta, Ser Javier Del",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.11323"" target=""_blank"">2003.11323</a>",,2025-12-03 22:39:25
Adversarial Examples and the Deeper Riddle of Induction: The Need for a Theory of Artifacts in Deep Learning,Cameron Buckner,arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.11917"" target=""_blank"">2003.11917</a>",,2025-12-03 22:39:25
Cooling-Shrinking Attack: Blinding the Tracker with Imperceptible Noises,"Bin Yan, Dong Wang, Huchuan Lu, Xiaoyun Yang",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.09595"" target=""_blank"">2003.09595</a>","<a href=""https://github.com/MasterBin-IIAU/CSA"" target=""_blank"">MasterBin-IIAU</a>",2025-12-03 22:39:25
Robust Out-of-distribution Detection in Neural Networks,"Jiefeng Chen, Yixuan Li, Xi Wu, Yingyu Liang, Somesh Jha",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.09711"" target=""_blank"">2003.09711</a>",,2025-12-03 22:39:25
Detecting Adversarial Examples in Learning-Enabled Cyber-Physical Systems using Variational Autoencoder for Regression,"Feiyang Cai, Jiani Li, Xenofon Koutsoukos",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.10804"" target=""_blank"">2003.10804</a>",,2025-12-03 22:39:25
Architectural Resilience to Foreground-and-Background Adversarial Noise,"Carl Cheng, Evan Hu",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.10045"" target=""_blank"">2003.10045</a>",,2025-12-03 22:39:25
Understanding the robustness of deep neural network classifiers for breast cancer screening,"Witold Oleszkiewicz, Taro Makino, Stanisław Jastrzębski, Tomasz Trzciński, Linda Moy, Kyunghyun Cho, Laura Heacock, Krzysztof J. Geras",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.10041"" target=""_blank"">2003.10041</a>",,2025-12-03 22:39:25
Adversarial Perturbations Fool Deepfake Detectors,"Apurva Gandhi, Shomik Jain",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.10596"" target=""_blank"">2003.10596</a>",,2025-12-03 22:39:25
Inherent Adversarial Robustness of Deep Spiking Neural Networks: Effects of Discrete Input Encoding and Non-Linear Activations,"Saima Sharmin, Nitin Rathi, Priyadarshini Panda, Kaushik Roy",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.10399"" target=""_blank"">2003.10399</a>",,2025-12-03 22:39:25
Adversarial Attacks on Monocular Depth Estimation,"Ziqi Zhang, Xinge Zhu, Yingwei Li, Xiangqun Chen, Yao Guo",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.10315"" target=""_blank"">2003.10315</a>",,2025-12-03 22:39:25
Defense Through Diverse Directions,"Christopher M. Bender, Yang Li, Yifeng Shi, Michael K. Reiter, Junier B. Oliva",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.10602"" target=""_blank"">2003.10602</a>",,2025-12-03 22:39:25
Challenging the adversarial robustness of DNNs based on error-correcting output codes,"Bowen Zhang, Benedetta Tondi, Xixiang Lv, Mauro Barni",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.11855"" target=""_blank"">2003.11855</a>",,2025-12-03 22:39:25
One Neuron to Fool Them All,"Anshuman Suri, David Evans",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.09372"" target=""_blank"">2003.09372</a>","<a href=""https://github.com/iamgroot42/sauron"" target=""_blank"">iamgroot42</a>",2025-12-03 22:39:25
Do Deep Minds Think Alike? Selective Adversarial Attacks for Fine-Grained Manipulation of Multiple Deep Neural Networks,"Zain Khan, Jirong Yi, Raghu Mudumbai, Xiaodong Wu, Weiyu Xu",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.11816"" target=""_blank"">2003.11816</a>",,2025-12-03 22:39:25
Adversarial Imitation Attack,"Mingyi Zhou, Jing Wu, Yipeng Liu, Shuaicheng Liu, Xiang Zhang, Ce Zhu",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.12760"" target=""_blank"">2003.12760</a>",,2025-12-03 22:39:25
DaST: Data-free Substitute Training for Adversarial Attacks,"Mingyi Zhou, Jing Wu, Yipeng Liu, Shuaicheng Liu, Ce Zhu",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.12703"" target=""_blank"">2003.12703</a>",,2025-12-03 22:39:25
Adversarial Robustness: From Self-Supervised Pre-Training to Fine-Tuning,"Tianlong Chen, Sijia Liu, Shiyu Chang, Yu Cheng, Lisa Amini, Zhangyang Wang",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.12862"" target=""_blank"">2003.12862</a>","<a href=""https://github.com/TAMU-VITA/Adv-SS-Pretraining"" target=""_blank"">TAMU-VITA</a>",2025-12-03 22:39:25
Efficient Black-box Optimization of Adversarial Windows Malware with Constrained Manipulations,"Luca Demetrio, Battista Biggio, Giovanni Lagorio, Fabio Roli, Alessandro Armando",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.13526"" target=""_blank"">2003.13526</a>",,2025-12-03 22:39:25
Towards Deep Learning Models Resistant to Large Perturbations,"Amirreza Shaeiri, Rozhin Nobahari, Mohammad Hossein Rohban",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.13370"" target=""_blank"">2003.13370</a>",,2025-12-03 22:39:25
A Thorough Comparison Study on Adversarial Attacks and Defenses for Common Thorax Disease Classification in Chest X-rays,"Chendi Rao, Jiezhang Cao, Runhao Zeng, Qi Chen, Huazhu Fu, Yanwu Xu, Mingkui Tan",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.13969"" target=""_blank"">2003.13969</a>",,2025-12-03 22:39:25
Inline Detection of DGA Domains Using Side Information,"Raaghavi Sivaguru, Jonathan Peck, Femi Olumofin, Anderson Nascimento, Cock Martine De",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.05703"" target=""_blank"">2003.05703</a>",,2025-12-03 22:39:25
Improved Gradient based Adversarial Attacks for Quantized Networks,"Kartik Gupta, Thalaiyasingam Ajanthan",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.13511"" target=""_blank"">2003.13511</a>",,2025-12-03 22:39:25
Characterizing Speech Adversarial Examples Using Self-Attention U-Net Enhancement,"Chao-Han Huck Yang, Jun Qi, Pin-Yu Chen, Xiaoli Ma, Chin-Hui Lee",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.13917"" target=""_blank"">2003.13917</a>",,2025-12-03 22:39:25
Quantum noise protects quantum classifiers against adversaries,"Yuxuan Du, Min-Hsiu Hsieh, Tongliang Liu, Dacheng Tao, Nana Liu",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.09416"" target=""_blank"">2003.09416</a>",,2025-12-03 22:39:25
Adversarial Light Projection Attacks on Face Recognition Systems: A Feasibility Study,"Luan Nguyen, Sunpreet S. Arora, Yuhang Wu, Hao Yang",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.11145"" target=""_blank"">2003.11145</a>",,2025-12-03 22:39:25
Adversarial Robustness on In- and Out-Distribution Improves Explainability,"Maximilian Augustin, Alexander Meinke, Matthias Hein",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.09461"" target=""_blank"">2003.09461</a>",,2025-12-03 22:39:25
Output Diversified Initialization for Adversarial Attacks,"Yusuke Tashiro, Yang Song, Stefano Ermon",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.06878"" target=""_blank"">2003.06878</a>","<a href=""https://github.com/ermongroup/ODI/"" target=""_blank"">ODI</a>",2025-12-03 22:39:25
GeoDA: a geometric framework for black-box adversarial attacks,"Ali Rahmati, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard, Huaiyu Dai",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.06468"" target=""_blank"">2003.06468</a>",,2025-12-03 22:39:25
Towards a Resilient Machine Learning Classifier -- a Case Study of Ransomware Detection,"Chih-Yuan Yang, Ravi Sahita",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.06428"" target=""_blank"">2003.06428</a>",,2025-12-03 22:39:25
Breaking certified defenses: Semantic adversarial examples with spoofed robustness certificates,"Amin Ghiasi, Ali Shafahi, Tom Goldstein",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.08937"" target=""_blank"">2003.08937</a>",,2025-12-03 22:39:25
When are Non-Parametric Methods Robust?,"Robi Bhattacharjee, Kamalika Chaudhuri",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.06121"" target=""_blank"">2003.06121</a>",,2025-12-03 22:39:25
On the benefits of defining vicinal distributions in latent space,"Puneet Mangla, Vedant Singh, Shreyas Jayant Havaldar, Vineeth N Balasubramanian",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.06566"" target=""_blank"">2003.06566</a>",,2025-12-03 22:39:25
Dynamic Divide-and-Conquer Adversarial Training for Robust Semantic Segmentation,"Xiaogang Xu, Hengshuang Zhao, Jiaya Jia",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.06555"" target=""_blank"">2003.06555</a>",,2025-12-03 22:39:25
Minimum-Norm Adversarial Examples on KNN and KNN-Based Models,"Chawin Sitawarin, David Wagner",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.06559"" target=""_blank"">2003.06559</a>",,2025-12-03 22:39:25
Toward Adversarial Robustness via Semi-supervised Robust Training,"Yiming Li, Baoyuan Wu, Yan Feng, Yanbo Fan, Yong Jiang, Zhifeng Li, Shutao Xia",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.06974"" target=""_blank"">2003.06974</a>","<a href=""https://github.com/THUYimingLi/Semi-supervised_Robust_Training"" target=""_blank"">THUYimingLi</a>",2025-12-03 22:39:25
Towards Face Encryption by Generating Adversarial Identity Masks,"Xiao Yang, Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu, Yuefeng Chen, Hui Xue",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.06814"" target=""_blank"">2003.06814</a>",,2025-12-03 22:39:25
Anomalous Example Detection in Deep Learning: A Survey,"Saikiran Bulusu, Bhavya Kailkhura, Bo Li, Pramod K. Varshney, Dawn Song",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.06979"" target=""_blank"">2003.06979</a>",,2025-12-03 22:39:25
Certified Defenses for Adversarial Patches,"Ping-Yeh Chiang, Renkun Ni, Ahmed Abdelkader, Chen Zhu, Christoph Studer, Tom Goldstein",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.06693"" target=""_blank"">2003.06693</a>","<a href=""https://github.com/Ping-C/certifiedpatchdefense"" target=""_blank"">Ping-C</a>",2025-12-03 22:39:25
Topological Effects on Attacks Against Vertex Classification,"Benjamin A. Miller, Mustafa Çamurcu, Alexander J. Gomez, Kevin Chan, Tina Eliassi-Rad",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.05822"" target=""_blank"">2003.05822</a>",,2025-12-03 22:39:25
Heat and Blur: An Effective and Fast Defense Against Adversarial Examples,"Haya Brama, Tal Grinshpoun",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.07573"" target=""_blank"">2003.07573</a>",,2025-12-03 22:39:25
Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior,"Hu Zhang, Linchao Zhu, Yi Zhu, Yi Yang",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.07637"" target=""_blank"">2003.07637</a>",,2025-12-03 22:39:25
SAT: Improving Adversarial Training via Curriculum-Based Loss Smoothing,"Chawin Sitawarin, Supriyo Chakraborty, David Wagner",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.09347"" target=""_blank"">2003.09347</a>",,2025-12-03 22:39:25
Solving Non-Convex Non-Differentiable Min-Max Games using Proximal Gradient Method,"Babak Barazandeh, Meisam Razaviyayn",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.08093"" target=""_blank"">2003.08093</a>",,2025-12-03 22:39:25
Generating Socially Acceptable Perturbations for Efficient Evaluation of Autonomous Vehicles,"Songan Zhang, Huei Peng, Subramanya Nageshrao, H. Eric Tseng",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.08034"" target=""_blank"">2003.08034</a>",,2025-12-03 22:39:25
Vulnerabilities of Connectionist AI Applications: Evaluation and Defence,"Christian Berghoff, Matthias Neu, Twickel Arndt von",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.08837"" target=""_blank"">2003.08837</a>",,2025-12-03 22:39:25
Adversarial Transferability in Wearable Sensor Systems,"Ramesh Kumar Sah, Hassan Ghasemzadeh",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.07982"" target=""_blank"">2003.07982</a>",,2025-12-03 22:39:25
Overinterpretation reveals image classification model pathologies,"Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.08907"" target=""_blank"">2003.08907</a>",,2025-12-03 22:39:25
Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations,"Huan Zhang, Hongge Chen, Chaowei Xiao, Bo Li, Mingyan Liu, Duane Boning, Cho-Jui Hsieh",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.08938"" target=""_blank"">2003.08938</a>","<a href=""https://github.com/chenhongge/StateAdvDRL"" target=""_blank"">chenhongge</a>",2025-12-03 22:39:25
Face-Off: Adversarial Face Obfuscation,"Varun Chandrasekaran, Chuhan Gao, Brian Tang, Kassem Fawaz, Somesh Jha, Suman Banerjee",arXiv,2020-03,"<a href=""http://arxiv.org/abs/2003.08861"" target=""_blank"">2003.08861</a>",,2025-12-03 22:39:25
Graph Universal Adversarial Attacks: A Few Bad Actors Ruin Graph Learning Models,"Xiao Zang, Yi Xie, Jie Chen, Bo Yuan",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.04784"" target=""_blank"">2002.04784</a>",,2025-12-03 22:39:25
Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial Perturbations,"Florian Tramèr, Jens Behrmann, Nicholas Carlini, Nicolas Papernot, Jörn-Henrik Jacobsen",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.04599"" target=""_blank"">2002.04599</a>",,2025-12-03 22:39:25
Robustness of Bayesian Neural Networks to Gradient-Based Attacks,"Ginevra Carbone, Matthew Wicker, Luca Laurenti, Andrea Patane, Luca Bortolussi, Guido Sanguinetti",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.04359"" target=""_blank"">2002.04359</a>",,2025-12-03 22:39:25
Improving the affordability of robustness training for DNNs,"Sidharth Gupta, Parijat Dube, Ashish Verma",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.04237"" target=""_blank"">2002.04237</a>",,2025-12-03 22:39:25
Fast Geometric Projections for Local Robustness Certification,"Aymeric Fromherz, Klas Leino, Matt Fredrikson, Bryan Parno, Corina Păsăreanu",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.04742"" target=""_blank"">2002.04742</a>",,2025-12-03 22:39:25
Adversarial Data Encryption,"Yingdong Hu, Liang Zhang, Wei Shan, Xiaoxiao Qin, Jing Qi, Zhenzhou Wu, Yang Yuan",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.03793"" target=""_blank"">2002.03793</a>",,2025-12-03 22:39:25
More Data Can Expand the Generalization Gap Between Adversarially Robust and Standard Models,"Lin Chen, Yifei Min, Mingrui Zhang, Amin Karbasi",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.04725"" target=""_blank"">2002.04725</a>",,2025-12-03 22:39:25
Playing to Learn Better: Repeated Games for Adversarial Learning with Multiple Classifiers,"Prithviraj Dasgupta, Joseph B. Collins, Michael McCarrick",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.03924"" target=""_blank"">2002.03924</a>",,2025-12-03 22:39:25
Generalised Lipschitz Regularisation Equals Distributional Robustness,"Zac Cranko, Zhan Shi, Xinhua Zhang, Richard Nock, Simon Kornblith",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.04197"" target=""_blank"">2002.04197</a>",,2025-12-03 22:39:25
MDEA: Malware Detection with Evolutionary Adversarial Learning,"Xiruo Wang, Risto Miikkulainen",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.03331"" target=""_blank"">2002.03331</a>",,2025-12-03 22:39:25
Over-the-Air Adversarial Flickering Attacks against Video Recognition Networks,"Roi Pony, Itay Naeh, Shie Mannor",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.05123"" target=""_blank"">2002.05123</a>",,2025-12-03 22:39:25
Adversarial Robustness for Code,"Pavol Bielik, Martin Vechev",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.04694"" target=""_blank"">2002.04694</a>",,2025-12-03 22:39:25
Over-parameterized Adversarial Training: An Analysis Overcoming the Curse of Dimensionality,"Yi Zhang, Orestis Plevrakis, Simon S. Du, Xingguo Li, Zhao Song, Sanjeev Arora",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.06668"" target=""_blank"">2002.06668</a>",,2025-12-03 22:39:25
Stabilizing Differentiable Architecture Search via Perturbation-based Regularization,"Xiangning Chen, Cho-Jui Hsieh",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.05283"" target=""_blank"">2002.05283</a>",,2025-12-03 22:39:25
Identifying Audio Adversarial Examples via Anomalous Pattern Detection,"Victor Akinwande, Celia Cintas, Skyler Speakman, Srihari Sridharan",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.05463"" target=""_blank"">2002.05463</a>",,2025-12-03 22:39:25
The Conditional Entropy Bottleneck,Ian Fischer,arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.05379"" target=""_blank"">2002.05379</a>",,2025-12-03 22:39:25
Recurrent Attention Model with Log-Polar Mapping is Robust against Adversarial Attacks,"Taro Kiritani, Koji Ono",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.05388"" target=""_blank"">2002.05388</a>",,2025-12-03 22:39:25
Adversarial Distributional Training for Robust Deep Learning,"Yinpeng Dong, Zhijie Deng, Tianyu Pang, Hang Su, Jun Zhu",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.05999"" target=""_blank"">2002.05999</a>",,2025-12-03 22:39:25
Skip Connections Matter: On the Transferability of Adversarial Examples Generated with ResNets,"Dongxian Wu, Yisen Wang, Shu-Tao Xia, James Bailey, Xingjun Ma",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.05990"" target=""_blank"">2002.05990</a>",,2025-12-03 22:39:25
Blind Adversarial Network Perturbations,"Milad Nasr, Alireza Bahramali, Amir Houmansadr",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.06495"" target=""_blank"">2002.06495</a>",,2025-12-03 22:39:25
Hold me tight! Influence of discriminative features on deep network boundaries,"Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.06349"" target=""_blank"">2002.06349</a>",,2025-12-03 22:39:25
GRAPHITE: A Practical Framework for Generating Automatic Physical Adversarial Machine Learning Attacks,"Ryan Feng, Neal Mangaokar, Jiefeng Chen, Earlence Fernandes, Somesh Jha, Atul Prakash",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.07088"" target=""_blank"">2002.07088</a>",,2025-12-03 22:39:25
Regularized Training and Tight Certification for Randomized Smoothed Classifier with Provable Robustness,"Huijie Feng, Chunpeng Wu, Guoyang Chen, Weifeng Zhang, Yang Ning",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.07246"" target=""_blank"">2002.07246</a>",,2025-12-03 22:39:25
Robust Stochastic Bandit Algorithms under Probabilistic Unbounded Adversarial Attack,"Ziwei Guan, Kaiyi Ji, Donald J Jr Bucci, Timothy Y Hu, Joseph Palombo, Michael Liston, Yingbin Liang",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.07214"" target=""_blank"">2002.07214</a>",,2025-12-03 22:39:25
On the Matrix-Free Generation of Adversarial Perturbations for Black-Box Attacks,"Hisaichi Shibata, Shouhei Hanaoka, Yukihiro Nomura, Naoto Hayashi, Osamu Abe",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.07317"" target=""_blank"">2002.07317</a>",,2025-12-03 22:39:25
Watch out! Motion is Blurring the Vision of Your Deep Neural Networks,"Qing Guo, Felix Juefei-Xu, Xiaofei Xie, Lei Ma, Jian Wang, Bing Yu, Wei Feng, Yang Liu",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.03500"" target=""_blank"">2002.03500</a>","<a href=""https://github.com/tsingqguo/ABBA"" target=""_blank"">tsingqguo</a>",2025-12-03 22:39:25
Robust binary classification with the 01 loss,"Yunzhe Xue, Meiyan Xie, Usman Roshan",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.03444"" target=""_blank"">2002.03444</a>",,2025-12-03 22:39:25
Defending Adversarial Attacks via Semantic Feature Manipulation,"Shuo Wang, Tianle Chen, Surya Nepal, Carsten Rudolph, Marthie Grobler, Shangyu Chen",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.02007"" target=""_blank"">2002.02007</a>",,2025-12-03 22:39:25
Feature-level Malware Obfuscation in Deep Learning,Keith Dillon,arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.05517"" target=""_blank"">2002.05517</a>",,2025-12-03 22:39:25
Over-the-Air Adversarial Attacks on Deep Learning Based Modulation Classifier over Wireless Channels,"Brian Kim, Yalin E. Sagduyu, Kemal Davaslioglu, Tugba Erpek, Sennur Ulukus",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.02400"" target=""_blank"">2002.02400</a>",,2025-12-03 22:39:25
Weighted Average Precision: Adversarial Example Detection in the Visual Perception of Autonomous Vehicles,"Yilan Li, Senem Velipasalar",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.03751"" target=""_blank"">2002.03751</a>",,2025-12-03 22:39:25
FastWordBug: A Fast Method To Generate Adversarial Text Against NLP Applications,"Dou Goodman, Lv Zhonghou, Wang minghua",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.00760"" target=""_blank"">2002.00760</a>",,2025-12-03 22:39:25
Politics of Adversarial Machine Learning,"Kendra Albert, Jonathon Penney, Bruce Schneier, Ram Shankar Siva Kumar",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.05648"" target=""_blank"">2002.05648</a>",,2025-12-03 22:39:25
AdvJND: Generating Adversarial Examples with Just Noticeable Difference,"Zifei Zhang, Kai Qiao, Lingyun Jiang, Linyuan Wang, Bin Yan",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.00179"" target=""_blank"">2002.00179</a>",,2025-12-03 22:39:25
Towards Sharper First-Order Adversary with Quantized Gradients,"Zhuanghua Liu, Ivor W. Tsang",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.02372"" target=""_blank"">2002.02372</a>",,2025-12-03 22:39:25
Robust saliency maps with decoy-enhanced saliency score,"Yang Lu, Wenbo Guo, Xinyu Xing, William Stafford Noble",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.00526"" target=""_blank"">2002.00526</a>",,2025-12-03 22:39:25
Regularizers for Single-step Adversarial Training,"B. S. Vivek, R. Venkatesh Babu",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.00614"" target=""_blank"">2002.00614</a>",,2025-12-03 22:39:25
A Differentiable Color Filter for Generating Unrestricted Adversarial Images,"Zhengyu Zhao, Zhuoran Liu, Martha Larson",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.01008"" target=""_blank"">2002.01008</a>",,2025-12-03 22:39:25
Minimax Defense against Gradient-based Adversarial Attacks,"Blerta Lindqvist, Rauf Izmailov",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.01256"" target=""_blank"">2002.01256</a>",,2025-12-03 22:39:25
Adversarial Attacks to Scale-Free Networks: Testing the Robustness of Physical Criteria,"Qi Xuan, Yalu Shan, Jinhuan Wang, Zhongyuan Ruan, Guanrong Chen",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.01249"" target=""_blank"">2002.01249</a>",,2025-12-03 22:39:25
Adversarially Robust Frame Sampling with Bounded Irregularities,"Hanhan Li, Pin Wang",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.01147"" target=""_blank"">2002.01147</a>",,2025-12-03 22:39:25
Understanding the Decision Boundary of Deep Neural Networks: An Empirical Study,"David Mickisch, Felix Assion, Florens Greßner, Wiebke Günther, Mariele Motta",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.01810"" target=""_blank"">2002.01810</a>",,2025-12-03 22:39:25
AI-GAN: Attack-Inspired Generation of Adversarial Examples,"Tao Bai, Jun Zhao, Jinlin Zhu, Shoudong Han, Jiefeng Chen, Bo Li, Alex Kot",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.02196"" target=""_blank"">2002.02196</a>",,2025-12-03 22:39:25
Adversarial Deepfakes: Evaluating Vulnerability of Deepfake Detectors to Adversarial Examples,"Paarth Neekhara, Shehzeen Hussain, Malhar Jere, Farinaz Koushanfar, Julian McAuley",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.12749"" target=""_blank"">2002.12749</a>",,2025-12-03 22:39:25
Scalable Quantitative Verification For Deep Neural Networks,"Teodora Baluta, Zheng Leong Chua, Kuldeep S. Meel, Prateek Saxena",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.06864"" target=""_blank"">2002.06864</a>",,2025-12-03 22:39:25
Reliability Validation of Learning Enabled Vehicle Tracking,"Youcheng Sun, Yifan Zhou, Simon Maskell, James Sharp, Xiaowei Huang",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.02424"" target=""_blank"">2002.02424</a>",,2025-12-03 22:39:25
Semantic Robustness of Models of Source Code,"Goutham Ramakrishnan, Jordan Henkel, Zi Wang, Aws Albarghouthi, Somesh Jha, Thomas Reps",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.03043"" target=""_blank"">2002.03043</a>",,2025-12-03 22:39:25
Assessing the Adversarial Robustness of Monte Carlo and Distillation Methods for Deep Bayesian Neural Network Classification,"Meet P. Vadera, Satya Narayan Shukla, Brian Jalaian, Benjamin M. Marlin",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.02842"" target=""_blank"">2002.02842</a>",,2025-12-03 22:39:25
RAID: Randomized Adversarial-Input Detection for Neural Networks,"Hasan Ferit Eniser, Maria Christakis, Valentin Wüstholz",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.02776"" target=""_blank"">2002.02776</a>",,2025-12-03 22:39:25
Analysis of Random Perturbations for Robust Convolutional Neural Networks,"Adam Dziedzic, Sanjay Krishnan",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.03080"" target=""_blank"">2002.03080</a>",,2025-12-03 22:39:25
Renofeation: A Simple Transfer Learning Method for Improved Adversarial Robustness,"Ting-Wu Chin, Cha Zhang, Diana Marculescu",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.02998"" target=""_blank"">2002.02998</a>","<a href=""https://github.com/cmu-enyac/Renofeation"" target=""_blank"">cmu-enyac</a>",2025-12-03 22:39:25
Curse of Dimensionality on Randomized Smoothing for Certifiable Robustness,"Aounon Kumar, Alexander Levine, Tom Goldstein, Soheil Feizi",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.03239"" target=""_blank"">2002.03239</a>",,2025-12-03 22:39:25
Attacking Optical Character Recognition (OCR) Systems with Adversarial Watermarks,"Lu Chen, Wei Xu",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.03095"" target=""_blank"">2002.03095</a>",,2025-12-03 22:39:25
Input Validation for Neural Networks via Runtime Local Robustness Verification,"Jiangchao Liu, Liqian Chen, Antoine Mine, Ji Wang",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.03339"" target=""_blank"">2002.03339</a>",,2025-12-03 22:39:25
Random Smoothing Might be Unable to Certify $\ell_\infty$ Robustness for High-Dimensional Images,"Avrim Blum, Travis Dick, Naren Manoj, Hongyang Zhang",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.03517"" target=""_blank"">2002.03517</a>",,2025-12-03 22:39:25
Certified Robustness of Community Detection against Adversarial Structural Perturbation via Randomized Smoothing,"Jinyuan Jia, Binghui Wang, Xiaoyu Cao, Neil Zhenqiang Gong",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.03421"" target=""_blank"">2002.03421</a>",,2025-12-03 22:39:25
CAT: Customized Adversarial Training for Improved Robustness,"Minhao Cheng, Qi Lei, Pin-Yu Chen, Inderjit Dhillon, Cho-Jui Hsieh",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.06789"" target=""_blank"">2002.06789</a>",,2025-12-03 22:39:25
An Analysis of Adversarial Attacks and Defenses on Autonomous Driving Models,"Yao Deng, Xi Zheng, Tianyi Zhang, Chen Chen, Guannan Lou, Miryung Kim",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.02175"" target=""_blank"">2002.02175</a>",,2025-12-03 22:39:25
On the Similarity of Deep Learning Representations Across Didactic and Adversarial Examples,"Pamela K. Douglas, Farzad Vasheghani Farahani",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.06816"" target=""_blank"">2002.06816</a>",,2025-12-03 22:39:25
HYDRA: Pruning Adversarially Robust Neural Networks,"Vikash Sehwag, Shiqi Wang, Prateek Mittal, Suman Jana",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.10509"" target=""_blank"">2002.10509</a>","<a href=""https://github.com/inspire-group/compactness-robustness"" target=""_blank"">inspire-group</a>",2025-12-03 22:39:25
Towards Rapid and Robust Adversarial Training with One-Step Attacks,"Leo Schwinn, René Raab, Björn Eskofier",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.10097"" target=""_blank"">2002.10097</a>",,2025-12-03 22:39:25
Utilizing a null class to restrict decision spaces and defend against neural network adversarial attacks,Matthew J. Roos,arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.10084"" target=""_blank"">2002.10084</a>","<a href=""https://github.com/mattroos/null_class_adversarial_defense"" target=""_blank"">mattroos</a>",2025-12-03 22:39:25
A Model-Based Derivative-Free Approach to Black-Box Adversarial Examples: BOBYQA,"Giuseppe Ughi, Vinayak Abrol, Jared Tanner",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.10349"" target=""_blank"">2002.10349</a>",,2025-12-03 22:39:25
Adversarial Ranking Attack and Defense,"Mo Zhou, Zhenxing Niu, Le Wang, Qilin Zhang, Gang Hua",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.11293"" target=""_blank"">2002.11293</a>",,2025-12-03 22:39:25
Attacks Which Do Not Kill Training Make Adversarial Learning Stronger,"Jingfeng Zhang, Xilie Xu, Bo Han, Gang Niu, Lizhen Cui, Masashi Sugiyama, Mohan Kankanhalli",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.11242"" target=""_blank"">2002.11242</a>",,2025-12-03 22:39:25
(De)Randomized Smoothing for Certifiable Defense against Patch Attacks,"Alexander Levine, Soheil Feizi",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.10733"" target=""_blank"">2002.10733</a>","<a href=""https://github.com/alevine0/patchSmoothing"" target=""_blank"">alevine0</a>",2025-12-03 22:39:25
Towards an Efficient and General Framework of Robust Training for Graph Neural Networks,"Kaidi Xu, Sijia Liu, Pin-Yu Chen, Mengshu Sun, Caiwen Ding, Bhavya Kailkhura, Xue Lin",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.10947"" target=""_blank"">2002.10947</a>",,2025-12-03 22:39:25
"G\""odel's Sentence Is An Adversarial Example But Unsolvable","Xiaodong Qi, Lansheng Han",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.10703"" target=""_blank"">2002.10703</a>",,2025-12-03 22:39:25
"The Curious Case of Adversarially Robust Models: More Data Can Help, Double Descend, or Hurt Generalization","Yifei Min, Lin Chen, Amin Karbasi",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.11080"" target=""_blank"">2002.11080</a>",,2025-12-03 22:39:25
Understanding and Mitigating the Tradeoff Between Robustness and Accuracy,"Aditi Raghunathan, Sang Michael Xie, Fanny Yang, John Duchi, Percy Liang",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.10716"" target=""_blank"">2002.10716</a>",,2025-12-03 22:39:25
Learning Adversarially Robust Representations via Worst-Case Mutual Information Maximization,"Sicheng Zhu, Xiao Zhang, David Evans",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.11798"" target=""_blank"">2002.11798</a>",,2025-12-03 22:39:25
Adversarial Attack on Deep Product Quantization Network for Image Retrieval,"Yan Feng, Bin Chen, Tao Dai, Shutao Xia",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.11374"" target=""_blank"">2002.11374</a>",,2025-12-03 22:39:25
Defense-PointNet: Protecting PointNet Against Adversarial Attacks,"Yu Zhang, Gongbo Liang, Tawfiq Salem, Nathan Jacobs",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.11881"" target=""_blank"">2002.11881</a>",,2025-12-03 22:39:25
Improving Robustness of Deep-Learning-Based Image Reconstruction,"Ankit Raj, Yoram Bresler, Bo Li",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.11821"" target=""_blank"">2002.11821</a>",,2025-12-03 22:39:25
MGA: Momentum Gradient Attack on Network,"Jinyin Chen, Yixian Chen, Haibin Zheng, Shijing Shen, Shanqing Yu, Dan Zhang, Qi Xuan",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.11320"" target=""_blank"">2002.11320</a>",,2025-12-03 22:39:25
Overfitting in adversarially robust deep learning,"Leslie Rice, Eric Wong, J. Zico Kolter",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.11569"" target=""_blank"">2002.11569</a>","<a href=""https://github.com/locuslab/robust_overfitting"" target=""_blank"">locuslab</a>",2025-12-03 22:39:25
Invariance vs,"Sandesh Kamath, Amit Deshpande, K V Subrahmanyam",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.11318"" target=""_blank"">2002.11318</a>",,2025-12-03 22:39:25
Revisiting Ensembles in an Adversarial Context: Improving Natural Accuracy,"Aditya Saligrama, Guillaume Leclerc",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.11572"" target=""_blank"">2002.11572</a>",,2025-12-03 22:39:25
FMix: Enhancing Mixed Sample Data Augmentation,"Ethan Harris, Antonia Marcu, Matthew Painter, Mahesan Niranjan, Adam Prügel-Bennett, Jonathon Hare",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.12047"" target=""_blank"">2002.12047</a>","<a href=""https://github.com/ecs-vlc/FMix"" target=""_blank"">ecs-vlc</a>",2025-12-03 22:39:25
Utilizing Network Properties to Detect Erroneous Inputs,"Matt Gorbett, Nathaniel Blanchard",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.12520"" target=""_blank"">2002.12520</a>",,2025-12-03 22:39:25
On Isometry Robustness of Deep 3D Point Cloud Models under Adversarial Attacks,"Yue Zhao, Yuwei Wu, Caihua Chen, Andrew Lim",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.12222"" target=""_blank"">2002.12222</a>",,2025-12-03 22:39:25
TSS: Transformation-Specific Smoothing for Robustness Certification,"Linyi Li, Maurice Weber, Xiaojun Xu, Luka Rimanic, Bhavya Kailkhura, Tao Xie, Ce Zhang, Bo Li",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.12398"" target=""_blank"">2002.12398</a>",,2025-12-03 22:39:25
Are L2 adversarial examples intrinsically different?,"Mingxuan Li, Jingyuan Wang, Yufan Wu",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.12527"" target=""_blank"">2002.12527</a>",,2025-12-03 22:39:25
Certified Defense to Image Transformations via Randomized Smoothing,"Marc Fischer, Maximilian Baader, Martin Vechev",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.12463"" target=""_blank"">2002.12463</a>","<a href=""https://github.com/eth-sri/transformation-smoothing"" target=""_blank"">eth-sri</a>",2025-12-03 22:39:25
Detecting Patch Adversarial Attacks with Image Residuals,"Marius Arvinte, Ahmed Tewfik, Sriram Vishwanath",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.12504"" target=""_blank"">2002.12504</a>",,2025-12-03 22:39:25
TensorShield: Tensor-based Defense Against Adversarial Attacks on Images,"Negin Entezari, Evangelos E. Papalexakis",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.10252"" target=""_blank"">2002.10252</a>",,2025-12-03 22:39:25
Applying Tensor Decomposition to image for Robustness against Adversarial Attack,"Seungju Cho, Tae Joon Jun, Mingu Kang, Daeyoung Kim",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.12913"" target=""_blank"">2002.12913</a>",,2025-12-03 22:39:25
Precise Tradeoffs in Adversarial Training for Linear Regression,"Adel Javanmard, Mahdi Soltanolkotabi, Hamed Hassani",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.10477"" target=""_blank"">2002.10477</a>",,2025-12-03 22:39:25
Randomization matters,"Rafael Pinot, Raphael Ettedgui, Geovani Rizk, Yann Chevaleyre, Jamal Atif",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.11565"" target=""_blank"">2002.11565</a>",,2025-12-03 22:39:25
Adversarial Attack on DL-based Massive MIMO CSI Feedback,"Qing Liu, Jiajia Guo, Chao-Kai Wen, Shi Jin",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.09896"" target=""_blank"">2002.09896</a>",,2025-12-03 22:39:25
A Bayes-Optimal View on Adversarial Examples,"Eitan Richardson, Yair Weiss",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.08859"" target=""_blank"">2002.08859</a>",,2025-12-03 22:39:25
Block Switching: A Stochastic Approach for Deep Learning Security,"Xiao Wang, Siyue Wang, Pin-Yu Chen, Xue Lin, Peter Chin",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.07920"" target=""_blank"">2002.07920</a>",,2025-12-03 22:39:25
Towards Query-Efficient Black-Box Adversary with Zeroth-Order Natural Gradient Descent,"Pu Zhao, Pin-Yu Chen, Siyue Wang, Xue Lin",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.07891"" target=""_blank"">2002.07891</a>",,2025-12-03 22:39:25
"Triple Wins: Boosting Accuracy, Robustness and Efficiency Together by Enabling Input-Adaptive Inference","Ting-Kuei Hu, Tianlong Chen, Haotao Wang, Zhangyang Wang",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.10025"" target=""_blank"">2002.10025</a>",,2025-12-03 22:39:25
Action-Manipulation Attacks Against Stochastic Bandits: Attacks and Defense,"Guanlin Liu, Lifeng lai",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.08000"" target=""_blank"">2002.08000</a>",,2025-12-03 22:39:25
Randomized Smoothing of All Shapes and Sizes,"Greg Yang, Tony Duan, J. Edward Hu, Hadi Salman, Ilya Razenshteyn, Jerry Li",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.08118"" target=""_blank"">2002.08118</a>",,2025-12-03 22:39:25
Indirect Adversarial Attacks via Poisoning Neighbors for Graph Convolutional Networks,Tsubasa Takahashi,arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.08012"" target=""_blank"">2002.08012</a>",,2025-12-03 22:39:25
On Adaptive Attacks to Adversarial Example Defenses,"Florian Tramer, Nicholas Carlini, Wieland Brendel, Aleksander Madry",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.08347"" target=""_blank"">2002.08347</a>",,2025-12-03 22:39:25
NAttack! Adversarial Attacks to bypass a GAN based classifier trained to detect Network intrusion,"Aritran Piplai, Sai Sree Laya Chukkapalli, Anupam Joshi",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.08527"" target=""_blank"">2002.08527</a>",,2025-12-03 22:39:25
AdvMS: A Multi-source Multi-cost Defense Against Adversarial Attacks,"Xiao Wang, Siyue Wang, Pin-Yu Chen, Xue Lin, Peter Chin",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.08439"" target=""_blank"">2002.08439</a>",,2025-12-03 22:39:25
Bayes-TrEx: Model Transparency by Example,"Serena Booth, Yilun Zhou, Ankit Shah, Julie Shah",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.10248"" target=""_blank"">2002.10248</a>",,2025-12-03 22:39:25
Byzantine-resilient Decentralized Stochastic Gradient Descent,"Shangwei Guo, Tianwei Zhang, Han Yu, Xiaofei Xie, Lei Ma, Tao Xiang, Yang Liu",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.08569"" target=""_blank"">2002.08569</a>",,2025-12-03 22:39:25
Boosting Adversarial Training with Hypersphere Embedding,"Tianyu Pang, Xiao Yang, Yinpeng Dong, Kun Xu, Hang Su, Jun Zhu",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.08619"" target=""_blank"">2002.08619</a>",,2025-12-03 22:39:25
Towards Certifiable Adversarial Sample Detection,"Ilia Shumailov, Yiren Zhao, Robert Mullins, Ross Anderson",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.08740"" target=""_blank"">2002.08740</a>",,2025-12-03 22:39:25
Deflecting Adversarial Attacks,"Yao Qin, Nicholas Frosst, Colin Raffel, Garrison Cottrell, Geoffrey Hinton",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.07405"" target=""_blank"">2002.07405</a>",,2025-12-03 22:39:25
On the Decision Boundaries of Deep Neural Networks: A Tropical Geometry Perspective,"Motasem Alfarra, Adel Bibi, Hasan Hammoud, Mohamed Gaafar, Bernard Ghanem",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.08838"" target=""_blank"">2002.08838</a>",,2025-12-03 22:39:25
Adversarial Detection and Correction by Matching Prediction Distributions,"Giovanni Vacanti, Looveren Arnaud Van",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.09364"" target=""_blank"">2002.09364</a>",,2025-12-03 22:39:25
Temporal Sparse Adversarial Attack on Sequence-based Gait Recognition,"Ziwen He, Wei Wang, Jing Dong, Tieniu Tan",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.09674"" target=""_blank"">2002.09674</a>",,2025-12-03 22:39:25
Non-Intrusive Detection of Adversarial Deep Learning Attacks via Observer Networks,"Kirthi Shankar Sivamani, Rajeev Sahay, Aly El Gamal",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.09772"" target=""_blank"">2002.09772</a>",,2025-12-03 22:39:25
Real-Time Detectors for Digital and Physical Adversarial Inputs to Perception Systems,"Yiannis Kantaros, Taylor Carpenter, Kaustubh Sridhar, Yahan Yang, Insup Lee, James Weimer",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.09792"" target=""_blank"">2002.09792</a>",,2025-12-03 22:39:25
Using Single-Step Adversarial Training to Defend Iterative Adversarial Examples,"Guanxiong Liu, Issa Khalil, Abdallah Khreishah",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.09632"" target=""_blank"">2002.09632</a>",,2025-12-03 22:39:25
Robustness from Simple Classifiers,"Sharon Qian, Dimitris Kalimeris, Gal Kaplun, Yaron Singer",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.09422"" target=""_blank"">2002.09422</a>",,2025-12-03 22:39:25
Polarizing Front Ends for Robust CNNs,"Can Bakiskan, Soorya Gopalakrishnan, Metehan Cekic, Upamanyu Madhow, Ramtin Pedarsani",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.09580"" target=""_blank"">2002.09580</a>",,2025-12-03 22:39:25
UnMask: Adversarial Detection and Defense Through Robust Feature Alignment,"Scott Freitas, Shang-Tse Chen, Zijie J. Wang, Duen Horng Chau",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.09576"" target=""_blank"">2002.09576</a>","<a href=""https://github.com/safreita1/unmask"" target=""_blank"">safreita1</a>",2025-12-03 22:39:25
Robustness to Programmable String Transformations via Augmented Abstract Training,"Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.09579"" target=""_blank"">2002.09579</a>",,2025-12-03 22:39:25
Black-Box Certification with Randomized Smoothing: A Functional Optimization Based Framework,"Dinghuai Zhang, Mao Ye, Chengyue Gong, Zhanxing Zhu, Qiang Liu",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.09169"" target=""_blank"">2002.09169</a>",,2025-12-03 22:39:25
Adversarial Attacks on Machine Learning Systems for High-Frequency Trading,"Micah Goldblum, Avi Schwarzschild, Ankit B. Patel, Tom Goldstein",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.09565"" target=""_blank"">2002.09565</a>",,2025-12-03 22:39:25
Enhanced Adversarial Strategically-Timed Attacks against Deep Reinforcement Learning,"Chao-Han Huck Yang, Jun Qi, Pin-Yu Chen, Yi Ouyang, I-Te Danny Hung, Chin-Hui Lee, Xiaoli Ma",arXiv,2020-02,"<a href=""http://arxiv.org/abs/2002.09027"" target=""_blank"">2002.09027</a>",,2025-12-03 22:39:25
Fast is better than free: Revisiting adversarial training,"Eric Wong, Leslie Rice, J. Zico Kolter",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.03994"" target=""_blank"">2001.03994</a>","<a href=""https://github.com/locuslab/fast_adversarial"" target=""_blank"">locuslab</a>",2025-12-03 22:39:25
ReluDiff: Differential Verification of Deep Neural Networks,"Brandon Paulsen, Jingbo Wang, Chao Wang",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.03662"" target=""_blank"">2001.03662</a>",,2025-12-03 22:39:25
Sparse Black-box Video Attack with Reinforcement Learning,"Huanqian Yan, Xingxing Wei, Bo Li",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.03754"" target=""_blank"">2001.03754</a>",,2025-12-03 22:39:25
Exploring and Improving Robustness of Multi Task Deep Neural Networks via Domain Agnostic Defenses,Kashyap Coimbatore Murali,arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.05286"" target=""_blank"">2001.05286</a>",,2025-12-03 22:39:25
Guess First to Enable Better Compression and Adversarial Robustness,"Sicheng Zhu, Bang An, Shiyu Niu",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.03311"" target=""_blank"">2001.03311</a>",,2025-12-03 22:39:25
Increasing the robustness of DNNs against image corruptions by playing the Game of Noise,"Evgenia Rusak, Lukas Schott, Roland S. Zimmermann, Julian Bitterwolf, Oliver Bringmann, Matthias Bethge, Wieland Brendel",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.06057"" target=""_blank"">2001.06057</a>",,2025-12-03 22:39:25
An Adversarial Approach for the Robust Classification of Pneumonia from Chest Radiographs,"Joseph D. Janizek, Gabriel Erion, Alex J. DeGrave, Su-In Lee",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.04051"" target=""_blank"">2001.04051</a>","<a href=""https://github.com/suinleelab/cxr_adv"" target=""_blank"">suinleelab</a>",2025-12-03 22:39:25
Membership Inference Attacks Against Object Detection Models,"Yeachan Park, Myungjoo Kang",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.04011"" target=""_blank"">2001.04011</a>",,2025-12-03 22:39:25
Advbox: a toolbox to generate adversarial examples that fool neural networks,"Dou Goodman, Hao Xin, Wang Yang, Wu Yuesheng, Xiong Junfeng, Zhang Huan",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.05574"" target=""_blank"">2001.05574</a>","<a href=""https://github.com/advboxes/AdvBox"" target=""_blank"">advboxes</a>",2025-12-03 22:39:25
Noisy Machines: Understanding Noisy Neural Networks and Enhancing Robustness to Analog Hardware Errors Using Distillation,"Chuteng Zhou, Prad Kadambi, Matthew Mattina, Paul N. Whatmough",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.04974"" target=""_blank"">2001.04974</a>",,2025-12-03 22:39:25
Universal Adversarial Attack on Attention and the Resulting Dataset DAmageNet,"Sizhe Chen, Zhengbao He, Chengjin Sun, Jie Yang, Xiaolin Huang",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.06325"" target=""_blank"">2001.06325</a>",,2025-12-03 22:39:25
The gap between theory and practice in function approximation with deep neural networks,"Ben Adcock, Nick Dexter",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.07523"" target=""_blank"">2001.07523</a>",,2025-12-03 22:39:25
To Transfer or Not to Transfer: Misclassification Attacks Against Transfer Learned Text Classifiers,"Bijeeta Pal, Shruti Tople",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.02438"" target=""_blank"">2001.02438</a>",,2025-12-03 22:39:25
The Human Visual System and Adversarial AI,"Yaoshiang Ho, Samuel Wookey",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.01172"" target=""_blank"">2001.01172</a>",,2025-12-03 22:39:25
MACER: Attack-free and Scalable Robust Training via Maximizing Certified Radius,"Runtian Zhai, Chen Dan, Di He, Huan Zhang, Boqing Gong, Pradeep Ravikumar, Cho-Jui Hsieh, Liwei Wang",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.02378"" target=""_blank"">2001.02378</a>",,2025-12-03 22:39:25
Transferability of Adversarial Examples to Attack Cloud-based Image Classifier Service,Dou Goodman,arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.03460"" target=""_blank"">2001.03460</a>",,2025-12-03 22:39:25
"Softmax-based Classification is k-means Clustering: Formal Proof, Consequences for Adversarial Attacks, and Improvement through Centroid Based Tailoring","Sibylle Hess, Wouter Duivesteijn, Decebal Mocanu",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.01987"" target=""_blank"">2001.01987</a>",,2025-12-03 22:39:25
Deceiving Image-to-Image Translation Networks for Autonomous Driving with Adversarial Perturbations,"Lin Wang, Wonjune Cho, Kuk-Jin Yoon",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.01506"" target=""_blank"">2001.01506</a>",,2025-12-03 22:39:25
Generating Semantic Adversarial Examples via Feature Manipulation,"Shuo Wang, Surya Nepal, Carsten Rudolph, Marthie Grobler, Shangyu Chen, Tianle Chen",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.02297"" target=""_blank"">2001.02297</a>",,2025-12-03 22:39:25
Reject Illegal Inputs with Generative Classifier Derived from Any Discriminative Classifier,Xin Wang,arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.00483"" target=""_blank"">2001.00483</a>",,2025-12-03 22:39:25
Exploring Adversarial Attack in Spiking Neural Networks with Spike-Compatible Gradient,"Ling Liang, Xing Hu, Lei Deng, Yujie Wu, Guoqi Li, Yufei Ding, Peng Li, Yuan Xie",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.01587"" target=""_blank"">2001.01587</a>",,2025-12-03 22:39:25
Ensembles of Many Diverse Weak Defenses can be Strong: Defending Deep Neural Networks Against Adversarial Attacks,"Ying Meng, Jianhai Su, Jason O'Kane, Pooyan Jamshidi",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.00308"" target=""_blank"">2001.00308</a>",,2025-12-03 22:39:25
Protecting GANs against privacy attacks by preventing overfitting,"Sumit Mukherjee, Yixi Xu, Anusua Trivedi, Juan Lavista Ferres",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.00071"" target=""_blank"">2001.00071</a>",,2025-12-03 22:39:25
"Erase and Restore: Simple, Accurate and Resilient Detection of $L_2$ Adversarial Examples","Fei Zuo, Qiang Zeng",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.00116"" target=""_blank"">2001.00116</a>",,2025-12-03 22:39:25
Quantum Adversarial Machine Learning,"Sirui Lu, Lu-Ming Duan, Dong-Ling Deng",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.00030"" target=""_blank"">2001.00030</a>",,2025-12-03 22:39:25
Adversarial Example Generation using Evolutionary Multi-objective Optimization,"Takahiro Suzuki, Shingo Takeshita, Satoshi Ono",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.05844"" target=""_blank"">2001.05844</a>",,2025-12-03 22:39:25
Code-Bridged Classifier (CBC): A Low or Negative Overhead Defense for Making a CNN Classifier Robust Against Adversarial Attacks,"Farnaz Behnia, Ali Mirzaeian, Mohammad Sabokrou, Sai Manoj, Tinoosh Mohsenin, Khaled N. Khasawneh, Liang Zhao, Houman Homayoun, Avesta Sasan",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.06099"" target=""_blank"">2001.06099</a>",,2025-12-03 22:39:25
A Little Fog for a Large Turn,"Harshitha Machiraju, Vineeth N Balasubramanian",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.05873"" target=""_blank"">2001.05873</a>",,2025-12-03 22:39:25
Privacy for All: Demystify Vulnerability Disparity of Differential Privacy against Membership Inference Attack,"Bo Zhang, Ruotong Yu, Haipei Sun, Yanying Li, Jun Xu, Hui Wang",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.08855"" target=""_blank"">2001.08855</a>",,2025-12-03 22:39:25
Cyber Attack Detection thanks to Machine Learning Algorithms,"Antoine Delplace, Sheryl Hermoso, Kristofer Anandita",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.06309"" target=""_blank"">2001.06309</a>",,2025-12-03 22:39:25
Ensemble Noise Simulation to Handle Uncertainty about Gradient-based Adversarial Attacks,"Rehana Mahfuz, Rajeev Sahay, Aly El Gamal",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.09486"" target=""_blank"">2001.09486</a>",,2025-12-03 22:39:25
Elephant in the Room: An Evaluation Framework for Assessing Adversarial Examples in NLP,"Ying Xu, Xu Zhong, Antonio Jose Jimeno Yepes, Jey Han Lau",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.07820"" target=""_blank"">2001.07820</a>",,2025-12-03 22:39:25
Additive Tree Ensembles: Reasoning About Potential Instances,"Laurens Devos, Wannes Meert, Jesse Davis",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.11905"" target=""_blank"">2001.11905</a>",,2025-12-03 22:39:25
Tiny Noise Can Make an EEG-Based Brain-Computer Interface Speller Output Anything,"Xiao Zhang, Dongrui Wu, Lieyun Ding, Hanbin Luo, Chin-Teng Lin, Tzyy-Ping Jung, Ricardo Chavarriaga",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.11569"" target=""_blank"">2001.11569</a>",,2025-12-03 22:39:25
A4 : Evading Learning-based Adblockers,"Shitong Zhu, Zhongjie Wang, Xun Chen, Shasha Li, Umar Iqbal, Zhiyun Qian, Kevin S. Chan, Srikanth V. Krishnamurthy, Zubair Shafiq",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.10999"" target=""_blank"">2001.10999</a>",,2025-12-03 22:39:25
D2M: Dynamic Defense and Modeling of Adversarial Movement in Networks,"Scott Freitas, Andrew Wicker, Duen Horng Chau, Joshua Neil",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.11108"" target=""_blank"">2001.11108</a>",,2025-12-03 22:39:25
Just Noticeable Difference for Machines to Generate Adversarial Images,"Adil Kaan Akan, Mehmet Ali Genc, Fatos T. Yarman Vural",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.11064"" target=""_blank"">2001.11064</a>",,2025-12-03 22:39:25
Adversarial Attacks on Convolutional Neural Networks in Facial Recognition Domain,"Yigit Alparslan, Ken Alparslan, Jeremy Keim-Shenk, Shweta Khade, Rachel Greenstadt",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.11137"" target=""_blank"">2001.11137</a>",,2025-12-03 22:39:25
Modelling and Quantifying Membership Information Leakage in Machine Learning,"Farhad Farokhi, Mohamed Ali Kaafar",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.10648"" target=""_blank"">2001.10648</a>",,2025-12-03 22:39:25
Interpreting Machine Learning Malware Detectors Which Leverage N-gram Analysis,"William Briguglio, Sherif Saad",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.10916"" target=""_blank"">2001.10916</a>",,2025-12-03 22:39:25
Generating Natural Adversarial Hyperspectral examples with a modified Wasserstein GAN,"Jean-Christophe OBELIX Burnel, Kilian OBELIX Fatras, Nicolas OBELIX Courty",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.09993"" target=""_blank"">2001.09993</a>",,2025-12-03 22:39:25
FakeLocator: Robust Localization of GAN-Based Face Manipulations via Semantic Segmentation Networks with Bells and Whistles,"Yihao Huang, Felix Juefei-Xu, Run Wang, Xiaofei Xie, Lei Ma, Jianwen Li, Weikai Miao, Yang Liu, Geguang Pu",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.09598"" target=""_blank"">2001.09598</a>",,2025-12-03 22:39:25
Challenges and Countermeasures for Adversarial Attacks on Deep Reinforcement Learning,"Inaam Ilahi, Muhammad Usama, Junaid Qadir, Muhammad Umar Janjua, Ala Al-Fuqaha, Dinh Thai Hoang, Dusit Niyato",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.09684"" target=""_blank"">2001.09684</a>",,2025-12-03 22:39:25
Practical Fast Gradient Sign Attack against Mammographic Image Classifier,Ibrahim Yilmaz,arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.09610"" target=""_blank"">2001.09610</a>",,2025-12-03 22:39:25
Semantic Adversarial Perturbations using Learnt Representations,"Isaac Dunn, Tom Melham, Daniel Kroening",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.11055"" target=""_blank"">2001.11055</a>",,2025-12-03 22:39:25
AI-Powered GUI Attack and Its Defensive Methods,"Ning Yu, Zachary Tuttle, Carl Jake Thurnau, Emmanuel Mireku",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.09388"" target=""_blank"">2001.09388</a>",,2025-12-03 22:39:25
SAUNet: Shape Attentive U-Net for Interpretable Medical Image Segmentation,"Jesse Sun, Fatemeh Darbeha, Mark Zaidi, Bo Wang",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.07645"" target=""_blank"">2001.07645</a>",,2025-12-03 22:39:25
Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning,"Nilaksh Polo Das, Haekyu Polo Park, Zijie J. Polo Wang, Fred Polo Hohman, Robert Polo Firstman, Emily Polo Rogers, Duen Polo Horng, Chau",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.07769"" target=""_blank"">2001.07769</a>",,2025-12-03 22:39:25
Analyzing the Noise Robustness of Deep Neural Networks,"Kelei Cao, Mengchen Liu, Hang Su, Jing Wu, Jun Zhu, Shixia Liu",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.09395"" target=""_blank"">2001.09395</a>",,2025-12-03 22:39:25
Generate High-Resolution Adversarial Samples by Identifying Effective Features,"Sizhe Chen, Peidong Zhang, Chengjin Sun, Jia Cai, Xiaolin Huang",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.07631"" target=""_blank"">2001.07631</a>",,2025-12-03 22:39:25
GhostImage: Perception Domain Attacks against Vision-based Object Classification Systems,"Yanmao Man, Ming Li, Ryan Gerdes",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.07792"" target=""_blank"">2001.07792</a>",,2025-12-03 22:39:25
Secure and Robust Machine Learning for Healthcare: A Survey,"Adnan Qayyum, Junaid Qadir, Muhammad Bilal, Ala Al-Fuqaha",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.08103"" target=""_blank"">2001.08103</a>",,2025-12-03 22:39:25
FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,"Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas Carlini, Ekin D. Cubuk, Alex Kurakin, Han Zhang, Colin Raffel",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.07685"" target=""_blank"">2001.07685</a>","<a href=""https://github.com/google-research/fixmatch"" target=""_blank"">google-research</a>",2025-12-03 22:39:25
Adversarial Attack on Community Detection by Hiding Individuals,"Jia Li, Honglei Zhang, Zhichao Han, Yu Rong, Hong Cheng, Junzhou Huang",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.07933"" target=""_blank"">2001.07933</a>",,2025-12-03 22:39:25
On the human evaluation of audio adversarial examples,"Jon Vadillo, Roberto Santana",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.08444"" target=""_blank"">2001.08444</a>",,2025-12-03 22:39:25
Towards Robust DNNs: An Taylor Expansion-Based Method for Generating Powerful Adversarial Examples,"Ya-guan Qian, Xi-Ming Zhang, Bin Wang, Wei Li, Jian-Hai Chen, Wu-Jie Zhou, Jing-Sheng Lei",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.08389"" target=""_blank"">2001.08389</a>",,2025-12-03 22:39:25
"When Wireless Security Meets Machine Learning: Motivation, Challenges, and Research Directions","Yalin E. Sagduyu, Yi Shi, Tugba Erpek, William Headley, Bryse Flowers, George Stantchev, Zhuo Lu",arXiv,2020-01,"<a href=""http://arxiv.org/abs/2001.08883"" target=""_blank"">2001.08883</a>",,2025-12-03 22:39:25
Achieving Robustness in the Wild via Adversarial Mixing with Disentangled Representations,"Sven Gowal, Chongli Qin, Po-Sen Huang, Taylan Cemgil, Krishnamurthy Dvijotham, Timothy Mann, Pushmeet Kohli",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.03192"" target=""_blank"">1912.03192</a>",,2025-12-03 22:39:25
Training Provably Robust Models by Polyhedral Envelope Regularization,"Chen Liu, Mathieu Salzmann, Sabine Süsstrunk",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.04792"" target=""_blank"">1912.04792</a>",,2025-12-03 22:39:25
Exploring the Back Alleys: Analysing The Robustness of Alternative Neural Network Architectures against Adversarial Attacks,"Yi Xiang Marcus Tan, Yuval Elovici, Alexander Binder",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.03609"" target=""_blank"">1912.03609</a>",,2025-12-03 22:39:25
Amora: Black-box Adversarial Morphing Attack,"Run Wang, Felix Juefei-Xu, Xiaofei Xie, Lei Ma, Yihao Huang, Yang Liu",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.03829"" target=""_blank"">1912.03829</a>",,2025-12-03 22:39:25
Principal Component Properties of Adversarial Samples,"Malhar Jere, Sandro Herbig, Christine Lind, Farinaz Koushanfar",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.03406"" target=""_blank"">1912.03406</a>",,2025-12-03 22:39:25
Hardening Random Forest Cyber Detectors Against Adversarial Attacks,"Giovanni Apruzzese, Mauro Andreolini, Michele Colajanni, Mirco Marchetti",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.03790"" target=""_blank"">1912.03790</a>",,2025-12-03 22:39:25
Feature Losses for Adversarial Robustness,Kirthi Shankar Sivamani,arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.04497"" target=""_blank"">1912.04497</a>",,2025-12-03 22:39:25
Statistically Robust Neural Network Classification,"Benjie Wang, Stefan Webb, Tom Rainforth",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.04884"" target=""_blank"">1912.04884</a>",,2025-12-03 22:39:25
An Efficient Approach for Using Expectation Maximization Algorithm in Capsule Networks,"Moein Hasani, Amin Nasim Saravi, Hassan Khotanlou",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.05333"" target=""_blank"">1912.05333</a>",,2025-12-03 22:39:25
Appending Adversarial Frames for Universal Video Attack,"Zhikai Chen, Lingxi Xie, Shanmin Pang, Yong He, Qi Tian",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.04538"" target=""_blank"">1912.04538</a>",,2025-12-03 22:39:25
Towards a Robust Classifier: An MDL-Based Method for Generating Adversarial Examples,"Behzad Asadi, Vijay Varadharajan",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.05945"" target=""_blank"">1912.05945</a>",,2025-12-03 22:39:25
What it Thinks is Important is Important: Robustness Transfers through Input Gradients,"Alvin Chan, Yi Tay, Yew-Soon Ong",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.05699"" target=""_blank"">1912.05699</a>",,2025-12-03 22:39:25
Detecting and Correcting Adversarial Images Using Image Processing Operations and Convolutional Neural Networks,"Huy H. Nguyen, Minoru Kuribayashi, Junichi Yamagishi, Isao Echizen",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.05391"" target=""_blank"">1912.05391</a>",,2025-12-03 22:39:25
Gabor Layers Enhance Network Robustness,"Juan C. Pérez, Motasem Alfarra, Guillaume Jeanneret, Adel Bibi, Ali Thabet, Bernard Ghanem, Pablo Arbeláez",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.05661"" target=""_blank"">1912.05661</a>",,2025-12-03 22:39:25
Learning to Model Aspects of Hearing Perception Using Neural Loss Functions,"Prateek Verma, Jonathan Berger",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.05683"" target=""_blank"">1912.05683</a>",,2025-12-03 22:39:25
Detection of Face Recognition Adversarial Attacks,"Fabio Valerio Massoli, Fabio Carrara, Giuseppe Amato, Fabrizio Falchi",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.02918"" target=""_blank"">1912.02918</a>",,2025-12-03 22:39:25
Potential adversarial samples for white-box attacks,"Amir Nazemi, Paul Fieguth",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.06409"" target=""_blank"">1912.06409</a>",,2025-12-03 22:39:25
Training Deep Neural Networks for Interpretability and Adversarial Robustness,"Adam Noack, Isaac Ahern, Dejing Dou, Boyang Li",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.03430"" target=""_blank"">1912.03430</a>","<a href=""https://github.com/a1noack/interp_regularization"" target=""_blank"">a1noack</a>",2025-12-03 22:39:25
A Method for Computing Class-wise Universal Adversarial Perturbations,"Tejus Gupta, Abhishek Sinha, Nupur Kumari, Mayank Singh, Balaji Krishnamurthy",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.00466"" target=""_blank"">1912.00466</a>",,2025-12-03 22:39:25
"The Search for Sparse, Robust Neural Networks","Justin Cosentino, Federico Zaiter, Dan Pei, Jun Zhu",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.02386"" target=""_blank"">1912.02386</a>","<a href=""https://github.com/justincosentino/robust-sparse-networks"" target=""_blank"">justincosentino</a>",2025-12-03 22:39:25
Deep Neural Network Fingerprinting by Conferrable Adversarial Examples,"Nils Lukas, Yuxuan Zhang, Florian Kerschbaum",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.00888"" target=""_blank"">1912.00888</a>",,2025-12-03 22:39:25
What Else Can Fool Deep Learning? Addressing Color Constancy Errors on Deep Neural Network Performance,"Mahmoud Afifi, Michael S Brown",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.06960"" target=""_blank"">1912.06960</a>",,2025-12-03 22:39:25
Square Attack: a query-efficient black-box adversarial attack via random search,"Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion, Matthias Hein",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.00049"" target=""_blank"">1912.00049</a>","<a href=""https://github.com/max-andr/square-attack"" target=""_blank"">max-andr</a>",2025-12-03 22:39:25
Error-Correcting Neural Network,"Yang Song, Qiyu Kang, Wee Peng Tay",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.00181"" target=""_blank"">1912.00181</a>",,2025-12-03 22:39:25
Design and Interpretation of Universal Adversarial Patches in Face Detection,"Xiao Yang, Fangyun Wei, Hongyang Zhang, Jun Zhu",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.05021"" target=""_blank"">1912.05021</a>",,2025-12-03 22:39:25
AdvPC: Transferable Adversarial Perturbations on 3D Point Clouds,"Abdullah Hamdi, Sara Rojas, Ali Thabet, Bernard Ghanem",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.00461"" target=""_blank"">1912.00461</a>",,2025-12-03 22:39:25
Adversary A3C for Robust Reinforcement Learning,"Zhaoyuan Gu, Zhenzhong Jia, Howie Choset",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.00330"" target=""_blank"">1912.00330</a>",,2025-12-03 22:39:25
Universal Adversarial Perturbations for CNN Classifiers in EEG-Based BCIs,"Zihan Liu, Xiao Zhang, Lubin Meng, Dongrui Wu",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.01171"" target=""_blank"">1912.01171</a>",,2025-12-03 22:39:25
Cost-Aware Robust Tree Ensembles for Security Applications,"Yizheng Chen, Shiqi Wang, Weifan Jiang, Asaf Cidon, Suman Jana",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.01149"" target=""_blank"">1912.01149</a>",,2025-12-03 22:39:25
Region-Wise Attack: On Efficient Generation of Robust Physical Adversarial Examples,"Bo Luo, Qiang Xu",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.02598"" target=""_blank"">1912.02598</a>",,2025-12-03 22:39:25
"FANNet: Formal Analysis of Noise Tolerance, Training Bias and Input Sensitivity in Neural Networks","Mahum Naseer, Mishal Fatima Minhas, Faiq Khalid, Muhammad Abdullah Hanif, Osman Hasan, Muhammad Shafique",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.01978"" target=""_blank"">1912.01978</a>",,2025-12-03 22:39:25
A Survey of Black-Box Adversarial Attacks on Computer Vision Models,"Siddhant Bhambri, Sumanyu Muku, Avinash Tulasi, Arun Balaji Buduru",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.01667"" target=""_blank"">1912.01667</a>",,2025-12-03 22:39:25
Scratch that! An Evolution-based Adversarial Attack against Neural Networks,"Malhar Jere, Briland Hitaj, Gabriela Ciocarlie, Farinaz Koushanfar",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.02316"" target=""_blank"">1912.02316</a>",,2025-12-03 22:39:25
Towards Robust Image Classification Using Sequential Attention Models,"Daniel Zoran, Mike Chrzanowski, Po-Sen Huang, Sven Gowal, Alex Mott, Pushmeet Kohl",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.02184"" target=""_blank"">1912.02184</a>",,2025-12-03 22:39:25
"Walking on the Edge: Fast, Low-Distortion Adversarial Examples","Hanwei Zhang, Yannis Avrithis, Teddy Furon, Laurent Amsaleg",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.02153"" target=""_blank"">1912.02153</a>",,2025-12-03 22:39:25
A Survey of Game Theoretic Approaches for Adversarial Machine Learning in Cybersecurity Tasks,"Prithviraj Dasgupta, Joseph B. Collins",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.02258"" target=""_blank"">1912.02258</a>",,2025-12-03 22:39:25
Learning with Multiplicative Perturbations,"Xiulong Yang, Shihao Ji",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.01810"" target=""_blank"">1912.01810</a>",,2025-12-03 22:39:25
Towards Robust Toxic Content Classification,"Keita Kurita, Anna Belova, Antonios Anastasopoulos",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.06872"" target=""_blank"">1912.06872</a>",,2025-12-03 22:39:25
Defending from adversarial examples with a two-stream architecture,"Hao Ge, Xiaoguang Tu, Mei Xie, Zheng Ma",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.12859"" target=""_blank"">1912.12859</a>",,2025-12-03 22:39:25
DAmageNet: A Universal Adversarial Dataset,"Sizhe Chen, Xiaolin Huang, Zhengbao He, Chengjin Sun",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.07160"" target=""_blank"">1912.07160</a>",,2025-12-03 22:39:25
Cronus: Robust and Heterogeneous Collaborative Learning with Black-Box Knowledge Transfer,"Hongyan Chang, Virat Shejwalkar, Reza Shokri, Amir Houmansadr",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.11279"" target=""_blank"">1912.11279</a>",,2025-12-03 22:39:25
Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing,"Jinyuan Jia, Xiaoyu Cao, Binghui Wang, Neil Zhenqiang Gong",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.09899"" target=""_blank"">1912.09899</a>","<a href=""https://github.com/jjy1994/Certify_Topk"" target=""_blank"">jjy1994</a>",2025-12-03 22:39:25
Measuring Dataset Granularity,"Yin Cui, Zeqi Gu, Dhruv Mahajan, der Maaten Laurens van, Serge Belongie, Ser-Nam Lim",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.10154"" target=""_blank"">1912.10154</a>",,2025-12-03 22:39:25
T3: Tree-Autoencoder Constrained Adversarial Text Generation for Targeted Attack,"Boxin Wang, Hengzhi Pei, Boyuan Pan, Qian Chen, Shuohang Wang, Bo Li",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.10375"" target=""_blank"">1912.10375</a>","<a href=""https://github.com/AI-secure/T3/"" target=""_blank"">T3</a>",2025-12-03 22:39:25
Geometry-aware Generation of Adversarial and Cooperative Point Clouds,"Yuxin Wen, Jiehong Lin, Ke Chen, Kui Jia",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.11171"" target=""_blank"">1912.11171</a>",,2025-12-03 22:39:25
Adversarial AutoAugment,"Xinyu Zhang, Qiang Wang, Jian Zhang, Zhao Zhong",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.11188"" target=""_blank"">1912.11188</a>",,2025-12-03 22:39:25
White Noise Analysis of Neural Networks,"Ali Borji, Sikun Lin",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.12106"" target=""_blank"">1912.12106</a>",,2025-12-03 22:39:25
Characterizing the Decision Boundary of Deep Neural Networks,"Hamid Karimi, Tyler Derr, Jiliang Tang",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.11460"" target=""_blank"">1912.11460</a>",,2025-12-03 22:39:25
Analysis of Moving Target Defense Against False Data Injection Attacks on Power Grid,"Zhenyong Zhang, Ruilong Deng, Member, IEEE, David K. Y. Yau, Senior Member, IEEE, Peng Cheng, Member, IEEE, Jiming Chen, Fellow, IEEE",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.11372"" target=""_blank"">1912.11372</a>",,2025-12-03 22:39:25
Jacobian Adversarially Regularized Networks for Robustness,"Alvin Chan, Yi Tay, Yew Soon Ong, Jie Fu",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.10185"" target=""_blank"">1912.10185</a>",,2025-12-03 22:39:25
Attack-Resistant Federated Learning with Residual-based Reweighting,"Shuhao Fu, Chulin Xie, Bo Li, Qifeng Chen",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.11464"" target=""_blank"">1912.11464</a>",,2025-12-03 22:39:25
Efficient Adversarial Training with Transferable Adversarial Examples,"Haizhong Zheng, Ziqi Zhang, Juncheng Gu, Honglak Lee, Atul Prakash",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.11969"" target=""_blank"">1912.11969</a>",,2025-12-03 22:39:25
Benchmarking Adversarial Robustness,"Yinpeng Dong, Qi-An Fu, Xiao Yang, Tianyu Pang, Hang Su, Zihao Xiao, Jun Zhu",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.11852"" target=""_blank"">1912.11852</a>",,2025-12-03 22:39:25
Search Based Repair of Deep Neural Networks,"Jeongju Sohn, Sungmin Kang, Shin Yoo",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.12463"" target=""_blank"">1912.12463</a>",,2025-12-03 22:39:25
Detecting Out-of-Distribution Examples with In-distribution Examples and Gram Matrices,"Chandramouli Shama Sastry, Sageev Oore",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.12510"" target=""_blank"">1912.12510</a>",,2025-12-03 22:39:25
Automated Testing for Deep Learning Systems with Differential Behavior Criteria,"Yuan Gao, Yiqiang Han",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.13258"" target=""_blank"">1912.13258</a>",,2025-12-03 22:39:25
Constructing a provably adversarially-robust classifier from a high accuracy one,"Grzegorz Głuch, Rüdiger Urbanke",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.07561"" target=""_blank"">1912.07561</a>",,2025-12-03 22:39:25
secml: A Python Library for Secure and Explainable Machine Learning,"Maura Pintor, Luca Demetrio, Angelo Sotgiu, Marco Melis, Ambra Demontis, Battista Biggio",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.10013"" target=""_blank"">1912.10013</a>","<a href=""https://github.com/pralab/secml"" target=""_blank"">pralab</a>",2025-12-03 22:39:25
Adversarial Embedding: A robust and elusive Steganography and Watermarking technique,"Salah Ghamizi, Maxime Cordy, Mike Papadakis, Yves Le Traon",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.01487"" target=""_blank"">1912.01487</a>",,2025-12-03 22:39:25
Explainability and Adversarial Robustness for RNNs,"Alexander Hartl, Maximilian Bachl, Joachim Fabini, Tanja Zseby",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.09855"" target=""_blank"">1912.09855</a>",,2025-12-03 22:39:25
An Adversarial Perturbation Oriented Domain Adaptation Approach for Semantic Segmentation,"Jihan Yang, Ruijia Xu, Ruiyu Li, Xiaojuan Qi, Xiaoyong Shen, Guanbin Li, Liang Lin",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.08954"" target=""_blank"">1912.08954</a>",,2025-12-03 22:39:25
Adversarial symmetric GANs: bridging adversarial samples and adversarial networks,"Faqiang Liu, Mingkun Xu, Guoqi Li, Jing Pei, Luping Shi, Rong Zhao",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.09670"" target=""_blank"">1912.09670</a>",,2025-12-03 22:39:25
On-manifold Adversarial Data Augmentation Improves Uncertainty Calibration,"Kanil Patel, William Beluch, Dan Zhang, Michael Pfeiffer, Bin Yang",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.07458"" target=""_blank"">1912.07458</a>",,2025-12-03 22:39:25
MimicGAN: Robust Projection onto Image Manifolds with Corruption Mimicking,"Rushil Anirudh, Jayaraman J. Thiagarajan, Bhavya Kailkhura, Timo Bremer",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.07748"" target=""_blank"">1912.07748</a>",,2025-12-03 22:39:25
CAG: A Real-time Low-cost Enhanced-robustness High-transferability Content-aware Adversarial Attack Generator,"Huy Phan, Yi Xie, Siyu Liao, Jie Chen, Bo Yuan",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.07742"" target=""_blank"">1912.07742</a>",,2025-12-03 22:39:25
APRICOT: A Dataset of Physical Adversarial Attacks on Object Detection,"A. Braunegg, Amartya Chakraborty, Michael Krumdick, Nicole Lape, Sara Leary, Keith Manville, Elizabeth Merkhofer, Laura Strickhart, Matthew Walmer",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.08166"" target=""_blank"">1912.08166</a>",,2025-12-03 22:39:25
SIGMA : Strengthening IDS with GAN and Metaheuristics Attacks,"Simon Msika, Alejandro Quintero, Foutse Khomh",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.09303"" target=""_blank"">1912.09303</a>",,2025-12-03 22:39:25
Adversarial VC-dimension and Sample Complexity of Neural Networks,"Zetong Qi, T. J. Wilder",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.08865"" target=""_blank"">1912.08865</a>",,2025-12-03 22:39:25
Detecting Adversarial Attacks On Audio-Visual Speech Recognition,"Pingchuan Ma, Stavros Petridis, Maja Pantic",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.08639"" target=""_blank"">1912.08639</a>",,2025-12-03 22:39:25
Identifying Adversarial Sentences by Analyzing Text Complexity,"Hoang-Quoc Nguyen-Son, Tran Phuong Thao, Seira Hidano, Shinsaku Kiyomoto",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.08981"" target=""_blank"">1912.08981</a>",,2025-12-03 22:39:25
Towards Verifying Robustness of Neural Networks Against Semantic Perturbations,"Jeet Lily Mohapatra, Lily Tsui-Wei, Weng, Pin-Yu Chen, Sijia Liu, Luca Daniel",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.09533"" target=""_blank"">1912.09533</a>","<a href=""https://github.com/JeetMo/Semantify-NN"" target=""_blank"">JeetMo</a>",2025-12-03 22:39:25
Does Symbolic Knowledge Prevent Adversarial Fooling?,Stefano Teso,arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.10834"" target=""_blank"">1912.10834</a>",,2025-12-03 22:39:25
$n$-ML: Mitigating Adversarial Examples via Ensembles of Topologically Manipulated Classifiers,"Mahmood Sharif, Lujo Bauer, Michael K. Reiter",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.09059"" target=""_blank"">1912.09059</a>",,2025-12-03 22:39:25
Optimization-Guided Binary Diversification to Mislead Neural Networks for Malware Detection,"Mahmood Sharif, Keane Lucas, Lujo Bauer, Michael K. Reiter, Saurabh Shintre",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.09064"" target=""_blank"">1912.09064</a>",,2025-12-03 22:39:25
Mitigating large adversarial perturbations on X-MAS (X minus Moving Averaged Samples),"Woohyung Chun, Sung-Min Hong, Junho Huh, Inyup Kang",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.12170"" target=""_blank"">1912.12170</a>",,2025-12-03 22:39:25
Perturbations on the Perceptual Ball,"Andrew Elliott, Stephen Law, Chris Russell",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.09405"" target=""_blank"">1912.09405</a>",,2025-12-03 22:39:25
A New Ensemble Method for Concessively Targeted Multi-model Attack,"Ziwen He, Wei Wang, Xinsheng Xuan, Jing Dong, Tieniu Tan",arXiv,2019-12,"<a href=""http://arxiv.org/abs/1912.10833"" target=""_blank"">1912.10833</a>",,2025-12-03 22:39:25
A Reinforced Generation of Adversarial Samples for Neural Machine Translation,"Wei Zou, Shujian Huang, Jun Xie, Xinyu Dai, Jiajun Chen",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.03677"" target=""_blank"">1911.03677</a>",,2025-12-03 22:39:25
CALPA-NET: Channel-pruning-assisted Deep Residual Network for Steganalysis of Digital Images,"Shunquan Tan, Weilong Wu, Zilong Shao, Qiushi Li, Bin Li, Jiwu Huang",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.04657"" target=""_blank"">1911.04657</a>",,2025-12-03 22:39:25
GraphDefense: Towards Robust Graph Convolutional Networks,"Xiaoyun Wang, Xuanqing Liu, Cho-Jui Hsieh",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.04429"" target=""_blank"">1911.04429</a>",,2025-12-03 22:39:25
Minimalistic Attacks: How Little it Takes to Fool a Deep Reinforcement Learning Policy,"Xinghua Qu, Zhu Sun, Yew-Soon Ong, Abhishek Gupta, Pengfei Wei",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.03849"" target=""_blank"">1911.03849</a>",,2025-12-03 22:39:25
Improving Machine Reading Comprehension via Adversarial Training,"Ziqing Yang, Yiming Cui, Wanxiang Che, Ting Liu, Shijin Wang, Guoping Hu",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.03614"" target=""_blank"">1911.03614</a>",,2025-12-03 22:39:25
Adaptive versus Standard Descent Methods and Robustness Against Adversarial Examples,Marc Khoury,arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.03784"" target=""_blank"">1911.03784</a>",,2025-12-03 22:39:25
Adversarial Attacks on Time-Series Intrusion Detection for Industrial Control Systems,"Giulio Zizzo, Chris Hankin, Sergio Maffeis, Kevin Jones",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.04278"" target=""_blank"">1911.04278</a>",,2025-12-03 22:39:25
Learning From Brains How to Regularize Machines,"Zhe Li, Wieland Brendel, Edgar Y. Walker, Erick Cobos, Taliah Muhammad, Jacob Reimer, Matthias Bethge, Fabian H. Sinz, Xaq Pitkow, Andreas S. Tolias",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.05072"" target=""_blank"">1911.05072</a>",,2025-12-03 22:39:25
Robust Design of Deep Neural Networks against Adversarial Attacks based on Lyapunov Theory,"Arash Rahnama, Andre T. Nguyen, Edward Raff",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.04636"" target=""_blank"">1911.04636</a>",,2025-12-03 22:39:25
CAGFuzz: Coverage-Guided Adversarial Generative Fuzzing Testing of Deep Learning Systems,"Pengcheng Zhang, Qiyin Dai, Patrizio Pelliccione",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.07931"" target=""_blank"">1911.07931</a>",,2025-12-03 22:39:25
RNN-Test: Towards Adversarial Testing for Recurrent Neural Network Systems,"Jianmin Guo, Yue Zhao, Quan Zhang, Yu Jiang",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.06155"" target=""_blank"">1911.06155</a>",,2025-12-03 22:39:25
Few-Features Attack to Fool Machine Learning Models through Mask-Based GAN,"Feng Chen, Yunkai Shang, Bo Xu, Jincheng Hu",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.06269"" target=""_blank"">1911.06269</a>",,2025-12-03 22:39:25
Adversarial Examples in Modern Machine Learning: A Review,"Rey Reza Wiyatno, Anqi Xu, Ousmane Dia, Berker Archy de",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.05268"" target=""_blank"">1911.05268</a>",,2025-12-03 22:39:25
On Robustness to Adversarial Examples and Polynomial Optimization,"Pranjal Awasthi, Abhratanu Dutta, Aravindan Vijayaraghavan",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.04681"" target=""_blank"">1911.04681</a>",,2025-12-03 22:39:25
Improving Robustness of Task Oriented Dialog Systems,"Arash Einolghozati, Sonal Gupta, Mrinal Mohit, Rushin Shah",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.05153"" target=""_blank"">1911.05153</a>",,2025-12-03 22:39:25
Adversarial Margin Maximization Networks,"Ziang Yan, Yiwen Guo, Changshui Zhang",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.05916"" target=""_blank"">1911.05916</a>",,2025-12-03 22:39:25
There is Limited Correlation between Coverage and Robustness for Deep Neural Networks,"Yizhen Dong, Peixin Zhang, Jingyi Wang, Shuang Liu, Jun Sun, Jianye Hao, Xinyu Wang, Li Wang, Jin Song Dong, Dai Ting",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.05904"" target=""_blank"">1911.05904</a>",,2025-12-03 22:39:25
Domain Robustness in Neural Machine Translation,"Mathias Müller, Annette Rios, Rico Sennrich",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.03109"" target=""_blank"">1911.03109</a>",,2025-12-03 22:39:25
DomainGAN: Generating Adversarial Examples to Attack Domain Generation Algorithm Classifiers,"Isaac Corley, Jonathan Lwowski, Justin Hoffman",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.06285"" target=""_blank"">1911.06285</a>",,2025-12-03 22:39:25
Self-supervised Adversarial Training,"Kejiang Chen, Hang Zhou, Yuefeng Chen, Xiaofeng Mao, Yuhong Li, Yuan He, Hui Xue, Weiming Zhang, Nenghai Yu",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.06470"" target=""_blank"">1911.06470</a>",,2025-12-03 22:39:25
Patch augmentation: Towards efficient decision boundaries for neural networks,"Marcus D. Bloice, Andreas Holzinger",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.07922"" target=""_blank"">1911.07922</a>",,2025-12-03 22:39:25
Adversarial Enhancement for Community Detection in Complex Networks,"Jiajun Zhou, Zhi Chen, Min Du, Lihong Chen, Shanqing Yu, Feifei Li, Guanrong Chen, Qi Xuan",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.01670"" target=""_blank"">1911.01670</a>",,2025-12-03 22:39:25
Adversarial Attacks on GMM i-vector based Speaker Verification Systems,"Xu Li, Jinghua Zhong, Xixin Wu, Jianwei Yu, Xunying Liu, Helen Meng",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.03078"" target=""_blank"">1911.03078</a>",,2025-12-03 22:39:25
Persistency of Excitation for Robustness of Neural Networks,"Kamil Nar, S. Shankar Sastry",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.01043"" target=""_blank"">1911.01043</a>",,2025-12-03 22:39:25
AdvKnn: Adversarial Attacks On K-Nearest Neighbor Classifiers With Approximate Gradients,"Xiaodan Li, Yuefeng Chen, Yuan He, Hui Xue",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.06591"" target=""_blank"">1911.06591</a>",,2025-12-03 22:39:25
Spot Evasion Attacks: Adversarial Examples for License Plate Recognition Systems with Convolutional Neural Networks,"Ya-guan Qian, Dan-feng Ma, Bin Wang, Jun Pan, Jia-min Wang, Jian-hai Chen, Wu-jie Zhou, Jing-sheng Lei",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.00927"" target=""_blank"">1911.00927</a>",,2025-12-03 22:39:25
Adversarial Music: Real World Audio Adversary Against Wake-word Detection System,"Juncheng B. Li, Shuhui Qu, Xinjian Li, Joseph Szurley, J. Zico Kolter, Florian Metze",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.00126"" target=""_blank"">1911.00126</a>",,2025-12-03 22:39:25
Automatic Detection of Generated Text is Easiest when Humans are Fooled,"Daphne Ippolito, Daniel Duckworth, Chris Callison-Burch, Douglas Eck",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.00650"" target=""_blank"">1911.00650</a>",,2025-12-03 22:39:25
MadNet: Using a MAD Optimization for Defending Against Adversarial Attacks,"Shai Rozenberg, Gal Elidan, Ran El-Yaniv",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.00870"" target=""_blank"">1911.00870</a>",,2025-12-03 22:39:25
Who is Real Bob? Adversarial Attacks on Speaker Recognition Systems,"Guangke Chen, Sen Chen, Lingling Fan, Xiaoning Du, Zhe Zhao, Fu Song, Yang Liu",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.01840"" target=""_blank"">1911.01840</a>",,2025-12-03 22:39:25
A Tale of Evil Twins: Adversarial Inputs versus Poisoned Models,"Ren Pang, Hua Shen, Xinyang Zhang, Shouling Ji, Yevgeniy Vorobeychik, Xiapu Luo, Alex Liu, Ting Wang",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.01559"" target=""_blank"">1911.01559</a>",,2025-12-03 22:39:25
Fast-UAP: An Algorithm for Speeding up Universal Adversarial Perturbation Generation with Orientation of Perturbation Vectors,"Jiazhu Dai, Le Shu",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.01172"" target=""_blank"">1911.01172</a>",,2025-12-03 22:39:25
Coverage Guided Testing for Recurrent Neural Networks,"Wei Huang, Youcheng Sun, Xingyu Zhao, James Sharp, Wenjie Ruan, Jie Meng, Xiaowei Huang",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.01952"" target=""_blank"">1911.01952</a>",,2025-12-03 22:39:25
Imperceptible Adversarial Attacks on Tabular Data,"Vincent Ballet, Xavier Renard, Jonathan Aigrain, Thibault Laugel, Pascal Frossard, Marcin Detyniecki",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.03274"" target=""_blank"">1911.03274</a>",,2025-12-03 22:39:25
Intriguing Properties of Adversarial ML Attacks in the Problem Space,"Fabio Pierazzi, Feargus Pendlebury, Jacopo Cortellazzi, Lorenzo Cavallaro",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.02142"" target=""_blank"">1911.02142</a>",,2025-12-03 22:39:25
DLA: Dense-Layer-Analysis for Adversarial Example Detection,"Philip Sperl, Ching-Yu Kao, Peng Chen, Konstantin Böttinger",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.01921"" target=""_blank"">1911.01921</a>",,2025-12-03 22:39:25
Reversible Adversarial Example based on Reversible Image Transformation,"Zhaoxia Yin, Hua Wang, Weiming Zhang",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.02360"" target=""_blank"">1911.02360</a>",,2025-12-03 22:39:25
The Threat of Adversarial Attacks on Machine Learning in Network Security -- A Survey,"Olakunle Ibitoye, Rana Abou-Khamis, Ashraf Matrawy, M. Omair Shafiq",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.02621"" target=""_blank"">1911.02621</a>",,2025-12-03 22:39:25
Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods,"Dylan Slack, Sophie Hilgard, Emily Jia, Sameer Singh, Himabindu Lakkaraju",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.02508"" target=""_blank"">1911.02508</a>",,2025-12-03 22:39:25
Towards Large yet Imperceptible Adversarial Image Perturbations with Perceptual Color Distance,"Zhengyu Zhao, Zhuoran Liu, Martha Larson",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.02466"" target=""_blank"">1911.02466</a>",,2025-12-03 22:39:25
Active Learning for Black-Box Adversarial Attacks in EEG-Based Brain-Computer Interfaces,"Xue Jiang, Xiao Zhang, Dongrui Wu",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.04338"" target=""_blank"">1911.04338</a>",,2025-12-03 22:39:25
White-Box Target Attack for EEG-Based BCI Regression Problems,"Lubin Meng, Chin-Teng Lin, Tzyy-Ring Jung, Dongrui Wu",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.04606"" target=""_blank"">1911.04606</a>",,2025-12-03 22:39:25
Security of Facial Forensics Models Against Adversarial Attacks,"Rong Huang, Fuming Fang, Huy H. Nguyen, Junichi Yamagishi, Isao Echizen",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.00660"" target=""_blank"">1911.00660</a>",,2025-12-03 22:39:25
An Adaptive View of Adversarial Robustness from Test-time Smoothing Defense,"Chao Tang, Yifei Fan, Anthony Yezzi",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.11881"" target=""_blank"">1911.11881</a>",,2025-12-03 22:39:25
Simple iterative method for generating targeted universal adversarial perturbations,"Hokuto Hirano, Kazuhiro Takemoto",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.06502"" target=""_blank"">1911.06502</a>",,2025-12-03 22:39:25
Patch-level Neighborhood Interpolation: A General and Effective Graph-based Regularization Strategy,"Ke Sun, Bing Yu, Zhouchen Lin, Zhanxing Zhu",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.09307"" target=""_blank"">1911.09307</a>",,2025-12-03 22:39:25
Heuristic Black-box Adversarial Attacks on Video Recognition Models,"Zhipeng Wei, Jingjing Chen, Xingxing Wei, Linxi Jiang, Tat-Seng Chua, Fengfeng Zhou, Yu-Gang Jiang",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.09449"" target=""_blank"">1911.09449</a>",,2025-12-03 22:39:25
Invert and Defend: Model-based Approximate Inversion of Generative Adversarial Networks for Secure Inference,"Wei-An Lin, Yogesh Balaji, Pouya Samangouei, Rama Chellappa",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.10291"" target=""_blank"">1911.10291</a>","<a href=""https://github.com/yogeshbalaji/InvGAN"" target=""_blank"">yogeshbalaji</a>",2025-12-03 22:39:25
Universal adversarial examples in speech command classification,"Jon Vadillo, Roberto Santana",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.10182"" target=""_blank"">1911.10182</a>",,2025-12-03 22:39:25
Attack Agnostic Statistical Method for Adversarial Detection,"Sambuddha Saha, Aashish Kumar, Pratyush Sahay, George Jose, Srinivas Kruthiventi, Harikrishna Muralidhara",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.10008"" target=""_blank"">1911.10008</a>",,2025-12-03 22:39:25
Enhancing Cross-task Black-Box Transferability of Adversarial Examples with Dispersion Reduction,"Yantao Lu, Yunhan Jia, Jianyu Wang, Bai Li, Weiheng Chai, Lawrence Carin, Senem Velipasalar",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.11616"" target=""_blank"">1911.11616</a>",,2025-12-03 22:39:25
Bounding Singular Values of Convolution Layers,"Sahil Singla, Soheil Feizi",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.10258"" target=""_blank"">1911.10258</a>","<a href=""https://github.com/singlasahil14/CONV-SV"" target=""_blank"">singlasahil14</a>",2025-12-03 22:39:25
Universal Adversarial Robustness of Texture and Shape-Biased Models,"Kenneth T. Co, Luis Muñoz-González, Leslie Kanthan, Ben Glocker, Emil C. Lupu",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.10364"" target=""_blank"">1911.10364</a>",,2025-12-03 22:39:25
Robust Assessment of Real-World Adversarial Examples,"Brett Jefferson, Carlos Ortiz Marrero",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.10435"" target=""_blank"">1911.10435</a>",,2025-12-03 22:39:25
Time-aware Gradient Attack on Dynamic Network Link Prediction,"Jinyin Chen, Jian Zhang, Zhi Chen, Min Du, Feifei Li, Qi Xuan",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.10561"" target=""_blank"">1911.10561</a>",,2025-12-03 22:39:25
When NAS Meets Robustness: In Search of Robust Architectures against Adversarial Attacks,"Minghao Guo, Yuzhe Yang, Rui Xu, Ziwei Liu, Dahua Lin",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.10695"" target=""_blank"">1911.10695</a>","<a href=""https://github.com/gmh14/RobNets"" target=""_blank"">gmh14</a>",2025-12-03 22:39:25
One Man's Trash is Another Man's Treasure: Resisting Adversarial Examples by Adversarial Examples,"Chang Xiao, Changxi Zheng",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.11219"" target=""_blank"">1911.11219</a>",,2025-12-03 22:39:25
Adversarial Attack with Pattern Replacement,"Ziang Dong, Liang Mao, Shiliang Sun",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.10875"" target=""_blank"">1911.10875</a>",,2025-12-03 22:39:25
ColorFool: Semantic Adversarial Colorization,"Ali Shahin Shamsabadi, Ricardo Sanchez-Matilla, Andrea Cavallaro",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.10891"" target=""_blank"">1911.10891</a>",,2025-12-03 22:39:25
Playing it Safe: Adversarial Robustness with an Abstain Option,"Cassidy Laidlaw, Soheil Feizi",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.11253"" target=""_blank"">1911.11253</a>",,2025-12-03 22:39:25
Using Depth for Pixel-Wise Detection of Adversarial Attacks in Crowd Counting,"Weizhe Liu, Mathieu Salzmann, Pascal Fua",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.11484"" target=""_blank"">1911.11484</a>",,2025-12-03 22:39:25
Can Attention Masks Improve Adversarial Robustness?,"Pratik Vaishnavi, Tianji Cong, Kevin Eykholt, Atul Prakash, Amir Rahmati",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.11946"" target=""_blank"">1911.11946</a>",,2025-12-03 22:39:25
Towards Privacy and Security of Deep Learning Systems: A Survey,"Yingzhe He, Guozhu Meng, Kai Chen, Xingbo Hu, Jinwen He",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.12562"" target=""_blank"">1911.12562</a>",,2025-12-03 22:39:25
Survey of Attacks and Defenses on Edge-Deployed Neural Networks,"Mihailo Isakov, Vijay Gadepally, Karen M. Gettings, Michel A. Kinsy",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.11932"" target=""_blank"">1911.11932</a>",,2025-12-03 22:39:25
On Model Robustness Against Adversarial Examples,"Shufei Zhang, Kaizhu Huang, Zenglin Xu",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.06479"" target=""_blank"">1911.06479</a>",,2025-12-03 22:39:25
Adversarial Examples Improve Image Recognition,"Cihang Xie, Mingxing Tan, Boqing Gong, Jiang Wang, Alan Yuille, Quoc V. Le",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.09665"" target=""_blank"">1911.09665</a>","<a href=""https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet"" target=""_blank"">official</a>",2025-12-03 22:39:25
Defending Against Adversarial Machine Learning,Alison Jenkins,arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.11746"" target=""_blank"">1911.11746</a>",,2025-12-03 22:39:25
Robustness Certificates for Sparse Adversarial Attacks by Randomized Ablation,"Alexander Levine, Soheil Feizi",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.09272"" target=""_blank"">1911.09272</a>","<a href=""https://github.com/alevine0/randomizedAblation/"" target=""_blank"">randomizedAblation</a>",2025-12-03 22:39:25
WITCHcraft: Efficient PGD attacks with random step size,"Ping-Yeh Chiang, Jonas Geiping, Micah Goldblum, Tom Goldstein, Renkun Ni, Steven Reich, Ali Shafahi",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.07989"" target=""_blank"">1911.07989</a>",,2025-12-03 22:39:25
Learning To Characterize Adversarial Subspaces,"Xiaofeng Mao, Yuefeng Chen, Yuhong Li, Yuan He, Hui Xue",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.06587"" target=""_blank"">1911.06587</a>",,2025-12-03 22:39:25
Analysis of Deep Networks for Monocular Depth Estimation Through Adversarial Attacks with Proposal of a Defense Method,"Junjie Hu, Takayuki Okatani",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.08790"" target=""_blank"">1911.08790</a>",,2025-12-03 22:39:25
Black-Box Adversarial Attack with Transferable Model-based Embedding,"Zhichao Huang, Tong Zhang",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.07140"" target=""_blank"">1911.07140</a>",,2025-12-03 22:39:25
Suspicion-Free Adversarial Attacks on Clustering Algorithms,"Anshuman Chhabra, Abhishek Roy, Prasant Mohapatra",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.07015"" target=""_blank"">1911.07015</a>",,2025-12-03 22:39:25
SMART: Skeletal Motion Action Recognition aTtack,"He Wang, Feixiang He, Zexi Peng, Yongliang Yang, Tianjia Shao, Kun Zhou, David Hogg",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.07107"" target=""_blank"">1911.07107</a>",,2025-12-03 22:39:25
Smoothed Inference for Adversarially-Trained Models,"Yaniv Nemcovsky, Evgenii Zheltonozhskii, Chaim Baskin, Brian Chmiel, Maxim Fishman, Alex M. Bronstein, Avi Mendelson",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.07198"" target=""_blank"">1911.07198</a>","<a href=""https://github.com/yanemcovsky/SIAM"" target=""_blank"">yanemcovsky</a>",2025-12-03 22:39:25
Deep Verifier Networks: Verification of Deep Discriminative Models with Deep Generative Models,"Tong Che, Xiaofeng Liu, Site Li, Yubin Ge, Ruixiang Zhang, Caiming Xiong, Yoshua Bengio",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.07421"" target=""_blank"">1911.07421</a>",,2025-12-03 22:39:25
Countering Inconsistent Labelling by Google's Vision API for Rotated Images,"Aman Apte, Aritra Bandyopadhyay, K Akhilesh Shenoy, Jason Peter Andrews, Aditya Rathod, Manish Agnihotri, Aditya Jajodia",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.07201"" target=""_blank"">1911.07201</a>",,2025-12-03 22:39:25
Deep Detector Health Management under Adversarial Campaigns,"Javier Echauz, Keith Kenemer, Sarfaraz Hussein, Jay Dhaliwal, Saurabh Shintre, Slawomir Grzonkowski, Andrew Gardner",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.08090"" target=""_blank"">1911.08090</a>",,2025-12-03 22:39:25
Defensive Few-shot Learning,"Wenbin Li, Lei Wang, Xingxing Zhang, Lei Qi, Jing Huo, Yang Gao, Jiebo Luo",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.06968"" target=""_blank"">1911.06968</a>","<a href=""https://github.com/WenbinLee/DefensiveFSL"" target=""_blank"">WenbinLee</a>",2025-12-03 22:39:25
Adversarial Attacks on Grid Events Classification: An Adversarial Machine Learning Approach,"Iman Niazazari, Hanif Livani",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.08011"" target=""_blank"">1911.08011</a>",,2025-12-03 22:39:25
A New Ensemble Adversarial Attack Powered by Long-term Gradient Memories,"Zhaohui Che, Ali Borji, Guangtao Zhai, Suiyi Ling, Jing Li, Patrick Le Callet",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.07682"" target=""_blank"">1911.07682</a>",,2025-12-03 22:39:25
Generate (non-software) Bugs to Fool Classifiers,"Hiromu Yakura, Youhei Akimoto, Jun Sakuma",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.08644"" target=""_blank"">1911.08644</a>",,2025-12-03 22:39:25
Adversarial Robustness of Flow-Based Generative Models,"Phillip Pope, Yogesh Balaji, Soheil Feizi",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.08654"" target=""_blank"">1911.08654</a>",,2025-12-03 22:39:25
Where is the Bottleneck of Adversarial Learning with Unlabeled Data?,"Jingfeng Zhang, Bo Han, Gang Niu, Tongliang Liu, Masashi Sugiyama",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.08696"" target=""_blank"">1911.08696</a>",,2025-12-03 22:39:25
A novel method for identifying the deep neural network model with the Serial Number,"XiangRui Xu, YaQin Li, Cao Yuan",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.08053"" target=""_blank"">1911.08053</a>",,2025-12-03 22:39:25
Fine-grained Synthesis of Unrestricted Adversarial Examples,"Omid Poursaeed, Tianxing Jiang, Harry Yang, Serge Belongie, Ser-Nam Lim",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.09058"" target=""_blank"">1911.09058</a>",,2025-12-03 22:39:25
Logic-inspired Deep Neural Networks,Minh Le,arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.08635"" target=""_blank"">1911.08635</a>",,2025-12-03 22:39:25
Deep Minimax Probability Machine,"Lirong He, Ziyi Guo, Kaizhu Huang, Zenglin Xu",arXiv,2019-11,"<a href=""http://arxiv.org/abs/1911.08723"" target=""_blank"">1911.08723</a>",,2025-12-03 22:39:25
Universal Adversarial Perturbation for Text Classification,"Hang Gao, Tim Oates",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.04618"" target=""_blank"">1910.04618</a>",,2025-12-03 22:39:25
Directional Adversarial Training for Cost Sensitive Deep Learning Classification Applications,"Matteo Terzi, Gian Antonio Susto, Pratik Chaudhari",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.03468"" target=""_blank"">1910.03468</a>",,2025-12-03 22:39:25
Adversarial Training: embedding adversarial perturbations into the parameter space of a neural network to build a robust system,"Shixian Wen, Laurent Itti",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.04279"" target=""_blank"">1910.04279</a>",,2025-12-03 22:39:25
Deep Latent Defence,"Giulio Zizzo, Chris Hankin, Sergio Maffeis, Kevin Jones",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.03916"" target=""_blank"">1910.03916</a>",,2025-12-03 22:39:25
Adversarial Learning of Deepfakes in Accounting,"Marco Schreyer, Timur Sattarov, Bernd Reimer, Damian Borth",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.03810"" target=""_blank"">1910.03810</a>",,2025-12-03 22:39:25
Learning deep forest with multi-scale Local Binary Pattern features for face anti-spoofing,"Rizhao Cai, Changsheng Chen",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.03850"" target=""_blank"">1910.03850</a>",,2025-12-03 22:39:25
Information Aware Max-Norm Dirichlet Networks for Predictive Uncertainty Estimation,Theodoros Tsiligkaridis,arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.04819"" target=""_blank"">1910.04819</a>",,2025-12-03 22:39:25
On Robustness of Neural Ordinary Differential Equations,"Hanshu Yan, Jiawei Du, Vincent Y. F. Tan, Jiashi Feng",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.05513"" target=""_blank"">1910.05513</a>",,2025-12-03 22:39:25
Verification of Neural Networks: Specifying Global Robustness using Generative Models,"Nathanaël Fijalkow, Mohit Kumar Gupta",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.05018"" target=""_blank"">1910.05018</a>",,2025-12-03 22:39:25
"Hear ""No Evil"", See ""Kenansville"": Efficient and Transferable Black-Box Attacks on Speech Recognition and Voice Identification Systems","Hadi Abdullah, Muhammad Sajidur Rahman, Washington Garcia, Logan Blue, Kevin Warren, Anurag Swarnim Yadav, Tom Shrimpton, Patrick Traynor",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.05262"" target=""_blank"">1910.05262</a>",,2025-12-03 22:39:25
Interpretable Disentanglement of Neural Networks by Extracting Class-Specific Subnetwork,"Yulong Wang, Xiaolin Hu, Hang Su",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.02673"" target=""_blank"">1910.02673</a>",,2025-12-03 22:39:25
Real-world adversarial attack on MTCNN face detection system,"Edgar Kaziakhmedov, Klim Kireev, Grigorii Melnikov, Mikhail Pautov, Aleksandr Petiushko",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.06261"" target=""_blank"">1910.06261</a>",,2025-12-03 22:39:25
Man-in-the-Middle Attacks against Machine Learning Classifiers via Malicious Generative Models,"Derek Derui, Wang, Chaoran Li, Sheng Wen, Surya Nepal, Yang Xiang",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.06838"" target=""_blank"">1910.06838</a>",,2025-12-03 22:39:25
ZO-AdaMM: Zeroth-Order Adaptive Momentum Method for Black-Box Optimization,"Xiangyi Chen, Sijia Liu, Kaidi Xu, Xingguo Li, Xue Lin, Mingyi Hong, David Cox",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.06513"" target=""_blank"">1910.06513</a>",,2025-12-03 22:39:25
Confidence-Calibrated Adversarial Training: Generalizing to Unseen Attacks,"David Stutz, Matthias Hein, Bernt Schiele",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.06259"" target=""_blank"">1910.06259</a>",,2025-12-03 22:39:25
DeepSearch: Simple and Effective Blackbox Fuzzing of Deep Neural Networks,"Fuyuan Zhang, Sankalan Pal Chowdhury, Maria Christakis",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.06296"" target=""_blank"">1910.06296</a>",,2025-12-03 22:39:25
SmoothFool: An Efficient Framework for Computing Smooth Adversarial Perturbations,"Ali Dabouei, Sobhan Soleymani, Fariborz Taherkhani, Jeremy Dawson, Nasser M. Nasrabadi",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.03624"" target=""_blank"">1910.03624</a>",,2025-12-03 22:39:25
Adversarial Examples for Cost-Sensitive Classifiers,"Gavin S. Hartnett, Andrew J. Lohn, Alexander P. Sedlack",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.02095"" target=""_blank"">1910.02095</a>",,2025-12-03 22:39:25
Unrestricted Adversarial Attacks for Semantic Segmentation,"Guangyu Shen, Chengzhi Mao, Junfeng Yang, Baishakhi Ray",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.02354"" target=""_blank"">1910.02354</a>",,2025-12-03 22:39:25
Attacking CNN-based anti-spoofing face authentication in the physical domain,"Bowen Zhang, Benedetta Tondi, Mauro Barni",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.00327"" target=""_blank"">1910.00327</a>",,2025-12-03 22:39:25
Adversarial Examples for Models of Code,"Noam Yefet, Uri Alon, Eran Yahav",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.07517"" target=""_blank"">1910.07517</a>",,2025-12-03 22:39:25
Training-Free Uncertainty Estimation for Dense Regression: Sensitivity as a Surrogate,"Lu Mi, Hao Wang, Yonglong Tian, Hao He, Nir Shavit",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.04858"" target=""_blank"">1910.04858</a>",,2025-12-03 22:39:25
Techniques for Adversarial Examples Threatening the Safety of Artificial Intelligence Based Systems,Utku Kose,arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.06907"" target=""_blank"">1910.06907</a>",,2025-12-03 22:39:25
Role of Spatial Context in Adversarial Robustness for Object Detection,"Aniruddha Saha, Akshayvarun Subramanya, Koninika Patil, Hamed Pirsiavash",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.00068"" target=""_blank"">1910.00068</a>",,2025-12-03 22:39:25
Deep Neural Rejection against Adversarial Examples,"Angelo Sotgiu, Ambra Demontis, Marco Melis, Battista Biggio, Giorgio Fumera, Xiaoyi Feng, Fabio Roli",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.00470"" target=""_blank"">1910.00470</a>",,2025-12-03 22:39:25
Cross-Layer Strategic Ensemble Defense Against Adversarial Examples,"Wenqi Wei, Ling Liu, Margaret Loper, Ka-Ho Chow, Emre Gursoy, Stacey Truex, Yanzhao Wu",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.01742"" target=""_blank"">1910.01742</a>",,2025-12-03 22:39:25
An Efficient and Margin-Approaching Zero-Confidence Adversarial Attack,"Yang Zhang, Shiyu Chang, Mo Yu, Kaizhi Qian",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.00511"" target=""_blank"">1910.00511</a>",,2025-12-03 22:39:25
Generating Semantic Adversarial Examples with Differentiable Rendering,"Lakshya Jain, Wilson Wu, Steven Chen, Uyeong Jang, Varun Chandrasekaran, Sanjit Seshia, Somesh Jha",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.00727"" target=""_blank"">1910.00727</a>",,2025-12-03 22:39:25
Yet another but more efficient black-box adversarial attack: tiling and evolution strategies,"Laurent Meunier, Jamal Atif, Olivier Teytaud",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.02244"" target=""_blank"">1910.02244</a>",,2025-12-03 22:39:25
Boosting Image Recognition with Non-differentiable Constraints,"Xuan Li, Yuchen Lu, Peng Xu, Jizong Peng, Christian Desrosiers, Xue Liu",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.00736"" target=""_blank"">1910.00736</a>",,2025-12-03 22:39:25
Adversarially Robust Few-Shot Learning: A Meta-Learning Approach,"Micah Goldblum, Liam Fowl, Tom Goldstein",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.00982"" target=""_blank"">1910.00982</a>",,2025-12-03 22:39:25
Attacking Vision-based Perception in End-to-End Autonomous Driving Models,"Adith Boloor, Karthik Garimella, Xin He, Christopher Gill, Yevgeniy Vorobeychik, Xuan Zhang",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.01907"" target=""_blank"">1910.01907</a>","<a href=""https://github.com/xz-group/AdverseDrive"" target=""_blank"">xz-group</a>",2025-12-03 22:39:25
Verification of Neural Network Behaviour: Formal Guarantees for Power System Applications,"Andreas Venzke, Spyros Chatzivasileiadis",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.01624"" target=""_blank"">1910.01624</a>",,2025-12-03 22:39:25
BUZz: BUffer Zones for defending adversarial examples in image classification,"Kaleel Mahmood, Phuong Ha Nguyen, Lam M. Nguyen, Thanh Nguyen, Dijk Marten van",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.02785"" target=""_blank"">1910.02785</a>",,2025-12-03 22:39:25
Perturbations are not Enough: Generating Adversarial Examples with Spatial Distortions,"He Zhao, Trung Le, Paul Montague, Vel Olivier De, Tamas Abraham, Dinh Phung",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.01329"" target=""_blank"">1910.01329</a>",,2025-12-03 22:39:25
Requirements for Developing Robust Neural Networks,"John S. Hyatt, Michael S. Lee",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.02125"" target=""_blank"">1910.02125</a>",,2025-12-03 22:39:25
On adversarial patches: real-world attack on ArcFace-100 face recognition system,"Mikhail Pautov, Grigorii Melnikov, Edgar Kaziakhmedov, Klim Kireev, Aleksandr Petiushko",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.07067"" target=""_blank"">1910.07067</a>",,2025-12-03 22:39:25
Enforcing Linearity in DNN succours Robustness and Adversarial Image Generation,"Anindya Sarkar, Nikhil Kumar Gupta, Raghu Iyengar",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.08108"" target=""_blank"">1910.08108</a>",,2025-12-03 22:39:25
Understanding Misclassifications by Attributes,"Sadaf Gulshad, Zeynep Akata, Jan Hendrik Metzen, Arnold Smeulders",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.07416"" target=""_blank"">1910.07416</a>",,2025-12-03 22:39:25
Word-level Textual Adversarial Attacking as Combinatorial Optimization,"Yuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Meng Zhang, Qun Liu, Maosong Sun",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.12196"" target=""_blank"">1910.12196</a>","<a href=""https://github.com/thunlp/SememePSO-Attack"" target=""_blank"">thunlp</a>",2025-12-03 22:39:25
ATZSL: Defensive Zero-Shot Recognition in the Presence of Adversaries,"Xingxing Zhang, Shupeng Gui, Zhenfeng Zhu, Yao Zhao, Ji Liu",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.10994"" target=""_blank"">1910.10994</a>",,2025-12-03 22:39:25
Label Smoothing and Logit Squeezing: A Replacement for Adversarial Training?,"Ali Shafahi, Amin Ghiasi, Furong Huang, Tom Goldstein",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.11585"" target=""_blank"">1910.11585</a>",,2025-12-03 22:39:25
MediaEval 2019: Concealed FGSM Perturbations for Privacy Preservation,"Panagiotis Linardos, Suzanne Little, Kevin McGuinness",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.11603"" target=""_blank"">1910.11603</a>",,2025-12-03 22:39:25
Effectiveness of random deep feature selection for securing image manipulation detectors against adversarial examples,"Mauro Barni, Ehsan Nowroozi, Benedetta Tondi, Bowen Zhang",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.12392"" target=""_blank"">1910.12392</a>",,2025-12-03 22:39:25
Adversarial Defense Via Local Flatness Regularization,"Jia Xu, Yiming Li, Yong Jiang, Shu-Tao Xia",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.12165"" target=""_blank"">1910.12165</a>",,2025-12-03 22:39:25
Detection of Adversarial Attacks and Characterization of Adversarial Subspace,"Mohammad Esmaeilpour, Patrick Cardinal, Alessandro Lameiras Koerich",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.12084"" target=""_blank"">1910.12084</a>",,2025-12-03 22:39:25
EdgeFool: An Adversarial Image Enhancement Filter,"Ali Shahin Shamsabadi, Changjae Oh, Andrea Cavallaro",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.12227"" target=""_blank"">1910.12227</a>","<a href=""https://github.com/smartcameras/EdgeFool"" target=""_blank"">smartcameras</a>",2025-12-03 22:39:25
Certified Adversarial Robustness for Deep Reinforcement Learning,"Björn Lütjens, Michael Everett, Jonathan P. How",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.12908"" target=""_blank"">1910.12908</a>",,2025-12-03 22:39:25
Wasserstein Smoothing: Certified Robustness against Wasserstein Adversarial Attacks,"Alexander Levine, Soheil Feizi",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.10783"" target=""_blank"">1910.10783</a>",,2025-12-03 22:39:25
Active Subspace of Neural Networks: Structural Analysis and Universal Attacks,"Chunfeng Cui, Kaiqi Zhang, Talgat Daulbaev, Julia Gusak, Ivan Oseledets, Zheng Zhang",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.13025"" target=""_blank"">1910.13025</a>",,2025-12-03 22:39:25
Adversarial Example in Remote Sensing Image Recognition,"Li Chen, Guowei Zhu, Qi Li, Haifeng Li",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.13222"" target=""_blank"">1910.13222</a>",,2025-12-03 22:39:25
Beyond Universal Person Re-ID Attack,"Wenjie Ding, Xing Wei, Rongrong Ji, Xiaopeng Hong, Qi Tian, Yihong Gong",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.14184"" target=""_blank"">1910.14184</a>",,2025-12-03 22:39:25
Investigating Resistance of Deep Learning-based IDS against Adversaries using min-max Optimization,"Rana Abou Khamis, Omair Shafiq, Ashraf Matrawy",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.14107"" target=""_blank"">1910.14107</a>",,2025-12-03 22:39:25
Improving Robustness of time series classifier with Neural ODE guided gradient based data augmentation,"Anindya Sarkar, Anirudh Sunder Raj, Raghu Sesha Iyengar",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.06813"" target=""_blank"">1910.06813</a>",,2025-12-03 22:39:25
Certifiable Robustness to Graph Perturbations,"Aleksandar Bojchevski, Stephan Günnemann",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.14356"" target=""_blank"">1910.14356</a>",,2025-12-03 22:39:25
Enhancing Certifiable Robustness via a Deep Model Ensemble,"Huan Zhang, Minhao Cheng, Cho-Jui Hsieh",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.14655"" target=""_blank"">1910.14655</a>",,2025-12-03 22:39:25
A Useful Taxonomy for Adversarial Robustness of Neural Networks,Leslie N. Smith,arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.10679"" target=""_blank"">1910.10679</a>",,2025-12-03 22:39:25
Understanding and Quantifying Adversarial Examples Existence in Linear Classification,"Xupeng Shi, A. Adam Ding",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.12163"" target=""_blank"">1910.12163</a>",,2025-12-03 22:39:25
Attacking Optical Flow,"Anurag Ranjan, Joel Janai, Andreas Geiger, Michael J. Black",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.10053"" target=""_blank"">1910.10053</a>",,2025-12-03 22:39:25
Toward Metrics for Differentiating Out-of-Distribution Sets,"Mahdieh Abbasi, Changjian Shui, Arezoo Rajabi, Christian Gagne, Rakesh Bobba",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.08650"" target=""_blank"">1910.08650</a>",,2025-12-03 22:39:25
A New Defense Against Adversarial Images: Turning a Weakness into a Strength,"Tao Yu, Shengyuan Hu, Chuan Guo, Wei-Lun Chao, Kilian Q. Weinberger",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.07629"" target=""_blank"">1910.07629</a>",,2025-12-03 22:39:25
Adversarial T-shirt! Evading Person Detectors in A Physical World,"Kaidi Xu, Gaoyuan Zhang, Sijia Liu, Quanfu Fan, Mengshu Sun, Hongge Chen, Pin-Yu Chen, Yanzhi Wang, Xue Lin",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.11099"" target=""_blank"">1910.11099</a>",,2025-12-03 22:39:25
Adversarial Example Detection by Classification for Deep Speech Recognition,"Saeid Samizade, Zheng-Hua Tan, Chao Shen, Xiaohong Guan",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.10013"" target=""_blank"">1910.10013</a>",,2025-12-03 22:39:25
LanCe: A Comprehensive and Lightweight CNN Defense Methodology against Physical Adversarial Attacks on Embedded Multimedia Applications,"Zirui Xu, Fuxun Yu, Xiang Chen",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.08536"" target=""_blank"">1910.08536</a>",,2025-12-03 22:39:25
Instance adaptive adversarial training: Improved accuracy tradeoffs in neural nets,"Yogesh Balaji, Tom Goldstein, Judy Hoffman",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.08051"" target=""_blank"">1910.08051</a>",,2025-12-03 22:39:25
A Fast Saddle-Point Dynamical System Approach to Robust Deep Learning,"Yasaman Esfandiari, Aditya Balu, Keivan Ebrahimi, Umesh Vaidya, Nicola Elia, Soumik Sarkar",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.08623"" target=""_blank"">1910.08623</a>",,2025-12-03 22:39:25
Are Perceptually-Aligned Gradients a General Property of Robust Classifiers?,"Simran Kaur, Jeremy Cohen, Zachary C. Lipton",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.08640"" target=""_blank"">1910.08640</a>",,2025-12-03 22:39:25
Spatial-aware Online Adversarial Perturbations Against Visual Object Tracking,"Qing Guo, Xiaofei Xie, Lei Ma, Zhongguo Li, Wei Feng, Yang Liu",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.08681"" target=""_blank"">1910.08681</a>",,2025-12-03 22:39:25
Adversarial Attacks on Spoofing Countermeasures of automatic speaker verification,"Songxiang Liu, Haibin Wu, Hung-yi Lee, Helen Meng",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.08716"" target=""_blank"">1910.08716</a>",,2025-12-03 22:39:25
Enhancing Recurrent Neural Networks with Sememes,"Yujia Qin, Fanchao Qi, Sicong Ouyang, Zhiyuan Liu, Cheng Yang, Yasheng Wang, Qun Liu, Maosong Sun",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.08910"" target=""_blank"">1910.08910</a>",,2025-12-03 22:39:25
An Alternative Surrogate Loss for PGD-based Adversarial Testing,"Sven Gowal, Jonathan Uesato, Chongli Qin, Po-Sen Huang, Timothy Mann, Pushmeet Kohli",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.09338"" target=""_blank"">1910.09338</a>",,2025-12-03 22:39:25
Learning to Learn by Zeroth-Order Oracle,"Yangjun Ruan, Yuanhao Xiong, Sashank Reddi, Sanjiv Kumar, Cho-Jui Hsieh",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.09464"" target=""_blank"">1910.09464</a>",,2025-12-03 22:39:25
Recovering Localized Adversarial Attacks,"Jan Philip Göpfert, Heiko Wersing, Barbara Hammer",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.09239"" target=""_blank"">1910.09239</a>",,2025-12-03 22:39:25
Structure Matters: Towards Generating Transferable Adversarial Images,"Dan Peng, Zizhan Zheng, Linhao Luo, Xiaofeng Zhang",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.09821"" target=""_blank"">1910.09821</a>",,2025-12-03 22:39:25
Cross-Representation Transferability of Adversarial Attacks: From Spectrograms to Audio Waveforms,"Karl M. Koerich, Mohammad Esmailpour, Sajjad Abdoli, Alceu S. Jr. Britto, Alessandro L. Koerich",arXiv,2019-10,"<a href=""http://arxiv.org/abs/1910.10106"" target=""_blank"">1910.10106</a>",,2025-12-03 22:39:25
Inspecting adversarial examples using the Fisher information,"Jörg Martin, Clemens Elster",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.05527"" target=""_blank"">1909.05527</a>",,2025-12-03 22:39:25
Identifying and Resisting Adversarial Videos Using Temporal Consistency,"Xiaojun Jia, Xingxing Wei, Xiaochun Cao",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.04837"" target=""_blank"">1909.04837</a>",,2025-12-03 22:39:25
Localized Adversarial Training for Increased Accuracy and Robustness in Image Classification,"Eitan Rothberg, Tingting Chen, Luo Jie, Hao Ji",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.04779"" target=""_blank"">1909.04779</a>",,2025-12-03 22:39:25
Sparse and Imperceivable Adversarial Attacks,"Francesco Croce, Matthias Hein",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.05040"" target=""_blank"">1909.05040</a>",,2025-12-03 22:39:25
Feedback Learning for Improving the Robustness of Neural Networks,"Chang Song, Zuoguan Wang, Hai Li",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.05443"" target=""_blank"">1909.05443</a>",,2025-12-03 22:39:25
Transferable Adversarial Robustness using Adversarially Trained Autoencoders,"Pratik Vaishnavi, Kevin Eykholt, Atul Prakash, Amir Rahmati",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.05921"" target=""_blank"">1909.05921</a>",,2025-12-03 22:39:25
An Empirical Investigation of Randomized Defenses against Adversarial Attacks,"Yannik Potdevin, Dirk Nowotka, Vijay Ganesh",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.05580"" target=""_blank"">1909.05580</a>",,2025-12-03 22:39:25
An Empirical Study towards Characterizing Deep Learning Development and Deployment across Different Frameworks and Platforms,"Qianyu Guo, Sen Chen, Xiaofei Xie, Lei Ma, Qiang Hu, Hongtao Liu, Yang Liu, Jianjun Zhao, Xiaohong Li",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.06727"" target=""_blank"">1909.06727</a>",,2025-12-03 22:39:25
Defending Against Adversarial Attacks by Suppressing the Largest Eigenvalue of Fisher Information Matrix,"Chaomin Shen, Yaxin Peng, Guixu Zhang, Jinsong Fan",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.06137"" target=""_blank"">1909.06137</a>",,2025-12-03 22:39:25
White-Box Adversarial Defense via Self-Supervised Data Estimation,"Zudi Lin, Hanspeter Pfister, Ziming Zhang",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.06271"" target=""_blank"">1909.06271</a>",,2025-12-03 22:39:25
Say What I Want: Towards the Dark Side of Neural Dialogue Models,"Haochen Liu, Tyler Derr, Zitao Liu, Jiliang Tang",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.06044"" target=""_blank"">1909.06044</a>",,2025-12-03 22:39:25
Adversarial Attack on Skeleton-based Human Action Recognition,"Jian Liu, Naveed Akhtar, Ajmal Mian",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.06500"" target=""_blank"">1909.06500</a>",,2025-12-03 22:39:25
Natural Language Adversarial Attacks and Defenses in Word Level,"Xiaosen Wang, Hao Jin, Kun He",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.06723"" target=""_blank"">1909.06723</a>",,2025-12-03 22:39:25
Detecting Adversarial Samples Using Influence Functions and Nearest Neighbors,"Gilad Cohen, Guillermo Sapiro, Raja Giryes",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.06872"" target=""_blank"">1909.06872</a>",,2025-12-03 22:39:25
Towards Noise-Robust Neural Networks via Progressive Adversarial Training,"Hang Yu, Aishan Liu, Xianglong Liu, Jichen Yang, Chongzhi Zhang",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.04839"" target=""_blank"">1909.04839</a>",,2025-12-03 22:39:25
Effectiveness of Adversarial Examples and Defenses for Malware Classification,"Robert Podschwadt, Hassan Takabi",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.04778"" target=""_blank"">1909.04778</a>",,2025-12-03 22:39:25
Metric Learning for Adversarial Robustness,"Chengzhi Mao, Ziyuan Zhong, Junfeng Yang, Carl Vondrick, Baishakhi Ray",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.00900"" target=""_blank"">1909.00900</a>",,2025-12-03 22:39:25
UPC: Learning Universal Physical Camouflage Attacks on Object Detectors,"Lifeng Huang, Chengying Gao, Yuyin Zhou, Changqing Zou, Cihang Xie, Alan Yuille, Ning Liu",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.04326"" target=""_blank"">1909.04326</a>","<a href=""https://mesunhlf.github.io/index_physical.html"" target=""_blank"">mesunhlf.github.io</a>",2025-12-03 22:39:25
Blackbox Attacks on Reinforcement Learning Agents Using Approximated Temporal Information,"Yiren Zhao, Ilia Shumailov, Han Cui, Xitong Gao, Robert Mullins, Ross Anderson",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.02918"" target=""_blank"">1909.02918</a>",,2025-12-03 22:39:25
Towards Quality Assurance of Software Product Lines with Adversarial Configurations,"Paul Temple, Mathieu Acher, Gilles Perrouin, Battista Biggio, Jean-marc Jezequel, Fabio Roli",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.07283"" target=""_blank"">1909.07283</a>",,2025-12-03 22:39:25
Achieving Verified Robustness to Symbol Substitutions via Interval Bound Propagation,"Po-Sen Huang, Robert Stanforth, Johannes Welbl, Chris Dyer, Dani Yogatama, Sven Gowal, Krishnamurthy Dvijotham, Pushmeet Kohli",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.01492"" target=""_blank"">1909.01492</a>",,2025-12-03 22:39:25
Certified Robustness to Adversarial Word Substitutions,"Robin Jia, Aditi Raghunathan, Kerem Göksel, Percy Liang",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.00986"" target=""_blank"">1909.00986</a>",,2025-12-03 22:39:25
Are Adversarial Robustness and Common Perturbation Robustness Independent Attributes ?,"Alfred Laugros, Alice Caplier, Matthieu Ospici",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.02436"" target=""_blank"">1909.02436</a>",,2025-12-03 22:39:25
Adversarial Examples with Difficult Common Words for Paraphrase Identification,"Zhouxing Shi, Minlie Huang, Ting Yao, Jingfang Xu",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.02560"" target=""_blank"">1909.02560</a>",,2025-12-03 22:39:25
Spatiotemporally Constrained Action Space Attacks on Deep Reinforcement Learning Agents,"Xian Yeow Lee, Sambit Ghadai, Kai Liang Tan, Chinmay Hegde, Soumik Sarkar",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.02583"" target=""_blank"">1909.02583</a>",,2025-12-03 22:39:25
Natural Adversarial Sentence Generation with Gradient-based Perturbation,"Yu-Lun Hsieh, Minhao Cheng, Da-Cheng Juan, Wei Wei, Wen-Lian Hsu, Cho-Jui Hsieh",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.04495"" target=""_blank"">1909.04495</a>",,2025-12-03 22:39:25
FDA: Feature Disruptive Attack,"Aditya Ganeshan, B. S. Vivek, R. Venkatesh Babu",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.04385"" target=""_blank"">1909.04385</a>","<a href=""https://github.com/BardOfCodes/fda"" target=""_blank"">BardOfCodes</a>",2025-12-03 22:39:25
Learning to Discriminate Perturbations for Blocking Adversarial Attacks in Text Classification,"Yichao Zhou, Jyun-Yu Jiang, Kai-Wei Chang, Wei Wang",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.03084"" target=""_blank"">1909.03084</a>",,2025-12-03 22:39:25
STA: Adversarial Attacks on Siamese Trackers,"Xugang Wu, Xiaoping Wang, Xu Zhou, Songlei Jian",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.03413"" target=""_blank"">1909.03413</a>",,2025-12-03 22:39:25
DeepObfuscator: Obfuscating Intermediate Representations with Privacy-Preserving Adversarial Learning on Smartphones,"Ang Li, Jiayi Guo, Huanrui Yang, Flora D. Salim, Yiran Chen",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.04126"" target=""_blank"">1909.04126</a>",,2025-12-03 22:39:25
Adversarial Robustness Against the Union of Multiple Perturbation Models,"Pratyush Maini, Eric Wong, J. Zico Kolter",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.04068"" target=""_blank"">1909.04068</a>",,2025-12-03 22:39:25
Toward Finding The Global Optimal of Adversarial Examples,"Zhenxin Xiao, Kai-Wei Chang, Cho-Jui Hsieh",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.04288"" target=""_blank"">1909.04288</a>",,2025-12-03 22:39:25
Learning to Disentangle Robust and Vulnerable Features for Adversarial Detection,"Byunggill Joe, Sung Ju Hwang, Insik Shin",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.04311"" target=""_blank"">1909.04311</a>",,2025-12-03 22:39:25
Interpreting and Improving Adversarial Robustness with Neuron Sensitivity,"Chongzhi Zhang, Aishan Liu, Xianglong Liu, Yitao Xu, Hang Yu, Yuqing Ma, Tianlin Li",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.06978"" target=""_blank"">1909.06978</a>",,2025-12-03 22:39:25
When Explainability Meets Adversarial Learning: Detecting Adversarial Examples using SHAP Signatures,"Gil Fidel, Ron Bitton, Asaf Shabtai",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.03418"" target=""_blank"">1909.03418</a>",,2025-12-03 22:39:25
HAD-GAN: A Human-perception Auxiliary Defense GAN to Defend Adversarial Examples,"Wanting Yu, Hongyi Yu, Lingyun Jiang, Mengli Zhang, Kai Qiao, Linyuan Wang, Bin Yan",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.07558"" target=""_blank"">1909.07558</a>",,2025-12-03 22:39:25
Lower Bounds on Adversarial Robustness from Optimal Transport,"Arjun Nitin Bhagoji, Daniel Cullina, Prateek Mittal",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.12272"" target=""_blank"">1909.12272</a>",,2025-12-03 22:39:25
Intelligent image synthesis to attack a segmentation CNN using adversarial learning,"Liang Chen, Paul Bentley, Kensaku Mori, Kazunari Misawa, Michitaka Fujiwara, Daniel Rueckert",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.11167"" target=""_blank"">1909.11167</a>",,2025-12-03 22:39:25
A Visual Analytics Framework for Adversarial Text Generation,"Brandon Laughlin, Christopher Collins, Karthik Sankaranarayanan, Khalil El-Khatib",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.11202"" target=""_blank"">1909.11202</a>",,2025-12-03 22:39:25
FreeLB: Enhanced Adversarial Training for Natural Language Understanding,"Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, Jingjing Liu",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.11764"" target=""_blank"">1909.11764</a>","<a href=""https://github.com/zhuchen03/FreeLB"" target=""_blank"">zhuchen03</a>",2025-12-03 22:39:25
Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks,"Tianyu Pang, Kun Xu, Jun Zhu",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.11515"" target=""_blank"">1909.11515</a>",,2025-12-03 22:39:25
Black-box Adversarial Attacks with Bayesian Optimization,"Satya Narayan Shukla, Anit Kumar Sahu, Devin Willmott, J. Zico Kolter",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.13857"" target=""_blank"">1909.13857</a>",,2025-12-03 22:39:25
Probabilistic Modeling of Deep Features for Out-of-Distribution and Adversarial Detection,"Nilesh A. Ahuja, Ibrahima Ndiour, Trushant Kalyanpur, Omesh Tickoo",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.11786"" target=""_blank"">1909.11786</a>",,2025-12-03 22:39:25
Towards neural networks that provably know when they don't know,"Alexander Meinke, Matthias Hein",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.12180"" target=""_blank"">1909.12180</a>",,2025-12-03 22:39:25
Matrix Sketching for Secure Collaborative Machine Learning,"Mengjiao Zhang, Shusen Wang",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.11201"" target=""_blank"">1909.11201</a>",,2025-12-03 22:39:25
Adversarial ML Attack on Self Organizing Cellular Networks,"Salah-ud-din Farooq, Muhammad Usama, Junaid Qadir, Muhammad Ali Imran",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.12161"" target=""_blank"">1909.12161</a>",,2025-12-03 22:39:25
Towards Understanding the Transferability of Deep Representations,"Hong Liu, Mingsheng Long, Jianmin Wang, Michael I. Jordan",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.12031"" target=""_blank"">1909.12031</a>",,2025-12-03 22:39:25
Impact of Low-bitwidth Quantization on the Adversarial Robustness for Embedded Neural Networks,"Rémi Bernhard, Pierre-Alain Moellic, Jean-Max Dutertre",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.12741"" target=""_blank"">1909.12741</a>",,2025-12-03 22:39:25
Maximal adversarial perturbations for obfuscation: Hiding certain attributes while preserving rest,"Indu Ilanchezian, Praneeth Vepakomma, Abhishek Singh, Otkrist Gupta, G. N. Srinivasa Prasanna, Ramesh Raskar",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.12734"" target=""_blank"">1909.12734</a>",,2025-12-03 22:39:25
Min-Max Optimization without Gradients: Convergence and Applications to Adversarial ML,"Sijia Liu, Songtao Lu, Xiangyi Chen, Yao Feng, Kaidi Xu, Abdullah Al-Dujaili, Minyi Hong, Una-May O'Reilly",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.13806"" target=""_blank"">1909.13806</a>",,2025-12-03 22:39:25
They Might NOT Be Giants: Crafting Black-Box Adversarial Examples with Fewer Queries Using Particle Swarm Optimization,"Rayan Mosli, Matthew Wright, Bo Yuan, Yin Pan",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.07490"" target=""_blank"">1909.07490</a>",,2025-12-03 22:39:25
Sign-OPT: A Query-Efficient Hard-label Adversarial Attack,"Minhao Cheng, Simranjit Singh, Patrick Chen, Pin-Yu Chen, Sijia Liu, Cho-Jui Hsieh",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.10773"" target=""_blank"">1909.10773</a>",,2025-12-03 22:39:25
Adversarial Machine Learning Attack on Modulation Classification,"Muhammad Usama, Muhammad Asim, Junaid Qadir, Ala Al-Fuqaha, Muhammad Ali Imran",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.12167"" target=""_blank"">1909.12167</a>",,2025-12-03 22:39:25
MemGuard: Defending against Black-Box Membership Inference Attacks via Adversarial Examples,"Jinyuan Jia, Ahmed Salem, Michael Backes, Yang Zhang, Neil Zhenqiang Gong",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.10594"" target=""_blank"">1909.10594</a>",,2025-12-03 22:39:25
Adversarial Vulnerability Bounds for Gaussian Process Classification,"Michael Thomas Smith, Kathrin Grosse, Michael Backes, Mauricio A Alvarez",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.08864"" target=""_blank"">1909.08864</a>",,2025-12-03 22:39:25
Robust Local Features for Improving the Generalization of Adversarial Training,"Chuanbiao Song, Kun He, Jiadong Lin, Liwei Wang, John E. Hopcroft",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.10147"" target=""_blank"">1909.10147</a>",,2025-12-03 22:39:25
Defending against Machine Learning based Inference Attacks via Adversarial Examples: Opportunities and Challenges,"Jinyuan Jia, Neil Zhenqiang Gong",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.08526"" target=""_blank"">1909.08526</a>",,2025-12-03 22:39:25
Generating Black-Box Adversarial Examples for Text Classifiers Using a Deep Reinforced Model,"Prashanth Vijayaraghavan, Deb Roy",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.07873"" target=""_blank"">1909.07873</a>",,2025-12-03 22:39:25
"Adversarial Attacks and Defenses in Images, Graphs and Text: A Review","Han Xu, Yao Ma, Haochen Liu, Debayan Deb, Hui Liu, Jiliang Tang, Anil Jain",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.08072"" target=""_blank"">1909.08072</a>",,2025-12-03 22:39:25
Toward Robust Image Classification,"Basemah Alshemali, Alta Graham, Jugal Kalita",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.12927"" target=""_blank"">1909.12927</a>",,2025-12-03 22:39:25
Absum: Simple Regularization Method for Reducing Structural Sensitivity of Convolutional Neural Networks,"Sekitoshi Kanai, Yasutoshi Ida, Yasuhiro Fujiwara, Masanori Yamada, Shuichi Adachi",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.08830"" target=""_blank"">1909.08830</a>",,2025-12-03 22:39:25
Training Robust Deep Neural Networks via Adversarial Noise Propagation,"Aishan Liu, Xianglong Liu, Chongzhi Zhang, Hang Yu, Qiang Liu, Dacheng Tao",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.09034"" target=""_blank"">1909.09034</a>",,2025-12-03 22:39:25
Propagated Perturbation of Adversarial Attack for well-known CNNs: Empirical Study and its Explanation,"Jihyeun Yoon, Kyungyul Kim, Jongseong Jang",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.09263"" target=""_blank"">1909.09263</a>",,2025-12-03 22:39:25
COPYCAT: Practical Adversarial Attacks on Visualization-Based Malware Detection,"Aminollah Khormali, Ahmed Abusnaina, Songqing Chen, DaeHun Nyang, Aziz Mohaisen",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.09735"" target=""_blank"">1909.09735</a>",,2025-12-03 22:39:25
Adversarial Learning with Margin-based Triplet Embedding Regularization,"Yaoyao Zhong, Weihong Deng",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.09481"" target=""_blank"">1909.09481</a>",,2025-12-03 22:39:25
Towards Interpreting Recurrent Neural Networks through Probabilistic Abstraction,"Guoliang Dong, Jingyi Wang, Jun Sun, Yang Zhang, Xinyu Wang, Ting Dai, Jin Song Dong, Xingen Wang",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.10023"" target=""_blank"">1909.10023</a>",,2025-12-03 22:39:25
HAWKEYE: Adversarial Example Detector for Deep Neural Networks,"Jinkyu Koo, Michael Roth, Saurabh Bagchi",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.09938"" target=""_blank"">1909.09938</a>",,2025-12-03 22:39:25
Defending Against Physically Realizable Attacks on Image Classification,"Tong Wu, Liang Tong, Yevgeniy Vorobeychik",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.09552"" target=""_blank"">1909.09552</a>",,2025-12-03 22:39:25
FENCE: Feasible Evasion Attacks on Neural Networks in Constrained Environments,"Alesia Chernikova, Alina Oprea",arXiv,2019-09,"<a href=""http://arxiv.org/abs/1909.10480"" target=""_blank"">1909.10480</a>",,2025-12-03 22:39:25
Defending Against Adversarial Iris Examples Using Wavelet Decomposition,"Sobhan Soleymani, Ali Dabouei, Jeremy Dawson, Nasser M. Nasrabadi",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.03176"" target=""_blank"">1908.03176</a>",,2025-12-03 22:39:25
Explaining Deep Neural Networks Using Spectrum-Based Fault Localization,"Youcheng Sun, Hana Chockler, Xiaowei Huang, Daniel Kroening",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.02374"" target=""_blank"">1908.02374</a>",,2025-12-03 22:39:25
Investigating Decision Boundaries of Trained Neural Networks,"Roozbeh Yousefzadeh, Dianne P O'Leary",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.02802"" target=""_blank"">1908.02802</a>",,2025-12-03 22:39:25
Improved Adversarial Robustness by Reducing Open Space Risk via Tent Activations,"Andras Rozsa, Terrance E. Boult",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.02435"" target=""_blank"">1908.02435</a>",,2025-12-03 22:39:25
Universal Adversarial Audio Perturbations,"Sajjad Abdoli, Luiz G. Hafemann, Jerome Rony, Ismail Ben Ayed, Patrick Cardinal, Alessandro L. Koerich",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.03173"" target=""_blank"">1908.03173</a>",,2025-12-03 22:39:25
Adversarial Neural Pruning with Latent Vulnerability Suppression,"Divyam Madaan, Jinwoo Shin, Sung Ju Hwang",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.04355"" target=""_blank"">1908.04355</a>",,2025-12-03 22:39:25
On the Adversarial Robustness of Neural Networks without Weight Transport,Mohamed Akrout,arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.03560"" target=""_blank"">1908.03560</a>",,2025-12-03 22:39:25
On Defending Against Label Flipping Attacks on Malware Detection Systems,"Rahim Taheri, Reza Javidan, Mohammad Shojafar, Zahra Pooranian, Ali Miri, Mauro Conti",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.04473"" target=""_blank"">1908.04473</a>",,2025-12-03 22:39:25
BlurNet: Defense by Filtering the Feature Maps,"Ravi Raju, Mikko Lipasti",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.02256"" target=""_blank"">1908.02256</a>",,2025-12-03 22:39:25
DAPAS : Denoising Autoencoder to Prevent Adversarial attack in Semantic Segmentation,"Seungju Cho, Tae Joon Jun, Byungsoo Oh, Daeyoung Kim",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.05195"" target=""_blank"">1908.05195</a>",,2025-12-03 22:39:25
MetaAdvDet: Towards Robust Detection of Evolving Adversarial Attacks,"Chen Ma, Chenxu Zhao, Hailin Shi, Li Chen, Junhai Yong, Dan Zeng",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.02199"" target=""_blank"">1908.02199</a>",,2025-12-03 22:39:25
AdvGAN++ : Harnessing latent layers for adversary generation,"Puneet Mangla, Surgan Jandial, Sakshi Varshney, Vineeth N Balasubramanian",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.00706"" target=""_blank"">1908.00706</a>",,2025-12-03 22:39:25
Random Directional Attack for Fooling Deep Neural Networks,"Wenjian Luo, Chenwang Wu, Nan Zhou, Li Ni",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.02658"" target=""_blank"">1908.02658</a>",,2025-12-03 22:39:25
Adversarial Self-Defense for Cycle-Consistent GANs,"Dina Bashkirova, Ben Usman, Kate Saenko",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.01517"" target=""_blank"">1908.01517</a>",,2025-12-03 22:39:25
Automated Detection System for Adversarial Examples with High-Frequency Noises Sieve,"Dang Duy Thang, Toshihiro Matsui",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.01469"" target=""_blank"">1908.01469</a>",,2025-12-03 22:39:25
A principled approach for generating adversarial images under non-smooth dissimilarity metrics,"Aram-Alexandre Pooladian, Chris Finlay, Tim Hoheisel, Adam Oberman",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.01667"" target=""_blank"">1908.01667</a>",,2025-12-03 22:39:25
Imperio: Robust Over-the-Air Adversarial Examples for Automatic Speech Recognition Systems,"Lea Schönherr, Thorsten Eisenhofer, Steffen Zeiler, Thorsten Holz, Dorothea Kolossa",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.01551"" target=""_blank"">1908.01551</a>",,2025-12-03 22:39:25
A Restricted Black-box Adversarial Framework Towards Attacking Graph Embedding Models,"Heng Chang, Yu Rong, Tingyang Xu, Wenbing Huang, Honglei Zhang, Peng Cui, Wenwu Zhu, Junzhou Huang",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.01297"" target=""_blank"">1908.01297</a>",,2025-12-03 22:39:25
Exploring the Robustness of NMT Systems to Nonsensical Inputs,"Akshay Chaturvedi, Abijith KP, Utpal Garain",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.01165"" target=""_blank"">1908.01165</a>",,2025-12-03 22:39:25
Black-box Adversarial ML Attack on Modulation Classification,"Muhammad Usama, Junaid Qadir, Ala Al-Fuqaha",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.00635"" target=""_blank"">1908.00635</a>",,2025-12-03 22:39:25
Robustifying deep networks for image segmentation,"Zheng Liu, Jinnian Zhang, Varun Jog, Po-Ling Loh, Alan B McMillan",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.00656"" target=""_blank"">1908.00656</a>",,2025-12-03 22:39:25
Adversarial Robustness Curves,"Christina Göpfert, Jan Philip Göpfert, Barbara Hammer",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.00096"" target=""_blank"">1908.00096</a>",,2025-12-03 22:39:25
Once a MAN: Towards Multi-Target Attack via Learning Multi-Target Adversarial Network Once,"Jiangfan Han, Xiaoyi Dong, Ruimao Zhang, Dongdong Chen, Weiming Zhang, Nenghai Yu, Ping Luo, Xiaogang Wang",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.05185"" target=""_blank"">1908.05185</a>",,2025-12-03 22:39:25
AdvFaces: Adversarial Face Synthesis,"Debayan Deb, Jianbang Zhang, Anil K. Jain",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.05008"" target=""_blank"">1908.05008</a>",,2025-12-03 22:39:25
Hybrid Batch Attacks: Finding Black-box Adversarial Examples with Limited Queries,"Fnu Suya, Jianfeng Chi, David Evans, Yuan Tian",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.07000"" target=""_blank"">1908.07000</a>",,2025-12-03 22:39:25
Adversarial point perturbations on 3D objects,"Daniel Liu, Ronald Yu, Hao Su",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.06062"" target=""_blank"">1908.06062</a>",,2025-12-03 22:39:25
AdvHat: Real-world adversarial attack on ArcFace Face ID system,"Stepan Komkov, Aleksandr Petiushko",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.08705"" target=""_blank"">1908.08705</a>",,2025-12-03 22:39:25
Adversarial Training Methods for Network Embedding,"Quanyu Dai, Xiao Shen, Liang Zhang, Qiang Li, Dan Wang",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.11514"" target=""_blank"">1908.11514</a>",,2025-12-03 22:39:25
Nesterov Accelerated Gradient and Scale Invariance for Adversarial Attacks,"Jiadong Lin, Chuanbiao Song, Kun He, Liwei Wang, John E. Hopcroft",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.06281"" target=""_blank"">1908.06281</a>",,2025-12-03 22:39:25
"Deep Neural Network Ensembles against Deception: Ensemble Diversity, Accuracy and Robustness","Ling Liu, Wenqi Wei, Ka-Ho Chow, Margaret Loper, Emre Gursoy, Stacey Truex, Yanzhao Wu",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.11091"" target=""_blank"">1908.11091</a>",,2025-12-03 22:39:25
Defeating Misclassification Attacks Against Transfer Learning,"Bang Wu, Shuo Wang, Xingliang Yuan, Cong Wang, Carsten Rudolph, Xiangwen Yang",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.11230"" target=""_blank"">1908.11230</a>",,2025-12-03 22:39:25
"Universal, transferable and targeted adversarial attacks","Junde Wu, Rao Fu",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.11332"" target=""_blank"">1908.11332</a>",,2025-12-03 22:39:25
A Statistical Defense Approach for Detecting Adversarial Examples,"Alessandro Cennamo, Ido Freeman, Anton Kummert",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.09705"" target=""_blank"">1908.09705</a>",,2025-12-03 22:39:25
Gated Convolutional Networks with Hybrid Connectivity for Image Classification,"Chuanguang Yang, Zhulin An, Hui Zhu, Xiaolong Hu, Kun Zhang, Kaiqiang Xu, Chao Li, Yongjun Xu",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.09699"" target=""_blank"">1908.09699</a>",,2025-12-03 22:39:25
advPattern: Physical-World Attacks on Deep Person Re-Identification via Adversarially Transformable Patterns,"Zhibo Wang, Siyan Zheng, Mengkai Song, Qian Wang, Alireza Rahimpour, Hairong Qi",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.09327"" target=""_blank"">1908.09327</a>",,2025-12-03 22:39:25
Targeted Mismatch Adversarial Attack: Query with a Flower to Retrieve the Tower,"Giorgos Tolias, Filip Radenovic, Ond{ř}ej Chum",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.09163"" target=""_blank"">1908.09163</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness via Attention and Adversarial Logit Pairing,"Dou Goodman, Xingjian Li, Jun Huan, Tao Wei",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.11435"" target=""_blank"">1908.11435</a>",,2025-12-03 22:39:25
Adversarial Edit Attacks for Tree Data,Benjamin Paaßen,arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.09364"" target=""_blank"">1908.09364</a>",,2025-12-03 22:39:25
Saliency Methods for Explaining Adversarial Attacks,"Jindong Gu, Volker Tresp",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.08413"" target=""_blank"">1908.08413</a>",,2025-12-03 22:39:25
Universal Adversarial Triggers for NLP,"Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, Sameer Singh",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.07125"" target=""_blank"">1908.07125</a>",,2025-12-03 22:39:25
Verification of Neural Network Control Policy Under Persistent Adversarial Perturbation,"Yuh-Shyang Wang, Tsui-Wei Weng, Luca Daniel",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.06353"" target=""_blank"">1908.06353</a>",,2025-12-03 22:39:25
Testing Robustness Against Unforeseen Adversaries,"Daniel Kang, Yi Sun, Dan Hendrycks, Tom Brown, Jacob Steinhardt",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.08016"" target=""_blank"">1908.08016</a>",,2025-12-03 22:39:25
On the Robustness of Human Pose Estimation,"Sahil Shah, Naman Jain, Abhishek Sharma, Arjun Jain",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.06401"" target=""_blank"">1908.06401</a>",,2025-12-03 22:39:25
Protecting Neural Networks with Hierarchical Random Switching: Towards Better Robustness-Accuracy Trade-off for Stochastic Defenses,"Xiao Wang, Siyue Wang, Pin-Yu Chen, Yanzhi Wang, Brian Kulis, Xue Lin, Peter Chin",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.07116"" target=""_blank"">1908.07116</a>",,2025-12-03 22:39:25
Adversarial Defense by Suppressing High-frequency Components,"Zhendong Zhang, Cheolkon Jung, Xiaolong Liang",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.06566"" target=""_blank"">1908.06566</a>",,2025-12-03 22:39:25
Transferring Robustness for Graph Neural Network Against Poisoning Attacks,"Xianfeng Tang, Yandong Li, Yiwei Sun, Huaxiu Yao, Prasenjit Mitra, Suhang Wang",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.07558"" target=""_blank"">1908.07558</a>","<a href=""https://github.com/tangxianfeng/PA-GNN"" target=""_blank"">tangxianfeng</a>",2025-12-03 22:39:25
Denoising and Verification Cross-Layer Ensemble Against Black-box Adversarial Attacks,"Ka-Ho Chow, Wenqi Wei, Yanzhao Wu, Ling Liu",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.07667"" target=""_blank"">1908.07667</a>",,2025-12-03 22:39:25
Evaluating Defensive Distillation For Defending Text Processing Neural Networks Against Adversarial Examples,"Marcus Soll, Tobias Hinz, Sven Magg, Stefan Wermter",arXiv,2019-08,"<a href=""http://arxiv.org/abs/1908.07899"" target=""_blank"">1908.07899</a>",,2025-12-03 22:39:25
Unsupervised Adversarial Attacks on Deep Feature-based Retrieval with GAN,"Guoping Zhao, Mingyu Zhang, Jiajun Liu, Ji-Rong Wen",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.05793"" target=""_blank"">1907.05793</a>",,2025-12-03 22:39:25
Adversarial Attacks in Sound Event Classification,"Vinod Subramanian, Emmanouil Benetos, Ning Xu, SKoT McDonald, Mark Sandler",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.02477"" target=""_blank"">1907.02477</a>",,2025-12-03 22:39:25
Stateful Detection of Black-Box Adversarial Attacks,"Steven Chen, Nicholas Carlini, David Wagner",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.05587"" target=""_blank"">1907.05587</a>",,2025-12-03 22:39:25
Generative Modeling by Estimating Gradients of the Data Distribution,"Yang Song, Stefano Ermon",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.05600"" target=""_blank"">1907.05600</a>",,2025-12-03 22:39:25
Why Blocking Targeted Adversarial Perturbations Impairs the Ability to Learn,"Ziv Katzir, Yuval Elovici",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.05718"" target=""_blank"">1907.05718</a>",,2025-12-03 22:39:25
Adversarial Objects Against LiDAR-Based Autonomous Driving Systems,"Yulong Cao, Chaowei Xiao, Dawei Yang, Jing Fang, Ruigang Yang, Mingyan Liu, Bo Li",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.05418"" target=""_blank"">1907.05418</a>",,2025-12-03 22:39:25
Metamorphic Detection of Adversarial Examples in Deep Learning Models With Affine Transformations,"Rohan Reddy Mekala, Gudjon Einar Magnusson, Adam Porter, Mikael Lindvall, Madeline Diep",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.04774"" target=""_blank"">1907.04774</a>",,2025-12-03 22:39:25
PhysGAN: Generating Physical-World-Resilient Adversarial Examples for Autonomous Driving,"Zelun Kong, Junfeng Guo, Ang Li, Cong Liu",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.04449"" target=""_blank"">1907.04449</a>",,2025-12-03 22:39:25
Affine Disentangled GAN for Interpretable and Robust AV Perception,"Letao Liu, Martin Saerbeck, Justin Dauwels",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.05274"" target=""_blank"">1907.05274</a>",,2025-12-03 22:39:25
Detecting and Diagnosing Adversarial Images with Class-Conditional Capsule Reconstructions,"Yao Qin, Nicholas Frosst, Sara Sabour, Colin Raffel, Garrison Cottrell, Geoffrey Hinton",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.02957"" target=""_blank"">1907.02957</a>",,2025-12-03 22:39:25
Adversarial Robustness through Local Linearization,"Chongli Qin, James Martens, Sven Gowal, Dilip Krishnan, Krishnamurthy Dvijotham, Alhussein Fawzi, Soham De, Robert Stanforth, Pushmeet Kohli",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.02610"" target=""_blank"">1907.02610</a>",,2025-12-03 22:39:25
Catfish Effect Between Internal and External Attackers:Being Semi-honest is Helpful,"Hanqing Liu, Na Ruan, Joseph K. Liu",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.03720"" target=""_blank"">1907.03720</a>",,2025-12-03 22:39:25
Robust Synthesis of Adversarial Visual Examples Using a Deep Image Prior,"Thomas Gittings, Steve Schneider, John Collomosse",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.01996"" target=""_blank"">1907.01996</a>",,2025-12-03 22:39:25
Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack,"Francesco Croce, Matthias Hein",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.02044"" target=""_blank"">1907.02044</a>",,2025-12-03 22:39:25
Efficient Cyber Attacks Detection in Industrial Control Systems Using Lightweight Neural Networks and PCA,"Moshe Kravchik, Asaf Shabtai",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.01216"" target=""_blank"">1907.01216</a>",,2025-12-03 22:39:25
Treant: Training Evasion-Aware Decision Trees,"Stefano Calzavara, Claudio Lucchese, Gabriele Tolomei, Seyum Assefa Abebe, Salvatore Orlando",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.01197"" target=""_blank"">1907.01197</a>",,2025-12-03 22:39:25
"Comment on ""Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network""",Roland S. Zimmermann,arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.00895"" target=""_blank"">1907.00895</a>",,2025-12-03 22:39:25
Diminishing the Effect of Adversarial Perturbations via Refining Feature Representation,"Nader Asadi, AmirMohammad Sarfi, Sahba Tahsini, Mahdi Eftekhari",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.01023"" target=""_blank"">1907.01023</a>",,2025-12-03 22:39:25
"Accurate, reliable and fast robustness evaluation","Wieland Brendel, Jonas Rauber, Matthias Kümmerer, Ivan Ustyuzhaninov, Matthias Bethge",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.01003"" target=""_blank"">1907.01003</a>",,2025-12-03 22:39:25
Fooling a Real Car with Adversarial Traffic Signs,"Nir Morgulis, Alexander Kreines, Shachar Mendelowitz, Yuval Weisglass",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.00374"" target=""_blank"">1907.00374</a>",,2025-12-03 22:39:25
Robustness Guarantees for Deep Neural Networks on Videos,"Min Wu, Marta Kwiatkowska",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.00098"" target=""_blank"">1907.00098</a>",,2025-12-03 22:39:25
Recovery Guarantees for Compressible Signals with Adversarial Noise,"Jasjeet Dhaliwal, Kyle Hambrook",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.06565"" target=""_blank"">1907.06565</a>",,2025-12-03 22:39:25
Measuring the Transferability of Adversarial Examples,"Deyan Petrov, Timothy M. Hospedales",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.06291"" target=""_blank"">1907.06291</a>",,2025-12-03 22:39:25
Understanding Adversarial Robustness: The Trade-off between Minimum and Average Margin,"Kaiwen Wu, Yaoliang Yu",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.11780"" target=""_blank"">1907.11780</a>",,2025-12-03 22:39:25
Graph Interpolating Activation Improves Both Natural and Robust Accuracies in Data-Efficient Deep Learning,"Bao Wang, Stanley J. Osher",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.06800"" target=""_blank"">1907.06800</a>","<a href=""https://github.com/BaoWangMath/DNN-DataDependentActivation"" target=""_blank"">BaoWangMath</a>",2025-12-03 22:39:25
Weakly Supervised Localization using Min-Max Entropy: an Interpretable Framework,"Soufiane Belharbi, Jérôme Rony, Jose Dolz, Ismail Ben Ayed, Luke McCaffrey, Eric Granger",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.12934"" target=""_blank"">1907.12934</a>","<a href=""https://github.com/sbelharbi/wsol-min-max-entropy-interpretability"" target=""_blank"">sbelharbi</a>",2025-12-03 22:39:25
Optimal Attacks on Reinforcement Learning Policies,"Alessio Russo, Alexandre Proutiere",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.13548"" target=""_blank"">1907.13548</a>",,2025-12-03 22:39:25
Explaining Vulnerabilities to Adversarial Machine Learning through Visual Analytics,"Yuxin Ma, Tiankai Xie, Jundong Li, Ross Maciejewski",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.07296"" target=""_blank"">1907.07296</a>",,2025-12-03 22:39:25
Impact of Adversarial Examples on Deep Learning Models for Biomedical Image Segmentation,"Utku Ozbulak, Messem Arnout Van, Neve Wesley De",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.13124"" target=""_blank"">1907.13124</a>","<a href=""https://github.com/utkuozbulak/adaptive-segmentation-mask-attack"" target=""_blank"">utkuozbulak</a>",2025-12-03 22:39:25
Are Odds Really Odd? Bypassing Statistical Detection of Adversarial Examples,"Hossein Hosseini, Sreeram Kannan, Radha Poovendran",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.12138"" target=""_blank"">1907.12138</a>",,2025-12-03 22:39:25
Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment,"Di Jin, Zhijing Jin, Joey Tianyi Zhou, Peter Szolovits",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.11932"" target=""_blank"">1907.11932</a>",,2025-12-03 22:39:25
On the Design of Black-box Adversarial Examples by Leveraging Gradient-free Optimization and Operator Splitting Method,"Pu Zhao, Sijia Liu, Pin-Yu Chen, Nghia Hoang, Kaidi Xu, Bhavya Kailkhura, Xue Lin",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.11684"" target=""_blank"">1907.11684</a>",,2025-12-03 22:39:25
Towards Adversarially Robust Object Detection,"Haichao Zhang, Jianyu Wang",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.10310"" target=""_blank"">1907.10310</a>",,2025-12-03 22:39:25
Joint Adversarial Training: Incorporating both Spatial and Pixel Attacks,"Haichao Zhang, Jianyu Wang",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.10737"" target=""_blank"">1907.10737</a>",,2025-12-03 22:39:25
Defense Against Adversarial Attacks Using Feature Scattering-based Adversarial Training,"Haichao Zhang, Jianyu Wang",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.10764"" target=""_blank"">1907.10764</a>",,2025-12-03 22:39:25
Not All Adversarial Examples Require a Complex Defense: Identifying Over-optimized Adversarial Examples with IQR-based Logit Thresholding,"Utku Ozbulak, Messem Arnout Van, Neve Wesley De",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.12744"" target=""_blank"">1907.12744</a>",,2025-12-03 22:39:25
Understanding Adversarial Attacks on Deep Learning Based Medical Image Analysis Systems,"Xingjun Ma, Yuhao Niu, Lin Gu, Yisen Wang, Yitian Zhao, James Bailey, Feng Lu",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.10456"" target=""_blank"">1907.10456</a>",,2025-12-03 22:39:25
Characterizing Attacks on Deep Reinforcement Learning,"Xinlei Pan, Chaowei Xiao, Warren He, Shuang Yang, Jian Peng, Mingjie Sun, Jinfeng Yi, Zijiang Yang, Mingyan Liu, Bo Li, Dawn Song",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.09470"" target=""_blank"">1907.09470</a>",,2025-12-03 22:39:25
Connecting Lyapunov Control Theory to Adversarial Attacks,"Arash Rahnama, Andre T. Nguyen, Edward Raff",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.07732"" target=""_blank"">1907.07732</a>",,2025-12-03 22:39:25
Robustness properties of Facebook's ResNeXt WSL models,A. Emin Orhan,arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.07640"" target=""_blank"">1907.07640</a>",,2025-12-03 22:39:25
Natural Adversarial Examples,"Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, Dawn Song",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.07174"" target=""_blank"">1907.07174</a>",,2025-12-03 22:39:25
Constrained Concealment Attacks against Reconstruction-based Anomaly Detectors in Industrial Control Systems,"Alessandro Erba, Riccardo Taormina, Stefano Galelli, Marcello Pogliani, Michele Carminati, Stefano Zanero, Nils Ole Tippenhauer",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.07487"" target=""_blank"">1907.07487</a>",,2025-12-03 22:39:25
Adversarial Security Attacks and Perturbations on Machine Learning and Deep Learning Methods,Arif Siddiqi,arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.07291"" target=""_blank"">1907.07291</a>",,2025-12-03 22:39:25
Enhancing Adversarial Example Transferability with an Intermediate Level Attack,"Qian Huang, Isay Katsman, Horace He, Zeqi Gu, Serge Belongie, Ser-Nam Lim",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.10823"" target=""_blank"">1907.10823</a>","<a href=""https://github.com/CUVL/Intermediate-Level-Attack"" target=""_blank"">CUVL</a>",2025-12-03 22:39:25
Adversarial Sensor Attack on LiDAR-based Perception in Autonomous Driving,"Yulong Cao, Chaowei Xiao, Benjamin Cyr, Yimeng Zhou, Won Park, Sara Rampazzi, Qi Alfred Chen, Kevin Fu, Z. Morley Mao",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.06826"" target=""_blank"">1907.06826</a>",,2025-12-03 22:39:25
Latent Adversarial Defence with Boundary-guided Generation,"Xiaowei Zhou, Ivor W. Tsang, Jie Yin",arXiv,2019-07,"<a href=""http://arxiv.org/abs/1907.07001"" target=""_blank"">1907.07001</a>",,2025-12-03 22:39:25
Adversarial Explanations for Understanding Image Classification Decisions and Improved Neural Network Robustness,"Walt Woods, Jack Chen, Christof Teuscher",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.02896"" target=""_blank"">1906.02896</a>",,2025-12-03 22:39:25
Efficient Project Gradient Descent for Ensemble Adversarial Attack,"Fanyou Wu, Rado Gazo, Eva Haviarova, Bedrich Benes",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03333"" target=""_blank"">1906.03333</a>",,2025-12-03 22:39:25
Inductive Bias of Gradient Descent based Adversarial Training on Separable Data,"Yan Li, Ethan X. Fang, Huan Xu, Tuo Zhao",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.02931"" target=""_blank"">1906.02931</a>",,2025-12-03 22:39:25
Robust Attacks against Multiple Classifiers,"Juan C. Perdomo, Yaron Singer",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.02816"" target=""_blank"">1906.02816</a>",,2025-12-03 22:39:25
Robustness for Non-Parametric Classification: A Generic Attack and Defense,"Yao-Yuan Yang, Cyrus Rashtchian, Yizhen Wang, Kamalika Chaudhuri",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03310"" target=""_blank"">1906.03310</a>","<a href=""https://github.com/yangarbiter/adversarial-nonparametrics/"" target=""_blank"">adversarial-nonparametrics</a>",2025-12-03 22:39:25
A cryptographic approach to black box adversarial machine learning,"Kevin Shi, Daniel Hsu, Allison Bishop",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03231"" target=""_blank"">1906.03231</a>",,2025-12-03 22:39:25
Improving Robustness Without Sacrificing Accuracy with Patch Gaussian Augmentation,"Raphael Gontijo Lopes, Dong Yin, Ben Poole, Justin Gilmer, Ekin D. Cubuk",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.02611"" target=""_blank"">1906.02611</a>",,2025-12-03 22:39:25
Understanding Adversarial Behavior of DNNs by Disentangling Non-Robust and Robust Components in Performance Metric,"Yujun Shi, Benben Liao, Guangyong Chen, Yun Liu, Ming-Ming Cheng, Jiashi Feng",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.02494"" target=""_blank"">1906.02494</a>",,2025-12-03 22:39:25
Using learned optimizers to make models robust to input noise,"Luke Metz, Niru Maheswaranathan, Jonathon Shlens, Jascha Sohl-Dickstein, Ekin D. Cubuk",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03367"" target=""_blank"">1906.03367</a>",,2025-12-03 22:39:25
ML-LOO: Detecting Adversarial Examples with Feature Attribution,"Puyudi Yang, Jianbo Chen, Cho-Jui Hsieh, Jane-Ling Wang, Michael I. Jordan",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03499"" target=""_blank"">1906.03499</a>",,2025-12-03 22:39:25
Defending Against Universal Attacks Through Selective Feature Regeneration,"Tejas Borkar, Felix Heide, Lina Karam",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03444"" target=""_blank"">1906.03444</a>",,2025-12-03 22:39:25
Making targeted black-box evasion attacks effective and efficient,"Mika Juuti, Buse Gul Atli, N. Asokan",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03397"" target=""_blank"">1906.03397</a>",,2025-12-03 22:39:25
Provably Robust Boosted Decision Stumps and Trees against Adversarial Attacks,"Maksym Andriushchenko, Matthias Hein",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03526"" target=""_blank"">1906.03526</a>","<a href=""http://github.com/max-andr/provably-robust-boosting"" target=""_blank"">max-andr</a>",2025-12-03 22:39:25
Sensitivity of Deep Convolutional Networks to Gabor Noise,"Kenneth T. Co, Luis Muñoz-González, Emil C. Lupu",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03455"" target=""_blank"">1906.03455</a>",,2025-12-03 22:39:25
Strategies to architect AI Safety: Defense to guard AI from Adversaries,"Rajagopal. A, Nirmala. V",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03466"" target=""_blank"">1906.03466</a>",,2025-12-03 22:39:25
Provably Robust Deep Learning via Adversarially Trained Smoothed Classifiers,"Hadi Salman, Greg Yang, Jerry Li, Pengchuan Zhang, Huan Zhang, Ilya Razenshteyn, Sebastien Bubeck",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.04584"" target=""_blank"">1906.04584</a>","<a href=""http://github.com/Hadisalman/smoothing-adversarial"" target=""_blank"">Hadisalman</a>",2025-12-03 22:39:25
Towards A Unified Min-Max Framework for Adversarial Exploration and Robustness,"Jingkang Wang, Tianyun Zhang, Sijia Liu, Pin-Yu Chen, Jiacen Xu, Makan Fardad, Bo Li",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03563"" target=""_blank"">1906.03563</a>",,2025-12-03 22:39:25
Image Synthesis with a Single (Robust) Classifier,"Shibani Santurkar, Dimitris Tsipras, Brandon Tran, Andrew Ilyas, Logan Engstrom, Aleksander Madry",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.09453"" target=""_blank"">1906.09453</a>",,2025-12-03 22:39:25
Attacking Graph Convolutional Networks via Rewiring,"Yao Ma, Suhang Wang, Tyler Derr, Lingfei Wu, Jiliang Tang",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03750"" target=""_blank"">1906.03750</a>",,2025-12-03 22:39:25
Improved Adversarial Robustness via Logit Regularization Methods,"Cecilia Summers, Michael J. Dinneen",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03749"" target=""_blank"">1906.03749</a>",,2025-12-03 22:39:25
Intriguing properties of adversarial training,"Cihang Xie, Alan Yuille",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03787"" target=""_blank"">1906.03787</a>",,2025-12-03 22:39:25
Should Adversarial Attacks Use Pixel p-Norm?,"Ayon Sen, Xiaojin Zhu, Liam Marshall, Robert Nowak",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.02439"" target=""_blank"">1906.02439</a>",,2025-12-03 22:39:25
The Adversarial Machine Learning Conundrum: Can The Insecurity of ML Become The Achilles' Heel of Cognitive Networks?,"Muhammad Usama, Junaid Qadir, Ala Al-Fuqaha, Mounir Hamdi",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.00679"" target=""_blank"">1906.00679</a>",,2025-12-03 22:39:25
MNIST-C: A Robustness Benchmark for Computer Vision,"Norman Mu, Justin Gilmer",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.02337"" target=""_blank"">1906.02337</a>",,2025-12-03 22:39:25
A Surprising Density of Illusionable Natural Speech,"Melody Y. Guan, Gregory Valiant",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.01040"" target=""_blank"">1906.01040</a>",,2025-12-03 22:39:25
Topology Attack and Defense for Graph Neural Networks: An Optimization Perspective,"Kaidi Xu, Hongge Chen, Sijia Liu, Pin-Yu Chen, Tsui-Wei Weng, Mingyi Hong, Xue Lin",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.04214"" target=""_blank"">1906.04214</a>",,2025-12-03 22:39:25
Functional Adversarial Attacks,"Cassidy Laidlaw, Soheil Feizi",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.00001"" target=""_blank"">1906.00001</a>","<a href=""https://github.com/cassidylaidlaw/ReColorAdv"" target=""_blank"">cassidylaidlaw</a>",2025-12-03 22:39:25
POBA-GA: Perturbation Optimized Black-Box Adversarial Attacks via Genetic Algorithm,"Jinyin Chen, Mengmeng Su, Shijing Shen, Hui Xiong, Haibin Zheng",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03181"" target=""_blank"">1906.03181</a>",,2025-12-03 22:39:25
Enhancing Transformation-based Defenses using a Distribution Classifier,"Connie Kou, Hwee Kuan Lee, Ee-Chien Chang, Teck Khim Ng",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.00258"" target=""_blank"">1906.00258</a>",,2025-12-03 22:39:25
Perceptual Evaluation of Adversarial Attacks for CNN-based Image Classification,"Sid Ahmed Fezza, Yassine Bakhti, Wassim Hamidouche, Olivier Déforges",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.00204"" target=""_blank"">1906.00204</a>",,2025-12-03 22:39:25
"Adversarial Examples for Edge Detection: They Exist, and They Transfer","Christian Cosgrove, Alan L. Yuille",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.00335"" target=""_blank"">1906.00335</a>",,2025-12-03 22:39:25
Adversarially Robust Generalization Just Requires More Unlabeled Data,"Runtian Zhai, Tianle Cai, Di He, Chen Dan, Kun He, John Hopcroft, Liwei Wang",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.00555"" target=""_blank"">1906.00555</a>",,2025-12-03 22:39:25
Understanding the Limitations of Conditional Generative Models,"Ethan Fetaya, Jörn-Henrik Jacobsen, Will Grathwohl, Richard Zemel",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.01171"" target=""_blank"">1906.01171</a>",,2025-12-03 22:39:25
Fast and Stable Interval Bounds Propagation for Training Verifiably Robust Models,"Paweł Morawiecki, Przemysław Spurek, Marek Śmieja, Jacek Tabor",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.00628"" target=""_blank"">1906.00628</a>",,2025-12-03 22:39:25
Achieving Generalizable Robustness of Deep Neural Networks by Stability Training,"Jan Laermann, Wojciech Samek, Nils Strodthoff",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.00735"" target=""_blank"">1906.00735</a>",,2025-12-03 22:39:25
Enhancing Gradient-based Attacks with Symbolic Intervals,"Shiqi Wang, Yizheng Chen, Ahmed Abdou, Suman Jana",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.02282"" target=""_blank"">1906.02282</a>",,2025-12-03 22:39:25
RL-Based Method for Benchmarking the Adversarial Resilience and Robustness of Deep Reinforcement Learning Policies,"Vahid Behzadan, William Hsu",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.01110"" target=""_blank"">1906.01110</a>",,2025-12-03 22:39:25
Adversarial Robustness as a Prior for Learned Representations,"Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Brandon Tran, Aleksander Madry",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.00945"" target=""_blank"">1906.00945</a>",,2025-12-03 22:39:25
Adversarial Risk Bounds for Neural Networks through Sparsity based Compression,"Emilio Rafael Balda, Arash Behboodi, Niklas Koep, Rudolf Mathar",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.00698"" target=""_blank"">1906.00698</a>",,2025-12-03 22:39:25
Adversarial Exploitation of Policy Imitation,"Vahid Behzadan, William Hsu",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.01121"" target=""_blank"">1906.01121</a>",,2025-12-03 22:39:25
Architecture Selection via the Trade-off Between Accuracy and Robustness,"Zhun Deng, Cynthia Dwork, Jialiang Wang, Yao Zhao",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.01354"" target=""_blank"">1906.01354</a>",,2025-12-03 22:39:25
Adversarial Training is a Form of Data-dependent Operator Norm Regularization,"Kevin Roth, Yannic Kilcher, Thomas Hofmann",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.01527"" target=""_blank"">1906.01527</a>",,2025-12-03 22:39:25
Multi-way Encoding for Robustness,"Donghyun Kim, Sarah Adel Bargal, Jianming Zhang, Stan Sclaroff",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.02033"" target=""_blank"">1906.02033</a>",,2025-12-03 22:39:25
c-Eval: A Unified Metric to Evaluate Feature-based Explanations via Perturbation,"Minh N. Vu, Truc D. Nguyen, NhatHai Phan, Ralucca Gera, My T. Thai",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.02032"" target=""_blank"">1906.02032</a>",,2025-12-03 22:39:25
Query-efficient Meta Attack to Deep Neural Networks,"Jiawei Du, Hu Zhang, Joey Tianyi Zhou, Yi Yang, Jiashi Feng",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.02398"" target=""_blank"">1906.02398</a>","<a href=""https://github.com/dydjw9/MetaAttack_ICLR2020/"" target=""_blank"">MetaAttack_ICLR2020</a>",2025-12-03 22:39:25
On the Vulnerability of Capsule Networks to Adversarial Attacks,"Felix Michels, Tobias Uelwer, Eric Upschulte, Stefan Harmeling",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03612"" target=""_blank"">1906.03612</a>",,2025-12-03 22:39:25
Evolving Robust Neural Architectures to Defend from Adversarial Attacks,"Shashank Kotyan, Danilo Vasconcellos Vargas",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.11667"" target=""_blank"">1906.11667</a>",,2025-12-03 22:39:25
Robustness Verification of Tree-based Models,"Hongge Chen, Huan Zhang, Si Si, Yang Li, Duane Boning, Cho-Jui Hsieh",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03849"" target=""_blank"">1906.03849</a>",,2025-12-03 22:39:25
Defending Against Adversarial Examples with K-Nearest Neighbor,"Chawin Sitawarin, David Wagner",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.09525"" target=""_blank"">1906.09525</a>",,2025-12-03 22:39:25
Convergence of Adversarial Training in Overparametrized Networks,"Ruiqi Gao, Tianle Cai, Haochuan Li, Liwei Wang, Cho-Jui Hsieh, Jason D. Lee",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.07916"" target=""_blank"">1906.07916</a>",,2025-12-03 22:39:25
A unified view on differential privacy and robustness to adversarial examples,"Rafael Pinot, Florian Yger, Cédric Gouy-Pailler, Jamal Atif",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.07982"" target=""_blank"">1906.07982</a>",,2025-12-03 22:39:25
Improving the robustness of ImageNet classifiers using elements of human visual cognition,"A. Emin Orhan, Brenden M. Lake",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.08416"" target=""_blank"">1906.08416</a>",,2025-12-03 22:39:25
On Physical Adversarial Patches for Object Detection,"Mark Lee, Zico Kolter",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.11897"" target=""_blank"">1906.11897</a>",,2025-12-03 22:39:25
A Cyclically-Trained Adversarial Network for Invariant Representation Learning,"Jiawei Chen, Janusz Konrad, Prakash Ishwar",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.09313"" target=""_blank"">1906.09313</a>",,2025-12-03 22:39:25
Adversarial Examples to Fool Iris Recognition Systems,"Sobhan Soleymani, Ali Dabouei, Jeremy Dawson, Nasser M. Nasrabadi",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.09300"" target=""_blank"">1906.09300</a>",,2025-12-03 22:39:25
Evolution Attack On Neural Networks,"YiGui Luo, RuiJia Yang, Wei Sha, WeiYi Ding, YouTeng Sun, YiSi Wang",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.09072"" target=""_blank"">1906.09072</a>",,2025-12-03 22:39:25
A Fourier Perspective on Model Robustness in Computer Vision,"Dong Yin, Raphael Gontijo Lopes, Jonathon Shlens, Ekin D. Cubuk, Justin Gilmer",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.08988"" target=""_blank"">1906.08988</a>",,2025-12-03 22:39:25
Hiding Faces in Plain Sight: Disrupting AI Face Synthesis with Adversarial Perturbations,"Yuezun Li, Xin Yang, Baoyuan Wu, Siwei Lyu",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.09288"" target=""_blank"">1906.09288</a>",,2025-12-03 22:39:25
Deceptive Reinforcement Learning Under Adversarial Manipulations on Cost Signals,"Yunhan Huang, Quanyan Zhu",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.10571"" target=""_blank"">1906.10571</a>",,2025-12-03 22:39:25
Cloud-based Image Classification Service Is Not Robust To Simple Transformations: A Forgotten Battlefield,"Dou Goodman, Tao Wei",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.07997"" target=""_blank"">1906.07997</a>",,2025-12-03 22:39:25
Are Adversarial Perturbations a Showstopper for ML-Based CAD? A Case Study on CNN-Based Lithographic Hotspot Detection,"Kang Liu, Haoyu Yang, Yuzhe Ma, Benjamin Tan, Bei Yu, Evangeline F. Y. Young, Ramesh Karri, Siddharth Garg",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.10773"" target=""_blank"">1906.10773</a>",,2025-12-03 22:39:25
Quantitative Verification of Neural Networks And its Security Applications,"Teodora Baluta, Shiqi Shen, Shweta Shinde, Kuldeep S. Meel, Prateek Saxena",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.10395"" target=""_blank"">1906.10395</a>",,2025-12-03 22:39:25
Defending Adversarial Attacks by Correcting logits,"Yifeng Li, Lingxi Xie, Ya Zhang, Rui Zhang, Yanfeng Wang, Qi Tian",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.10973"" target=""_blank"">1906.10973</a>",,2025-12-03 22:39:25
The Adversarial Robustness of Sampling,"Omri Ben-Eliezer, Eylon Yogev",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.11327"" target=""_blank"">1906.11327</a>",,2025-12-03 22:39:25
Adversarial Robustness via Label-Smoothing,"Morgane Goibert, Elvis Dohmatob",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.11567"" target=""_blank"">1906.11567</a>",,2025-12-03 22:39:25
Using Intuition from Empirical Properties to Simplify Adversarial Training Defense,"Guanxiong Liu, Issa Khalil, Abdallah Khreishah",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.11729"" target=""_blank"">1906.11729</a>",,2025-12-03 22:39:25
Evaluating the Robustness of Nearest Neighbor Classifiers: A Primal-Dual Perspective,"Lu Wang, Xuanqing Liu, Jinfeng Yi, Zhi-Hua Zhou, Cho-Jui Hsieh",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03972"" target=""_blank"">1906.03972</a>",,2025-12-03 22:39:25
Certifiable Robustness and Robust Training for Graph Convolutional Networks,"Daniel Zügner, Stephan Günnemann",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.12269"" target=""_blank"">1906.12269</a>",,2025-12-03 22:39:25
Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty,"Dan Hendrycks, Mantas Mazeika, Saurav Kadavath, Dawn Song",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.12340"" target=""_blank"">1906.12340</a>",,2025-12-03 22:39:25
Global Adversarial Attacks for Assessing Deep Learning Robustness,"Hanbin Hu, Mit Shah, Jianhua Z. Huang, Peng Li",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.07920"" target=""_blank"">1906.07920</a>",,2025-12-03 22:39:25
Learning to Cope with Adversarial Attacks,"Xian Yeow Lee, Aaron Havens, Girish Chowdhary, Soumik Sarkar",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.12061"" target=""_blank"">1906.12061</a>",,2025-12-03 22:39:25
SemanticAdv: Generating Adversarial Examples via Attribute-conditional Image Editing,"Haonan Qiu, Chaowei Xiao, Lei Yang, Xinchen Yan, Honglak Lee, Bo Li",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.07927"" target=""_blank"">1906.07927</a>",,2025-12-03 22:39:25
Robust or Private? Adversarial Training Makes Models More Vulnerable to Privacy Attacks,"Felipe A. Mejia, Paul Gamble, Zigfried Hampel-Arias, Michael Lomnitz, Nina Lopatina, Lucas Tindall, Maria Alejandra Barrios",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.06449"" target=""_blank"">1906.06449</a>",,2025-12-03 22:39:25
Adversarial attacks on Copyright Detection Systems,"Parsa Saadatpanah, Ali Shafahi, Tom Goldstein",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.07153"" target=""_blank"">1906.07153</a>",,2025-12-03 22:39:25
E-LPIPS: Robust Perceptual Image Similarity via Random Transformation Ensembles,"Markus Kettunen, Erik Härkönen, Jaakko Lehtinen",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.03973"" target=""_blank"">1906.03973</a>",,2025-12-03 22:39:25
Efficient and Accurate Estimation of Lipschitz Constants for Deep Neural Networks,"Mahyar Fazlyab, Alexander Robey, Hamed Hassani, Manfred Morari, George J. Pappas",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.04893"" target=""_blank"">1906.04893</a>",,2025-12-03 22:39:25
Subspace Attack: Exploiting Promising Subspaces for Query-Efficient Black-box Attacks,"Ziang Yan, Yiwen Guo, Changshui Zhang",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.04392"" target=""_blank"">1906.04392</a>",,2025-12-03 22:39:25
Tight Certificates of Adversarial Robustness for Randomly Smoothed Classifiers,"Guang-He Lee, Yang Yuan, Shiyu Chang, Tommi S. Jaakkola",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.04948"" target=""_blank"">1906.04948</a>",,2025-12-03 22:39:25
Lower Bounds for Adversarially Robust PAC Learning,"Dimitrios I. Diochnos, Saeed Mahloujifar, Mohammad Mahmoody",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.05815"" target=""_blank"">1906.05815</a>",,2025-12-03 22:39:25
A Computationally Efficient Method for Defending Adversarial Deep Learning Attacks,"Rajeev Sahay, Rehana Mahfuz, Aly El Gamal",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.05599"" target=""_blank"">1906.05599</a>",,2025-12-03 22:39:25
Adversarial Robustness Assessment: Why both $L_0$ and $L_\infty$ Attacks Are Necessary,"Shashank Kotyan, Danilo Vasconcellos Vargas",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.06026"" target=""_blank"">1906.06026</a>",,2025-12-03 22:39:25
Towards Stable and Efficient Training of Verifiably Robust Neural Networks,"Huan Zhang, Hongge Chen, Chaowei Xiao, Bo Li, Duane Boning, Cho-Jui Hsieh",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.06316"" target=""_blank"">1906.06316</a>",,2025-12-03 22:39:25
Mimic and Fool: A Task Agnostic Adversarial Attack,"Akshay Chaturvedi, Utpal Garain",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.04606"" target=""_blank"">1906.04606</a>",,2025-12-03 22:39:25
Copy and Paste: A Simple But Effective Initialization Method for Black-Box Adversarial Attacks,"Thomas Brunner, Frederik Diehl, Alois Knoll",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.06086"" target=""_blank"">1906.06086</a>",,2025-12-03 22:39:25
Defending Against Adversarial Attacks Using Random Forests,"Yifan Ding, Liqiang Wang, Huan Zhang, Jinfeng Yi, Deliang Fan, Boqing Gong",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.06765"" target=""_blank"">1906.06765</a>",,2025-12-03 22:39:25
Improving Black-box Adversarial Attacks with a Transfer-based Prior,"Shuyu Cheng, Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.06919"" target=""_blank"">1906.06919</a>",,2025-12-03 22:39:25
Perceptual Based Adversarial Audio Attacks,"Joseph Szurley, J. Zico Kolter",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.06355"" target=""_blank"">1906.06355</a>",,2025-12-03 22:39:25
Interpolated Adversarial Training: Achieving Robust Neural Networks without Sacrificing Accuracy,"Alex Lamb, Vikas Verma, Juho Kannala, Yoshua Bengio",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.06784"" target=""_blank"">1906.06784</a>",,2025-12-03 22:39:25
The Attack Generator: A Systematic Approach Towards Constructing Adversarial Attacks,"Felix Assion, Peter Schlicht, Florens Greßner, Wiebke Günther, Fabian Hüger, Nico Schmidt, Umair Rasheed",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.07077"" target=""_blank"">1906.07077</a>",,2025-12-03 22:39:25
Representation Quality Of Neural Networks Links To Adversarial Attacks and Defences,"Shashank Kotyan, Danilo Vasconcellos Vargas, Moe Matsuki",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.06627"" target=""_blank"">1906.06627</a>",,2025-12-03 22:39:25
Adversarial Training Can Hurt Generalization,"Aditi Raghunathan, Sang Michael Xie, Fanny Yang, John C. Duchi, Percy Liang",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.06032"" target=""_blank"">1906.06032</a>",,2025-12-03 22:39:25
Towards Compact and Robust Deep Neural Networks,"Vikash Sehwag, Shiqi Wang, Prateek Mittal, Suman Jana",arXiv,2019-06,"<a href=""http://arxiv.org/abs/1906.06110"" target=""_blank"">1906.06110</a>",,2025-12-03 22:39:25
Interpreting and Evaluating Neural Network Robustness,"Fuxun Yu, Zhuwei Qin, Chenchen Liu, Liang Zhao, Yanzhi Wang, Xiang Chen",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.04270"" target=""_blank"">1905.04270</a>",,2025-12-03 22:39:25
Moving Target Defense for Deep Visual Sensing against Adversarial Examples,"Qun Song, Zhenyu Yan, Rui Tan",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.13148"" target=""_blank"">1905.13148</a>",,2025-12-03 22:39:25
Parsimonious Black-Box Adversarial Attacks via Efficient Combinatorial Optimization,"Seungyong Moon, Gaon An, Hyun Oh Song",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.06635"" target=""_blank"">1905.06635</a>","<a href=""https://github.com/snu-mllab/parsimonious-blackbox-attack"" target=""_blank"">snu-mllab</a>",2025-12-03 22:39:25
On the Connection Between Adversarial Robustness and Saliency Map Interpretability,"Christian Etmann, Sebastian Lunz, Peter Maass, Carola-Bibiane Schönlieb",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.04172"" target=""_blank"">1905.04172</a>",,2025-12-03 22:39:25
Analyzing Adversarial Attacks Against Deep Learning for Intrusion Detection in IoT Networks,"Olakunle Ibitoye, Omair Shafiq, Ashraf Matrawy",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.05137"" target=""_blank"">1905.05137</a>",,2025-12-03 22:39:25
Adversarial Examples for Electrocardiograms,"Xintian Han, Yuxuan Hu, Luca Foschini, Larry Chinitz, Lior Jankelson, Rajesh Ranganath",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.05163"" target=""_blank"">1905.05163</a>",,2025-12-03 22:39:25
Robustification of deep net classifiers by key based diversified aggregation with pre-filtering,"Olga Taran, Shideh Rezaeifar, Taras Holotyak, Slava Voloshynovskiy",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.05454"" target=""_blank"">1905.05454</a>",,2025-12-03 22:39:25
An Efficient Pre-processing Method to Eliminate Adversarial Effects,"Hua Wang, Jie Wang, Zhaoxia Yin",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.08614"" target=""_blank"">1905.08614</a>",,2025-12-03 22:39:25
On Norm-Agnostic Robustness of Adversarial Training,"Bai Li, Changyou Chen, Wenlin Wang, Lawrence Carin",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.06455"" target=""_blank"">1905.06455</a>",,2025-12-03 22:39:25
Harnessing the Vulnerability of Latent Layers in Adversarially Trained Models,"Mayank Singh, Abhishek Sinha, Nupur Kumari, Harshitha Machiraju, Balaji Krishnamurthy, Vineeth N Balasubramanian",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.05186"" target=""_blank"">1905.05186</a>",,2025-12-03 22:39:25
POPQORN: Quantifying Robustness of Recurrent Neural Networks,"Ching-Yun Ko, Zhaoyang Lyu, Tsui-Wei Weng, Luca Daniel, Ngai Wong, Dahua Lin",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.07387"" target=""_blank"">1905.07387</a>",,2025-12-03 22:39:25
Simple Black-box Adversarial Attacks,"Chuan Guo, Jacob R. Gardner, Yurong You, Andrew Gordon Wilson, Kilian Q. Weinberger",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.07121"" target=""_blank"">1905.07121</a>",,2025-12-03 22:39:25
A critique of the DeepSec Platform for Security Analysis of Deep Learning Models,Nicholas Carlini,arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.07112"" target=""_blank"">1905.07112</a>",,2025-12-03 22:39:25
Taking Care of The Discretization Problem:A Black-Box Adversarial Image Attack in Discrete Integer Domain,"Yuchao Duan, Zhe Zhao, Lei Bu, Fu Song",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.07672"" target=""_blank"">1905.07672</a>",,2025-12-03 22:39:25
What Do Adversarially Robust Models Look At?,"Takahiro Itazuri, Yoshihiro Fukuhara, Hirokatsu Kataoka, Shigeo Morishima",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.07666"" target=""_blank"">1905.07666</a>",,2025-12-03 22:39:25
Testing DNN Image Classifiers for Confusion & Bias Errors,"Yuchi Tian, Ziyuan Zhong, Vicente Ordonez, Gail Kaiser, Baishakhi Ray",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.07831"" target=""_blank"">1905.07831</a>",,2025-12-03 22:39:25
Adversarially robust transfer learning,"Ali Shafahi, Parsa Saadatpanah, Chen Zhu, Amin Ghiasi, Christoph Studer, David Jacobs, Tom Goldstein",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.08232"" target=""_blank"">1905.08232</a>",,2025-12-03 22:39:25
Adversarial Defense Framework for Graph Neural Network,"Shen Wang, Zhengzhang Chen, Jingchao Ni, Xiao Yu, Zhichun Li, Haifeng Chen, Philip S. Yu",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.03679"" target=""_blank"">1905.03679</a>",,2025-12-03 22:39:25
DoPa: A Fast and Comprehensive CNN Defense Methodology against Physical Adversarial Attacks,"Zirui Xu, Fuxun Yu, Xiang Chen",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.08790"" target=""_blank"">1905.08790</a>",,2025-12-03 22:39:25
Detecting Adversarial Examples and Other Misclassifications in Neural Networks by Introspection,"Jonathan Aigrain, Marcin Detyniecki",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.09186"" target=""_blank"">1905.09186</a>",,2025-12-03 22:39:25
Convergence and Margin of Adversarial Training on Separable Data,"Zachary Charles, Shashank Rajput, Stephen Wright, Dimitris Papailiopoulos",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.09209"" target=""_blank"">1905.09209</a>",,2025-12-03 22:39:25
Exact Adversarial Attack to Image Captioning via Structured Output Learning with Latent Variables,"Yan Xu, Baoyuan Wu, Fumin Shen, Yanbo Fan, Yong Zhang, Heng Tao Shen, Wei Liu",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.04016"" target=""_blank"">1905.04016</a>",,2025-12-03 22:39:25
An Empirical Evaluation of Adversarial Robustness under Transfer Learning,"Todor Davchev, Timos Korres, Stathi Fotiadis, Nick Antonopoulos, Subramanian Ramamoorthy",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.02675"" target=""_blank"">1905.02675</a>",,2025-12-03 22:39:25
Mitigating Deep Learning Vulnerabilities from Adversarial Examples Attack in the Cybersecurity Domain,Chris Einar San Agustin,arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.03517"" target=""_blank"">1905.03517</a>",,2025-12-03 22:39:25
Exploring the Hyperparameter Landscape of Adversarial Robustness,"Evelyn Duesterwald, Anupama Murthi, Ganesh Venkataraman, Mathieu Sinn, Deepak Vijaykeerthy",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.03837"" target=""_blank"">1905.03837</a>",,2025-12-03 22:39:25
Interpreting Adversarially Trained Convolutional Neural Networks,"Tianyuan Zhang, Zhanxing Zhu",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.09797"" target=""_blank"">1905.09797</a>",,2025-12-03 22:39:25
NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks,"Yandong Li, Lijun Li, Liqiang Wang, Tong Zhang, Boqing Gong",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.00441"" target=""_blank"">1905.00441</a>",,2025-12-03 22:39:25
Dropping Pixels for Adversarial Robustness,"Hossein Hosseini, Sreeram Kannan, Radha Poovendran",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.00180"" target=""_blank"">1905.00180</a>",,2025-12-03 22:39:25
You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle,"Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing Zhu, Bin Dong",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.00877"" target=""_blank"">1905.00877</a>",,2025-12-03 22:39:25
Weight Map Layer for Noise and Adversarial Attack Robustness,"Mohammed Amer, Tomás Maul",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.00568"" target=""_blank"">1905.00568</a>",,2025-12-03 22:39:25
Adversarial Training with Voronoi Constraints,"Marc Khoury, Dylan Hadfield-Menell",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.01019"" target=""_blank"">1905.01019</a>",,2025-12-03 22:39:25
Transfer of Adversarial Robustness Between Perturbation Types,"Daniel Kang, Yi Sun, Tom Brown, Dan Hendrycks, Jacob Steinhardt",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.01034"" target=""_blank"">1905.01034</a>",,2025-12-03 22:39:25
Better the Devil you Know: An Analysis of Evasion Attacks using Out-of-Distribution Adversarial Examples,"Vikash Sehwag, Arjun Nitin Bhagoji, Liwei Song, Chawin Sitawarin, Daniel Cullina, Mung Chiang, Prateek Mittal",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.01726"" target=""_blank"">1905.01726</a>",,2025-12-03 22:39:25
Machine Learning Cryptanalysis of a Quantum Random Number Generator,"Nhan Duy Truong, Jing Yan Haw, Syed Muhamad Assad, Ping Koy Lam, Omid Kavehei",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.02342"" target=""_blank"">1905.02342</a>",,2025-12-03 22:39:25
"Adversarial Examples Are Not Bugs, They Are Features","Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, Aleksander Madry",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.02175"" target=""_blank"">1905.02175</a>",,2025-12-03 22:39:25
Batch Normalization is a Cause of Adversarial Vulnerability,"Angus Galloway, Anna Golubeva, Thomas Tanay, Medhat Moussa, Graham W. Taylor",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.02161"" target=""_blank"">1905.02161</a>",,2025-12-03 22:39:25
Adaptive Generation of Unrestricted Adversarial Inputs,"Isaac Dunn, Hadrien Pouget, Tom Melham, Daniel Kroening",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.02463"" target=""_blank"">1905.02463</a>",,2025-12-03 22:39:25
Representation of White- and Black-Box Adversarial Examples in Deep Neural Networks and Humans: A Functional Magnetic Resonance Imaging Study,"Chihye Han, Wonjun Yoon, Gihyun Kwon, Seungkyu Nam, Daeshik Kim",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.02422"" target=""_blank"">1905.02422</a>",,2025-12-03 22:39:25
A Comprehensive Analysis on Adversarial Robustness of Spiking Neural Networks,"Saima Sharmin, Priyadarshini Panda, Syed Shakib Sarwar, Chankyu Lee, Wachirawit Ponghiran, Kaushik Roy",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.02704"" target=""_blank"">1905.02704</a>",,2025-12-03 22:39:25
Adversarial Image Translation: Unrestricted Adversarial Examples in Face Recognition Systems,"Kazuya Kakizaki, Kosuke Yoshida",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.03421"" target=""_blank"">1905.03421</a>",,2025-12-03 22:39:25
Enhancing Cross-task Transferability of Adversarial Examples with Dispersion Reduction,"Yunhan Jia, Yantao Lu, Senem Velipasalar, Zhenyu Zhong, Tao Wei",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.03333"" target=""_blank"">1905.03333</a>",,2025-12-03 22:39:25
ROSA: Robust Salient Object Detection against Adversarial Attacks,"Haofeng Li, Guanbin Li, Yizhou Yu",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.03434"" target=""_blank"">1905.03434</a>",,2025-12-03 22:39:25
Universal Adversarial Perturbations for Speech Recognition Systems,"Paarth Neekhara, Shehzeen Hussain, Prakhar Pandey, Shlomo Dubnov, Julian McAuley, Farinaz Koushanfar",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.03828"" target=""_blank"">1905.03828</a>",,2025-12-03 22:39:25
Learning Interpretable Features via Adversarially Robust Optimization,"Ashkan Khakzar, Shadi Albarqouni, Nassir Navab",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.03767"" target=""_blank"">1905.03767</a>",,2025-12-03 22:39:25
Adversarially Robust Distillation,"Micah Goldblum, Liam Fowl, Soheil Feizi, Tom Goldstein",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.09747"" target=""_blank"">1905.09747</a>",,2025-12-03 22:39:25
Are Labels Required for Improving Adversarial Robustness?,"Jonathan Uesato, Jean-Baptiste Alayrac, Po-Sen Huang, Robert Stanforth, Alhussein Fawzi, Pushmeet Kohli",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.13725"" target=""_blank"">1905.13725</a>",,2025-12-03 22:39:25
Thwarting finite difference adversarial attacks with output randomization,"Haidar Khan, Daniel Park, Azer Khan, Bülent Yener",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.09871"" target=""_blank"">1905.09871</a>",,2025-12-03 22:39:25
CopyCAT: Taking Control of Neural Policies with Constant Attacks,"Léonard Hussenot, Matthieu Geist, Olivier Pietquin",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.12282"" target=""_blank"">1905.12282</a>",,2025-12-03 22:39:25
Certifiably Robust Interpretation in Deep Learning,"Alexander Levine, Sahil Singla, Soheil Feizi",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.12105"" target=""_blank"">1905.12105</a>",,2025-12-03 22:39:25
Cross-Domain Transferability of Adversarial Perturbations,"Muzammal Naseer, Salman H. Khan, Harris Khan, Fahad Shahbaz Khan, Fatih Porikli",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11736"" target=""_blank"">1905.11736</a>",,2025-12-03 22:39:25
Empirically Measuring Concentration: Fundamental Limits on Intrinsic Robustness,"Saeed Mahloujifar, Xiao Zhang, Mohammad Mahmoody, David Evans",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.12202"" target=""_blank"">1905.12202</a>","<a href=""https://github.com/xiaozhanguva/Measure-Concentration"" target=""_blank"">xiaozhanguva</a>",2025-12-03 22:39:25
Expected Tight Bounds for Robust Training,"Salman Alsubaihi, Adel Bibi, Modar Alfadly, Abdullah Hamdi, Bernard Ghanem",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.12418"" target=""_blank"">1905.12418</a>",,2025-12-03 22:39:25
High Frequency Component Helps Explain the Generalization of Convolutional Neural Networks,"Haohan Wang, Xindi Wu, Zeyi Huang, Eric P. Xing",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.13545"" target=""_blank"">1905.13545</a>",,2025-12-03 22:39:25
Snooping Attacks on Deep Reinforcement Learning,"Matthew Inkawhich, Yiran Chen, Hai Li",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11832"" target=""_blank"">1905.11832</a>",,2025-12-03 22:39:25
Improving the Robustness of Deep Neural Networks via Adversarial Training with Triplet Loss,"Pengcheng Li, Jinfeng Yi, Bowen Zhou, Lijun Zhang",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11713"" target=""_blank"">1905.11713</a>",,2025-12-03 22:39:25
Adversarial Attacks on Remote User Authentication Using Behavioural Mouse Dynamics,"Yi Xiang Marcus Tan, Alfonso Iacovazzi, Ivan Homoliak, Yuval Elovici, Alexander Binder",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11831"" target=""_blank"">1905.11831</a>",,2025-12-03 22:39:25
ME-Net: Towards Effective Adversarial Robustness with Matrix Estimation,"Yuzhe Yang, Guo Zhang, Dina Katabi, Zhi Xu",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11971"" target=""_blank"">1905.11971</a>",,2025-12-03 22:39:25
Misleading Authorship Attribution of Source Code using Adversarial Learning,"Erwin Quiring, Alwin Maier, Konrad Rieck",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.12386"" target=""_blank"">1905.12386</a>",,2025-12-03 22:39:25
Label Universal Targeted Attack,"Naveed Akhtar, Mohammad A. A. K. Jalwana, Mohammed Bennamoun, Ajmal Mian",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11544"" target=""_blank"">1905.11544</a>",,2025-12-03 22:39:25
Bandlimiting Neural Networks Against Adversarial Attacks,"Yuping Lin, Kasra Ahmadi K. A., Hui Jiang",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.12797"" target=""_blank"">1905.12797</a>",,2025-12-03 22:39:25
Interpretable Adversarial Training for Text,"Samuel Barham, Soheil Feizi",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.12864"" target=""_blank"">1905.12864</a>",,2025-12-03 22:39:25
Robust Sparse Regularization: Simultaneously Optimizing Neural Network Robustness and Compactness,"Adnan Siraj Rakin, Zhezhi He, Li Yang, Yanzhi Wang, Liqiang Wang, Deliang Fan",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.13074"" target=""_blank"">1905.13074</a>",,2025-12-03 22:39:25
Identifying Classes Susceptible to Adversarial Attacks,"Rangeet Pan, Md Johirul Islam, Shibbir Ahmed, Hridesh Rajan",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.13284"" target=""_blank"">1905.13284</a>",,2025-12-03 22:39:25
Residual Networks as Nonlinear Systems: Stability Analysis using Linearization,"Kai Rothauge, Zhewei Yao, Zixi Hu, Michael W. Mahoney",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.13386"" target=""_blank"">1905.13386</a>",,2025-12-03 22:39:25
Real-Time Adversarial Attacks,"Yuan Gong, Boyang Li, Christian Poellabauer, Yiyu Shi",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.13399"" target=""_blank"">1905.13399</a>",,2025-12-03 22:39:25
Reverse KL-Divergence Training of Prior Networks: Improved Uncertainty and Adversarial Robustness,"Andrey Malinin, Mark Gales",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.13472"" target=""_blank"">1905.13472</a>",,2025-12-03 22:39:25
Unlabeled Data Improves Adversarial Robustness,"Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, Percy Liang, John C. Duchi",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.13736"" target=""_blank"">1905.13736</a>",,2025-12-03 22:39:25
PHom-GeM: Persistent Homology for Generative Models,"Jeremy Charlier, Radu State, Jean Hilger",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.09894"" target=""_blank"">1905.09894</a>",,2025-12-03 22:39:25
Brain-inspired reverse adversarial examples,"Shaokai Ye, Sia Huat Tan, Kaidi Xu, Yanzhi Wang, Chenglong Bao, Kaisheng Ma",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.12171"" target=""_blank"">1905.12171</a>",,2025-12-03 22:39:25
Securing Connected & Autonomous Vehicles: Challenges Posed by Adversarial Machine Learning and The Way Forward,"Adnan Qayyum, Muhammad Usama, Junaid Qadir, Ala Al-Fuqaha",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.12762"" target=""_blank"">1905.12762</a>",,2025-12-03 22:39:25
Fooling Detection Alone is Not Enough: First Adversarial Attack against Multiple Object Tracking,"Yunhan Jia, Yantao Lu, Junjie Shen, Qi Alfred Chen, Zhenyu Zhong, Tao Wei",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11026"" target=""_blank"">1905.11026</a>",,2025-12-03 22:39:25
Rearchitecting Classification Frameworks For Increased Robustness,"Varun Chandrasekaran, Brian Tang, Nicolas Papernot, Kassem Fawaz, Somesh Jha, Xi Wu",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.10900"" target=""_blank"">1905.10900</a>",,2025-12-03 22:39:25
Provable robustness against all adversarial $l_p$-perturbations for $p\geq 1$,"Francesco Croce, Matthias Hein",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11213"" target=""_blank"">1905.11213</a>",,2025-12-03 22:39:25
Power up! Robust Graph Convolutional Network via Graph Powering,"Ming Jin, Heng Chang, Wenwu Zhu, Somayeh Sojoudi",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.10029"" target=""_blank"">1905.10029</a>",,2025-12-03 22:39:25
Enhancing Adversarial Defense by k-Winners-Take-All,"Chang Xiao, Peilin Zhong, Changxi Zheng",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.10510"" target=""_blank"">1905.10510</a>",,2025-12-03 22:39:25
Robustness to Adversarial Perturbations in Learning from Incomplete Data,"Amir Najafi, Shin-ichi Maeda, Masanori Koyama, Takeru Miyato",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.13021"" target=""_blank"">1905.13021</a>",,2025-12-03 22:39:25
Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness,"Tianyu Pang, Kun Xu, Yinpeng Dong, Chao Du, Ning Chen, Jun Zhu",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.10626"" target=""_blank"">1905.10626</a>",,2025-12-03 22:39:25
Adversarial Distillation for Ordered Top-k Attacks,"Zekun Zhang, Tianfu Wu",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.10695"" target=""_blank"">1905.10695</a>",,2025-12-03 22:39:25
"Trust but Verify: An Information-Theoretic Explanation for the Adversarial Fragility of Machine Learning Systems, and a General Defense against Adversarial Attacks","Jirong Yi, Hui Xie, Leixin Zhou, Xiaodong Wu, Weiyu Xu, Raghuraman Mudumbai",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11381"" target=""_blank"">1905.11381</a>",,2025-12-03 22:39:25
Generalizable Adversarial Attacks Using Generative Models,"Avishek Joey Bose, Andre Cianflone, William L. Hamilton",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.10864"" target=""_blank"">1905.10864</a>",,2025-12-03 22:39:25
Robust Classification using Robust Feature Augmentation,"Kevin Eykholt, Swati Gupta, Atul Prakash, Amir Rahmati, Pratik Vaishnavi, Haizhong Zheng",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.10904"" target=""_blank"">1905.10904</a>",,2025-12-03 22:39:25
Adversarial Policies: Attacking Deep Reinforcement Learning,"Adam Gleave, Michael Dennis, Cody Wild, Neel Kant, Sergey Levine, Stuart Russell",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.10615"" target=""_blank"">1905.10615</a>","<a href=""https://adversarialpolicies.github.io/"" target=""_blank"">adversarialpolicies.github.io</a>",2025-12-03 22:39:25
A Direct Approach to Robust Deep Learning Using Adversarial Networks,"Huaxia Wang, Chun-Nam Yu",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.09591"" target=""_blank"">1905.09591</a>",,2025-12-03 22:39:25
Non-Determinism in Neural Networks for Adversarial Robustness,"Daanish Ali Khan, Linhong Li, Ninghao Sha, Zhuoran Liu, Abelino Jimenez, Bhiksha Raj, Rita Singh",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.10906"" target=""_blank"">1905.10906</a>",,2025-12-03 22:39:25
State-Reification Networks: Improving Generalization by Modeling the Distribution of Hidden Representations,"Alex Lamb, Jonathan Binas, Anirudh Goyal, Sandeep Subramanian, Ioannis Mitliagkas, Denis Kazakov, Yoshua Bengio, Michael C. Mozer",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11382"" target=""_blank"">1905.11382</a>",,2025-12-03 22:39:25
GAT: Generative Adversarial Training for Adversarial Example Detection and Robust Classification,"Xuwang Yin, Soheil Kolouri, Gustavo K. Rohde",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11475"" target=""_blank"">1905.11475</a>",,2025-12-03 22:39:25
Unsupervised Euclidean Distance Attack on Network Embedding,"Shanqing Yu, Jun Zheng, Jinhuan Wang, Jian Zhang, Lihong Chen, Qi Xuan, Jinyin Chen, Dan Zhang, Qingpeng Zhang",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11015"" target=""_blank"">1905.11015</a>",,2025-12-03 22:39:25
Adversarially Robust Learning Could Leverage Computational Hardness,"Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11564"" target=""_blank"">1905.11564</a>",,2025-12-03 22:39:25
Analyzing the Interpretability Robustness of Self-Explaining Models,"Haizhong Zheng, Earlence Fernandes, Atul Prakash",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.12429"" target=""_blank"">1905.12429</a>",,2025-12-03 22:39:25
Combating Adversarial Misspellings with Robust Word Recognition,"Danish Pruthi, Bhuwan Dhingra, Zachary C. Lipton",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11268"" target=""_blank"">1905.11268</a>",,2025-12-03 22:39:25
Purifying Adversarial Perturbation with Adversarially Trained Auto-encoders,"Hebi Li, Qi Xiao, Shixin Tian, Jin Tian",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.10729"" target=""_blank"">1905.10729</a>",,2025-12-03 22:39:25
Scaleable input gradient regularization for adversarial robustness,"Chris Finlay, Adam M Oberman",arXiv,2019-05,"<a href=""http://arxiv.org/abs/1905.11468"" target=""_blank"">1905.11468</a>",,2025-12-03 22:39:25
A Target-Agnostic Attack on Deep Models: Exploiting Security Vulnerabilities of Transfer Learning,"Shahbaz Rezaei, Xin Liu",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.04334"" target=""_blank"">1904.04334</a>",,2025-12-03 22:39:25
Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks,"Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.02884"" target=""_blank"">1904.02884</a>",,2025-12-03 22:39:25
On Training Robust PDF Malware Classifiers,"Yizheng Chen, Shiqi Wang, Dongdong She, Suman Jana",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.03542"" target=""_blank"">1904.03542</a>",,2025-12-03 22:39:25
Malware Evasion Attack and Defense,"Yonghong Huang, Utkarsh Verma, Celeste Fralick, Gabriel Infante-Lopez, Brajesh Kumarz, Carl Woodward",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.05747"" target=""_blank"">1904.05747</a>",,2025-12-03 22:39:25
JumpReLU: A Retrofit Defense Strategy for Adversarial Attacks,"N. Benjamin Erichson, Zhewei Yao, Michael W. Mahoney",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.03750"" target=""_blank"">1904.03750</a>",,2025-12-03 22:39:25
Unrestricted Adversarial Examples via Semantic Manipulation,"Anand Bhattad, Min Jin Chong, Kaizhao Liang, Bo Li, D. A. Forsyth",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.06347"" target=""_blank"">1904.06347</a>",,2025-12-03 22:39:25
Efficient Decision-based Black-box Adversarial Attacks on Face Recognition,"Yinpeng Dong, Hang Su, Baoyuan Wu, Zhifeng Li, Wei Liu, Tong Zhang, Jun Zhu",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.04433"" target=""_blank"">1904.04433</a>",,2025-12-03 22:39:25
Generation & Evaluation of Adversarial Examples for Malware Obfuscation,"Daniel Park, Haidar Khan, Bülent Yener",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.04802"" target=""_blank"">1904.04802</a>",,2025-12-03 22:39:25
Black-box Adversarial Attacks on Video Recognition Models,"Linxi Jiang, Xingjun Ma, Shaoxiang Chen, James Bailey, Yu-Gang Jiang",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.05181"" target=""_blank"">1904.05181</a>",,2025-12-03 22:39:25
Black-Box Decision based Adversarial Attack with Symmetric $\alpha$-stable Distribution,"Vignesh Srinivasan, Ercan E. Kuruoglu, Klaus-Robert Müller, Wojciech Samek, Shinichi Nakajima",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.05586"" target=""_blank"">1904.05586</a>",,2025-12-03 22:39:25
Minimum Uncertainty Based Detection of Adversaries in Deep Neural Networks,"Fatemeh Sheikholeslami, Swayambhoo Jain, Georgios B. Giannakis",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.02841"" target=""_blank"">1904.02841</a>",,2025-12-03 22:39:25
Learning to Generate Synthetic Data via Compositing,"Shashank Tripathi, Siddhartha Chandra, Amit Agrawal, Ambrish Tyagi, James M. Rehg, Visesh Chari",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.05475"" target=""_blank"">1904.05475</a>",,2025-12-03 22:39:25
On the Vulnerability of CNN Classifiers in EEG-Based BCIs,"Xiao Zhang, Dongrui Wu",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.01002"" target=""_blank"">1904.01002</a>",,2025-12-03 22:39:25
"Understanding the efficacy, reliability and resiliency of computer vision techniques for malware detection and future research directions",Li Chen,arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.10504"" target=""_blank"">1904.10504</a>",,2025-12-03 22:39:25
Interpreting Adversarial Examples by Activation Promotion and Suppression,"Kaidi Xu, Sijia Liu, Gaoyuan Zhang, Mengshu Sun, Pu Zhao, Quanfu Fan, Chuang Gan, Xue Lin",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.02057"" target=""_blank"">1904.02057</a>",,2025-12-03 22:39:25
HopSkipJumpAttack: A Query-Efficient Decision-Based Attack,"Jianbo Chen, Michael I. Jordan, Martin J. Wainwright",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.02144"" target=""_blank"">1904.02144</a>",,2025-12-03 22:39:25
Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations,"Fred Hohman, Haekyu Park, Caleb Robinson, Duen Horng Chau",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.02323"" target=""_blank"">1904.02323</a>",,2025-12-03 22:39:25
Adversarial Attacks against Deep Saliency Models,"Zhaohui Che, Ali Borji, Guangtao Zhai, Suiyi Ling, Guodong Guo, Patrick Le Callet",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.01231"" target=""_blank"">1904.01231</a>",,2025-12-03 22:39:25
Curls & Whey: Boosting Black-Box Adversarial Attacks,"Yucheng Shi, Siyu Wang, Yahong Han",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.01160"" target=""_blank"">1904.01160</a>",,2025-12-03 22:39:25
Robustness of 3D Deep Learning in an Adversarial Setting,"Matthew Wicker, Marta Kwiatkowska",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.00923"" target=""_blank"">1904.00923</a>",,2025-12-03 22:39:25
Defending against adversarial attacks by randomized diversification,"Olga Taran, Shideh Rezaeifar, Taras Holotyak, Slava Voloshynovskiy",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.00689"" target=""_blank"">1904.00689</a>",,2025-12-03 22:39:25
Adversarial Defense by Restricting the Hidden Space of Deep Neural Networks,"Aamir Mustafa, Salman Khan, Munawar Hayat, Roland Goecke, Jianbing Shen, Ling Shao",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.00887"" target=""_blank"">1904.00887</a>",,2025-12-03 22:39:25
Regional Homogeneity: Towards Learning Transferable Universal Adversarial Perturbations Against Defenses,"Yingwei Li, Song Bai, Cihang Xie, Zhenyu Liao, Xiaohui Shen, Alan L. Yuille",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.00979"" target=""_blank"">1904.00979</a>","<a href=""https://github.com/LiYingwei/Regional-Homogeneity"" target=""_blank"">LiYingwei</a>",2025-12-03 22:39:25
Adversarial camera stickers: A physical camera-based attack on deep learning systems,"Juncheng Li, Frank R. Schmidt, J. Zico Kolter",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.00759"" target=""_blank"">1904.00759</a>",,2025-12-03 22:39:25
Practical Hidden Voice Attacks against Speech and Speaker Recognition Systems,"Hadi Abdullah, Washington Garcia, Christian Peeters, Patrick Traynor, Kevin R. B. Butler, Joseph Wilson",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.05734"" target=""_blank"">1904.05734</a>",,2025-12-03 22:39:25
Evaluating Robustness of Deep Image Super-Resolution against Adversarial Attacks,"Jun-Ho Choi, Huan Zhang, Jun-Hyuk Kim, Cho-Jui Hsieh, Jong-Seok Lee",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.06097"" target=""_blank"">1904.06097</a>",,2025-12-03 22:39:25
Adversarial Learning in Statistical Classification: A Comprehensive Review of Defenses Against Attacks,"David J. Miller, Zhen Xiang, George Kesidis",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.06292"" target=""_blank"">1904.06292</a>",,2025-12-03 22:39:25
White-to-Black: Efficient Distillation of Black-Box Adversarial Attacks,"Yotam Gil, Yoav Chai, Or Gorodissky, Jonathan Berant",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.02405"" target=""_blank"">1904.02405</a>",,2025-12-03 22:39:25
Generating Minimal Adversarial Perturbations with Integrated Adaptive Gradients,"Yatie Xiao, Chi-Man Pun",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.06186"" target=""_blank"">1904.06186</a>",,2025-12-03 22:39:25
Salient Object Detection in the Deep Learning Era: An In-Depth Survey,"Wenguan Wang, Qiuxia Lai, Huazhu Fu, Jianbing Shen, Haibin Ling, Ruigang Yang",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.09146"" target=""_blank"">1904.09146</a>","<a href=""https://github.com/wenguanwang/SODsurvey"" target=""_blank"">wenguanwang</a>",2025-12-03 22:39:25
Detecting Adversarial Examples through Nonlinear Dimensionality Reduction,"Francesco Crecchi, Davide Bacciu, Battista Biggio",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.13094"" target=""_blank"">1904.13094</a>",,2025-12-03 22:39:25
Adversarial Training for Free!,"Ali Shafahi, Mahyar Najibi, Amin Ghiasi, Zheng Xu, John Dickerson, Christoph Studer, Larry S. Davis, Gavin Taylor, Tom Goldstein",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.12843"" target=""_blank"">1904.12843</a>","<a href=""https://github.com/ashafahi/free_adv_train"" target=""_blank"">ashafahi</a>",2025-12-03 22:39:25
Cycle-Consistent Adversarial GAN: the integration of adversarial attack and defense,"Lingyun Jiang, Kai Qiao, Ruoxi Qin, Linyuan Wang, Jian Chen, Haibing Bu, Bin Yan",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.06026"" target=""_blank"">1904.06026</a>",,2025-12-03 22:39:25
Non-Local Context Encoder: Robust Biomedical Image Segmentation against Adversarial Attacks,"Xiang He, Sibei Yang, Guanbin Li?, Haofeng Li, Huiyou Chang, Yizhou Yu",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.12181"" target=""_blank"">1904.12181</a>",,2025-12-03 22:39:25
Robustness Verification of Support Vector Machines,"Francesco Ranzato, Marco Zanella",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.11803"" target=""_blank"">1904.11803</a>",,2025-12-03 22:39:25
A Robust Approach for Securing Audio Classification Against Adversarial Attacks,"Mohammad Esmaeilpour, Patrick Cardinal, Alessandro Lameiras Koerich",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.10990"" target=""_blank"">1904.10990</a>",,2025-12-03 22:39:25
Physical Adversarial Textures that Fool Visual Object Tracking,"Rey Reza Wiyatno, Anqi Xu",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.11042"" target=""_blank"">1904.11042</a>",,2025-12-03 22:39:25
Minimizing Perceived Image Quality Loss Through Adversarial Attack Scoping,"Kostiantyn Khabarlak, Larysa Koriashkina",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.10390"" target=""_blank"">1904.10390</a>",,2025-12-03 22:39:25
blessing in disguise: Designing Robust Turing Test by Employing Algorithm Unrobustness,"Jiaming Zhang, Jitao Sang, Kaiyuan Xu, Shangxi Wu, Yongli Hu, Yanfeng Sun, Jian Yu",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.09804"" target=""_blank"">1904.09804</a>",,2025-12-03 22:39:25
Using Videos to Evaluate Image Model Robustness,"Keren Gu, Brandon Yang, Jiquan Ngiam, Quoc Le, Jonathon Shlens",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.10076"" target=""_blank"">1904.10076</a>",,2025-12-03 22:39:25
Beyond Explainability: Leveraging Interpretability for Improved Adversarial Learning,"Devinder Kumar, Ibrahim Ben-Daya, Kanav Vats, Jeffery Feng, Graham Taylor and, Alexander Wong",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.09633"" target=""_blank"">1904.09633</a>",,2025-12-03 22:39:25
Can Machine Learning Model with Static Features be Fooled: an Adversarial Machine Learning Approach,"Rahim Taheri, Reza Javidan, Mohammad Shojafar, Vinod P, Mauro Conti",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.09433"" target=""_blank"">1904.09433</a>",,2025-12-03 22:39:25
Adversarial Training and Robustness for Multiple Perturbations,"Florian Tramèr, Dan Boneh",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.13000"" target=""_blank"">1904.13000</a>",,2025-12-03 22:39:25
Fooling automated surveillance cameras: adversarial patches to attack person detection,"Simen Thys, Ranst Wiebe Van, Toon Goedemé",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.08653"" target=""_blank"">1904.08653</a>",,2025-12-03 22:39:25
Reducing Adversarial Example Transferability Using Gradient Regularization,"George Adam, Petr Smirnov, Benjamin Haibe-Kains, Anna Goldenberg",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.07980"" target=""_blank"">1904.07980</a>",,2025-12-03 22:39:25
Exploiting Vulnerabilities of Load Forecasting Through Adversarial Attacks,"Yize Chen, Yushi Tan, Baosen Zhang",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.06606"" target=""_blank"">1904.06606</a>",,2025-12-03 22:39:25
ZK-GanDef: A GAN based Zero Knowledge Adversarial Training Defense for Neural Networks,"Guanxiong Liu, Issa Khalil, Abdallah Khreishah",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.08516"" target=""_blank"">1904.08516</a>",,2025-12-03 22:39:25
Influence of Control Parameters and the Size of Biomedical Image Datasets on the Success of Adversarial Attacks,"Vassili Kovalev, Dmitry Voynov",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.06964"" target=""_blank"">1904.06964</a>",,2025-12-03 22:39:25
Are Self-Driving Cars Secure? Evasion Attacks against Deep Neural Networks for Steering Angle Prediction,"Alesia Chernikova, Alina Oprea, Cristina Nita-Rotaru, BaekGyu Kim",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.07370"" target=""_blank"">1904.07370</a>",,2025-12-03 22:39:25
AT-GAN: An Adversarial Generator Model for Non-constrained Adversarial Examples,"Xiaosen Wang, Kun He, Chuanbiao Song, Liwei Wang, John E. Hopcroft",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.07793"" target=""_blank"">1904.07793</a>",,2025-12-03 22:39:25
Test Selection for Deep Learning Systems,"Wei Ma, Mike Papadakis, Anestis Tsakmalis, Maxime Cordy, Yves Le Traon",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.13195"" target=""_blank"">1904.13195</a>",,2025-12-03 22:39:25
Semantic Adversarial Attacks: Parametric Transformations That Fool Deep Classifiers,"Ameya Joshi, Amitangshu Mukherjee, Soumik Sarkar, Chinmay Hegde",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.08489"" target=""_blank"">1904.08489</a>",,2025-12-03 22:39:25
Adversarial Defense Through Network Profiling Based Path Extraction,"Yuxian Qiu, Jingwen Leng, Cong Guo, Quan Chen, Chao Li, Minyi Guo, Yuhao Zhu",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.08089"" target=""_blank"">1904.08089</a>",,2025-12-03 22:39:25
Defensive Quantization: When Efficiency Meets Robustness,"Ji Lin, Chuang Gan, Song Han",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.08444"" target=""_blank"">1904.08444</a>",,2025-12-03 22:39:25
Interpreting Adversarial Examples with Attributes,"Sadaf Gulshad, Jan Hendrik Metzen, Arnold Smeulders, Zeynep Akata",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.08279"" target=""_blank"">1904.08279</a>",,2025-12-03 22:39:25
Gotta Catch 'Em All: Using Concealed Trapdoors to Detect Adversarial Attacks on Neural Networks,"Shawn Shan, Emily Willson, Bolun Wang, Bo Li, Haitao Zheng, Ben Y. Zhao",arXiv,2019-04,"<a href=""http://arxiv.org/abs/1904.08554"" target=""_blank"">1904.08554</a>",,2025-12-03 22:39:25
Out-domain examples for generative models,"Dario Pasquini, Marco Mingione, Massimo Bernaschi",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.02926"" target=""_blank"">1903.02926</a>",,2025-12-03 22:39:25
On Certifying Non-uniform Bound against Adversarial Attacks,"Chen Liu, Ryota Tomioka, Volkan Cevher",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.06603"" target=""_blank"">1903.06603</a>",,2025-12-03 22:39:25
A Research Agenda: Dynamic Models to Defend Against Correlated Attacks,Ian Goodfellow,arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.06293"" target=""_blank"">1903.06293</a>",,2025-12-03 22:39:25
Attribution-driven Causal Analysis for Detection of Adversarial Examples,"Susmit Jha, Sunny Raj, Steven Lawrence Fernandes, Sumit Kumar Jha, Somesh Jha, Gunjan Verma, Brian Jalaian, Ananthram Swami",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.05821"" target=""_blank"">1903.05821</a>",,2025-12-03 22:39:25
Adversarial attacks against Fact Extraction and VERification,"James Thorne, Andreas Vlachos",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.05543"" target=""_blank"">1903.05543</a>",,2025-12-03 22:39:25
Simple Physical Adversarial Examples against End-to-End Autonomous Driving Models,"Adith Boloor, Xin He, Christopher Gill, Yevgeniy Vorobeychik, Xuan Zhang",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.05157"" target=""_blank"">1903.05157</a>",,2025-12-03 22:39:25
Can Adversarial Network Attack be Defended?,"Jinyin Chen, Yangyang Wu, Xiang Lin, Qi Xuan",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.05994"" target=""_blank"">1903.05994</a>",,2025-12-03 22:39:25
Manifold Preserving Adversarial Learning,"Ousmane Amadou Dia, Elnaz Barshan, Reza Babanezhad",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.03905"" target=""_blank"">1903.03905</a>",,2025-12-03 22:39:25
Attack Type Agnostic Perceptual Enhancement of Adversarial Images,"Bilgin Aksoy, Alptekin Temizel",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.03029"" target=""_blank"">1903.03029</a>",,2025-12-03 22:39:25
Statistical Guarantees for the Robustness of Bayesian Neural Networks,"Luca Cardelli, Marta Kwiatkowska, Luca Laurenti, Nicola Paoletti, Andrea Patane, Matthew Wicker",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.01980"" target=""_blank"">1903.01980</a>",,2025-12-03 22:39:25
GanDef: A GAN based Adversarial Training Defense for Neural Network Classifier,"Guanxiong Liu, Issa Khalil, Abdallah Khreishah",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.02585"" target=""_blank"">1903.02585</a>",,2025-12-03 22:39:25
L 1-norm double backpropagation adversarial defense,"Ismaïla LIMOS, LITIS Seck, Gaëlle LIMOS Loosli, Stephane LITIS Canu",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.01715"" target=""_blank"">1903.01715</a>",,2025-12-03 22:39:25
Defense Against Adversarial Images using Web-Scale Nearest-Neighbor Search,"Abhimanyu Dubey, der Maaten Laurens van, Zeki Yalniz, Yixuan Li, Dhruv Mahajan",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.01612"" target=""_blank"">1903.01612</a>",,2025-12-03 22:39:25
The Vulnerabilities of Graph Convolutional Networks: Stronger Attacks and Defensive Techniques,"Huijun Wu, Chen Wang, Yuriy Tyshetskiy, Andrew Dotcherty, Kai Lu, Liming Zhu",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.01610"" target=""_blank"">1903.01610</a>",,2025-12-03 22:39:25
Safety Verification and Robustness Analysis of Neural Networks via Quadratic Constraints and Semidefinite Programming,"Mahyar Fazlyab, Manfred Morari, George J. Pappas",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.01287"" target=""_blank"">1903.01287</a>",,2025-12-03 22:39:25
A Kernelized Manifold Mapping to Diminish the Effect of Adversarial Perturbations,"Saeid Asgari Taghanaki, Kumar Abhishek, Shekoofeh Azizi, Ghassan Hamarneh",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.01015"" target=""_blank"">1903.01015</a>",,2025-12-03 22:39:25
Evaluating Adversarial Evasion Attacks in the Context of Wireless Communications,"Bryse Flowers, R. Michael Buehrer, William C. Headley",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.01563"" target=""_blank"">1903.01563</a>",,2025-12-03 22:39:25
PuVAE: A Variational Autoencoder to Purify Adversarial Examples,"Uiwon Hwang, Jaewoo Park, Hyemi Jang, Sungroh Yoon, Nam Ik Cho",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.00585"" target=""_blank"">1903.00585</a>",,2025-12-03 22:39:25
Attacking Graph-based Classification via Manipulating the Graph Structure,"Binghui Wang, Neil Zhenqiang Gong",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.00553"" target=""_blank"">1903.00553</a>",,2025-12-03 22:39:25
On the Effectiveness of Low Frequency Perturbations,"Yash Sharma, Gavin Weiguang Ding, Marcus Brubaker",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.00073"" target=""_blank"">1903.00073</a>",,2025-12-03 22:39:25
Complement Objective Training,"Hao-Yun Chen, Pei-Hsin Wang, Chun-Hao Liu, Shih-Chieh Chang, Jia-Yu Pan, Yu-Ting Chen, Wei Wei, Da-Cheng Juan",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.01182"" target=""_blank"">1903.01182</a>",,2025-12-03 22:39:25
On Evaluation of Adversarial Perturbations for Sequence-to-Sequence Models,"Paul Michel, Xian Li, Graham Neubig, Juan Miguel Pino",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.06620"" target=""_blank"">1903.06620</a>","<a href=""https://github.com/pmichel31415/teapot-nlp"" target=""_blank"">pmichel31415</a>",2025-12-03 22:39:25
Adversarial Attacks on Deep Neural Networks for Time Series Classification,"Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, Pierre-Alain Muller",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.07054"" target=""_blank"">1903.07054</a>",,2025-12-03 22:39:25
Defending against Whitebox Adversarial Attacks via Randomized Discretization,"Yuchen Zhang, Percy Liang",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.10586"" target=""_blank"">1903.10586</a>",,2025-12-03 22:39:25
Generating Adversarial Examples With Conditional Generative Adversarial Net,"Ping Yu, Kaitao Song, Jianfeng Lu",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.07282"" target=""_blank"">1903.07282</a>",,2025-12-03 22:39:25
"Adversarial Robustness vs Model Compression, or Both?","Shaokai Ye, Kaidi Xu, Sijia Liu, Hao Cheng, Jan-Henrik Lambrechts, Huan Zhang, Aojun Zhou, Kaisheng Ma, Yanzhi Wang, Xue Lin",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.12561"" target=""_blank"">1903.12561</a>","<a href=""https://github.com/yeshaokai/Robustness-Aware-Pruning-ADMM"" target=""_blank"">yeshaokai</a>",2025-12-03 22:39:25
Benchmarking Neural Network Robustness to Common Corruptions and Perturbations,"Dan Hendrycks, Thomas Dietterich",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.12261"" target=""_blank"">1903.12261</a>",,2025-12-03 22:39:25
Smooth Adversarial Examples,"Hanwei Zhang, Yannis Avrithis, Teddy Furon, Laurent Amsaleg",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.11862"" target=""_blank"">1903.11862</a>",,2025-12-03 22:39:25
Scaling up the randomized gradient-free adversarial attack reveals overestimation of robustness using established attacks,"Francesco Croce, Jonas Rauber, Matthias Hein",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.11359"" target=""_blank"">1903.11359</a>",,2025-12-03 22:39:25
Rallying Adversarial Techniques against Deep Learning for Network Security,"Joseph Clements, Yuzhe Yang, Ankur Sharma, Hongxin Hu, Yingjie Lao",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.11688"" target=""_blank"">1903.11688</a>",,2025-12-03 22:39:25
Text Processing Like Humans Do: Visually Attacking and Shielding NLP Systems,"Steffen Eger, Gözde Gül Şahin, Andreas Rücklé, Ji-Ung Lee, Claudia Schulz, Mohsen Mesgar, Krishnkant Swarnkar, Edwin Simpson, Iryna Gurevych",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.11508"" target=""_blank"">1903.11508</a>",,2025-12-03 22:39:25
On the Adversarial Robustness of Multivariate Robust Estimation,"Erhan Bayraktar, Lifeng Lai",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.11220"" target=""_blank"">1903.11220</a>",,2025-12-03 22:39:25
A geometry-inspired decision-based attack,"Yujia Liu, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.10826"" target=""_blank"">1903.10826</a>",,2025-12-03 22:39:25
Bridging Adversarial Robustness and Gradient Interpretability,"Beomsu Kim, Junghoon Seo, Taegyun Jeon",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.11626"" target=""_blank"">1903.11626</a>",,2025-12-03 22:39:25
Exploiting Excessive Invariance caused by Norm-Bounded Adversarial Robustness,"Jörn-Henrik Jacobsen, Jens Behrmannn, Nicholas Carlini, Florian Tramèr, Nicolas Papernot",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.10484"" target=""_blank"">1903.10484</a>",,2025-12-03 22:39:25
Robust Neural Networks using Randomized Adversarial Training,"Alexandre Araujo, Laurent Meunier, Rafael Pinot, Benjamin Negrevergne",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.10219"" target=""_blank"">1903.10219</a>",,2025-12-03 22:39:25
A Formalization of Robustness for Deep Neural Networks,"Tommaso Dreossi, Shromona Ghosh, Alberto Sangiovanni-Vincentelli, Sanjit A. Seshia",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.10033"" target=""_blank"">1903.10033</a>",,2025-12-03 22:39:25
Variational Inference with Latent Space Quantization for Adversarial Resilience,"Vinay Kyatham, Mayank Mishra, Tarun Kumar Yadav, Deepak Mishra, Prathosh AP",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.09940"" target=""_blank"">1903.09940</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness via Guided Complement Entropy,"Hao-Yun Chen, Jhao-Hong Liang, Shih-Chieh Chang, Jia-Yu Pan, Yu-Ting Chen, Wei Wei, Da-Cheng Juan",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.09799"" target=""_blank"">1903.09799</a>",,2025-12-03 22:39:25
"Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition","Yao Qin, Nicholas Carlini, Ian Goodfellow, Garrison Cottrell, Colin Raffel",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.10346"" target=""_blank"">1903.10346</a>",,2025-12-03 22:39:25
Fast Bayesian Uncertainty Estimation and Reduction of Batch Normalized Single Image Super-Resolution Network,"Aupendu Kar, Prabir Kumar Biswas",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.09410"" target=""_blank"">1903.09410</a>",,2025-12-03 22:39:25
Provable Certificates for Adversarial Examples: Fitting a Ball in the Union of Polytopes,"Matt Jordan, Justin Lewis, Alexandros G. Dimakis",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.08778"" target=""_blank"">1903.08778</a>",,2025-12-03 22:39:25
The LogBarrier adversarial attack: making effective use of decision boundary information,"Chris Finlay, Aram-Alexandre Pooladian, Adam M. Oberman",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.10396"" target=""_blank"">1903.10396</a>",,2025-12-03 22:39:25
On the Robustness of Deep K-Nearest Neighbors,"Chawin Sitawarin, David Wagner",arXiv,2019-03,"<a href=""http://arxiv.org/abs/1903.08333"" target=""_blank"">1903.08333</a>",,2025-12-03 22:39:25
Mockingbird: Defending Against Deep-Learning-Based Website Fingerprinting Attacks with Adversarial Traces,"Mohsen Imani, Mohammad Saidur Rahman, Nate Mathews, Matthew Wright",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.06626"" target=""_blank"">1902.06626</a>",,2025-12-03 22:39:25
Understanding the One-Pixel Attack: Propagation Maps and Locality Analysis,"Danilo Vasconcellos Vargas, Jiawei Su",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.02947"" target=""_blank"">1902.02947</a>",,2025-12-03 22:39:25
Minimal Images in Deep Neural Networks: Fragile Object Recognition in Natural Images,"Sanjana Srivastava, Guy Ben-Yosef, Xavier Boix",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.03227"" target=""_blank"">1902.03227</a>",,2025-12-03 22:39:25
When Causal Intervention Meets Adversarial Examples and Image Masking for Deep Neural Networks,"Chao-Han Huck Yang, Yi-Chieh Liu, Pin-Yu Chen, Xiaoli Ma, Yi-Chang James Tsai",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.03380"" target=""_blank"">1902.03380</a>","<a href=""https://github.com/jjaacckkyy63/Causal-Intervention-AE-wAdvImg"" target=""_blank"">jjaacckkyy63</a>",2025-12-03 22:39:25
Model Compression with Adversarial Robustness: A Unified Optimization Framework,"Shupeng University of Rochester Gui, Haotao Texas A&M University Wang, Chen University of Rochester Yu, Haichuan University of Rochester Yang, Zhangyang Texas A&M University Wang, Ji Ytech Seattle AI lab, FeDA lab, AI platform, Kwai Inc Liu",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.03538"" target=""_blank"">1902.03538</a>","<a href=""https://github.com/shupenggui/ATMC"" target=""_blank"">shupenggui</a>",2025-12-03 22:39:25
A Survey: Towards a Robust Deep Neural Network in Text Domain,"Wenqi Wang, Lina Wang, Benxiao Tang, Run Wang, Aoshuang Ye",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.07285"" target=""_blank"">1902.07285</a>",,2025-12-03 22:39:25
Can Intelligent Hyperparameter Selection Improve Resistance to Adversarial Examples?,"Cody Burkard, Brent Lagesse",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.05586"" target=""_blank"">1902.05586</a>",,2025-12-03 22:39:25
Adversarial Samples on Android Malware Detection Systems for IoT Systems,"Xiaolei Liu, Xiaojiang Du, Xiaosong Zhang, Qingxin Zhu, Mohsen Guizani",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.04238"" target=""_blank"">1902.04238</a>",,2025-12-03 22:39:25
Examining Adversarial Learning against Graph-based IoT Malware Detection Systems,"Ahmed Abusnaina, Aminollah Khormali, Hisham Alasmary, Jeman Park, Afsah Anwar, Ulku Meteriz, Aziz Mohaisen",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.04416"" target=""_blank"">1902.04416</a>",,2025-12-03 22:39:25
The Odds are Odd: A Statistical Test for Detecting Adversarial Examples,"Kevin Roth, Yannic Kilcher, Thomas Hofmann",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.04818"" target=""_blank"">1902.04818</a>",,2025-12-03 22:39:25
DeepFault: Fault Localization for Deep Neural Networks,"Hasan Ferit Eniser, Simos Gerasimou, Alper Sen",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.05974"" target=""_blank"">1902.05974</a>",,2025-12-03 22:39:25
Adversarial Examples in RF Deep Learning: Detection of the Attack and its Physical Robustness,"Silvija Kokalj-Filipovic, Rob Miller",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.06044"" target=""_blank"">1902.06044</a>",,2025-12-03 22:39:25
Robustness Of Saak Transform Against Adversarial Attacks,"Thiyagarajan Ramanathan, Abinaya Manimaran, Suya You, C-C Jay Kuo",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.02826"" target=""_blank"">1902.02826</a>",,2025-12-03 22:39:25
Discretization based Solutions for Secure Machine Learning against Adversarial Attacks,"Priyadarshini Panda, Indranil Chakraborty, Kaushik Roy",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.03151"" target=""_blank"">1902.03151</a>",,2025-12-03 22:39:25
Robustness of Generalized Learning Vector Quantization Models against Adversarial Attacks,"Sascha Saralajew, Lars Holdijk, Maike Rees, Thomas Villmann",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.00577"" target=""_blank"">1902.00577</a>",,2025-12-03 22:39:25
Certified Adversarial Robustness via Randomized Smoothing,"Jeremy M Cohen, Elan Rosenfeld, J. Zico Kolter",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.02918"" target=""_blank"">1902.02918</a>","<a href=""http://github.com/locuslab/smoothing"" target=""_blank"">locuslab</a>",2025-12-03 22:39:25
Fooling Neural Network Interpretations via Adversarial Model Manipulation,"Juyeon Heo, Sunghwan Joo, Taesup Moon",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.02041"" target=""_blank"">1902.02041</a>",,2025-12-03 22:39:25
Daedalus: Breaking Non-Maximum Suppression in Object Detection via Adversarial Examples,"Derui Wang, Chaoran Li, Sheng Wen, Xiaojun Chang, Surya Nepal, Yang Xiang",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.02067"" target=""_blank"">1902.02067</a>",,2025-12-03 22:39:25
Fatal Brain Damage,"El Mahdi El Mhamdi, Rachid Guerraoui, Sergei Volodin",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.01686"" target=""_blank"">1902.01686</a>",,2025-12-03 22:39:25
Theoretical evidence for adversarial robustness through randomization,"Rafael Pinot, Laurent Meunier, Alexandre Araujo, Hisashi Kashima, Florian Yger, Cédric Gouy-Pailler, Jamal Atif",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.01148"" target=""_blank"">1902.01148</a>",,2025-12-03 22:39:25
Predictive Uncertainty Quantification with Compound Density Networks,"Agustinus Kristiadi, Sina Däubener, Asja Fischer",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.01080"" target=""_blank"">1902.01080</a>",,2025-12-03 22:39:25
Is Spiking Secure? A Comparative Study on the Security Vulnerabilities of Spiking and Deep Neural Networks,"Alberto Marchisio, Giorgio Nanfa, Faiq Khalid, Muhammad Abdullah Hanif, Maurizio Martina, Muhammad Shafique",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.01147"" target=""_blank"">1902.01147</a>",,2025-12-03 22:39:25
Robustness Certificates Against Adversarial Examples for ReLU Networks,"Sahil Singla, Soheil Feizi",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.01235"" target=""_blank"">1902.01235</a>",,2025-12-03 22:39:25
Natural and Adversarial Error Detection using Invariance to Image Transformations,"Yuval Bahat, Michal Irani, Gregory Shakhnarovich",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.00236"" target=""_blank"">1902.00236</a>",,2025-12-03 22:39:25
Adaptive Gradient for Adversarial Perturbations Generation,"Yatie Xiao, Chi-Man Pun",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.01220"" target=""_blank"">1902.01220</a>",,2025-12-03 22:39:25
The Efficacy of SHIELD under Different Threat Models,"Cory Cornelius, Nilaksh Das, Shang-Tse Chen, Li Chen, Michael E. Kounavis, Duen Horng Chau",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.00541"" target=""_blank"">1902.00541</a>",,2025-12-03 22:39:25
A New Family of Neural Networks Provably Resistant to Adversarial Attacks,"Rakshit Agrawal, Alfaro Luca de, David Helmbold",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.01208"" target=""_blank"">1902.01208</a>",,2025-12-03 22:39:25
Training Artificial Neural Networks by Generalized Likelihood Ratio Method: Exploring Brain-like Learning to Improve Robustness,"Li Xiao, Yijie Peng, Jeff Hong, Zewu Ke, Shuhuai Yang",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.00358"" target=""_blank"">1902.00358</a>","<a href=""https://github.com/LX-doctorAI/GLR_ADV"" target=""_blank"">LX-doctorAI</a>",2025-12-03 22:39:25
Mitigation of Adversarial Examples in RF Deep Classifiers Utilizing AutoEncoder Pre-training,"Silvija Kokalj-Filipovic, Rob Miller, Nicholas Chang, Chi Leung Lau",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.08034"" target=""_blank"">1902.08034</a>",,2025-12-03 22:39:25
Quantifying Perceptual Distortion of Adversarial Examples,"Matt Jordan, Naren Manoj, Surbhi Goel, Alexandros G. Dimakis",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.08265"" target=""_blank"">1902.08265</a>",,2025-12-03 22:39:25
AuxBlocks: Defense Adversarial Example via Auxiliary Blocks,"Yueyao Yu, Pengfei Yu, Wenye Li",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.06415"" target=""_blank"">1902.06415</a>",,2025-12-03 22:39:25
Adversarial attacks hidden in plain sight,"Jan Philip Göpfert, André Artelt, Heiko Wersing, Barbara Hammer",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.09286"" target=""_blank"">1902.09286</a>",,2025-12-03 22:39:25
On Evaluating Adversarial Robustness,"Nicholas Carlini, Anish Athalye, Nicolas Papernot, Wieland Brendel, Jonas Rauber, Dimitris Tsipras, Ian Goodfellow, Aleksander Madry, Alexey Kurakin",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.06705"" target=""_blank"">1902.06705</a>",,2025-12-03 22:39:25
Enhancing the Robustness of Deep Neural Networks by Boundary Conditional GAN,"Ke Sun, Zhanxing Zhu, Zhouchen Lin",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.11029"" target=""_blank"">1902.11029</a>",,2025-12-03 22:39:25
"Towards Understanding Adversarial Examples Systematically: Exploring Data Size, Task and Model Factors","Ke Sun, Zhanxing Zhu, Zhouchen Lin",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.11019"" target=""_blank"">1902.11019</a>",,2025-12-03 22:39:25
Adversarial Attack and Defense on Point Sets,"Qiang Zhang, Jiancheng Yang, Rongyao Fang, Bingbing Ni, Jinxian Liu, Qi Tian",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.10899"" target=""_blank"">1902.10899</a>",,2025-12-03 22:39:25
Robust Decision Trees Against Adversarial Examples,"Hongge Chen, Huan Zhang, Duane Boning, Cho-Jui Hsieh",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.10660"" target=""_blank"">1902.10660</a>",,2025-12-03 22:39:25
Tensor Dropout for Robust Learning,"Arinbjörn Kolbeinsson, Jean Kossaifi, Yannis Panagakis, Adrian Bulat, Anima Anandkumar, Ioanna Tzoulaki, Paul Matthews",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.10758"" target=""_blank"">1902.10758</a>",,2025-12-03 22:39:25
The Best Defense Is a Good Offense: Adversarial Attacks to Avoid Modulation Detection,"Muhammad Zaid Hameed, Andras Gyorgy, Deniz Gunduz",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.10674"" target=""_blank"">1902.10674</a>",,2025-12-03 22:39:25
A Distributionally Robust Optimization Method for Adversarial Multiple Kernel Learning,"Masoud Badiei Khuzani, Hongyi Ren, Md Tauhidul Islam, Lei Xing",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.10365"" target=""_blank"">1902.10365</a>",,2025-12-03 22:39:25
AutoGAN-based Dimension Reduction for Privacy Preservation,"Hung Nguyen, Di Zhuang, Pei-Yuan Wu, Morris Chang",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.10799"" target=""_blank"">1902.10799</a>",,2025-12-03 22:39:25
Disentangled Deep Autoencoding Regularization for Robust Image Classification,"Zhenyu Duan, Martin Renqiang Min, Li Erran Li, Mingbo Cai, Yi Xu, Bingbing Ni",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.11134"" target=""_blank"">1902.11134</a>",,2025-12-03 22:39:25
Analyzing Deep Neural Networks with Symbolic Propagation: Towards Higher Precision and Faster Verification,"Jianlin Li, Pengfei Yang, Jiangchao Liu, Liqian Chen, Xiaowei Huang, Lijun Zhang",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.09866"" target=""_blank"">1902.09866</a>",,2025-12-03 22:39:25
Verification of Non-Linear Specifications for Neural Networks,"Chongli Dj Qin, Dj Krishnamurthy, Dvijotham, Brendan O'Donoghue, Rudy Bunel, Robert Stanforth, Sven Gowal, Jonathan Uesato, Grzegorz Swirszcz, Pushmeet Kohli",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.09592"" target=""_blank"">1902.09592</a>",,2025-12-03 22:39:25
Adversarial Attacks on Time Series,"Fazle Karim, Somshubra Majumdar, Houshang Darabi",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.10755"" target=""_blank"">1902.10755</a>",,2025-12-03 22:39:25
MaskDGA: A Black-box Evasion Technique Against DGA Classifiers and Adversarial Defenses,"Lior Sidi, Asaf Nadler, Asaf Shabtai",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.08909"" target=""_blank"">1902.08909</a>",,2025-12-03 22:39:25
On the Sensitivity of Adversarial Robustness to Input Data Distributions,"Gavin Weiguang Ding, Kry Yik Chau Lui, Xiaomeng Jin, Luyu Wang, Ruitong Huang",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.08336"" target=""_blank"">1902.08336</a>",,2025-12-03 22:39:25
Adversarial Reinforcement Learning under Partial Observability in Software-Defined Networking,"Yi Han, David Hubczenko, Paul Montague, Vel Olivier De, Tamas Abraham, Benjamin I. P. Rubinstein, Christopher Leckie, Tansu Alpcan, Sarah Erfani",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.09062"" target=""_blank"">1902.09062</a>",,2025-12-03 22:39:25
There are No Bit Parts for Sign Bits in Black-Box Attacks,"Abdullah Al-Dujaili, Una-May O'Reilly",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.06894"" target=""_blank"">1902.06894</a>",,2025-12-03 22:39:25
Graph Adversarial Training: Dynamically Regularizing Based on Graph Structure,"Fuli Feng, Xiangnan He, Jie Tang, Tat-Seng Chua",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.08226"" target=""_blank"">1902.08226</a>","<a href=""https://github.com/fulifeng/GraphAT"" target=""_blank"">fulifeng</a>",2025-12-03 22:39:25
advertorch v0,"Gavin Weiguang Ding, Luyu Wang, Xiaomeng Jin",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.07623"" target=""_blank"">1902.07623</a>","<a href=""https://github.com/BorealisAI/advertorch"" target=""_blank"">BorealisAI</a>",2025-12-03 22:39:25
Wasserstein Adversarial Examples via Projected Sinkhorn Iterations,"Eric Wong, Frank R. Schmidt, J. Zico Kolter",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.07906"" target=""_blank"">1902.07906</a>","<a href=""https://github.com/locuslab/projected_sinkhorn"" target=""_blank"">locuslab</a>",2025-12-03 22:39:25
Perceptual Quality-preserving Black-Box Attack against Deep Learning Image Classifiers,"Diego Gragnaniello, Francesco Marra, Giovanni Poggi, Luisa Verdoliva",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.07776"" target=""_blank"">1902.07776</a>",,2025-12-03 22:39:25
Adversarial Attacks on Graph Neural Networks via Meta Learning,"Daniel Zügner, Stephan Günnemann",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.08412"" target=""_blank"">1902.08412</a>",,2025-12-03 22:39:25
A Convex Relaxation Barrier to Tight Robustness Verification of Neural Networks,"Hadi Salman, Greg Yang, Huan Zhang, Cho-Jui Hsieh, Pengchuan Zhang",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.08722"" target=""_blank"">1902.08722</a>","<a href=""http://github.com/Hadisalman/robust-verify-benchmark"" target=""_blank"">Hadisalman</a>",2025-12-03 22:39:25
Physical Adversarial Attacks Against End-to-End Autoencoder Communication Systems,"Meysam Sadeghi, Erik G. Larsson",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.08391"" target=""_blank"">1902.08391</a>",,2025-12-03 22:39:25
"A Deep, Information-theoretic Framework for Robust Biometric Recognition","Renjie Xie, Yanzhi Chen, Yan Wo, Qiao Wang",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.08785"" target=""_blank"">1902.08785</a>",,2025-12-03 22:39:25
Re-evaluating ADEM: A Deeper Look at Scoring Dialogue Responses,"Ananya B. Sai, Mithun Das Gupta, Mitesh M. Khapra, Mukundhan Srinivasan",arXiv,2019-02,"<a href=""http://arxiv.org/abs/1902.08832"" target=""_blank"">1902.08832</a>",,2025-12-03 22:39:25
Universal Rules for Fooling Deep Neural Networks based Text Classification,"Di Li, Danilo Vasconcellos Vargas, Sakurai Kouichi",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.07132"" target=""_blank"">1901.07132</a>",,2025-12-03 22:39:25
Characterizing and evaluating adversarial examples for Offline Handwritten Signature Verification,"Luiz G. Hafemann, Robert Sabourin, Luiz S. Oliveira",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.03398"" target=""_blank"">1901.03398</a>",,2025-12-03 22:39:25
Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey,"Wei Emma Zhang, Quan Z. Sheng, Ahoud Alhazmi, Chenliang Li",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.06796"" target=""_blank"">1901.06796</a>",,2025-12-03 22:39:25
Sensitivity Analysis of Deep Neural Networks,"Hai Shu, Hongtu Zhu",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.07152"" target=""_blank"">1901.07152</a>",,2025-12-03 22:39:25
Perception-in-the-Loop Adversarial Examples,"Mahmoud Salamati, Sadegh Soudjani, Rupak Majumdar",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.06834"" target=""_blank"">1901.06834</a>",,2025-12-03 22:39:25
Easy to Fool? Testing the Anti-evasion Capabilities of PDF Malware Scanners,"Saeed TU Darmstadt Ehteshamifar, Antonio xorlab Barresi, Thomas R. ETH Zurich Gross, Michael TU Darmstadt Pradel",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.05674"" target=""_blank"">1901.05674</a>",,2025-12-03 22:39:25
The Limitations of Adversarial Training and the Blind-Spot Attack,"Huan Zhang, Hongge Chen, Zhao Song, Duane Boning, Inderjit S. Dhillon, Cho-Jui Hsieh",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.04684"" target=""_blank"">1901.04684</a>",,2025-12-03 22:39:25
Generating Adversarial Perturbation with Root Mean Square Gradient,"Yatie Xiao, Chi-Man Pun, Jizhe Zhou",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.03706"" target=""_blank"">1901.03706</a>",,2025-12-03 22:39:25
ECGadv: Generating Adversarial Electrocardiogram to Misguide Arrhythmia Classification System,"Huangxun Chen, Chenyu Huang, Qianyi Huang, Qian Zhang, Wei Wang",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.03808"" target=""_blank"">1901.03808</a>",,2025-12-03 22:39:25
Explaining Vulnerabilities of Deep Learning to Adversarial Malware Binaries,"Luca Demetrio, Battista Biggio, Giovanni Lagorio, Fabio Roli, Alessandro Armando",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.03583"" target=""_blank"">1901.03583</a>",,2025-12-03 22:39:25
Adversarial Examples Versus Cloud-based Detectors: A Black-box Empirical Study,"Xurong Li, Shouling Ji, Meng Han, Juntao Ji, Zhenyu Ren, Yushan Liu, Chunming Wu",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.01223"" target=""_blank"">1901.01223</a>",,2025-12-03 22:39:25
Image Transformation can make Neural Networks more robust against Adversarial Examples,"Dang Duy Thang, Toshihiro Matsui",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.03037"" target=""_blank"">1901.03037</a>",,2025-12-03 22:39:25
Extending Adversarial Attacks and Defenses to Deep 3D Point Cloud Classifiers,"Daniel Liu, Ronald Yu, Hao Su",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.03006"" target=""_blank"">1901.03006</a>",,2025-12-03 22:39:25
Interpretable BoW Networks for Adversarial Example Detection,"Krishna Kanth Nakka, Mathieu Salzmann",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.02229"" target=""_blank"">1901.02229</a>",,2025-12-03 22:39:25
Image Super-Resolution as a Defense Against Adversarial Attacks,"Aamir Mustafa, Salman H. Khan, Munawar Hayat, Jianbing Shen, Ling Shao",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.01677"" target=""_blank"">1901.01677</a>","<a href=""https://github.com/aamir-mustafa/super-resolution-adversarial-defense"" target=""_blank"">aamir-mustafa</a>",2025-12-03 22:39:25
Fake News Detection via NLP is Vulnerable to Adversarial Attacks,"Zhixuan Zhou, Huankang Guan, Meghana Moorthy Bhat, Justin Hsu",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.09657"" target=""_blank"">1901.09657</a>",,2025-12-03 22:39:25
Multi-Label Adversarial Perturbations,"Qingquan Song, Haifeng Jin, Xiao Huang, Xia Hu",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.00546"" target=""_blank"">1901.00546</a>",,2025-12-03 22:39:25
Adversarial Robustness May Be at Odds With Simplicity,Preetum Nakkiran,arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.00532"" target=""_blank"">1901.00532</a>",,2025-12-03 22:39:25
A Noise-Sensitivity-Analysis-Based Test Prioritization Technique for Deep Neural Networks,"Long Zhang, Xuechao Sun, Yong Li, Zhenyu Zhang",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.00054"" target=""_blank"">1901.00054</a>",,2025-12-03 22:39:25
SirenAttack: Generating Adversarial Audio for End-to-End Acoustic Systems,"Tianyu Du, Shouling Ji, Jinfeng Li, Qinchen Gu, Ting Wang, Raheem Beyah",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.07846"" target=""_blank"">1901.07846</a>",,2025-12-03 22:39:25
Sitatapatra: Blocking the Transfer of Adversarial Samples,"Ilia Shumailov, Xitong Gao, Yiren Zhao, Robert Mullins, Ross Anderson, Cheng-Zhong Xu",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.08121"" target=""_blank"">1901.08121</a>",,2025-12-03 22:39:25
Theoretically Principled Trade-off between Robustness and Accuracy,"Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P. Xing, Laurent El Ghaoui, Michael I. Jordan",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.08573"" target=""_blank"">1901.08573</a>",,2025-12-03 22:39:25
Reliable Smart Road Signs,"Muhammed O. Sayin, Chung-Wei Lin, Eunsuk Kang, Shinichi Shiraishi, Tamer Basar",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.10622"" target=""_blank"">1901.10622</a>",,2025-12-03 22:39:25
Using Pre-Training Can Improve Model Robustness and Uncertainty,"Dan Hendrycks, Kimin Lee, Mantas Mazeika",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.09960"" target=""_blank"">1901.09960</a>",,2025-12-03 22:39:25
Cross-Entropy Loss and Low-Rank Features Have Responsibility for Adversarial Examples,"Kamil Nar, Orhan Ocal, S. Shankar Sastry, Kannan Ramchandran",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.08360"" target=""_blank"">1901.08360</a>",,2025-12-03 22:39:25
A Simple Explanation for the Existence of Adversarial Examples with Small Hamming Distance,"Adi Shamir, Itay Safran, Eyal Ronen, Orr Dunkelman",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.10861"" target=""_blank"">1901.10861</a>",,2025-12-03 22:39:25
Augmenting Model Robustness with Transformation-Invariant Attacks,"Houpu Yao, Zhe Wang, Guangyu Nie, Yassine Mazboudi, Yezhou Yang, Yi Ren",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.11188"" target=""_blank"">1901.11188</a>",,2025-12-03 22:39:25
Adversarial Examples Are a Natural Consequence of Test Error in Noise,"Nic Ford, Justin Gilmer, Nicolas Carlini, Dogus Cubuk",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.10513"" target=""_blank"">1901.10513</a>",,2025-12-03 22:39:25
RED-Attack: Resource Efficient Decision based Attack for Machine Learning,"Faiq Khalid, Hassan Ali, Muhammad Abdullah Hanif, Semeen Rehman, Rehan Ahmed, Muhammad Shafique",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.10258"" target=""_blank"">1901.10258</a>",,2025-12-03 22:39:25
On the Effect of Low-Rank Weights on Adversarial Robustness of Neural Networks,"Peter Langenberg, Emilio Rafael Balda, Arash Behboodi, Rudolf Mathar",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.10371"" target=""_blank"">1901.10371</a>",,2025-12-03 22:39:25
Adversarial Metric Attack and Defense for Person Re-identification,"Song Bai, Yingwei Li, Yuyin Zhou, Qizhu Li, Philip H. S. Torr",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.10650"" target=""_blank"">1901.10650</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness of Ensembles with Diversity Training,"Sanjay Kariyappa, Moinuddin K. Qureshi",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.09981"" target=""_blank"">1901.09981</a>",,2025-12-03 22:39:25
Defense Methods Against Adversarial Examples for Recurrent Neural Networks,"Ishai Rosenberg, Asaf Shabtai, Yuval Elovici, Lior Rokach",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.09963"" target=""_blank"">1901.09963</a>",,2025-12-03 22:39:25
CapsAttacks: Robust and Imperceptible Adversarial Attacks on Capsule Networks,"Alberto Marchisio, Giorgio Nanfa, Faiq Khalid, Muhammad Abdullah Hanif, Maurizio Martina, Muhammad Shafique",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.09878"" target=""_blank"">1901.09878</a>",,2025-12-03 22:39:25
"Efficient Multiparty Interactive Coding for Insertions, Deletions and Substitutions","Ran Gelles, Yael T. Kalai, Govind Ramnarayan",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.09863"" target=""_blank"">1901.09863</a>",,2025-12-03 22:39:25
An Information-Theoretic Explanation for the Adversarial Fragility of AI Classifiers,"Hui Xie, Jirong Yi, Weiyu Xu, Raghu Mudumbai",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.09413"" target=""_blank"">1901.09413</a>",,2025-12-03 22:39:25
Characterizing the Shape of Activation Space in Deep Neural Networks,"Thomas Gebhart, Paul Schrater, Alan Hylton",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.09496"" target=""_blank"">1901.09496</a>",,2025-12-03 22:39:25
Strong Black-box Adversarial Attacks on Unsupervised Machine Learning Models,"Anshuman Chhabra, Abhishek Roy, Prasant Mohapatra",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.09493"" target=""_blank"">1901.09493</a>",,2025-12-03 22:39:25
A Black-box Attack on Neural Networks Based on Swarm Evolutionary Algorithm,"Xiaolei Liu, Yuheng Luo, Xiaosong Zhang, Qingxin Zhu",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.09892"" target=""_blank"">1901.09892</a>",,2025-12-03 22:39:25
Weighted-Sampling Audio Adversarial Example Attack,"Xiaolei Liu, Xiaosong Zhang, Kun Wan, Qingxin Zhu, Yufei Ding",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.10300"" target=""_blank"">1901.10300</a>",,2025-12-03 22:39:25
Generative Adversarial Networks for Black-Box API Attacks with Limited Training Data,"Yi Shi, Yalin E. Sagduyu, Kemal Davaslioglu, Jason H. Li",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.09113"" target=""_blank"">1901.09113</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness via Promoting Ensemble Diversity,"Tianyu Pang, Kun Xu, Chao Du, Ning Chen, Jun Zhu",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.08846"" target=""_blank"">1901.08846</a>",,2025-12-03 22:39:25
Chapter: Vulnerability of Quantum Information Systems to Collective Manipulation,"Fernando J. Gómez-Ruiz, Ferney J. Rodríguez, Luis Quiroga, Neil F. Johnson",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.08873"" target=""_blank"">1901.08873</a>",,2025-12-03 22:39:25
Towards Interpretable Deep Neural Networks by Leveraging Adversarial Examples,"Yinpeng Dong, Fan Bao, Hang Su, Jun Zhu",arXiv,2019-01,"<a href=""http://arxiv.org/abs/1901.09035"" target=""_blank"">1901.09035</a>",,2025-12-03 22:39:25
Prior Networks for Detection of Adversarial Attacks,"Andrey Malinin, Mark Gales",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.02575"" target=""_blank"">1812.02575</a>",,2025-12-03 22:39:25
On Configurable Defense against Adversarial Example Attacks,"Bo Luo, Min Li, Yu Li, Qiang Xu",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.02737"" target=""_blank"">1812.02737</a>",,2025-12-03 22:39:25
MMA Training: Direct Input Space Margin Maximization through Adversarial Training,"Gavin Weiguang Ding, Yash Sharma, Kry Yik Chau Lui, Ruitong Huang",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.02637"" target=""_blank"">1812.02637</a>","<a href=""https://github.com/BorealisAI/mma_training"" target=""_blank"">BorealisAI</a>",2025-12-03 22:39:25
The Limitations of Model Uncertainty in Adversarial Settings,"Kathrin Grosse, David Pfaff, Michael Thomas Smith, Michael Backes",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.02606"" target=""_blank"">1812.02606</a>",,2025-12-03 22:39:25
Fooling Network Interpretation in Image Classification,"Akshayvarun Subramanya, Vipin Pillai, Hamed Pirsiavash",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.02843"" target=""_blank"">1812.02843</a>",,2025-12-03 22:39:25
Towards Leveraging the Information of Gradients in Optimization-based Adversarial Attack,"Jingyang Zhang, Hsin-Pai Cheng, Chunpeng Wu, Hai Li, Yiran Chen",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.02524"" target=""_blank"">1812.02524</a>",,2025-12-03 22:39:25
AutoGAN: Robust Classifier Against Adversarial Attacks,"Blerta Lindqvist, Shridatt Sugrim, Rauf Izmailov",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.03405"" target=""_blank"">1812.03405</a>",,2025-12-03 22:39:25
"Adversarial Attacks, Regression, and Numerical Stability Regularization","Andre T. Nguyen, Edward Raff",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.02885"" target=""_blank"">1812.02885</a>",,2025-12-03 22:39:25
Adversarial Defense of Image Classification Using a Variational Auto-Encoder,"Yi Luo, Henry Pfister",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.02891"" target=""_blank"">1812.02891</a>",,2025-12-03 22:39:25
Combatting Adversarial Attacks through Denoising and Dimensionality Reduction: A Cascaded Autoencoder Approach,"Rajeev Sahay, Rehana Mahfuz, Aly El Gamal",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.03087"" target=""_blank"">1812.03087</a>",,2025-12-03 22:39:25
Deep-RBF Networks Revisited: Robust Classification with Rejection,"Pourya Habib Zadeh, Reshad Hosseini, Suvrit Sra",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.03190"" target=""_blank"">1812.03190</a>",,2025-12-03 22:39:25
Learning Transferable Adversarial Examples via Ghost Networks,"Yingwei Li, Song Bai, Yuyin Zhou, Cihang Xie, Zhishuai Zhang, Alan Yuille",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.03413"" target=""_blank"">1812.03413</a>","<a href=""https://github.com/LiYingwei/ghost-network"" target=""_blank"">LiYingwei</a>",2025-12-03 22:39:25
Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures,"Jonathan Dj Uesato, Ananya Dj Kumar, Csaba Dj Szepesvari, Tom Dj Erez, Avraham Dj Ruderman, Keith Dj Anderson, Dj Krishmamurthy, Dvijotham, Nicolas Heess, Pushmeet Kohli",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.01647"" target=""_blank"">1812.01647</a>",,2025-12-03 22:39:25
SADA: Semantic Adversarial Diagnostic Attacks for Autonomous Applications,"Abdullah Hamdi, Matthias Müller, Bernard Ghanem",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.02132"" target=""_blank"">1812.02132</a>",,2025-12-03 22:39:25
SentiNet: Detecting Localized Universal Attacks Against Deep Learning Systems,"Edward Chou, Florian Tramèr, Giancarlo Pellegrino",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.00292"" target=""_blank"">1812.00292</a>",,2025-12-03 22:39:25
Random Spiking and Systematic Evaluation of Defenses Against Adversarial Examples,"Huangyi Ge, Sze Yiu Chau, Bruno Ribeiro, Ninghui Li",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.01804"" target=""_blank"">1812.01804</a>",,2025-12-03 22:39:25
Disentangling Adversarial Robustness and Generalization,"David Stutz, Matthias Hein, Bernt Schiele",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.00740"" target=""_blank"">1812.00740</a>",,2025-12-03 22:39:25
Interpretable Deep Learning under Fire,"Xinyang Zhang, Ningfei Wang, Hua Shen, Shouling Ji, Xiapu Luo, Ting Wang",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.00891"" target=""_blank"">1812.00891</a>",,2025-12-03 22:39:25
Adversarial Example Decomposition,"Horace He, Aaron Lou, Qingxuan Jiang, Isay Katsman, Serge Belongie, Ser-Nam Lim",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.01198"" target=""_blank"">1812.01198</a>",,2025-12-03 22:39:25
Model-Reuse Attacks on Deep Learning Systems,"Yujie Ji, Xinyang Zhang, Shouling Ji, Xiapu Luo, Ting Wang",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.00483"" target=""_blank"">1812.00483</a>",,2025-12-03 22:39:25
Universal Perturbation Attack Against Image Retrieval,"Jie Li, Rongrong Ji, Hong Liu, Xiaopeng Hong, Yue Gao, Qi Tian",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.00552"" target=""_blank"">1812.00552</a>",,2025-12-03 22:39:25
FineFool: Fine Object Contour Attack via Attention,"Jinyin Chen, Haibin Zheng, Hui Xiong, Mengmeng Su",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.01713"" target=""_blank"">1812.01713</a>",,2025-12-03 22:39:25
Building robust classifiers through generation of confident out of distribution examples,"Kumar Sricharan, Ashok Srivastava",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.00239"" target=""_blank"">1812.00239</a>",,2025-12-03 22:39:25
Discrete Adversarial Attacks and Submodular Optimization with Applications to Text Classification,"Qi Lei, Lingfei Wu, Pin-Yu Chen, Alexandros G. Dimakis, Inderjit S. Dhillon, Michael Witbrock",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.00151"" target=""_blank"">1812.00151</a>",,2025-12-03 22:39:25
Effects of Loss Functions And Target Representations on Adversarial Robustness,"Sean Saito, Sujoy Roy",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.00181"" target=""_blank"">1812.00181</a>",,2025-12-03 22:39:25
Adversarial Defense by Stratified Convolutional Sparse Coding,"Bo Sun, Nian-hsuan Tsai, Fangchen Liu, Ronald Yu, Hao Su",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.00037"" target=""_blank"">1812.00037</a>",,2025-12-03 22:39:25
Convolutional Neural Networks with Transformed Input based on Robust Tensor Network Decomposition,"Jenn-Bing Ong, Wee-Keong Ng, C. -C. Jay Kuo",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.02622"" target=""_blank"">1812.02622</a>",,2025-12-03 22:39:25
Detecting Adversarial Examples in Convolutional Neural Networks,"Stefanos Pertigkiozoglou, Petros Maragos",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.03303"" target=""_blank"">1812.03303</a>",,2025-12-03 22:39:25
Regularized Ensembles and Transferability in Adversarial Learning,"Yifan Chen, Yevgeniy Vorobeychik",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.01821"" target=""_blank"">1812.01821</a>",,2025-12-03 22:39:25
Feature Denoising for Improving Adversarial Robustness,"Cihang Xie, Yuxin Wu, der Maaten Laurens van, Alan Yuille, Kaiming He",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.03411"" target=""_blank"">1812.03411</a>","<a href=""https://github.com/facebookresearch/ImageNet-Adversarial-Training"" target=""_blank"">facebookresearch</a>",2025-12-03 22:39:25
Spartan Networks: Self-Feature-Squeezing Neural Networks for increased robustness in adversarial settings,"François Menet, Paul Berthier, José M. Fernandez, Michel Gagnon",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.06815"" target=""_blank"">1812.06815</a>",,2025-12-03 22:39:25
Adversarial Attack and Defense on Graph Data: A Survey,"Lichao Sun, Yingtong Dou, Carl Yang, Ji Wang, Yixin Liu, Philip S. Yu, Lifang He, Bo Li",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.10528"" target=""_blank"">1812.10528</a>",,2025-12-03 22:39:25
Noise Flooding for Detecting Audio Adversarial Examples Against Automatic Speech Recognition,"Krishan Rajaratnam, Jugal Kalita",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.10061"" target=""_blank"">1812.10061</a>",,2025-12-03 22:39:25
Defending Against Universal Perturbations With Shared Adversarial Training,"Chaithanya Kumar Mummadi, Thomas Brox, Jan Hendrik Metzen",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.03705"" target=""_blank"">1812.03705</a>",,2025-12-03 22:39:25
PPD: Permutation Phase Defense Against Adversarial Examples in Deep Learning,"Mehdi Jafarnia-Jahromi, Tasmin Chowdhury, Hsin-Tai Wu, Sayandev Mukherjee",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.10049"" target=""_blank"">1812.10049</a>",,2025-12-03 22:39:25
A Multiversion Programming Inspired Approach to Detecting Audio Adversarial Examples,"Qiang Zeng, Jianhai Su, Chenglong Fu, Golam Kayas, Lannan Luo",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.10199"" target=""_blank"">1812.10199</a>",,2025-12-03 22:39:25
A Data-driven Adversarial Examples Recognition Framework via Adversarial Feature Genome,"Li Chen, Qi Li, Weiye Chen, Zeyu Wang, Haifeng Li",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.10085"" target=""_blank"">1812.10085</a>","<a href=""https://github.com/GeoX-Lab/Adv_Fea_Genome"" target=""_blank"">GeoX-Lab</a>",2025-12-03 22:39:25
Seeing isn't Believing: Practical Adversarial Attack Against Object Detectors,"Yue Zhao, Hong Zhu, Ruigang Liang, Qintao Shen, Shengzhi Zhang, Kai Chen",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.10217"" target=""_blank"">1812.10217</a>",,2025-12-03 22:39:25
Markov Game Modeling of Moving Target Defense for Strategic Detection of Threats in Cloud Networks,"Ankur Chowdhary, Sailik Sengupta, Dijiang Huang, Subbarao Kambhampati",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.09660"" target=""_blank"">1812.09660</a>",,2025-12-03 22:39:25
Guessing Smart: Biased Sampling for Efficient Black-Box Adversarial Attacks,"Thomas Brunner, Frederik Diehl, Michael Truong Le, Alois Knoll",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.09803"" target=""_blank"">1812.09803</a>",,2025-12-03 22:39:25
Exploiting the Inherent Limitation of L0 Adversarial Examples,"Fei Zuo, Bokai Yang, Xiaopeng Li, Lannan Luo, Qiang Zeng",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.09638"" target=""_blank"">1812.09638</a>",,2025-12-03 22:39:25
Dissociable neural representations of adversarially perturbed images in convolutional neural networks and the human brain,"Chi Zhang, Xiaohan Duan, Linyuan Wang, Yongli Li, Bin Yan, Guoen Hu, Ruyuan Zhang, Li Tong",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.09431"" target=""_blank"">1812.09431</a>",,2025-12-03 22:39:25
"Enhancing Robustness of Deep Neural Networks Against Adversarial Malware Samples: Principles, Framework, and AICS'2019 Challenge","Deqiang Li, Qianmu Li, Yanfang Ye, Shouhuai Xu",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.08108"" target=""_blank"">1812.08108</a>",,2025-12-03 22:39:25
PROVEN: Certifying Robustness of Neural Networks with a Probabilistic Approach,"Tsui-Wei Weng, Pin-Yu Chen, Lam M. Nguyen, Mark S. Squillante, Ivan Oseledets, Luca Daniel",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.08329"" target=""_blank"">1812.08329</a>",,2025-12-03 22:39:25
DUP-Net: Denoiser and Upsampler Network for 3D Adversarial Point Clouds Defense,"Hang Zhou, Kejiang Chen, Weiming Zhang, Han Fang, Wenbo Zhou, Nenghai Yu",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.11017"" target=""_blank"">1812.11017</a>",,2025-12-03 22:39:25
Designing Adversarially Resilient Classifiers using Resilient Feature Engineering,"Kevin Eykholt, Atul Prakash",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.06626"" target=""_blank"">1812.06626</a>",,2025-12-03 22:39:25
TextBugger: Generating Adversarial Text Against Real-world Applications,"Jinfeng Li, Shouling Ji, Tianyu Du, Bo Li, Ting Wang",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.05271"" target=""_blank"">1812.05271</a>",,2025-12-03 22:39:25
Adversarial Framing for Image and Video Classification,"Konrad Zolna, Michal Zajac, Negar Rostamzadeh, Pedro O. Pinheiro",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.04599"" target=""_blank"">1812.04599</a>","<a href=""https://github.com/zajaczajac/adv_framing"" target=""_blank"">zajaczajac</a>",2025-12-03 22:39:25
DeepBillboard: Systematic Physical-World Testing of Autonomous Driving Systems,"Husheng Zhou, Wei Li, Yuankun Zhu, Yuqun Zhang, Bei Yu, Lingming Zhang, Cong Liu",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.10812"" target=""_blank"">1812.10812</a>",,2025-12-03 22:39:25
On the Security of Randomized Defenses Against Adversarial Samples,"Kumar Sharad, Giorgia Azzurra Marson, Hien Thi Thu Truong, Ghassan Karame",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.04293"" target=""_blank"">1812.04293</a>",,2025-12-03 22:39:25
Thwarting Adversarial Examples: An $L_0$-RobustSparse Fourier Transform,"Mitali Bafna, Jack Murtagh, Nikhil Vyas",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.05013"" target=""_blank"">1812.05013</a>",,2025-12-03 22:39:25
Why ReLU networks yield high-confidence predictions far away from the training data and how to mitigate the problem,"Matthias Hein, Maksym Andriushchenko, Julian Bitterwolf",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.05720"" target=""_blank"">1812.05720</a>",,2025-12-03 22:39:25
Generating Hard Examples for Pixel-wise Classification,"Hyungtae Lee, Heesung Kwon, Wonkook Kim",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.05447"" target=""_blank"">1812.05447</a>",,2025-12-03 22:39:25
Adversarial Sample Detection for Deep Neural Network through Model Mutation Testing,"Jingyi Wang, Guoliang Dong, Jun Sun, Xinyu Wang, Peixin Zhang",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.05793"" target=""_blank"">1812.05793</a>",,2025-12-03 22:39:25
Trust Region Based Adversarial Attack on Neural Networks,"Zhewei Yao, Amir Gholami, Peng Xu, Kurt Keutzer, Michael Mahoney",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.06371"" target=""_blank"">1812.06371</a>",,2025-12-03 22:39:25
Perturbation Analysis of Learning Algorithms: A Unifying Perspective on Generation of Adversarial Examples,"Emilio Rafael Balda, Arash Behboodi, Rudolf Mathar",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.07385"" target=""_blank"">1812.07385</a>",,2025-12-03 22:39:25
Defense-VAE: A Fast and Accurate Defense against Adversarial Attacks,"Xiang Li, Shihao Ji",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.06570"" target=""_blank"">1812.06570</a>","<a href=""https://github.com/lxuniverse/defense-vae"" target=""_blank"">lxuniverse</a>",2025-12-03 22:39:25
A Survey of Safety and Trustworthiness of Deep Neural Networks,"Xiaowei Huang, Daniel Kroening, Wenjie Ruan, James Sharp, Youcheng Sun, Emese Thamo, Min Wu, Xinping Yi",arXiv,2018-12,"<a href=""http://arxiv.org/abs/1812.08342"" target=""_blank"">1812.08342</a>",,2025-12-03 22:39:25
SparseFool: a few pixels make a big difference,"Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.02248"" target=""_blank"">1811.02248</a>",,2025-12-03 22:39:25
Universal Decision-Based Black-Box Perturbations: Breaking Security-Through-Obscurity Defenses,"Thomas A. Hogan, Bhavya Kailkhura",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.03733"" target=""_blank"">1811.03733</a>",,2025-12-03 22:39:25
MixTrain: Scalable Training of Verifiably Robust Neural Networks,"Shiqi Wang, Yizheng Chen, Ahmed Abdou, Suman Jana",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.02625"" target=""_blank"">1811.02625</a>",,2025-12-03 22:39:25
AdVersarial: Perceptual Ad Blocking meets Adversarial Machine Learning,"Florian Tramèr, Pascal Dupré, Gili Rusak, Giancarlo Pellegrino, Dan Boneh",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.03194"" target=""_blank"">1811.03194</a>",,2025-12-03 22:39:25
CAAD 2018: Iterative Ensemble Adversarial Attack,"Jiayang Liu, Weiming Zhang, Nenghai Yu",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.03456"" target=""_blank"">1811.03456</a>",,2025-12-03 22:39:25
A Geometric Perspective on the Transferability of Adversarial Directions,"Zachary Charles, Harrison Rosenberg, Dimitris Papailiopoulos",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.03531"" target=""_blank"">1811.03531</a>",,2025-12-03 22:39:25
New CleverHans Feature: Better Adversarial Robustness Evaluations with Attack Bundling,Ian Goodfellow,arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.03685"" target=""_blank"">1811.03685</a>",,2025-12-03 22:39:25
Mathematical Analysis of Adversarial Attacks,"Zehao Dou, Stanley J. Osher, Bao Wang",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.06492"" target=""_blank"">1811.06492</a>",,2025-12-03 22:39:25
Deep Q learning for fooling neural networks,Mandar Kulkarni,arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.05521"" target=""_blank"">1811.05521</a>",,2025-12-03 22:39:25
Robustness of spectral methods for community detection,"Ludovic Stephan, Laurent Massoulié",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.05808"" target=""_blank"">1811.05808</a>",,2025-12-03 22:39:25
Verification of Recurrent Neural Networks Through Rule Extraction,"Qinglong Wang, Kaixuan Zhang, Xue Liu, C. Lee Giles",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.06029"" target=""_blank"">1811.06029</a>",,2025-12-03 22:39:25
A Spectral View of Adversarially Robust Features,"Shivam Garg, Vatsal Sharan, Brian Hu Zhang, Gregory Valiant",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.06609"" target=""_blank"">1811.06609</a>",,2025-12-03 22:39:25
Adversarial Examples from Cryptographic Pseudo-Random Generators,"Sébastien Bubeck, Yin Tat Lee, Eric Price, Ilya Razenshteyn",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.06418"" target=""_blank"">1811.06418</a>",,2025-12-03 22:39:25
A note on hyperparameters in black-box adversarial examples,Jamie Hayes,arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.06539"" target=""_blank"">1811.06539</a>",,2025-12-03 22:39:25
FUNN: Flexible Unsupervised Neural Network,"David Vigouroux, Sylvain Picard",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.01749"" target=""_blank"">1811.01749</a>",,2025-12-03 22:39:25
Active Deep Learning Attacks under Strict Rate Limitations for Online API Calls,"Yi Shi, Yalin E. Sagduyu, Kemal Davaslioglu, Jason H. Li",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.01811"" target=""_blank"">1811.01811</a>",,2025-12-03 22:39:25
Improving Adversarial Robustness by Encouraging Discriminative Features,"Chirag Agarwal, Anh Nguyen, Dan Schonfeld",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.00621"" target=""_blank"">1811.00621</a>",,2025-12-03 22:39:25
On the Transferability of Adversarial Examples Against CNN-Based Image Forensics,"Mauro Barni, Kassem Kallas, Ehsan Nowroozi, Benedetta Tondi",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.01629"" target=""_blank"">1811.01629</a>",,2025-12-03 22:39:25
Efficient Neural Network Robustness Certification with General Activation Functions,"Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, Luca Daniel",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.00866"" target=""_blank"">1811.00866</a>",,2025-12-03 22:39:25
Unauthorized AI cannot Recognize Me: Reversible Adversarial Example,"Jiayang Liu, Weiming Zhang, Kazuto Fukuchi, Youhei Akimoto, Jun Sakuma",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.00189"" target=""_blank"">1811.00189</a>",,2025-12-03 22:39:25
When Not to Classify: Detection of Reverse Engineering Attacks on DNN Image Classifiers,"Yujia Wang, David J. Miller, George Kesidis",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.02658"" target=""_blank"">1811.02658</a>",,2025-12-03 22:39:25
Excessive Invariance Causes Adversarial Vulnerability,"Jörn-Henrik Jacobsen, Jens Behrmann, Richard Zemel, Matthias Bethge",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.00401"" target=""_blank"">1811.00401</a>",,2025-12-03 22:39:25
On the Geometry of Adversarial Examples,"Marc Khoury, Dylan Hadfield-Menell",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.00525"" target=""_blank"">1811.00525</a>",,2025-12-03 22:39:25
Protecting Voice Controlled Systems Using Sound Source Identification Based on Acoustic Cues,"Yuan Gong, Christian Poellabauer",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.07018"" target=""_blank"">1811.07018</a>",,2025-12-03 22:39:25
TrISec: Training Data-Unaware Imperceptible Security Attacks on Deep Neural Networks,"Faiq Khalid, Muhammad Abdullah Hanif, Semeen Rehman, Rehan Ahmed, Muhammad Shafique",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.01031"" target=""_blank"">1811.01031</a>",,2025-12-03 22:39:25
Towards Adversarial Malware Detection: Lessons Learned from PDF-based Attacks,"Davide Maiorca, Battista Biggio, Giorgio Giacinto",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.00830"" target=""_blank"">1811.00830</a>",,2025-12-03 22:39:25
Semidefinite relaxations for certifying robustness to adversarial examples,"Aditi Raghunathan, Jacob Steinhardt, Percy Liang",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.01057"" target=""_blank"">1811.01057</a>",,2025-12-03 22:39:25
FAdeML: Understanding the Impact of Pre-Processing Noise Filtering on Adversarial Machine Learning,"Faiq Khalid, Muhammmad Abdullah Hanif, Semeen Rehman, Junaid Qadir, Muhammad Shafique",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.01444"" target=""_blank"">1811.01444</a>",,2025-12-03 22:39:25
A Marauder's Map of Security and Privacy in Machine Learning,Nicolas Papernot,arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.01134"" target=""_blank"">1811.01134</a>",,2025-12-03 22:39:25
Learning to Defense by Learning to Attack,"Haoming Jiang, Zhehui Chen, Yuyang Shi, Bo Dai, Tuo Zhao",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.01213"" target=""_blank"">1811.01213</a>",,2025-12-03 22:39:25
Adversarial Black-Box Attacks on Automatic Speech Recognition Systems using Multi-Objective Evolutionary Optimization,"Shreya Khare, Rahul Aralikatte, Senthil Mani",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.01312"" target=""_blank"">1811.01312</a>",,2025-12-03 22:39:25
CAAD 2018: Powerful None-Access Black-Box Attack Based on Adversarial Transformation Network,"Xiaoyi Dong, Weiming Zhang, Nenghai Yu",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.01225"" target=""_blank"">1811.01225</a>",,2025-12-03 22:39:25
Adversarial Gain,"Peter Henderson, Koustuv Sinha, Rosemary Nan Ke, Joelle Pineau",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.01302"" target=""_blank"">1811.01302</a>",,2025-12-03 22:39:25
SSCNets: Robustifying DNNs using Secure Selective Convolutional Filters,"Hassan Ali, Faiq Khalid, Hammad Tariq, Muhammad Abdullah Hanif, Semeen Rehman, Rehan Ahmed, Muhammad Shafique",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.01443"" target=""_blank"">1811.01443</a>",,2025-12-03 22:39:25
QuSecNets: Quantization-based Defense Mechanism for Securing Deep Neural Network against Adversarial Attacks,"Faiq Khalid, Hassan Ali, Hammad Tariq, Muhammad Abdullah Hanif, Semeen Rehman, Rehan Ahmed, Muhammad Shafique",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.01437"" target=""_blank"">1811.01437</a>",,2025-12-03 22:39:25
DARCCC: Detecting Adversaries by Reconstruction from Class Conditional Capsules,"Nicholas Frosst, Sara Sabour, Geoffrey Hinton",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.06969"" target=""_blank"">1811.06969</a>",,2025-12-03 22:39:25
Classifiers Based on Deep Sparse Coding Architectures are Robust to Deep Learning Transferable Examples,"Jacob M. Springer, Charles S. Strauss, Austin M. Thresher, Edward Kim, Garrett T. Kenyon",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.07211"" target=""_blank"">1811.07211</a>",,2025-12-03 22:39:25
Boosting the Robustness Verification of DNN by Identifying the Achilles's Heel,"Chengdong Feng, Zhenbang Chen, Weijiang Hong, Hengbiao Yu, Wei Dong, Ji Wang",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.07108"" target=""_blank"">1811.07108</a>",,2025-12-03 22:39:25
Is Data Clustering in Adversarial Settings Secure?,"Battista Biggio, Ignazio Pillai, Samuel Rota Bulò, Davide Ariu, Marcello Pelillo, Fabio Roli",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.09982"" target=""_blank"">1811.09982</a>",,2025-12-03 22:39:25
ResNets Ensemble via the Feynman-Kac Formalism to Improve Natural and Robust Accuracies,"Bao Wang, Binjie Yuan, Zuoqiang Shi, Stanley J. Osher",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.10745"" target=""_blank"">1811.10745</a>","<a href=""https://github.com/BaoWangMath/EnResNet"" target=""_blank"">BaoWangMath</a>",2025-12-03 22:39:25
A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks,"Jinghui Chen, Dongruo Zhou, Jinfeng Yi, Quanquan Gu",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.10828"" target=""_blank"">1811.10828</a>",,2025-12-03 22:39:25
Using Attribution to Decode Dataset Bias in Neural Network Models for Chemistry,"Kevin McCloskey, Ankur Taly, Federico Monti, Michael P. Brenner, Lucy Colwell",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.11310"" target=""_blank"">1811.11310</a>",,2025-12-03 22:39:25
Universal Adversarial Training,"Ali Shafahi, Mahyar Najibi, Zheng Xu, John Dickerson, Larry S. Davis, Tom Goldstein",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.11304"" target=""_blank"">1811.11304</a>",,2025-12-03 22:39:25
Robust Classification of Financial Risk,"Suproteem K. Sarkar, Kojin Oshiba, Daniel Giebisch, Yaron Singer",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.11079"" target=""_blank"">1811.11079</a>",,2025-12-03 22:39:25
Adversarial Machine Learning And Speech Emotion Recognition: Utilizing Generative Adversarial Networks For Robustness,"Siddique Latif, Rajib Rana, Junaid Qadir",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.11402"" target=""_blank"">1811.11402</a>",,2025-12-03 22:39:25
A randomized gradient-free attack on ReLU networks,"Francesco Croce, Matthias Hein",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.11493"" target=""_blank"">1811.11493</a>",,2025-12-03 22:39:25
Strike (with) a Pose: Neural Networks Are Easily Fooled by Strange Poses of Familiar Objects,"Michael A. Alcorn, Qi Li, Zhitao Gong, Chengfei Wang, Long Mai, Wei-Shinn Ku, Anh Nguyen",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.11553"" target=""_blank"">1811.11553</a>",,2025-12-03 22:39:25
Adversarial Attacks for Optical Flow-Based Action Recognition Classifiers,"Nathan Inkawhich, Matthew Inkawhich, Yiran Chen, Hai Li",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.11875"" target=""_blank"">1811.11875</a>",,2025-12-03 22:39:25
Analyzing Federated Learning through an Adversarial Lens,"Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, Seraphin Calo",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.12470"" target=""_blank"">1811.12470</a>",,2025-12-03 22:39:25
DeepConsensus: using the consensus of features from multiple layers to attain robust image classification,"Yuchen Li, Safwan Hossain, Kiarash Jamali, Frank Rudzicz",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.07266"" target=""_blank"">1811.07266</a>",,2025-12-03 22:39:25
Bayesian Adversarial Spheres: Bayesian Inference and Adversarial Examples in a Noiseless Setting,"Artur Bekasov, Iain Murray",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.12335"" target=""_blank"">1811.12335</a>",,2025-12-03 22:39:25
CNN-Cert: An Efficient Framework for Certifying Robustness of Convolutional Neural Networks,"Akhilan Boopathy, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, Luca Daniel",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.12395"" target=""_blank"">1811.12395</a>",,2025-12-03 22:39:25
ComDefend: An Efficient Image Compression Model to Defend Adversarial Examples,"Xiaojun Jia, Xingxing Wei, Xiaochun Cao, Hassan Foroosh",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.12673"" target=""_blank"">1811.12673</a>",,2025-12-03 22:39:25
Transferable Adversarial Attacks for Image and Video Object Detection,"Xingxing Wei, Siyuan Liang, Xiaochun Cao, Jun Zhu",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.12641"" target=""_blank"">1811.12641</a>",,2025-12-03 22:39:25
Bilateral Adversarial Training: Towards Fast Training of More Robust Models Against Adversarial Attacks,"Jianyu Wang, Haichao Zhang",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.10716"" target=""_blank"">1811.10716</a>",,2025-12-03 22:39:25
Adversarial Examples as an Input-Fault Tolerance Problem,"Angus Galloway, Anna Golubeva, Graham W. Taylor",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.12601"" target=""_blank"">1811.12601</a>",,2025-12-03 22:39:25
"Attention, Please! Adversarial Defense via Activation Rectification and Preservation","Shangxi Wu, Jitao Sang, Kaiyuan Xu, Jiaming Zhang, Yanfeng Sun, Liping Jing, Jian Yu",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.09831"" target=""_blank"">1811.09831</a>",,2025-12-03 22:39:25
MimicGAN: Corruption-Mimicking for Blind Image Recovery & Adversarial Defense,"Rushil Anirudh, Jayaraman J. Thiagarajan, Bhavya Kailkhura, Timo Bremer",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.08484"" target=""_blank"">1811.08484</a>",,2025-12-03 22:39:25
"Robustness via curvature regularization, and vice versa","Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Jonathan Uesato, Pascal Frossard",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.09716"" target=""_blank"">1811.09716</a>",,2025-12-03 22:39:25
The Taboo Trap: Behavioural Detection of Adversarial Samples,"Ilia Shumailov, Yiren Zhao, Robert Mullins, Ross Anderson",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.07375"" target=""_blank"">1811.07375</a>",,2025-12-03 22:39:25
Generalizable Adversarial Training via Spectral Normalization,"Farzan Farnia, Jesse M. Zhang, David Tse",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.07457"" target=""_blank"">1811.07457</a>","<a href=""https://github.com/jessemzhang/dl_spectral_normalization"" target=""_blank"">jessemzhang</a>",2025-12-03 22:39:25
Optimal Transport Classifier: Defending Against Adversarial Attacks by Regularized Deep Embedding,"Yao Li, Martin Renqiang Min, Wenchao Yu, Cho-Jui Hsieh, Thomas C. M. Lee, Erik Kruus",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.07950"" target=""_blank"">1811.07950</a>",,2025-12-03 22:39:25
Lightweight Lipschitz Margin Training for Certified Defense against Adversarial Examples,"Hajime Ono, Tsubasa Takahashi, Kazuya Kakizaki",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.08080"" target=""_blank"">1811.08080</a>",,2025-12-03 22:39:25
Intermediate Level Adversarial Attack for Enhanced Transferability,"Qian Huang, Zeqi Gu, Isay Katsman, Horace He, Pian Pawakapan, Zhiqiu Lin, Serge Belongie, Ser-Nam Lim",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.08458"" target=""_blank"">1811.08458</a>",,2025-12-03 22:39:25
Regularized adversarial examples for model interpretability,"Yoel Shoshan, Vadim Ratner",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.07311"" target=""_blank"">1811.07311</a>",,2025-12-03 22:39:25
How the Softmax Output is Misleading for Evaluating the Strength of Adversarial Examples,"Utku Ozbulak, Neve Wesley De, Messem Arnout Van",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.08577"" target=""_blank"">1811.08577</a>",,2025-12-03 22:39:25
Decoupling Direction and Norm for Efficient Gradient-Based L2 Adversarial Attacks and Defenses,"Jérôme Rony, Luiz G. Hafemann, Luiz S. Oliveira, Ismail Ben Ayed, Robert Sabourin, Eric Granger",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.09600"" target=""_blank"">1811.09600</a>",,2025-12-03 22:39:25
Task-generalizable Adversarial Attack based on Perceptual Metric,"Muzammal Naseer, Salman H. Khan, Shafin Rahman, Fatih Porikli",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.09020"" target=""_blank"">1811.09020</a>",,2025-12-03 22:39:25
Detecting Adversarial Perturbations Through Spatial Behavior in Activation Spaces,"Ziv Katzir, Yuval Elovici",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.09043"" target=""_blank"">1811.09043</a>",,2025-12-03 22:39:25
Strength in Numbers: Trading-off Robustness and Computation via Adversarially-Trained Ensembles,"Edward Grefenstette, Robert Stanforth, Brendan O'Donoghue, Jonathan Uesato, Grzegorz Swirszcz, Pushmeet Kohli",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.09300"" target=""_blank"">1811.09300</a>",,2025-12-03 22:39:25
Parametric Noise Injection: Trainable Randomness to Improve Deep Neural Network Robustness against Adversarial Attack,"Adnan Siraj Rakin, Zhezhi He, Deliang Fan",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.09310"" target=""_blank"">1811.09310</a>",,2025-12-03 22:39:25
Towards Robust Neural Networks with Lipschitz Continuity,"Muhammad Usama, Dong Eui Chang",arXiv,2018-11,"<a href=""http://arxiv.org/abs/1811.09008"" target=""_blank"">1811.09008</a>",,2025-12-03 22:39:25
Improved Generalization Bounds for Robust Learning,"Idan Attias, Aryeh Kontorovich, Yishay Mansour",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.02180"" target=""_blank"">1810.02180</a>",,2025-12-03 22:39:25
Feature Prioritization and Regularization Improve Standard Accuracy and Adversarial Robustness,"Chihuang Liu, Joseph JaJa",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.02424"" target=""_blank"">1810.02424</a>",,2025-12-03 22:39:25
Average Margin Regularization for Classifiers,"Matt Olfat, Anil Aswani",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.03773"" target=""_blank"">1810.03773</a>",,2025-12-03 22:39:25
Combinatorial Attacks on Binarized Neural Networks,"Elias B. Khalil, Amrita Gupta, Bistra Dilkina",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.03538"" target=""_blank"">1810.03538</a>",,2025-12-03 22:39:25
Efficient Two-Step Adversarial Defense for Deep Neural Networks,"Ting-Jui Chang, Yukun He, Peng Li",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.03739"" target=""_blank"">1810.03739</a>",,2025-12-03 22:39:25
Analyzing the Noise Robustness of Deep Neural Networks,"Mengchen Liu, Shixia Liu, Hang Su, Kelei Cao, Jun Zhu",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.03913"" target=""_blank"">1810.03913</a>",,2025-12-03 22:39:25
Limitations of adversarial robustness: strong No Free Lunch Theorem,Elvis Dohmatob,arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.04065"" target=""_blank"">1810.04065</a>",,2025-12-03 22:39:25
The Adversarial Attack and Detection under the Fisher Information Metric,"Chenxiao Zhao, P. Thomas Fletcher, Mixue Yu, Yaxin Peng, Guixu Zhang, Chaomin Shen",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.03806"" target=""_blank"">1810.03806</a>",,2025-12-03 22:39:25
Is PGD-Adversarial Training Necessary? Alternative Training via a Soft-Quantization Network with Noisy-Natural Samples Only,"Tianhang Zheng, Changyou Chen, Kui Ren",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.05665"" target=""_blank"">1810.05665</a>","<a href=""https://github.com/tianzheng4/Noisy-Training-Soft-Quantization"" target=""_blank"">tianzheng4</a>",2025-12-03 22:39:25
MeshAdv: Adversarial Meshes for Visual Recognition,"Chaowei Xiao, Dawei Yang, Bo Li, Jia Deng, Mingyan Liu",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.05206"" target=""_blank"">1810.05206</a>",,2025-12-03 22:39:25
Adversarial Examples - A Complete Characterisation of the Phenomenon,"Alexandru Constantin Serban, Erik Poll, Joost Visser",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.01185"" target=""_blank"">1810.01185</a>",,2025-12-03 22:39:25
Can Adversarially Robust Learning Leverage Computational Hardness?,"Saeed Mahloujifar, Mohammad Mahmoody",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.01407"" target=""_blank"">1810.01407</a>",,2025-12-03 22:39:25
Interpreting Adversarial Robustness: A View from Decision Surface in Input Space,"Fuxun Yu, Chenchen Liu, Yanzhi Wang, Liang Zhao, Xiang Chen",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.00144"" target=""_blank"">1810.00144</a>",,2025-12-03 22:39:25
Link Prediction Adversarial Attack,"Jinyin Chen, Ziqiang Shi, Yangyang Wu, Xuanheng Xu, Haibin Zheng",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.01110"" target=""_blank"">1810.01110</a>",,2025-12-03 22:39:25
Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network,"Xuanqing Liu, Yao Li, Chongruo Wu, Cho-Jui Hsieh",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.01279"" target=""_blank"">1810.01279</a>",,2025-12-03 22:39:25
Improving the Generalization of Adversarial Training with Domain Adaptation,"Chuanbiao Song, Kun He, Liwei Wang, John E. Hopcroft",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.00740"" target=""_blank"">1810.00740</a>",,2025-12-03 22:39:25
Large batch size training of neural networks with adversarial training and second-order information,"Zhewei Yao, Amir Gholami, Daiyaan Arfeen, Richard Liaw, Joseph Gonzalez, Kurt Keutzer, Michael Mahoney",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.01021"" target=""_blank"">1810.01021</a>",,2025-12-03 22:39:25
Improved robustness to adversarial examples using Lipschitz regularization of the loss,"Chris Finlay, Adam Oberman, Bilal Abbasi",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.00953"" target=""_blank"">1810.00953</a>",,2025-12-03 22:39:25
Procedural Noise Adversarial Examples for Black-Box Attacks on Deep Convolutional Networks,"Kenneth T. Co, Luis Muñoz-González, Maupeou Sixte de, Emil C. Lupu",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.00470"" target=""_blank"">1810.00470</a>",,2025-12-03 22:39:25
CAAD 2018: Generating Transferable Adversarial Examples,"Yash Sharma, Tien-Dung Le, Moustafa Alzantot",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.01268"" target=""_blank"">1810.01268</a>",,2025-12-03 22:39:25
To compress or not to compress: Understanding the Interactions between Adversarial Attacks and Neural Network Compression,"Yiren Zhao, Ilia Shumailov, Robert Mullins, Ross Anderson",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.00208"" target=""_blank"">1810.00208</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defences: A Survey,"Anirban Chakraborty, Manaar Alam, Vishal Dey, Anupam Chattopadhyay, Debdeep Mukhopadhyay",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.00069"" target=""_blank"">1810.00069</a>",,2025-12-03 22:39:25
Explainable Black-Box Attacks Against Model-based Authentication,"Washington Garcia, Joseph I. Choi, Suman K. Adari, Somesh Jha, Kevin R. B. Butler",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.00024"" target=""_blank"">1810.00024</a>",,2025-12-03 22:39:25
Adversarial Attacks on Cognitive Self-Organizing Networks: The Challenge and the Way Forward,"Muhammad Usama, Junaid Qadir, Ala Al-Fuqaha",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.07242"" target=""_blank"">1810.07242</a>",,2025-12-03 22:39:25
Concise Explanations of Neural Networks using Adversarial Training,"Prasad Chalasani, Jiefeng Chen, Amrita Roy Chowdhury, Somesh Jha, Xi Wu",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.06583"" target=""_blank"">1810.06583</a>",,2025-12-03 22:39:25
Characterizing Adversarial Examples Based on Spatial Consistency Information for Semantic Segmentation,"Chaowei Xiao, Ruizhi Deng, Bo Li, Fisher Yu, Mingyan Liu, Dawn Song",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.05162"" target=""_blank"">1810.05162</a>",,2025-12-03 22:39:25
RecurJac: An Efficient Recursive Algorithm for Bounding Jacobian Matrix of Neural Networks and Its Applications,"Huan Zhang, Pengchuan Zhang, Cho-Jui Hsieh",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.11783"" target=""_blank"">1810.11783</a>","<a href=""http://github.com/huanzhang12/RecurJac-Jacobian-bounds"" target=""_blank"">huanzhang12</a>",2025-12-03 22:39:25
Security Matters: A Survey on Adversarial Machine Learning,"Guofu Li, Pengjia Zhu, Jin Li, Zhemin Yang, Ning Cao, Zhiyi Chen",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.07339"" target=""_blank"">1810.07339</a>",,2025-12-03 22:39:25
Evading classifiers in discrete domains with provable optimality guarantees,"Bogdan Kulynych, Jamie Hayes, Nikita Samarin, Carmela Troncoso",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.10939"" target=""_blank"">1810.10939</a>",,2025-12-03 22:39:25
On the Effectiveness of Interval Bound Propagation for Training Verifiably Robust Models,"Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan Uesato, Relja Arandjelovic, Timothy Mann, Pushmeet Kohli",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.12715"" target=""_blank"">1810.12715</a>",,2025-12-03 22:39:25
Adversarial Risk and Robustness: General Definitions and Implications for the Uniform Distribution,"Dimitrios I. Diochnos, Saeed Mahloujifar, Mohammad Mahmoody",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.12272"" target=""_blank"">1810.12272</a>",,2025-12-03 22:39:25
Projecting Trouble: Light Based Adversarial Attacks on Deep Learning Classifiers,"Nicole Nichols, Robert Jasper",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.10337"" target=""_blank"">1810.10337</a>",,2025-12-03 22:39:25
Improved Network Robustness with Adversary Critic,"Alexander Matyasko, Lap-Pui Chau",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.12576"" target=""_blank"">1810.12576</a>","<a href=""https://github.com/aam-at/adversary_critic"" target=""_blank"">aam-at</a>",2025-12-03 22:39:25
Rademacher Complexity for Adversarially Robust Generalization,"Dong Yin, Kannan Ramchandran, Peter Bartlett",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.11914"" target=""_blank"">1810.11914</a>",,2025-12-03 22:39:25
Robust Audio Adversarial Example for a Physical Attack,"Hiromu Yakura, Jun Sakuma",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.11793"" target=""_blank"">1810.11793</a>",,2025-12-03 22:39:25
Towards Robust Deep Neural Networks,"Timothy E. Wang, Yiming Gu, Dhagash Mehta, Xiaojun Zhao, Edgar A. Bernal",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.11726"" target=""_blank"">1810.11726</a>",,2025-12-03 22:39:25
Regularization Effect of Fast Gradient Sign Method and its Generalization,Chandler Zuo,arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.11711"" target=""_blank"">1810.11711</a>",,2025-12-03 22:39:25
Attacks Meet Interpretability: Attribute-steered Detection of Adversarial Samples,"Guanhong Tao, Shiqing Ma, Yingqi Liu, Xiangyu Zhang",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.11580"" target=""_blank"">1810.11580</a>",,2025-12-03 22:39:25
Law and Adversarial Machine Learning,"Ram Shankar Siva Kumar, David R. O'Brien, Kendra Albert, Salome Vilojen",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.10731"" target=""_blank"">1810.10731</a>",,2025-12-03 22:39:25
Attack Graph Convolutional Networks by Adding Fake Nodes,"Xiaoyun Wang, Minhao Cheng, Joe Eaton, Cho-Jui Hsieh, Felix Wu",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.10751"" target=""_blank"">1810.10751</a>",,2025-12-03 22:39:25
Logit Pairing Methods Can Fool Gradient-Based Attacks,"Marius Mosbach, Maksym Andriushchenko, Thomas Trost, Matthias Hein, Dietrich Klakow",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.12042"" target=""_blank"">1810.12042</a>",,2025-12-03 22:39:25
Robust Adversarial Learning via Sparsifying Front Ends,"Soorya Gopalakrishnan, Zhinus Marzi, Metehan Cekic, Upamanyu Madhow, Ramtin Pedarsani",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.10625"" target=""_blank"">1810.10625</a>",,2025-12-03 22:39:25
Sparse DNNs with Improved Adversarial Robustness,"Yiwen Guo, Chao Zhang, Changshui Zhang, Yurong Chen",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.09619"" target=""_blank"">1810.09619</a>",,2025-12-03 22:39:25
Stochastic Substitute Training: A Gray-box Approach to Craft Adversarial Examples Against Gradient Obfuscation Defenses,"Mohammad Hashemi, Greg Cusack, Eric Keller",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.10031"" target=""_blank"">1810.10031</a>",,2025-12-03 22:39:25
Provable Robustness of ReLU networks via Maximization of Linear Regions,"Francesco University of Tübingen Croce, Maksym Saarland University Andriushchenko, Matthias University of Tübingen Hein",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.07481"" target=""_blank"">1810.07481</a>",,2025-12-03 22:39:25
Exploring Adversarial Examples in Malware Detection,"Octavian Suciu, Scott E. Coull, Jeffrey Johns",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.08280"" target=""_blank"">1810.08280</a>",,2025-12-03 22:39:25
On Extensions of CLEVER: A Neural Network Robustness Evaluation Algorithm,"Tsui-Wei Weng, Huan Zhang, Pin-Yu Chen, Aurelie Lozano, Cho-Jui Hsieh, Luca Daniel",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.08640"" target=""_blank"">1810.08640</a>",,2025-12-03 22:39:25
A Training-based Identification Approach to VIN Adversarial Examples,"Yingdi Wang, Wenjia Niu, Tong Chen, Yingxiao Xiang, Jingjing Liu, Gang Li, Jiqiang Liu",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.08070"" target=""_blank"">1810.08070</a>",,2025-12-03 22:39:25
Cost-Sensitive Robustness against Adversarial Examples,"Xiao Zhang, David Evans",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.09225"" target=""_blank"">1810.09225</a>",,2025-12-03 22:39:25
Adversarial Risk Bounds via Function Transformation,"Justin Khim, Po-Ling Loh",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.09519"" target=""_blank"">1810.09519</a>",,2025-12-03 22:39:25
Et Tu Alexa? When Commodity WiFi Devices Turn into Adversarial Motion Sensors,"Yanzi Zhu, Zhujun Xiao, Yuxin Chen, Zhijing Li, Max Liu, Ben Y. Zhao, Haitao Zheng",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.10109"" target=""_blank"">1810.10109</a>",,2025-12-03 22:39:25
One Bit Matters: Understanding Adversarial Examples as the Abuse of Redundancy,"Jingkang Wang, Ruoxi Jia, Gerald Friedland, Bo Li, Costas Spanos",arXiv,2018-10,"<a href=""http://arxiv.org/abs/1810.09650"" target=""_blank"">1810.09650</a>",,2025-12-03 22:39:25
Training for Faster Adversarial Robustness Verification via Inducing ReLU Stability,"Kai Y. Xiao, Vincent Tjeng, Nur Muhammad Shafiullah, Aleksander Madry",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.03008"" target=""_blank"">1809.03008</a>",,2025-12-03 22:39:25
Query Attack via Opposite-Direction Feature:Towards Robust Image Retrieval,"Zhedong Zheng, Liang Zheng, Yi Yang, Fei Wu",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.02681"" target=""_blank"">1809.02681</a>",,2025-12-03 22:39:25
Certified Adversarial Robustness with Additive Noise,"Bai Li, Changyou Chen, Wenlin Wang, Lawrence Carin",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.03113"" target=""_blank"">1809.03113</a>",,2025-12-03 22:39:25
Towards Query Efficient Black-box Attacks: An Input-free Perspective,"Yali Du, Meng Fang, Jinfeng Yi, Jun Cheng, Dacheng Tao",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.02918"" target=""_blank"">1809.02918</a>",,2025-12-03 22:39:25
Fast Gradient Attack on Network Embedding,"Jinyin Chen, Yangyang Wu, Xuanheng Xu, Yixian Chen, Haibin Zheng, Qi Xuan",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.02797"" target=""_blank"">1809.02797</a>",,2025-12-03 22:39:25
Structure-Preserving Transformation: Generating Diverse and Transferable Adversarial Examples,"Dan Peng, Zizhan Zheng, Xiaofeng Zhang",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.02786"" target=""_blank"">1809.02786</a>",,2025-12-03 22:39:25
Why Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks,"Ambra Demontis, Marco Melis, Maura Pintor, Matthew Jagielski, Battista Biggio, Alina Oprea, Cristina Nita-Rotaru, Fabio Roli",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.02861"" target=""_blank"">1809.02861</a>",,2025-12-03 22:39:25
A Deeper Look at 3D Shape Classifiers,"Jong-Chyi Su, Matheus Gadelha, Rui Wang, Subhransu Maji",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.02560"" target=""_blank"">1809.02560</a>",,2025-12-03 22:39:25
Metamorphic Relation Based Adversarial Attacks on Differentiable Neural Computer,"Alvin Chan, Lei Ma, Felix Juefei-Xu, Xiaofei Xie, Yang Liu, Yew Soon Ong",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.02444"" target=""_blank"">1809.02444</a>",,2025-12-03 22:39:25
Trick Me If You Can: Human-in-the-loop Generation of Adversarial Examples for Question Answering,"Eric Wallace, Pedro Rodriguez, Shi Feng, Ikuya Yamada, Jordan Boyd-Graber",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.02701"" target=""_blank"">1809.02701</a>",,2025-12-03 22:39:25
Adversarial Attacks on Node Embeddings,"Aleksandar Bojchevski, Stephan Günnemann",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.01093"" target=""_blank"">1809.01093</a>",,2025-12-03 22:39:25
Adversarial Over-Sensitivity and Over-Stability Strategies for Dialogue Models,"Tong Niu, Mohit Bansal",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.02079"" target=""_blank"">1809.02079</a>",,2025-12-03 22:39:25
Are adversarial examples inevitable?,"Ali Shafahi, W. Ronny Huang, Christoph Studer, Soheil Feizi, Tom Goldstein",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.02104"" target=""_blank"">1809.02104</a>",,2025-12-03 22:39:25
IDSGAN: Generative Adversarial Networks for Attack Generation against Intrusion Detection,"Zilong Lin, Yong Shi, Zhi Xue",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.02077"" target=""_blank"">1809.02077</a>",,2025-12-03 22:39:25
Adversarial Reprogramming of Text Classification Neural Networks,"Paarth Neekhara, Shehzeen Hussain, Shlomo Dubnov, Farinaz Koushanfar",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.01829"" target=""_blank"">1809.01829</a>",,2025-12-03 22:39:25
Bridging machine learning and cryptography in defence against adversarial attacks,"Olga Taran, Shideh Rezaeifar, Slava Voloshynovskiy",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.01715"" target=""_blank"">1809.01715</a>",,2025-12-03 22:39:25
HASP: A High-Performance Adaptive Mobile Security Enhancement Against Malicious Speech Recognition,"Zirui Xu, Fuxun Yu, Chenchen Liu, Xiang Chen",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.01697"" target=""_blank"">1809.01697</a>",,2025-12-03 22:39:25
Adversarial Attack Type I: Cheat Classifiers by Significant Changes,"Sanli Tang, Xiaolin Huang, Mingjian Chen, Chengjin Sun, Jie Yang",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.00594"" target=""_blank"">1809.00594</a>",,2025-12-03 22:39:25
MULDEF: Multi-model-based Defense Against Adversarial Examples for Neural Networks,"Siwakorn Srisakaokul, Yuhao Zhang, Zexuan Zhong, Wei Yang, Tao Xie, Bo Li",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.00065"" target=""_blank"">1809.00065</a>",,2025-12-03 22:39:25
Targeted Nonlinear Adversarial Perturbations in Images and Videos,"Roberto Rey-de-Castro, Herschel Rabitz",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.00958"" target=""_blank"">1809.00958</a>",,2025-12-03 22:39:25
Does it care what you asked? Understanding Importance of Verbs in Deep Learning QA System,"Barbara Rychalska, Dominika Basaj, Przemyslaw Biecek, Anna Wroblewska",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.03740"" target=""_blank"">1809.03740</a>",,2025-12-03 22:39:25
The Curse of Concentration in Robust Learning: Evasion and Poisoning Attacks from Concentration of Measure,"Saeed Mahloujifar, Dimitrios I. Diochnos, Mohammad Mahmoody",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.03063"" target=""_blank"">1809.03063</a>",,2025-12-03 22:39:25
Defensive Dropout for Hardening Deep Neural Networks under Adversarial Attacks,"Siyue Wang, Xiao Wang, Pu Zhao, Wujie Wen, David Kaeli, Peter Chin, Xue Lin",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.05165"" target=""_blank"">1809.05165</a>",,2025-12-03 22:39:25
Humans can decipher adversarial images,"Zhenglong Zhou, Chaz Firestone",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.04120"" target=""_blank"">1809.04120</a>",,2025-12-03 22:39:25
Efficient Formal Safety Analysis of Neural Networks,"Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, Suman Jana",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.08098"" target=""_blank"">1809.08098</a>",,2025-12-03 22:39:25
Characterizing Audio Adversarial Examples Using Temporal Dependency,"Zhuolin Yang, Bo Li, Pin-Yu Chen, Dawn Song",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.10875"" target=""_blank"">1809.10875</a>",,2025-12-03 22:39:25
Neural Networks with Structural Resistance to Adversarial Attacks,Alfaro Luca de,arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.09262"" target=""_blank"">1809.09262</a>",,2025-12-03 22:39:25
Fast Geometrically-Perturbed Adversarial Faces,"Ali Dabouei, Sobhan Soleymani, Jeremy Dawson, Nasser M. Nasrabadi",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.08999"" target=""_blank"">1809.08999</a>","<a href=""https://github.com/alldbi/FLM"" target=""_blank"">alldbi</a>",2025-12-03 22:39:25
On The Utility of Conditional Generation Based Mutual Information for Characterizing Adversarial Subspaces,"Chia-Yi Hsu, Pei-Hsuan Lu, Pin-Yu Chen, Chia-Mu Yu",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.08986"" target=""_blank"">1809.08986</a>",,2025-12-03 22:39:25
Isolated and Ensemble Audio Preprocessing Methods for Detecting Adversarial Examples against Automatic Speech Recognition,"Krishan Rajaratnam, Kunal Shah, Jugal Kalita",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.04397"" target=""_blank"">1809.04397</a>",,2025-12-03 22:39:25
Is Ordered Weighted $\ell_1$ Regularized Regression Robust to Adversarial Perturbation? A Case Study on OSCAR,"Pin-Yu Chen, Bhanukiran Vinzamuri, Sijia Liu",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.08706"" target=""_blank"">1809.08706</a>",,2025-12-03 22:39:25
Adversarial Defense via Data Dependent Activation Function and Total Variation Minimization,"Bao Wang, Alex T. Lin, Wei Zhu, Penghang Yin, Andrea L. Bertozzi, Stanley J. Osher",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.08516"" target=""_blank"">1809.08516</a>",,2025-12-03 22:39:25
Unrestricted Adversarial Examples,"Tom B. Brown, Nicholas Carlini, Chiyuan Zhang, Catherine Olsson, Paul Christiano, Ian Goodfellow",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.08352"" target=""_blank"">1809.08352</a>",,2025-12-03 22:39:25
Adversarial Binaries for Authorship Identification,"Xiaozhu Meng, Barton P. Miller, Somesh Jha",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.08316"" target=""_blank"">1809.08316</a>",,2025-12-03 22:39:25
Playing the Game of Universal Adversarial Perturbations,"Julien Perolat, Mateusz Malinowski, Bilal Piot, Olivier Pietquin",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.07802"" target=""_blank"">1809.07802</a>",,2025-12-03 22:39:25
Low Frequency Adversarial Perturbation,"Chuan Guo, Jared S. Frank, Kilian Q. Weinberger",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.08758"" target=""_blank"">1809.08758</a>",,2025-12-03 22:39:25
Adversarial Training Towards Robust Multimedia Recommender System,"Jinhui Tang, Xiaoyu Du, Xiangnan He, Fajie Yuan, Qi Tian, Tat-Seng Chua",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.07062"" target=""_blank"">1809.07062</a>","<a href=""https://github.com/duxy-me/AMR"" target=""_blank"">duxy-me</a>",2025-12-03 22:39:25
Robust Adversarial Perturbation on Deep Proposal-based Models,"Yuezun Li, Daniel Tian, Ming-Ching Chang, Xiao Bian, Siwei Lyu",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.05962"" target=""_blank"">1809.05962</a>",,2025-12-03 22:39:25
On the Structural Sensitivity of Deep Convolutional Networks to the Directions of Fourier Basis Functions,"Yusuke Tsuzuku, Issei Sato",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.04098"" target=""_blank"">1809.04098</a>",,2025-12-03 22:39:25
Generating 3D Adversarial Point Clouds,"Chong Xiang, Charles R. Qi, Bo Li",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.07016"" target=""_blank"">1809.07016</a>",,2025-12-03 22:39:25
Query-Efficient Black-Box Attack by Active Learning,"Pengcheng Li, Jinfeng Yi, Lijun Zhang",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.04913"" target=""_blank"">1809.04913</a>",,2025-12-03 22:39:25
Adversarial Examples: Opportunities and Challenges,"Jiliang Zhang, Chen Li",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.04790"" target=""_blank"">1809.04790</a>",,2025-12-03 22:39:25
Robustness Guarantees for Bayesian Inference with Gaussian Processes,"Luca Cardelli, Marta Kwiatkowska, Luca Laurenti, Andrea Patane",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.06452"" target=""_blank"">1809.06452</a>",,2025-12-03 22:39:25
HashTran-DNN: A Framework for Enhancing Robustness of Deep Neural Networks against Adversarial Malware Samples,"Deqiang Li, Ramesh Baral, Tao Li, Han Wang, Qianmu Li, Shouhuai Xu",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.06498"" target=""_blank"">1809.06498</a>",,2025-12-03 22:39:25
Exploring the Vulnerability of Single Shot Module in Object Detectors via Imperceptible Background Patches,"Yuezun Li, Xiao Bian, Ming-ching Chang, Siwei Lyu",arXiv,2018-09,"<a href=""http://arxiv.org/abs/1809.05966"" target=""_blank"">1809.05966</a>",,2025-12-03 22:39:25
Distributionally Adversarial Attack,"Tianhang Zheng, Changyou Chen, Kui Ren",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.05537"" target=""_blank"">1808.05537</a>","<a href=""https://github.com/tianzheng4/Distributionally-Adversarial-Attack"" target=""_blank"">tianzheng4</a>",2025-12-03 22:39:25
Gray-box Adversarial Training,"Vivek B. S., Konda Reddy Mopuri, R. Venkatesh Babu",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.01753"" target=""_blank"">1808.01753</a>",,2025-12-03 22:39:25
Android HIV: A Study of Repackaging Malware for Evading Machine-Learning Detection,"Xiao Chen, Chaoran Li, Derui Wang, Sheng Wen, Jun Zhang, Surya Nepal, Yang Xiang, Kui Ren",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.04218"" target=""_blank"">1808.04218</a>",,2025-12-03 22:39:25
Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer,"Hsueh-Ti Derek Liu, Michael Tao, Chun-Liang Li, Derek Nowrouzezahrai, Alec Jacobson",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.02651"" target=""_blank"">1808.02651</a>",,2025-12-03 22:39:25
Data augmentation using synthetic data for time series classification with deep residual networks,"Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, Pierre-Alain Muller",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.02455"" target=""_blank"">1808.02455</a>",,2025-12-03 22:39:25
Adversarial Vision Challenge,"Wieland Brendel, Jonas Rauber, Alexey Kurakin, Nicolas Papernot, Behar Veliqi, Marcel Salathé, Sharada P. Mohanty, Matthias Bethge",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.01976"" target=""_blank"">1808.01976</a>",,2025-12-03 22:39:25
Structured Adversarial Attack: Towards General Implementation and Better Interpretability,"Kaidi Xu, Sijia Liu, Pu Zhao, Pin-Yu Chen, Huan Zhang, Quanfu Fan, Deniz Erdogmus, Yanzhi Wang, Xue Lin",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.01664"" target=""_blank"">1808.01664</a>",,2025-12-03 22:39:25
Is Robustness the Cost of Accuracy? -- A Comprehensive Study on the Robustness of 18 Deep Image Classification Models,"Dong Su, Huan Zhang, Hongge Chen, Jinfeng Yi, Pin-Yu Chen, Yupeng Gao",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.01688"" target=""_blank"">1808.01688</a>","<a href=""https://github.com/huanzhang12/Adversarial_Survey"" target=""_blank"">huanzhang12</a>",2025-12-03 22:39:25
Traits & Transferability of Adversarial Examples against Instance Segmentation & Object Detection,"Raghav Gurbaxani, Shivank Mishra",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.01452"" target=""_blank"">1808.01452</a>",,2025-12-03 22:39:25
ATMPA: Attacking Machine Learning-based Malware Visualization Detection Methods via Adversarial Examples,"Xinbo Liu, Jiliang Zhang, Yaping Lin, He Li",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.01546"" target=""_blank"">1808.01546</a>",,2025-12-03 22:39:25
"Ask, Acquire, and Attack: Data-free UAP Generation using Class Impressions","Konda Reddy Mopuri, Phani Krishna Uppala, R. Venkatesh Babu",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.01153"" target=""_blank"">1808.01153</a>",,2025-12-03 22:39:25
DeepCloak: Adversarial Crafting As a Defensive Measure to Cloak Processes,"Mehmet Sinan Inci, Thomas Eisenbarth, Berk Sunar",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.01352"" target=""_blank"">1808.01352</a>",,2025-12-03 22:39:25
EagleEye: Attack-Agnostic Defense against Adversarial Inputs (Technical Report),"Yujie Ji, Xinyang Zhang, Ting Wang",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.00123"" target=""_blank"">1808.00123</a>",,2025-12-03 22:39:25
Using Randomness to Improve Robustness of Machine-Learning Models Against Evasion Attacks,"Fan Yang, Zhiyuan Chen",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.03601"" target=""_blank"">1808.03601</a>",,2025-12-03 22:39:25
Defense Against Adversarial Attacks with Saak Transform,"Sibo Song, Yueru Chen, Ngai-Man Cheung, C. -C. Jay Kuo",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.01785"" target=""_blank"">1808.01785</a>",,2025-12-03 22:39:25
Adversarial Attacks Against Automatic Speech Recognition Systems via Psychoacoustic Hiding,"Lea Schönherr, Katharina Kohls, Steffen Zeiler, Thorsten Holz, Dorothea Kolossa",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.05665"" target=""_blank"">1808.05665</a>",,2025-12-03 22:39:25
Guiding Deep Learning System Testing using Surprise Adequacy,"Jinhan Kim, Robert Feldt, Shin Yoo",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.08444"" target=""_blank"">1808.08444</a>",,2025-12-03 22:39:25
Mitigation of Adversarial Attacks through Embedded Feature Selection,"Ziyi Bao, Luis Muñoz-González, Emil C. Lupu",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.05705"" target=""_blank"">1808.05705</a>",,2025-12-03 22:39:25
"All You Need is ""Love"": Evading Hate-speech Detection","Tommi Gröndahl, Luca Pajola, Mika Juuti, Mauro Conti, N. Asokan",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.09115"" target=""_blank"">1808.09115</a>",,2025-12-03 22:39:25
Lipschitz regularized Deep Neural Networks generalize and are adversarially robust,"Chris Finlay, Jeff Calder, Bilal Abbasi, Adam Oberman",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.09540"" target=""_blank"">1808.09540</a>",,2025-12-03 22:39:25
Generalisation in humans and deep neural networks,"Robert Geirhos, Carlos R. Medina Temme, Jonas Rauber, Heiko H. Schütt, Matthias Bethge, Felix A. Wichmann",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.08750"" target=""_blank"">1808.08750</a>",,2025-12-03 22:39:25
Adversarially Regularising Neural NLI Models to Integrate Logical Background Knowledge,"Pasquale Minervini, Sebastian Riedel",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.08609"" target=""_blank"">1808.08609</a>",,2025-12-03 22:39:25
Analysis of adversarial attacks against CNN-based image forgery detectors,"Diego Gragnaniello, Francesco Marra, Giovanni Poggi, Luisa Verdoliva",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.08426"" target=""_blank"">1808.08426</a>",,2025-12-03 22:39:25
DLFuzz: Differential Fuzzing Testing of Deep Learning Systems,"Jianmin Guo, Yu Jiang, Yue Zhao, Quan Chen, Jiaguang Sun",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.09413"" target=""_blank"">1808.09413</a>",,2025-12-03 22:39:25
Is Machine Learning in Power Systems Vulnerable?,"Yize Chen, Yushi Tan, Deepjyoti Deka",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.08197"" target=""_blank"">1808.08197</a>",,2025-12-03 22:39:25
Adversarial Attacks on Deep-Learning Based Radio Signal Classification,"Meysam Sadeghi, Erik G. Larsson",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.07713"" target=""_blank"">1808.07713</a>",,2025-12-03 22:39:25
Controlling Over-generalization and its Effect on Adversarial Examples Generation and Detection,"Mahdieh Abbasi, Arezoo Rajabi, Azadeh Sadat Mozafari, Rakesh B. Bobba, Christian Gagne",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.08282"" target=""_blank"">1808.08282</a>",,2025-12-03 22:39:25
Stochastic Combinatorial Ensembles for Defending Against Adversarial Examples,"George A. Adam, Petr Smirnov, David Duvenaud, Benjamin Haibe-Kains, Anna Goldenberg",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.06645"" target=""_blank"">1808.06645</a>",,2025-12-03 22:39:25
Reinforcement Learning for Autonomous Defence in Software-Defined Networking,"Yi Han, Benjamin I. P. Rubinstein, Tamas Abraham, Tansu Alpcan, Vel Olivier De, Sarah Erfani, David Hubczenko, Christopher Leckie, Paul Montague",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.05770"" target=""_blank"">1808.05770</a>",,2025-12-03 22:39:25
Maximal Jacobian-based Saliency Map Attack,"Rey Wiyatno, Anqi Xu",arXiv,2018-08,"<a href=""http://arxiv.org/abs/1808.07945"" target=""_blank"">1808.07945</a>",,2025-12-03 22:39:25
Implicit Generative Modeling of Random Noise during Training for Adversarial Robustness,"Priyadarshini Panda, Kaushik Roy",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.02188"" target=""_blank"">1807.02188</a>",,2025-12-03 22:39:25
A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks,"Kimin Lee, Kibok Lee, Honglak Lee, Jinwoo Shin",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.03888"" target=""_blank"">1807.03888</a>",,2025-12-03 22:39:25
A Game-Based Approximate Verification of Deep Neural Networks with Provable Guarantees,"Min Wu, Matthew Wicker, Wenjie Ruan, Xiaowei Huang, Marta Kwiatkowska",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.03571"" target=""_blank"">1807.03571</a>",,2025-12-03 22:39:25
Attack and defence in cellular decision-making: lessons from machine learning,"Thomas J. Rademaker, Emmanuel Bengio, Paul François",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.04270"" target=""_blank"">1807.04270</a>",,2025-12-03 22:39:25
Adaptive Adversarial Attack on Scene Text Recognition,"Xiaoyong Yuan, Pan He, Xiaolin Andy Li, Dapeng Oliver Wu",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.03326"" target=""_blank"">1807.03326</a>",,2025-12-03 22:39:25
Vulnerability Analysis of Chest X-Ray Image Classification Against Adversarial Attacks,"Saeid Asgari Taghanaki, Arkadeep Das, Ghassan Hamarneh",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.02905"" target=""_blank"">1807.02905</a>",,2025-12-03 22:39:25
Adversarial Robustness Toolbox v1,"Maria-Irina Nicolae, Mathieu Sinn, Minh Ngoc Tran, Beat Buesser, Ambrish Rawat, Martin Wistuba, Valentina Zantedeschi, Nathalie Baracaldo, Bryant Chen, Heiko Ludwig, Ian M. Molloy, Ben Edwards",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.01069"" target=""_blank"">1807.01069</a>","<a href=""https://github.com/IBM/adversarial-robustness-toolbox"" target=""_blank"">IBM</a>",2025-12-03 22:39:25
Benchmarking Neural Network Robustness to Common Corruptions and Surface Variations,"Dan Hendrycks, Thomas G. Dietterich",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.01697"" target=""_blank"">1807.01697</a>",,2025-12-03 22:39:25
Local Gradients Smoothing: Defense against localized adversarial attacks,"Muzammal Naseer, Salman H. Khan, Fatih Porikli",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.01216"" target=""_blank"">1807.01216</a>",,2025-12-03 22:39:25
Adversarial Perturbations Against Real-Time Video Classification Systems,"Shasha Li, Ajaya Neupane, Sujoy Paul, Chengyu Song, Srikanth V. Krishnamurthy, Amit K. Roy Chowdhury, Ananthram Swami",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.00458"" target=""_blank"">1807.00458</a>",,2025-12-03 22:39:25
Towards Adversarial Training with Moderate Performance Improvement for Neural Network Classification,"Xinhan Di, Pengqian Yu, Meng Tian",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.00340"" target=""_blank"">1807.00340</a>",,2025-12-03 22:39:25
Adversarial Examples in Deep Learning: Characterization and Divergence,"Wenqi Wei, Ling Liu, Margaret Loper, Stacey Truex, Lei Yu, Mehmet Emre Gursoy, Yanzhao Wu",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.00051"" target=""_blank"">1807.00051</a>",,2025-12-03 22:39:25
Query-Efficient Hard-label Black-box Attack:An Optimization-based Approach,"Minhao Cheng, Thong Le, Pin-Yu Chen, Jinfeng Yi, Huan Zhang, Cho-Jui Hsieh",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.04457"" target=""_blank"">1807.04457</a>",,2025-12-03 22:39:25
"With Friends Like These, Who Needs Adversaries?","Saumya Jetley, Nicholas A. Lord, Philip H. S. Torr",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.04200"" target=""_blank"">1807.04200</a>",,2025-12-03 22:39:25
Manifold Adversarial Learning,"Shufei Zhang, Kaizhu Huang, Jianke Zhu, Yang Liu",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.05832"" target=""_blank"">1807.05832</a>",,2025-12-03 22:39:25
Limitations of the Lipschitz constant as a defense against adversarial examples,"Todd Huster, Cho-Yu Jason Chiang, Ritu Chadha",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.09705"" target=""_blank"">1807.09705</a>",,2025-12-03 22:39:25
Simultaneous Adversarial Training - Learn from Others Mistakes,Zukang Liao,arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.08108"" target=""_blank"">1807.08108</a>",,2025-12-03 22:39:25
Online Robust Policy Learning in the Presence of Unknown Adversaries,"Aaron J. Havens, Zhanhong Jiang, Soumik Sarkar",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.06064"" target=""_blank"">1807.06064</a>",,2025-12-03 22:39:25
A general metric for identifying adversarial images,Siddharth Krishna Kumar,arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.10335"" target=""_blank"">1807.10335</a>",,2025-12-03 22:39:25
Evaluating and Understanding the Robustness of Adversarial Logit Pairing,"Logan Engstrom, Andrew Ilyas, Anish Athalye",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.10272"" target=""_blank"">1807.10272</a>",,2025-12-03 22:39:25
HiDDeN: Hiding Data With Deep Networks,"Jiren Zhu, Russell Kaplan, Justin Johnson, Li Fei-Fei",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.09937"" target=""_blank"">1807.09937</a>",,2025-12-03 22:39:25
Unbounded Output Networks for Classification,"Stefan Elfwing, Eiji Uchibe, Kenji Doya",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.09443"" target=""_blank"">1807.09443</a>",,2025-12-03 22:39:25
Contrastive Video Representation Learning via Adversarial Perturbations,"Jue Wang, Anoop Cherian",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.09380"" target=""_blank"">1807.09380</a>",,2025-12-03 22:39:25
Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors,"Andrew Ilyas, Logan Engstrom, Aleksander Madry",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.07978"" target=""_blank"">1807.07978</a>",,2025-12-03 22:39:25
Physical Adversarial Examples for Object Detectors,"Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, Amir Rahmati, Florian Tramer, Atul Prakash, Tadayoshi Kohno, Dawn Song",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.07769"" target=""_blank"">1807.07769</a>",,2025-12-03 22:39:25
Harmonic Adversarial Attack Method,"Wen Heng, Shuchang Zhou, Tingting Jiang",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.10590"" target=""_blank"">1807.10590</a>",,2025-12-03 22:39:25
Gradient Band-based Adversarial Training for Generalized Attack Immunity of A3C Path Finding,"Tong Chen, Wenjia Niu, Yingxiao Xiang, Xiaoxuan Bai, Jiqiang Liu, Zhen Han, Gang Li",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.06752"" target=""_blank"">1807.06752</a>",,2025-12-03 22:39:25
Motivating the Rules of the Game for Adversarial Example Research,"Justin Gilmer, Ryan P. Adams, Ian Goodfellow, David Andersen, George E. Dahl",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.06732"" target=""_blank"">1807.06732</a>",,2025-12-03 22:39:25
Defend Deep Neural Networks Against Adversarial Examples via Fixed and Dynamic Quantized Activation Functions,"Adnan Siraj Rakin, Jinfeng Yi, Boqing Gong, Deliang Fan",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.06714"" target=""_blank"">1807.06714</a>",,2025-12-03 22:39:25
"Rob-GAN: Generator, Discriminator, and Adversarial Attacker","Xuanqing Liu, Cho-Jui Hsieh",arXiv,2018-07,"<a href=""http://arxiv.org/abs/1807.10454"" target=""_blank"">1807.10454</a>",,2025-12-03 22:39:25
Training Augmentation with Adversarial Examples for Robust Speech Recognition,"Sining Sun, Ching-Feng Yeh, Mari Ostendorf, Mei-Yuh Hwang, Lei Xie",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.02782"" target=""_blank"">1806.02782</a>",,2025-12-03 22:39:25
Adversarial Regression with Multiple Learners,"Liang Tong, Sixie Yu, Scott Alfeld, Yevgeniy Vorobeychik",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.02256"" target=""_blank"">1806.02256</a>",,2025-12-03 22:39:25
Adversarial Attack on Graph Structured Data,"Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, Le Song",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.02371"" target=""_blank"">1806.02371</a>",,2025-12-03 22:39:25
Ranking Robustness Under Adversarial Document Manipulations,"Gregory Goren, Oren Kurland, Moshe Tennenholtz, Fiana Raiber",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.04425"" target=""_blank"">1806.04425</a>",,2025-12-03 22:39:25
Revisiting Adversarial Risk,"Arun Sai Suggala, Adarsh Prasad, Vaishnavh Nagarajan, Pradeep Ravikumar",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.02924"" target=""_blank"">1806.02924</a>",,2025-12-03 22:39:25
Monge blunts Bayes: Hardness Results for Adversarial Training,"Zac Cranko, Aditya Krishna Menon, Richard Nock, Cheng Soon Ong, Zhan Shi, Christian Walder",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.02977"" target=""_blank"">1806.02977</a>",,2025-12-03 22:39:25
DPatch: An Adversarial Patch Attack on Object Detectors,"Xin Liu, Huanrui Yang, Ziwei Liu, Linghao Song, Hai Li, Yiran Chen",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.02299"" target=""_blank"">1806.02299</a>",,2025-12-03 22:39:25
Killing four birds with one Gaussian process: the relation between different test-time attacks,"Kathrin Grosse, Michael T. Smith, Michael Backes",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.02032"" target=""_blank"">1806.02032</a>",,2025-12-03 22:39:25
Resisting Adversarial Attacks using Gaussian Mixture Variational Autoencoders,"Partha Ghosh, Arpan Losalka, Michael J Black",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.00081"" target=""_blank"">1806.00081</a>",,2025-12-03 22:39:25
Mitigation of Policy Manipulation Attacks on Deep Q-Networks with Parameter-Space Noise,"Vahid Behzadan, Arslan Munir",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.02190"" target=""_blank"">1806.02190</a>",,2025-12-03 22:39:25
An Explainable Adversarial Robustness Metric for Deep Learning Neural Networks,"Chirag Agarwal, Bo Dong, Dan Schonfeld, Anthony Hoogs",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.01477"" target=""_blank"">1806.01477</a>",,2025-12-03 22:39:25
PAC-learning in the presence of evasion adversaries,"Daniel Cullina, Arjun Nitin Bhagoji, Prateek Mittal",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.01471"" target=""_blank"">1806.01471</a>",,2025-12-03 22:39:25
Sufficient Conditions for Idealised Models to Have No Adversarial Examples: a Theoretical and Empirical Study with Bayesian Neural Networks,"Yarin Gal, Lewis Smith",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.00667"" target=""_blank"">1806.00667</a>",,2025-12-03 22:39:25
Detecting Adversarial Examples via Key-based Network,"Pinlong Zhao, Zhouyu Fu, Ou wu, Qinghua Hu, Jun Wang",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.00580"" target=""_blank"">1806.00580</a>",,2025-12-03 22:39:25
PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks,"Jan Svoboda, Jonathan Masci, Federico Monti, Michael M. Bronstein, Leonidas Guibas",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.00088"" target=""_blank"">1806.00088</a>",,2025-12-03 22:39:25
Defense Against the Dark Arts: An overview of adversarial example security research and future research directions,Ian Goodfellow,arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.04169"" target=""_blank"">1806.04169</a>",,2025-12-03 22:39:25
Defending Malware Classification Networks Against Adversarial Perturbations with Non-Negative Weight Restrictions,Alex Kouzemtchenko,arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.09035"" target=""_blank"">1806.09035</a>",,2025-12-03 22:39:25
Adversarial Attacks on Variational Autoencoders,"George Gondim-Ribeiro, Pedro Tabacof, Eduardo Valle",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.04646"" target=""_blank"">1806.04646</a>",,2025-12-03 22:39:25
Detection based Defense against Adversarial Examples from the Steganalysis Point of View,"Jiayang Liu, Weiming Zhang, Yiwei Zhang, Dongdong Hou, Yujia Liu, Hongyue Zha, Nenghai Yu",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.09186"" target=""_blank"">1806.09186</a>",,2025-12-03 22:39:25
Manifold Mixup: Better Representations by Interpolating Hidden States,"Vikas Verma, Alex Lamb, Christopher Beckham, Amir Najafi, Ioannis Mitliagkas, Aaron Courville, David Lopez-Paz, Yoshua Bengio",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.05236"" target=""_blank"">1806.05236</a>",,2025-12-03 22:39:25
Adversarial Reprogramming of Neural Networks,"Gamaleldin F. Elsayed, Ian Goodfellow, Jascha Sohl-Dickstein",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.11146"" target=""_blank"">1806.11146</a>",,2025-12-03 22:39:25
Gradient Similarity: An Explainable Approach to Detect Adversarial Attacks against Deep Learning,"Jasjeet Dhaliwal, Saurabh Shintre",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.10707"" target=""_blank"">1806.10707</a>",,2025-12-03 22:39:25
Customizing an Adversarial Example Generator with Class-Conditional GANs,Shih-hong Tsai,arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.10496"" target=""_blank"">1806.10496</a>",,2025-12-03 22:39:25
On Adversarial Examples for Character-Level Neural Machine Translation,"Javid Ebrahimi, Daniel Lowd, Dejing Dou",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.09030"" target=""_blank"">1806.09030</a>",,2025-12-03 22:39:25
Evaluation of Momentum Diverse Input Iterative Fast Gradient Sign Method (M-DI2-FGSM) Based Attack Method on MCS 2018 Adversarial Attacks on Black Box Face Recognition System,Md Ashraful Alam Milton,arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.08970"" target=""_blank"">1806.08970</a>",,2025-12-03 22:39:25
Exploring Adversarial Examples: Patterns of One-Pixel Attacks,"David Kügler, Alexander Distergoft, Arjan Kuijper, Anirban Mukhopadhyay",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.09410"" target=""_blank"">1806.09410</a>",,2025-12-03 22:39:25
Gradient Adversarial Training of Neural Networks,"Ayan Sinha, Zhao Chen, Vijay Badrinarayanan, Andrew Rabinovich",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.08028"" target=""_blank"">1806.08028</a>",,2025-12-03 22:39:25
Combinatorial Testing for Deep Learning Systems,"Lei Ma, Fuyuan Zhang, Minhui Xue, Bo Li, Yang Liu, Jianjun Zhao, Yadong Wang",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.07723"" target=""_blank"">1806.07723</a>",,2025-12-03 22:39:25
On the Learning of Deep Local Features for Robust Face Spoofing Detection,"Souza Gustavo Botelho de, João Paulo Papa, Aparecido Nilceu Marana",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.07492"" target=""_blank"">1806.07492</a>",,2025-12-03 22:39:25
Built-in Vulnerabilities to Imperceptible Adversarial Perturbations,"Thomas Tanay, Jerone T. A. Andrews, Lewis D. Griffin",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.07409"" target=""_blank"">1806.07409</a>",,2025-12-03 22:39:25
Non-Negative Networks Against Adversarial Attacks,"William Fleshman, Edward Raff, Jared Sylvester, Steven Forsyth, Mark McLean",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.06108"" target=""_blank"">1806.06108</a>",,2025-12-03 22:39:25
Copycat CNN: Stealing Knowledge by Persuading Confession with Random Non-Labeled Data,"Jacson Rodrigues Correia-Silva, Rodrigo F. Berriel, Claudine Badue, Souza Alberto F. de, Thiago Oliveira-Santos",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.05476"" target=""_blank"">1806.05476</a>",,2025-12-03 22:39:25
Hierarchical interpretations for neural network predictions,"Chandan Singh, W. James Murdoch, Bin Yu",arXiv,2018-06,"<a href=""http://arxiv.org/abs/1806.05337"" target=""_blank"">1806.05337</a>",,2025-12-03 22:39:25
Detecting Adversarial Samples for Deep Neural Networks through Mutation Testing,"Jingyi Wang, Jun Sun, Peixin Zhang, Xinyu Wang",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.05010"" target=""_blank"">1805.05010</a>",,2025-12-03 22:39:25
Bidirectional Learning for Robust Neural Networks,"Sidney Pontes-Filho, Marcus Liwicki",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.08006"" target=""_blank"">1805.08006</a>",,2025-12-03 22:39:25
Adversarial Attacks on Neural Networks for Graph Data,"Daniel Zügner, Amir Akbarnejad, Stephan Günnemann",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.07984"" target=""_blank"">1805.07984</a>",,2025-12-03 22:39:25
Adversarial Noise Layer: Regularize Neural Network By Adding Noise,"Zhonghui You, Jinmian Ye, Kunming Li, Zenglin Xu, Ping Wang",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.08000"" target=""_blank"">1805.08000</a>",,2025-12-03 22:39:25
Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference,"Ruying Bao, Sihang Liang, Qingcan Wang",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.07862"" target=""_blank"">1805.07862</a>",,2025-12-03 22:39:25
Towards Understanding Limitations of Pixel Discretization Against Adversarial Attacks,"Jiefeng Chen, Xi Wu, Vaibhav Rastogi, Yingyu Liang, Somesh Jha",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.07816"" target=""_blank"">1805.07816</a>",,2025-12-03 22:39:25
Targeted Adversarial Examples for Black Box Audio Systems,"Rohan Taori, Amog Kamsetty, Brenton Chu, Nikita Vemuri",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.07820"" target=""_blank"">1805.07820</a>",,2025-12-03 22:39:25
Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models,"Pouya Samangouei, Maya Kabkab, Rama Chellappa",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.06605"" target=""_blank"">1805.06605</a>","<a href=""https://github.com/kabkabm/defensegan"" target=""_blank"">kabkabm</a>",2025-12-03 22:39:25
Towards Robust Neural Machine Translation,"Yong Cheng, Zhaopeng Tu, Fandong Meng, Junjie Zhai, Yang Liu",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.06130"" target=""_blank"">1805.06130</a>",,2025-12-03 22:39:25
Siamese networks for generating adversarial examples,"Mandar Kulkarni, Aria Abubakar",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.01431"" target=""_blank"">1805.01431</a>",,2025-12-03 22:39:25
Curriculum Adversarial Training,"Qi-Zhi Cai, Min Du, Chang Liu, Dawn Song",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.04807"" target=""_blank"">1805.04807</a>",,2025-12-03 22:39:25
AttriGuard: A Practical Defense Against Attribute Inference Attacks via Adversarial Machine Learning,"Jinyuan Jia, Neil Zhenqiang Gong",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.04810"" target=""_blank"">1805.04810</a>",,2025-12-03 22:39:25
Breaking Transferability of Adversarial Samples with Randomness,"Yan Zhou, Murat Kantarcioglu, Bowei Xi",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.04613"" target=""_blank"">1805.04613</a>",,2025-12-03 22:39:25
On Visual Hallmarks of Robustness to Adversarial Malware,"Alex Huang, Abdullah Al-Dujaili, Erik Hemberg, Una-May O'Reilly",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.03553"" target=""_blank"">1805.03553</a>",,2025-12-03 22:39:25
Robust Classification with Convolutional Prototype Learning,"Hong-Ming Yang, Xu-Yao Zhang, Fei Yin, Cheng-Lin Liu",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.03438"" target=""_blank"">1805.03438</a>",,2025-12-03 22:39:25
Interpretable Adversarial Perturbation in Input Embedding Space for Text,"Motoki Sato, Jun Suzuki, Hiroyuki Shindo, Yuji Matsumoto",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.02917"" target=""_blank"">1805.02917</a>",,2025-12-03 22:39:25
A Counter-Forensic Method for CNN-Based Camera Model Identification,"David Güera, Yu Wang, Luca Bondi, Paolo Bestagini, Stefano Tubaro, Edward J. Delp",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.02131"" target=""_blank"">1805.02131</a>",,2025-12-03 22:39:25
Concolic Testing for Deep Neural Networks,"Youcheng Sun, Min Wu, Wenjie Ruan, Xiaowei Huang, Marta Kwiatkowska, Daniel Kroening",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.00089"" target=""_blank"">1805.00089</a>",,2025-12-03 22:39:25
On the Limitation of MagNet Defense against $L_1$-based Adversarial Examples,"Pei-Hsuan Lu, Pin-Yu Chen, Kang-Cheng Chen, Chia-Mu Yu",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.00310"" target=""_blank"">1805.00310</a>",,2025-12-03 22:39:25
Constructing Unrestricted Adversarial Examples with Generative Models,"Yang Song, Rui Shu, Nate Kushman, Stefano Ermon",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.07894"" target=""_blank"">1805.07894</a>",,2025-12-03 22:39:25
Anonymizing k-Facial Attributes via Adversarial Perturbations,"Saheb Chhabra, Richa Singh, Mayank Vatsa, Gaurav Gupta",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.09380"" target=""_blank"">1805.09380</a>",,2025-12-03 22:39:25
Adversarially Robust Training through Structured Gradient Regularization,"Kevin Roth, Aurelien Lucchi, Sebastian Nowozin, Thomas Hofmann",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.08736"" target=""_blank"">1805.08736</a>",,2025-12-03 22:39:25
Adversarial Noise Attacks of Deep Learning Architectures -- Stability Analysis via Sparse Modeled Signals,"Yaniv Romano, Aviad Aberdam, Jeremias Sulam, Michael Elad",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.11596"" target=""_blank"">1805.11596</a>",,2025-12-03 22:39:25
Scaling provable adversarial defenses,"Eric Wong, Frank R. Schmidt, Jan Hendrik Metzen, J. Zico Kolter",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.12514"" target=""_blank"">1805.12514</a>","<a href=""https://github.com/locuslab/convex_adversarial/"" target=""_blank"">convex_adversarial</a>",2025-12-03 22:39:25
Towards the first adversarially robust neural network model on MNIST,"Lukas Schott, Jonas Rauber, Matthias Bethge, Wieland Brendel",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.09190"" target=""_blank"">1805.09190</a>",,2025-12-03 22:39:25
Greedy Attack and Gumbel Attack: Generating Adversarial Examples for Discrete Data,"Puyudi Yang, Jianbo Chen, Cho-Jui Hsieh, Jane-Ling Wang, Michael I. Jordan",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.12316"" target=""_blank"">1805.12316</a>",,2025-12-03 22:39:25
Adversarial Attacks on Face Detectors using Neural Net based Constrained Optimization,"Avishek Joey Bose, Parham Aarabi",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.12302"" target=""_blank"">1805.12302</a>",,2025-12-03 22:39:25
ADAGIO: Interactive Experimentation with Adversarial Attack and Defense for Audio,"Nilaksh Das, Madhuri Shanbhogue, Shang-Tse Chen, Li Chen, Michael E. Kounavis, Duen Horng Chau",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.11852"" target=""_blank"">1805.11852</a>",,2025-12-03 22:39:25
Robustifying Models Against Adversarial Attacks by Langevin Dynamics,"Vignesh Srinivasan, Arturo Marban, Klaus-Robert Müller, Wojciech Samek, Shinichi Nakajima",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.12017"" target=""_blank"">1805.12017</a>",,2025-12-03 22:39:25
Robustness May Be at Odds with Accuracy,"Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, Aleksander Madry",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.12152"" target=""_blank"">1805.12152</a>",,2025-12-03 22:39:25
AutoZOOM: Autoencoder-based Zeroth Order Optimization Method for Attacking Black-box Neural Networks,"Chun-Chen Tu, Paishun Ting, Pin-Yu Chen, Sijia Liu, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh, Shin-Ming Cheng",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.11770"" target=""_blank"">1805.11770</a>",,2025-12-03 22:39:25
Sequential Attacks on Agents for Long-Term Adversarial Goals,"Edgar Tretschk, Seong Joon Oh, Mario Fritz",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.12487"" target=""_blank"">1805.12487</a>",,2025-12-03 22:39:25
Why Botnets Work: Distributed Brute-Force Attacks Need No Synchronization,"Salman Salamatian, Wasim Huleihel, Ahmad Beirami, Asaf Cohen, Muriel Médard",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.11666"" target=""_blank"">1805.11666</a>",,2025-12-03 22:39:25
GenAttack: Practical Black-box Attacks with Gradient-Free Optimization,"Moustafa Alzantot, Yash Sharma, Supriyo Chakraborty, Huan Zhang, Cho-Jui Hsieh, Mani Srivastava",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.11090"" target=""_blank"">1805.11090</a>",,2025-12-03 22:39:25
Defending Against Adversarial Attacks by Leveraging an Entire GAN,"Gokula Krishnan Santhanam, Paulina Grnarova",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.10652"" target=""_blank"">1805.10652</a>",,2025-12-03 22:39:25
Training verified learners with learned verifiers,"Krishnamurthy Dvijotham, Sven Gowal, Robert Stanforth, Relja Arandjelovic, Brendan O'Donoghue, Jonathan Uesato, Pushmeet Kohli",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.10265"" target=""_blank"">1805.10265</a>",,2025-12-03 22:39:25
Adversarial examples from computational constraints,"Sébastien Bubeck, Eric Price, Ilya Razenshteyn",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.10204"" target=""_blank"">1805.10204</a>",,2025-12-03 22:39:25
Laplacian Networks: Bounding Indicator Function Smoothness for Neural Network Robustness,"Carlos Eduardo Rosar Kos Lassance, Vincent Gripon, Antonio Ortega",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.10133"" target=""_blank"">1805.10133</a>",,2025-12-03 22:39:25
Towards Robust Training of Neural Networks by Regularizing Adversarial Gradients,"Fuxun Yu, Zirui Xu, Yanzhi Wang, Chenchen Liu, Xiang Chen",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.09370"" target=""_blank"">1805.09370</a>",,2025-12-03 22:39:25
Adversarial Examples in Remote Sensing,"Wojciech Czaja, Neil Fendley, Michael Pekala, Christopher Ratto, I-Jeng Wang",arXiv,2018-05,"<a href=""http://arxiv.org/abs/1805.10997"" target=""_blank"">1805.10997</a>",,2025-12-03 22:39:25
On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses,"Anish Athalye, Nicholas Carlini",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.03286"" target=""_blank"">1804.03286</a>",,2025-12-03 22:39:25
Adversarial Example Generation with Syntactically Controlled Paraphrase Networks,"Mohit Iyyer, John Wieting, Kevin Gimpel, Luke Zettlemoyer",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.06059"" target=""_blank"">1804.06059</a>",,2025-12-03 22:39:25
Global Robustness Evaluation of Deep Neural Networks with Provable Guarantees for the $L_0$ Norm,"Wenjie Ruan, Min Wu, Youcheng Sun, Xiaowei Huang, Daniel Kroening, Marta Kwiatkowska",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.05805"" target=""_blank"">1804.05805</a>",,2025-12-03 22:39:25
ShapeShifter: Robust Physical Adversarial Attack on Faster R-CNN Object Detector,"Shang-Tse Chen, Cory Cornelius, Jason Martin, Duen Horng Chau",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.05810"" target=""_blank"">1804.05810</a>",,2025-12-03 22:39:25
Adversarial Attacks Against Medical Deep Learning Systems,"Samuel G. Finlayson, Hyung Won Chung, Isaac S. Kohane, Andrew L. Beam",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.05296"" target=""_blank"">1804.05296</a>",,2025-12-03 22:39:25
Detecting Malicious PowerShell Commands using Deep Neural Networks,"Danny Hendler, Shay Kels, Amir Rubin",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.04177"" target=""_blank"">1804.04177</a>",,2025-12-03 22:39:25
Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations,"Alex Lamb, Jonathan Binas, Anirudh Goyal, Dmitriy Serdyuk, Sandeep Subramanian, Ioannis Mitliagkas, Yoshua Bengio",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.02485"" target=""_blank"">1804.02485</a>",,2025-12-03 22:39:25
Adversarial Training Versus Weight Decay,"Angus Galloway, Thomas Tanay, Graham W. Taylor",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.03308"" target=""_blank"">1804.03308</a>",,2025-12-03 22:39:25
An ADMM-Based Universal Framework for Adversarial Attacks on Deep Neural Networks,"Pu Zhao, Sijia Liu, Yanzhi Wang, Xue Lin",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.03193"" target=""_blank"">1804.03193</a>",,2025-12-03 22:39:25
Adaptive Spatial Steganography Based on Probability-Controlled Adversarial Examples,"Sai Ma, Qingxiao Guan, Xianfeng Zhao, Yaqi Liu",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.02691"" target=""_blank"">1804.02691</a>",,2025-12-03 22:39:25
Unifying Bilateral Filtering and Adversarial Training for Robust Neural Networks,"Neale Ratzlaff, Li Fuxin",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.01635"" target=""_blank"">1804.01635</a>",,2025-12-03 22:39:25
Adversarial Attacks and Defences Competition,"Alexey Kurakin, Ian Goodfellow, Samy Bengio, Yinpeng Dong, Fangzhou Liao, Ming Liang, Tianyu Pang, Jun Zhu, Xiaolin Hu, Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, Alan Yuille, Sangxia Huang, Yao Zhao, Yuzhe Zhao, Zhonglin Han, Junjiajia Long, Yerkebulan Berdibekov, Takuya Akiba, Seiya Tokui, Motoki Abe",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.00097"" target=""_blank"">1804.00097</a>",,2025-12-03 22:39:25
Generalizability vs,"Magdalini Paschali, Sailesh Conjeti, Fernando Navarro, Nassir Navab",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.00504"" target=""_blank"">1804.00504</a>",,2025-12-03 22:39:25
Semantic Adversarial Examples,"Hossein Hosseini, Radha Poovendran",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.00499"" target=""_blank"">1804.00499</a>",,2025-12-03 22:39:25
Robust Machine Comprehension Models via Adversarial Training,"Yicheng Wang, Mohit Bansal",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.06473"" target=""_blank"">1804.06473</a>",,2025-12-03 22:39:25
Neural Automated Essay Scoring and Coherence Modeling for Adversarially Crafted Input,"Youmna Farag, Helen Yannakoudakis, Ted Briscoe",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.06898"" target=""_blank"">1804.06898</a>",,2025-12-03 22:39:25
Simulation-based Adversarial Test Generation for Autonomous Vehicles with Machine Learning Components,"Cumhur Erkan Tuncali, Georgios Fainekos, Hisahiro Ito, James Kapinski",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.06760"" target=""_blank"">1804.06760</a>",,2025-12-03 22:39:25
Black-box Adversarial Attacks with Limited Queries and Information,"Andrew Ilyas, Logan Engstrom, Anish Athalye, Jessy Lin",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.08598"" target=""_blank"">1804.08598</a>",,2025-12-03 22:39:25
How Robust are Deep Neural Networks?,"Biswa Sengupta, Karl J. Friston",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.11313"" target=""_blank"">1804.11313</a>",,2025-12-03 22:39:25
Semantic Adversarial Deep Learning,"Tommaso Dreossi, Somesh Jha, Sanjit A. Seshia",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.07045"" target=""_blank"">1804.07045</a>",,2025-12-03 22:39:25
Adversarial Regression for Detecting Attacks in Cyber-Physical Systems,"Amin Ghafouri, Yevgeniy Vorobeychik, Xenofon Koutsoukos",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.11022"" target=""_blank"">1804.11022</a>",,2025-12-03 22:39:25
Formal Security Analysis of Neural Networks using Symbolic Intervals,"Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, Suman Jana",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.10829"" target=""_blank"">1804.10829</a>",,2025-12-03 22:39:25
Towards Fast Computation of Certified Robustness for ReLU Networks,"Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Duane Boning, Inderjit S. Dhillon, Luca Daniel",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.09699"" target=""_blank"">1804.09699</a>",,2025-12-03 22:39:25
Towards Dependable Deep Convolutional Neural Networks (CNNs) with Out-distribution Learning,"Mahdieh Abbasi, Arezoo Rajabi, Christian Gagné, Rakesh B. Bobba",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.08794"" target=""_blank"">1804.08794</a>",,2025-12-03 22:39:25
Siamese Generative Adversarial Privatizer for Biometric Data,"Witold Oleszkiewicz, Peter Kairouz, Karol Piczak, Ram Rajagopal, Tomasz Trzcinski",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.08757"" target=""_blank"">1804.08757</a>",,2025-12-03 22:39:25
Adversarially Robust Generalization Requires More Data,"Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, Aleksander Mądry",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.11285"" target=""_blank"">1804.11285</a>",,2025-12-03 22:39:25
VectorDefense: Vectorization as a Defense to Adversarial Examples,"Vishaal Munusamy Kabilan, Brandon Morris, Anh Nguyen",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.08529"" target=""_blank"">1804.08529</a>",,2025-12-03 22:39:25
Generating Natural Language Adversarial Examples,"Moustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani Srivastava, Kai-Wei Chang",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.07998"" target=""_blank"">1804.07998</a>",,2025-12-03 22:39:25
Gradient Masking Causes CLEVER to Overestimate Adversarial Perturbation Size,Ian Goodfellow,arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.07870"" target=""_blank"">1804.07870</a>",,2025-12-03 22:39:25
Learning More Robust Features with Adversarial Training,"Shuangtao Li, Yuanke Chen, Yanlin Peng, Lin Bai",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.07757"" target=""_blank"">1804.07757</a>",,2025-12-03 22:39:25
ADef: an Iterative Algorithm to Construct Adversarial Deformations,"Rima Alaifari, Giovanni S. Alberti, Tandri Gauksson",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.07729"" target=""_blank"">1804.07729</a>",,2025-12-03 22:39:25
Query-Efficient Black-Box Attack Against Sequence-Based Malware Classifiers,"Ishai Rosenberg, Asaf Shabtai, Yuval Elovici, Lior Rokach",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.08778"" target=""_blank"">1804.08778</a>",,2025-12-03 22:39:25
Attacking Convolutional Neural Network using Differential Evolution,"Jiawei Su, Danilo Vasconcellos Vargas, Kouichi Sakurai",arXiv,2018-04,"<a href=""http://arxiv.org/abs/1804.07062"" target=""_blank"">1804.07062</a>",,2025-12-03 22:39:25
Detecting Adversarial Examples - A Lesson from Multimedia Forensics,"Pascal Schöttle, Alexander Schlögl, Cecilia Pasquini, Rainer Böhme",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.03613"" target=""_blank"">1803.03613</a>",,2025-12-03 22:39:25
Feature Distillation: DNN-Oriented JPEG Compression Against Adversarial Examples,"Zihao Liu, Qi Liu, Tao Liu, Nuo Xu, Xue Lin, Yanzhi Wang, Wujie Wen",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.05787"" target=""_blank"">1803.05787</a>",,2025-12-03 22:39:25
"Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning","Nicolas Papernot, Patrick McDaniel",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.04765"" target=""_blank"">1803.04765</a>",,2025-12-03 22:39:25
Invisible Mask: Practical Attacks on Face Recognition with Infrared,"Zhe Zhou, Di Tang, Xiaofeng Wang, Weili Han, Xiangyu Liu, Kehuan Zhang",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.04683"" target=""_blank"">1803.04683</a>",,2025-12-03 22:39:25
Defending against Adversarial Attack towards Deep Neural Networks via Collaborative Multi-task Training,"Derek Wang, Chaoran Li, Sheng Wen, Surya Nepal, Yang Xiang",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.05123"" target=""_blank"">1803.05123</a>",,2025-12-03 22:39:25
Adversarial Malware Binaries: Evading Deep Learning for Malware Detection in Executables,"Bojan Kolosnjaji, Ambra Demontis, Battista Biggio, Davide Maiorca, Giorgio Giacinto, Claudia Eckert, Fabio Roli",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.04173"" target=""_blank"">1803.04173</a>",,2025-12-03 22:39:25
Combating Adversarial Attacks Using Sparse Representations,"Soorya Gopalakrishnan, Zhinus Marzi, Upamanyu Madhow, Ramtin Pedarsani",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.03880"" target=""_blank"">1803.03880</a>",,2025-12-03 22:39:25
Detecting Adversarial Examples via Neural Fingerprinting,"Sumanth Dathathri, Stephan Zheng, Tianwei Yin, Richard M. Murray, Yisong Yue",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.03870"" target=""_blank"">1803.03870</a>",,2025-12-03 22:39:25
Rethinking Feature Distribution for Loss Functions in Image Classification,"Weitao Wan, Yuanyi Zhong, Tianpeng Li, Jiansheng Chen",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.02988"" target=""_blank"">1803.02988</a>",,2025-12-03 22:39:25
On Generation of Adversarial Examples using Convex Programming,"Emilio Rafael Balda, Arash Behboodi, Rudolf Mathar",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.03607"" target=""_blank"">1803.03607</a>",,2025-12-03 22:39:25
Explaining Black-box Android Malware Detection,"Marco Melis, Davide Maiorca, Battista Biggio, Giorgio Giacinto, Fabio Roli",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.03544"" target=""_blank"">1803.03544</a>",,2025-12-03 22:39:25
Sparse Adversarial Perturbations for Videos,"Xingxing Wei, Jun Zhu, Hang Su",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.02536"" target=""_blank"">1803.02536</a>",,2025-12-03 22:39:25
Stochastic Activation Pruning for Robust Adversarial Defense,"Guneet S. Dhillon, Kamyar Azizzadenesheli, Zachary C. Lipton, Jeremy Bernstein, Jean Kossaifi, Aran Khanna, Anima Anandkumar",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.01442"" target=""_blank"">1803.01442</a>",,2025-12-03 22:39:25
Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples,"Minhao Cheng, Jinfeng Yi, Pin-Yu Chen, Huan Zhang, Cho-Jui Hsieh",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.01128"" target=""_blank"">1803.01128</a>",,2025-12-03 22:39:25
Protecting JPEG Images Against Adversarial Attacks,"Aaditya Prakash, Nick Moran, Solomon Garber, Antonella DiLillo, James Storer",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.00940"" target=""_blank"">1803.00940</a>",,2025-12-03 22:39:25
Deep Defense: Training DNNs with Improved Adversarial Robustness,"Ziang Yan, Yiwen Guo, Changshui Zhang",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.00404"" target=""_blank"">1803.00404</a>","<a href=""https://github.com/ZiangYan/deepdefense.pytorch"" target=""_blank"">ZiangYan</a>",2025-12-03 22:39:25
Unravelling Robustness of Deep Learning based Face Recognition Against Adversarial Attacks,"Gaurav Goswami, Nalini Ratha, Akshay Agarwal, Richa Singh, Mayank Vatsa",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.00401"" target=""_blank"">1803.00401</a>",,2025-12-03 22:39:25
Large Margin Deep Networks for Classification,"Gamaleldin F. Elsayed, Dilip Krishnan, Hossein Mobahi, Kevin Regan, Samy Bengio",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.05598"" target=""_blank"">1803.05598</a>",,2025-12-03 22:39:25
On the Limitation of Local Intrinsic Dimensionality for Characterizing the Subspaces of Adversarial Examples,"Pei-Hsuan Lu, Pin-Yu Chen, Chia-Mu Yu",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.09638"" target=""_blank"">1803.09638</a>",,2025-12-03 22:39:25
Adversarial Logit Pairing,"Harini Kannan, Alexey Kurakin, Ian Goodfellow",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.06373"" target=""_blank"">1803.06373</a>",,2025-12-03 22:39:25
CNN Based Adversarial Embedding with Minimum Alteration for Image Steganography,"Weixuan Tang, Bin Li, Shunquan Tan, Mauro Barni, Jiwu Huang",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.09043"" target=""_blank"">1803.09043</a>",,2025-12-03 22:39:25
Security Consideration For Deep Learning-Based Image Forensics,"Wei Zhao, Pengpeng Yang, Rongrong Ni, Yao Zhao, Haorui Wu",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.11157"" target=""_blank"">1803.11157</a>",,2025-12-03 22:39:25
Defending against Adversarial Images using Basis Functions Transformations,"Uri Shaham, James Garritano, Yutaro Yamada, Ethan Weinberger, Alex Cloninger, Xiuyuan Cheng, Kelly Stanton, Yuval Kluger",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.10840"" target=""_blank"">1803.10840</a>",,2025-12-03 22:39:25
A Dual Approach to Scalable Verification of Deep Networks,"Dj Krishnamurthy, Dvijotham, Robert Stanforth, Sven Gowal, Timothy Mann, Pushmeet Kohli",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.06567"" target=""_blank"">1803.06567</a>",,2025-12-03 22:39:25
The Effects of JPEG and JPEG2000 Compression on Attacks using Adversarial Examples,"Ayse Elvan Aydemir, Alptekin Temizel, Tugba Taskaya Temizel",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.10418"" target=""_blank"">1803.10418</a>",,2025-12-03 22:39:25
Bypassing Feature Squeezing by Increasing Adversary Strength,"Yash Sharma, Pin-Yu Chen",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.09868"" target=""_blank"">1803.09868</a>",,2025-12-03 22:39:25
Clipping free attacks against artificial neural networks,"Boussad Addad, Jerome Kodjabachian, Christophe Meyer",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.09468"" target=""_blank"">1803.09468</a>",,2025-12-03 22:39:25
A Dynamic-Adversarial Mining Approach to the Security of Machine Learning,"Tegjyot Singh Sethi, Mehmed Kantardzic, Lingyu Lyua, Jiashun Chen",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.09162"" target=""_blank"">1803.09162</a>",,2025-12-03 22:39:25
An Overview of Vulnerabilities of Voice Controlled Systems,"Yuan Gong, Christian Poellabauer",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.09156"" target=""_blank"">1803.09156</a>",,2025-12-03 22:39:25
Security Theater: On the Vulnerability of Classifiers to Exploratory Attacks,"Tegjyot Singh Sethi, Mehmed Kantardzic, Joung Woo Ryu",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.09163"" target=""_blank"">1803.09163</a>",,2025-12-03 22:39:25
Detecting Adversarial Perturbations with Saliency,"Chiliang Zhang, Zhimou Yang, Zuochang Ye",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.08773"" target=""_blank"">1803.08773</a>",,2025-12-03 22:39:25
Improving DNN Robustness to Adversarial Attacks using Jacobian Regularization,"Daniel Jakubovitz, Raja Giryes",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.08680"" target=""_blank"">1803.08680</a>",,2025-12-03 22:39:25
Understanding Measures of Uncertainty for Adversarial Example Detection,"Lewis Smith, Yarin Gal",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.08533"" target=""_blank"">1803.08533</a>",,2025-12-03 22:39:25
Adversarial Defense based on Structure-to-Signal Autoencoders,"Joachim Folz, Sebastian Palacio, Joern Hees, Damian Borth, Andreas Dengel",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.07994"" target=""_blank"">1803.07994</a>",,2025-12-03 22:39:25
Task dependent Deep LDA pruning of neural networks,"Qing Tian, Tal Arbel, James J. Clark",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.08134"" target=""_blank"">1803.08134</a>",,2025-12-03 22:39:25
DeepGauge: Multi-Granularity Testing Criteria for Deep Learning Systems,"Lei Ma, Felix Juefei-Xu, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li, Chunyang Chen, Ting Su, Li Li, Yang Liu, Jianjun Zhao, Yadong Wang",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.07519"" target=""_blank"">1803.07519</a>",,2025-12-03 22:39:25
Technical Report: When Does Machine Learning FAIL? Generalized Transferability for Evasion and Poisoning Attacks,"Octavian Suciu, Radu Mărginean, Yiğitcan Kaya, Hal III Daumé, Tudor Dumitraş",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.06975"" target=""_blank"">1803.06975</a>",,2025-12-03 22:39:25
Improving Transferability of Adversarial Examples with Input Diversity,"Cihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu Wang, Zhou Ren, Alan Yuille",arXiv,2018-03,"<a href=""http://arxiv.org/abs/1803.06978"" target=""_blank"">1803.06978</a>","<a href=""https://github.com/cihangxie/DI-2-FGSM"" target=""_blank"">cihangxie</a>",2025-12-03 22:39:25
Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks,"Yusuke Tsuzuku, Issei Sato, Masashi Sugiyama",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.04034"" target=""_blank"">1802.04034</a>",,2025-12-03 22:39:25
ASP:A Fast Adversarial Attack Example Generation Framework based on Adversarial Saliency Prediction,"Fuxun Yu, Qide Dong, Xiang Chen",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.05763"" target=""_blank"">1802.05763</a>",,2025-12-03 22:39:25
Adversarial Risk and the Dangers of Evaluating Against Weak Attacks,"Jonathan Uesato, Brendan O'Donoghue, Aaron van den Oord, Pushmeet Kohli",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.05666"" target=""_blank"">1802.05666</a>",,2025-12-03 22:39:25
Fooling OCR Systems with Adversarial Text Images,"Congzheng Song, Vitaly Shmatikov",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.05385"" target=""_blank"">1802.05385</a>",,2025-12-03 22:39:25
Security Analysis and Enhancement of Model Compressed Deep Learning Systems under Adversarial Attacks,"Qi Liu, Tao Liu, Zihao Liu, Yanzhi Wang, Yier Jin, Wujie Wen",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.05193"" target=""_blank"">1802.05193</a>",,2025-12-03 22:39:25
Query-Free Attacks on Industry-Grade Face Recognition Systems under Resource Constraints,"Di Tang, XiaoFeng Wang, Kehuan Zhang",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.09900"" target=""_blank"">1802.09900</a>",,2025-12-03 22:39:25
Identify Susceptible Locations in Medical Records via Adversarial Attacks on Deep Predictive Models,"Mengying Sun, Fengyi Tang, Jinfeng Yi, Fei Wang, Jiayu Zhou",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.04822"" target=""_blank"">1802.04822</a>",,2025-12-03 22:39:25
Deceiving End-to-End Deep Learning Malware Detectors using Adversarial Examples,"Felix Kreuk, Assi Barak, Shir Aviv-Reuven, Moran Baruch, Benny Pinkas, Joseph Keshet",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.04528"" target=""_blank"">1802.04528</a>",,2025-12-03 22:39:25
Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples,"Anish Athalye, Nicholas Carlini, David Wagner",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.00420"" target=""_blank"">1802.00420</a>",,2025-12-03 22:39:25
Predicting Adversarial Examples with High Confidence,"Angus Galloway, Graham W. Taylor, Medhat Moussa",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.04457"" target=""_blank"">1802.04457</a>",,2025-12-03 22:39:25
Certified Robustness to Adversarial Examples with Differential Privacy,"Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, Suman Jana",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.03471"" target=""_blank"">1802.03471</a>",,2025-12-03 22:39:25
Detection of Adversarial Training Examples in Poisoning Attacks through Anomaly Detection,"Andrea Paudice, Luis Muñoz-González, Andras Gyorgy, Emil C. Lupu",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.03041"" target=""_blank"">1802.03041</a>",,2025-12-03 22:39:25
Blind Pre-Processing: A Robust Defense Method Against Adversarial Examples,"Adnan Siraj Rakin, Zhezhi He, Boqing Gong, Deliang Fan",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.01549"" target=""_blank"">1802.01549</a>",,2025-12-03 22:39:25
First-order Adversarial Vulnerability of Neural Networks and Input Dimension,"Carl-Johann Simon-Gabriel, Yann Ollivier, Léon Bottou, Bernhard Schölkopf, David Lopez-Paz",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.01421"" target=""_blank"">1802.01421</a>",,2025-12-03 22:39:25
Secure Detection of Image Manipulation by means of Random Feature Selection,"Zhipeng Chen, Benedetta Tondi, Xiaolong Li, Rongrong Ni, Yao Zhao, Mauro Barni",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.00573"" target=""_blank"">1802.00573</a>",,2025-12-03 22:39:25
Hardening Deep Neural Networks via Adversarial Model Cascades,"Deepak Vijaykeerthy, Anshuman Suri, Sameep Mehta, Ponnurangam Kumaraguru",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.01448"" target=""_blank"">1802.01448</a>",,2025-12-03 22:39:25
Are Generative Classifiers More Robust to Adversarial Attacks?,"Yingzhen Li, John Bradshaw, Yash Sharma",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.06552"" target=""_blank"">1802.06552</a>",,2025-12-03 22:39:25
DARTS: Deceiving Autonomous Cars with Toxic Signs,"Chawin Sitawarin, Arjun Nitin Bhagoji, Arsalan Mosenia, Mung Chiang, Prateek Mittal",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.06430"" target=""_blank"">1802.06430</a>",,2025-12-03 22:39:25
On Lyapunov exponents and adversarial perturbation,"Vinay Uday Prabhu, Nishant Desai, John Whaley",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.06927"" target=""_blank"">1802.06927</a>",,2025-12-03 22:39:25
Robustness of Rotation-Equivariant Networks to Adversarial Perturbations,"Beranger Dumont, Simona Maggio, Pablo Montalvo",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.06627"" target=""_blank"">1802.06627</a>",,2025-12-03 22:39:25
Adversarial Examples that Fool both Computer Vision and Time-Limited Humans,"Gamaleldin F. Elsayed, Shreya Shankar, Brian Cheung, Nicolas Papernot, Alex Kurakin, Ian Goodfellow, Jascha Sohl-Dickstein",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.08195"" target=""_blank"">1802.08195</a>",,2025-12-03 22:39:25
"Divide, Denoise, and Defend against Adversarial Attacks","Seyed-Mohsen Moosavi-Dezfooli, Ashish Shrivastava, Oncel Tuzel",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.06806"" target=""_blank"">1802.06806</a>",,2025-12-03 22:39:25
On the Suitability of $L_p$-norms for Creating and Preventing Adversarial Examples,"Mahmood Sharif, Lujo Bauer, Michael K. Reiter",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.09653"" target=""_blank"">1802.09653</a>",,2025-12-03 22:39:25
Retrieval-Augmented Convolutional Neural Networks for Improved Robustness against Adversarial Examples,"Jake Zhao, Kyunghyun Cho",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.09502"" target=""_blank"">1802.09502</a>",,2025-12-03 22:39:25
Max-Mahalanobis Linear Discriminant Analysis Networks,"Tianyu Pang, Chao Du, Jun Zhu",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.09308"" target=""_blank"">1802.09308</a>",,2025-12-03 22:39:25
Sensitivity and Generalization in Neural Networks: an Empirical Study,"Roman Novak, Yasaman Bahri, Daniel A. Abolafia, Jeffrey Pennington, Jascha Sohl-Dickstein",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.08760"" target=""_blank"">1802.08760</a>",,2025-12-03 22:39:25
Verifying Controllers Against Adversarial Examples with Bayesian Optimization,"Shromona Ghosh, Felix Berkenkamp, Gireeja Ranade, Shaz Qadeer, Ashish Kapoor",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.08678"" target=""_blank"">1802.08678</a>",,2025-12-03 22:39:25
Hessian-based Analysis of Large Batch Training and Robustness to Adversaries,"Zhewei Yao, Amir Gholami, Qi Lei, Kurt Keutzer, Michael W. Mahoney",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.08241"" target=""_blank"">1802.08241</a>",,2025-12-03 22:39:25
Adversarial vulnerability for any classifier,"Alhussein Fawzi, Hamza Fawzi, Omar Fawzi",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.08686"" target=""_blank"">1802.08686</a>",,2025-12-03 22:39:25
Adversarial Training for Probabilistic Spiking Neural Networks,"Alireza Bagheri, Osvaldo Simeone, Bipin Rajendran",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.08567"" target=""_blank"">1802.08567</a>",,2025-12-03 22:39:25
L2-Nonexpansive Neural Networks,"Haifeng Qian, Mark N. Wegman",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.07896"" target=""_blank"">1802.07896</a>",,2025-12-03 22:39:25
Generalizable Adversarial Examples Detection Based on Bi-model Decision Mismatch,"João Monteiro, Isabela Albuquerque, Zahid Akhtar, Tiago H. Falk",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.07770"" target=""_blank"">1802.07770</a>",,2025-12-03 22:39:25
Attack Strength vs,"Christopher Frederickson, Michael Moore, Glenn Dawson, Robi Polikar",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.07295"" target=""_blank"">1802.07295</a>",,2025-12-03 22:39:25
Out-distribution training confers robustness to deep neural networks,"Mahdieh Abbasi, Christian Gagné",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.07124"" target=""_blank"">1802.07124</a>",,2025-12-03 22:39:25
Understanding and Enhancing the Transferability of Adversarial Examples,"Lei Wu, Zhanxing Zhu, Cheng Tai, Weinan E",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.09707"" target=""_blank"">1802.09707</a>",,2025-12-03 22:39:25
"Shield: Fast, Practical Defense and Vaccination for Deep Learning using JPEG Compression","Nilaksh Das, Madhuri Shanbhogue, Shang-Tse Chen, Fred Hohman, Siwei Li, Li Chen, Michael E. Kounavis, Duen Horng Chau",arXiv,2018-02,"<a href=""http://arxiv.org/abs/1802.06816"" target=""_blank"">1802.06816</a>",,2025-12-03 22:39:25
Adversarial Perturbation Intensity Achieving Chosen Intra-Technique Transferability Level for Logistic Regression,Martin Gubri,arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.01953"" target=""_blank"">1801.01953</a>",,2025-12-03 22:39:25
Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality,"Xingjun Ma, Bo Li, Yisen Wang, Sarah M. Erfani, Sudanthi Wijewickrema, Grant Schoenebeck, Dawn Song, Michael E. Houle, James Bailey",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.02613"" target=""_blank"">1801.02613</a>",,2025-12-03 22:39:25
Spatially Transformed Adversarial Examples,"Chaowei Xiao, Jun-Yan Zhu, Bo Li, Warren He, Mingyan Liu, Dawn Song",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.02612"" target=""_blank"">1801.02612</a>",,2025-12-03 22:39:25
Generating Adversarial Examples with Adversarial Networks,"Chaowei Xiao, Bo Li, Jun-Yan Zhu, Warren He, Mingyan Liu, Dawn Song",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.02610"" target=""_blank"">1801.02610</a>",,2025-12-03 22:39:25
LaVAN: Localized and Visible Adversarial Noise,"Danny Karmon, Daniel Zoran, Yoav Goldberg",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.02608"" target=""_blank"">1801.02608</a>",,2025-12-03 22:39:25
Attacking Speaker Recognition With Deep Generative Models,"Wilson Cai, Anish Doshi, Rafael Valle",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.02384"" target=""_blank"">1801.02384</a>",,2025-12-03 22:39:25
HeNet: A Deep Learning Approach on Intel$^\circledR$ Processor Trace for Effective Exploit Detection,"Li Chen, Salmin Sultana, Ravi Sahita",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.02318"" target=""_blank"">1801.02318</a>",,2025-12-03 22:39:25
Denoising Dictionary Learning Against Adversarial Perturbations,"John Mitro, Derek Bridge, Steven Prestwich",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.02257"" target=""_blank"">1801.02257</a>",,2025-12-03 22:39:25
A General Framework for Adversarial Examples with Objectives,"Mahmood Sharif, Sruti Bhagavatula, Lujo Bauer, Michael K. Reiter",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.00349"" target=""_blank"">1801.00349</a>",,2025-12-03 22:39:25
Audio Adversarial Examples: Targeted Attacks on Speech-to-Text,"Nicholas Carlini, David Wagner",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.01944"" target=""_blank"">1801.01944</a>",,2025-12-03 22:39:25
Shielding Google's language toxicity model against adversarial attacks,"Nestor Rodriguez, Sergio Rojas-Galeano",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.01828"" target=""_blank"">1801.01828</a>",,2025-12-03 22:39:25
Facial Attributes: Accuracy and Adversarial Robustness,"Andras Rozsa, Manuel Günther, Ethan M. Rudd, Terrance E. Boult",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.02480"" target=""_blank"">1801.02480</a>",,2025-12-03 22:39:25
Neural Networks in Adversarial Setting and Ill-Conditioned Weight Space,"Mayank Singh, Abhishek Sinha, Balaji Krishnamurthy",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.00905"" target=""_blank"">1801.00905</a>",,2025-12-03 22:39:25
"High Dimensional Spaces, Deep Learning and Adversarial Examples",Simant Dube,arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.00634"" target=""_blank"">1801.00634</a>",,2025-12-03 22:39:25
Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey,"Naveed Akhtar, Ajmal Mian",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.00553"" target=""_blank"">1801.00553</a>",,2025-12-03 22:39:25
Rogue Signs: Deceiving Traffic Sign Recognition with Malicious Ads and Logos,"Chawin Sitawarin, Arjun Nitin Bhagoji, Arsalan Mosenia, Prateek Mittal, Mung Chiang",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.02780"" target=""_blank"">1801.02780</a>",,2025-12-03 22:39:25
Adversarial Spheres,"Justin Gilmer, Luke Metz, Fartash Faghri, Samuel S. Schoenholz, Maithra Raghu, Martin Wattenberg, Ian Goodfellow",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.02774"" target=""_blank"">1801.02774</a>",,2025-12-03 22:39:25
Did you hear that? Adversarial Examples Against Automatic Speech Recognition,"Moustafa Alzantot, Bharathan Balaji, Mani Srivastava",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.00554"" target=""_blank"">1801.00554</a>",,2025-12-03 22:39:25
Less is More: Culling the Training Set to Improve Robustness of Deep Neural Networks,"Yongshuai Liu, Jiyu Chen, Hao Chen",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.02850"" target=""_blank"">1801.02850</a>",,2025-12-03 22:39:25
Generalizable Data-free Objective for Crafting Universal Adversarial Perturbations,"Konda Reddy Mopuri, Aditya Ganeshan, R. Venkatesh Babu",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.08092"" target=""_blank"">1801.08092</a>",,2025-12-03 22:39:25
Adversarial Deep Learning for Robust Detection of Binary Encoded Malware,"Abdullah Al-Dujaili, Alex Huang, Erik Hemberg, Una-May O'Reilly",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.02950"" target=""_blank"">1801.02950</a>",,2025-12-03 22:39:25
Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach,"Tsui-Wei Weng, Huan Zhang, Pin-Yu Chen, Jinfeng Yi, Dong Su, Yupeng Gao, Cho-Jui Hsieh, Luca Daniel",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.10578"" target=""_blank"">1801.10578</a>",,2025-12-03 22:39:25
Robustness of classification ability of spiking neural networks,"Jie Yang, Pingping Zhang, Yan Liu",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.09827"" target=""_blank"">1801.09827</a>",,2025-12-03 22:39:25
Certified Defenses against Adversarial Examples,"Aditi Raghunathan, Jacob Steinhardt, Percy Liang",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.09344"" target=""_blank"">1801.09344</a>",,2025-12-03 22:39:25
Towards an Understanding of Neural Networks in Natural-Image Spaces,"Yifei Fan, Anthony Yezzi",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.09097"" target=""_blank"">1801.09097</a>",,2025-12-03 22:39:25
Learning to Evade Static PE Machine Learning Malware Models via Reinforcement Learning,"Hyrum S. Anderson, Anant Kharkar, Bobby Filar, David Evans, Phil Roth",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.08917"" target=""_blank"">1801.08917</a>",,2025-12-03 22:39:25
CommanderSong: A Systematic Approach for Practical Adversarial Voice Recognition,"Xuejing Yuan, Yuxuan Chen, Yue Zhao, Yunhui Long, Xiaokang Liu, Kai Chen, Shengzhi Zhang, Heqing Huang, Xiaofeng Wang, Carl A. Gunter",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.08535"" target=""_blank"">1801.08535</a>",,2025-12-03 22:39:25
Deflecting Adversarial Attacks with Pixel Deflection,"Aaditya Prakash, Nick Moran, Solomon Garber, Antonella DiLillo, James Storer",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.08926"" target=""_blank"">1801.08926</a>",,2025-12-03 22:39:25
Adversarial Texts with Gradient Methods,"Zhitao Gong, Wenlu Wang, Bo Li, Dawn Song, Wei-Shinn Ku",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.07175"" target=""_blank"">1801.07175</a>",,2025-12-03 22:39:25
A Comparative Study of Rule Extraction for Recurrent Neural Networks,"Qinglong Wang, Kaixuan Zhang, Alexander G. II Ororbia, Xinyu Xing, Xue Liu, C. Lee Giles",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.05420"" target=""_blank"">1801.05420</a>",,2025-12-03 22:39:25
Sparsity-based Defense against Adversarial Attacks on Linear Classifiers,"Zhinus Marzi, Soorya Gopalakrishnan, Upamanyu Madhow, Ramtin Pedarsani",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.04695"" target=""_blank"">1801.04695</a>",,2025-12-03 22:39:25
Towards Imperceptible and Robust Adversarial Example Attacks against Neural Networks,"Bo Luo, Yannan Liu, Lingxiao Wei, Qiang Xu",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.04693"" target=""_blank"">1801.04693</a>",,2025-12-03 22:39:25
Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers,"Ji Gao, Jack Lanchantin, Mary Lou Soffa, Yanjun Qi",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.04354"" target=""_blank"">1801.04354</a>",,2025-12-03 22:39:25
A3T: Adversarially Augmented Adversarial Training,"Akram Erraqabi, Aristide Baratin, Yoshua Bengio, Simon Lacoste-Julien",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.04055"" target=""_blank"">1801.04055</a>",,2025-12-03 22:39:25
Fooling End-to-end Speaker Verification by Adversarial Examples,"Felix Kreuk, Yossi Adi, Moustapha Cisse, Joseph Keshet",arXiv,2018-01,"<a href=""http://arxiv.org/abs/1801.03339"" target=""_blank"">1801.03339</a>",,2025-12-03 22:39:25
Defense against Adversarial Attacks Using High-Level Representation Guided Denoiser,"Fangzhou Liao, Ming Liang, Yinpeng Dong, Tianyu Pang, Xiaolin Hu, Jun Zhu",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.02976"" target=""_blank"">1712.02976</a>",,2025-12-03 22:39:25
DANCin SEQ2SEQ: Fooling Text Classifiers with Adversarial Text Example Generation,Catherine Wong,arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.05419"" target=""_blank"">1712.05419</a>",,2025-12-03 22:39:25
Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models,"Wieland Brendel, Jonas Rauber, Matthias Bethge",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.04248"" target=""_blank"">1712.04248</a>","<a href=""https://github.com/bethgelab/foolbox"" target=""_blank"">bethgelab</a>",2025-12-03 22:39:25
Training Ensembles to Detect Adversarial Examples,"Alexander Bagnall, Razvan Bunescu, Gordon Stewart",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.04006"" target=""_blank"">1712.04006</a>",,2025-12-03 22:39:25
Robust Deep Reinforcement Learning with Adversarial Attacks,"Anay Pattanaik, Zhenyi Tang, Shuijing Liu, Gautham Bommannan, Girish Chowdhary",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.03632"" target=""_blank"">1712.03632</a>",,2025-12-03 22:39:25
NAG: Network for Adversary Generation,"Konda Reddy Mopuri, Utkarsh Ojha, Utsav Garg, R. Venkatesh Babu",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.03390"" target=""_blank"">1712.03390</a>",,2025-12-03 22:39:25
Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning,"Battista Biggio, Fabio Roli",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.03141"" target=""_blank"">1712.03141</a>",,2025-12-03 22:39:25
"Where Classification Fails, Interpretation Rises","Chanh Nguyen, Georgi Georgiev, Yujie Ji, Ting Wang",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.00558"" target=""_blank"">1712.00558</a>",,2025-12-03 22:39:25
Adversarial Examples that Fool Detectors,"Jiajun Lu, Hussein Sibai, Evan Fabry",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.02494"" target=""_blank"">1712.02494</a>",,2025-12-03 22:39:25
Exploring the Landscape of Spatial Robustness,"Logan Engstrom, Brandon Tran, Dimitris Tsipras, Ludwig Schmidt, Aleksander Madry",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.02779"" target=""_blank"">1712.02779</a>","<a href=""https://github.com/MadryLab/adversarial_spatial"" target=""_blank"">MadryLab</a>",2025-12-03 22:39:25
Generative Adversarial Perturbations,"Omid Poursaeed, Isay Katsman, Bicheng Gao, Serge Belongie",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.02328"" target=""_blank"">1712.02328</a>",,2025-12-03 22:39:25
Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning,"Hongge Chen, Huan Zhang, Pin-Yu Chen, Jinfeng Yi, Cho-Jui Hsieh",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.02051"" target=""_blank"">1712.02051</a>",,2025-12-03 22:39:25
Towards Practical Verification of Machine Learning: The Case of Computer Vision Systems,"Kexin Pei, Linjie Zhu, Yinzhi Cao, Junfeng Yang, Carl Vondrick, Suman Jana",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.01785"" target=""_blank"">1712.01785</a>",,2025-12-03 22:39:25
Improving Network Robustness against Adversarial Attacks with Compact Convolution,"Rajeev Ranjan, Swami Sankaranarayanan, Carlos D. Castillo, Rama Chellappa",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.00699"" target=""_blank"">1712.00699</a>",,2025-12-03 22:39:25
Towards Robust Neural Networks via Random Self-ensemble,"Xuanqing Liu, Minhao Cheng, Huan Zhang, Cho-Jui Hsieh",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.00673"" target=""_blank"">1712.00673</a>",,2025-12-03 22:39:25
Super-sparse Learning in Similarity Spaces,"Ambra Demontis, Marco Melis, Battista Biggio, Giorgio Fumera, Fabio Roli",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.06131"" target=""_blank"">1712.06131</a>",,2025-12-03 22:39:25
"Attack and Defense of Dynamic Analysis-Based, Adversarial Neural Malware Classification Models","Jack W. Stokes, De Wang, Mady Marinescu, Marc Marino, Brian Bussone",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.05919"" target=""_blank"">1712.05919</a>",,2025-12-03 22:39:25
When Not to Classify: Anomaly Detection of Attacks (ADA) on DNN Classifiers at Test Time,"David J. Miller, Yulia Wang, George Kesidis",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.06646"" target=""_blank"">1712.06646</a>",,2025-12-03 22:39:25
Deep Neural Networks as 0-1 Mixed Integer Linear Programs: A Feasibility Study,"Matteo Fischetti, Jason Jo",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.06174"" target=""_blank"">1712.06174</a>",,2025-12-03 22:39:25
"Whatever Does Not Kill Deep Reinforcement Learning, Makes It Stronger","Vahid Behzadan, Arslan Munir",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.09344"" target=""_blank"">1712.09344</a>",,2025-12-03 22:39:25
Gradient Regularization Improves Accuracy of Discriminative Models,"Dániel Varga, Adrián Csiszárik, Zsolt Zombori",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.09936"" target=""_blank"">1712.09936</a>",,2025-12-03 22:39:25
HotFlip: White-Box Adversarial Examples for Text Classification,"Javid Ebrahimi, Anyi Rao, Daniel Lowd, Dejing Dou",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.06751"" target=""_blank"">1712.06751</a>",,2025-12-03 22:39:25
Exploring the Space of Black-box Attacks on Deep Neural Networks,"Arjun Nitin Bhagoji, Warren He, Bo Li, Dawn Song",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.09491"" target=""_blank"">1712.09491</a>",,2025-12-03 22:39:25
Building Robust Deep Neural Networks for Road Sign Detection,"Arkar Min Aung, Yousef Fadila, Radian Gondokaryono, Luis Gonzalez",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.09327"" target=""_blank"">1712.09327</a>",,2025-12-03 22:39:25
The Robust Manifold Defense: Adversarial Training using Generative Models,"Ajil Jalal, Andrew Ilyas, Constantinos Daskalakis, Alexandros G. Dimakis",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.09196"" target=""_blank"">1712.09196</a>","<a href=""https://github.com/ajiljalal/manifold-defense"" target=""_blank"">ajiljalal</a>",2025-12-03 22:39:25
Android Malware Detection using Deep Learning on API Method Sequences,"ElMouatez Billah Karbab, Mourad Debbabi, Abdelouahid Derhab, Djedjiga Mouheb",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.08996"" target=""_blank"">1712.08996</a>",,2025-12-03 22:39:25
Adversarial Patch,"Tom B. Brown, Dandelion Mané, Aurko Roy, Martín Abadi, Justin Gilmer",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.09665"" target=""_blank"">1712.09665</a>","<a href=""https://github.com/tensorflow/cleverhans/tree/master/examples/adversarial_patch"" target=""_blank"">examples</a>",2025-12-03 22:39:25
Query-limited Black-box Attacks to Classifiers,"Fnu Suya, Yuan Tian, David Evans, Paolo Papotti",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.08713"" target=""_blank"">1712.08713</a>",,2025-12-03 22:39:25
ReabsNet: Detecting and Revising Adversarial Examples,"Jiefeng Chen, Zihang Meng, Changtian Sun, Wei Tang, Yinglun Zhu",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.08250"" target=""_blank"">1712.08250</a>",,2025-12-03 22:39:25
Note on Attacking Object Detectors with Adversarial Stickers,"Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, Dawn Song, Tadayoshi Kohno, Amir Rahmati, Atul Prakash, Florian Tramer",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.08062"" target=""_blank"">1712.08062</a>",,2025-12-03 22:39:25
Wolf in Sheep's Clothing - The Downscaling Attack Against Deep Learning Applications,"Qixue Xiao, Kang Li, Deyue Zhang, Yier Jin",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.07805"" target=""_blank"">1712.07805</a>",,2025-12-03 22:39:25
Query-Efficient Black-box Adversarial Examples (superceded),"Andrew Ilyas, Logan Engstrom, Anish Athalye, Jessy Lin",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.07113"" target=""_blank"">1712.07113</a>",,2025-12-03 22:39:25
Adversarial Examples: Attacks and Defenses for Deep Learning,"Xiaoyong Yuan, Pan He, Qile Zhu, Xiaolin Li",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.07107"" target=""_blank"">1712.07107</a>",,2025-12-03 22:39:25
Using LIP to Gloss Over Faces in Single-Stage Face Detection Networks,"Siqi Yang, Arnold Wiliem, Shaokang Chen, Brian C. Lovell",arXiv,2017-12,"<a href=""http://arxiv.org/abs/1712.08263"" target=""_blank"">1712.08263</a>",,2025-12-03 22:39:25
Mitigating Adversarial Effects Through Randomization,"Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, Alan Yuille",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.01991"" target=""_blank"">1711.01991</a>","<a href=""https://github.com/cihangxie/NIPS2017_adv_challenge_defense"" target=""_blank"">cihangxie</a>",2025-12-03 22:39:25
The best defense is a good offense: Countering black box attacks by predicting slightly wrong labels,"Yannic Kilcher, Thomas Hofmann",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.05475"" target=""_blank"">1711.05475</a>",,2025-12-03 22:39:25
Machine vs Machine: Minimax-Optimal Defense Against Adversarial Examples,"Jihun Hamm, Akshay Mehra",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.04368"" target=""_blank"">1711.04368</a>",,2025-12-03 22:39:25
Crafting Adversarial Examples For Speech Paralinguistics Applications,"Yuan Gong, Christian Poellabauer",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.03280"" target=""_blank"">1711.03280</a>",,2025-12-03 22:39:25
Intriguing Properties of Adversarial Examples,"Ekin D. Cubuk, Barret Zoph, Samuel S. Schoenholz, Quoc V. Le",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.02846"" target=""_blank"">1711.02846</a>",,2025-12-03 22:39:25
Enhanced Attacks on Defensively Distilled Deep Neural Networks,"Yujia Liu, Weiming Zhang, Shaohua Li, Nenghai Yu",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.05934"" target=""_blank"">1711.05934</a>",,2025-12-03 22:39:25
The (Un)reliability of saliency methods,"Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber, Kristof T. Schütt, Sven Dähne, Dumitru Erhan, Been Kim",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.00867"" target=""_blank"">1711.00867</a>",,2025-12-03 22:39:25
HyperNetworks with statistical filtering for defending adversarial examples,"Zhun Sun, Mete Ozay, Takayuki Okatani",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.01791"" target=""_blank"">1711.01791</a>",,2025-12-03 22:39:25
Towards Reverse-Engineering Black-Box Neural Networks,"Seong Joon Oh, Max Augustin, Bernt Schiele, Mario Fritz",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.01768"" target=""_blank"">1711.01768</a>",,2025-12-03 22:39:25
Provable defenses against adversarial examples via the convex outer adversarial polytope,"Eric Wong, J. Zico Kolter",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.00851"" target=""_blank"">1711.00851</a>","<a href=""https://github.com/locuslab/convex_adversarial"" target=""_blank"">locuslab</a>",2025-12-03 22:39:25
Attacking Binarized Neural Networks,"Angus Galloway, Graham W. Taylor, Medhat Moussa",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.00449"" target=""_blank"">1711.00449</a>",,2025-12-03 22:39:25
Countering Adversarial Images using Input Transformations,"Chuan Guo, Mayank Rana, Moustapha Cisse, der Maaten Laurens van",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.00117"" target=""_blank"">1711.00117</a>",,2025-12-03 22:39:25
Defense against Universal Adversarial Perturbations,"Naveed Akhtar, Jian Liu, Ajmal Mian",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.05929"" target=""_blank"">1711.05929</a>",,2025-12-03 22:39:25
"MagNet and ""Efficient Defenses Against Adversarial Attacks"" are Not Robust to Adversarial Examples","Nicholas Carlini, David Wagner",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.08478"" target=""_blank"">1711.08478</a>",,2025-12-03 22:39:25
How Wrong Am I? - Studying Adversarial Examples and their Impact on Uncertainty in Gaussian Process Machine Learning Models,"Kathrin Grosse, David Pfaff, Michael Thomas Smith, Michael Backes",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.06598"" target=""_blank"">1711.06598</a>",,2025-12-03 22:39:25
Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients,"Andrew Slavin Ross, Finale Doshi-Velez",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.09404"" target=""_blank"">1711.09404</a>",,2025-12-03 22:39:25
Adversarial Attacks Beyond the Image Space,"Xiaohui Zeng, Chenxi Liu, Yu-Siang Wang, Weichao Qiu, Lingxi Xie, Yu-Wing Tai, Chi Keung Tang, Alan L. Yuille",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.07183"" target=""_blank"">1711.07183</a>",,2025-12-03 22:39:25
Measuring the tendency of CNNs to Learn Surface Statistical Regularities,"Jason Jo, Yoshua Bengio",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.11561"" target=""_blank"">1711.11561</a>",,2025-12-03 22:39:25
Adversary Detection in Neural Networks via Persistent Homology,"Thomas Gebhart, Paul Schrater",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.10056"" target=""_blank"">1711.10056</a>",,2025-12-03 22:39:25
Butterfly Effect: Bidirectional Control of Classification Performance by Small Additive Perturbation,"YoungJoon Yoo, Seonguk Park, Junyoung Choi, Sangdoo Yun, Nojun Kwak",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.09681"" target=""_blank"">1711.09681</a>",,2025-12-03 22:39:25
On the Robustness of Semantic Segmentation Models to Adversarial Attacks,"Anurag Arnab, Ondrej Miksik, Philip H. S. Torr",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.09856"" target=""_blank"">1711.09856</a>",,2025-12-03 22:39:25
Geometric robustness of deep networks: analysis and improvement,"Can Kanbak, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.09115"" target=""_blank"">1711.09115</a>",,2025-12-03 22:39:25
Safer Classification by Synthesis,"William Wang, Angelina Wang, Aviv Tamar, Xi Chen, Pieter Abbeel",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.08534"" target=""_blank"">1711.08534</a>",,2025-12-03 22:39:25
Adversarial Phenomenon in the Eyes of Bayesian Deep Learning,"Ambrish Rawat, Martin Wistuba, Maria-Irina Nicolae",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.08244"" target=""_blank"">1711.08244</a>",,2025-12-03 22:39:25
Reinforcing Adversarial Robustness using Model Confidence Induced by Adversarial Training,"Xi Wu, Uyeong Jang, Jiefeng Chen, Lingjiao Chen, Somesh Jha",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.08001"" target=""_blank"">1711.08001</a>",,2025-12-03 22:39:25
Evaluating Robustness of Neural Networks with Mixed Integer Programming,"Vincent Tjeng, Kai Xiao, Russ Tedrake",arXiv,2017-11,"<a href=""http://arxiv.org/abs/1711.07356"" target=""_blank"">1711.07356</a>",,2025-12-03 22:39:25
One pixel attack for fooling deep neural networks,"Jiawei Su, Danilo Vasconcellos Vargas, Sakurai Kouichi",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.08864"" target=""_blank"">1710.08864</a>",,2025-12-03 22:39:25
DeepSafe: A Data-driven Approach for Checking Adversarial Robustness in Neural Networks,"Divya Gopinath, Guy Katz, Corina S. Pasareanu, Clark Barrett",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.00486"" target=""_blank"">1710.00486</a>",,2025-12-03 22:39:25
Detecting Adversarial Attacks on Neural Network Policies with Visual Foresight,"Yen-Chen Lin, Ming-Yu Liu, Min Sun, Jia-Bin Huang",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.00814"" target=""_blank"">1710.00814</a>",,2025-12-03 22:39:25
Verification of Binarized Neural Networks via Inter-Neuron Factoring,"Chih-Hong Cheng, Georg Nührenberg, Chung-Hao Huang, Harald Ruess",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.03107"" target=""_blank"">1710.03107</a>",,2025-12-03 22:39:25
Game-Theoretic Design of Secure and Resilient Distributed Support Vector Machines with Adversaries,"Rui Zhang, Quanyan Zhu",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.04677"" target=""_blank"">1710.04677</a>",,2025-12-03 22:39:25
Boosting Adversarial Attacks with Momentum,"Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, Jianguo Li",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.06081"" target=""_blank"">1710.06081</a>",,2025-12-03 22:39:25
Feature-Guided Black-Box Safety Testing of Deep Neural Networks,"Matthew Wicker, Xiaowei Huang, Marta Kwiatkowska",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.07859"" target=""_blank"">1710.07859</a>",,2025-12-03 22:39:25
Standard detectors aren't (currently) fooled by physical adversarial stop signs,"Jiajun Lu, Hussein Sibai, Evan Fabry, David Forsyth",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.03337"" target=""_blank"">1710.03337</a>",,2025-12-03 22:39:25
mixup: Beyond Empirical Risk Minimization,"Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, David Lopez-Paz",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.09412"" target=""_blank"">1710.09412</a>",,2025-12-03 22:39:25
Interpretation of Neural Networks is Fragile,"Amirata Ghorbani, Abubakar Abid, James Zou",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.10547"" target=""_blank"">1710.10547</a>",,2025-12-03 22:39:25
Certifying Some Distributional Robustness with Principled Adversarial Training,"Aman Sinha, Hongseok Namkoong, Riccardo Volpi, John Duchi",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.10571"" target=""_blank"">1710.10571</a>",,2025-12-03 22:39:25
Conditional Variance Penalties and Domain Shift Robustness,"Christina Heinze-Deml, Nicolai Meinshausen",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.11469"" target=""_blank"">1710.11469</a>",,2025-12-03 22:39:25
Attacking the Madry Defense Model with $L_1$-based Adversarial Examples,"Yash Sharma, Pin-Yu Chen",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.10733"" target=""_blank"">1710.10733</a>",,2025-12-03 22:39:25
PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples,"Yang Song, Taesup Kim, Sebastian Nowozin, Stefano Ermon, Nate Kushman",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.10766"" target=""_blank"">1710.10766</a>",,2025-12-03 22:39:25
Generating Natural Adversarial Examples,"Zhengli Zhao, Dheeru Dua, Sameer Singh",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.11342"" target=""_blank"">1710.11342</a>",,2025-12-03 22:39:25
Adversarial Detection of Flash Malware: Limitations and Open Issues,"Davide Maiorca, Ambra Demontis, Battista Biggio, Fabio Roli, Giorgio Giacinto",arXiv,2017-10,"<a href=""http://arxiv.org/abs/1710.10225"" target=""_blank"">1710.10225</a>",,2025-12-03 22:39:25
EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples,"Pin-Yu Chen, Yash Sharma, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.04114"" target=""_blank"">1709.04114</a>",,2025-12-03 22:39:25
On Security and Sparsity of Linear Classifiers for Adversarial Settings,"Ambra Demontis, Paolo Russu, Battista Biggio, Giorgio Fumera, Fabio Roli",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.00045"" target=""_blank"">1709.00045</a>",,2025-12-03 22:39:25
Security Evaluation of Pattern Classifiers under Attack,"Battista Biggio, Giorgio Fumera, Fabio Roli",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.00609"" target=""_blank"">1709.00609</a>",,2025-12-03 22:39:25
DeepFense: Online Accelerated Defense Against Adversarial Deep Learning,"Bita Darvish Rouhani, Mohammad Samragh, Mojan Javaheripi, Tara Javidi, Farinaz Koushanfar",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.02538"" target=""_blank"">1709.02538</a>",,2025-12-03 22:39:25
Towards Proving the Adversarial Robustness of Deep Neural Networks,"Guy Stanford University Katz, Clark Stanford University Barrett, David L. Stanford University Dill, Kyle Stanford University Julian, Mykel J. Stanford University Kochenderfer",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.02802"" target=""_blank"">1709.02802</a>",,2025-12-03 22:39:25
Ensemble Methods as a Defense to Adversarial Perturbations Against Deep Neural Networks,"Thilo Strauss, Markus Hanselmann, Andrej Junginger, Holger Ulmer",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.03423"" target=""_blank"">1709.03423</a>",,2025-12-03 22:39:25
Art of singular vectors and universal adversarial perturbations,"Valentin Khrulkov, Ivan Oseledets",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.03582"" target=""_blank"">1709.03582</a>",,2025-12-03 22:39:25
A Learning and Masking Approach to Secure Learning,"Linh Nguyen, Sky Wang, Arunesh Sinha",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.04447"" target=""_blank"">1709.04447</a>",,2025-12-03 22:39:25
Models and Framework for Adversarial Attacks on Complex Adaptive Systems,"Vahid Behzadan, Arslan Munir",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.04137"" target=""_blank"">1709.04137</a>",,2025-12-03 22:39:25
Mitigating Evasion Attacks to Deep Neural Networks via Region-based Classification,"Xiaoyu Cao, Neil Zhenqiang Gong",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.05583"" target=""_blank"">1709.05583</a>",,2025-12-03 22:39:25
Verifying Properties of Binarized Deep Neural Networks,"Nina Narodytska, Shiva Prasad Kasiviswanathan, Leonid Ryzhyk, Mooly Sagiv, Toby Walsh",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.06662"" target=""_blank"">1709.06662</a>",,2025-12-03 22:39:25
Fooling Vision and Language Models Despite Localization and Attention Mechanism,"Xiaojun Xu, Xinyun Chen, Chang Liu, Anna Rohrbach, Trevor Darrell, Dawn Song",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.08693"" target=""_blank"">1709.08693</a>",,2025-12-03 22:39:25
Output Range Analysis for Deep Neural Networks,"Souradeep Dutta, Susmit Jha, Sriram Sanakaranarayanan, Ashish Tiwari",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.09130"" target=""_blank"">1709.09130</a>",,2025-12-03 22:39:25
DR,"Ferdinand Technische Universität Darmstadt, Germany Brasser, Srdjan ETH Zurich, Switzerland Capkun, Alexandra University of Würzburg Dmitrienko, Tommaso Technische Universität Darmstadt, Germany Frassetto, Kari ETH Zurich, Switzerland Kostiainen, Ahmad-Reza Technische Universität Darmstadt, Germany Sadeghi",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.09917"" target=""_blank"">1709.09917</a>",,2025-12-03 22:39:25
Provably Minimally-Distorted Adversarial Examples,"Nicholas Carlini, Guy Katz, Clark Barrett, David L. Dill",arXiv,2017-09,"<a href=""http://arxiv.org/abs/1709.10207"" target=""_blank"">1709.10207</a>",,2025-12-03 22:39:25
Towards Interpretable Deep Neural Networks by Leveraging Adversarial Examples,"Yinpeng Dong, Hang Su, Jun Zhu, Fan Bao",arXiv,2017-08,"<a href=""http://arxiv.org/abs/1708.05493"" target=""_blank"">1708.05493</a>",,2025-12-03 22:39:25
Adversarial-Playground: A Visualization Suite Showing How Adversarial Examples Fool Deep Learning,"Andrew P. Norton, Yanjun Qi",arXiv,2017-08,"<a href=""http://arxiv.org/abs/1708.00807"" target=""_blank"">1708.00807</a>","<a href=""https://github.com/QData/AdversarialDNN-Playground"" target=""_blank"">QData</a>",2025-12-03 22:39:25
Adversarial Robustness: Softmax versus Openmax,"Andras Rozsa, Manuel Günther, Terrance E. Boult",arXiv,2017-08,"<a href=""http://arxiv.org/abs/1708.01697"" target=""_blank"">1708.01697</a>",,2025-12-03 22:39:25
Cascade Adversarial Machine Learning Regularized with a Unified Embedding,"Taesik Na, Jong Hwan Ko, Saibal Mukhopadhyay",arXiv,2017-08,"<a href=""http://arxiv.org/abs/1708.02582"" target=""_blank"">1708.02582</a>",,2025-12-03 22:39:25
ZOO: Zeroth Order Optimization based Black-box Attacks to Deep Neural Networks without Training Substitute Models,"Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, Cho-Jui Hsieh",arXiv,2017-08,"<a href=""http://arxiv.org/abs/1708.03999"" target=""_blank"">1708.03999</a>",,2025-12-03 22:39:25
Attacking Automatic Video Analysis Algorithms: A Case Study of Google Cloud Video Intelligence API,"Hossein Hosseini, Baicen Xiao, Andrew Clark, Radha Poovendran",arXiv,2017-08,"<a href=""http://arxiv.org/abs/1708.04301"" target=""_blank"">1708.04301</a>",,2025-12-03 22:39:25
Learning Universal Adversarial Perturbations with Generative Models,"Jamie Hayes, George Danezis",arXiv,2017-08,"<a href=""http://arxiv.org/abs/1708.05207"" target=""_blank"">1708.05207</a>",,2025-12-03 22:39:25
Evasion Attacks against Machine Learning at Test Time,"Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim Srndic, Pavel Laskov, Giorgio Giacinto, Fabio Roli",arXiv,2017-08,"<a href=""http://arxiv.org/abs/1708.06131"" target=""_blank"">1708.06131</a>",,2025-12-03 22:39:25
CNN Fixations: An unraveling approach to visualize the discriminative image regions,"Konda Reddy Mopuri, Utsav Garg, R. Venkatesh Babu",arXiv,2017-08,"<a href=""http://arxiv.org/abs/1708.06670"" target=""_blank"">1708.06670</a>",,2025-12-03 22:39:25
Is Deep Learning Safe for Robot Vision? Adversarial Examples against the iCub Humanoid,"Marco Melis, Ambra Demontis, Battista Biggio, Gavin Brown, Giorgio Fumera, Fabio Roli",arXiv,2017-08,"<a href=""http://arxiv.org/abs/1708.06939"" target=""_blank"">1708.06939</a>",,2025-12-03 22:39:25
Improving Robustness of ML Classifiers against Realizable Evasion Attacks Using Conserved Features,"Liang Tong, Bo Li, Chen Hajaj, Chaowei Xiao, Ning Zhang, Yevgeniy Vorobeychik",arXiv,2017-08,"<a href=""http://arxiv.org/abs/1708.08327"" target=""_blank"">1708.08327</a>",,2025-12-03 22:39:25
DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous Cars,"Yuchi Tian, Kexin Pei, Suman Jana, Baishakhi Ray",arXiv,2017-08,"<a href=""http://arxiv.org/abs/1708.08559"" target=""_blank"">1708.08559</a>",,2025-12-03 22:39:25
Practical Attacks Against Graph-based Clustering,"Yizheng Chen, Yacin Nadji, Athanasios Kountouras, Fabian Monrose, Roberto Perdisci, Manos Antonakakis, Nikolaos Vasiloglou",arXiv,2017-08,"<a href=""http://arxiv.org/abs/1708.09056"" target=""_blank"">1708.09056</a>",,2025-12-03 22:39:25
Be Selfish and Avoid Dilemmas: Fork After Withholding (FAW) Attacks on Bitcoin,"Yujin Kwon, Dohyun Kim, Yunmok Son, Eugene Vasserman, Yongdae Kim",arXiv,2017-08,"<a href=""http://arxiv.org/abs/1708.09790"" target=""_blank"">1708.09790</a>",,2025-12-03 22:39:25
APE-GAN: Adversarial Perturbation Elimination with GAN,"Shiwei Shen, Guoqing Jin, Ke Gao, Yongdong Zhang",arXiv,2017-07,"<a href=""http://arxiv.org/abs/1707.05474"" target=""_blank"">1707.05474</a>",,2025-12-03 22:39:25
UPSET and ANGRI : Breaking High Performance Image Classifiers,"Sayantan Sarkar, Ankan Bansal, Upal Mahbub, Rama Chellappa",arXiv,2017-07,"<a href=""http://arxiv.org/abs/1707.01159"" target=""_blank"">1707.01159</a>",,2025-12-03 22:39:25
Towards Crafting Text Adversarial Samples,"Suranjana Samanta, Sameep Mehta",arXiv,2017-07,"<a href=""http://arxiv.org/abs/1707.02812"" target=""_blank"">1707.02812</a>",,2025-12-03 22:39:25
A Survey on Resilient Machine Learning,"Atul Kumar, Sameep Mehta",arXiv,2017-07,"<a href=""http://arxiv.org/abs/1707.03184"" target=""_blank"">1707.03184</a>",,2025-12-03 22:39:25
NO Need to Worry about Adversarial Examples in Object Detection in Autonomous Vehicles,"Jiajun Lu, Hussein Sibai, Evan Fabry, David Forsyth",arXiv,2017-07,"<a href=""http://arxiv.org/abs/1707.03501"" target=""_blank"">1707.03501</a>",,2025-12-03 22:39:25
Foolbox: A Python toolbox to benchmark the robustness of machine learning models,"Jonas Rauber, Wieland Brendel, Matthias Bethge",arXiv,2017-07,"<a href=""http://arxiv.org/abs/1707.04131"" target=""_blank"">1707.04131</a>","<a href=""https://github.com/bethgelab/foolbox"" target=""_blank"">bethgelab</a>",2025-12-03 22:39:25
Houdini: Fooling Deep Structured Prediction Models,"Moustapha Cisse, Yossi Adi, Natalia Neverova, Joseph Keshet",arXiv,2017-07,"<a href=""http://arxiv.org/abs/1707.05373"" target=""_blank"">1707.05373</a>",,2025-12-03 22:39:25
Efficient Defenses Against Adversarial Attacks,"Valentina Zantedeschi, Maria-Irina Nicolae, Ambrish Rawat",arXiv,2017-07,"<a href=""http://arxiv.org/abs/1707.06728"" target=""_blank"">1707.06728</a>",,2025-12-03 22:39:25
Fast Feature Fool: A data independent approach to universal adversarial perturbations,"Konda Reddy Mopuri, Utsav Garg, R. Venkatesh Babu",arXiv,2017-07,"<a href=""http://arxiv.org/abs/1707.05572"" target=""_blank"">1707.05572</a>",,2025-12-03 22:39:25
Generic Black-Box End-to-End Attack Against State of the Art API Call Based Malware Classifiers,"Ishai Rosenberg, Asaf Shabtai, Lior Rokach, Yuval Elovici",arXiv,2017-07,"<a href=""http://arxiv.org/abs/1707.05970"" target=""_blank"">1707.05970</a>",,2025-12-03 22:39:25
Confidence estimation in Deep Neural networks via density modelling,"Akshayvarun Subramanya, Suraj Srinivas, R. Venkatesh Babu",arXiv,2017-07,"<a href=""http://arxiv.org/abs/1707.07013"" target=""_blank"">1707.07013</a>",,2025-12-03 22:39:25
Adversarial Examples for Evaluating Reading Comprehension Systems,"Robin Jia, Percy Liang",arXiv,2017-07,"<a href=""http://arxiv.org/abs/1707.07328"" target=""_blank"">1707.07328</a>",,2025-12-03 22:39:25
Synthesizing Robust Adversarial Examples,"Anish Athalye, Logan Engstrom, Andrew Ilyas, Kevin Kwok",arXiv,2017-07,"<a href=""http://arxiv.org/abs/1707.07397"" target=""_blank"">1707.07397</a>",,2025-12-03 22:39:25
Robust Physical-World Attacks on Deep Learning Models,"Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, Amir Rahmati, Chaowei Xiao, Atul Prakash, Tadayoshi Kohno, Dawn Song",arXiv,2017-07,"<a href=""http://arxiv.org/abs/1707.08945"" target=""_blank"">1707.08945</a>",,2025-12-03 22:39:25
Analyzing the Robustness of Nearest Neighbors to Adversarial Examples,"Yizhen Wang, Somesh Jha, Kamalika Chaudhuri",arXiv,2017-06,"<a href=""http://arxiv.org/abs/1706.03922"" target=""_blank"">1706.03922</a>",,2025-12-03 22:39:25
Adversarial-Playground: A Visualization Suite for Adversarial Sample Generation,"Andrew Norton, Yanjun Qi",arXiv,2017-06,"<a href=""http://arxiv.org/abs/1706.01763"" target=""_blank"">1706.01763</a>","<a href=""https://github.com/QData/AdversarialDNN-Playground"" target=""_blank"">QData</a>",2025-12-03 22:39:25
Towards Robust Detection of Adversarial Examples,"Tianyu Pang, Chao Du, Yinpeng Dong, Jun Zhu",arXiv,2017-06,"<a href=""http://arxiv.org/abs/1706.00633"" target=""_blank"">1706.00633</a>",,2025-12-03 22:39:25
Adversarial Example Defenses: Ensembles of Weak Defenses are not Strong,"Warren He, James Wei, Xinyun Chen, Nicholas Carlini, Dawn Song",arXiv,2017-06,"<a href=""http://arxiv.org/abs/1706.04701"" target=""_blank"">1706.04701</a>",,2025-12-03 22:39:25
Comparing deep neural networks against humans: object recognition when the signal gets weaker,"Robert Geirhos, David H. J. Janssen, Heiko H. Schütt, Jonas Rauber, Matthias Bethge, Felix A. Wichmann",arXiv,2017-06,"<a href=""http://arxiv.org/abs/1706.06969"" target=""_blank"">1706.06969</a>",,2025-12-03 22:39:25
Towards Deep Learning Models Resistant to Adversarial Attacks,"Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu",arXiv,2017-06,"<a href=""http://arxiv.org/abs/1706.06083"" target=""_blank"">1706.06083</a>","<a href=""https://github.com/MadryLab/mnist_challenge"" target=""_blank"">MadryLab</a>",2025-12-03 22:39:25
Evading Classifiers by Morphing in the Dark,"Hung Dang, Yue Huang, Ee-Chien Chang",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.07535"" target=""_blank"">1705.07535</a>",,2025-12-03 22:39:25
Detecting Adversarial Samples Using Density Ratio Estimates,Lovedeep Gondara,arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.02224"" target=""_blank"">1705.02224</a>",,2025-12-03 22:39:25
Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression,"Nilaksh Das, Madhuri Shanbhogue, Shang-Tse Chen, Fred Hohman, Li Chen, Michael E. Kounavis, Duen Horng Chau",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.02900"" target=""_blank"">1705.02900</a>",,2025-12-03 22:39:25
Generative Adversarial Trainer: Defense to Adversarial Perturbations with GAN,"Hyeungill Lee, Sungyeob Han, Jungwoo Lee",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.03387"" target=""_blank"">1705.03387</a>",,2025-12-03 22:39:25
Extending Defensive Distillation,"Nicolas Papernot, Patrick McDaniel",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.05264"" target=""_blank"">1705.05264</a>",,2025-12-03 22:39:25
Delving into adversarial attacks on deep policies,"Jernej Kos, Dawn Song",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.06452"" target=""_blank"">1705.06452</a>",,2025-12-03 22:39:25
DeepXplore: Automated Whitebox Testing of Deep Learning Systems,"Kexin Pei, Yinzhi Cao, Junfeng Yang, Suman Jana",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.06640"" target=""_blank"">1705.06640</a>",,2025-12-03 22:39:25
MTDeep: Boosting the Security of Deep Neural Nets Against Adversarial Attacks with Moving Target Defense,"Sailik Sengupta, Tathagata Chakraborti, Subbarao Kambhampati",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.07213"" target=""_blank"">1705.07213</a>",,2025-12-03 22:39:25
Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods,"Nicholas Carlini, David Wagner",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.07263"" target=""_blank"">1705.07263</a>",,2025-12-03 22:39:25
Ensemble Adversarial Training: Attacks and Defenses,"Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, Patrick McDaniel",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.07204"" target=""_blank"">1705.07204</a>",,2025-12-03 22:39:25
Regularizing deep networks using efficient layerwise adversarial training,"Swami Sankaranarayanan, Arpit Jain, Rama Chellappa, Ser Nam Lim",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.07819"" target=""_blank"">1705.07819</a>",,2025-12-03 22:39:25
Black-Box Attacks against RNN based Malware Detection Algorithms,"Weiwei Hu, Ying Tan",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.08131"" target=""_blank"">1705.08131</a>",,2025-12-03 22:39:25
Detecting Adversarial Image Examples in Deep Networks with Adaptive Noise Reduction,"Bin Liang, Hongcheng Li, Miaoqiang Su, Xirong Li, Wenchang Shi, Xiaofeng Wang",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.08378"" target=""_blank"">1705.08378</a>",,2025-12-03 22:39:25
Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation,"Matthias Hein, Maksym Andriushchenko",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.08475"" target=""_blank"">1705.08475</a>",,2025-12-03 22:39:25
MagNet: a Two-Pronged Defense against Adversarial Examples,"Dongyu Meng, Hao Chen",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.09064"" target=""_blank"">1705.09064</a>",,2025-12-03 22:39:25
Robustness of classifiers to universal perturbations: a geometric perspective,"Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, Pascal Frossard, Stefano Soatto",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.09554"" target=""_blank"">1705.09554</a>",,2025-12-03 22:39:25
Classification regions of deep neural networks,"Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard, Stefano Soatto",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.09552"" target=""_blank"">1705.09552</a>",,2025-12-03 22:39:25
MAT: A Multi-strength Adversarial Training Method to Mitigate Adversarial Attacks,"Chang Song, Hsin-Pai Cheng, Huanrui Yang, Sicheng Li, Chunpeng Wu, Qing Wu, Hai Li, Yiran Chen",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.09764"" target=""_blank"">1705.09764</a>",,2025-12-03 22:39:25
Feature Squeezing Mitigates and Detects Carlini/Wagner Adversarial Examples,"Weilin Xu, David Evans, Yanjun Qi",arXiv,2017-05,"<a href=""http://arxiv.org/abs/1705.10686"" target=""_blank"">1705.10686</a>",,2025-12-03 22:39:25
SafetyNet: Detecting and Rejecting Adversarial Examples Robustly,"Jiajun Lu, Theerasit Issaranon, David Forsyth",arXiv,2017-04,"<a href=""http://arxiv.org/abs/1704.00103"" target=""_blank"">1704.00103</a>",,2025-12-03 22:39:25
Interpretable Explanations of Black Boxes by Meaningful Perturbation,"Ruth Fong, Andrea Vedaldi",arXiv,2017-04,"<a href=""http://arxiv.org/abs/1704.03296"" target=""_blank"">1704.03296</a>",,2025-12-03 22:39:25
Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks,"Weilin Xu, David Evans, Yanjun Qi",arXiv,2017-04,"<a href=""http://arxiv.org/abs/1704.01155"" target=""_blank"">1704.01155</a>",,2025-12-03 22:39:25
"Comment on ""Biologically inspired protection of deep networks from adversarial attacks""","Wieland Brendel, Matthias Bethge",arXiv,2017-04,"<a href=""http://arxiv.org/abs/1704.01547"" target=""_blank"">1704.01547</a>",,2025-12-03 22:39:25
Adequacy of the Gradient-Descent Method for Classifier Evasion Attacks,"Yi Han, Benjamin I. P. Rubinstein",arXiv,2017-04,"<a href=""http://arxiv.org/abs/1704.01704"" target=""_blank"">1704.01704</a>",,2025-12-03 22:39:25
Enhancing Robustness of Machine Learning Systems via Data Transformations,"Arjun Nitin Bhagoji, Daniel Cullina, Chawin Sitawarin, Prateek Mittal",arXiv,2017-04,"<a href=""http://arxiv.org/abs/1704.02654"" target=""_blank"">1704.02654</a>",,2025-12-03 22:39:25
Parseval Networks: Improving Robustness to Adversarial Examples,"Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, Nicolas Usunier",arXiv,2017-04,"<a href=""http://arxiv.org/abs/1704.08847"" target=""_blank"">1704.08847</a>",,2025-12-03 22:39:25
The Space of Transferable Adversarial Examples,"Florian Tramèr, Nicolas Papernot, Ian Goodfellow, Dan Boneh, Patrick McDaniel",arXiv,2017-04,"<a href=""http://arxiv.org/abs/1704.03453"" target=""_blank"">1704.03453</a>",,2025-12-03 22:39:25
Deep Text Classification Can be Fooled,"Bin Liang, Hongcheng Li, Miaoqiang Su, Pan Bian, Xirong Li, Wenchang Shi",arXiv,2017-04,"<a href=""http://arxiv.org/abs/1704.08006"" target=""_blank"">1704.08006</a>",,2025-12-03 22:39:25
"Yes, Machine Learning Can Be More Secure! A Case Study on Android Malware Detection","Ambra Demontis, Marco Melis, Battista Biggio, Davide Maiorca, Daniel Arp, Konrad Rieck, Igino Corona, Giorgio Giacinto, Fabio Roli",arXiv,2017-04,"<a href=""http://arxiv.org/abs/1704.08996"" target=""_blank"">1704.08996</a>",,2025-12-03 22:39:25
Google's Cloud Vision API Is Not Robust To Noise,"Hossein Hosseini, Baicen Xiao, Radha Poovendran",arXiv,2017-04,"<a href=""http://arxiv.org/abs/1704.05051"" target=""_blank"">1704.05051</a>",,2025-12-03 22:39:25
Universal Adversarial Perturbations Against Semantic Image Segmentation,"Jan Hendrik Metzen, Mummadi Chaithanya Kumar, Thomas Brox, Volker Fischer",arXiv,2017-04,"<a href=""http://arxiv.org/abs/1704.05712"" target=""_blank"">1704.05712</a>",,2025-12-03 22:39:25
Adversarial and Clean Data Are Not Twins,"Zhitao Gong, Wenlu Wang, Wei-Shinn Ku",arXiv,2017-04,"<a href=""http://arxiv.org/abs/1704.04960"" target=""_blank"">1704.04960</a>",,2025-12-03 22:39:25
Adversarial Transformation Networks: Learning to Generate Adversarial Examples,"Shumeet Baluja, Ian Fischer",arXiv,2017-03,"<a href=""http://arxiv.org/abs/1703.09387"" target=""_blank"">1703.09387</a>",,2025-12-03 22:39:25
Biologically inspired protection of deep networks from adversarial attacks,"Aran Nayebi, Surya Ganguli",arXiv,2017-03,"<a href=""http://arxiv.org/abs/1703.09202"" target=""_blank"">1703.09202</a>",,2025-12-03 22:39:25
Detecting Adversarial Samples from Artifacts,"Reuben Feinman, Ryan R. Curtin, Saurabh Shintre, Andrew B. Gardner",arXiv,2017-03,"<a href=""http://arxiv.org/abs/1703.00410"" target=""_blank"">1703.00410</a>",,2025-12-03 22:39:25
Compositional Falsification of Cyber-Physical Systems with Machine Learning Components,"Tommaso Dreossi, Alexandre Donzé, Sanjit A. Seshia",arXiv,2017-03,"<a href=""http://arxiv.org/abs/1703.00978"" target=""_blank"">1703.00978</a>",,2025-12-03 22:39:25
Adversarial Examples for Semantic Image Segmentation,"Volker Fischer, Mummadi Chaithanya Kumar, Jan Hendrik Metzen, Thomas Brox",arXiv,2017-03,"<a href=""http://arxiv.org/abs/1703.01101"" target=""_blank"">1703.01101</a>",,2025-12-03 22:39:25
Tactics of Adversarial Attack on Deep Reinforcement Learning Agents,"Yen-Chen Lin, Zhang-Wei Hong, Yuan-Hong Liao, Meng-Li Shih, Ming-Yu Liu, Min Sun",arXiv,2017-03,"<a href=""http://arxiv.org/abs/1703.06748"" target=""_blank"">1703.06748</a>",,2025-12-03 22:39:25
Blocking Transferability of Adversarial Examples in Black-Box Learning Systems,"Hossein Hosseini, Yize Chen, Sreeram Kannan, Baosen Zhang, Radha Poovendran",arXiv,2017-03,"<a href=""http://arxiv.org/abs/1703.04318"" target=""_blank"">1703.04318</a>",,2025-12-03 22:39:25
On the Limitation of Convolutional Neural Networks in Recognizing Negative Images,"Hossein Hosseini, Baicen Xiao, Mayoore Jaiswal, Radha Poovendran",arXiv,2017-03,"<a href=""http://arxiv.org/abs/1703.06857"" target=""_blank"">1703.06857</a>",,2025-12-03 22:39:25
Data Driven Exploratory Attacks on Black Box Classifiers in Adversarial Domains,"Tegjyot Singh Sethi, Mehmed Kantardzic",arXiv,2017-03,"<a href=""http://arxiv.org/abs/1703.07909"" target=""_blank"">1703.07909</a>",,2025-12-03 22:39:25
Self corrective Perturbations for Semantic Segmentation and Classification,"Swami Sankaranarayanan, Arpit Jain, Ser Nam Lim",arXiv,2017-03,"<a href=""http://arxiv.org/abs/1703.07928"" target=""_blank"">1703.07928</a>",,2025-12-03 22:39:25
Adversarial Examples for Semantic Segmentation and Object Detection,"Cihang Xie, Jianyu Wang, Zhishuai Zhang, Yuyin Zhou, Lingxi Xie, Alan Yuille",arXiv,2017-03,"<a href=""http://arxiv.org/abs/1703.08603"" target=""_blank"">1703.08603</a>",,2025-12-03 22:39:25
Deceiving Google's Cloud Video Intelligence API Built for Summarizing Videos,"Hossein Hosseini, Baicen Xiao, Radha Poovendran",arXiv,2017-03,"<a href=""http://arxiv.org/abs/1703.09793"" target=""_blank"">1703.09793</a>",,2025-12-03 22:39:25
Fraternal Twins: Unifying Attacks on Machine Learning and Digital Watermarking,"Erwin Quiring, Daniel Arp, Konrad Rieck",arXiv,2017-03,"<a href=""http://arxiv.org/abs/1703.05561"" target=""_blank"">1703.05561</a>",,2025-12-03 22:39:25
On the (Statistical) Detection of Adversarial Examples,"Kathrin Grosse, Praveen Manoharan, Nicolas Papernot, Michael Backes, Patrick McDaniel",arXiv,2017-02,"<a href=""http://arxiv.org/abs/1702.06280"" target=""_blank"">1702.06280</a>",,2025-12-03 22:39:25
Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks,"Guy Katz, Clark Barrett, David Dill, Kyle Julian, Mykel Kochenderfer",arXiv,2017-02,"<a href=""http://arxiv.org/abs/1702.01135"" target=""_blank"">1702.01135</a>",,2025-12-03 22:39:25
Adversarial Attacks on Neural Network Policies,"Sandy Huang, Nicolas Papernot, Ian Goodfellow, Yan Duan, Pieter Abbeel",arXiv,2017-02,"<a href=""http://arxiv.org/abs/1702.02284"" target=""_blank"">1702.02284</a>",,2025-12-03 22:39:25
On Detecting Adversarial Perturbations,"Jan Hendrik Metzen, Tim Genewein, Volker Fischer, Bastian Bischoff",arXiv,2017-02,"<a href=""http://arxiv.org/abs/1702.04267"" target=""_blank"">1702.04267</a>",,2025-12-03 22:39:25
Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN,"Weiwei Hu, Ying Tan",arXiv,2017-02,"<a href=""http://arxiv.org/abs/1702.05983"" target=""_blank"">1702.05983</a>",,2025-12-03 22:39:25
DeepCloak: Masking Deep Neural Network Models for Robustness Against Adversarial Samples,"Ji Gao, Beilun Wang, Zeming Lin, Weilin Xu, Yanjun Qi",arXiv,2017-02,"<a href=""http://arxiv.org/abs/1702.06763"" target=""_blank"">1702.06763</a>",,2025-12-03 22:39:25
Robustness to Adversarial Examples through an Ensemble of Specialists,"Mahdieh Abbasi, Christian Gagné",arXiv,2017-02,"<a href=""http://arxiv.org/abs/1702.06856"" target=""_blank"">1702.06856</a>",,2025-12-03 22:39:25
Deceiving Google's Perspective API Built for Detecting Toxic Comments,"Hossein Hosseini, Sreeram Kannan, Baosen Zhang, Radha Poovendran",arXiv,2017-02,"<a href=""http://arxiv.org/abs/1702.08138"" target=""_blank"">1702.08138</a>",,2025-12-03 22:39:25
Adversarial examples for generative models,"Jernej Kos, Ian Fischer, Dawn Song",arXiv,2017-02,"<a href=""http://arxiv.org/abs/1702.06832"" target=""_blank"">1702.06832</a>",,2025-12-03 22:39:25
Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks,"Vahid Behzadan, Arslan Munir",arXiv,2017-01,"<a href=""http://arxiv.org/abs/1701.04143"" target=""_blank"">1701.04143</a>",,2025-12-03 22:39:25
Dense Associative Memory is Robust to Adversarial Inputs,"Dmitry Krotov, John J Hopfield",arXiv,2017-01,"<a href=""http://arxiv.org/abs/1701.00939"" target=""_blank"">1701.00939</a>",,2025-12-03 22:39:25
A Theoretical Framework for Robustness of (Deep) Classifiers against Adversarial Examples,"Beilun Wang, Ji Gao, Yanjun Qi",arXiv,2016-12,"<a href=""http://arxiv.org/abs/1612.00334"" target=""_blank"">1612.00334</a>",,2025-12-03 22:39:25
Towards Robust Deep Neural Networks with BANG,"Andras Rozsa, Manuel Gunther, Terrance E. Boult",arXiv,2016-12,"<a href=""http://arxiv.org/abs/1612.00138"" target=""_blank"">1612.00138</a>",,2025-12-03 22:39:25
Deep Variational Information Bottleneck,"Alexander A. Alemi, Ian Fischer, Joshua V. Dillon, Kevin Murphy",arXiv,2016-12,"<a href=""http://arxiv.org/abs/1612.00410"" target=""_blank"">1612.00410</a>",,2025-12-03 22:39:25
Adversarial Images for Variational Autoencoders,"Pedro Tabacof, Julia Tavares, Eduardo Valle",arXiv,2016-12,"<a href=""http://arxiv.org/abs/1612.00155"" target=""_blank"">1612.00155</a>",,2025-12-03 22:39:25
Learning Adversary-Resistant Deep Neural Networks,"Qinglong Wang, Wenbo Guo, Kaixuan Zhang, Alexander G. II Ororbia, Xinyu Xing, Xue Liu, C. Lee Giles",arXiv,2016-12,"<a href=""http://arxiv.org/abs/1612.01401"" target=""_blank"">1612.01401</a>",,2025-12-03 22:39:25
Simple Black-Box Adversarial Perturbations for Deep Networks,"Nina Narodytska, Shiva Prasad Kasiviswanathan",arXiv,2016-12,"<a href=""http://arxiv.org/abs/1612.06299"" target=""_blank"">1612.06299</a>",,2025-12-03 22:39:25
Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics,"Xin Li, Fuxin Li",arXiv,2016-12,"<a href=""http://arxiv.org/abs/1612.07767"" target=""_blank"">1612.07767</a>",,2025-12-03 22:39:25
LOTS about Attacking Deep Features,"Andras Rozsa, Manuel Günther, Terrance E. Boult",arXiv,2016-11,"<a href=""http://arxiv.org/abs/1611.06179"" target=""_blank"">1611.06179</a>",,2025-12-03 22:39:25
AdversariaLib: An Open-source Library for the Security Evaluation of Machine Learning Algorithms Under Attack,"Igino Corona, Battista Biggio, Davide Maiorca",arXiv,2016-11,"<a href=""http://arxiv.org/abs/1611.04786"" target=""_blank"">1611.04786</a>",,2025-12-03 22:39:25
Towards the Science of Security and Privacy in Machine Learning,"Nicolas Papernot, Patrick McDaniel, Arunesh Sinha, Michael Wellman",arXiv,2016-11,"<a href=""http://arxiv.org/abs/1611.03814"" target=""_blank"">1611.03814</a>",,2025-12-03 22:39:25
Delving into Transferable Adversarial Examples and Black-box Attacks,"Yanpei Liu, Xinyun Chen, Chang Liu, Dawn Song",arXiv,2016-11,"<a href=""http://arxiv.org/abs/1611.02770"" target=""_blank"">1611.02770</a>",,2025-12-03 22:39:25
Adversarial Machine Learning at Scale,"Alexey Kurakin, Ian Goodfellow, Samy Bengio",arXiv,2016-11,"<a href=""http://arxiv.org/abs/1611.01236"" target=""_blank"">1611.01236</a>",,2025-12-03 22:39:25
Technical Report on the CleverHans v2,"Nicolas Papernot, Fartash Faghri, Nicholas Carlini, Ian Goodfellow, Reuben Feinman, Alexey Kurakin, Cihang Xie, Yash Sharma, Tom Brown, Aurko Roy, Alexander Matyasko, Vahid Behzadan, Karen Hambardzumyan, Zhishuai Zhang, Yi-Lin Juang, Zhi Li, Ryan Sheatsley, Abhibhav Garg, Jonathan Uesato, Willi Gierke, Yinpeng Dong, David Berthelot, Paul Hendricks, Jonas Rauber, Rujun Long, Patrick McDaniel",arXiv,2016-10,"<a href=""http://arxiv.org/abs/1610.00768"" target=""_blank"">1610.00768</a>",,2025-12-03 22:39:25
Adversary Resistant Deep Neural Networks with an Application to Malware Detection,"Qinglong Wang, Wenbo Guo, Kaixuan Zhang, Alexander G. II Ororbia, Xinyu Xing, C. Lee Giles, Xue Liu",arXiv,2016-10,"<a href=""http://arxiv.org/abs/1610.01239"" target=""_blank"">1610.01239</a>",,2025-12-03 22:39:25
Assessing Threat of Adversarial Examples on Deep Neural Networks,"Abigail Graese, Andras Rozsa, Terrance E. Boult",arXiv,2016-10,"<a href=""http://arxiv.org/abs/1610.04256"" target=""_blank"">1610.04256</a>",,2025-12-03 22:39:25
Using Non-invertible Data Transformations to Build Adversarial-Robust Neural Networks,"Qinglong Wang, Wenbo Guo, Alexander G. II Ororbia, Xinyu Xing, Lin Lin, C. Lee Giles, Xue Liu, Peng Liu, Gang Xiong",arXiv,2016-10,"<a href=""http://arxiv.org/abs/1610.01934"" target=""_blank"">1610.01934</a>",,2025-12-03 22:39:25
Are Accuracy and Robustness Correlated?,"Andras Rozsa, Manuel Günther, Terrance E. Boult",arXiv,2016-10,"<a href=""http://arxiv.org/abs/1610.04563"" target=""_blank"">1610.04563</a>",,2025-12-03 22:39:25
Safety Verification of Deep Neural Networks,"Xiaowei Huang, Marta Kwiatkowska, Sen Wang, Min Wu",arXiv,2016-10,"<a href=""http://arxiv.org/abs/1610.06940"" target=""_blank"">1610.06940</a>",,2025-12-03 22:39:25
Universal adversarial perturbations,"Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, Pascal Frossard",arXiv,2016-10,"<a href=""http://arxiv.org/abs/1610.08401"" target=""_blank"">1610.08401</a>",,2025-12-03 22:39:25
Statistical Meta-Analysis of Presentation Attacks for Secure Multibiometric Systems,"Battista Biggio, Giorgio Fumera, Gian Luca Marcialis, Fabio Roli",arXiv,2016-09,"<a href=""http://arxiv.org/abs/1609.01461"" target=""_blank"">1609.01461</a>",,2025-12-03 22:39:25
Randomized Prediction Games for Adversarial Machine Learning,"Samuel Rota Bulò, Battista Biggio, Ignazio Pillai, Marcello Pelillo, Fabio Roli",arXiv,2016-09,"<a href=""http://arxiv.org/abs/1609.00804"" target=""_blank"">1609.00804</a>",,2025-12-03 22:39:25
Robustness of classifiers: from adversarial to random noise,"Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard",arXiv,2016-08,"<a href=""http://arxiv.org/abs/1608.08967"" target=""_blank"">1608.08967</a>",,2025-12-03 22:39:25
A Boundary Tilting Persepective on the Phenomenon of Adversarial Examples,"Thomas Tanay, Lewis Griffin",arXiv,2016-08,"<a href=""http://arxiv.org/abs/1608.07690"" target=""_blank"">1608.07690</a>",,2025-12-03 22:39:25
Towards Evaluating the Robustness of Neural Networks,"Nicholas Carlini, David Wagner",arXiv,2016-08,"<a href=""http://arxiv.org/abs/1608.04644"" target=""_blank"">1608.04644</a>",,2025-12-03 22:39:25
A study of the effect of JPG compression on adversarial images,"Gintare Karolina Dziugaite, Zoubin Ghahramani, Daniel M. Roy",arXiv,2016-08,"<a href=""http://arxiv.org/abs/1608.00853"" target=""_blank"">1608.00853</a>",,2025-12-03 22:39:25
Early Methods for Detecting Adversarial Images,"Dan Hendrycks, Kevin Gimpel",arXiv,2016-08,"<a href=""http://arxiv.org/abs/1608.00530"" target=""_blank"">1608.00530</a>",,2025-12-03 22:39:25
Adversarial examples in the physical world,"Alexey Kurakin, Ian Goodfellow, Samy Bengio",arXiv,2016-07,"<a href=""http://arxiv.org/abs/1607.02533"" target=""_blank"">1607.02533</a>",,2025-12-03 22:39:25
Defensive Distillation is Not Robust to Adversarial Examples,"Nicholas Carlini, David Wagner",arXiv,2016-07,"<a href=""http://arxiv.org/abs/1607.04311"" target=""_blank"">1607.04311</a>",,2025-12-03 22:39:25
On the Effectiveness of Defensive Distillation,"Nicolas Papernot, Patrick McDaniel",arXiv,2016-07,"<a href=""http://arxiv.org/abs/1607.05113"" target=""_blank"">1607.05113</a>",,2025-12-03 22:39:25
Adversarial Perturbations Against Deep Neural Networks for Malware Classification,"Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, Patrick McDaniel",arXiv,2016-06,"<a href=""http://arxiv.org/abs/1606.04435"" target=""_blank"">1606.04435</a>",,2025-12-03 22:39:25
Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples,"Nicolas Papernot, Patrick McDaniel, Ian Goodfellow",arXiv,2016-05,"<a href=""http://arxiv.org/abs/1605.07277"" target=""_blank"">1605.07277</a>",,2025-12-03 22:39:25
Measuring Neural Net Robustness with Constraints,"Osbert Bastani, Yani Ioannou, Leonidas Lampropoulos, Dimitrios Vytiniotis, Aditya Nori, Antonio Criminisi",arXiv,2016-05,"<a href=""http://arxiv.org/abs/1605.07262"" target=""_blank"">1605.07262</a>",,2025-12-03 22:39:25
Are Facial Attributes Adversarially Robust?,"Andras Rozsa, Manuel Günther, Ethan M. Rudd, Terrance E. Boult",arXiv,2016-05,"<a href=""http://arxiv.org/abs/1605.05411"" target=""_blank"">1605.05411</a>",,2025-12-03 22:39:25
Adversarial Diversity and Hard Positive Generation,"Andras Rozsa, Ethan M. Rudd, Terrance E. Boult",arXiv,2016-05,"<a href=""http://arxiv.org/abs/1605.01775"" target=""_blank"">1605.01775</a>",,2025-12-03 22:39:25
Crafting Adversarial Input Sequences for Recurrent Neural Networks,"Nicolas Papernot, Patrick McDaniel, Ananthram Swami, Richard Harang",arXiv,2016-04,"<a href=""http://arxiv.org/abs/1604.08275"" target=""_blank"">1604.08275</a>",,2025-12-03 22:39:25
Improving the Robustness of Deep Neural Networks via Stability Training,"Stephan Zheng, Yang Song, Thomas Leung, Ian Goodfellow",arXiv,2016-04,"<a href=""http://arxiv.org/abs/1604.04326"" target=""_blank"">1604.04326</a>",,2025-12-03 22:39:25
A General Retraining Framework for Scalable Adversarial Classification,"Bo Li, Yevgeniy Vorobeychik, Xinyun Chen",arXiv,2016-04,"<a href=""http://arxiv.org/abs/1604.02606"" target=""_blank"">1604.02606</a>",,2025-12-03 22:39:25
Suppressing the Unusual: towards Robust CNNs using Symmetric Activation Functions,"Qiyang Zhao, Lewis D Griffin",arXiv,2016-03,"<a href=""http://arxiv.org/abs/1603.05145"" target=""_blank"">1603.05145</a>",,2025-12-03 22:39:25
Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms,"Tom Zahavy, Bingyi Kang, Alex Sivak, Jiashi Feng, Huan Xu, Shie Mannor",arXiv,2016-02,"<a href=""http://arxiv.org/abs/1602.02389"" target=""_blank"">1602.02389</a>",,2025-12-03 22:39:25
Practical Black-Box Attacks against Machine Learning,"Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z. Berkay Celik, Ananthram Swami",arXiv,2016-02,"<a href=""http://arxiv.org/abs/1602.02697"" target=""_blank"">1602.02697</a>",,2025-12-03 22:39:25
Breaking Symmetric Cryptosystems using Quantum Period Finding,"Marc Kaplan, Gaëtan Leurent, Anthony Leverrier, María Naya-Plasencia",arXiv,2016-02,"<a href=""http://arxiv.org/abs/1602.05973"" target=""_blank"">1602.05973</a>",,2025-12-03 22:39:25
Unifying Adversarial Training Algorithms with Flexible Deep Data Gradient Regularization,"Alexander G. II Ororbia, C. Lee Giles, Daniel Kifer",arXiv,2016-01,"<a href=""http://arxiv.org/abs/1601.07213"" target=""_blank"">1601.07213</a>",,2025-12-03 22:39:25
Towards Open Set Deep Networks,"Abhijit Bendale, Terrance Boult",arXiv,2015-11,"<a href=""http://arxiv.org/abs/1511.06233"" target=""_blank"">1511.06233</a>",,2025-12-03 22:39:25
Learning with a Strong Adversary,"Ruitong Huang, Bing Xu, Dale Schuurmans, Csaba Szepesvari",arXiv,2015-11,"<a href=""http://arxiv.org/abs/1511.03034"" target=""_blank"">1511.03034</a>",,2025-12-03 22:39:25
DeepFool: a simple and accurate method to fool deep neural networks,"Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Pascal Frossard",arXiv,2015-11,"<a href=""http://arxiv.org/abs/1511.04599"" target=""_blank"">1511.04599</a>",,2025-12-03 22:39:25
Adversarial Manipulation of Deep Representations,"Sara Sabour, Yanshuai Cao, Fartash Faghri, David J. Fleet",arXiv,2015-11,"<a href=""http://arxiv.org/abs/1511.05122"" target=""_blank"">1511.05122</a>",,2025-12-03 22:39:25
Understanding Adversarial Training: Increasing Local Stability of Neural Nets through Robust Optimization,"Uri Shaham, Yutaro Yamada, Sahand Negahban",arXiv,2015-11,"<a href=""http://arxiv.org/abs/1511.05432"" target=""_blank"">1511.05432</a>",,2025-12-03 22:39:25
Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks,"Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, Ananthram Swami",arXiv,2015-11,"<a href=""http://arxiv.org/abs/1511.04508"" target=""_blank"">1511.04508</a>",,2025-12-03 22:39:25
Foveation-based Mechanisms Alleviate Adversarial Examples,"Yan Luo, Xavier Boix, Gemma Roig, Tomaso Poggio, Qi Zhao",arXiv,2015-11,"<a href=""http://arxiv.org/abs/1511.06292"" target=""_blank"">1511.06292</a>",,2025-12-03 22:39:25
Robust Convolutional Neural Networks under Adversarial Noise,"Jonghoon Jin, Aysegul Dundar, Eugenio Culurciello",arXiv,2015-11,"<a href=""http://arxiv.org/abs/1511.06306"" target=""_blank"">1511.06306</a>",,2025-12-03 22:39:25
Manifold Regularized Deep Neural Networks using Adversarial Examples,"Taehoon Lee, Minsuk Choi, Sungroh Yoon",arXiv,2015-11,"<a href=""http://arxiv.org/abs/1511.06381"" target=""_blank"">1511.06381</a>",,2025-12-03 22:39:25
A Unified Gradient Regularization Family for Adversarial Examples,"Chunchuan Lyu, Kaizhu Huang, Hai-Ning Liang",arXiv,2015-11,"<a href=""http://arxiv.org/abs/1511.06385"" target=""_blank"">1511.06385</a>",,2025-12-03 22:39:25
The Limitations of Deep Learning in Adversarial Settings,"Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay Celik, Ananthram Swami",arXiv,2015-11,"<a href=""http://arxiv.org/abs/1511.07528"" target=""_blank"">1511.07528</a>",,2025-12-03 22:39:25
Exploring the Space of Adversarial Images,"Pedro Tabacof, Eduardo Valle",arXiv,2015-10,"<a href=""http://arxiv.org/abs/1510.05328"" target=""_blank"">1510.05328</a>",,2025-12-03 22:39:25
Improving Back-Propagation by Adding an Adversarial Gradient,Arild Nøkland,arXiv,2015-10,"<a href=""http://arxiv.org/abs/1510.04189"" target=""_blank"">1510.04189</a>",,2025-12-03 22:39:25
Deep Learning and Music Adversaries,"Corey Kereliuk, Bob L. Sturm, Jan Larsen",arXiv,2015-07,"<a href=""http://arxiv.org/abs/1507.04761"" target=""_blank"">1507.04761</a>",,2025-12-03 22:39:25
Analysis of classifiers' robustness to adversarial perturbations,"Alhussein Fawzi, Omar Fawzi, Pascal Frossard",arXiv,2015-02,"<a href=""http://arxiv.org/abs/1502.02590"" target=""_blank"">1502.02590</a>",,2025-12-03 22:39:25
Explaining and Harnessing Adversarial Examples,"Ian J. Goodfellow, Jonathon Shlens, Christian Szegedy",arXiv,2014-12,"<a href=""http://arxiv.org/abs/1412.6572"" target=""_blank"">1412.6572</a>",,2025-12-03 22:39:25
Towards Deep Neural Network Architectures Robust to Adversarial Examples,"Shixiang Gu, Luca Rigazio",arXiv,2014-12,"<a href=""http://arxiv.org/abs/1412.5068"" target=""_blank"">1412.5068</a>",,2025-12-03 22:39:25
Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images,"Anh Nguyen, Jason Yosinski, Jeff Clune",arXiv,2014-12,"<a href=""http://arxiv.org/abs/1412.1897"" target=""_blank"">1412.1897</a>",,2025-12-03 22:39:25
Security Evaluation of Support Vector Machines in Adversarial Environments,"Battista Biggio, Igino Corona, Blaine Nelson, Benjamin I. P. Rubinstein, Davide Maiorca, Giorgio Fumera, Giorgio Giacinto, and Fabio Roli",arXiv,2014-01,"<a href=""http://arxiv.org/abs/1401.7727"" target=""_blank"">1401.7727</a>",,2025-12-03 22:39:25
Intriguing properties of neural networks,"Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, Rob Fergus",arXiv,2013-12,"<a href=""http://arxiv.org/abs/1312.6199"" target=""_blank"">1312.6199</a>",,2025-12-03 22:39:25
