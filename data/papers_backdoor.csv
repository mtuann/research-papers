title,venue,year,pages,author,url,month,comment,code
Invariant Aggregator for Defending against Federated Backdoor Attacks,AISTATS,2024, (1): 2728-2736,"Xiaoyang Wang, Dimitrios Dimitriadis, Sanmi Koyejo, Shruti Tople",https://proceedings.mlr.press/v238/wang24e.html,,Conference and Workshop Papers,
On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing Problem,AISTATS,2024, (1): 4051-4059,"Georg Pichler, Marco Romanelli, Divya Prakash Manivannan, Prashanth Krishnamurthy, Farshad Khorrami, Siddharth Garg",https://proceedings.mlr.press/v238/pichler24a.html,,Conference and Workshop Papers,
Highly-Effective Backdoors for Hash Functions and Beyond,IACR Cryptol. ePrint Arch.,2024,2024 (1): 536,"Mihir Bellare, Doreen Riepel, Laura Shea",https://eprint.iacr.org/2024/536,,Informal and Other Publications,
Gradient-Based Clean Label Backdoor Attack to Graph Neural Networks,ICISSP,2024, (1): 510-521,"Ryo Meguro, Hiroya Kato, Shintaro Narisada, Seira Hidano, Kazuhide Fukushima, Takuo Suganuma, Masahiro Hiji",https://doi.org/10.5220/0012369500003648,,Conference and Workshop Papers,
Transferring Troubles: Cross-Lingual Transferability of Backdoor Attacks in LLMs with Instruction Tuning,arXiv/CoRR,2024,abs/2404.19597 (1): 1,"Xuanli He, Jun Wang, Qiongkai Xu, Pasquale Minervini, Pontus Stenetorp, Benjamin I. P. Rubinstein, Trevor Cohn",https://doi.org/10.48550/arXiv.2404.19597,,Informal and Other Publications,
Let&apos;s Focus: Focused Backdoor Attack against Federated Transfer Learning,arXiv/CoRR,2024,abs/2404.19420 (1): 1,"Marco Arazzi, Stefanos Koffas, Antonino Nocera, Stjepan Picek",https://doi.org/10.48550/arXiv.2404.19420,,Informal and Other Publications,
Physical Backdoor: Towards Temperature-based Backdoor Attacks in the Physical World,arXiv/CoRR,2024,abs/2404.19417 (1): 1,"Wen Yin, Jian Lou, Pan Zhou, Yulai Xie, Dan Feng, Yuhua Sun, Tailai Zhang, Lichao Sun",https://doi.org/10.48550/arXiv.2404.19417,,Informal and Other Publications,
Competition Report: Finding Universal Jailbreak Backdoors in Aligned LLMs,arXiv/CoRR,2024,abs/2404.14461 (1): 1,"Javier Rando, Francesco Croce, Krystof Mitka, Stepan Shabalin, Maksym Andriushchenko, Nicolas Flammarion, Florian Tramèr",https://doi.org/10.48550/arXiv.2404.14461,,Informal and Other Publications,
CloudFort: Enhancing Robustness of 3D Point Cloud Classification Against Backdoor Attacks via Spatial Partitioning and Ensemble Prediction,arXiv/CoRR,2024,abs/2404.14042 (1): 1,"Wenhao Lan, Yijun Yang, Haihua Shen, Shan Li",https://doi.org/10.48550/arXiv.2404.14042,,Informal and Other Publications,
Dual Model Replacement:invisible Multi-target Backdoor Attack based on Federal Learning,arXiv/CoRR,2024,abs/2404.13946 (1): 1,"Rong Wang, Guichen Zhou, Mingjun Gao, Yunpeng Xiao",https://doi.org/10.48550/arXiv.2404.13946,,Informal and Other Publications,
Backdoor Attacks and Defenses on Semantic-Symbol Reconstruction in Semantic Communications,arXiv/CoRR,2024,abs/2404.13279 (1): 1,"Yuan Zhou, Rose Qingyang Hu, Yi Qian",https://doi.org/10.48550/arXiv.2404.13279,,Informal and Other Publications,
Physical Backdoor Attack can Jeopardize Driving with Vision-Large-Language Models,arXiv/CoRR,2024,abs/2404.12916 (1): 1,"Zhenyang Ni, Rui Ye, Yuxi Wei, Zhen Xiang, Yanfeng Wang, Siheng Chen",https://doi.org/10.48550/arXiv.2404.12916,,Informal and Other Publications,
A Clean-graph Backdoor Attack against Graph Convolutional Networks with Poisoned Label Only,arXiv/CoRR,2024,abs/2404.12704 (1): 1,"Jiazhu Dai, Haoyu Sun",https://doi.org/10.48550/arXiv.2404.12704,,Informal and Other Publications,
Detector Collapse: Backdooring Object Detection to Catastrophic Overload or Blindness,arXiv/CoRR,2024,abs/2404.11357 (1): 1,"Hangtao Zhang, Shengshan Hu, Yichen Wang, Leo Yu Zhang, Ziqi Zhou, Xianlong Wang, Yanjun Zhang, Chao Chen",https://doi.org/10.48550/arXiv.2404.11357,,Informal and Other Publications,
On the critical path to implant backdoors and the effectiveness of potential mitigation techniques: Early learnings from XZ,arXiv/CoRR,2024,abs/2404.08987 (1): 1,"Mario Lins, René Mayrhofer, Michael Roland, Daniel Hofer, Martin Schwaighofer",https://doi.org/10.48550/arXiv.2404.08987,,Informal and Other Publications,
Backdoor Contrastive Learning via Bi-level Trigger Optimization,arXiv/CoRR,2024,abs/2404.07863 (1): 1,"Weiyu Sun, Xinyu Zhang, Hao Lu, Yingcong Chen, Ting Wang, Jinghui Chen, Lu Lin",https://doi.org/10.48550/arXiv.2404.07863,,Informal and Other Publications,
How to Craft Backdoors with Unlabeled Data Alone?,arXiv/CoRR,2024,abs/2404.06694 (1): 1,"Yifei Wang, Wenhan Ma, Stefanie Jegelka, Yisen Wang",https://doi.org/10.48550/arXiv.2404.06694,,Informal and Other Publications,
Exploring Backdoor Vulnerabilities of Chat Models,arXiv/CoRR,2024,abs/2404.02406 (1): 1,"Yunzhuo Hao, Wenkai Yang, Yankai Lin",https://doi.org/10.48550/arXiv.2404.02406,,Informal and Other Publications,
Backdoor Attack on Multilingual Machine Translation,arXiv/CoRR,2024,abs/2404.02393 (1): 1,"Jun Wang, Qiongkai Xu, Xuanli He, Benjamin I. P. Rubinstein, Trevor Cohn",https://doi.org/10.48550/arXiv.2404.02393,,Informal and Other Publications,
Two Heads are Better than One: Nested PoE for Robust Defense Against Multi-Backdoors,arXiv/CoRR,2024,abs/2404.02356 (1): 1,"Victoria Graf, Qin Liu, Muhao Chen",https://doi.org/10.48550/arXiv.2404.02356,,Informal and Other Publications,
Privacy Backdoors: Enhancing Membership Inference through Poisoning Pre-trained Models,arXiv/CoRR,2024,abs/2404.01231 (1): 1,"Yuxin Wen, Leo Marchyok, Sanghyun Hong, Jonas Geiping, Tom Goldstein, Nicholas Carlini",https://doi.org/10.48550/arXiv.2404.01231,,Informal and Other Publications,
UFID: A Unified Framework for Input-level Backdoor Detection on Diffusion Models,arXiv/CoRR,2024,abs/2404.01101 (1): 1,"Zihan Guan, Mengxuan Hu, Sheng Li, Anil Vullikanti",https://doi.org/10.48550/arXiv.2404.01101,,Informal and Other Publications,
Privacy Backdoors: Stealing Data with Corrupted Pretrained Models,arXiv/CoRR,2024,abs/2404.00473 (1): 1,"Shanglun Feng, Florian Tramèr",https://doi.org/10.48550/arXiv.2404.00473,,Informal and Other Publications,
A Backdoor Approach with Inverted Labels Using Dirty Label-Flipping Attacks,arXiv/CoRR,2024,abs/2404.00076 (1): 1,Orson Mengara,https://doi.org/10.48550/arXiv.2404.00076,,Informal and Other Publications,
Spikewhisper: Temporal Spike Backdoor Attacks on Federated Neuromorphic Learning over Low-power Devices,arXiv/CoRR,2024,abs/2403.18607 (1): 1,"Hanqing Fu, Gaolei Li, Jun Wu, Jianhua Li, Xi Lin, Kai Zhou, Yuchen Liu",https://doi.org/10.48550/arXiv.2403.18607,,Informal and Other Publications,
Securing GNNs: Explanation-Based Identification of Backdoored Training Graphs,arXiv/CoRR,2024,abs/2403.18136 (1): 1,"Jane Downer, Ren Wang, Binghui Wang",https://doi.org/10.48550/arXiv.2403.18136,,Informal and Other Publications,
LOTUS: Evasive and Resilient Backdoor Attacks through Sub-Partitioning,arXiv/CoRR,2024,abs/2403.17188 (1): 1,"Siyuan Cheng, Guanhong Tao, Yingqi Liu, Guangyu Shen, Shengwei An, Shiwei Feng, Xiangzhe Xu, Kaiyuan Zhang, Shiqing Ma, Xiangyu Zhang",https://doi.org/10.48550/arXiv.2403.17188,,Informal and Other Publications,
Task-Agnostic Detector for Insertion-Based Backdoor Attacks,arXiv/CoRR,2024,abs/2403.17155 (1): 1,"Weimin Lyu, Xiao Lin, Songzhu Zheng, Lu Pang, Haibin Ling, Susmit Jha, Chao Chen",https://doi.org/10.48550/arXiv.2403.17155,,Informal and Other Publications,
Revealing Vulnerabilities of Neural Networks in Parameter Learning and Defense Against Explanation-Aware Backdoors,arXiv/CoRR,2024,abs/2403.16569 (1): 1,"Md Abdul Kadir, Gowtham Krishna Addluri, Daniel Sonntag",https://doi.org/10.48550/arXiv.2403.16569,,Informal and Other Publications,
Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion,arXiv/CoRR,2024,abs/2403.16365 (1): 1,"Hossein Souri, Arpit Bansal, Hamid Kazemi, Liam Fowl, Aniruddha Saha, Jonas Geiping, Andrew Gordon Wilson, Rama Chellappa, Tom Goldstein, Micah Goldblum",https://doi.org/10.48550/arXiv.2403.16365,,Informal and Other Publications,
Unlearning Backdoor Threats: Enhancing Backdoor Defense in Multimodal Contrastive Learning via Local Token Unlearning,arXiv/CoRR,2024,abs/2403.16257 (1): 1,"Siyuan Liang, Kuanrong Liu, Jiajun Gong, Jiawei Liang, Yuan Xun, Ee-Chien Chang, Xiaochun Cao",https://doi.org/10.48550/arXiv.2403.16257,,Informal and Other Publications,
An Embarrassingly Simple Defense Against Backdoor Attacks On SSL,arXiv/CoRR,2024,abs/2403.15918 (1): 1,"Aryan Satpathy, Nilaksh Nilaksh, Dhruva Rajwade",https://doi.org/10.48550/arXiv.2403.15918,,Informal and Other Publications,
Clean-image Backdoor Attacks,arXiv/CoRR,2024,abs/2403.15010 (1): 1,"Dazhong Rong, Guoyao Yu, Shuheng Shen, Xinyi Fu, Peng Qian, Jianhai Chen, Qinming He, Xing Fu, Weiqiang Wang",https://doi.org/10.48550/arXiv.2403.15010,,Informal and Other Publications,
BadEdit: Backdooring large language models by model editing,arXiv/CoRR,2024,abs/2403.13355 (1): 1,"Yanzhou Li, Tianlin Li, Kangjie Chen, Jian Zhang, Shangqing Liu, Wenhan Wang, Tianwei Zhang, Yang Liu",https://doi.org/10.48550/arXiv.2403.13355,,Informal and Other Publications,
Invisible Backdoor Attack Through Singular Value Decomposition,arXiv/CoRR,2024,abs/2403.13018 (1): 1,"Wenmin Chen, Xiaowei Xu",https://doi.org/10.48550/arXiv.2403.13018,,Informal and Other Publications,
Impart: An Imperceptible and Effective Label-Specific Backdoor Attack,arXiv/CoRR,2024,abs/2403.13017 (1): 1,"Jingke Zhao, Zan Wang, Yongwei Wang, Lanjun Wang",https://doi.org/10.48550/arXiv.2403.13017,,Informal and Other Publications,
Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency,arXiv/CoRR,2024,abs/2403.10717 (1): 1,"Soumyadeep Pal, Yuguang Yao, Ren Wang, Bingquan Shen, Sijia Liu",https://doi.org/10.48550/arXiv.2403.10717,,Informal and Other Publications,
REPQC: Reverse Engineering and Backdooring Hardware Accelerators for Post-quantum Cryptography,arXiv/CoRR,2024,abs/2403.09352 (1): 1,"Samuel Pagliarini, Aikata, Malik Imran, Sujoy Sinha Roy",https://doi.org/10.48550/arXiv.2403.09352,,Informal and Other Publications,
Advancing Security in AI Systems: A Novel Approach to Detecting Backdoors in Deep Neural Networks,arXiv/CoRR,2024,abs/2403.08208 (1): 1,"Khondoker Murad Hossain, Tim Oates",https://doi.org/10.48550/arXiv.2403.08208,,Informal and Other Publications,
Backdoor Attack with Mode Mixture Latent Modification,arXiv/CoRR,2024,abs/2403.07463 (1): 1,"Hongwei Zhang, Xiaoyin Xu, Dongsheng An, Xianfeng Gu, Min Zhang",https://doi.org/10.48550/arXiv.2403.07463,,Informal and Other Publications,
Real is not True: Backdoor Attacks Against Deepfake Detection,arXiv/CoRR,2024,abs/2403.06610 (1): 1,"Hong Sun, Ziqiang Li, Lei Liu, Bin Li",https://doi.org/10.48550/arXiv.2403.06610,,Informal and Other Publications,
AS-FIBA: Adaptive Selective Frequency-Injection for Backdoor Attack on Deep Face Restoration,arXiv/CoRR,2024,abs/2403.06430 (1): 1,"Zhenbo Song, Wenhao Gao, Kaihao Zhang, Wenhan Luo, Zhaoxin Fan, Jianfeng Lu",https://doi.org/10.48550/arXiv.2403.06430,,Informal and Other Publications,
MirrorAttack: Backdoor Attack on 3D Point Cloud with a Distorting Mirror,arXiv/CoRR,2024,abs/2403.05847 (1): 1,"Yuhao Bian, Shengjing Tian, Xiuping Liu",https://doi.org/10.48550/arXiv.2403.05847,,Informal and Other Publications,
On the Effectiveness of Distillation in Mitigating Backdoors in Pre-trained Encoder,arXiv/CoRR,2024,abs/2403.03846 (1): 1,"Tingxu Han, Shenghan Huang, Ziqi Ding, Weisong Sun, Yebo Feng, Chunrong Fang, Jun Li, Hanwei Qian, Cong Wu, Quanjun Zhang, Yang Liu, Zhenyu Chen",https://doi.org/10.48550/arXiv.2403.03846,,Informal and Other Publications,
A general approach to enhance the survivability of backdoor attacks by decision path coupling,arXiv/CoRR,2024,abs/2403.02950 (1): 1,"Yufei Zhao, Dingji Wang, Bihuan Chen, Ziqian Chen, Xin Peng",https://doi.org/10.48550/arXiv.2403.02950,,Informal and Other Publications,
WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection,arXiv/CoRR,2024,abs/2403.01472 (1): 1,"Anudeex Shetty, Yue Teng, Ke He, Qiongkai Xu",https://doi.org/10.48550/arXiv.2403.01472,,Informal and Other Publications,
Here&apos;s a Free Lunch: Sanitizing Backdoored Models with Model Merge,arXiv/CoRR,2024,abs/2402.19334 (1): 1,"Ansh Arora, Xuanli He, Maximilian Mozes, Srinibas Swain, Mark Dras, Qiongkai Xu",https://doi.org/10.48550/arXiv.2402.19334,,Informal and Other Publications,
Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on Pre-trained Language Models,arXiv/CoRR,2024,abs/2402.18945 (1): 1,"Pengzhou Cheng, Wei Du, Zongru Wu, Fengwei Zhang, Libo Chen, Gongshen Liu",https://doi.org/10.48550/arXiv.2402.18945,,Informal and Other Publications,
Model Pairing Using Embedding Translation for Backdoor Attack Detection on Open-Set Classification Tasks,arXiv/CoRR,2024,abs/2402.18718 (1): 1,"Alexander Unnervik, Hatef Otroshi-Shahreza, Anjith George, Sébastien Marcel",https://doi.org/10.48550/arXiv.2402.18718,,Informal and Other Publications,
Model X-ray: Detect Backdoored Models via Decision Boundary,arXiv/CoRR,2024,abs/2402.17465 (1): 1,"Yanghao Su, Jie Zhang, Ting Xu, Tianwei Zhang, Weiming Zhang, Nenghai Yu",https://doi.org/10.48550/arXiv.2402.17465,,Informal and Other Publications,
Low-Frequency Black-Box Backdoor Attack via Evolutionary Algorithm,arXiv/CoRR,2024,abs/2402.15653 (1): 1,"Yanqi Qiao, Dazhuang Liu, Rui Wang, Kaitai Liang",https://doi.org/10.48550/arXiv.2402.15653,,Informal and Other Publications,
Mudjacking: Patching Backdoor Vulnerabilities in Foundation Models,arXiv/CoRR,2024,abs/2402.14977 (1): 1,"Hongbin Liu, Michael K. Reiter, Neil Zhenqiang Gong",https://doi.org/10.48550/arXiv.2402.14977,,Informal and Other Publications,
Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment,arXiv/CoRR,2024,abs/2402.14968 (1): 1,"Jiongxiao Wang, Jiazhao Li, Yiquan Li, Xiangyu Qi, Junjie Hu, Yixuan Li, Patrick McDaniel, Muhao Chen, Bo Li, Chaowei Xiao",https://doi.org/10.48550/arXiv.2402.14968,,Informal and Other Publications,
VL-Trojan: Multimodal Instruction Backdoor Attacks against Autoregressive Visual Language Models,arXiv/CoRR,2024,abs/2402.13851 (1): 1,"Jiawei Liang, Siyuan Liang, Man Luo, Aishan Liu, Dongchen Han, Ee-Chien Chang, Xiaochun Cao",https://doi.org/10.48550/arXiv.2402.13851,,Informal and Other Publications,
Backdoor Attacks on Dense Passage Retrievers for Disseminating Misinformation,arXiv/CoRR,2024,abs/2402.13532 (1): 1,"Quanyu Long, Yue Deng, Leilei Gan, Wenya Wang, Sinno Jialin Pan",https://doi.org/10.48550/arXiv.2402.13532,,Informal and Other Publications,
Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning,arXiv/CoRR,2024,abs/2402.12168 (1): 1,"Shuai Zhao, Leilei Gan, Luu Anh Tuan, Jie Fu, Lingjuan Lyu, Meihuizi Jia, Jinming Wen",https://doi.org/10.48550/arXiv.2402.12168,,Informal and Other Publications,
Acquiring Clean Language Models from Backdoor Poisoned Datasets by Downscaling Frequency Space,arXiv/CoRR,2024,abs/2402.12026 (1): 1,"Zongru Wu, Zhuosheng Zhang, Pengzhou Cheng, Gongshen Liu",https://doi.org/10.48550/arXiv.2402.12026,,Informal and Other Publications,
Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection,arXiv/CoRR,2024,abs/2402.11473 (1): 1,"Jiawei Liang, Siyuan Liang, Aishan Liu, Xiaojun Jia, Junhao Kuang, Xiaochun Cao",https://doi.org/10.48550/arXiv.2402.11473,,Informal and Other Publications,
Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents,arXiv/CoRR,2024,abs/2402.11208 (1): 1,"Wenkai Yang, Xiaohan Bi, Yankai Lin, Sishuo Chen, Jie Zhou, Xu Sun",https://doi.org/10.48550/arXiv.2402.11208,,Informal and Other Publications,
Test-Time Backdoor Attacks on Multimodal Large Language Models,arXiv/CoRR,2024,abs/2402.08577 (1): 1,"Dong Lu, Tianyu Pang, Chao Du, Qian Liu, Xianjun Yang, Min Lin",https://doi.org/10.48550/arXiv.2402.08577,,Informal and Other Publications,
OrderBkd: Textual backdoor attack through repositioning,arXiv/CoRR,2024,abs/2402.07689 (1): 1,"Irina Alekseevskaia, Konstantin Arkhipenko",https://doi.org/10.48550/arXiv.2402.07689,,Informal and Other Publications,
Architectural Neural Backdoors from First Principles,arXiv/CoRR,2024,abs/2402.06957 (1): 1,"Harry Langford, Ilia Shumailov, Yiren Zhao, Robert D. Mullins, Nicolas Papernot",https://doi.org/10.48550/arXiv.2402.06957,,Informal and Other Publications,
The last Dance : Robust backdoor attack via diffusion models and bayesian approach,arXiv/CoRR,2024,abs/2402.05967 (1): 1,Orson Mengara,https://doi.org/10.48550/arXiv.2402.05967,,Informal and Other Publications,
Time-Distributed Backdoor Attacks on Federated Spiking Learning,arXiv/CoRR,2024,abs/2402.02886 (1): 1,"Gorka Abad, Stjepan Picek, Aitor Urbieta",https://doi.org/10.48550/arXiv.2402.02886,,Informal and Other Publications,
DisDet: Exploring Detectability of Backdoor Attack on Diffusion Models,arXiv/CoRR,2024,abs/2402.02739 (1): 1,"Yang Sui, Huy Phan, Jinqi Xiao, Tianfang Zhang, Zijie Tang, Cong Shi, Yan Wang, Yingying Chen, Bo Yuan",https://doi.org/10.48550/arXiv.2402.02739,,Informal and Other Publications,
Universal Post-Training Reverse-Engineering Defense Against Backdoors in Deep Neural Networks,arXiv/CoRR,2024,abs/2402.02034 (1): 1,"Xi Li, Hang Wang, David J. Miller, George Kesidis",https://doi.org/10.48550/arXiv.2402.02034,,Informal and Other Publications,
TransTroj: Transferable Backdoor Attacks to Pre-trained Models via Embedding Indistinguishability,arXiv/CoRR,2024,abs/2401.15883 (1): 1,"Hao Wang, Tao Xiang, Shangwei Guo, Jialing He, Hangcheng Liu, Tianwei Zhang",https://doi.org/10.48550/arXiv.2401.15883,,Informal and Other Publications,
"Multi-Trigger Backdoor Attacks: More Triggers, More Threats",arXiv/CoRR,2024,abs/2401.15295 (1): 1,"Yige Li, Xingjun Ma, Jiabo He, Hanxun Huang, Yu-Gang Jiang",https://doi.org/10.48550/arXiv.2401.15295,,Informal and Other Publications,
BackdoorBench: A Comprehensive Benchmark and Analysis of Backdoor Learning,arXiv/CoRR,2024,abs/2401.15002 (1): 1,"Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Mingli Zhu, Ruotong Wang, Li Liu, Chao Shen",https://doi.org/10.48550/arXiv.2401.15002,,Informal and Other Publications,
WPDA: Frequency-based Backdoor Attack with Wavelet Packet Decomposition,arXiv/CoRR,2024,abs/2401.13578 (1): 1,"Zhengyao Song, Yongqiang Li, Danni Yuan, Li Liu, Shaokui Wei, Baoyuan Wu",https://doi.org/10.48550/arXiv.2401.13578,,Informal and Other Publications,
BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models,arXiv/CoRR,2024,abs/2401.12242 (1): 1,"Zhen Xiang, Fengqing Jiang, Zidi Xiong, Bhaskar Ramasubramanian, Radha Poovendran, Bo Li",https://doi.org/10.48550/arXiv.2401.12242,,Informal and Other Publications,
Learning Backdoors for Mixed Integer Programs with Contrastive Learning,arXiv/CoRR,2024,abs/2401.10467 (1): 1,"Junyang Cai, Taoan Huang, Bistra Dilkina",https://doi.org/10.48550/arXiv.2401.10467,,Informal and Other Publications,
Can We Trust the Unlabeled Target Data? Towards Backdoor Attack and Defense on Model Adaptation,arXiv/CoRR,2024,abs/2401.06030 (1): 1,"Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan",https://doi.org/10.48550/arXiv.2401.06030,,Informal and Other Publications,
Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks,arXiv/CoRR,2024,abs/2401.05949 (1): 1,"Shuai Zhao, Meihuizi Jia, Luu Anh Tuan, Jinming Wen",https://doi.org/10.48550/arXiv.2401.05949,,Informal and Other Publications,
TEN-GUARD: Tensor Decomposition for Backdoor Attack Detection in Deep Neural Networks,arXiv/CoRR,2024,abs/2401.05432 (1): 1,"Khondoker Murad Hossain, Tim Oates",https://doi.org/10.48550/arXiv.2401.05432,,Informal and Other Publications,
"The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline",arXiv/CoRR,2024,abs/2401.04136 (1): 1,"Haonan Wang, Qianli Shen, Yao Tong, Yang Zhang, Kenji Kawaguchi",https://doi.org/10.48550/arXiv.2401.04136,,Informal and Other Publications,
End-to-End Anti-Backdoor Learning on Images and Time Series,arXiv/CoRR,2024,abs/2401.03215 (1): 1,"Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, Yige Li, James Bailey",https://doi.org/10.48550/arXiv.2401.03215,,Informal and Other Publications,
A backdoor attack against link prediction tasks with graph neural networks,arXiv/CoRR,2024,abs/2401.02663 (1): 1,"Jiazhu Dai, Haoyu Sun",https://doi.org/10.48550/arXiv.2401.02663,,Informal and Other Publications,
MalModel: Hiding Malicious Payload in Mobile Deep Learning Models with Black-box Backdoor Attack,arXiv/CoRR,2024,abs/2401.02659 (1): 1,"Jiayi Hua, Kailong Wang, Meizhen Wang, Guangdong Bai, Xiapu Luo, Haoyu Wang",https://doi.org/10.48550/arXiv.2401.02659,,Informal and Other Publications,
Spy-Watermark: Robust Invisible Watermarking for Backdoor Attack,arXiv/CoRR,2024,abs/2401.02031 (1): 1,"Ruofei Wang, Renjie Wan, Zongyu Guo, Qing Guo, Rui Huang",https://doi.org/10.48550/arXiv.2401.02031,,Informal and Other Publications,
The Art of Deception: Robust Backdoor Attack using Dynamic Stacking of Triggers,arXiv/CoRR,2024,abs/2401.01537 (1): 1,Orson Mengara,https://doi.org/10.48550/arXiv.2401.01537,,Informal and Other Publications,
Imperio: Language-Guided Backdoor Attacks for Arbitrary Model Control,arXiv/CoRR,2024,abs/2401.01085 (1): 1,"Ka Ho Chow, Wenqi Wei, Lei Yu",https://doi.org/10.48550/arXiv.2401.01085,,Informal and Other Publications,
Is It Possible to Backdoor Face Forgery Detection with Natural Triggers?,arXiv/CoRR,2024,abs/2401.00414 (1): 1,"Xiaoxuan Han, Songlin Yang, Wei Wang, Ziwen He, Jing Dong",https://doi.org/10.48550/arXiv.2401.00414,,Informal and Other Publications,
A clean-label graph backdoor attack method in node classification task,arXiv/CoRR,2024,abs/2401.00163 (1): 1,"Xiaogang Xing, Ming Xu, Yujing Bai, Dongdong Yang",https://doi.org/10.48550/arXiv.2401.00163,,Informal and Other Publications,
SSL-OTA: Unveiling Backdoor Threats in Self-Supervised Learning for Object Detection,arXiv/CoRR,2024,abs/2401.00137 (1): 1,"Qiannan Wang, Changchun Yin, Liming Fang, Lu Zhou, Zhe Liu, Run Wang, Chenhao Lin",https://doi.org/10.48550/arXiv.2401.00137,,Informal and Other Publications,
Federated Learning Backdoor Attack Based on Frequency Domain Injection,Entropy,2024,26 (2): 164,"Jiawang Liu, Changgen Peng, Weijie Tan, Chenghui Shi",https://doi.org/10.3390/e26020164,,Journal Articles,
SEER: Backdoor Detection for Vision-Language Models through Searching Target Text and Image Trigger Jointly,AAAI,2024, (1): 7766-7774,"Liuwan Zhu, Rui Ning, Jiang Li, Chunsheng Xin, Hongyi Wu",https://doi.org/10.1609/aaai.v38i7.28611,,Conference and Workshop Papers,
Temporal-Distributed Backdoor Attack against Video Based Action Recognition,AAAI,2024, (1): 3199-3207,"Xi Li, Songhe Wang, Ruiquan Huang, Mahanth Gowda, George Kesidis",https://doi.org/10.1609/aaai.v38i4.28104,,Conference and Workshop Papers,
COMBAT: Alternated Training for Effective Clean-Label Backdoor Attacks,AAAI,2024, (1): 2436-2444,"Tran Huynh, Dang Nguyen, Tung Pham, Anh Tran",https://doi.org/10.1609/aaai.v38i3.28019,,Conference and Workshop Papers,
A Dual Stealthy Backdoor: From Both Spatial and Frequency Perspectives,AAAI,2024, (1): 1851-1859,"Yudong Gao, Honglong Chen, Peng Sun, Junjian Li, Anqing Zhang, Zhibo Wang, Weifeng Liu",https://doi.org/10.1609/aaai.v38i3.27954,,Conference and Workshop Papers,
BadSAM: Exploring Security Vulnerabilities of SAM via Backdoor Attacks (Student Abstract),AAAI,2024, (1): 23506-23507,"Zihan Guan, Mengxuan Hu, Zhongliang Zhou, Jielu Zhang, Sheng Li, Ninghao Liu",https://doi.org/10.1609/aaai.v38i21.30448,,Conference and Workshop Papers,
DataElixir: Purifying Poisoned Dataset to Mitigate Backdoor Attacks via Diffusion Models,AAAI,2024, (1): 21850-21858,"Jiachen Zhou, Peizhuo Lv, Yibing Lan, Guozhu Meng, Kai Chen, Hualong Ma",https://doi.org/10.1609/aaai.v38i19.30186,,Conference and Workshop Papers,
UMA: Facilitating Backdoor Scanning via Unlearning-Based Model Ablation,AAAI,2024, (1): 21823-21831,"Yue Zhao, Congyi Li, Kai Chen",https://doi.org/10.1609/aaai.v38i19.30183,,Conference and Workshop Papers,
Beyond Traditional Threats: A Persistent Backdoor Attack on Federated Learning,AAAI,2024, (1): 21359-21367,"Tao Liu, Yuhang Zhang, Zhu Feng, Zhiqin Yang, Chen Xu, Dapeng Man, Wu Yang",https://doi.org/10.1609/aaai.v38i19.30131,,Conference and Workshop Papers,
Personalization as a Shortcut for Few-Shot Backdoor Attack against Text-to-Image Diffusion Models,AAAI,2024, (1): 21169-21178,"Yihao Huang, Felix Juefei-Xu, Qing Guo, Jie Zhang, Yutong Wu, Ming Hu, Tianlin Li, Geguang Pu, Yang Liu",https://doi.org/10.1609/aaai.v38i19.30110,,Conference and Workshop Papers,
Invisible Backdoor Attack against 3D Point Cloud Classifier in Graph Spectral Domain,AAAI,2024, (1): 21072-21080,"Linkun Fan, Fazhi He, Tongzhen Si, Wei Tang, Bing Li",https://doi.org/10.1609/aaai.v38i19.30099,,Conference and Workshop Papers,
Does Few-Shot Learning Suffer from Backdoor Attacks?,AAAI,2024, (1): 19893-19901,"Xinwei Liu, Xiaojun Jia, Jindong Gu, Yuan Xun, Siyuan Liang, Xiaochun Cao",https://doi.org/10.1609/aaai.v38i18.29965,,Conference and Workshop Papers,
Conditional Backdoor Attack via JPEG Compression,AAAI,2024, (1): 19823-19831,"Qiuyu Duan, Zhongyun Hua, Qing Liao, Yushu Zhang, Leo Yu Zhang",https://doi.org/10.1609/aaai.v38i18.29957,,Conference and Workshop Papers,
Chronic Poisoning: Backdoor Attack against Split Learning,AAAI,2024, (1): 16531-16538,"Fangchao Yu, Bo Zeng, Kai Zhao, Zhi Pang, Lina Wang",https://doi.org/10.1609/aaai.v38i15.29591,,Conference and Workshop Papers,
Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective,AAAI,2024, (1): 14677-14685,"Zhen Qin, Feiyi Chen, Chen Zhi, Xueqiang Yan, Shuiguang Deng",https://doi.org/10.1609/aaai.v38i13.29385,,Conference and Workshop Papers,
Backdoor Attacks via Machine Unlearning,AAAI,2024, (1): 14115-14123,"Zihao Liu, Tianhao Wang, Mengdi Huai, Chenglin Miao",https://doi.org/10.1609/aaai.v38i13.29321,,Conference and Workshop Papers,
Backdoor Adjustment via Group Adaptation for Debiased Coupon Recommendations,AAAI,2024, (1): 11944-11952,"Junpeng Fang, Gongduo Zhang, Qing Cui, Caizhi Tang, Lihong Gu, Longfei Li, Jinjie Gu, Jun Zhou",https://doi.org/10.1609/aaai.v38i11.29081,,Conference and Workshop Papers,
BadRL: Sparse Targeted Backdoor Attack against Reinforcement Learning,AAAI,2024, (1): 11687-11694,"Jing Cui, Yufei Han, Yuzhe Ma, Jianbin Jiao, Junge Zhang",https://doi.org/10.1609/aaai.v38i10.29052,,Conference and Workshop Papers,
Progressive Poisoned Data Isolation for Training-Time Backdoor Defense,AAAI,2024, (1): 11425-11433,"Yiming Chen, Haiwei Wu, Jiantao Zhou",https://doi.org/10.1609/aaai.v38i10.29023,,Conference and Workshop Papers,
Elijah: Eliminating Backdoors Injected in Diffusion Models via Distribution Shift,AAAI,2024, (1): 10847-10855,"Shengwei An, Sheng-Yen Chou, Kaiyuan Zhang, Qiuling Xu, Guanhong Tao, Guangyu Shen, Siyuan Cheng, Shiqing Ma, Pin-Yu Chen, Tsung-Yi Ho, Xiangyu Zhang",https://doi.org/10.1609/aaai.v38i10.28958,,Conference and Workshop Papers,
Inspecting Prediction Confidence for Detecting Black-Box Backdoor Attacks,AAAI,2024, (1): 274-282,"Tong Wang, Yuan Yao, Feng Xu, Miao Xu, Shengwei An, Ting Wang",https://doi.org/10.1609/aaai.v38i1.27780,,Conference and Workshop Papers,
Backdoor Attacks on Graph Neural Networks Trained with Data Augmentation,IEICE Trans. Fundam. Electron. Commun. Comput. Sci.,2024,107 (3): 355-358,"Shingo Yashiki, Chako Takahashi, Koutarou Suzuki",https://doi.org/10.1587/transfun.2023cil0007,,Journal Articles,
"Backdoor advertising scandals, Yingyeo culture, and cancel culture among YouTube Influencers in South Korea",New Media Soc.,2024,26 (1): 405-425,"Jin Lee, Crystal Abidin",https://doi.org/10.1177/14614448211061829,,Journal Articles,
Backdoors on Manifold Learning,WiseML@WiSec,2024, (1): 1-7,"Christina Kreza, Stefanos Koffas, Behrad Tajalli, Mauro Conti, Stjepan Picek",https://doi.org/10.1145/3649403.3656484,,Conference and Workshop Papers,
Exploring Semantic Redundancy using Backdoor Triggers: A Complementary Insight into the Challenges Facing DNN-based Software Vulnerability Detection,ACM Trans. Softw. Eng. Methodol.,2024,33 (4): 92:1-92:28,"Changjie Shao, Gaolei Li, Jun Wu, James Xi Zheng",https://doi.org/10.1145/3640333,,Journal Articles,
Watermarking in Secure Federated Learning: A Verification Framework Based on Client-Side Backdooring,ACM Trans. Intell. Syst. Technol.,2024,15 (1): 5:1-5:25,"Wenyuan Yang, Shuo Shao, Yue Yang, Xiyao Liu, Ximeng Liu, Zhihua Xia, Gerald Schaefer, Hui Fang",https://doi.org/10.1145/3630636,,Journal Articles,
Interpretation-Empowered Neural Cleanse for Backdoor Attacks,WWW,2024, (1): 951-954,"Liang-bo Ning, Zeyu Dai, Jingran Su, Chao Pan, Luning Wang, Wenqi Fan, Qing Li",https://doi.org/10.1145/3589335.3651525,,Conference and Workshop Papers,
A Closer Look at Robustness of Vision Transformers to Backdoor Attacks,WACV,2024, (1): 3862-3871,"Akshayvarun Subramanya, Soroush Abbasi Koohpayegani, Aniruddha Saha, Ajinkya Tejankar, Hamed Pirsiavash",https://doi.org/10.1109/WACV57701.2024.00383,,Conference and Workshop Papers,
Stealthy Backdoor Attack for Code Models,IEEE Trans. Software Eng.,2024,50 (4): 721-741,"Zhou Yang, Bowen Xu, Jie M. Zhang, Hong Jin Kang, Jieke Shi, Junda He, David Lo",https://doi.org/10.1109/TSE.2024.3361661,,Journal Articles,
Dyn-Backdoor: Backdoor Attack on Dynamic Link Prediction,IEEE Trans. Netw. Sci. Eng.,2024,11 (1): 525-542,"Jinyin Chen, Haiyang Xiong, Haibin Zheng, Jian Zhang, Yi Liu",https://doi.org/10.1109/TNSE.2023.3301673,,Journal Articles,
Critical Path-Based Backdoor Detection for Deep Neural Networks,IEEE Trans. Neural Networks Learn. Syst.,2024,35 (3): 4032-4046,"Wei Jiang, Xiangyu Wen, Jinyu Zhan, Xupeng Wang, Ziwei Song, Chen Bian",https://doi.org/10.1109/TNNLS.2022.3201586,,Journal Articles,
Backdoor Learning: A Survey,IEEE Trans. Neural Networks Learn. Syst.,2024,35 (1): 5-22,"Yiming Li, Yong Jiang, Zhifeng Li, Shu-Tao Xia",https://doi.org/10.1109/TNNLS.2022.3182979,,Journal Articles,
BadCM: Invisible Backdoor Attack Against Cross-Modal Learning,IEEE Trans. Image Process.,2024,33 (1): 2558-2571,"Zheng Zhang, Xu Yuan, Lei Zhu, Jingkuan Song, Liqiang Nie",https://doi.org/10.1109/TIP.2024.3378918,,Journal Articles,
PerVK: A Robust Personalized Federated Framework to Defend Against Backdoor Attacks for IoT Applications,IEEE Trans. Ind. Informatics,2024,20 (3): 4930-4939,"Yongkang Wang, Di-Hua Zhai, Yuanqing Xia, Danyang Liu",https://doi.org/10.1109/TII.2023.3329688,,Journal Articles,
Untargeted Backdoor Attack Against Deep Neural Networks With Imperceptible Trigger,IEEE Trans. Ind. Informatics,2024,20 (3): 5004-5013,"Mingfu Xue, Yinghao Wu, Shifeng Ni, Leo Yu Zhang, Yushu Zhang, Weiqiang Liu",https://doi.org/10.1109/TII.2023.3329641,,Journal Articles,
NeuralSanitizer: Detecting Backdoors in Neural Networks,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 4970-4985,"Hong Zhu, Yue Zhao, Shengzhi Zhang, Kai Chen",https://doi.org/10.1109/TIFS.2024.3390599,,Journal Articles,
BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 4865-4880,"Jordan Vice, Naveed Akhtar, Richard I. Hartley, Ajmal Mian",https://doi.org/10.1109/TIFS.2024.3386058,,Journal Articles,
FLPurifier: Backdoor Defense in Federated Learning via Decoupled Contrastive Training,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 4752-4766,"Jiale Zhang, Chengcheng Zhu, Xiaobing Sun, Chunpeng Ge, Bing Chen, Willy Susilo, Shui Yu",https://doi.org/10.1109/TIFS.2024.3384846,,Journal Articles,
Minimalism is King! High-Frequency Energy-Based Screening for Data-Efficient Backdoor Attacks,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 4560-4571,"Yuan Xun, Xiaojun Jia, Jindong Gu, Xinwei Liu, Qing Guo, Xiaochun Cao",https://doi.org/10.1109/TIFS.2024.3380821,,Journal Articles,
BDMMT: Backdoor Sample Detection for Language Models Through Model Mutation Testing,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 4285-4300,"Jiali Wei, Ming Fan, Wenjing Jiao, Wuxia Jin, Ting Liu",https://doi.org/10.1109/TIFS.2024.3376968,,Journal Articles,
On Model Outsourcing Adaptive Attacks to Deep Learning Backdoor Defenses,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 2356-2369,"Huaibing Peng, Huming Qiu, Hua Ma, Shuo Wang, Anmin Fu, Said F. Al-Sarawi, Derek Abbott, Yansong Gao",https://doi.org/10.1109/TIFS.2024.3349869,,Journal Articles,
MBA: Backdoor Attacks Against 3D Mesh Classifier,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 2127-2142,"Linkun Fan, Fazhi He, Tongzhen Si, Rubin Fan, Chuanlong Ye, Bing Li",https://doi.org/10.1109/TIFS.2023.3346644,,Journal Articles,
Imperceptible and Robust Backdoor Attack in 3D Point Cloud,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 1267-1282,"Kuofeng Gao, Jiawang Bai, Baoyuan Wu, Mengxi Ya, Shu-Tao Xia",https://doi.org/10.1109/TIFS.2023.3333687,,Journal Articles,
Universal Detection of Backdoor Attacks via Density-Based Clustering and Centroids Analysis,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 970-984,"Wei Guo, Benedetta Tondi, Mauro Barni",https://doi.org/10.1109/TIFS.2023.3329426,,Journal Articles,
Verifying in the Dark: Verifiable Machine Unlearning by Using Invisible Backdoor Triggers,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 708-721,"Yu Guo, Yu Zhao, Saihui Hou, Cong Wang, Xiaohua Jia",https://doi.org/10.1109/TIFS.2023.3328269,,Journal Articles,
Backdoor Attack Against Split Neural Network-Based Vertical Federated Learning,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 748-763,"Ying He, Zhili Shen, Jingyu Hua, Qixuan Dong, Jiacheng Niu, Wei Tong, Xu Huang, Chen Li, Sheng Zhong",https://doi.org/10.1109/TIFS.2023.3327853,,Journal Articles,
Privacy-Enhancing and Robust Backdoor Defense for Federated Learning on Heterogeneous Data,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 693-707,"Zekai Chen, Shengxing Yu, Mingyuan Fan, Ximeng Liu, Robert H. Deng",https://doi.org/10.1109/TIFS.2023.3326983,,Journal Articles,
Toward a Critical Evaluation of Robustness for Deep Learning Backdoor Countermeasures,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 455-468,"Huming Qiu, Hua Ma, Zhi Zhang, Alsharif Abuadbba, Wei Kang, Anmin Fu, Yansong Gao",https://doi.org/10.1109/TIFS.2023.3324318,,Journal Articles,
Invisible Backdoor Attack With Dynamic Triggers Against Person Re-Identification,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 307-319,"Wenli Sun, Xinyang Jiang, Shuguang Dou, Dongsheng Li, Duoqian Miao, Cheng Deng, Cairong Zhao",https://doi.org/10.1109/TIFS.2023.3322659,,Journal Articles,
Backdoor Attack on Deep Learning-Based Medical Image Encryption and Decryption Network,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 280-292,"Yi Ding, Zi Wang, Zhen Qin, Erqiang Zhou, Guobin Zhu, Zhiguang Qin, Kim-Kwang Raymond Choo",https://doi.org/10.1109/TIFS.2023.3322315,,Journal Articles,
NTD: Non-Transferability Enabled Deep Learning Backdoor Detection,IEEE Trans. Inf. Forensics Secur.,2024,19 (1): 104-119,"Yinshan Li, Hua Ma, Zhi Zhang, Yansong Gao, Alsharif Abuadbba, Minhui Xue, Anmin Fu, Yifeng Zheng, Said F. Al-Sarawi, Derek Abbott",https://doi.org/10.1109/TIFS.2023.3312973,,Journal Articles,
Quantization Backdoors to Deep Learning Commercial Frameworks,IEEE Trans. Dependable Secur. Comput.,2024,21 (3): 1155-1172,"Hua Ma, Huming Qiu, Yansong Gao, Zhi Zhang, Alsharif Abuadbba, Minhui Xue, Anmin Fu, Jiliang Zhang, Said F. Al-Sarawi, Derek Abbott",https://doi.org/10.1109/TDSC.2023.3271956,,Journal Articles,
"Incremental Learning, Incremental Backdoor Threats",IEEE Trans. Dependable Secur. Comput.,2024,21 (2): 559-572,"Wenbo Jiang, Tianwei Zhang, Han Qiu, Hongwei Li, Guowen Xu",https://doi.org/10.1109/TDSC.2022.3201234,,Journal Articles,
Motif-Backdoor: Rethinking the Backdoor Attack on Graph Neural Networks via Motifs,IEEE Trans. Comput. Soc. Syst.,2024,11 (2): 2479-2493,"Haibin Zheng, Haiyang Xiong, Jinyin Chen, Haonan Ma, Guohan Huang",https://doi.org/10.1109/TCSS.2023.3267094,,Journal Articles,
Link-Backdoor: Backdoor Attack on Link Prediction via Node Injection,IEEE Trans. Comput. Soc. Syst.,2024,11 (2): 1816-1831,"Haibin Zheng, Haiyang Xiong, Haonan Ma, Guohan Huang, Jinyin Chen",https://doi.org/10.1109/TCSS.2023.3260833,,Journal Articles,
ImpNet: Imperceptible and blackbox-undetectable backdoors in compiled neural networks,SaTML,2024, (1): 344-357,"Eleanor Clifford, Ilia Shumailov, Yiren Zhao, Ross J. Anderson, Robert D. Mullins",https://doi.org/10.1109/SaTML59370.2024.00024,,Conference and Workshop Papers,
REStore: Exploring a Black-Box Defense against DNN Backdoors using Rare Event Simulation,SaTML,2024, (1): 286-308,"Quentin Le Roux, Kassem Kallas, Teddy Furon",https://doi.org/10.1109/SaTML59370.2024.00021,,Conference and Workshop Papers,
Backdoor Attack on Unpaired Medical Image-Text Foundation Models: A Pilot Study on MedCLIP,SaTML,2024, (1): 272-285,"Ruinan Jin, Chun-Yin Huang, Chenyu You, Xiaoxiao Li",https://doi.org/10.1109/SaTML59370.2024.00020,,Conference and Workshop Papers,
A Spatiotemporal Backdoor Attack Against Behavior-Oriented Decision Makers in Metaverse: From Perspective of Autonomous Driving,IEEE J. Sel. Areas Commun.,2024,42 (4): 948-962,"Yinbo Yu, Jiajia Liu, Hongzhi Guo, Bomin Mao, Nei Kato",https://doi.org/10.1109/JSAC.2023.3345379,,Journal Articles,
Effective Backdoor Attack on Graph Neural Networks in Spectral Domain,IEEE Internet Things J.,2024,11 (7): 12102-12114,"Xiangyu Zhao, Hanzhou Wu, Xinpeng Zhang",https://doi.org/10.1109/JIOT.2023.3332848,,Journal Articles,
Enrollment-Stage Backdoor Attacks on Speaker Recognition Systems via Adversarial Ultrasound,IEEE Internet Things J.,2024,11 (8): 13108-13124,"Xinfeng Li, Junning Ze, Chen Yan, Yushi Cheng, Xiaoyu Ji, Wenyuan Xu",https://doi.org/10.1109/JIOT.2023.3328253,,Journal Articles,
MITDBA: Mitigating Dynamic Backdoor Attacks in Federated Learning for IoT Applications,IEEE Internet Things J.,2024,11 (6): 10115-10132,"Yongkang Wang, Di-Hua Zhai, Dongyu Han, Yuyin Guan, Yuanqing Xia",https://doi.org/10.1109/JIOT.2023.3325634,,Journal Articles,
Detecting Backdoors Embedded in Ensembles,ICEIC,2024, (1): 1-3,"SeokHee Kim, Changhee Hahn",https://doi.org/10.1109/ICEIC61013.2024.10457185,,Conference and Workshop Papers,
Defense Method Challenges Against Backdoor Attacks in Neural Networks,ICAIIC,2024, (1): 396-400,"Samaneh Shamshiri, Insoo Sohn",https://doi.org/10.1109/ICAIIC60209.2024.10463411,,Conference and Workshop Papers,
Backdoor Attacks and Generative Model Fairness: Current Trends and Future Research Directions,COMSNETS,2024, (1): 31-36,"Ryan Holland, Shantanu Pal, Lei Pan, Leo Yu Zhang",https://doi.org/10.1109/COMSNETS59351.2024.10427172,,Conference and Workshop Papers,
Optimal Smoothing Distribution Exploration for Backdoor Neutralization in Deep Learning-based Traffic Systems,ANZCC,2024, (1): 115-120,"Yue Wang, Wenqing Li, Michail Maniatakos, Saif Eddin Jabari",https://doi.org/10.1109/ANZCC59813.2024.10432866,,Conference and Workshop Papers,
A Comprehensive Survey on Backdoor Attacks and Their Defenses in Face Recognition Systems,IEEE Access,2024,12 (1): 47433-47468,"Quentin Le Roux, Eric Bourbao, Yannick Teglia, Kassem Kallas",https://doi.org/10.1109/ACCESS.2024.3382584,,Journal Articles,
"Backdoor Attacks to Deep Neural Networks: A Survey of the Literature, Challenges, and Future Research Directions",IEEE Access,2024,12 (1): 29004-29023,"Orson Mengara, Anderson R. Avila, Tiago H. Falk",https://doi.org/10.1109/ACCESS.2024.3355816,,Journal Articles,
Defending Against Backdoor Attacks by Quarantine Training,IEEE Access,2024,12 (1): 10681-10689,"Chengxu Yu, Yulai Zhang",https://doi.org/10.1109/ACCESS.2024.3354385,,Journal Articles,
SilentTrig: An imperceptible backdoor attack against speaker identification with hidden triggers,Pattern Recognit. Lett.,2024,177 (1): 103-109,"Yu Tang, Lijuan Sun, Xiaolong Xu",https://doi.org/10.1016/j.patrec.2023.12.002,,Journal Articles,
Multi-target label backdoor attacks on graph neural networks,Pattern Recognit.,2024,152 (1): 110449,"Kaiyang Wang, Huaxin Deng, Yijia Xu, Zhonglin Liu, Yong Fang",https://doi.org/10.1016/j.patcog.2024.110449,,Journal Articles,
SecureNet: Proactive intellectual property protection and model security defense for DNNs based on backdoor learning,Neural Networks,2024,174 (1): 106199,"Peihao Li, Jie Huang, Huaqing Wu, Zeping Zhang, Chunyang Qi",https://doi.org/10.1016/j.neunet.2024.106199,,Journal Articles,
FDNet: Imperceptible backdoor attacks via frequency domain steganography and negative sampling,Neurocomputing,2024,583 (1): 127546,"Liang Dong, Zhongwang Fu, Leiyang Chen, Hongwei Ding, Chengliang Zheng, Xiaohui Cui, Zhidong Shen",https://doi.org/10.1016/j.neucom.2024.127546,,Journal Articles,
RoPE: Defending against backdoor attacks in federated learning systems,Knowl. Based Syst.,2024,293 (1): 111660,"Yongkang Wang, Di-Hua Zhai, Yuanqing Xia",https://doi.org/10.1016/j.knosys.2024.111660,,Journal Articles,
FLMAAcBD: Defending against backdoors in Federated Learning via Model Anomalous Activation Behavior Detection,Knowl. Based Syst.,2024,289 (1): 111511,"Hongyun Cai, Jiahao Wang, Lijing Gao, Fengyu Li",https://doi.org/10.1016/j.knosys.2024.111511,,Journal Articles,
One-to-Multiple Clean-Label Image Camouflage (OmClic) based backdoor attack on deep learning,Knowl. Based Syst.,2024,288 (1): 111456,"Guohong Wang, Hua Ma, Yansong Gao, Alsharif Abuadbba, Zhi Zhang, Wei Kang, Said F. Al-Sarawi, Gongxuan Zhang, Derek Abbott",https://doi.org/10.1016/j.knosys.2024.111456,,Journal Articles,
Detection of backdoor attacks using targeted universal adversarial perturbations for deep neural networks,J. Syst. Softw.,2024,207 (1): 111859,"Yubin Qu, Song Huang, Xiang Chen, Xingya Wang, Yongming Yao",https://doi.org/10.1016/j.jss.2023.111859,,Journal Articles,
TridentShell: An enhanced covert and scalable backdoor injection attack on web applications,J. Netw. Comput. Appl.,2024,223 (1): 103823,"Xiaobo Yu, Weizhi Meng, Yi-Ning Liu, Fei Zhou",https://doi.org/10.1016/j.jnca.2023.103823,,Journal Articles,
The reality of backdoored S-Boxes - An eye opener,J. Inf. Secur. Appl.,2024,80 (1): 103674,"Shah Fahd, Mehreen Afzal, Waseem Iqbal, Dawood Shah, Ijaz Khalid",https://doi.org/10.1016/j.jisa.2023.103674,,Journal Articles,
Backdoor attack detection via prediction trustworthiness assessment,Inf. Sci.,2024,662 (1): 120283,"Nan Zhong, Zhenxing Qian, Xinpeng Zhang",https://doi.org/10.1016/j.ins.2024.120283,,Journal Articles,
NLPSweep: A comprehensive defense scheme for mitigating NLP backdoor attacks,Inf. Sci.,2024,661 (1): 120176,"Tao Xiang, Fei Ouyang, Di Zhang, Chunlong Xie, Hao Wang",https://doi.org/10.1016/j.ins.2024.120176,,Journal Articles,
"Backdoor attacks and defenses in federated learning: Survey, challenges and future research directions",Eng. Appl. Artif. Intell.,2024,127 (Part A): 107166,"Thuy Dung Nguyen, Tuan Nguyen, Phi Le Nguyen, Hieu H. Pham, Khoa D. Doan, Kok-Seng Wong",https://doi.org/10.1016/j.engappai.2023.107166,,Journal Articles,
WaTrojan: Wavelet domain trigger injection for backdoor attacks,Comput. Secur.,2024,140 (1): 103767,"Zhenghao Zhang, Jianwei Ding, Qi Zhang, Qiyao Deng",https://doi.org/10.1016/j.cose.2024.103767,,Journal Articles,
Shadow backdoor attack: Multi-intensity backdoor attack against federated learning,Comput. Secur.,2024,139 (1): 103740,"Qixian Ren, Yu Zheng, Chao Yang, Yue Li, Jian-Feng Ma",https://doi.org/10.1016/j.cose.2024.103740,,Journal Articles,
Universal adversarial backdoor attacks to fool vertical federated learning,Comput. Secur.,2024,137 (1): 103601,"Peng Chen, Xin Du, Zhihui Lu, Hongfeng Chai",https://doi.org/10.1016/j.cose.2023.103601,,Journal Articles,
Federated learning backdoor attack detection with persistence diagram,Comput. Secur.,2024,136 (1): 103557,"Zihan Ma, Tianchong Gao",https://doi.org/10.1016/j.cose.2023.103557,,Journal Articles,
SGBA: A stealthy scapegoat backdoor attack against deep neural networks,Comput. Secur.,2024,136 (1): 103523,"Ying He, Zhili Shen, Chang Xia, Jingyu Hua, Wei Tong, Sheng Zhong",https://doi.org/10.1016/j.cose.2023.103523,,Journal Articles,
Enhanced Coalescence Backdoor Attack Against DNN Based on Pixel Gradient,Neural Process. Lett.,2024,56 (2): 114,"Jianyao Yin, Honglong Chen, Junjian Li, Yudong Gao",https://doi.org/10.1007/s11063-024-11469-4,,Journal Articles,
Imperceptible and multi-channel backdoor attack,Appl. Intell.,2024,54 (1): 1099-1116,"Mingfu Xue, Shifeng Ni, Yinghao Wu, Yushu Zhang, Weiqiang Liu",https://doi.org/10.1007/s10489-023-05228-6,,Journal Articles,
Invisible backdoor learning in regional transform domain,Neural Comput. Appl.,2024,36 (14): 8097-8108,"Yuyuan Sun, Yuliang Lu, Xuehu Yan, Xuan Wang",https://doi.org/10.1007/s00521-024-09506-3,,Journal Articles,
Backdoor Attack Against One-Class Sequential Anomaly Detection Models,PAKDD,2024, (1): 262-274,"He Cheng, Shuhan Yuan",https://doi.org/10.1007/978-981-97-2259-4_20,,Conference and Workshop Papers,
Unveiling Backdoor Risks Brought by Foundation Models in Heterogeneous Federated Learning,PAKDD,2024, (1): 168-181,"Xi Li, Chen Wu, Jiaqi Wang",https://doi.org/10.1007/978-981-97-2259-4_13,,Conference and Workshop Papers,
On the Possibility of a Backdoor in the Micali-Schnorr Generator,Public Key Cryptography,2024, (1): 352-386,"Hannah Davis, Matthew D. Green, Nadia Heninger, Keegan Ryan, Adam Suhl",https://doi.org/10.1007/978-3-031-57718-5_12,,Conference and Workshop Papers,
Backdoor NLP Models via AI-Generated Text,LREC/COLING,2024, (1): 2067-2079,"Wei Du, Tianjie Ju, Ge Ren, Gaolei Li, Gongshen Liu",https://aclanthology.org/2024.lrec-main.186,,Conference and Workshop Papers,
PELICAN: Exploiting Backdoors of Naturally Trained Deep Learning Models In Binary Code Analysis,USENIX Security Symposium,2023, (1): 2365-2382,"Zhuo Zhang, Guanhong Tao, Guangyu Shen, Shengwei An, Qiuling Xu, Yingqi Liu, Yapeng Ye, Yaoxuan Wu, Xiangyu Zhang",https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-zhuo-pelican,,Conference and Workshop Papers,
Aliasing Backdoor Attacks on Pre-trained Models,USENIX Security Symposium,2023, (1): 2707-2724,"Cheng&apos;an Wei, Yeonjoon Lee, Kai Chen, Guozhu Meng, Peizhuo Lv",https://www.usenix.org/conference/usenixsecurity23/presentation/wei-chengan,,Conference and Workshop Papers,
Sparsity Brings Vulnerabilities: Exploring New Metrics in Backdoor Attacks,USENIX Security Symposium,2023, (1): 2689-2706,"Jianwen Tian, Kefan Qiu, Debin Gao, Zhi Wang, Xiaohui Kuang, Gang Zhao",https://www.usenix.org/conference/usenixsecurity23/presentation/tian,,Conference and Workshop Papers,
Towards A Proactive ML Approach for Detecting Backdoor Poison Samples,USENIX Security Symposium,2023, (1): 1685-1702,"Xiangyu Qi, Tinghao Xie, Jiachen T. Wang, Tong Wu, Saeed Mahloujifar, Prateek Mittal",https://www.usenix.org/conference/usenixsecurity23/presentation/qi,,Conference and Workshop Papers,
ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep Learning Paradigms,USENIX Security Symposium,2023, (1): 2725-2742,"Minzhou Pan, Yi Zeng, Lingjuan Lyu, Xue Lin, Ruoxi Jia",https://www.usenix.org/conference/usenixsecurity23/presentation/pan,,Conference and Workshop Papers,
A Data-free Backdoor Injection Approach in Neural Networks,USENIX Security Symposium,2023, (1): 2671-2688,"Peizhuo Lv, Chang Yue, Ruigang Liang, Yunfei Yang, Shengzhi Zhang, Hualong Ma, Kai Chen",https://www.usenix.org/conference/usenixsecurity23/presentation/lv,,Conference and Workshop Papers,
VILLAIN: Backdoor Attacks Against Vertical Split Learning,USENIX Security Symposium,2023, (1): 2743-2760,"Yijie Bai, Yanjiao Chen, Hanlei Zhang, Wenyuan Xu, Haiqin Weng, Dou Goodman",https://www.usenix.org/conference/usenixsecurity23/presentation/bai,,Conference and Workshop Papers,
The &quot;Beatrix&quot; Resurrections: Robust Backdoor Detection via Gram Matrices,NDSS,2023, (1): 1,"Wanlun Ma, Derui Wang, Ruoxi Sun, Minhui Xue, Sheng Wen, Yang Xiang",https://www.ndss-symposium.org/ndss-paper/the-beatrix-resurrections-robust-backdoor-detection-via-gram-matrices/,,Conference and Workshop Papers,
BEAGLE: Forensics of Deep Learning Backdoor Attack for Better Defense,NDSS,2023, (1): 1,"Siyuan Cheng, Guanhong Tao, Yingqi Liu, Shengwei An, Xiangzhe Xu, Shiwei Feng, Guangyu Shen, Kaiyuan Zhang, Qiuling Xu, Shiqing Ma, Xiangyu Zhang",https://www.ndss-symposium.org/ndss-paper/beagle-forensics-of-deep-learning-backdoor-attack-for-better-defense/,,Conference and Workshop Papers,
Backdoor Attacks Against Dataset Distillation,NDSS,2023, (1): 1,"Yugeng Liu, Zheng Li, Michael Backes, Yun Shen, Yang Zhang",https://www.ndss-symposium.org/ndss-paper/backdoor-attacks-against-dataset-distillation/,,Conference and Workshop Papers,
Graph Contrastive Backdoor Attacks,ICML,2023, (1): 40888-40910,"Hangfan Zhang, Jinghui Chen, Lu Lin, Jinyuan Jia, Dinghao Wu",https://proceedings.mlr.press/v202/zhang23e.html,,Conference and Workshop Papers,
UMD: Unsupervised Model Detection for X2X Backdoor Attacks,ICML,2023, (1): 38013-38038,"Zhen Xiang, Zidi Xiong, Bo Li",https://proceedings.mlr.press/v202/xiang23a.html,,Conference and Workshop Papers,
Understanding Backdoor Attacks through the Adaptability Hypothesis,ICML,2023, (1): 37952-37976,"Xun Xian, Ganghua Wang, Jayanth Srinivasa, Ashish Kundu, Xuan Bi, Mingyi Hong, Jie Ding",https://proceedings.mlr.press/v202/xian23a.html,,Conference and Workshop Papers,
Reconstructive Neuron Pruning for Backdoor Defense,ICML,2023, (1): 19837-19854,"Yige Li, Xixiang Lyu, Xingjun Ma, Nodens Koren, Lingjuan Lyu, Bo Li, Yu-Gang Jiang",https://proceedings.mlr.press/v202/li23v.html,,Conference and Workshop Papers,
Rethinking Backdoor Attacks,ICML,2023, (1): 16216-16236,"Alaa Khaddaj, Guillaume Leclerc, Aleksandar Makelov, Kristian Georgiev, Hadi Salman, Andrew Ilyas, Aleksander Madry",https://proceedings.mlr.press/v202/khaddaj23a.html,,Conference and Workshop Papers,
Chameleon: Adapting to Peer Images for Planting Durable Backdoors in Federated Learning,ICML,2023, (1): 6712-6725,"Yanbo Dai, Songze Li",https://proceedings.mlr.press/v202/dai23a.html,,Conference and Workshop Papers,
Clean-image Backdoor: Attacking Multi-label Models with Poisoned Labels Only,ICLR,2023, (1): 1,"Kangjie Chen, Xiaoxuan Lou, Guowen Xu, Jiwei Li, Tianwei Zhang",https://openreview.net/pdf?id=rFQfjDC9Mt,,Conference and Workshop Papers,
SCALE-UP: An Efficient Black-box Input-level Backdoor Detection via Analyzing Scaled Prediction Consistency,ICLR,2023, (1): 1,"Junfeng Guo, Yiming Li, Xun Chen, Hanqing Guo, Lichao Sun, Cong Liu",https://openreview.net/pdf?id=o0LFPcoFKnr,,Conference and Workshop Papers,
Incompatibility Clustering as a Defense Against Backdoor Poisoning Attacks,ICLR,2023, (1): 1,"Charles Jin, Melinda Sun, Martin C. Rinard",https://openreview.net/pdf?id=mkJm5Uy4HrQ,,Conference and Workshop Papers,
The Dark Side of AutoML: Towards Architectural Backdoor Search,ICLR,2023, (1): 1,"Ren Pang, Changjiang Li, Zhaohan Xi, Shouling Ji, Ting Wang",https://openreview.net/pdf?id=bsZULlDGXe,,Conference and Workshop Papers,
Few-shot Backdoor Attacks via Neural Tangent Kernels,ICLR,2023, (1): 1,"Jonathan Hayase, Sewoong Oh",https://openreview.net/pdf?id=a70lGJ-rwy,,Conference and Workshop Papers,
Revisiting the Assumption of Latent Separability for Backdoor Defenses,ICLR,2023, (1): 1,"Xiangyu Qi, Tinghao Xie, Yiming Li, Saeed Mahloujifar, Prateek Mittal",https://openreview.net/pdf?id=_wSHsgrVali,,Conference and Workshop Papers,
FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning,ICLR,2023, (1): 1,"Kaiyuan Zhang, Guanhong Tao, Qiuling Xu, Siyuan Cheng, Shengwei An, Yingqi Liu, Shiwei Feng, Guangyu Shen, Pin-Yu Chen, Shiqing Ma, Xiangyu Zhang",https://openreview.net/pdf?id=Xo2E217_M4n,,Conference and Workshop Papers,
Distilling Cognitive Backdoor Patterns within an Image,ICLR,2023, (1): 1,"Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey",https://openreview.net/pdf?id=S3D9NLzjnQ5,,Conference and Workshop Papers,
UNICORN: A Unified Backdoor Trigger Inversion Framework,ICLR,2023, (1): 1,"Zhenting Wang, Kai Mei, Juan Zhai, Shiqing Ma",https://openreview.net/pdf?id=Mj7K4lglGyj,,Conference and Workshop Papers,
Towards Robustness Certification Against Universal Perturbations,ICLR 2023 poster,2023,,"Yi Zeng, Zhouxing Shi, Ming Jin, Feiyang Kang, Lingjuan Lyu, Cho-Jui Hsieh, Ruoxi Jia",https://openreview.net/pdf/ee043d338b4d99fee86cf7332af005a6da63696f.pdf,,,
In Search of Smooth Minima for Purifying Backdoor in Deep Neural Networks,Submitted to ICLR 2023,2023,,"Nazmul Karim, Abdullah Al Arafat, Umar Khalid, Zhishan Guo, Nazanin Rahnavard",https://openreview.net/pdf/dff40f4aa1974f2276bb999d06a29c4454686a4d.pdf,,,
Rethinking the Necessity of Labels in Backdoor Removal,ICLR 2023 BANDS Spotlight,2023,,"Zidi Xiong, Dongxian Wu, Yifei Wang, Yisen Wang",https://openreview.net/pdf/bee89f4ca2138baf5b21d76abfc7b5e980dcdfa1.pdf,,,
Backdoor Attacks Against Transformers with Attention Enhancement,ICLR 2023 BANDS Oral,2023,,"Weimin Lyu, Songzhu Zheng, Haibin Ling, Chao Chen",https://openreview.net/pdf/b84e17b59651c6854c9743eb9d89b6283288dce7.pdf,,,
Understanding Adversarial Transferability in Federated Learning,Submitted to ICLR 2023,2023,,"Yijiang Li, ying gao, Dawn Song, Haohan Wang",https://openreview.net/pdf/b4ed1eef00fa301c81f0081c4aada76d1e20acc4.pdf,,,
Backdoor or Feature? A New Perspective on Data Poisoning,Submitted to ICLR 2023,2023,,"Alaa Khaddaj, Guillaume Leclerc, Aleksandar Makelov, Kristian Georgiev, Andrew Ilyas, Hadi Salman, Aleksander Madry",https://openreview.net/pdf/b2755ed779b6e6f9a30bc9352266fecb77f097bc.pdf,,,
Backdoor Mitigation by Correcting Activation Distribution Alteration,Submitted to ICLR 2023,2023,,"Xi Li, Zhen Xiang, George Kesidis, Bo Li, David J. Miller",https://openreview.net/pdf/af27752e75f6e47d933407c498c301e9a5f0e5ec.pdf,,,
Removing Backdoor Behaviors with Unlabeled Data,ICLR 2023 BANDS Oral,2023,,"Lu Pang, Tao Sun, Haibin Ling, Chao Chen",https://openreview.net/pdf/ac5d0cc01ad76c940dbc322f48c9401144517e95.pdf,,,
FLGAME: A Game-theoretic Defense against Backdoor Attacks In Federated Learning,Submitted to ICLR 2023,2023,,"Jinyuan Jia, Zhuowen Yuan, Dinuka Sahabandu, Luyao Niu, Arezoo Rajabi, Bhaskar Ramasubramanian, Bo Li, Radha Poovendran",https://openreview.net/pdf/a6657c2c63a1178e53f3fc6218eaac7d4db2998d.pdf,,,
The Dark Side of AutoML: Towards Architectural Backdoor Search,ICLR 2023 poster,2023,,"Ren Pang, Changjiang Li, Zhaohan Xi, Shouling Ji, Ting Wang",https://openreview.net/pdf/9b89e3f420dd473917d9c33741ea888a54ecb1b3.pdf,,,
An Upper Bound for the Distribution Overlap Index and Its Applications,Submitted to ICLR 2023,2023,,"Hao Fu, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami",https://openreview.net/pdf/91e5cde6c4f432d051e86e64580609fd6ac810a9.pdf,,,
Flareon: Stealthy Backdoor Injection via Poisoned Augmentation,Submitted to ICLR 2023,2023,,"Tianrui Qin, Xitong Gao, Xianghuan He, Yiren Zhao, Kejiang Ye, Cheng-zhong Xu",https://openreview.net/pdf/8f5e6d6b8c53b5115dfb5e4950961efed881feaa.pdf,,,
DEFENDING BACKDOOR ATTACKS VIA ROBUSTNESS AGAINST NOISY LABEL,Submitted to ICLR 2023,2023,,"Boyang Liu, Zhuangdi Zhu, Yijiang Pang, Pang-Ning Tan, Jiayu Zhou",https://openreview.net/pdf/84ee6ba3856600625ef0f6e7fe0a85cff86bafca.pdf,,,
Clean-image Backdoor: Attacking Multi-label Models with Poisoned Labels Only,ICLR 2023 notable top 5%,2023,,"Kangjie Chen, Xiaoxuan Lou, Guowen Xu, Jiwei Li, Tianwei Zhang",https://openreview.net/pdf/6021cbdfd717a31730914f92bc2b1e9762135b65.pdf,,,
Salient Conditional Diffusion for Backdoors,ICLR 2023 BANDS Spotlight,2023,,"Brandon B May, Norman Joseph Tatro, Piyush Kumar, Nathan Shnidman",https://openreview.net/pdf/5ff8b3a86b729b5727377cad27f35a409cdca597.pdf,,,
Do We Really Need Labels for Backdoor Defense?,Submitted to ICLR 2023,2023,,"Zidi Xiong, Dongxian Wu, Yifei Wang, Yisen Wang",https://openreview.net/pdf/5efdc16d5d97d8a695a25cfc1e3fb8c0cb79ccfe.pdf,,,
Trusted Aggregation (TAG): Model Filtering Backdoor Defense In Federated Learning,Submitted to ICLR 2023,2023,,"Joseph Lavond, Minhao Cheng, Yao Li",https://openreview.net/pdf/5d905ba0289cbac9fe40bf8cd02c7aa8f1d15fed.pdf,,,
Interventional Rationalization,Submitted to ICLR 2023,2023,,"Linan Yue, Qi Liu, Li Wang, Yanqing An, Yichao Du, Zhenya Huang",https://openreview.net/pdf/506c51f0c1792a058f9d944d0a0d26fa63ac5ab5.pdf,,,
Unlearning Backdoor Attacks in Federated Learning,ICLR 2023 BANDS Spotlight,2023,,"Chen Wu, SENCUN ZHU, Prasenjit Mitra",https://openreview.net/pdf/4e39585f831617ea3bd02b6b0a4d2e5eee358bf3.pdf,,,
Revisiting the Assumption of Latent Separability for Backdoor Defenses,ICLR 2023 poster,2023,,"Xiangyu Qi, Tinghao Xie, Yiming Li, Saeed Mahloujifar, Prateek Mittal",https://openreview.net/pdf/4c94fe40e30925694ed4ecc84bacd2fc7543b21c.pdf,,,
Attention-Guided Backdoor Attacks against Transformers,Submitted to ICLR 2023,2023,,"Weimin Lyu, Songzhu Zheng, Haibin Ling, Chao Chen",https://openreview.net/pdf/45168b08a417530a4d5a92a408a18c2a1348abdf.pdf,,,
On the Existence of a Trojaned Twin Model,ICLR 2023 BANDS Spotlight,2023,,"Songzhu Zheng, Yikai Zhang, Lu Pang, Weimin Lyu, Mayank Goswami, Anderson Schneider, Yuriy Nevmyvaka, Haibin Ling, Chao Chen",https://openreview.net/pdf/407717d19d51dd1616c9c749c6bd26cfec9d9138.pdf,,,
Exploring Vulnerabilities of Semi-Supervised Learning to Simple Backdoor Attacks,ICLR 2023 BANDS Spotlight,2023,,"Marissa Catherine Connor, Vincent Emanuele",https://openreview.net/pdf/38a9342c8b7fcbfa30b33aa1435745390d4d59ec.pdf,,,
Efficient Trojan Injection: 90% Attack Success Rate Using 0.04% Poisoned Samples,Submitted to ICLR 2023,2023,,"Pengfei Xia, Yueqi Zeng, Ziqiang Li, Wei Zhang, Bin Li",https://openreview.net/pdf/1a61167bf009aabc04f2677a432ebd1bed5e941c.pdf,,,
DLP: Data-Driven Label-Poisoning Backdoor Attack,Submitted to ICLR 2023,2023,,"Xun Xian, Xuan Bi, Mingyi Hong, Jie Ding",https://openreview.net/pdf/185eab633f4819f7b1cac2547817535e4e9fd684.pdf,,,
Poisoning Generative Models to Promote Catastrophic Forgetting,Submitted to ICLR 2023,2023,,"Siteng Kang, Zhan Shi, Xinhua Zhang",https://openreview.net/pdf/18233d1bca0057b7b0f4d192b487416df262f69c.pdf,,,
Efficient and Stealthy Backdoor Attack Triggers are Close at Hand,Submitted to ICLR 2023,2023,,"Minlong Peng, Xu Li, Mingming Sun",https://openreview.net/pdf/0cc88752312703fd9df8726127dbde5242126074.pdf,,,
TrojText: Test-time Invisible Textual Trojan Insertion,ICLR 2023 poster,2023,,"Qian Lou, Yepeng Liu, Bo Feng",https://openreview.net/pdf/090c1fa0cc728fa6eb032fe3c74b8b5125be7e94.pdf,,,
Bayesian Causal Bandits with Backdoor Adjustment Prior,Trans. Mach. Learn. Res.,2023,2023 (1): 1,"Jireh Huang, Qing Zhou",https://openreview.net/forum?id=sMsGv5Kfm3,,Journal Articles,
Fully Hidden Dynamic Trigger Backdoor Attacks,ICAART,2023, (1): 81-91,"Shintaro Narisada, Seira Hidano, Kazuhide Fukushima",https://doi.org/10.5220/0011617800003393,,Conference and Workshop Papers,
Manipulating Trajectory Prediction with Backdoors,arXiv/CoRR,2023,abs/2312.13863 (1): 1,"Kaouther Messaoud, Kathrin Grosse, Mickaël Chen, Matthieu Cord, Patrick Pérez, Alexandre Alahi",https://doi.org/10.48550/arXiv.2312.13863,,Informal and Other Publications,
UltraClean: A Simple Framework to Train Robust Neural Networks against Backdoor Attacks,arXiv/CoRR,2023,abs/2312.10657 (1): 1,"Bingyin Zhao, Yingjie Lao",https://doi.org/10.48550/arXiv.2312.10657,,Informal and Other Publications,
FlowMur: A Stealthy and Practical Audio Backdoor Attack with Limited Knowledge,arXiv/CoRR,2023,abs/2312.09665 (1): 1,"Jiahe Lan, Jie Wang, Baochen Yan, Zheng Yan, Elisa Bertino",https://doi.org/10.48550/arXiv.2312.09665,,Informal and Other Publications,
On the Difficulty of Defending Contrastive Learning against Backdoor Attacks,arXiv/CoRR,2023,abs/2312.09057 (1): 1,"Changjiang Li, Ren Pang, Bochuan Cao, Zhaohan Xi, Jinghui Chen, Shouling Ji, Ting Wang",https://doi.org/10.48550/arXiv.2312.09057,,Informal and Other Publications,
"Data and Model Poisoning Backdoor Attacks on Wireless Federated Learning, and the Defense Mechanisms: A Comprehensive Survey",arXiv/CoRR,2023,abs/2312.08667 (1): 1,"Yichen Wan, Youyang Qu, Wei Ni, Yong Xiang, Longxiang Gao, Ekram Hossain",https://doi.org/10.48550/arXiv.2312.08667,,Informal and Other Publications,
Erasing Self-Supervised Learning Backdoor by Cluster Activation Masking,arXiv/CoRR,2023,abs/2312.07955 (1): 1,"Shengsheng Qian, Yifei Wang, Dizhan Xue, Shengjie Zhang, Huaiwen Zhang, Changsheng Xu",https://doi.org/10.48550/arXiv.2312.07955,,Informal and Other Publications,
Activation Gradient based Poisoned Sample Detection Against Backdoor Attacks,arXiv/CoRR,2023,abs/2312.06230 (1): 1,"Danni Yuan, Shaokui Wei, Mingda Zhang, Li Liu, Baoyuan Wu",https://doi.org/10.48550/arXiv.2312.06230,,Informal and Other Publications,
BELT: Old-School Backdoor Attacks can Evade the State-of-the-Art Defense with Backdoor Exclusivity Lifting,arXiv/CoRR,2023,abs/2312.04902 (1): 1,"Huming Qiu, Junjie Sun, Mi Zhang, Xudong Pan, Min Yang",https://doi.org/10.48550/arXiv.2312.04902,,Informal and Other Publications,
Towards Sample-specific Backdoor Attack with Clean Labels via Attribute Trigger,arXiv/CoRR,2023,abs/2312.04584 (1): 1,"Yiming Li, Mingyan Zhu, Junfeng Guo, Tao Wei, Shu-Tao Xia, Zhan Qin",https://doi.org/10.48550/arXiv.2312.04584,,Informal and Other Publications,
Synthesizing Physical Backdoor Datasets: An Automated Framework Leveraging Deep Generative Models,arXiv/CoRR,2023,abs/2312.03419 (1): 1,"Sze Jue Yang, Chinh D. La, Quang H. Nguyen, Eugene Bagdasaryan, Kok-Seng Wong, Anh Tuan Tran, Chee Seng Chan, Khoa D. Doan",https://doi.org/10.48550/arXiv.2312.03419,,Informal and Other Publications,
Robust Backdoor Detection for Deep Learning via Topological Evolution Dynamics,arXiv/CoRR,2023,abs/2312.02673 (1): 1,"Xiaoxing Mo, Yechao Zhang, Leo Yu Zhang, Wei Luo, Nan Sun, Shengshan Hu, Shang Gao, Yang Xiang",https://doi.org/10.48550/arXiv.2312.02673,,Informal and Other Publications,
OCGEC: One-class Graph Embedding Classification for DNN Backdoor Detection,arXiv/CoRR,2023,abs/2312.01585 (1): 1,"Haoyu Jiang, Haiyang Yu, Nan Li, Ping Yi",https://doi.org/10.48550/arXiv.2312.01585,,Informal and Other Publications,
Universal Backdoor Attacks,arXiv/CoRR,2023,abs/2312.00157 (1): 1,"Benjamin Schneider, Nils Lukas, Florian Kerschbaum",https://doi.org/10.48550/arXiv.2312.00157,,Informal and Other Publications,
Stealthy and Persistent Unalignment on Large Language Models via Backdoor Injections,arXiv/CoRR,2023,abs/2312.00027 (1): 1,"Yuanpu Cao, Bochuan Cao, Jinghui Chen",https://doi.org/10.48550/arXiv.2312.00027,,Informal and Other Publications,
TARGET: Template-Transferable Backdoor Attack Against Prompt-based NLP Models via GPT4,arXiv/CoRR,2023,abs/2311.17429 (1): 1,"Zihao Tan, Qingliang Chen, Yongjian Huang, Chen Liang",https://doi.org/10.48550/arXiv.2311.17429,,Informal and Other Publications,
Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective,arXiv/CoRR,2023,abs/2311.16646 (1): 1,"Ming-Yu Chung, Sheng-Yen Chou, Chia-Mu Yu, Pin-Yu Chen, Sy-Yen Kuo, Tsung-Yi Ho",https://doi.org/10.48550/arXiv.2311.16646,,Informal and Other Publications,
BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP,arXiv/CoRR,2023,abs/2311.16194 (1): 1,"Jiawang Bai, Kuofeng Gao, Shaobo Min, Shu-Tao Xia, Zhifeng Li, Wei Liu",https://doi.org/10.48550/arXiv.2311.16194,,Informal and Other Publications,
BAGEL: Backdoor Attacks against Federated Contrastive Learning,arXiv/CoRR,2023,abs/2311.16113 (1): 1,"Yao Huang, Kongyang Chen, Jiannong Cao, Jiaxing Shen, Shaowei Wang, Yun Peng, Weilong Peng, Kechao Cai",https://doi.org/10.48550/arXiv.2311.16113,,Informal and Other Publications,
Effective Backdoor Mitigation Depends on the Pre-training Objective,arXiv/CoRR,2023,abs/2311.14948 (1): 1,"Sahil Verma, Gantavya Bhatt, Avi Schwarzschild, Soumye Singhal, Arnav Mohanty Das, Chirag Shah, John P. Dickerson, Jeff A. Bilmes",https://doi.org/10.48550/arXiv.2311.14948,,Informal and Other Publications,
Universal Jailbreak Backdoors from Poisoned Human Feedback,arXiv/CoRR,2023,abs/2311.14455 (1): 1,"Javier Rando, Florian Tramèr",https://doi.org/10.48550/arXiv.2311.14455,,Informal and Other Publications,
BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning,arXiv/CoRR,2023,abs/2311.12075 (1): 1,,https://doi.org/10.48550/arXiv.2311.12075,,Withdrawn Items,
TextGuard: Provable Defense against Backdoor Attacks on Text Classification,arXiv/CoRR,2023,abs/2311.11225 (1): 1,"Hengzhi Pei, Jinyuan Jia, Wenbo Guo, Bo Li, Dawn Song",https://doi.org/10.48550/arXiv.2311.11225,,Informal and Other Publications,
FedTruth: Byzantine-Robust and Backdoor-Resilient Federated Learning Framework,arXiv/CoRR,2023,abs/2311.10248 (1): 1,"Sheldon C. Ebron Jr., Kan Yang",https://doi.org/10.48550/arXiv.2311.10248,,Informal and Other Publications,
Test-time Backdoor Mitigation for Black-Box Large Language Models with Defensive Demonstrations,arXiv/CoRR,2023,abs/2311.09763 (1): 1,"Wenjie Mo, Jiashu Xu, Qin Liu, Jiongxiao Wang, Jun Yan, Chaowei Xiao, Muhao Chen",https://doi.org/10.48550/arXiv.2311.09763,,Informal and Other Publications,
Backdoor Activation Attack: Attack Large Language Models using Activation Steering for Safety-Alignment,arXiv/CoRR,2023,abs/2311.09433 (1): 1,"Haoran Wang, Kai Shu",https://doi.org/10.48550/arXiv.2311.09433,,Informal and Other Publications,
Tabdoor: Backdoor Vulnerabilities in Transformer-based Neural Networks for Tabular Data,arXiv/CoRR,2023,abs/2311.07550 (1): 1,"Bart Pleiter, Behrad Tajalli, Stefanos Koffas, Gorka Abad, Jing Xu, Martha A. Larson, Stjepan Picek",https://doi.org/10.48550/arXiv.2311.07550,,Informal and Other Publications,
Mitigating Backdoors within Deep Neural Networks in Data-limited Configuration,arXiv/CoRR,2023,abs/2311.07417 (1): 1,"Soroush Hashemifar, Saeed Parsa, Morteza Zakeri Nasrabadi",https://doi.org/10.48550/arXiv.2311.07417,,Informal and Other Publications,
Does Differential Privacy Prevent Backdoor Attacks in Practice?,arXiv/CoRR,2023,abs/2311.06227 (1): 1,"Fereshteh Razmi, Jian Lou, Li Xiong",https://doi.org/10.48550/arXiv.2311.06227,,Informal and Other Publications,
From Trojan Horses to Castle Walls: Unveiling Bilateral Backdoor Effects in Diffusion Models,arXiv/CoRR,2023,abs/2311.02373 (1): 1,"Zhuoshi Pan, Yuguang Yao, Gaowen Liu, Bingquan Shen, H. Vicky Zhao, Ramana Rao Kompella, Sijia Liu",https://doi.org/10.48550/arXiv.2311.02373,,Informal and Other Publications,
Backdoor Threats from Compromised Foundation Models to Federated Learning,arXiv/CoRR,2023,abs/2311.00144 (1): 1,"Xi Li, Songhe Wang, Chen Wu, Hao Zhou, Jiaqi Wang",https://doi.org/10.48550/arXiv.2311.00144,,Informal and Other Publications,
PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models,arXiv/CoRR,2023,abs/2310.12439 (1): 1,"Hongwei Yao, Jian Lou, Zhan Qin",https://doi.org/10.48550/arXiv.2310.12439,,Informal and Other Publications,
WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks,arXiv/CoRR,2023,abs/2310.11595 (1): 1,"Jun Xia, Zhihao Yue, Yingbo Zhou, Zhiwei Ling, Xian Wei, Mingsong Chen",https://doi.org/10.48550/arXiv.2310.11595,,Informal and Other Publications,
Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning,arXiv/CoRR,2023,abs/2310.11594 (1): 1,"Taejin Kim, Jiarui Li, Shubhranshu Singh, Nikhil Madaan, Carlee Joe-Wong",https://doi.org/10.48550/arXiv.2310.11594,,Informal and Other Publications,
Demystifying Poisoning Backdoor Attacks from a Statistical Perspective,arXiv/CoRR,2023,abs/2310.10780 (1): 1,"Ganghua Wang, Xun Xian, Jayanth Srinivasa, Ashish Kundu, Xuan Bi, Mingyi Hong, Jie Ding",https://doi.org/10.48550/arXiv.2310.10780,,Informal and Other Publications,
Backdoor Attack through Machine Unlearning,arXiv/CoRR,2023,abs/2310.10659 (1): 1,"Peixin Zhang, Jun Sun, Mingtian Tan, Xinyu Wang",https://doi.org/10.48550/arXiv.2310.10659,,Informal and Other Publications,
Explore the Effect of Data Selection on Poison Efficiency in Backdoor Attacks,arXiv/CoRR,2023,abs/2310.09744 (1): 1,"Ziqiang Li, Pengfei Xia, Hong Sun, Yueqi Zeng, Wei Zhang, Bin Li",https://doi.org/10.48550/arXiv.2310.09744,,Informal and Other Publications,
Defending Our Privacy With Backdoors,arXiv/CoRR,2023,abs/2310.08320 (1): 1,"Dominik Hintersdorf, Lukas Struppek, Daniel Neider, Kristian Kersting",https://doi.org/10.48550/arXiv.2310.08320,,Informal and Other Publications,
Invisible Threats: Backdoor Attack in OCR Systems,arXiv/CoRR,2023,abs/2310.08259 (1): 1,"Mauro Conti, Nicola Farronato, Stefanos Koffas, Luca Pajola, Stjepan Picek",https://doi.org/10.48550/arXiv.2310.08259,,Informal and Other Publications,
Composite Backdoor Attacks Against Large Language Models,arXiv/CoRR,2023,abs/2310.07676 (1): 1,"Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang",https://doi.org/10.48550/arXiv.2310.07676,,Informal and Other Publications,
Prompt Backdoors in Visual Prompt Learning,arXiv/CoRR,2023,abs/2310.07632 (1): 1,"Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang",https://doi.org/10.48550/arXiv.2310.07632,,Informal and Other Publications,
High Dimensional Causal Inference with Variational Backdoor Adjustment,arXiv/CoRR,2023,abs/2310.06100 (1): 1,"Daniel Israel, Aditya Grover, Guy Van den Broeck",https://doi.org/10.48550/arXiv.2310.06100,,Informal and Other Publications,
Better Safe than Sorry: Pre-training CLIP against Targeted Data Poisoning and Backdoor Attacks,arXiv/CoRR,2023,abs/2310.05862 (1): 1,"Wenhan Yang, Jingdong Gao, Baharan Mirzasoleiman",https://doi.org/10.48550/arXiv.2310.05862,,Informal and Other Publications,
Confidence-driven Sampling for Backdoor Attacks,arXiv/CoRR,2023,abs/2310.05263 (1): 1,"Pengfei He, Han Xu, Yue Xing, Jie Ren, Yingqian Cui, Shenglai Zeng, Jiliang Tang, Makoto Yamada, Mohammad Sabokrou",https://doi.org/10.48550/arXiv.2310.05263,,Informal and Other Publications,
Backdoor Adjustment of Confounding by Provenance for Robust Text Classification of Multi-institutional Clinical Notes,arXiv/CoRR,2023,abs/2310.02451 (1): 1,"Xiruo Ding, Zhecheng Sheng, Meliha Yetisgen, Serguei Pakhomov, Trevor Cohen",https://doi.org/10.48550/arXiv.2310.02451,,Informal and Other Publications,
GhostEncoder: Stealthy Backdoor Attacks with Dynamic Triggers to Pre-trained Encoders in Self-supervised Learning,arXiv/CoRR,2023,abs/2310.00626 (1): 1,"Qiannan Wang, Changchun Yin, Zhe Liu, Liming Fang, Run Wang, Chenhao Lin",https://doi.org/10.48550/arXiv.2310.00626,,Informal and Other Publications,
Horizontal Class Backdoor to Deep Learning,arXiv/CoRR,2023,abs/2310.00542 (1): 1,"Hua Ma, Shang Wang, Yansong Gao",https://doi.org/10.48550/arXiv.2310.00542,,Informal and Other Publications,
Steganography for Neural Radiance Fields by Backdooring,arXiv/CoRR,2023,abs/2309.10503 (1): 1,"Weina Dong, Jia Liu, Yan Ke, Lifeng Chen, Wenquan Sun, Xiaozhong Pan",https://doi.org/10.48550/arXiv.2309.10503,,Informal and Other Publications,
Robust Backdoor Attacks on Object Detection in Real World,arXiv/CoRR,2023,abs/2309.08953 (1): 1,"Yaguan Qian, Boyuan Ji, Shuke He, Shenhui Huang, Xiang Ling, Bin Wang, Wei Wang",https://doi.org/10.48550/arXiv.2309.08953,,Informal and Other Publications,
Backdoor Attacks and Countermeasures in Natural Language Processing Models: A Comprehensive Security Review,arXiv/CoRR,2023,abs/2309.06055 (1): 1,"Pengzhou Cheng, Zongru Wu, Wei Du, Haodong Zhao, Gongshen Liu",https://doi.org/10.48550/arXiv.2309.06055,,Informal and Other Publications,
BadSQA: Stealthy Backdoor Attacks Using Presence Events as Triggers in Non-Intrusive Speech Quality Assessment,arXiv/CoRR,2023,abs/2309.01480 (1): 1,"Ying Ren, Kailai Shen, Zhe Ye, Diqun Yan",https://doi.org/10.48550/arXiv.2309.01480,,Informal and Other Publications,
FTA: Stealthy and Adaptive Backdoor Attack with Flexible Triggers on Federated Learning,arXiv/CoRR,2023,abs/2309.00127 (1): 1,"Yanqi Qiao, Dazhuang Liu, Congwen Chen, Rui Wang, Kaitai Liang",https://doi.org/10.48550/arXiv.2309.00127,,Informal and Other Publications,
Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack,arXiv/CoRR,2023,abs/2308.16684 (1): 1,"Sze Jue Yang, Quang H. Nguyen, Chee Seng Chan, Khoa Doan",https://doi.org/10.48550/arXiv.2308.16684,,Informal and Other Publications,
A Comprehensive Overview of Backdoor Attacks in Large Language Models within Communication Networks,arXiv/CoRR,2023,abs/2308.14367 (1): 1,"Haomiao Yang, Kunlan Xiang, Hongwei Li, Rongxing Lu",https://doi.org/10.48550/arXiv.2308.14367,,Informal and Other Publications,
LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors,arXiv/CoRR,2023,abs/2308.13904 (1): 1,"Chengkun Wei, Wenlong Meng, Zhikun Zhang, Min Chen, Minghu Zhao, Wenjing Fang, Lei Wang, Zihui Zhang, Wenzhi Chen",https://doi.org/10.48550/arXiv.2308.13904,,Informal and Other Publications,
BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection,arXiv/CoRR,2023,abs/2308.12439 (1): 1,"Tinghao Xie, Xiangyu Qi, Ping He, Yiming Li, Jiachen T. Wang, Prateek Mittal",https://doi.org/10.48550/arXiv.2308.12439,,Informal and Other Publications,
Protect Federated Learning Against Backdoor Attacks via Data-Free Trigger Generation,arXiv/CoRR,2023,abs/2308.11333 (1): 1,"Yanxin Yang, Ming Hu, Yue Cao, Jun Xia, Yihao Huang, Yang Liu, Mingsong Chen",https://doi.org/10.48550/arXiv.2308.11333,,Informal and Other Publications,
Backdooring Textual Inversion for Concept Censorship,arXiv/CoRR,2023,abs/2308.10718 (1): 1,"Yutong Wu, Jie Zhang, Florian Kerschbaum, Tianwei Zhang",https://doi.org/10.48550/arXiv.2308.10718,,Informal and Other Publications,
Hiding Backdoors within Event Sequence Data via Poisoning Attacks,arXiv/CoRR,2023,abs/2308.10201 (1): 1,"Elizaveta Kovtun, Alina Ermilova, Dmitry Berestnev, Alexey Zaytsev",https://doi.org/10.48550/arXiv.2308.10201,,Informal and Other Publications,
Backdoor Mitigation by Correcting the Distribution of Neural Activations,arXiv/CoRR,2023,abs/2308.09850 (1): 1,"Xi Li, Zhen Xiang, David J. Miller, George Kesidis",https://doi.org/10.48550/arXiv.2308.09850,,Informal and Other Publications,
Test-Time Adaptation for Backdoor Defense,arXiv/CoRR,2023,abs/2308.06107 (1): 1,"Jiyang Guan, Jian Liang, Ran He",https://doi.org/10.48550/arXiv.2308.06107,,Informal and Other Publications,
Improved Activation Clipping for Universal Backdoor Mitigation and Test-Time Detection,arXiv/CoRR,2023,abs/2308.04617 (1): 1,"Hang Wang, Zhen Xiang, David J. Miller, George Kesidis",https://doi.org/10.48550/arXiv.2308.04617,,Informal and Other Publications,
Backdoor Federated Learning by Poisoning Backdoor-Critical Layers,arXiv/CoRR,2023,abs/2308.04466 (1): 1,"Haomin Zhuang, Mingxian Yu, Hao Wang, Yang Hua, Jian Li, Xu Yuan",https://doi.org/10.48550/arXiv.2308.04466,,Informal and Other Publications,
You Can Backdoor Personalized Federated Learning,arXiv/CoRR,2023,abs/2307.15971 (1): 1,"Tiandi Ye, Cen Chen, Yinggui Wang, Xiang Li, Ming Gao",https://doi.org/10.48550/arXiv.2307.15971,,Informal and Other Publications,
Backdoor Defense with Non-Adversarial Backdoor,arXiv/CoRR,2023,abs/2307.15539 (1): 1,"Min Liu, Alberto L. Sangiovanni-Vincentelli, Xiangyu Yue",https://doi.org/10.48550/arXiv.2307.15539,,Informal and Other Publications,
Backdoor Attacks for In-Context Learning with Language Models,arXiv/CoRR,2023,abs/2307.14692 (1): 1,"Nikhil Kandpal, Matthew Jagielski, Florian Tramèr, Nicholas Carlini",https://doi.org/10.48550/arXiv.2307.14692,,Informal and Other Publications,
Backdoor Attacks against Voice Recognition Systems: A Survey,arXiv/CoRR,2023,abs/2307.13643 (1): 1,"Baochen Yan, Jiahe Lan, Zheng Yan",https://doi.org/10.48550/arXiv.2307.13643,,Informal and Other Publications,
FMT: Removing Backdoor Feature Maps via Feature Map Testing in Deep Neural Networks,arXiv/CoRR,2023,abs/2307.11565 (1): 1,"Dong Huang, Qingwen Bu, Yahao Qing, Yichao Fu, Heming Cui",https://doi.org/10.48550/arXiv.2307.11565,,Informal and Other Publications,
Backdoor Attack against Object Detection with Clean Annotation,arXiv/CoRR,2023,abs/2307.10487 (1): 1,"Yize Cheng, Wenbin Hu, Minhao Cheng",https://doi.org/10.48550/arXiv.2307.10487,,Informal and Other Publications,
Towards Stealthy Backdoor Attacks against Speech Recognition via Elements of Sound,arXiv/CoRR,2023,abs/2307.08208 (1): 1,"Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao, Stefanos Koffas, Yiming Li",https://doi.org/10.48550/arXiv.2307.08208,,Informal and Other Publications,
Boosting Backdoor Attack with A Learnable Poisoning Sample Selection Strategy,arXiv/CoRR,2023,abs/2307.07328 (1): 1,"Zihao Zhu, Mingda Zhang, Shaokui Wei, Li Shen, Yanbo Fan, Baoyuan Wu",https://doi.org/10.48550/arXiv.2307.07328,,Informal and Other Publications,
Efficient Backdoor Removal Through Natural Gradient Fine-tuning,arXiv/CoRR,2023,abs/2306.17441 (1): 1,"Nazmul Karim, Abdullah Al Arafat, Umar Khalid, Zhishan Guo, Nazanin Rahnavard",https://doi.org/10.48550/arXiv.2306.17441,,Informal and Other Publications,
Fake the Real: Backdoor Attack on Deep Speech Classification via Voice Conversion,arXiv/CoRR,2023,abs/2306.15875 (1): 1,"Zhe Ye, Terui Mao, Li Dong, Diqun Yan",https://doi.org/10.48550/arXiv.2306.15875,,Informal and Other Publications,
IMPOSITION: Implicit Backdoor Attack through Scenario Injection,arXiv/CoRR,2023,abs/2306.15755 (1): 1,"Mozhgan PourKeshavarz, Mohammad Sabokrou, Amir Rasouli",https://doi.org/10.48550/arXiv.2306.15755,,Informal and Other Publications,
Bkd-FedGNN: A Benchmark for Classification Backdoor Attacks on Federated Graph Neural Network,arXiv/CoRR,2023,abs/2306.10351 (1): 1,"Fan Liu, Siqi Lai, Yansong Ning, Hao Liu",https://doi.org/10.48550/arXiv.2306.10351,,Informal and Other Publications,
Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios,arXiv/CoRR,2023,abs/2306.08386 (1): 1,"Hong Sun, Ziqiang Li, Pengfei Xia, Heng Li, Beihao Xia, Yi Wu, Bin Li",https://doi.org/10.48550/arXiv.2306.08386,,Informal and Other Publications,
A Proxy-Free Strategy for Practically Improving the Poisoning Efficiency in Backdoor Attacks,arXiv/CoRR,2023,abs/2306.08313 (1): 1,"Ziqiang Li, Hong Sun, Pengfei Xia, Beihao Xia, Xue Rui, Wei Zhang, Bin Li",https://doi.org/10.48550/arXiv.2306.08313,,Informal and Other Publications,
Backdoor Attack with Sparse and Invisible Trigger,arXiv/CoRR,2023,abs/2306.06209 (1): 1,"Yinghua Gao, Yiming Li, Xueluan Gong, Shu-Tao Xia, Qian Wang",https://doi.org/10.48550/arXiv.2306.06209,,Informal and Other Publications,
G2uardFL: Safeguarding Federated Learning Against Backdoor Attacks through Attributed Client Graph Clustering,arXiv/CoRR,2023,abs/2306.04984 (1): 1,"Hao Yu, Chuan Ma, Meng Liu, Xinwang Liu, Zhe Liu, Ming Ding",https://doi.org/10.48550/arXiv.2306.04984,,Informal and Other Publications,
Mitigating Backdoor Attack Via Prerequisite Transformation,arXiv/CoRR,2023,abs/2306.01983 (1): 1,Han Gao,https://doi.org/10.48550/arXiv.2306.01983,,Informal and Other Publications,
"Robust Backdoor Attack with Visible, Semantic, Sample-Specific, and Compatible Triggers",arXiv/CoRR,2023,abs/2306.00816 (1): 1,"Ruotong Wang, Hongrui Chen, Zihao Zhu, Li Liu, Yong Zhang, Yanbo Fan, Baoyuan Wu",https://doi.org/10.48550/arXiv.2306.00816,,Informal and Other Publications,
Backdoor Attacks Against Incremental Learners: An Empirical Evaluation Study,arXiv/CoRR,2023,abs/2305.18384 (1): 1,"Yiqi Zhong, Xianming Liu, Deming Zhai, Junjun Jiang, Xiangyang Ji",https://doi.org/10.48550/arXiv.2305.18384,,Informal and Other Publications,
IMBERT: Making BERT Immune to Insertion-based Backdoor Attacks,arXiv/CoRR,2023,abs/2305.16503 (1): 1,"Xuanli He, Jun Wang, Benjamin I. P. Rubinstein, Trevor Cohn",https://doi.org/10.48550/arXiv.2305.16503,,Informal and Other Publications,
From Shortcuts to Triggers: Backdoor Defense with Denoised PoE,arXiv/CoRR,2023,abs/2305.14910 (1): 1,"Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen",https://doi.org/10.48550/arXiv.2305.14910,,Informal and Other Publications,
Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models,arXiv/CoRR,2023,abs/2305.14710 (1): 1,"Jiashu Xu, Mingyu Derek Ma, Fei Wang, Chaowei Xiao, Muhao Chen",https://doi.org/10.48550/arXiv.2305.14710,,Informal and Other Publications,
Zero-Day Backdoor Attack against Text-to-Image Diffusion Models via Personalization,arXiv/CoRR,2023,abs/2305.10701 (1): 1,"Yihao Huang, Qing Guo, Felix Juefei-Xu",https://doi.org/10.48550/arXiv.2305.10701,,Informal and Other Publications,
Towards Invisible Backdoor Attacks in the Frequency Domain against Deep Neural Networks,arXiv/CoRR,2023,abs/2305.10596 (1): 1,"Xinrui Liu, Yajie Wang, Yu-An Tan, Kefan Qiu, Yuanzhang Li",https://doi.org/10.48550/arXiv.2305.10596,,Informal and Other Publications,
Stealthy Low-frequency Backdoor Attack against Deep Neural Networks,arXiv/CoRR,2023,abs/2305.09677 (1): 1,"Xinrui Liu, Yu-an Tan, Yajie Wang, Kefan Qiu, Yuanzhang Li",https://doi.org/10.48550/arXiv.2305.09677,,Informal and Other Publications,
UOR: Universal Backdoor Attacks on Pre-trained Language Models,arXiv/CoRR,2023,abs/2305.09574 (1): 1,"Wei Du, Peixuan Li, Boqun Li, Haodong Zhao, Gongshen Liu",https://doi.org/10.48550/arXiv.2305.09574,,Informal and Other Publications,
Backdoor to the Hidden Ground State: Planted Vertex Cover Example,arXiv/CoRR,2023,abs/2305.06610 (1): 1,"Xin-Yi Fan, Hai-Jun Zhou",https://doi.org/10.48550/arXiv.2305.06610,,Informal and Other Publications,
BadCS: A Backdoor Attack Framework for Code search,arXiv/CoRR,2023,abs/2305.05503 (1): 1,"Shiyi Qi, Yuanhang Yang, Shuzheng Gao, Cuiyun Gao, Zenglin Xu",https://doi.org/10.48550/arXiv.2305.05503,,Informal and Other Publications,
BadSAM: Exploring Security Vulnerabilities of SAM via Backdoor Attacks,arXiv/CoRR,2023,abs/2305.03289 (1): 1,"Zihan Guan, Mengxuan Hu, Zhongliang Zhou, Jielu Zhang, Sheng Li, Ninghao Liu",https://doi.org/10.48550/arXiv.2305.03289,,Informal and Other Publications,
Backdoor Learning on Sequence to Sequence Models,arXiv/CoRR,2023,abs/2305.02424 (1): 1,"Lichang Chen, Minhao Cheng, Heng Huang",https://doi.org/10.48550/arXiv.2305.02424,,Informal and Other Publications,
DABS: Data-Agnostic Backdoor attack at the Server in Federated Learning,arXiv/CoRR,2023,abs/2305.01267 (1): 1,"Wenqiang Sun, Sen Li, Yuchang Sun, Jun Zhang",https://doi.org/10.48550/arXiv.2305.01267,,Informal and Other Publications,
ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger,arXiv/CoRR,2023,abs/2304.14475 (1): 1,"Jiazhao Li, Yijin Yang, Zhuofeng Wu, V. G. Vinod Vydiswaran, Chaowei Xiao",https://doi.org/10.48550/arXiv.2304.14475,,Informal and Other Publications,
BadGPT: Exploring Security Vulnerabilities of ChatGPT via Backdoor Attacks to InstructGPT,arXiv/CoRR,2023,abs/2304.12298 (1): 1,"Jiawen Shi, Yixin Liu, Pan Zhou, Lichao Sun",https://doi.org/10.48550/arXiv.2304.12298,,Informal and Other Publications,
Universal Adversarial Backdoor Attacks to Fool Vertical Federated Learning in Cloud-Edge Collaboration,arXiv/CoRR,2023,abs/2304.11432 (1): 1,"Peng Chen, Xin Du, Zhihui Lu, Hongfeng Chai",https://doi.org/10.48550/arXiv.2304.11432,,Informal and Other Publications,
Launching a Robust Backdoor Attack under Capability Constrained Scenarios,arXiv/CoRR,2023,abs/2304.10985 (1): 1,"Ming Yi, Yixiao Xu, Kangyi Ding, Mingyong Yin, Xiaolei Liu",https://doi.org/10.48550/arXiv.2304.10985,,Informal and Other Publications,
Get Rid Of Your Trail: Remotely Erasing Backdoors in Federated Learning,arXiv/CoRR,2023,abs/2304.10638 (1): 1,"Manaar Alam, Hithem Lamri, Michail Maniatakos",https://doi.org/10.48550/arXiv.2304.10638,,Informal and Other Publications,
BadVFL: Backdoor Attacks in Vertical Federated Learning,arXiv/CoRR,2023,abs/2304.08847 (1): 1,"Mohammad Naseri, Yufei Han, Emiliano De Cristofaro",https://doi.org/10.48550/arXiv.2304.08847,,Informal and Other Publications,
Evil from Within: Machine Learning Backdoors through Hardware Trojans,arXiv/CoRR,2023,abs/2304.08411 (1): 1,"Alexander Warnecke, Julian Speith, Jan-Niklas Möller, Konrad Rieck, Christof Paar",https://doi.org/10.48550/arXiv.2304.08411,,Informal and Other Publications,
Recover Triggered States: Protect Model Against Backdoor Attack in Reinforcement Learning,arXiv/CoRR,2023,abs/2304.00252 (1): 1,"Hao Chen, Chen Gong, Yizhe Wang, Xinwen Hou",https://doi.org/10.48550/arXiv.2304.00252,,Informal and Other Publications,
Mask and Restore: Blind Backdoor Defense at Test Time with Masked Autoencoder,arXiv/CoRR,2023,abs/2303.15564 (1): 1,"Tao Sun, Lu Pang, Chao Chen, Haibin Ling",https://doi.org/10.48550/arXiv.2303.15564,,Informal and Other Publications,
Backdoor Attacks with Input-unique Triggers in NLP,arXiv/CoRR,2023,abs/2303.14325 (1): 1,"Xukun Zhou, Jiwei Li, Tianwei Zhang, Lingjuan Lyu, Muqiao Yang, Jun He",https://doi.org/10.48550/arXiv.2303.14325,,Informal and Other Publications,
PoisonedGNN: Backdoor Attack on Graph Neural Networks-based Hardware Security Systems,arXiv/CoRR,2023,abs/2303.14009 (1): 1,"Lilas Alrahis, Satwik Patnaik, Muhammad Abdullah Hanif, Muhammad Shafique, Ozgur Sinanoglu",https://doi.org/10.48550/arXiv.2303.14009,,Informal and Other Publications,
Do Backdoors Assist Membership Inference Attacks?,arXiv/CoRR,2023,abs/2303.12589 (1): 1,"Yumeki Goto, Nami Ashizawa, Toshiki Shibahara, Naoto Yanai",https://doi.org/10.48550/arXiv.2303.12589,,Informal and Other Publications,
Influencer Backdoor Attack on Semantic Segmentation,arXiv/CoRR,2023,abs/2303.12054 (1): 1,"Haoheng Lan, Jindong Gu, Philip H. S. Torr, Hengshuang Zhao",https://doi.org/10.48550/arXiv.2303.12054,,Informal and Other Publications,
Did You Train on My Dataset? Towards Public Dataset Protection with Clean-Label Backdoor Watermarking,arXiv/CoRR,2023,abs/2303.11470 (1): 1,"Ruixiang Tang, Qizhang Feng, Ninghao Liu, Fan Yang, Xia Hu",https://doi.org/10.48550/arXiv.2303.11470,,Informal and Other Publications,
Learning to Backdoor Federated Learning,arXiv/CoRR,2023,abs/2303.03320 (1): 1,"Henger Li, Chen Wu, Sencun Zhu, Zizhan Zheng",https://doi.org/10.48550/arXiv.2303.03320,,Informal and Other Publications,
Backdoor for Debias: Mitigating Model Bias with Backdoor Attack-based Artificial Bias,arXiv/CoRR,2023,abs/2303.01504 (1): 1,"Shangxi Wu, Qiuyang He, Fangzhao Wu, Jitao Sang, Yaowei Wang, Changsheng Xu",https://doi.org/10.48550/arXiv.2303.01504,,Informal and Other Publications,
Mitigating Backdoors in Federated Learning with FLD,arXiv/CoRR,2023,abs/2303.00302 (1): 1,"Yihang Lin, Pengyuan Zhou, Zhiqian Wu, Yong Liao",https://doi.org/10.48550/arXiv.2303.00302,,Informal and Other Publications,
A semantic backdoor attack against Graph Convolutional Networks,arXiv/CoRR,2023,abs/2302.14353 (1): 1,"Jiazhu Dai, Zhipeng Xiong",https://doi.org/10.48550/arXiv.2302.14353,,Informal and Other Publications,
SATBA: An Invisible Backdoor Attack Based On Spatial Attention,arXiv/CoRR,2023,abs/2302.13056 (1): 1,"Huasong Zhou, Zhenyu Wang, Xiaowei Xu",https://doi.org/10.48550/arXiv.2302.13056,,Informal and Other Publications,
Analyzing And Editing Inner Mechanisms Of Backdoored Language Models,arXiv/CoRR,2023,abs/2302.12461 (1): 1,"Max Lamparth, Anka Reuel",https://doi.org/10.48550/arXiv.2302.12461,,Informal and Other Publications,
"Adversarial Machine Learning: A Systematic Survey of Backdoor Attack, Weight Attack and Adversarial Example",arXiv/CoRR,2023,abs/2302.09457 (1): 1,"Baoyuan Wu, Li Liu, Zihao Zhu, Qingshan Liu, Zhaofeng He, Siwei Lyu",https://doi.org/10.48550/arXiv.2302.09457,,Informal and Other Publications,
RobustNLP: A Technique to Defend NLP Models Against Backdoor Attacks,arXiv/CoRR,2023,abs/2302.09420 (1): 1,Marwan Omar,https://doi.org/10.48550/arXiv.2302.09420,,Informal and Other Publications,
Backdoor Attacks to Pre-trained Unified Foundation Models,arXiv/CoRR,2023,abs/2302.09360 (1): 1,"Zenghui Yuan, Yixin Liu, Kai Zhang, Pan Zhou, Lichao Sun",https://doi.org/10.48550/arXiv.2302.09360,,Informal and Other Publications,
"Backdoor Learning for NLP: Recent Advances, Challenges, and Future Research Directions",arXiv/CoRR,2023,abs/2302.06801 (1): 1,Marwan Omar,https://doi.org/10.48550/arXiv.2302.06801,,Informal and Other Publications,
Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural Networks with Neuromorphic Data,arXiv/CoRR,2023,abs/2302.06279 (1): 1,"Gorka Abad, Oguzhan Ersoy, Stjepan Picek, Aitor Urbieta",https://doi.org/10.48550/arXiv.2302.06279,,Informal and Other Publications,
Hyperparameter Search Is All You Need For Training-Agnostic Backdoor Robustness,arXiv/CoRR,2023,abs/2302.04977 (1): 1,"Eugene Bagdasaryan, Vitaly Shmatikov",https://doi.org/10.48550/arXiv.2302.04977,,Informal and Other Publications,
Imperceptible Sample-Specific Backdoor to DNN with Denoising Autoencoder,arXiv/CoRR,2023,abs/2302.04457 (1): 1,"Jiliang Zhang, Jing Xu, Zhi Zhang, Yansong Gao",https://doi.org/10.48550/arXiv.2302.04457,,Informal and Other Publications,
BackdoorBox: A Python Toolbox for Backdoor Learning,arXiv/CoRR,2023,abs/2302.01762 (1): 1,"Yiming Li, Mengxi Ya, Yang Bai, Yong Jiang, Shu-Tao Xia",https://doi.org/10.48550/arXiv.2302.01762,,Informal and Other Publications,
A Systematic Evaluation of Backdoor Trigger Characteristics in Image Classification,arXiv/CoRR,2023,abs/2302.01740 (1): 1,"Gorka Abad, Jing Xu, Stefanos Koffas, Behrad Tajalli, Stjepan Picek",https://doi.org/10.48550/arXiv.2302.01740,,Informal and Other Publications,
Universal Soldier: Using Universal Adversarial Perturbations for Detecting Backdoor Attacks,arXiv/CoRR,2023,abs/2302.00747 (1): 1,"Xiaoyun Xu, Oguzhan Ersoy, Stjepan Picek",https://doi.org/10.48550/arXiv.2302.00747,,Informal and Other Publications,
Salient Conditional Diffusion for Defending Against Backdoor Attacks,arXiv/CoRR,2023,abs/2301.13862 (1): 1,"Brandon B. May, N. Joseph Tatro, Piyush Kumar, Nathan Shnidman",https://doi.org/10.48550/arXiv.2301.13862,,Informal and Other Publications,
Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering,arXiv/CoRR,2023,abs/2301.12318 (1): 1,"Rui Zhu, Di Tang, Siyuan Tang, Guanhong Tao, Shiqing Ma, XiaoFeng Wang, Haixu Tang",https://doi.org/10.48550/arXiv.2301.12318,,Informal and Other Publications,
PECAN: A Deterministic Certified Defense Against Backdoor Attacks,arXiv/CoRR,2023,abs/2301.11824 (1): 1,"Yuhao Zhang, Aws Albarghouthi, Loris D&apos;Antoni",https://doi.org/10.48550/arXiv.2301.11824,,Informal and Other Publications,
Backdoor Attacks in Peer-to-Peer Federated Learning,arXiv/CoRR,2023,abs/2301.09732 (1): 1,"Gökberk Yar, Cristina Nita-Rotaru, Alina Oprea",https://doi.org/10.48550/arXiv.2301.09732,,Informal and Other Publications,
Silent Killer: Optimizing Backdoor Trigger Yields a Stealthy and Powerful Data Poisoning Attack,arXiv/CoRR,2023,abs/2301.02615 (1): 1,"Tzvi Lederer, Gallil Maimon, Lior Rokach",https://doi.org/10.48550/arXiv.2301.02615,,Informal and Other Publications,
"Look, Listen, and Attack: Backdoor Attacks Against Video Action Recognition",arXiv/CoRR,2023,abs/2301.00986 (1): 1,"Hasan Abed Al Kader Hammoud, Shuming Liu, Mohammad Alkhrashi, Fahad Albalawi, Bernard Ghanem",https://doi.org/10.48550/arXiv.2301.00986,,Informal and Other Publications,
Edge-Cloud Collaborative Defense against Backdoor Attacks in Federated Learning,Sensors,2023,23 (3): 1052,"Jie Yang, Jun Zheng, Haochen Wang, Jiaxing Li, Haipeng Sun, Weifeng Han, Nan Jiang, Yu-An Tan",https://doi.org/10.3390/s23031052,,Journal Articles,
Robust Feature-Guided Generative Adversarial Network for Aerial Image Semantic Segmentation against Backdoor Attacks,Remote. Sens.,2023,15 (10): 2580,"Zhen Wang, Buhong Wang, Chuanlei Zhang, Yaohui Liu, Jianxin Guo",https://doi.org/10.3390/rs15102580,,Journal Articles,
Backdoor Attack against Face Sketch Synthesis,Entropy,2023,25 (7): 974,"Shengchuan Zhang, Suhang Ye",https://doi.org/10.3390/e25070974,,Journal Articles,
A Textual Backdoor Defense Method Based on Deep Feature Classification,Entropy,2023,25 (2): 220,"Kun Shao, Jun-an Yang, Pengjiang Hu, Xiaoshuai Li",https://doi.org/10.3390/e25020220,,Journal Articles,
A New Idea for RSA Backdoors,Cryptogr.,2023,7 (3): 45,Marco Cesati,https://doi.org/10.3390/cryptography7030045,,Journal Articles,
Invisible Backdoor Attacks Using Data Poisoning in Frequency Domain,ECAI,2023, (1): 2954-2961,"Chang Yue, Peizhuo Lv, Ruigang Liang, Kai Chen",https://doi.org/10.3233/FAIA230610,,Conference and Workshop Papers,
XGBD: Explanation-Guided Graph Backdoor Detection,ECAI,2023, (1): 932-939,"Zihan Guan, Mengnan Du, Ninghao Liu",https://doi.org/10.3233/FAIA230363,,Conference and Workshop Papers,
Orion: Online Backdoor Sample Detection via Evolution Deviance,IJCAI,2023, (1): 864-874,"Huayang Huang, Qian Wang, Xueluan Gong, Tao Wang",https://doi.org/10.24963/ijcai.2023/96,,Conference and Workshop Papers,
Adversarial Clean Label Backdoor Attacks and Defenses on Text Classification Systems,RepL4NLP@ACL,2023, (1): 1-12,"Ashim Gupta, Amrith Krishna",https://doi.org/10.18653/v1/2023.repl4nlp-1.1,,Conference and Workshop Papers,
Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers,EMNLP,2023, (1): 12499-12527,"Wencong You, Zayd Hammoudeh, Daniel Lowd",https://doi.org/10.18653/v1/2023.findings-emnlp.833,,Conference and Workshop Papers,
Attention-Enhancing Backdoor Attacks Against BERT-based Models,EMNLP,2023, (1): 10672-10690,"Weimin Lyu, Songzhu Zheng, Lu Pang, Haibin Ling, Chao Chen",https://doi.org/10.18653/v1/2023.findings-emnlp.716,,Conference and Workshop Papers,
Defending against Insertion-based Textual Backdoor Attacks via Attribution,ACL,2023, (1): 8818-8833,"Jiazhao Li, Zhuofeng Wu, Wei Ping, Chaowei Xiao, V. G. Vinod Vydiswaran",https://doi.org/10.18653/v1/2023.findings-acl.561,,Conference and Workshop Papers,
"Maximum Entropy Loss, the Silver Bullet Targeting Backdoor Attacks in Pre-trained Language Models",ACL,2023, (1): 3850-3868,"Zhengxiao Liu, Bowen Shen, Zheng Lin, Fali Wang, Weiping Wang",https://doi.org/10.18653/v1/2023.findings-acl.237,,Conference and Workshop Papers,
Diffusion Theory as a Scalpel: Detecting and Purifying Poisonous Dimensions in Pre-trained Language Models Caused by Backdoor or Bias,ACL,2023, (1): 2495-2517,"Zhiyuan Zhang, Deli Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun",https://doi.org/10.18653/v1/2023.findings-acl.157,,Conference and Workshop Papers,
Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models,EMNLP,2023, (1): 12303-12317,"Shuai Zhao, Jinming Wen, Anh Tuan Luu, Junbo Zhao, Jie Fu",https://doi.org/10.18653/v1/2023.emnlp-main.757,,Conference and Workshop Papers,
Mitigating Backdoor Poisoning Attacks through the Lens of Spurious Correlation,EMNLP,2023, (1): 953-967,"Xuanli He, Qiongkai Xu, Jun Wang, Benjamin I. P. Rubinstein, Trevor Cohn",https://doi.org/10.18653/v1/2023.emnlp-main.60,,Conference and Workshop Papers,
NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models,ACL,2023, (1): 15551-15565,"Kai Mei, Zheng Li, Zhenting Wang, Yang Zhang, Shiqing Ma",https://doi.org/10.18653/v1/2023.acl-long.867,,Conference and Workshop Papers,
BITE: Textual Backdoor Attacks with Iterative Trigger Injection,ACL,2023, (1): 12951-12968,"Jun Yan, Vansh Gupta, Xiang Ren",https://doi.org/10.18653/v1/2023.acl-long.725,,Conference and Workshop Papers,
Backdooring Neural Code Search,ACL,2023, (1): 9692-9708,"Weisong Sun, Yuchen Chen, Guanhong Tao, Chunrong Fang, Xiangyu Zhang, Quanjun Zhang, Bin Luo",https://doi.org/10.18653/v1/2023.acl-long.540,,Conference and Workshop Papers,
Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark,ACL,2023, (1): 7653-7668,"Wenjun Peng, Jingwei Yi, Fangzhao Wu, Shangxi Wu, Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu, Guangzhong Sun, Xing Xie",https://doi.org/10.18653/v1/2023.acl-long.423,,Conference and Workshop Papers,
Multi-target Backdoor Attacks for Code Pre-trained Models,ACL,2023, (1): 7236-7254,"Yanzhou Li, Shangqing Liu, Kangjie Chen, Xiaofei Xie, Tianwei Zhang, Yang Liu",https://doi.org/10.18653/v1/2023.acl-long.399,,Conference and Workshop Papers,
A Gradient Control Method for Backdoor Attacks on Parameter-Efficient Tuning,ACL,2023, (1): 3508-3520,"Naibin Gu, Peng Fu, Xiyu Liu, Zhengxiao Liu, Zheng Lin, Weiping Wang",https://doi.org/10.18653/v1/2023.acl-long.194,,Conference and Workshop Papers,
Poisoning with Cerberus: Stealthy and Colluded Backdoor Attack against Federated Learning,AAAI,2023, (1): 9020-9028,"Xiaoting Lyu, Yufei Han, Wei Wang, Jingkai Liu, Bin Wang, Jiqiang Liu, Xiangliang Zhang",https://doi.org/10.1609/aaai.v37i7.26083,,Conference and Workshop Papers,
Defending against Backdoor Attacks in Natural Language Generation,AAAI,2023, (1): 5257-5265,"Xiaofei Sun, Xiaoya Li, Yuxian Meng, Xiang Ao, Lingjuan Lyu, Jiwei Li, Tianwei Zhang",https://doi.org/10.1609/aaai.v37i4.25656,,Conference and Workshop Papers,
Probabilistic Generalization of Backdoor Trees with Application to SAT,AAAI,2023, (1): 4095-4103,"Alexander A. Semenov, Daniil Chivilikhin, Stepan Kochemazov, Ibragim Dzhiblavi",https://doi.org/10.1609/aaai.v37i4.25525,,Conference and Workshop Papers,
Poisoning-Based Backdoor Attacks in Computer Vision,AAAI,2023, (1): 16121-16122,Yiming Li,https://doi.org/10.1609/aaai.v37i13.26921,,Conference and Workshop Papers,
On the Vulnerability of Backdoor Defenses for Federated Learning,AAAI,2023, (1): 11800-11808,"Pei Fang, Jinghui Chen",https://doi.org/10.1609/aaai.v37i10.26393,,Conference and Workshop Papers,
Defending Backdoor Attacks on Vision Transformer via Patch Processing,AAAI,2023, (1): 506-515,"Khoa D. Doan, Yingjie Lao, Peng Yang, Ping Li",https://doi.org/10.1609/aaai.v37i1.25125,,Conference and Workshop Papers,
NBA: defensive distillation for backdoor removal via neural behavior alignment,Cybersecur.,2023,6 (1): 20,"Zonghao Ying, Bin Wu",https://doi.org/10.1186/s42400-023-00154-z,,Journal Articles,
DLP: towards active defense against backdoor attacks with decoupled learning process,Cybersecur.,2023,6 (1): 9,"Zonghao Ying, Bin Wu",https://doi.org/10.1186/s42400-023-00141-4,,Journal Articles,
IPCADP-Equalizer: An Improved Multibalance Privacy Preservation Scheme against Backdoor Attacks in Federated Learning,Int. J. Intell. Syst.,2023,2023 (1): 1-20,"Wenjuan Lian, Yichi Zhang, Xin Chen, Bin Jia, Xiaosong Zhang",https://doi.org/10.1155/2023/6357750,,Journal Articles,
Feature-Based Graph Backdoor Attack in the Node Classification Task,Int. J. Intell. Syst.,2023,2023 (1): 1-13,"Yang Chen, Zhonglin Ye, Haixing Zhao, Ying Wang",https://doi.org/10.1155/2023/5418398,,Journal Articles,
Robust Sentiment Classification Based on the Backdoor Adjustment,MLNLP,2023, (1): 41-47,"Lulu Dai, Mingyue Han",https://doi.org/10.1145/3639479.3639488,,Conference and Workshop Papers,
FLEDGE: Ledger-based Federated Learning Resilient to Inference and Backdoor Attacks,ACSAC,2023, (1): 647-661,"Jorge Castillo, Phillip Rieger, Hossein Fereidooni, Qian Chen, Ahmad-Reza Sadeghi",https://doi.org/10.1145/3627106.3627194,,Conference and Workshop Papers,
SEBD: Sensor Emulation Based Backdoor for Autopilot,IoT,2023, (1): 265-269,"Yue Wang, Chao Yang, Ning Xi, Yulong Shen, Jianfeng Ma",https://doi.org/10.1145/3627050.3631577,,Conference and Workshop Papers,
FedDefender: Backdoor Attack Defense in Federated Learning,SE4SafeML@SIGSOFT FSE,2023, (1): 6-9,"Waris Gill, Ali Anwar, Muhammad Ali Gulzar",https://doi.org/10.1145/3617574.3617858,,Conference and Workshop Papers,
Did You Train on My Dataset? Towards Public Dataset Protection with CleanLabel Backdoor Watermarking,SIGKDD Explor.,2023,25 (1): 43-53,"Ruixiang Tang, Qizhang Feng, Ninghao Liu, Fan Yang, Xia Hu",https://doi.org/10.1145/3606274.3606279,,Journal Articles,
Lookin&apos; Out My Backdoor! Investigating Backdooring Attacks Against DL-driven Malware Detectors,AISec@CCS,2023, (1): 209-220,"Mario D&apos;Onghia, Federico Di Cesare, Luigi Gallo, Michele Carminati, Mario Polino, Stefano Zanero",https://doi.org/10.1145/3605764.3623919,,Conference and Workshop Papers,
B3: Backdoor Attacks against Black-box Machine Learning Models,ACM Trans. Priv. Secur.,2023,26 (4): 43:1-43:24,"Xueluan Gong, Yanjiao Chen, Wenbin Yang, Huayang Huang, Qian Wang",https://doi.org/10.1145/3605212,,Journal Articles,
Exploiting a Benign Loudspeaker as Magnetic Backdoor for Practical Injection Attacks,ACM TUR-C,2023, (1): 145-147,"Tiantian Liu, Feng Lin",https://doi.org/10.1145/3603165.3607443,,Conference and Workshop Papers,
Blind Concealment from Reconstruction-based Attack Detectors for Industrial Control Systems via Backdoor Attacks,CPSS@AsiaCCS,2023, (1): 36-47,"Tim Walita, Alessandro Erba, John Henry Castellanos, Nils Ole Tippenhauer",https://doi.org/10.1145/3592538.3594271,,Conference and Workshop Papers,
Attacking Neural Networks with Neural Networks: Towards Deep Synchronization for Backdoor Attacks,CIKM,2023, (1): 608-618,"Zihan Guan, Lichao Sun, Mengnan Du, Ninghao Liu",https://doi.org/10.1145/3583780.3614784,,Conference and Workshop Papers,
The Silent Manipulator: A Practical and Inaudible Backdoor Attack against Speech Recognition Systems,ACM Multimedia,2023, (1): 7849-7858,"Zhicong Zheng, Xinfeng Li, Chen Yan, Xiaoyu Ji, Wenyuan Xu",https://doi.org/10.1145/3581783.3613843,,Conference and Workshop Papers,
Physical Invisible Backdoor Based on Camera Imaging,ACM Multimedia,2023, (1): 7817-7825,"Yusheng Guo, Nan Zhong, Zhenxing Qian, Xinpeng Zhang",https://doi.org/10.1145/3581783.3612476,,Conference and Workshop Papers,
PointCRT: Detecting Backdoor in 3D Point Cloud via Corruption Robustness,ACM Multimedia,2023, (1): 666-675,"Shengshan Hu, Wei Liu, Minghui Li, Yechao Zhang, Xiaogeng Liu, Xianlong Wang, Leo Yu Zhang, Junhui Hou",https://doi.org/10.1145/3581783.3612456,,Conference and Workshop Papers,
Model-Contrastive Learning for Backdoor Elimination,ACM Multimedia,2023, (1): 8869-8880,"Zhihao Yue, Jun Xia, Zhiwei Ling, Ming Hu, Ting Wang, Xian Wei, Mingsong Chen",https://doi.org/10.1145/3581783.3612415,,Conference and Workshop Papers,
ACQ: Few-shot Backdoor Defense via Activation Clipping and Quantizing,ACM Multimedia,2023, (1): 5410-5418,"Yulin Jin, Xiaoyu Zhang, Jian Lou, Xiaofeng Chen",https://doi.org/10.1145/3581783.3612410,,Conference and Workshop Papers,
Text-to-Image Diffusion Models can be Easily Backdoored through Multimodal Data Poisoning,ACM Multimedia,2023, (1): 1577-1587,"Shengfang Zhai, Yinpeng Dong, Qingni Shen, Shi Pu, Yuejian Fang, Hang Su",https://doi.org/10.1145/3581783.3612108,,Conference and Workshop Papers,
PatchBackdoor: Backdoor Attack against Deep Neural Networks without Model Modification,ACM Multimedia,2023, (1): 9134-9142,"Yizhen Yuan, Rui Kong, Shenghao Xie, Yuanchun Li, Yunxin Liu",https://doi.org/10.1145/3581783.3612032,,Conference and Workshop Papers,
Moiré Backdoor Attack (MBA): A Novel Trigger for Pedestrian Detectors in the Physical World,ACM Multimedia,2023, (1): 8828-8838,"Hui Wei, Hanxun Yu, Kewei Zhang, Zhixiang Wang, Jianke Zhu, Zheng Wang",https://doi.org/10.1145/3581783.3611910,,Conference and Workshop Papers,
Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks,KDD,2023, (1): 4743-4755,"Zeyu Qin, Liuyi Yao, Daoyuan Chen, Yaliang Li, Bolin Ding, Minhao Cheng",https://doi.org/10.1145/3580305.3599898,,Conference and Workshop Papers,
CASSOCK: Viable Backdoor Attacks against DNN in the Wall of Source-Specific Backdoor Defenses,AsiaCCS,2023, (1): 938-950,"Shang Wang, Yansong Gao, Anmin Fu, Zhi Zhang, Yuqing Zhang, Willy Susilo, Dongxi Liu",https://doi.org/10.1145/3579856.3582829,,Conference and Workshop Papers,
DHBE: Data-free Holistic Backdoor Erasing in Deep Neural Networks via Restricted Adversarial Distillation,AsiaCCS,2023, (1): 731-745,"Zhicong Yan, Shenghong Li, Ruijie Zhao, Yuan Tian, Yuanyuan Zhao",https://doi.org/10.1145/3579856.3582822,,Conference and Workshop Papers,
Detecting Backdoors in Collaboration Graphs of Software Repositories,CODASPY,2023, (1): 189-200,"Tom Ganz, Inaam Ashraf, Martin Härterich, Konrad Rieck",https://doi.org/10.1145/3577923.3583657,,Conference and Workshop Papers,
Poster: Multi-target &amp; Multi-trigger Backdoor Attacks on Graph Neural Networks,CCS,2023, (1): 3570-3572,"Jing Xu, Stjepan Picek",https://doi.org/10.1145/3576915.3624387,,Conference and Workshop Papers,
Poster: Fooling XAI with Explanation-Aware Backdoors,CCS,2023, (1): 3612-3614,"Maximilian Noppel, Christian Wressnegger",https://doi.org/10.1145/3576915.3624379,,Conference and Workshop Papers,
Poster: Backdoor Attack on Extreme Learning Machines,CCS,2023, (1): 3588-3590,"Behrad Tajalli, Gorka Abad, Stjepan Picek",https://doi.org/10.1145/3576915.3624369,,Conference and Workshop Papers,
Narcissus: A Practical Clean-Label Backdoor Attack with Limited Information,CCS,2023, (1): 771-785,"Yi Zeng, Minzhou Pan, Hoang Anh Just, Lingjuan Lyu, Meikang Qiu, Ruoxi Jia",https://doi.org/10.1145/3576915.3616617,,Conference and Workshop Papers,
MASTERKEY: Practical Backdoor Attack Against Speaker Verification Systems,MobiCom,2023, (1): 48:1-48:15,"Hanqing Guo, Xun Chen, Junfeng Guo, Li Xiao, Qiben Yan",https://doi.org/10.1145/3570361.3613261,,Conference and Workshop Papers,
Pied-Piper: Revealing the Backdoor Threats in Ethereum ERC Token Contracts,ACM Trans. Softw. Eng. Methodol.,2023,32 (3): 61:1-61:24,"Fuchen Ma, Meng Ren, Lerong Ouyang, Yuanliang Chen, Juan Zhu, Ting Chen, Yingli Zheng, Xiao Dai, Yu Jiang, Jiaguang Sun",https://doi.org/10.1145/3560264,,Journal Articles,
Unnoticeable Backdoor Attacks on Graph Neural Networks,WWW,2023, (1): 2263-2273,"Enyan Dai, Minhua Lin, Xiang Zhang, Suhang Wang",https://doi.org/10.1145/3543507.3583392,,Conference and Workshop Papers,
Training-free Lexical Backdoor Attacks on Language Models,WWW,2023, (1): 2198-2208,"Yujin Huang, Terry Yue Zhuo, Qiongkai Xu, Han Hu, Xingliang Yuan, Chunyang Chen",https://doi.org/10.1145/3543507.3583348,,Conference and Workshop Papers,
TRAPDOOR: Repurposing neural network backdoors to detect dataset bias in machine learning-based genomic analysis,VLSI-SoC,2023, (1): 1-6,"Esha Sarkar, Constantine Doumanidis, Michail Maniatakos",https://doi.org/10.1109/VLSI-SoC57769.2023.10321928,,Conference and Workshop Papers,
Hidden Backdoor Attack Against Deep Learning-Based Wireless Signal Modulation Classifiers,IEEE Trans. Veh. Technol.,2023,72 (9): 12396-12400,"Yunsong Huang, Weicheng Liu, Hui-Ming Wang",https://doi.org/10.1109/TVT.2023.3267455,,Journal Articles,
FUBA: Federated Uncovering of Backdoor Attacks for Heterogeneous Data,TPS-ISA,2023, (1): 55-63,"Fabiola Espinoza Castellon, Deepika Singh, Aurelien Mayoue, Cedric Gouy-Pailler",https://doi.org/10.1109/TPS-ISA58951.2023.00017,,Conference and Workshop Papers,
"Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses",IEEE Trans. Pattern Anal. Mach. Intell.,2023,45 (2): 1563-1580,"Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, Avi Schwarzschild, Dawn Song, Aleksander Madry, Bo Li, Tom Goldstein",https://doi.org/10.1109/TPAMI.2022.3162397,,Journal Articles,
Differential Analysis of Triggers and Benign Features for Black-Box DNN Backdoor Detection,IEEE Trans. Inf. Forensics Secur.,2023,18 (1): 4668-4680,"Hao Fu, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami",https://doi.org/10.1109/TIFS.2023.3297056,,Journal Articles,
SAFELearning: Secure Aggregation in Federated Learning With Backdoor Detectability,IEEE Trans. Inf. Forensics Secur.,2023,18 (1): 3289-3304,"Zhuosheng Zhang, Jiarui Li, Shucheng Yu, Christian Makaya",https://doi.org/10.1109/TIFS.2023.3280032,,Journal Articles,
Black-Box Dataset Ownership Verification via Backdoor Watermarking,IEEE Trans. Inf. Forensics Secur.,2023,18 (1): 2318-2332,"Yiming Li, Mingyan Zhu, Xue Yang, Yong Jiang, Tao Wei, Shu-Tao Xia",https://doi.org/10.1109/TIFS.2023.3265535,,Journal Articles,
Backdoor Attacks for Remote Sensing Data With Wavelet Transform,IEEE Trans. Geosci. Remote. Sens.,2023,61 (1): 1-15,"Nikolaus Dräger, Yonghao Xu, Pedram Ghamisi",https://doi.org/10.1109/TGRS.2023.3289307,,Journal Articles,
Kaleidoscope: Physical Backdoor Attacks Against Deep Neural Networks With RGB Filters,IEEE Trans. Dependable Secur. Comput.,2023,20 (6): 4993-5004,"Xueluan Gong, Ziyao Wang, Yanjiao Chen, Meng Xue, Qian Wang, Chao Shen",https://doi.org/10.1109/TDSC.2023.3239225,,Journal Articles,
A Temporal Chrominance Trigger for Clean-Label Backdoor Attack Against Anti-Spoof Rebroadcast Detection,IEEE Trans. Dependable Secur. Comput.,2023,20 (6): 4752-4762,"Wei Guo, Benedetta Tondi, Mauro Barni",https://doi.org/10.1109/TDSC.2022.3233519,,Journal Articles,
MARNet: Backdoor Attacks Against Cooperative Multi-Agent Reinforcement Learning,IEEE Trans. Dependable Secur. Comput.,2023,20 (5): 4188-4198,"Yanjiao Chen, Zhicong Zheng, Xueluan Gong",https://doi.org/10.1109/TDSC.2022.3207429,,Journal Articles,
Can We Mitigate Backdoor Attack Using Adversarial Detection Methods?,IEEE Trans. Dependable Secur. Comput.,2023,20 (4): 2867-2881,"Kaidi Jin, Tianwei Zhang, Chao Shen, Yufei Chen, Ming Fan, Chenhao Lin, Ting Liu",https://doi.org/10.1109/TDSC.2022.3194642,,Journal Articles,
FooBaR: Fault Fooling Backdoor Attack on Neural Network Training,IEEE Trans. Dependable Secur. Comput.,2023,20 (3): 1895-1908,"Jakub Breier, Xiaolu Hou, Martín Ochoa, Jesus Solano",https://doi.org/10.1109/TDSC.2022.3166671,,Journal Articles,
Enhancing Backdoor Attacks With Multi-Level MMD Regularization,IEEE Trans. Dependable Secur. Comput.,2023,20 (2): 1675-1686,"Pengfei Xia, Hongjing Niu, Ziqiang Li, Bin Li",https://doi.org/10.1109/TDSC.2022.3161477,,Journal Articles,
An Imperceptible Data Augmentation Based Blackbox Clean-Label Backdoor Attack on Deep Neural Networks,IEEE Trans. Circuits Syst. I Regul. Pap.,2023,70 (12): 5011-5024,"Chaohui Xu, Wenye Liu, Yue Zheng, Si Wang, Chip-Hong Chang",https://doi.org/10.1109/TCSI.2023.3298802,,Journal Articles,
$\tt{PoisonedGNN}$: Backdoor Attack on Graph Neural Networks-Based Hardware Security Systems,IEEE Trans. Computers,2023,72 (10): 2822-2834,"Lilas Alrahis, Satwik Patnaik, Muhammad Abdullah Hanif, Muhammad Shafique, Ozgur Sinanoglu",https://doi.org/10.1109/TC.2023.3271126,,Journal Articles,
Training Data Leakage via Imperceptible Backdoor Attack,SSCI,2023, (1): 1553-1559,"Xiangkai Yang, Wenjian Luo, Qi Zhou, Zhijian Chen",https://doi.org/10.1109/SSCI52147.2023.10372011,,Conference and Workshop Papers,
TransCAB: Transferable Clean-Annotation Backdoor to Object Detection with Natural Trigger in Real-World,SRDS,2023, (1): 82-92,"Hua Ma, Yinshan Li, Yansong Gao, Zhi Zhang, Alsharif Abuadbba, Anmin Fu, Said F. Al-Sarawi, Surya Nepal, Derek Abbott",https://doi.org/10.1109/SRDS60354.2023.00018,,Conference and Workshop Papers,
On Feasibility of Server-side Backdoor Attacks on Split Learning,SP,2023, (1): 84-93,"Behrad Tajalli, Oguzhan Ersoy, Stjepan Picek",https://doi.org/10.1109/SPW59333.2023.00014,,Conference and Workshop Papers,
AI-Guardian: Defeating Adversarial Attacks using Backdoors,SP,2023, (1): 701-718,"Hong Zhu, Shengzhi Zhang, Kai Chen",https://doi.org/10.1109/SP46215.2023.10179473,,Conference and Workshop Papers,
RAB: Provable Robustness Against Backdoor Attacks,SP,2023, (1): 1311-1328,"Maurice Weber, Xiaojun Xu, Bojan Karlas, Ce Zhang, Bo Li",https://doi.org/10.1109/SP46215.2023.10179451,,Conference and Workshop Papers,
3DFed: Adaptive and Extensible Framework for Covert Backdoor Attack in Federated Learning,SP,2023, (1): 1893-1907,"Haoyang Li, Qingqing Ye, Haibo Hu, Jin Li, Leixia Wang, Chengfang Fang, Jie Shi",https://doi.org/10.1109/SP46215.2023.10179401,,Conference and Workshop Papers,
Redeem Myself: Purifying Backdoors in Deep Learning Models using Self Attention Distillation,SP,2023, (1): 755-772,"Xueluan Gong, Yanjiao Chen, Wang Yang, Qian Wang, Yuzhe Gu, Huayang Huang, Chao Shen",https://doi.org/10.1109/SP46215.2023.10179375,,Conference and Workshop Papers,
MagBackdoor: Beware of Your Loudspeaker as A Backdoor For Magnetic Injection Attacks,SP,2023, (1): 3416-3431,"Tiantian Liu, Feng Lin, Zhangsen Wang, Chao Wang, Zhongjie Ba, Li Lu, Wenyao Xu, Kui Ren",https://doi.org/10.1109/SP46215.2023.10179364,,Conference and Workshop Papers,
BayBFed: Bayesian Backdoor Defense for Federated Learning,SP,2023, (1): 737-754,"Kavita Kumari, Phillip Rieger, Hossein Fereidooni, Murtuza Jadliwala, Ahmad-Reza Sadeghi",https://doi.org/10.1109/SP46215.2023.10179362,,Conference and Workshop Papers,
Jigsaw Puzzle: Selective Backdoor Attack to Subvert Malware Classifiers,SP,2023, (1): 719-736,"Limin Yang, Zhi Chen, Jacopo Cortellazzi, Feargus Pendlebury, Kevin Tu, Fabio Pierazzi, Lorenzo Cavallaro, Gang Wang",https://doi.org/10.1109/SP46215.2023.10179347,,Conference and Workshop Papers,
Disguising Attacks with Explanation-Aware Backdoors,SP,2023, (1): 664-681,"Maximilian Noppel, Lukas Peter, Christian Wressnegger",https://doi.org/10.1109/SP46215.2023.10179308,,Conference and Workshop Papers,
BATFL: Battling Backdoor Attacks in Federated Learning,SIN,2023, (1): 1-6,"Mayank Kumar, Radha Agrawal, Priyanka Singh",https://doi.org/10.1109/SIN60469.2023.10474981,,Conference and Workshop Papers,
QDoor: Exploiting Approximate Synthesis for Backdoor Attacks in Quantum Neural Networks,QCE,2023, (1): 1098-1106,"Cheng Chu, Fan Chen, Philip Richerme, Lei Jiang",https://doi.org/10.1109/QCE57702.2023.00124,,Conference and Workshop Papers,
Defending Federated Learning from Backdoor Attacks: Anomaly-Aware FedAVG with Layer-Based Aggregation,PIMRC,2023, (1): 1-6,"Habib Ullah Manzoor, Ahsan Raza Khan, Tahir Sher, Wasim Ahmad, Ahmed Zoha",https://doi.org/10.1109/PIMRC56721.2023.10293950,,Conference and Workshop Papers,
Backdoor Attacks to Deep Learning Models and Countermeasures: A Survey,IEEE Open J. Comput. Soc.,2023,4 (1): 134-146,"Yudong Li, Shigeng Zhang, Weiping Wang, Hong Song",https://doi.org/10.1109/OJCS.2023.3267221,,Journal Articles,
"Backdoor Attacks and Defenses in Federated Learning: State-of-the-Art, Taxonomy, and Future Directions",IEEE Wirel. Commun.,2023,30 (2): 114-121,"Xueluan Gong, Yanjiao Chen, Qian Wang, Weihan Kong",https://doi.org/10.1109/MWC.017.2100714,,Journal Articles,
DUBIOUS: Detecting Unknown Backdoored Input by Observing Unusual Signatures,MILCOM,2023, (1): 696-702,"Matthew Yudin, Rauf Izmailov",https://doi.org/10.1109/MILCOM58377.2023.10356229,,Conference and Workshop Papers,
Data Poisoning and Backdoor Attacks on Audio Intelligence Systems,IEEE Commun. Mag.,2023,61 (12): 176-182,"Yunjie Ge, Qian Wang, Jiayuan Yu, Chao Shen, Qi Li",https://doi.org/10.1109/MCOM.012.2200596,,Journal Articles,
Stealthy Frequency-Domain Backdoor Attacks: Fourier Decomposition and Fundamental Frequency Injection,IEEE Signal Process. Lett.,2023,30 (1): 1677-1681,"Qianli Ma, Junping Qin, Kai Yan, Lei Wang, Hao Sun",https://doi.org/10.1109/LSP.2023.3330126,,Journal Articles,
Stealthy Backdoor Attack Against Speaker Recognition Using Phase-Injection Hidden Trigger,IEEE Signal Process. Lett.,2023,30 (1): 1057-1061,"Zhe Ye, Diqun Yan, Li Dong, Jiacheng Deng, Shui Yu",https://doi.org/10.1109/LSP.2023.3293429,,Journal Articles,
Backdoor-Resistant Public Data Integrity Verification Scheme Based on Smart Contracts,IEEE Internet Things J.,2023,10 (16): 14269-14284,"Shanshan Li, Chunxiang Xu, Yuan Zhang, Yicong Du, Anjia Yang, Xinsheng Wen, Kefei Chen",https://doi.org/10.1109/JIOT.2023.3285939,,Journal Articles,
Facilitating Early-Stage Backdoor Attacks in Federated Learning With Whole Population Distribution Inference,IEEE Internet Things J.,2023,10 (12): 10385-10399,"Tian Liu, Xueyang Hu, Tao Shu",https://doi.org/10.1109/JIOT.2023.3237806,,Journal Articles,
A Triggerless Backdoor Attack and Defense Mechanism for Intelligent Task Offloading in Multi-UAV Systems,IEEE Internet Things J.,2023,10 (7): 5719-5732,"Shafkat Islam, Shahriar Badsha, Ibrahim Khalil, Mohammed Atiquzzaman, Charalambos Konstantinou",https://doi.org/10.1109/JIOT.2022.3172936,,Journal Articles,
Computational Color Constancy-Based Backdoor Attacks,ISPA,2023, (1): 1-6,"Donik Vrsnak, Ivan Sabolic, Marko Subasic, Sven Loncaric",https://doi.org/10.1109/ISPA58351.2023.10278694,,Conference and Workshop Papers,
Content Style-triggered Backdoor Attack in Non-IID Federated Learning via Generative AI,ISPA/BDCloud/SocialCom/SustainCom,2023, (1): 640-647,"Jinke Cheng, Gaolei Li, Xi Lin, Hao Peng, Jianhua Li",https://doi.org/10.1109/ISPA-BDCloud-SocialCom-SustainCom59178.2023.00116,,Conference and Workshop Papers,
Robust Federated Learning against Backdoor Attackers,INFOCOM Workshops,2023, (1): 1-6,"Priyesh Ranjan, Ashish Gupta, Federico Coro, Sajal K. Das",https://doi.org/10.1109/INFOCOMWKSHPS57453.2023.10225922,,Conference and Workshop Papers,
Mind Your Heart: Stealthy Backdoor Attack on Dynamic Deep Neural Network in Edge Computing,INFOCOM,2023, (1): 1-10,"Tian Dong, Ziyuan Zhang, Han Qiu, Tianwei Zhang, Hewu Li, Terry Wang",https://doi.org/10.1109/INFOCOM53939.2023.10229092,,Conference and Workshop Papers,
SDN Application Backdoor: Disrupting the Service via Poisoning the Topology,INFOCOM,2023, (1): 1-10,"Shuhua Deng, Xian Qing, Xiaofan Li, Xing Gao, Xieping Gao",https://doi.org/10.1109/INFOCOM53939.2023.10229058,,Conference and Workshop Papers,
Rethinking the Trigger-injecting Position in Graph Backdoor Attack,IJCNN,2023, (1): 1-8,"Jing Xu, Gorka Abad, Stjepan Picek",https://doi.org/10.1109/IJCNN54540.2023.10191949,,Conference and Workshop Papers,
Backdoor Attack on Deep Neural Networks in Perception Domain,IJCNN,2023, (1): 1-8,"Xiaoxing Mo, Leo Yu Zhang, Nan Sun, Wei Luo, Shang Gao",https://doi.org/10.1109/IJCNN54540.2023.10191661,,Conference and Workshop Papers,
FedGrad: Mitigating Backdoor Attacks in Federated Learning Through Local Ultimate Gradients Inspection,IJCNN,2023, (1): 1-10,"Thuy Dung Nguyen, Anh Duy Nguyen, Thanh-Hung Nguyen, Kok-Seng Wong, Huy Hieu Pham, Truong Thao Nguyen, Phi Le Nguyen",https://doi.org/10.1109/IJCNN54540.2023.10191655,,Conference and Workshop Papers,
Privacy Inference-Empowered Stealthy Backdoor Attack on Federated Learning under Non-IID Scenarios,IJCNN,2023, (1): 1-10,"Haochen Mei, Gaolei Li, Jun Wu, Longfei Zheng",https://doi.org/10.1109/IJCNN54540.2023.10191260,,Conference and Workshop Papers,
X-HDNN: Explainable Hybrid DNN for Industrial Internet of Things Backdoor Attack Detection,ICTC,2023, (1): 1053-1057,"Love Allen Chijioke Ahakonye, Cosmas Ifeanyi Nwakanma, Jae Min Lee, Dong-Seong Kim",https://doi.org/10.1109/ICTC58733.2023.10393379,,Conference and Workshop Papers,
SemSBA: Semantic-perturbed Stealthy Backdoor Attack on Federated Semi-supervised Learning,ICPADS,2023, (1): 1569-1576,"Yingrui Tong, Jun Feng, Gaolei Li, Xi Lin, Chengcheng Zhao, Xiaoyu Yi, Jianhua Li",https://doi.org/10.1109/ICPADS60453.2023.00221,,Conference and Workshop Papers,
RPFL: Robust and Privacy Federated Learning against Backdoor and Sample Inference Attacks,ICPADS,2023, (1): 1508-1515,"Di Xiao, Zhuyang Yu, Lvjun Chen",https://doi.org/10.1109/ICPADS60453.2023.00213,,Conference and Workshop Papers,
DBIA: Data-Free Backdoor Attack Against Transformer Networks,ICME,2023, (1): 2819-2824,"Peizhuo Lv, Hualong Ma, Jiachen Zhou, Ruigang Liang, Kai Chen, Shengzhi Zhang, Yunfei Yang",https://doi.org/10.1109/ICME55011.2023.00479,,Conference and Workshop Papers,
Watermarks for Generative Adversarial Network Based on Steganographic Invisible Backdoor,ICME,2023, (1): 1211-1216,"Yuwei Zeng, Jingxuan Tan, Zhengxin You, Zhenxing Qian, Xinpeng Zhang",https://doi.org/10.1109/ICME55011.2023.00211,,Conference and Workshop Papers,
Fedward: Flexible Federated Backdoor Defense Framework with Non-IID Data,ICME,2023, (1): 348-353,"Zekai Chen, Fuyi Wang, Zhiwei Zheng, Ximeng Liu, Yujie Lin",https://doi.org/10.1109/ICME55011.2023.00067,,Conference and Workshop Papers,
Efficient any-Target Backdoor Attack with Pseudo Poisoned Samples,ICIP,2023, (1): 3319-3323,"Bin Huang, Zhi Wang",https://doi.org/10.1109/ICIP49359.2023.10222807,,Conference and Workshop Papers,
CSSBA: A Clean Label Sample-Specific Backdoor Attack,ICIP,2023, (1): 965-969,"Zihan Shen, Wei Hou, Yun Li",https://doi.org/10.1109/ICIP49359.2023.10222085,,Conference and Workshop Papers,
Backdoor Attack on 3D Grey Image Segmentation,ICDM,2023, (1): 708-717,"Honghui Xu, Zhipeng Cai, Zuobin Xiong, Wei Li",https://doi.org/10.1109/ICDM58522.2023.00080,,Conference and Workshop Papers,
A Practical Clean-Label Backdoor Attack with Limited Information in Vertical Federated Learning,ICDM,2023, (1): 41-50,"Peng Chen, Jirui Yang, Junxiong Lin, Zhihui Lu, Qiang Duan, Hongfeng Chai",https://doi.org/10.1109/ICDM58522.2023.00013,,Conference and Workshop Papers,
ScanFed: Scalable Behavior-Based Backdoor Detection in Federated Learning,ICDCS,2023, (1): 782-793,"Rui Ning, Jiang Li, Chunsheng Xin, Chonggang Wang, Xu Li, Robert Gazda, Jin-Hee Cho, Hongyi Wu",https://doi.org/10.1109/ICDCS57875.2023.00011,,Conference and Workshop Papers,
Computation and Data Efficient Backdoor Attacks,ICCV,2023, (1): 4782-4791,"Yutong Wu, Xingshuo Han, Han Qiu, Tianwei Zhang",https://doi.org/10.1109/ICCV51070.2023.00443,,Conference and Workshop Papers,
The Perils of Learning From Unlabeled Data: Backdoor Attacks on Semi-supervised Learning,ICCV,2023, (1): 4707-4717,"Virat Shejwalkar, Lingjuan Lyu, Amir Houmansadr",https://doi.org/10.1109/ICCV51070.2023.00436,,Conference and Workshop Papers,
PolicyCleanse: Backdoor Detection and Mitigation for Competitive Reinforcement Learning,ICCV,2023, (1): 4676-4685,"Junfeng Guo, Ang Li, Lixu Wang, Cong Liu",https://doi.org/10.1109/ICCV51070.2023.00433,,Conference and Workshop Papers,
Multi-metrics adaptively identifies backdoors in Federated learning,ICCV,2023, (1): 4629-4639,"Siquan Huang, Yijiang Li, Chong Chen, Leyu Shi, Ying Gao",https://doi.org/10.1109/ICCV51070.2023.00429,,Conference and Workshop Papers,
Beating Backdoor Attack at Its Own Game,ICCV,2023, (1): 4597-4606,"Min Liu, Alberto L. Sangiovanni-Vincentelli, Xiangyu Yue",https://doi.org/10.1109/ICCV51070.2023.00426,,Conference and Workshop Papers,
Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis,ICCV,2023, (1): 4561-4573,"Lukas Struppek, Dominik Hintersdorf, Kristian Kersting",https://doi.org/10.1109/ICCV51070.2023.00423,,Conference and Workshop Papers,
Enhancing Fine-Tuning based Backdoor Defense with Sharpness-Aware Minimization,ICCV,2023, (1): 4443-4454,"Mingli Zhu, Shaokui Wei, Li Shen, Yanbo Fan, Baoyuan Wu",https://doi.org/10.1109/ICCV51070.2023.00412,,Conference and Workshop Papers,
An Embarrassingly Simple Backdoor Attack on Self-supervised Learning,ICCV,2023, (1): 4344-4355,"Changjiang Li, Ren Pang, Zhaohan Xi, Tianyu Du, Shouling Ji, Yuan Yao, Ting Wang",https://doi.org/10.1109/ICCV51070.2023.00403,,Conference and Workshop Papers,
TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal Backdoored Models,ICCV,2023, (1): 165-175,"Indranil Sur, Karan Sikka, Matthew Walmer, Kaushik Koneripalli, Anirban Roy, Xiao Lin, Ajay Divakaran, Susmit Jha",https://doi.org/10.1109/ICCV51070.2023.00022,,Conference and Workshop Papers,
Invisible Encoded Backdoor attack on DNNs using Conditional GAN,ICCE,2023, (1): 1-5,"Iram Arshad, Yuansong Qiao, Brian Lee, Yuhang Ye",https://doi.org/10.1109/ICCE56470.2023.10043484,,Conference and Workshop Papers,
Countermeasure against Backdoor Attack for Deep Learning-Based Phishing Detection,ICCE-Taiwan,2023, (1): 651-652,"Koko Nishiura, Tomotaka Kimura, Jun Cheng",https://doi.org/10.1109/ICCE-Taiwan58799.2023.10226938,,Conference and Workshop Papers,
Stealthy Backdoor Attack on RF Signal Classification,ICCCN,2023, (1): 1-10,"Tianming Zhao, Zijie Tang, Tianfang Zhang, Huy Phan, Yan Wang, Cong Shi, Bo Yuan, Yingying Chen",https://doi.org/10.1109/ICCCN58024.2023.10230152,,Conference and Workshop Papers,
Random Location Poisoning Backdoor Attack Against Automatic Modulation Classification in Wireless Networks,ICCC,2023, (1): 1-6,"Zixin Li, Hang Jiang, Sicheng Zhang, Wei Xiang, Yun Lin",https://doi.org/10.1109/ICCC57788.2023.10233544,,Conference and Workshop Papers,
Towards Defending Adaptive Backdoor Attacks in Federated Learning,ICC,2023, (1): 5078-5084,"Han Yang, Dongbing Gu, Jianhua He",https://doi.org/10.1109/ICC45041.2023.10279267,,Conference and Workshop Papers,
Successive Interference Cancellation Based Defense for Trigger Backdoor in Federated Learning,ICC,2023, (1): 26-32,"Yu-Wen Chen, Bo-Hsu Ke, Bozhong Chen, Si-Rong Chiu, Chun-Wei Tu, Jian-Jhih Kuo",https://doi.org/10.1109/ICC45041.2023.10278979,,Conference and Workshop Papers,
FedMC: Federated Learning with Mode Connectivity Against Distributed Backdoor Attacks,ICC,2023, (1): 4873-4878,"Weiqi Wang, Chenhan Zhang, Shushu Liu, Mingjian Tang, An Liu, Shui Yu",https://doi.org/10.1109/ICC45041.2023.10278903,,Conference and Workshop Papers,
Training Set Cleansing of Backdoor Poisoning by Self-Supervised Representation Learning,ICASSP,2023, (1): 1-5,"Hang Wang, Sahar Karami, Ousmane Dia, Hippolyt Ritter, Ehsan Emamjomeh-Zadeh, Jiahui Chen, Zhen Xiang, David J. Miller, George Kesidis",https://doi.org/10.1109/ICASSP49357.2023.10097244,,Conference and Workshop Papers,
Backdoor Defense via Suppressing Model Shortcuts,ICASSP,2023, (1): 1-5,"Sheng Yang, Yiming Li, Yong Jiang, Shu-Tao Xia",https://doi.org/10.1109/ICASSP49357.2023.10097220,,Conference and Workshop Papers,
Measure and Countermeasure of the Capsulation Attack Against Backdoor-Based Deep Neural Network Watermarks,ICASSP,2023, (1): 1-5,"Fang-Qi Li, Shi-Lin Wang, Yun Zhu",https://doi.org/10.1109/ICASSP49357.2023.10096448,,Conference and Workshop Papers,
Going in Style: Audio Backdoors Through Stylistic Transformations,ICASSP,2023, (1): 1-5,"Stefanos Koffas, Luca Pajola, Stjepan Picek, Mauro Conti",https://doi.org/10.1109/ICASSP49357.2023.10096332,,Conference and Workshop Papers,
QTROJAN: A Circuit Backdoor Against Quantum Neural Networks,ICASSP,2023, (1): 1-5,"Cheng Chu, Lei Jiang, Martin Swany, Fan Chen",https://doi.org/10.1109/ICASSP49357.2023.10096293,,Conference and Workshop Papers,
BATT: Backdoor Attack with Transformation-Based Triggers,ICASSP,2023, (1): 1-5,"Tong Xu, Yiming Li, Yong Jiang, Shu-Tao Xia",https://doi.org/10.1109/ICASSP49357.2023.10096034,,Conference and Workshop Papers,
Untargeted Backdoor Attack Against Object Detection,ICASSP,2023, (1): 1-5,"Chengxiao Luo, Yiming Li, Yong Jiang, Shu-Tao Xia",https://doi.org/10.1109/ICASSP49357.2023.10095980,,Conference and Workshop Papers,
An Empirical Study of Backdoor Attacks on Masked Auto Encoders,ICASSP,2023, (1): 1-5,"Shuli Zhuang, Pengfei Xia, Bin Li",https://doi.org/10.1109/ICASSP49357.2023.10095201,,Conference and Workshop Papers,
NCL: Textual Backdoor Defense Using Noise-Augmented Contrastive Learning,ICASSP,2023, (1): 1-5,"Shengfang Zhai, Qingni Shen, Xiaoyi Chen, Weilong Wang, Cong Li, Yuejian Fang, Zhonghai Wu",https://doi.org/10.1109/ICASSP49357.2023.10095007,,Conference and Workshop Papers,
BadRes: Reveal the Backdoors Through Residual Connection,ICASSP,2023, (1): 1-5,"Mingrui He, Tianyu Chen, Haoyi Zhou, Shanghang Zhang, Jianxin Li",https://doi.org/10.1109/ICASSP49357.2023.10094691,,Conference and Workshop Papers,
Backdoor Attack Against Automatic Speaker Verification Models in Federated Learning,ICASSP,2023, (1): 1-5,"Dan Meng, Xue Wang, Jun Wang",https://doi.org/10.1109/ICASSP49357.2023.10094675,,Conference and Workshop Papers,
PBE-Plan: Periodic Backdoor Erasing Plan for Trustworthy Federated Learning,HPCC/DSS/SmartCity/DependSys,2023, (1): 41-48,"Bei Chen, Gaolei Li, Mingzhe Chen, Yuchen Liu, Xiaoyu Yi, Jianhua Li",https://doi.org/10.1109/HPCC-DSS-SmartCity-DependSys60770.2023.00016,,Conference and Workshop Papers,
Backdoor Attacks on Multi-Agent Reinforcement Learning-based Spectrum Management,GLOBECOM,2023, (1): 3361-3365,"Hongyi Zhang, Mingqian Liu, Yunfei Chen",https://doi.org/10.1109/GLOBECOM54140.2023.10437779,,Conference and Workshop Papers,
Knowledge Distillation Based Defense for Audio Trigger Backdoor in Federated Learning,GLOBECOM,2023, (1): 4271-4276,"Yu-Wen Chen, Bo-Hsu Ke, Bozhong Chen, Si-Rong Chiu, Chun-Wei Tu, Jian-Jhih Kuo",https://doi.org/10.1109/GLOBECOM54140.2023.10437601,,Conference and Workshop Papers,
Backdoor Attacks Against Deep Learning-Based Massive MIMO Localization,GLOBECOM,2023, (1): 2796-2801,"Tianya Zhao, Xuyu Wang, Shiwen Mao",https://doi.org/10.1109/GLOBECOM54140.2023.10437534,,Conference and Workshop Papers,
Genetic Algorithm-Based Dynamic Backdoor Attack on Federated Learning-Based Network Traffic Classification,FMEC,2023, (1): 204-209,"Mahmoud Nazzal, Nura Aljaafari, Ahmad H. Sawalmeh, Abdallah Khreishah, Muhammad Anan, Abdulelah Abdallah Algosaibi, Mohammed Alnaeem, Adel Aldalbahi, Abdulaziz Alhumam, Conrado P. Vizcarra, Shadan Alhamed",https://doi.org/10.1109/FMEC59375.2023.10306137,,Conference and Workshop Papers,
An Investigation of Recent Backdoor Attacks and Defenses in Federated Learning,FMEC,2023, (1): 262-269,"Qiuxian Chen, Yizheng Tao",https://doi.org/10.1109/FMEC59375.2023.10306127,,Conference and Workshop Papers,
Watermarking Graph Neural Networks based on Backdoor Attacks,EuroS&amp;P,2023, (1): 1179-1197,"Jing Xu, Stefanos Koffas, Oguzhan Ersoy, Stjepan Picek",https://doi.org/10.1109/EuroSP57164.2023.00072,,Conference and Workshop Papers,
Don&apos;t Knock! Rowhammer at the Backdoor of DNN Models,DSN,2023, (1): 109-122,"M. Caner Tol, Saad Islam, Andrew J. Adiletta, Berk Sunar, Ziming Zhang",https://doi.org/10.1109/DSN58367.2023.00023,,Conference and Workshop Papers,
Don&apos;t FREAK Out: A Frequency-Inspired Approach to Detecting Backdoor Poisoned Samples in DNNs,CVPR Workshops,2023, (1): 2338-2345,"Hasan Abed Al Kader Hammoud, Adel Bibi, Philip H. S. Torr, Bernard Ghanem",https://doi.org/10.1109/CVPRW59228.2023.00230,,Conference and Workshop Papers,
You Are Catching My Attention: Are Vision Transformers Bad Learners under Backdoor Attacks?,CVPR,2023, (1): 24605-24615,"Zenghui Yuan, Pan Zhou, Kai Zou, Yu Cheng",https://doi.org/10.1109/CVPR52729.2023.02357,,Conference and Workshop Papers,
Architectural Backdoors in Neural Networks,CVPR,2023, (1): 24595-24604,"Mikel Bober-Irizar, Ilia Shumailov, Yiren Zhao, Robert D. Mullins, Nicolas Papernot",https://doi.org/10.1109/CVPR52729.2023.02356,,Conference and Workshop Papers,
The Dark Side of Dynamic Routing Neural Networks: Towards Efficiency Backdoor Injection,CVPR,2023, (1): 24585-24594,"Simin Chen, Hanlin Chen, Mirazul Haque, Cong Liu, Wei Yang",https://doi.org/10.1109/CVPR52729.2023.02355,,Conference and Workshop Papers,
Progressive Backdoor Erasing via connecting Backdoor and Adversarial Attacks,CVPR,2023, (1): 20495-20503,"Bingxu Mu, Zhenxing Niu, Le Wang, Xue Wang, Qiguang Mia, Rong Jin, Gang Hua",https://doi.org/10.1109/CVPR52729.2023.01963,,Conference and Workshop Papers,
MEDIC: Remove Model Backdoors via Importance Driven Cloning,CVPR,2023, (1): 20485-20494,"Qiuling Xu, Guanhong Tao, Jean Honorio, Yingqi Liu, Shengwei An, Guangyu Shen, Siyuan Cheng, Xiangyu Zhang",https://doi.org/10.1109/CVPR52729.2023.01962,,Conference and Workshop Papers,
Detecting Backdoors During the Inference Stage Based on Corruption Robustness Consistency,CVPR,2023, (1): 16363-16372,"Xiaogeng Liu, Minghui Li, Haoyu Wang, Shengshan Hu, Dengpan Ye, Hai Jin, Libing Wu, Chaowei Xiao",https://doi.org/10.1109/CVPR52729.2023.01570,,Conference and Workshop Papers,
Detecting Backdoors in Pre-trained Encoders,CVPR,2023, (1): 16352-16362,"Shiwei Feng, Guanhong Tao, Siyuan Cheng, Guangyu Shen, Xiangzhe Xu, Yingqi Liu, Kaiyuan Zhang, Shiqing Ma, Xiangyu Zhang",https://doi.org/10.1109/CVPR52729.2023.01569,,Conference and Workshop Papers,
Backdoor Attacks Against Deep Image Compression via Adaptive Frequency Trigger,CVPR,2023, (1): 12250-12259,"Yi Yu, Yufei Wang, Wenhan Yang, Shijian Lu, Yap-Peng Tan, Alex C. Kot",https://doi.org/10.1109/CVPR52729.2023.01179,,Conference and Workshop Papers,
Defending Against Patch-based Backdoor Attacks on Self-Supervised Learning,CVPR,2023, (1): 12239-12249,"Ajinkya Tejankar, Maziar Sanjabi, Qifan Wang, Sinong Wang, Hamed Firooz, Hamed Pirsiavash, Liang Tan",https://doi.org/10.1109/CVPR52729.2023.01178,,Conference and Workshop Papers,
Backdoor Defense via Deconfounded Representation Learning,CVPR,2023, (1): 12228-12238,"Zaixi Zhang, Qi Liu, Zhicai Wang, Zepu Lu, Qingyong Hu",https://doi.org/10.1109/CVPR52729.2023.01177,,Conference and Workshop Papers,
Backdoor Cleansing with Unlabeled Data,CVPR,2023, (1): 12218-12227,"Lu Pang, Tao Sun, Haibin Ling, Chao Chen",https://doi.org/10.1109/CVPR52729.2023.01176,,Conference and Workshop Papers,
Color Backdoor: A Robust Poisoning Attack in Color Space,CVPR,2023, (1): 8133-8142,"Wenbo Jiang, Hongwei Li, Guowen Xu, Tianwei Zhang",https://doi.org/10.1109/CVPR52729.2023.00786,,Conference and Workshop Papers,
Single Image Backdoor Inversion via Robust Smoothed Classifiers,CVPR,2023, (1): 8113-8122,"Mingjie Sun, Zico Kolter",https://doi.org/10.1109/CVPR52729.2023.00784,,Conference and Workshop Papers,
How to Backdoor Diffusion Models?,CVPR,2023, (1): 4015-4024,"Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho",https://doi.org/10.1109/CVPR52729.2023.00391,,Conference and Workshop Papers,
Backdoor Defense via Adaptively Splitting Poisoned Dataset,CVPR,2023, (1): 4005-4014,"Kuofeng Gao, Yang Bai, Jindong Gu, Yong Yang, Shu-Tao Xia",https://doi.org/10.1109/CVPR52729.2023.00390,,Conference and Workshop Papers,
PerDoor: Persistent Backdoors in Federated Learning using Adversarial Perturbations,COINS,2023, (1): 1-6,"Manaar Alam, Esha Sarkar, Michail Maniatakos",https://doi.org/10.1109/COINS57856.2023.10189281,,Conference and Workshop Papers,
Vulnerabilities of Deep Learning-Driven Semantic Communications to Backdoor (Trojan) Attacks,CISS,2023, (1): 1-6,"Yalin E. Sagduyu, Tugba Erpek, Sennur Ulukus, Aylin Yener",https://doi.org/10.1109/CISS56502.2023.10089692,,Conference and Workshop Papers,
Physical Backdoor Trigger Activation of Autonomous Vehicle Using Reachability Analysis,CDC,2023, (1): 821-826,"Wenqing Li, Yue Wang, Muhammad Shafique, Saif Eddin Jabari",https://doi.org/10.1109/CDC49753.2023.10383622,,Conference and Workshop Papers,
A Max-Min Security Game for Coordinated Backdoor Attacks on Federated Learning,IEEE Big Data,2023, (1): 3566-3573,"Omar Abdel Wahab, Anderson Avila",https://doi.org/10.1109/BigData59044.2023.10386756,,Conference and Workshop Papers,
SolScope: Effectively Hunting Potential Permission Backdoor Threats in Smart Contracts,BIGCOM,2023, (1): 88-95,"Renjie Ji, Wansen Wang, Yan Xiong, Wenchao Huang",https://doi.org/10.1109/BIGCOM61073.2023.00020,,Conference and Workshop Papers,
Joint Energy-Based Model for Robust Speech Classification System Against Dirty-Label Backdoor Poisoning Attacks,ASRU,2023, (1): 1-8,"Martin Sustek, Sonal Joshi, Henry Li, Thomas Thebaud, Jesús Villalba, Sanjeev Khudanpur, Najim Dehak",https://doi.org/10.1109/ASRU57964.2023.10389697,,Conference and Workshop Papers,
Instance-Agnostic and Practical Clean Label Backdoor Attack Method for Deep Learning Based Face Recognition Models,IEEE Access,2023,11 (1): 144040-144050,"Tae-Hoon Kim, SeokHwan Choi, Yoon-Ho Choi",https://doi.org/10.1109/ACCESS.2023.3342922,,Journal Articles,
Backdoor Pony: Evaluating backdoor attacks and defenses in different domains,SoftwareX,2023,22 (1): 101387,"Arthur Mercier, Nikita Smolin, Oliver Sihlovec, Stefanos Koffas, Stjepan Picek",https://doi.org/10.1016/j.softx.2023.101387,,Journal Articles,
Deep fidelity in DNN watermarking: A study of backdoor watermarking for classification models,Pattern Recognit.,2023,144 (1): 109844,"Guang Hua, Andrew Beng Jin Teoh",https://doi.org/10.1016/j.patcog.2023.109844,,Journal Articles,
TAT: Targeted backdoor attacks against visual object tracking,Pattern Recognit.,2023,142 (1): 109629,"Ziyi Cheng, Baoyuan Wu, Zhenya Zhang, Jianjun Zhao",https://doi.org/10.1016/j.patcog.2023.109629,,Journal Articles,
Not All Samples Are Born Equal: Towards Effective Clean-Label Backdoor Attacks,Pattern Recognit.,2023,139 (1): 109512,"Yinghua Gao, Yiming Li, Linghui Zhu, Dongxian Wu, Yong Jiang, Shu-Tao Xia",https://doi.org/10.1016/j.patcog.2023.109512,,Journal Articles,
How to backdoor split learning,Neural Networks,2023,168 (1): 326-336,"Fangchao Yu, Lina Wang, Bo Zeng, Kai Zhao, Zhi Pang, Tian Wu",https://doi.org/10.1016/j.neunet.2023.09.037,,Journal Articles,
Multidomain active defense: Detecting multidomain backdoor poisoned samples via ALL-to-ALL decoupling training without clean datasets,Neural Networks,2023,168 (1): 350-362,"Binhao Ma, Jiahui Wang, Dejun Wang, Bo Meng",https://doi.org/10.1016/j.neunet.2023.09.036,,Journal Articles,
A lightweight backdoor defense framework based on image inpainting,Neurocomputing,2023,537 (1): 22-36,"Yier Wei, Haichang Gao, Yufei Wang, Yipeng Gao, Huan Liu",https://doi.org/10.1016/j.neucom.2023.03.052,,Journal Articles,
Backdoor attack and defense in federated generative adversarial network-based medical image synthesis,Medical Image Anal.,2023,90 (1): 102965,"Ruinan Jin, Xiaoxiao Li",https://doi.org/10.1016/j.media.2023.102965,,Journal Articles,
Turning backdoors for efficient privacy protection against image retrieval violations,Inf. Process. Manag.,2023,60 (5): 103471,"Qiang Liu, Tongqing Zhou, Zhiping Cai, Yuan Yuan, Ming Xu, Jiaohua Qin, Wentao Ma",https://doi.org/10.1016/j.ipm.2023.103471,,Journal Articles,
Efficient and persistent backdoor attack by boundary trigger set constructing against federated learning,Inf. Sci.,2023,651 (1): 119743,"Deshan Yang, Senlin Luo, Jinjie Zhou, Limin Pan, Xiaonan Yang, Jiyuan Xing",https://doi.org/10.1016/j.ins.2023.119743,,Journal Articles,
Unlabeled backdoor poisoning on trained-from-scratch semi-supervised learning,Inf. Sci.,2023,647 (1): 119453,"Le Feng, Zhenxing Qian, Xinpeng Zhang, Sheng Li",https://doi.org/10.1016/j.ins.2023.119453,,Journal Articles,
Debiasing backdoor attack: A benign application of backdoor attack in eliminating data bias,Inf. Sci.,2023,643 (1): 119171,"Shangxi Wu, Qiuyang He, Yi Zhang, Dongyuan Lu, Jitao Sang",https://doi.org/10.1016/j.ins.2023.119171,,Journal Articles,
Detecting backdoor in deep neural networks via intentional adversarial perturbations,Inf. Sci.,2023,634 (1): 564-577,"Mingfu Xue, Yinghao Wu, Zhiyu Wu, Yushu Zhang, Jian Wang, Weiqiang Liu",https://doi.org/10.1016/j.ins.2023.03.112,,Journal Articles,
An adaptive robust defending algorithm against backdoor attacks in federated learning,Future Gener. Comput. Syst.,2023,143 (1): 118-131,"Yongkang Wang, Di-Hua Zhai, Yongping He, Yuanqing Xia",https://doi.org/10.1016/j.future.2023.01.026,,Journal Articles,
A defense method against backdoor attacks on neural networks,Expert Syst. Appl.,2023,213 (Part): 118990,"Sara Kaviani, Samaneh Shamshiri, Insoo Sohn",https://doi.org/10.1016/j.eswa.2022.118990,,Journal Articles,
SCFL: Mitigating backdoor attacks in federated learning based on SVD and clustering,Comput. Secur.,2023,133 (1): 103414,"Yongkang Wang, Di-Hua Zhai, Yuanqing Xia",https://doi.org/10.1016/j.cose.2023.103414,,Journal Articles,
ADFL: Defending backdoor attacks in federated learning via adversarial distillation,Comput. Secur.,2023,132 (1): 103366,"Chengcheng Zhu, Jiale Zhang, Xiaobing Sun, Bing Chen, Weizhi Meng",https://doi.org/10.1016/j.cose.2023.103366,,Journal Articles,
Object-free backdoor attack and defense on semantic segmentation,Comput. Secur.,2023,132 (1): 103365,"Jiaoze Mao, Yaguan Qian, Jianchang Huang, Zejie Lian, Renhui Tao, Bin Wang, Wei Wang, Tengteng Yao",https://doi.org/10.1016/j.cose.2023.103365,,Journal Articles,
"DIHBA: Dynamic, invisible and high attack success rate boundary backdoor attack with low poison ratio",Comput. Secur.,2023,129 (1): 103212,"Binhao Ma, Can Zhao, Dejun Wang, Bo Meng",https://doi.org/10.1016/j.cose.2023.103212,,Journal Articles,
LR-BA: Backdoor attack against vertical federated learning using local latent representations,Comput. Secur.,2023,129 (1): 103193,"Yuhao Gu, Yuebin Bai",https://doi.org/10.1016/j.cose.2023.103193,,Journal Articles,
Towards Backdoor Attacks and Defense in Robust Machine Learning Models,Comput. Secur.,2023,127 (1): 103101,"Ezekiel O. Soremekun, Sakshi Udeshi, Sudipta Chattopadhyay",https://doi.org/10.1016/j.cose.2023.103101,,Journal Articles,
Universal backdoor attack on deep neural networks for malware detection,Appl. Soft Comput.,2023,143 (1): 110389,"Yunchun Zhang, Fan Feng, Zikun Liao, Zixuan Li, Shaowen Yao",https://doi.org/10.1016/j.asoc.2023.110389,,Journal Articles,
Backdoor attacks against deep reinforcement learning based traffic signal control systems,Peer Peer Netw. Appl.,2023,16 (1): 466-474,"Heng Zhang, Jun Gu, Zhikun Zhang, Linkang Du, Yongmin Zhang, Yan Ren, Jian Zhang, Hongran Li",https://doi.org/10.1007/s12083-022-01434-0,,Journal Articles,
Red Alarm for Pre-trained Models: Universal Vulnerability to Neuron-level Backdoor Attacks,Mach. Intell. Res.,2023,20 (2): 180-193,"Zhengyan Zhang, Guangxuan Xiao, Yongwei Li, Tian Lv, Fanchao Qi, Zhiyuan Liu, Yasheng Wang, Xin Jiang, Maosong Sun",https://doi.org/10.1007/s11633-022-1377-5,,Journal Articles,
Active poisoning: efficient backdoor attacks on transfer learning-based brain-computer interfaces,Sci. China Inf. Sci.,2023,66 (8): 1,"Xue Jiang, Lubin Meng, Siyang Li, Dongrui Wu",https://doi.org/10.1007/s11432-022-3548-2,,Journal Articles,
A stealthy and robust backdoor attack via frequency domain transform,World Wide Web,2023,26 (5): 2767-2783,"Ruitao Hou, Teng Huang, Hongyang Yan, Lishan Ke, Weixuan Tang",https://doi.org/10.1007/s11280-023-01153-3,,Journal Articles,
Compression-resistant backdoor attack against deep neural networks,Appl. Intell.,2023,53 (17): 20402-20417,"Mingfu Xue, Xin Wang, Shichang Sun, Yushu Zhang, Jian Wang, Weiqiang Liu",https://doi.org/10.1007/s10489-023-04575-8,,Journal Articles,
Evil vs evil: using adversarial examples to against backdoor attack in federated learning,Multim. Syst.,2023,29 (2): 553-568,"Tao Liu, Mingjun Li, Haibin Zheng, Zhaoyan Ming, Jinyin Chen",https://doi.org/10.1007/s00530-022-00965-z,,Journal Articles,
DFaP: Data Filtering and Purification Against Backdoor Attacks,AIS&amp;P,2023, (1): 81-97,"Haochen Wang, Tianshi Mu, Guocong Feng, ShangBo Wu, Yuanzhang Li",https://doi.org/10.1007/978-981-99-9785-5_7,,Conference and Workshop Papers,
SSL-ABD : An Adversarial Defense Method Against Backdoor Attacks in Self-supervised Learning,AIS&amp;P,2023, (1): 456-467,"Hui Yang, Ruilin Yang, Heqiu Cai, Xiao Zhang, Qingqi Pei, Shaowei Wang, Hongyang Yan",https://doi.org/10.1007/978-981-99-9785-5_32,,Conference and Workshop Papers,
SDBC: A Novel and Effective Self-Distillation Backdoor Cleansing Approach,ICONIP,2023, (1): 285-297,"Sheng Ran, Baolin Zheng, Mingwei Sun",https://doi.org/10.1007/978-981-99-8148-9_23,,Conference and Workshop Papers,
MIC: An Effective Defense Against Word-Level Textual Backdoor Attacks,ICONIP,2023, (1): 3-18,"Shufan Yang, Qianmu Li, Zhichao Lian, Pengchuan Wang, Jun Hou",https://doi.org/10.1007/978-981-99-8076-5_1,,Conference and Workshop Papers,
Neural Network Backdoor Attacks Fully Controlled by Composite Natural Utterance Fragments,ICICS,2023, (1): 451-466,"Xubo Yang, Linsen Li, Yenan Chen",https://doi.org/10.1007/978-981-99-7356-9_27,,Conference and Workshop Papers,
Identifying Backdoor Attacks in Federated Learning via Anomaly Detection,APWeb/WAIM,2023, (1): 111-126,"Yuxi Mi, Yiheng Sun, Jihong Guan, Shuigeng Zhou",https://doi.org/10.1007/978-981-97-2387-4_8,,Conference and Workshop Papers,
Poison Egg: Scrambling Federated Learning with Delayed Backdoor Attack,UbiSec,2023, (1): 191-204,"Masayoshi Tsutsui, Tatsuya Kaneko, Shinya Takamaeda-Yamazaki",https://doi.org/10.1007/978-981-97-1274-8_13,,Conference and Workshop Papers,
TRGE: A Backdoor Detection After Quantization,Inscrypt,2023, (1): 394-398,"Renhua Xie, Xuxin Fang, Bo Ma, Chuanhuang Li, Xiaoyong Yuan",https://doi.org/10.1007/978-981-97-0945-8_24,,Conference and Workshop Papers,
Black-Box Graph Backdoor Defense,ICA3PP,2023, (1): 163-180,"Xiao Yang, Gaolei Li, Xiaoyi Tao, Chaofeng Zhang, Jianhua Li",https://doi.org/10.1007/978-981-97-0808-6_10,,Conference and Workshop Papers,
Backdoor Learning on Siamese Networks Using Physical Triggers: FaceNet as a Case Study,ICDF2C,2023, (1): 279-292,"Zeshan Pang, Yuyuan Sun, Shasha Guo, Yuliang Lu",https://doi.org/10.1007/978-3-031-56580-9_17,,Conference and Workshop Papers,
Persistent Clean-Label Backdoor on Graph-Based Semi-supervised Cybercrime Detection,ICDF2C,2023, (1): 264-278,"Xiao Yang, Gaolei Li, Meng Han",https://doi.org/10.1007/978-3-031-56580-9_16,,Conference and Workshop Papers,
CCBA: Code Poisoning-Based Clean-Label Covert Backdoor Attack Against DNNs,ICDF2C,2023, (1): 179-192,"Xubo Yang, Linsen Li, Cunqing Hua, Changhao Yao",https://doi.org/10.1007/978-3-031-56580-9_11,,Conference and Workshop Papers,
Backdoor Attacks Leveraging Latent Representation in Competitive Learning,ESORICS Workshops,2023, (1): 700-718,"Kazuki Iwahana, Naoto Yanai, Toru Fujiwara",https://doi.org/10.1007/978-3-031-54129-2_41,,Conference and Workshop Papers,
&quot;We Must Protect the Transformers&quot;: Understanding Efficacy of Backdoor Attack Mitigation on Transformer Models,SPACE,2023, (1): 242-260,"Rohit Raj, Biplab Roy, Abir Das, Mainack Mondal",https://doi.org/10.1007/978-3-031-51583-5_14,,Conference and Workshop Papers,
Immunizing Backdoored PRGs,TCC,2023, (1): 153-182,"Marshall Ball, Yevgeniy Dodis, Eli Goldin",https://doi.org/10.1007/978-3-031-48621-0_6,,Conference and Workshop Papers,
IMTM: Invisible Multi-trigger Multimodal Backdoor Attack,NLPCC,2023, (1): 533-545,"Zhicheng Li, Piji Li, Xuan Sheng, Changchun Yin, Lu Zhou",https://doi.org/10.1007/978-3-031-44696-2_42,,Conference and Workshop Papers,
Punctuation Matters! Stealthy Backdoor Attack for Language Models,NLPCC,2023, (1): 524-536,"Xuan Sheng, Zhicheng Li, Zhaoyang Han, Xiangmao Chang, Piji Li",https://doi.org/10.1007/978-3-031-44693-1_41,,Conference and Workshop Papers,
Practical and General Backdoor Attacks Against Vertical Federated Learning,ECML/PKDD,2023, (1): 402-417,"Yuexin Xuan, Xiaojun Chen, Zhendong Zhao, Bisheng Tang, Ye Dong",https://doi.org/10.1007/978-3-031-43415-0_24,,Conference and Workshop Papers,
BHAC-MRI: Backdoor and Hybrid Attacks on MRI Brain Tumor Classification Using CNN,ICIAP,2023, (1): 332-344,"Muhammad Imran, Hassaan Khaliq Qureshi, Irene Amerini",https://doi.org/10.1007/978-3-031-43153-1_28,,Conference and Workshop Papers,
Defending Against Backdoor Attacks by Layer-wise Feature Analysis,PAKDD,2023, (1): 428-440,"Najeeb Moharram Jebreel, Josep Domingo-Ferrer, Yiming Li",https://doi.org/10.1007/978-3-031-33377-4_33,,Conference and Workshop Papers,
Backdoor Mitigation in Deep Neural Networks via Strategic Retraining,FM,2023, (1): 635-647,"Akshay Dhonthi, Ernst Moritz Hahn, Vahid Hashemi",https://doi.org/10.1007/978-3-031-27481-7_37,,Conference and Workshop Papers,
Towards a Robust Defense: A Multifaceted Approach to the Detection and Mitigation of Neural Backdoor Attacks through Feature Space Exploration and Analysis,,2023, (1): 1,Liuwan Zhu,https://digitalcommons.odu.edu/ece_etds/254,,Books and Theses,
PerCBA: Persistent Clean-label Backdoor Attacks on Semi-Supervised Graph Node Classification,AISafety/SafeRL@IJCAI,2023, (1): 1,"Xiao Yang, Gaolei Li, Chaofeng Zhang, Meng Han, Wu Yang",https://ceur-ws.org/Vol-3505/paper_4.pdf,,Conference and Workshop Papers,
Backdoor Attack Detection in Computer Vision by Applying Matrix Factorization on the Weights of Deep Networks,SafeAI@AAAI,2023, (1): 1,"Khondoker Murad Hossain, Tim Oates",https://ceur-ws.org/Vol-3381/40.pdf,,Conference and Workshop Papers,
Towards Understanding How Self-training Tolerates Data Backdoor Poisoning,SafeAI@AAAI,2023, (1): 1,"Soumyadeep Pal, Ren Wang, Yuguang Yao, Sijia Liu",https://ceur-ws.org/Vol-3381/31.pdf,,Conference and Workshop Papers,
Backdoor Attack on Hash-based Image Retrieval via Clean-label Data Poisoning,BMVC,2023, (1): 172-173,"Kuofeng Gao, Jiawang Bai, Bin Chen, Dongxian Wu, Shu-Tao Xia",http://proceedings.bmvc2023.org/172/,,Conference and Workshop Papers,
Towards Stable Backdoor Purification through Feature Shift Tuning,NeurIPS,2023, (1): 1,"Rui Min, Zeyu Qin, Li Shen, Minhao Cheng",http://papers.nips.cc/paper_files/paper/2023/hash/ee37d51b3c003d89acba2363dde256af-Abstract-Conference.html,,Conference and Workshop Papers,
Setting the Trap: Capturing and Defeating Backdoors in Pretrained Language Models through Honeypots,NeurIPS,2023, (1): 1,"Ruixiang (Ryan) Tang, Jiayi Yuan, Yiming Li, Zirui Liu, Rui Chen, Xia Hu",http://papers.nips.cc/paper_files/paper/2023/hash/e7938ede51225b490bb69f7b361a9259-Abstract-Conference.html,,Conference and Workshop Papers,
IBA: Towards Irreversible Backdoor Attacks in Federated Learning,NeurIPS,2023, (1): 1,"Thuy Dung Nguyen, Tuan Nguyen, Anh Tran, Khoa D. Doan, Kok-Seng Wong",http://papers.nips.cc/paper_files/paper/2023/hash/d0c6bc641a56bebee9d985b937307367-Abstract-Conference.html,,Conference and Workshop Papers,
Fed-FA: Theoretically Modeling Client Data Divergence for Federated Language Backdoor Defense,NeurIPS,2023, (1): 1,"Zhiyuan Zhang, Deli Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun",http://papers.nips.cc/paper_files/paper/2023/hash/c39578c86423df5f9e8834ce1cd456e4-Abstract-Conference.html,,Conference and Workshop Papers,
A3FL: Adversarially Adaptive Backdoor Attacks to Federated Learning,NeurIPS,2023, (1): 1,"Hangfan Zhang, Jinyuan Jia, Jinghui Chen, Lu Lin, Dinghao Wu",http://papers.nips.cc/paper_files/paper/2023/hash/c07d71ff0bc042e4b9acd626a79597fa-Abstract-Conference.html,,Conference and Workshop Papers,
Black-box Backdoor Defense via Zero-shot Image Purification,NeurIPS,2023, (1): 1,"Yucheng Shi, Mengnan Du, Xuansheng Wu, Zihan Guan, Jin Sun, Ninghao Liu",http://papers.nips.cc/paper_files/paper/2023/hash/b36554b97da741b1c48c9de05c73993e-Abstract-Conference.html,,Conference and Workshop Papers,
FedGame: A Game-Theoretic Defense against Backdoor Attacks in Federated Learning,NeurIPS,2023, (1): 1,"Jinyuan Jia, Zhuowen Yuan, Dinuka Sahabandu, Luyao Niu, Arezoo Rajabi, Bhaskar Ramasubramanian, Bo Li, Radha Poovendran",http://papers.nips.cc/paper_files/paper/2023/hash/a6678e2be4ce7aef9d2192e03cd586b7-Abstract-Conference.html,,Conference and Workshop Papers,
BadTrack: A Poison-Only Backdoor Attack on Visual Object Tracking,NeurIPS,2023, (1): 1,"Bin Huang, Jiaqian Yu, Yiwei Chen, Siyang Pan, Qiang Wang, Zhi Wang",http://papers.nips.cc/paper_files/paper/2023/hash/828bb8f42d4ab15322b9315151959c61-Abstract-Conference.html,,Conference and Workshop Papers,
BIRD: Generalizable Backdoor Detection and Removal for Deep Reinforcement Learning,NeurIPS,2023, (1): 1,"Xuan Chen, Wenbo Guo, Guanhong Tao, Xiangyu Zhang, Dawn Song",http://papers.nips.cc/paper_files/paper/2023/hash/802e90325f4c8546e13e5763b2ecab88-Abstract-Conference.html,,Conference and Workshop Papers,
VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion Models,NeurIPS,2023, (1): 1,"Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho",http://papers.nips.cc/paper_files/paper/2023/hash/6b055b95d689b1f704d8f92191cdb788-Abstract-Conference.html,,Conference and Workshop Papers,
Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks,NeurIPS,2023, (1): 1,"Zhaohan Xi, Tianyu Du, Changjiang Li, Ren Pang, Shouling Ji, Jinghui Chen, Fenglong Ma, Ting Wang",http://papers.nips.cc/paper_files/paper/2023/hash/677c8dc72c99482507323f313faf4738-Abstract-Conference.html,,Conference and Workshop Papers,
Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples,NeurIPS,2023, (1): 1,"Shaokui Wei, Mingda Zhang, Hongyuan Zha, Baoyuan Wu",http://papers.nips.cc/paper_files/paper/2023/hash/520425a5a4c2fb7f7fc345078b188201-Abstract-Conference.html,,Conference and Workshop Papers,
Lockdown: Backdoor Defense for Federated Learning with Isolated Subspace Training,NeurIPS,2023, (1): 1,"Tiansheng Huang, Sihao Hu, Ka Ho Chow, Fatih Ilhan, Selim F. Tekin, Ling Liu",http://papers.nips.cc/paper_files/paper/2023/hash/2376f25ef1725a9e3516ee3c86a59f46-Abstract-Conference.html,,Conference and Workshop Papers,
Robust Contrastive Language-Image Pretraining against Data Poisoning and Backdoor Attacks,NeurIPS,2023, (1): 1,"Wenhan Yang, Jingdong Gao, Baharan Mirzasoleiman",http://papers.nips.cc/paper_files/paper/2023/hash/2232e8fee69b150005ac420bfa83d705-Abstract-Conference.html,,Conference and Workshop Papers,
A Unified Detection Framework for Inference-Stage Backdoor Defenses,NeurIPS,2023, (1): 1,"Xun Xian, Ganghua Wang, Jayanth Srinivasa, Ashish Kundu, Xuan Bi, Mingyi Hong, Jie Ding",http://papers.nips.cc/paper_files/paper/2023/hash/1868a3c73d0d2a44c42458575fa8514c-Abstract-Conference.html,,Conference and Workshop Papers,
CBD: A Certified Backdoor Detector Based on Local Dominant Probability,NeurIPS,2023, (1): 1,"Zhen Xiang, Zidi Xiong, Bo Li",http://papers.nips.cc/paper_files/paper/2023/hash/0fbf046448d7eea18b982001320b9a10-Abstract-Conference.html,,Conference and Workshop Papers,
Neural Polarizer: A Lightweight and Effective Backdoor Defense via Purifying Poisoned Features,NeurIPS,2023, (1): 1,"Mingli Zhu, Shaokui Wei, Hongyuan Zha, Baoyuan Wu",http://papers.nips.cc/paper_files/paper/2023/hash/03df5246cc78af497940338dd3eacbaa-Abstract-Conference.html,,Conference and Workshop Papers,
Hidden Trigger Backdoor Attack on NLP Models via Linguistic Style Manipulation,USENIX Security Symposium,2022, (1): 3611-3628,"Xudong Pan, Mi Zhang, Beina Sheng, Jiaming Zhu, Min Yang",https://www.usenix.org/conference/usenixsecurity22/presentation/pan-hidden,,Conference and Workshop Papers,
FLAME: Taming Backdoors in Federated Learning,USENIX Security Symposium,2022, (1): 1415-1432,"Thien Duc Nguyen, Phillip Rieger, Huili Chen, Hossein Yalame, Helen Möllering, Hossein Fereidooni, Samuel Marchal, Markus Miettinen, Azalia Mirhoseini, Shaza Zeitouni, Farinaz Koushanfar, Ahmad-Reza Sadeghi, Thomas Schneider",https://www.usenix.org/conference/usenixsecurity22/presentation/nguyen,,Conference and Workshop Papers,
ATTEQ-NN: Attention-based QoE-aware Evasive Backdoor Attacks,NDSS,2022, (1): 1,"Xueluan Gong, Yanjiao Chen, Jianshuo Dong, Qian Wang",https://www.ndss-symposium.org/ndss-paper/auto-draft-238/,,Conference and Workshop Papers,
DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection,NDSS,2022, (1): 1,"Phillip Rieger, Thien Duc Nguyen, Markus Miettinen, Ahmad-Reza Sadeghi",https://www.ndss-symposium.org/ndss-paper/auto-draft-205/,,Conference and Workshop Papers,
Neurotoxin: Durable Backdoors in Federated Learning,ICML,2022, (1): 26429-26446,"Zhengming Zhang, Ashwinee Panda, Linyue Song, Yaoqing Yang, Michael W. Mahoney, Prateek Mittal, Kannan Ramchandran, Joseph Gonzalez",https://proceedings.mlr.press/v162/zhang22w.html,,Conference and Workshop Papers,
Constrained Optimization with Dynamic Bound-scaling for Effective NLP Backdoor Defense,ICML,2022, (1): 19879-19892,"Guangyu Shen, Yingqi Liu, Guanhong Tao, Qiuling Xu, Zhuo Zhang, Shengwei An, Shiqing Ma, Xiangyu Zhang",https://proceedings.mlr.press/v162/shen22e.html,,Conference and Workshop Papers,
Defending Against Backdoor Attacks Using Ensembles of Weak Learners ,ICLR 2022 Submitted,2022,,"Charles Jin, Melinda Sun, Martin Rinard",https://openreview.net/pdf/fce04a6398776d3ea079229e0a98b746941756e4.pdf,,,
Finding Naturally Occurring Physical Backdoors in Image Datasets,NeurIPS 2022 Datasets and Benchmarks ,2022,,"Emily Wenger, Roma Bhattacharjee, Arjun Nitin Bhagoji, Josephine Passananti, Emilio Andere, Haitao Zheng, Ben Zhao",https://openreview.net/pdf/fc96993df3ae013160ef05f61cd1bd8bb80466ff.pdf,,,
Towards General Robustness to Bad Training Data,ICLR 2022 Submitted,2022,,"Tianhao Wang, Yi Zeng, Ming Jin, Ruoxi Jia",https://openreview.net/pdf/dbe4b96676cea77be59c61d209458926c99dce98.pdf,,,
Friendly Noise against Adversarial Noise: A Powerful Defense against Data Poisoning Attack,NeurIPS 2022 Accept,2022,,"Tian Yu Liu, Yu Yang, Baharan Mirzasoleiman",https://openreview.net/pdf/d929e1c412e3fecf6a4fb8991f306a09330510c6.pdf,,,
Moderate-fitting as a Natural Backdoor Defender for Pre-trained Language Models,NeurIPS 2022 Accept,2022,,"Biru Zhu, Yujia Qin, Ganqu Cui, Yangyi Chen, Weilin Zhao, Chong Fu, Yangdong Deng, Zhiyuan Liu, Jingang Wang, Wei Wu, Maosong Sun, Ming Gu",https://openreview.net/pdf/c4fc6df6829404ccd0da096c0b97ea0689c6e819.pdf,,,
Gradient Broadcast Adaptation: Defending against the backdoor attack in pre-trained models,ICLR 2022 Submitted,2022,,"Tianyu Chen, Haoyi Zhou, He Mingrui, Jianxin Li",https://openreview.net/pdf/ab7054f88f833e302b7643c974c47755f2e243aa.pdf,,,
Pre-activation Distributions Expose Backdoor Neurons,NeurIPS 2022 Accept,2022,,"Runkai Zheng, Rongjun Tang, Jianze Li, Li Liu",https://openreview.net/pdf/8e53129e6250dab82ad52dc5fd8d6a4015ac7c99.pdf,,,
Randomized Channel Shuffling: Minimal-Overhead Backdoor Attack Detection without Clean Datasets,NeurIPS 2022 Accept,2022,,"Ruisi Cai, Zhenyu Zhang, Tianlong Chen, Xiaohan Chen, Zhangyang Wang",https://openreview.net/pdf/8a0c5fb7d856a9ca21433b90a5249ad9814429c8.pdf,,,
Effective Backdoor Defense by Exploiting Sensitivity of Poisoned Samples,NeurIPS 2022 Accept,2022,,"Weixin Chen, Baoyuan Wu, Haoqian Wang",https://openreview.net/pdf/82397e777241ae042276e8493ca8e5d228821582.pdf,,,
Defend Against Textual Backdoor Attacks By Token Substitution,RobustSeq @ NeurIPS 2022 Poster,2022,,"Xinglin Li, Yao Li, Minhao Cheng",https://openreview.net/pdf/660abd116777164eeb9f7d68c81098bf01bd38f6.pdf,,,
An Optimization Perspective on Realizing Backdoor Injection Attacks on Deep Neural Networks in Hardware,ICLR 2022 Submitted,2022,,"M. Caner Tol, Saad Islam, Berk Sunar, Ziming Zhang",https://openreview.net/pdf/628fdbcebf74b3b22b28cf024722d2d5b78c9136.pdf,,,
Defending Backdoor Data Poisoning Attacks by Using Noisy Label Defense Algorithm,ICLR 2022 Submitted,2022,,"Boyang Liu, Zhuangdi Zhu, Pang-Ning Tan, Jiayu Zhou",https://openreview.net/pdf/5ff5019b74c4ec5b4a9ef6ccc642b82bd47fe1d0.pdf,,,
BAAT: Towards Sample-specific Backdoor Attack with Clean Labels,MLSW2022,2022,,"Yiming Li, Mingyan Zhu, Chengxiao Luo, Haiqin Weng, Yong Jiang, Tao Wei, Shu-Tao Xia",https://openreview.net/pdf/5876315b65f28dd4180e671ed7454304af1d21eb.pdf,,,
Benchmarking the Effect of Poisoning Defenses on the Security and Bias of the Final Model,TSRML2022,2022,,"Nathalie Baracaldo, Kevin Eykholt, Farhan Ahmed, Yi Zhou, Shriti Priya, Taesung Lee, Swanand Kadhe, Yusong Tan, Sridevi Polavaram, Sterling Suggs, Yuyang Gao, David Slater",https://openreview.net/pdf/1a0ad3517de5377f93a8ce4d81c6d4ad662b0375.pdf,,,
Continual Poisoning of Generative Models to Promote Catastrophic Forgetting,MLSW2022,2022,,"Siteng Kang, Zhan Shi, Xinhua Zhang",https://openreview.net/pdf/12a52f46f39ec7b986dd3192173071f8ae256433.pdf,,,
Backdoor Attacks in Federated Learning by Poisoned Word Embeddings,FL4NLP@ACL2022,2022,,"KiYoon Yoo, Nojun Kwak",https://openreview.net/pdf/0b3f11fc9e736a061c3ab99af154f14c26373b16.pdf,,,
Symbolic Causal Inference via Operations on Probabilistic Circuits,nCSI WS @ NeurIPS 2022 Poster,2022,,"Benjie Wang, Marta Kwiatkowska",https://openreview.net/pdf/0aa93b52f539d4a823da220b783628a024fcc9de.pdf,,,
Few-Shot Backdoor Attacks on Visual Object Tracking,ICLR,2022, (1): 1,"Yiming Li, Haoxiang Zhong, Xingjun Ma, Yong Jiang, Shu-Tao Xia",https://openreview.net/forum?id=qSV5CuSaK_a,,Conference and Workshop Papers,
Poisoning and Backdooring Contrastive Learning,ICLR,2022, (1): 1,"Nicholas Carlini, Andreas Terzis",https://openreview.net/forum?id=iC4UHbQ01Mp,,Conference and Workshop Papers,
Backdoor Defense via Decoupling the Training Process,ICLR,2022, (1): 1,"Kunzhe Huang, Yiming Li, Baoyuan Wu, Zhan Qin, Kui Ren",https://openreview.net/forum?id=TySnJ-0RdKI,,Conference and Workshop Papers,
AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value Analysis,ICLR,2022, (1): 1,"Junfeng Guo, Ang Li, Cong Liu",https://openreview.net/forum?id=OM_lYiHXiCL,,Conference and Workshop Papers,
BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models,ICLR,2022, (1): 1,"Kangjie Chen, Yuxian Meng, Xiaofei Sun, Shangwei Guo, Tianwei Zhang, Jiwei Li, Chun Fan",https://openreview.net/forum?id=Mng8CQ9eBW,,Conference and Workshop Papers,
Adversarial Unlearning of Backdoors via Implicit Hypergradient,ICLR,2022, (1): 1,"Yi Zeng, Si Chen, Won Park, Zhuoqing Mao, Ming Jin, Ruoxi Jia",https://openreview.net/forum?id=MeeQkFYVbzW,,Conference and Workshop Papers,
Post-Training Detection of Backdoor Attacks for Two-Class and Multi-Attack Scenarios,ICLR,2022, (1): 1,"Zhen Xiang, David J. Miller, George Kesidis",https://openreview.net/forum?id=MSgB8D4Hy51,,Conference and Workshop Papers,
How to Inject Backdoors with Better Consistency: Logit Anchoring on Clean Data,ICLR,2022, (1): 1,"Zhiyuan Zhang, Lingjuan Lyu, Weiqiang Wang, Lichao Sun, Xu Sun",https://openreview.net/forum?id=Bn09TnDngN,,Conference and Workshop Papers,
How to Backdoor (Classical) McEliece and How to Guard Against Backdoors,IACR Cryptol. ePrint Arch.,2022,2022 (1): 362,"Alexander May, Carl Richard Theodor Schneider",https://eprint.iacr.org/2022/362,,Informal and Other Publications,
Backdooring Post-Quantum Cryptography: Kleptographic Attacks on Lattice-based KEMs,IACR Cryptol. ePrint Arch.,2022,2022 (1): 1681,"Prasanna Ravi, Shivam Bhasin, Anupam Chattopadhyay, Aikata, Sujoy Sinha Roy",https://eprint.iacr.org/2022/1681,,Informal and Other Publications,
How to backdoor LWE-like cryptosystems,IACR Cryptol. ePrint Arch.,2022,2022 (1): 1381,Tobias Hemmert,https://eprint.iacr.org/2022/1381,,Informal and Other Publications,
XMAM: X-raying Models with A Matrix to Reveal Backdoor Attacks for Federated Learning,arXiv/CoRR,2022,abs/2212.13675 (1): 1,"Jianyi Zhang, Fangjiao Zhang, Qichao Jin, Zhiqiang Wang, Xiaodong Lin, Xiali Hei",https://doi.org/10.48550/arXiv.2212.13675,,Informal and Other Publications,
VSVC: Backdoor attack against Keyword Spotting based on Voiceprint Selection and Voice Conversion,arXiv/CoRR,2022,abs/2212.10103 (1): 1,"Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao, Shunhui Ji",https://doi.org/10.48550/arXiv.2212.10103,,Informal and Other Publications,
Flareon: Stealthy any2any Backdoor Injection via Poisoned Augmentation,arXiv/CoRR,2022,abs/2212.09979 (1): 1,"Tianrui Qin, Xianghuan He, Xitong Gao, Yiren Zhao, Kejiang Ye, Cheng-Zhong Xu",https://doi.org/10.48550/arXiv.2212.09979,,Informal and Other Publications,
Fine-Tuning Is All You Need to Mitigate Backdoor Attacks,arXiv/CoRR,2022,abs/2212.09067 (1): 1,"Zeyang Sha, Xinlei He, Pascal Berrang, Mathias Humbert, Yang Zhang",https://doi.org/10.48550/arXiv.2212.09067,,Informal and Other Publications,
"Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of Backdoor Effects in Trojaned Machine Learning Models",arXiv/CoRR,2022,abs/2212.04687 (1): 1,"Rui Zhu, Di Tang, Siyuan Tang, XiaoFeng Wang, Haixu Tang",https://doi.org/10.48550/arXiv.2212.04687,,Informal and Other Publications,
Rethinking Backdoor Data Poisoning Attacks in the Context of Semi-Supervised Learning,arXiv/CoRR,2022,abs/2212.02582 (1): 1,"Marissa Connor, Vincent Emanuele",https://doi.org/10.48550/arXiv.2212.02582,,Informal and Other Publications,
Be Careful with Rotation: A Uniform Backdoor Pattern for 3D Shape,arXiv/CoRR,2022,abs/2211.16192 (1): 1,"Linkun Fan, Fazhi He, Qing Guo, Wei Tang, Xiaolin Hong, Bing Li",https://doi.org/10.48550/arXiv.2211.16192,,Informal and Other Publications,
Backdoor Vulnerabilities in Normally Trained Deep Learning Models,arXiv/CoRR,2022,abs/2211.15929 (1): 1,"Guanhong Tao, Zhenting Wang, Siyuan Cheng, Shiqing Ma, Shengwei An, Yingqi Liu, Guangyu Shen, Zhuo Zhang, Yunshu Mao, Xiangyu Zhang",https://doi.org/10.48550/arXiv.2211.15929,,Informal and Other Publications,
Backdoor Attacks on Multiagent Collaborative Systems,arXiv/CoRR,2022,abs/2211.11455 (1): 1,"Shuo Chen, Yue Qiu, Jie Zhang",https://doi.org/10.48550/arXiv.2211.11455,,Informal and Other Publications,
PBSM: Backdoor attack against Keyword spotting based on pitch boosting and sound masking,arXiv/CoRR,2022,abs/2211.08697 (1): 1,"Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao, Shunhui Ji",https://doi.org/10.48550/arXiv.2211.08697,,Informal and Other Publications,
CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive Learning,arXiv/CoRR,2022,abs/2211.08229 (1): 1,"Jinghuai Zhang, Hongbin Liu, Jinyuan Jia, Neil Zhenqiang Gong",https://doi.org/10.48550/arXiv.2211.08229,,Informal and Other Publications,
Backdoor Attacks on Time Series: A Generative Approach,arXiv/CoRR,2022,abs/2211.07915 (1): 1,"Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, James Bailey",https://doi.org/10.48550/arXiv.2211.07915,,Informal and Other Publications,
Physics-Constrained Backdoor Attacks on Power System Fault Localization,arXiv/CoRR,2022,abs/2211.04445 (1): 1,"Jianing Bai, Ren Wang, Zuyi Li",https://doi.org/10.48550/arXiv.2211.04445,,Informal and Other Publications,
Rickrolling the Artist: Injecting Invisible Backdoors into Text-Guided Image Generation Models,arXiv/CoRR,2022,abs/2211.02408 (1): 1,"Lukas Struppek, Dominik Hintersdorf, Kristian Kersting",https://doi.org/10.48550/arXiv.2211.02408,,Informal and Other Publications,
M-to-N Backdoor Paradigm: A Stealthy and Fuzzy Attack to Deep Learning Models,arXiv/CoRR,2022,abs/2211.01875 (1): 1,"Linshan Hou, Zhongyun Hua, Yuhong Li, Leo Yu Zhang",https://doi.org/10.48550/arXiv.2211.01875,,Informal and Other Publications,
Detecting Backdoors in Deep Text Classifiers,arXiv/CoRR,2022,abs/2210.11264 (1): 1,"You Guo, Jun Wang, Trevor Cohn",https://doi.org/10.48550/arXiv.2210.11264,,Informal and Other Publications,
Apple of Sodom: Hidden Backdoors in Superior Sentence Embeddings via Contrastive Learning,arXiv/CoRR,2022,abs/2210.11082 (1): 1,"Xiaoyi Chen, Baisong Xin, Shengfang Zhai, Shiqing Ma, Qingni Shen, Zhonghai Wu",https://doi.org/10.48550/arXiv.2210.11082,,Informal and Other Publications,
Thinking Two Moves Ahead: Anticipating Other Users Improves Backdoor Attacks in Federated Learning,arXiv/CoRR,2022,abs/2210.09305 (1): 1,"Yuxin Wen, Jonas Geiping, Liam Fowl, Hossein Souri, Rama Chellappa, Micah Goldblum, Tom Goldstein",https://doi.org/10.48550/arXiv.2210.09305,,Informal and Other Publications,
Close the Gate: Detecting Backdoored Models in Federated Learning based on Client-Side Deep Layer Output Analysis,arXiv/CoRR,2022,abs/2210.07714 (1): 1,"Phillip Rieger, Torsten Krauß, Markus Miettinen, Alexandra Dmitrienko, Ahmad-Reza Sadeghi",https://doi.org/10.48550/arXiv.2210.07714,,Informal and Other Publications,
Watermarking Pre-trained Language Models with Backdooring,arXiv/CoRR,2022,abs/2210.07543 (1): 1,"Chenxi Gu, Chengsong Huang, Xiaoqing Zheng, Kai-Wei Chang, Cho-Jui Hsieh",https://doi.org/10.48550/arXiv.2210.07543,,Informal and Other Publications,
Understanding Impacts of Task Similarity on Backdoor Attack and Detection,arXiv/CoRR,2022,abs/2210.06509 (1): 1,"Di Tang, Rui Zhu, XiaoFeng Wang, Haixu Tang, Yi Chen",https://doi.org/10.48550/arXiv.2210.06509,,Informal and Other Publications,
Mind Your Data! Hiding Backdoors in Offline Reinforcement Learning Datasets,arXiv/CoRR,2022,abs/2210.04688 (1): 1,"Chen Gong, Zhou Yang, Yunpeng Bai, Junda He, Jieke Shi, Arunesh Sinha, Bowen Xu, Xinwen Hou, Guoliang Fan, David Lo",https://doi.org/10.48550/arXiv.2210.04688,,Informal and Other Publications,
Invariant Aggregator for Defending Federated Backdoor Attacks,arXiv/CoRR,2022,abs/2210.01834 (1): 1,"Xiaoyang Wang, Dimitrios Dimitriadis, Sanmi Koyejo, Shruti Tople",https://doi.org/10.48550/arXiv.2210.01834,,Informal and Other Publications,
Backdoor Attacks in the Supply Chain of Masked Image Modeling,arXiv/CoRR,2022,abs/2210.01632 (1): 1,"Xinyue Shen, Xinlei He, Zheng Li, Yun Shen, Michael Backes, Yang Zhang",https://doi.org/10.48550/arXiv.2210.01632,,Informal and Other Publications,
Augmentation Backdoors,arXiv/CoRR,2022,abs/2209.15139 (1): 1,"Joseph Rance, Yiren Zhao, Ilia Shumailov, Robert D. Mullins",https://doi.org/10.48550/arXiv.2209.15139,,Informal and Other Publications,
Black-box Ownership Verification for Dataset Protection via Backdoor Watermarking,arXiv/CoRR,2022,abs/2209.06015 (1): 1,"Yiming Li, Mingyan Zhu, Xue Yang, Yong Jiang, Shu-Tao Xia",https://doi.org/10.48550/arXiv.2209.06015,,Informal and Other Publications,
Adaptive Perturbation Generation for Multiple Backdoors Detection,arXiv/CoRR,2022,abs/2209.05244 (1): 1,"Yuhang Wang, Huafeng Shi, Rui Min, Ruijia Wu, Siyuan Liang, Yichao Wu, Ding Liang, Aishan Liu",https://doi.org/10.48550/arXiv.2209.05244,,Informal and Other Publications,
Defending Against Backdoor Attack on Graph Nerual Network by Explainability,arXiv/CoRR,2022,abs/2209.02902 (1): 1,"Bingchen Jiang, Zhao Li",https://doi.org/10.48550/arXiv.2209.02902,,Informal and Other Publications,
MACAB: Model-Agnostic Clean-Annotation Backdoor to Object Detection with Natural Trigger in Real-World,arXiv/CoRR,2022,abs/2209.02339 (1): 1,"Hua Ma, Yinshan Li, Yansong Gao, Zhi Zhang, Alsharif Abuadbba, Anmin Fu, Said F. Al-Sarawi, Surya Nepal, Derek Abbott",https://doi.org/10.48550/arXiv.2209.02339,,Informal and Other Publications,
Solving the Capsulation Attack against Backdoor-based Deep Neural Network Watermarks by Reversing Triggers,arXiv/CoRR,2022,abs/2208.14127 (1): 1,"Fangqi Li, Shilin Wang, Yun Zhu",https://doi.org/10.48550/arXiv.2208.14127,,Informal and Other Publications,
Confidence Matters: Inspecting Backdoors in Deep Neural Networks via Distribution Transfer,arXiv/CoRR,2022,abs/2208.06592 (1): 1,"Tong Wang, Yuan Yao, Feng Xu, Miao Xu, Shengwei An, Ting Wang",https://doi.org/10.48550/arXiv.2208.06592,,Informal and Other Publications,
Defense against Backdoor Attacks via Identifying and Purifying Bad Neurons,arXiv/CoRR,2022,abs/2208.06537 (1): 1,"Mingyuan Fan, Yang Liu, Cen Chen, Ximeng Liu, Wenzhong Guo",https://doi.org/10.48550/arXiv.2208.06537,,Informal and Other Publications,
A Knowledge Distillation-Based Backdoor Attack in Federated Learning,arXiv/CoRR,2022,abs/2208.06176 (1): 1,"Yifan Wang, Wei Fan, Keke Yang, Naji Alhusaini, Jing Li",https://doi.org/10.48550/arXiv.2208.06176,,Informal and Other Publications,
Backdoor Watermarking Deep Learning Classification Models With Deep Fidelity,arXiv/CoRR,2022,abs/2208.00563 (1): 1,"Guang Hua, Andrew Beng Jin Teoh",https://doi.org/10.48550/arXiv.2208.00563,,Informal and Other Publications,
FRIB: Low-poisoning Rate Invisible Backdoor Attack based on Feature Repair,arXiv/CoRR,2022,abs/2207.12863 (1): 1,"Hui Xia, Xiugui Yang, Xiangyun Qian, Rui Zhang",https://doi.org/10.48550/arXiv.2207.12863,,Informal and Other Publications,
Technical Report: Assisting Backdoor Federated Learning with Whole Population Knowledge Alignment,arXiv/CoRR,2022,abs/2207.12327 (1): 1,"Tian Liu, Xueyang Hu, Tao Shu",https://doi.org/10.48550/arXiv.2207.12327,,Informal and Other Publications,
Invisible Backdoor Attacks Using Data Poisoning in the Frequency Domain,arXiv/CoRR,2022,abs/2207.04209 (1): 1,"Chang Yue, Peizhuo Lv, Ruigang Liang, Kai Chen",https://doi.org/10.48550/arXiv.2207.04209,,Informal and Other Publications,
Natural Backdoor Datasets,arXiv/CoRR,2022,abs/2206.10673 (1): 1,"Emily Wenger, Roma Bhattacharjee, Arjun Nitin Bhagoji, Josephine Passananti, Emilio Andere, Haitao Zheng, Ben Y. Zhao",https://doi.org/10.48550/arXiv.2206.10673,,Informal and Other Publications,
DECK: Model Hardening for Defending Pervasive Backdoors,arXiv/CoRR,2022,abs/2206.09272 (1): 1,"Guanhong Tao, Yingqi Liu, Siyuan Cheng, Shengwei An, Zhuo Zhang, Qiuling Xu, Guangyu Shen, Xiangyu Zhang",https://doi.org/10.48550/arXiv.2206.09272,,Informal and Other Publications,
Backdoor Attacks on Vision Transformers,arXiv/CoRR,2022,abs/2206.08477 (1): 1,"Akshayvarun Subramanya, Aniruddha Saha, Soroush Abbasi Koohpayegani, Ajinkya Tejankar, Hamed Pirsiavash",https://doi.org/10.48550/arXiv.2206.08477,,Informal and Other Publications,
Enhancing Clean Label Backdoor Attack with Two-phase Specific Triggers,arXiv/CoRR,2022,abs/2206.04881 (1): 1,"Nan Luo, Yuanzhang Li, Yajie Wang, Shangbo Wu, Yu-An Tan, Quanxin Zhang",https://doi.org/10.48550/arXiv.2206.04881,,Informal and Other Publications,
Can Backdoor Attacks Survive Time-Varying Models?,arXiv/CoRR,2022,abs/2206.04677 (1): 1,"Huiying Li, Arjun Nitin Bhagoji, Ben Y. Zhao, Haitao Zheng",https://doi.org/10.48550/arXiv.2206.04677,,Informal and Other Publications,
Contributor-Aware Defenses Against Adversarial Backdoor Attacks,arXiv/CoRR,2022,abs/2206.03583 (1): 1,"Glenn Dawson, Muhammad Umer, Robi Polikar",https://doi.org/10.48550/arXiv.2206.03583,,Informal and Other Publications,
CASSOCK: Viable Backdoor Attacks against DNN in The Wall of Source-Specific Backdoor Defences,arXiv/CoRR,2022,abs/2206.00145 (1): 1,"Shang Wang, Yansong Gao, Anmin Fu, Zhi Zhang, Yuqing Zhang, Willy Susilo",https://doi.org/10.48550/arXiv.2206.00145,,Informal and Other Publications,
Defending Against Stealthy Backdoor Attacks,arXiv/CoRR,2022,abs/2205.14246 (1): 1,"Sangeet Sagar, Abhinav Bhatt, Abhijith Srinivas Bidaralli",https://doi.org/10.48550/arXiv.2205.14246,,Informal and Other Publications,
Fight Poison with Poison: Detecting Backdoor Poison Samples via Decoupling Benign Correlations,arXiv/CoRR,2022,abs/2205.13616 (1): 1,"Xiangyu Qi, Tinghao Xie, Saeed Mahloujifar, Prateek Mittal",https://doi.org/10.48550/arXiv.2205.13616,,Informal and Other Publications,
Circumventing Backdoor Defenses That Are Based on Latent Separability,arXiv/CoRR,2022,abs/2205.13613 (1): 1,"Xiangyu Qi, Tinghao Xie, Saeed Mahloujifar, Prateek Mittal",https://doi.org/10.48550/arXiv.2205.13613,,Informal and Other Publications,
PerDoor: Persistent Non-Uniform Backdoors in Federated Learning using Adversarial Perturbations,arXiv/CoRR,2022,abs/2205.13523 (1): 1,"Manaar Alam, Esha Sarkar, Michail Maniatakos",https://doi.org/10.48550/arXiv.2205.13523,,Informal and Other Publications,
Textual Backdoor Attacks with Iterative Trigger Injection,arXiv/CoRR,2022,abs/2205.12700 (1): 1,"Jun Yan, Vansh Gupta, Xiang Ren",https://doi.org/10.48550/arXiv.2205.12700,,Informal and Other Publications,
Towards a Defense against Backdoor Attacks in Continual Federated Learning,arXiv/CoRR,2022,abs/2205.11736 (1): 1,"Shuaiqi Wang, Jonathan Hayase, Giulia Fanti, Sewoong Oh",https://doi.org/10.48550/arXiv.2205.11736,,Informal and Other Publications,
Backdoor Attacks on Bayesian Neural Networks using Reverse Distribution,arXiv/CoRR,2022,abs/2205.09167 (1): 1,"Zhixin Pan, Prabhat Mishra",https://doi.org/10.48550/arXiv.2205.09167,,Informal and Other Publications,
Universal Post-Training Backdoor Detection,arXiv/CoRR,2022,abs/2205.06900 (1): 1,"Hang Wang, Zhen Xiang, David J. Miller, George Kesidis",https://doi.org/10.48550/arXiv.2205.06900,,Informal and Other Publications,
Model-Contrastive Learning for Backdoor Defense,arXiv/CoRR,2022,abs/2205.04411 (1): 1,"Zhihao Yue, Jun Xia, Zhiwei Ling, Ming Hu, Ting Wang, Xian Wei, Mingsong Chen",https://doi.org/10.48550/arXiv.2205.04411,,Informal and Other Publications,
Detecting Backdoor Poisoning Attacks on Deep Neural Networks by Heatmap Clustering,arXiv/CoRR,2022,abs/2204.12848 (1): 1,"Lukas Schulth, Christian Berghoff, Matthias Neu",https://doi.org/10.48550/arXiv.2204.12848,,Informal and Other Publications,
Backdooring Explainable Machine Learning,arXiv/CoRR,2022,abs/2204.09498 (1): 1,"Maximilian Noppel, Lukas Peter, Christian Wressnegger",https://doi.org/10.48550/arXiv.2204.09498,,Informal and Other Publications,
Planting Undetectable Backdoors in Machine Learning Models,arXiv/CoRR,2022,abs/2204.06974 (1): 1,"Shafi Goldwasser, Michael P. Kim, Vinod Vaikuntanathan, Or Zamir",https://doi.org/10.48550/arXiv.2204.06974,,Informal and Other Publications,
Towards A Critical Evaluation of Robustness for Deep Learning Backdoor Countermeasures,arXiv/CoRR,2022,abs/2204.06273 (1): 1,"Huming Qiu, Hua Ma, Zhi Zhang, Alsharif Abuadbba, Wei Kang, Anmin Fu, Yansong Gao",https://doi.org/10.48550/arXiv.2204.06273,,Informal and Other Publications,
Backdoor Attack against NLP models with Robustness-Aware Perturbation defense,arXiv/CoRR,2022,abs/2204.05758 (1): 1,"Shaik Mohammed Maqsood, Viveros Manuela Ceron, Addluri GowthamKrishna",https://doi.org/10.48550/arXiv.2204.05758,,Informal and Other Publications,
An Adaptive Black-box Backdoor Detection Method for Deep Neural Networks,arXiv/CoRR,2022,abs/2204.04329 (1): 1,"Xinqiao Zhang, Huili Chen, Ke Huang, Farinaz Koushanfar",https://doi.org/10.48550/arXiv.2204.04329,,Informal and Other Publications,
Trojan Horse Training for Breaking Defenses against Backdoor Attacks in Deep Learning,arXiv/CoRR,2022,abs/2203.15506 (1): 1,"Arezoo Rajabi, Bhaskar Ramasubramanian, Radha Poovendran",https://doi.org/10.48550/arXiv.2203.15506,,Informal and Other Publications,
PiDAn: A Coherence Optimization Approach for Backdoor Attack Detection and Mitigation in Deep Neural Networks,arXiv/CoRR,2022,abs/2203.09289 (1): 1,"Yue Wang, Wenqing Li, Esha Sarkar, Muhammad Shafique, Michail Maniatakos, Saif Eddin Jabari",https://doi.org/10.48550/arXiv.2203.09289,,Informal and Other Publications,
Client-Wise Targeted Backdoor in Federated Learning,arXiv/CoRR,2022,abs/2203.08689 (1): 1,"Gorka Abad, Servio Paguada, Stjepan Picek, Víctor Julio Ramírez-Durán, Aitor Urbieta",https://doi.org/10.48550/arXiv.2203.08689,,Informal and Other Publications,
Low-Loss Subspace Compression for Clean Gains against Multi-Agent Backdoor Attacks,arXiv/CoRR,2022,abs/2203.03692 (1): 1,"Siddhartha Datta, Nigel Shadbolt",https://doi.org/10.48550/arXiv.2203.03692,,Informal and Other Publications,
Clean-Annotation Backdoor Attack against Lane Detection Systems in the Wild,arXiv/CoRR,2022,abs/2203.00858 (1): 1,"Xingshuo Han, Guowen Xu, Yuan Zhou, Xuehuan Yang, Jiwei Li, Tianwei Zhang",https://doi.org/10.48550/arXiv.2203.00858,,Informal and Other Publications,
Backdoor Sets on Nowhere Dense SAT,ICALP,2022, (1): 91:1-91:20,"Daniel Lokshtanov, Fahad Panolan, M. S. Ramanujan",https://doi.org/10.4230/LIPIcs.ICALP.2022.91,,Conference and Workshop Papers,
SAT Backdoors: Depth Beats Size,ESA,2022, (1): 46:1-46:18,"Jan Dreier, Sebastian Ordyniak, Stefan Szeider",https://doi.org/10.4230/LIPIcs.ESA.2022.46,,Conference and Workshop Papers,
IBD: An Interpretable Backdoor-Detection Method via Multivariate Interactions,Sensors,2022,22 (22): 8697,"Yixiao Xu, Xiaolei Liu, Kangyi Ding, Bangzhou Xin",https://doi.org/10.3390/s22228697,,Journal Articles,
Boosting the Performance of CDCL-Based SAT Solvers by Exploiting Backbones and Backdoors,Algorithms,2022,15 (9): 302,"Tasniem Nasser Al-Yahya, Mohamed El Bachir Menai, Hassan Mathkour",https://doi.org/10.3390/a15090302,,Journal Articles,
PPT: Backdoor Attacks on Pre-trained Models via Poisoned Prompt Tuning,IJCAI,2022, (1): 680-686,"Wei Du, Yichun Zhao, Boqun Li, Gongshen Liu, Shilin Wang",https://doi.org/10.24963/ijcai.2022/96,,Conference and Workshop Papers,
Data-Efficient Backdoor Attacks,IJCAI,2022, (1): 3992-3998,"Pengfei Xia, Ziqiang Li, Wei Zhang, Bin Li",https://doi.org/10.24963/ijcai.2022/554,,Conference and Workshop Papers,
Membership Inference via Backdooring,IJCAI,2022, (1): 3832-3838,"Hongsheng Hu, Zoran Salcic, Gillian Dobbie, Jinjun Chen, Lichao Sun, Xuyun Zhang",https://doi.org/10.24963/ijcai.2022/532,,Conference and Workshop Papers,
Imperceptible Backdoor Attack: From Input Space to Feature Representation,IJCAI,2022, (1): 1736-1742,"Nan Zhong, Zhenxing Qian, Xinpeng Zhang",https://doi.org/10.24963/ijcai.2022/242,,Conference and Workshop Papers,
Eliminating Backdoor Triggers for Deep Neural Networks Using Attention Relation Graph Distillation,IJCAI,2022, (1): 1481-1487,"Jun Xia, Ting Wang, Jiepin Ding, Xian Wei, Mingsong Chen",https://doi.org/10.24963/ijcai.2022/206,,Conference and Workshop Papers,
A Universal Identity Backdoor Attack against Speaker Verification based on Siamese Network,INTERSPEECH,2022, (1): 4770-4774,"Haodong Zhao, Wei Du, Junjie Guo, Gongshen Liu",https://doi.org/10.21437/Interspeech.2022-446,,Conference and Workshop Papers,
Triggerless Backdoor Attack for NLP Tasks with Clean Labels,NAACL-HLT,2022, (1): 2942-2952,"Leilei Gan, Jiwei Li, Tianwei Zhang, Xiaoya Li, Yuxian Meng, Fei Wu, Yi Yang, Shangwei Guo, Chun Fan",https://doi.org/10.18653/v1/2022.naacl-main.214,,Conference and Workshop Papers,
Expose Backdoors on the Way: A Feature-Based Efficient Defense against Textual Backdoor Attacks,EMNLP,2022, (1): 668-683,"Sishuo Chen, Wenkai Yang, Zhiyuan Zhang, Xiaohan Bi, Xu Sun",https://doi.org/10.18653/v1/2022.findings-emnlp.47,,Conference and Workshop Papers,
Fine-mixing: Mitigating Backdoors in Fine-tuned Language Models,EMNLP,2022, (1): 355-372,"Zhiyuan Zhang, Lingjuan Lyu, Xingjun Ma, Chenguang Wang, Xu Sun",https://doi.org/10.18653/v1/2022.findings-emnlp.26,,Conference and Workshop Papers,
Dim-Krum: Backdoor-Resistant Federated Learning for NLP with Dimension-wise Krum-Based Aggregation,EMNLP,2022, (1): 339-354,"Zhiyuan Zhang, Qi Su, Xu Sun",https://doi.org/10.18653/v1/2022.findings-emnlp.25,,Conference and Workshop Papers,
WeDef: Weakly Supervised Backdoor Defense for Text Classification,EMNLP,2022, (1): 11614-11626,"Lesheng Jin, Zihan Wang, Jingbo Shang",https://doi.org/10.18653/v1/2022.emnlp-main.798,,Conference and Workshop Papers,
Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks,EMNLP,2022, (1): 11215-11221,"Yangyi Chen, Fanchao Qi, Hongcheng Gao, Zhiyuan Liu, Maosong Sun",https://doi.org/10.18653/v1/2022.emnlp-main.770,,Conference and Workshop Papers,
Backdoor Attacks in Federated Learning by Rare Embeddings and Gradient Ensembling,EMNLP,2022, (1): 72-88,"KiYoon Yoo, Nojun Kwak",https://doi.org/10.18653/v1/2022.emnlp-main.6,,Conference and Workshop Papers,
On Probabilistic Generalization of Backdoors in Boolean Satisfiability,AAAI,2022, (1): 10353-10361,"Alexander A. Semenov, Artem Pavlenko, Daniil Chivilikhin, Stepan Kochemazov",https://doi.org/10.1609/aaai.v36i9.21277,,Conference and Workshop Papers,
Hibernated Backdoor: A Mutual Information Empowered Backdoor Attack to Deep Neural Networks,AAAI,2022, (1): 10309-10318,"Rui Ning, Jiang Li, Chunsheng Xin, Hongyi Wu, Chonggang Wang",https://doi.org/10.1609/aaai.v36i9.21272,,Conference and Workshop Papers,
Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks,AAAI,2022, (1): 9575-9583,"Jinyuan Jia, Yupei Liu, Xiaoyu Cao, Neil Zhenqiang Gong",https://doi.org/10.1609/aaai.v36i9.21191,,Conference and Workshop Papers,
Tractable Abstract Argumentation via Backdoor-Treewidth,AAAI,2022, (1): 5608-5615,"Wolfgang Dvorák, Markus Hecher, Matthias König, André Schidler, Stefan Szeider, Stefan Woltran",https://doi.org/10.1609/aaai.v36i5.20501,,Conference and Workshop Papers,
Finding Backdoors to Integer Programs: A Monte Carlo Tree Search Framework,AAAI,2022, (1): 3786-3795,"Elias B. Khalil, Pashootan Vaezipoor, Bistra Dilkina",https://doi.org/10.1609/aaai.v36i4.20293,,Conference and Workshop Papers,
Faster Algorithms for Weak Backdoors,AAAI,2022, (1): 3741-3748,"Serge Gaspers, Andrew Kaploun",https://doi.org/10.1609/aaai.v36i4.20288,,Conference and Workshop Papers,
Backdoor Attacks on the DNN Interpretation System,AAAI,2022, (1): 561-570,"Shihong Fang, Anna Choromanska",https://doi.org/10.1609/aaai.v36i1.19935,,Conference and Workshop Papers,
Multi-Model Selective Backdoor Attack with Different Trigger Positions,IEICE Trans. Inf. Syst.,2022,105-D (1): 170-174,Hyun Kwon,https://doi.org/10.1587/transinf.2021edl8054,,Journal Articles,
Experimental Study of Fault Injection Attack on Image Sensor Interface for Triggering Backdoored DNN Models,IEICE Trans. Fundam. Electron. Commun. Comput. Sci.,2022,105-A (3): 336-343,"Tatsuya Oyama, Shunsuke Okura, Kota Yoshida, Takeshi Fujino",https://doi.org/10.1587/transfun.2021cip0019,,Journal Articles,
Robust Federated Learning for Ubiquitous Computing through Mitigation of Edge-Case Backdoor Attacks,Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,2022,6 (4): 162:1-162:27,"Fatima Elhattab, Sara Bouchenak, Rania Talbi, Vlad Nitu",https://doi.org/10.1145/3569492,,Journal Articles,
More is Better (Mostly): On the Backdoor Attacks in Federated Graph Neural Networks,ACSAC,2022, (1): 684-698,"Jing Xu, Rui Wang, Stefanos Koffas, Kaitai Liang, Stjepan Picek",https://doi.org/10.1145/3564625.3567999,,Conference and Workshop Papers,
Make Data Reliable: An Explanation-powered Cleaning on Malware Dataset Against Backdoor Poisoning Attacks,ACSAC,2022, (1): 267-278,"Xutong Wang, Chaoge Liu, Xiaohui Hu, Zhi Wang, Jie Yin, Xiang Cui",https://doi.org/10.1145/3564625.3564661,,Conference and Workshop Papers,
Towards Backdoor Attacks against LiDAR Object Detection in Autonomous Driving,SenSys,2022, (1): 533-547,"Yan Zhang, Yi Zhu, Zihao Liu, Chenglin Miao, Foad Hajiaghajani, Lu Su, Chunming Qiao",https://doi.org/10.1145/3560905.3568539,,Conference and Workshop Papers,
Just Rotate it: Deploying Backdoor Attacks via Rotation Transformation,AISec@CCS,2022, (1): 91-102,"Tong Wu, Tianhao Wang, Vikash Sehwag, Saeed Mahloujifar, Prateek Mittal",https://doi.org/10.1145/3560830.3563730,,Conference and Workshop Papers,
Poster: Backdoor Attacks on Spiking NNs and Neuromorphic Datasets,CCS,2022, (1): 3315-3317,"Gorka Abad, Oguzhan Ersoy, Stjepan Picek, Víctor Julio Ramírez-Durán, Aitor Urbieta",https://doi.org/10.1145/3548606.3563532,,Conference and Workshop Papers,
Poster: Clean-label Backdoor Attack on Graph Neural Networks,CCS,2022, (1): 3491-3493,"Jing Xu, Stjepan Picek",https://doi.org/10.1145/3548606.3563531,,Conference and Workshop Papers,
Transferable Graph Backdoor Attack,RAID,2022, (1): 321-332,"Shuiqiao Yang, Bao Gia Doan, Paul Montague, Olivier Y. de Vel, Tamas Abraham, Seyit Camtepe, Damith C. Ranasinghe, Salil S. Kanhere",https://doi.org/10.1145/3545948.3545976,,Conference and Workshop Papers,
"A highly efficient, confidential, and continuous federated learning backdoor attack strategy",ICMLC,2022, (1): 18-27,"Jiarui Cao, Liehuang Zhu",https://doi.org/10.1145/3529836.3529845,,Conference and Workshop Papers,
Defending against Poisoning Backdoor Attacks on Federated Meta-learning,ACM Trans. Intell. Syst. Technol.,2022,13 (5): 76:1-76:25,"Chien-Lun Chen, Sara Babakniya, Marco Paolieri, Leana Golubchik",https://doi.org/10.1145/3523062,,Journal Articles,
Can You Hear It?: Backdoor Attacks via Ultrasonic Triggers,WiseML@WiSec,2022, (1): 57-62,"Stefanos Koffas, Jing Xu, Mauro Conti, Stjepan Picek",https://doi.org/10.1145/3522783.3529523,,Conference and Workshop Papers,
Backdoor Attacks on Crowd Counting,ACM Multimedia,2022, (1): 5351-5360,"Yuhua Sun, Tailai Zhang, Xingjun Ma, Pan Zhou, Jian Lou, Zichuan Xu, Xing Di, Yu Cheng, Lichao Sun",https://doi.org/10.1145/3503161.3548296,,Conference and Workshop Papers,
BadHash: Invisible Backdoor Attacks against Deep Hashing with Clean Label,ACM Multimedia,2022, (1): 678-686,"Shengshan Hu, Ziqi Zhou, Yechao Zhang, Leo Yu Zhang, Yifeng Zheng, Yuanyuan He, Hai Jin",https://doi.org/10.1145/3503161.3548272,,Conference and Workshop Papers,
Opportunistic Backdoor Attacks: Exploring Human-imperceptible Vulnerabilities on Speech Recognition Systems,ACM Multimedia,2022, (1): 2390-2398,"Qiang Liu, Tongqing Zhou, Zhiping Cai, Yonghao Tang",https://doi.org/10.1145/3503161.3548261,,Conference and Workshop Papers,
Physical Backdoor Attacks to Lane Detection Systems in Autonomous Driving,ACM Multimedia,2022, (1): 2957-2968,"Xingshuo Han, Guowen Xu, Yuan Zhou, Xuehuan Yang, Jiwei Li, Tianwei Zhang",https://doi.org/10.1145/3503161.3548171,,Conference and Workshop Papers,
Purifier: Plug-and-play Backdoor Mitigation for Pre-trained Models Via Anomaly Activation Suppression,ACM Multimedia,2022, (1): 4291-4299,"Xiaoyu Zhang, Yulin Jin, Tao Wang, Jian Lou, Xiaofeng Chen",https://doi.org/10.1145/3503161.3548065,,Conference and Workshop Papers,
Audio-domain position-independent backdoor attack via unnoticeable triggers,MobiCom,2022, (1): 583-595,"Cong Shi, Tianfang Zhang, Zhuohang Li, Huy Phan, Tianming Zhao, Yan Wang, Jian Liu, Bo Yuan, Yingying Chen",https://doi.org/10.1145/3495243.3560531,,Conference and Workshop Papers,
Extracting a Minimal Trigger for an Efficient Backdoor Poisoning Attack Using the Activation Values of a Deep Neural Network,WDC@AsiaCCS,2022, (1): 3-6,"Hyunsik Na, Daeseon Choi",https://doi.org/10.1145/3494109.3527192,,Conference and Workshop Papers,
On the Neural Backdoor of Federated Generative Models in Edge Computing,ACM Trans. Internet Techn.,2022,22 (2): 43:1-43:21,"Derui Wang, Sheng Wen, Alireza Jolfaei, Mohammad Sayad Haghighi, Surya Nepal, Yang Xiang",https://doi.org/10.1145/3425662,,Journal Articles,
Clean-label Backdoor Attack on Machine Learning-based Malware Detection Models and Countermeasures,TrustCom,2022, (1): 1235-1242,"Wanjia Zheng, Kazumasa Omote",https://doi.org/10.1109/TrustCom56396.2022.00171,,Conference and Workshop Papers,
A General Backdoor Attack to Graph Neural Networks Based on Explanation Method,TrustCom,2022, (1): 759-768,"Luyao Chen, Na Yan, Boyang Zhang, Zhaoyang Wang, Yu Wen, Yanfei Hu",https://doi.org/10.1109/TrustCom56396.2022.00107,,Conference and Workshop Papers,
Backdoor Attacks Against Transfer Learning With Pre-Trained Deep Learning Models,IEEE Trans. Serv. Comput.,2022,15 (3): 1526-1539,"Shuo Wang, Surya Nepal, Carsten Rudolph, Marthie Grobler, Shangyu Chen, Tianle Chen",https://doi.org/10.1109/TSC.2020.3000900,,Journal Articles,
Model Agnostic Defence Against Backdoor Attacks in Machine Learning,IEEE Trans. Reliab.,2022,71 (2): 880-895,"Sakshi Udeshi, Shanshan Peng, Gerald Woo, Lionell Loh, Louth Rawshan, Sudipta Chattopadhyay",https://doi.org/10.1109/TR.2022.3159784,,Journal Articles,
Detection of Backdoors in Trained Classifiers Without Access to the Training Set,IEEE Trans. Neural Networks Learn. Syst.,2022,33 (3): 1177-1191,"Zhen Xiang, David J. Miller, George Kesidis",https://doi.org/10.1109/TNNLS.2020.3041202,,Journal Articles,
Poison Ink: Robust and Invisible Backdoor Attack,IEEE Trans. Image Process.,2022,31 (1): 5691-5705,"Jie Zhang, Dongdong Chen, Qidong Huang, Jing Liao, Weiming Zhang, Huamin Feng, Gang Hua, Nenghai Yu",https://doi.org/10.1109/TIP.2022.3201472,,Journal Articles,
Mitigating the Backdoor Attack by Federated Filters for Industrial IoT Applications,IEEE Trans. Ind. Informatics,2022,18 (5): 3562-3571,"Boyu Hou, Jiqiang Gao, Xiaojie Guo, Thar Baker, Ying Zhang, Yanlong Wen, Zheli Liu",https://doi.org/10.1109/TII.2021.3112100,,Journal Articles,
Dispersed Pixel Perturbation-Based Imperceptible Backdoor Trigger for Image Classifier Models,IEEE Trans. Inf. Forensics Secur.,2022,17 (1): 3091-3106,"Yulong Wang, Minghui Zhao, Shenghong Li, Xin Yuan, Wei Ni",https://doi.org/10.1109/TIFS.2022.3202687,,Journal Articles,
LinkBreaker: Breaking the Backdoor-Trigger Link in DNNs via Neurons Consistency Check,IEEE Trans. Inf. Forensics Secur.,2022,17 (1): 2000-2014,"Zhenzhu Chen, Shang Wang, Anmin Fu, Yansong Gao, Shui Yu, Robert H. Deng",https://doi.org/10.1109/TIFS.2022.3175616,,Journal Articles,
Stealthy Backdoors as Compression Artifacts,IEEE Trans. Inf. Forensics Secur.,2022,17 (1): 1372-1387,"Yulong Tian, Fnu Suya, Fengyuan Xu, David Evans",https://doi.org/10.1109/TIFS.2022.3160359,,Journal Articles,
Backdoor Attack on Machine Learning Based Android Malware Detectors,IEEE Trans. Dependable Secur. Comput.,2022,19 (5): 3357-3370,"Chaoran Li, Xiao Chen, Derui Wang, Sheng Wen, Muhammad Ejaz Ahmed, Seyit Camtepe, Yang Xiang",https://doi.org/10.1109/TDSC.2021.3094824,,Journal Articles,
One-to-N &amp; N-to-One: Two Advanced Backdoor Attacks Against Deep Learning Models,IEEE Trans. Dependable Secur. Comput.,2022,19 (3): 1562-1578,"Mingfu Xue, Can He, Jian Wang, Weiqiang Liu",https://doi.org/10.1109/TDSC.2020.3028448,,Journal Articles,
Backdoor Federated Learning-Based mmWave Beam Selection,IEEE Trans. Commun.,2022,70 (10): 6563-6578,"Zhengming Zhang, Ruming Yang, Xiangyu Zhang, Chunguo Li, Yongming Huang, Luxi Yang",https://doi.org/10.1109/TCOMM.2022.3200111,,Journal Articles,
Interpretability-Guided Defense Against Backdoor Attacks to Deep Neural Networks,IEEE Trans. Comput. Aided Des. Integr. Circuits Syst.,2022,41 (8): 2611-2624,"Wei Jiang, Xiangyu Wen, Jinyu Zhan, Xupeng Wang, Ziwei Song",https://doi.org/10.1109/TCAD.2021.3111123,,Journal Articles,
A Novel Backdoor Attack Adapted to Transfer Learning,SmartWorld/UIC/ScalCom/DigitalTwin/PriComp/Meta,2022, (1): 1730-1735,"Peihao Li, Jie Huang, Shuaishuai Zhang, Chunyang Qi, Chuang Liang, Yang Peng",https://doi.org/10.1109/SmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00246,,Conference and Workshop Papers,
Energy-Based Learning for Polluted Outlier Detection in Backdoor,SmartCloud,2022, (1): 47-52,"Xiangyu Gao, Meikang Qiu",https://doi.org/10.1109/SmartCloud55982.2022.00014,,Conference and Workshop Papers,
Never Too Late: Tracing and Mitigating Backdoor Attacks in Federated Learning,SRDS,2022, (1): 69-81,"Hui Zeng, Tongqing Zhou, Xinyi Wu, Zhiping Cai",https://doi.org/10.1109/SRDS55811.2022.00017,,Conference and Workshop Papers,
BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning,SP,2022, (1): 2043-2059,"Jinyuan Jia, Yupei Liu, Neil Zhenqiang Gong",https://doi.org/10.1109/SP46214.2022.9833644,,Conference and Workshop Papers,
Piccolo: Exposing Complex Backdoors in NLP Transformer Models,SP,2022, (1): 2025-2042,"Yingqi Liu, Guangyu Shen, Guanhong Tao, Shengwei An, Shiqing Ma, Xiangyu Zhang",https://doi.org/10.1109/SP46214.2022.9833579,,Conference and Workshop Papers,
Inconspicuous Data Augmentation Based Backdoor Attack on Deep Neural Networks,SOCC,2022, (1): 1-6,"Chaohui Xu, Wenye Liu, Yue Zheng, Si Wang, Chip-Hong Chang",https://doi.org/10.1109/SOCC56010.2022.9908113,,Conference and Workshop Papers,
Assisting Backdoor Federated Learning with Whole Population Knowledge Alignment in Mobile Edge Computing,SECON,2022, (1): 416-424,"Tian Liu, Xueyang Hu, Tao Shu",https://doi.org/10.1109/SECON55815.2022.9918550,,Conference and Workshop Papers,
Un-Fair Trojan: Targeted Backdoor Attacks Against Model Fairness,SDS,2022, (1): 1-9,"Nicholas Furth, Abdallah Khreishah, Guanxiong Liu, NhatHai Phan, Yaser Jararweh",https://doi.org/10.1109/SDS57574.2022.10062890,,Conference and Workshop Papers,
A Survey on Backdoor Attack and Defense in Natural Language Processing,QRS,2022, (1): 809-820,"Xuan Sheng, Zhaoyang Han, Piji Li, Xiangmao Chang",https://doi.org/10.1109/QRS57517.2022.00086,,Conference and Workshop Papers,
Distributed Swift and Stealthy Backdoor Attack on Federated Learning,NAS,2022, (1): 1-8,"Agnideven Palanisamy Sundar, Feng Li, Xukai Zou, Tianchong Gao",https://doi.org/10.1109/NAS55553.2022.9925353,,Conference and Workshop Papers,
Are Backdoor Mandates Ethical? - A Position Paper,IEEE Technol. Soc. Mag.,2022,41 (4): 63-70,"Raphaël Khoury, Sylvain Hallé",https://doi.org/10.1109/MTS.2022.3217699,,Journal Articles,
Breaking Distributed Backdoor Defenses for Federated Learning in Non-IID Settings,MSN,2022, (1): 347-354,"Jijia Yang, Jiangang Shu, Xiaohua Jia",https://doi.org/10.1109/MSN57253.2022.00064,,Conference and Workshop Papers,
Backdoors Against Natural Language Processing: A Review,IEEE Secur. Priv.,2022,20 (5): 50-59,"Shaofeng Li, Tian Dong, Benjamin Zi Hao Zhao, Minhui Xue, Suguo Du, Haojin Zhu",https://doi.org/10.1109/MSEC.2022.3181001,,Journal Articles,
Coordinated Backdoor Attacks against Federated Learning with Model-Dependent Triggers,IEEE Netw.,2022,36 (1): 84-90,"Xueluan Gong, Yanjiao Chen, Huayang Huang, Yuqing Liao, Shuai Wang, Qian Wang",https://doi.org/10.1109/MNET.011.2000783,,Journal Articles,
I Know Your Triggers: Defending Against Textual Backdoor Attacks with Benign Backdoor Augmentation,MILCOM,2022, (1): 442-449,"Yue Gao, Jack W. Stokes, Manoj Ajith Prasad, Andrew T. Marshall, Kassem Fawaz, Emre Kiciman",https://doi.org/10.1109/MILCOM55135.2022.10017466,,Conference and Workshop Papers,
An Improved Method for Making CNN Immune to Backdoor Attack by Activating Clustering,ISCSIC,2022, (1): 1-6,"Yuang Zhou, Yichen Lei, Limin Yu, Xianyao Li, Dingding Chen, Tongpo Zhang",https://doi.org/10.1109/ISCSIC57216.2022.00012,,Conference and Workshop Papers,
Backdoor Defense with Machine Unlearning,INFOCOM,2022, (1): 280-289,"Yang Liu, Mingyuan Fan, Cen Chen, Ximeng Liu, Zhuo Ma, Li Wang, Jianfeng Ma",https://doi.org/10.1109/INFOCOM48880.2022.9796974,,Conference and Workshop Papers,
TrojanFlow: A Neural Backdoor Attack to Deep Learning-based Network Traffic Classifiers,INFOCOM,2022, (1): 1429-1438,"Rui Ning, Chunsheng Xin, Hongyi Wu",https://doi.org/10.1109/INFOCOM48880.2022.9796878,,Conference and Workshop Papers,
Latent Space-Based Backdoor Attacks Against Deep Neural Networks,IJCNN,2022, (1): 1-10,"Adrian Kristanto, Shuo Wang, Carsten Rudolph",https://doi.org/10.1109/IJCNN55064.2022.9892842,,Conference and Workshop Papers,
ACTSS: Input Detection Defense against Backdoor Attacks via Activation Subset Scanning,IJCNN,2022, (1): 1-8,"Yuexin Xuan, Xiaojun Chen, Zhendong Zhao, Yangyang Ding, Jianming Lv",https://doi.org/10.1109/IJCNN55064.2022.9891900,,Conference and Workshop Papers,
Detecting Backdoor Attacks on Deep Neural Networks Based on Model Parameters Analysis,ICTAI,2022, (1): 630-637,"Mingyuan Ma, Hu Li, Xiaohui Kuang",https://doi.org/10.1109/ICTAI56018.2022.00098,,Conference and Workshop Papers,
Backdoors in Neural Models of Source Code,ICPR,2022, (1): 2892-2899,"Goutham Ramakrishnan, Aws Albarghouthi",https://doi.org/10.1109/ICPR56361.2022.9956690,,Conference and Workshop Papers,
Backdoor Attacks against Deep Neural Networks by Personalized Audio Steganography,ICPR,2022, (1): 68-74,"Peng Liu, Shuyi Zhang, Chuanjian Yao, Wenzhe Ye, Xianxian Li",https://doi.org/10.1109/ICPR56361.2022.9956521,,Conference and Workshop Papers,
UltraBD: Backdoor Attack against Automatic Speaker Verification Systems via Adversarial Ultrasound,ICPADS,2022, (1): 193-200,"Junning Ze, Xinfeng Li, Yushi Cheng, Xiaoyu Ji, Wenyuan Xu",https://doi.org/10.1109/ICPADS56603.2022.00033,,Conference and Workshop Papers,
Unlabeled Backdoor Poisoning in Semi-Supervised Learning,ICME,2022, (1): 1-6,"Le Feng, Sheng Li, Zhenxing Qian, Xinpeng Zhang",https://doi.org/10.1109/ICME52920.2022.9859941,,Conference and Workshop Papers,
CRAB: Certified Patch Robustness Against Poisoning-Based Backdoor Attacks,ICIP,2022, (1): 2486-2490,"Huxiao Ji, Jie Li, Chentao Wu",https://doi.org/10.1109/ICIP46576.2022.9897387,,Conference and Workshop Papers,
Backdoor Poisoning of Encrypted Traffic Classifiers,ICDM,2022, (1): 577-585,"John T. Holodnak, Olivia M. Brown, Jason Matterer, Andrew Lemke",https://doi.org/10.1109/ICDMW58026.2022.00080,,Conference and Workshop Papers,
Data Leakage Attack via Backdoor Misclassification Triggers of Deep Learning Models,ICDIS,2022, (1): 61-66,"Xiangkai Yang, Wenjian Luo, Licai Zhang, Zhijian Chen, Jiahai Wang",https://doi.org/10.1109/ICDIS55630.2022.00017,,Conference and Workshop Papers,
Towards Backdoor Attack on Deep Learning based Time Series Classification,ICDE,2022, (1): 1274-1287,"Daizong Ding, Mi Zhang, Yuanmin Huang, Xudong Pan, Fuli Feng, Erling Jiang, Min Yang",https://doi.org/10.1109/ICDE53745.2022.00100,,Conference and Workshop Papers,
Toward Cleansing Backdoored Neural Networks in Federated Learning,ICDCS,2022, (1): 820-830,"Chen Wu, Xian Yang, Sencun Zhu, Prasenjit Mitra",https://doi.org/10.1109/ICDCS54860.2022.00084,,Conference and Workshop Papers,
Against Backdoor Attacks In Federated Learning With Differential Privacy,ICASSP,2022, (1): 2999-3003,"Lu Miao, Wei Yang, Rong Hu, Lu Li, Liusheng Huang",https://doi.org/10.1109/ICASSP43922.2022.9747653,,Conference and Workshop Papers,
Invisible and Efficient Backdoor Attacks for Compressed Deep Neural Networks,ICASSP,2022, (1): 96-100,"Huy Phan, Yi Xie, Jian Liu, Yingying Chen, Bo Yuan",https://doi.org/10.1109/ICASSP43922.2022.9747582,,Conference and Workshop Papers,
Detecting Backdoor Attacks against Point Cloud Classifiers,ICASSP,2022, (1): 3159-3163,"Zhen Xiang, David J. Miller, Siheng Chen, Xi Li, George Kesidis",https://doi.org/10.1109/ICASSP43922.2022.9747194,,Conference and Workshop Papers,
Test-Time Detection of Backdoor Triggers for Poisoned Deep Neural Networks,ICASSP,2022, (1): 3333-3337,"Xi Li, Zhen Xiang, David J. Miller, George Kesidis",https://doi.org/10.1109/ICASSP43922.2022.9746573,,Conference and Workshop Papers,
Object-Oriented Backdoor Attack Against Image Captioning,ICASSP,2022, (1): 2864-2868,"Meiling Li, Nan Zhong, Xinpeng Zhang, Zhenxing Qian, Sheng Li",https://doi.org/10.1109/ICASSP43922.2022.9746440,,Conference and Workshop Papers,
When Does Backdoor Attack Succeed in Image Reconstruction? A Study of Heuristics vs. Bi-Level Solution,ICASSP,2022, (1): 4398-4402,"Vardaan Taneja, Pin-Yu Chen, Yuguang Yao, Sijia Liu",https://doi.org/10.1109/ICASSP43922.2022.9746433,,Conference and Workshop Papers,
Stealthy Backdoor Attack with Adversarial Training,ICASSP,2022, (1): 2969-2973,"Le Feng, Sheng Li, Zhenxing Qian, Xinpeng Zhang",https://doi.org/10.1109/ICASSP43922.2022.9746008,,Conference and Workshop Papers,
Propagable Backdoors over Blockchain-based Federated Learning via Sample-Specific Eclipse,GLOBECOM,2022, (1): 2579-2584,"Zheng Yang, Gaolei Li, Jun Wu, Wu Yang",https://doi.org/10.1109/GLOBECOM48099.2022.10001370,,Conference and Workshop Papers,
A Temporal-Pattern Backdoor Attack to Deep Reinforcement Learning,GLOBECOM,2022, (1): 2710-2715,"Yinbo Yu, Jiajia Liu, Shouqing Li, Kepu Huang, Xudong Feng",https://doi.org/10.1109/GLOBECOM48099.2022.10000751,,Conference and Workshop Papers,
Planting Undetectable Backdoors in Machine Learning Models : [Extended Abstract],FOCS,2022, (1): 931-942,"Shafi Goldwasser, Michael P. Kim, Vinod Vaikuntanathan, Or Zamir",https://doi.org/10.1109/FOCS54457.2022.00092,,Conference and Workshop Papers,
Dynamic Backdoor Attacks Against Machine Learning Models,EuroS&amp;P,2022, (1): 703-718,"Ahmed Salem, Rui Wen, Michael Backes, Shiqing Ma, Yang Zhang",https://doi.org/10.1109/EuroSP53844.2022.00049,,Conference and Workshop Papers,
"TrojanZoo: Towards Unified, Holistic, and Practical Evaluation of Neural Backdoors",EuroS&amp;P,2022, (1): 684-702,"Ren Pang, Zheng Zhang, Xiangshan Gao, Zhaohan Xi, Shouling Ji, Peng Cheng, Xiapu Luo, Ting Wang",https://doi.org/10.1109/EuroSP53844.2022.00048,,Conference and Workshop Papers,
TextBack: Watermarking Text Classifiers using Backdooring,DSD,2022, (1): 340-347,"Nandish Chattopadhyay, Rajan Kataria, Anupam Chattopadhyay",https://doi.org/10.1109/DSD57027.2022.00053,,Conference and Workshop Papers,
FIBA: Frequency-Injection based Backdoor Attack in Medical Image Analysis,CVPR,2022, (1): 20844-20853,"Yu Feng, Benteng Ma, Jing Zhang, Shanshan Zhao, Yong Xia, Dacheng Tao",https://doi.org/10.1109/CVPR52688.2022.02021,,Conference and Workshop Papers,
Dual-Key Multimodal Backdoors for Visual Question Answering,CVPR,2022, (1): 15354-15364,"Matthew Walmer, Karan Sikka, Indranil Sur, Abhinav Shrivastava, Susmit Jha",https://doi.org/10.1109/CVPR52688.2022.01494,,Conference and Workshop Papers,
DEFEAT: Deep Hidden Feature Backdoor Attacks by Imperceptible Perturbation and Latent Representation Constraints,CVPR,2022, (1): 15192-15201,"Zhendong Zhao, Xiaojun Chen, Yuexin Xuan, Ye Dong, Dakui Wang, Kaitai Liang",https://doi.org/10.1109/CVPR52688.2022.01478,,Conference and Workshop Papers,
Complex Backdoor Detection by Symmetric Feature Differencing,CVPR,2022, (1): 14983-14993,"Yingqi Liu, Guangyu Shen, Guanhong Tao, Zhenting Wang, Shiqing Ma, Xiangyu Zhang",https://doi.org/10.1109/CVPR52688.2022.01458,,Conference and Workshop Papers,
Better Trigger Inversion Optimization in Backdoor Scanning,CVPR,2022, (1): 13358-13368,"Guanhong Tao, Guangyu Shen, Yingqi Liu, Shengwei An, Qiuling Xu, Shiqing Ma, Pan Li, Xiangyu Zhang",https://doi.org/10.1109/CVPR52688.2022.01301,,Conference and Workshop Papers,
Few-shot Backdoor Defense Using Shapley Estimation,CVPR,2022, (1): 13348-13357,"Jiyang Guan, Zhuozhuo Tu, Ran He, Dacheng Tao",https://doi.org/10.1109/CVPR52688.2022.01300,,Conference and Workshop Papers,
Towards Practical Deployment-Stage Backdoor Attack on Deep Neural Networks,CVPR,2022, (1): 13337-13347,"Xiangyu Qi, Tinghao Xie, Ruizhe Pan, Jifeng Zhu, Yong Yang, Kai Bu",https://doi.org/10.1109/CVPR52688.2022.01299,,Conference and Workshop Papers,
Backdoor Attacks on Self-Supervised Learning,CVPR,2022, (1): 13327-13336,"Aniruddha Saha, Ajinkya Tejankar, Soroush Abbasi Koohpayegani, Hamed Pirsiavash",https://doi.org/10.1109/CVPR52688.2022.01298,,Conference and Workshop Papers,
Asynchronous Evolutionary Algorithm for Finding Backdoors in Boolean Satisfiability,CEC,2022, (1): 1-8,"Artem Pavlenko, Daniil Chivilikhin, Alexander A. Semenov",https://doi.org/10.1109/CEC55065.2022.9870262,,Conference and Workshop Papers,
A Federated Learning Backdoor Attack Defense,BigDataService,2022, (1): 143-148,"Jin Yan, Yingchi Mao, Hua Nie, Zijian Tu, Jianxin Huang",https://doi.org/10.1109/BigDataService55688.2022.00030,,Conference and Workshop Papers,
SentMod: Hidden Backdoor Attack on Unstructured Textual Data,BigDataSecurity/HPSC/IDS,2022, (1): 224-231,"Saquib Irtiza, Latifur Khan, Kevin W. Hamlen",https://doi.org/10.1109/BigDataSecurityHPSCIDS54978.2022.00050,,Conference and Workshop Papers,
Saisiyat Is Where It Is At! Insights Into Backdoors And Debiasing Of Cross Lingual Transformers For Named Entity Recognition,IEEE Big Data,2022, (1): 2940-2949,"Ricardo A. Calix, J. J. Ben-Joseph, Nina Lopatina, Ryan Ashley, Mona Gogia, George Sieniawski, Andrea Brennen",https://doi.org/10.1109/BigData55660.2022.10020403,,Conference and Workshop Papers,
Triggerability of Backdoor Attacks in Multi-Source Transfer Learning-based Intrusion Detection,BDCAT,2022, (1): 40-47,"Nour Alhussien, Ahmed Aleroud, Reza Rahaeimehr, Alexander Schwarzmann",https://doi.org/10.1109/BDCAT56447.2022.00013,,Conference and Workshop Papers,
Sample-Specific Backdoor based Active Intellectual Property Protection for Deep Neural Networks,AICAS,2022, (1): 316-319,"Yinghao Wu, Mingfu Xue, Dujuan Gu, Yushu Zhang, Weiqiang Liu",https://doi.org/10.1109/AICAS54282.2022.9869927,,Conference and Workshop Papers,
Dynamic Backdoors with Global Average Pooling,AICAS,2022, (1): 320-323,"Stefanos Koffas, Stjepan Picek, Mauro Conti",https://doi.org/10.1109/AICAS54282.2022.9869920,,Conference and Workshop Papers,
Backdoor Defence for Voice Print Recognition Model Based on Speech Enhancement and Weight Pruning,IEEE Access,2022,10 (1): 114016-114023,"Jiawei Zhu, Lin Chen, Dongwei Xu, Wenhong Zhao",https://doi.org/10.1109/ACCESS.2022.3217322,,Journal Articles,
A Feature-Based On-Line Detector to Remove Adversarial-Backdoors by Iterative Demarcation,IEEE Access,2022,10 (1): 5545-5558,"Hao Fu, Akshaj Kumar Veldanda, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami",https://doi.org/10.1109/ACCESS.2022.3141077,,Journal Articles,
Backdoor attacks-resilient aggregation based on Robust Filtering of Outliers in federated learning for image classification,Knowl. Based Syst.,2022,245 (1): 108588,"Nuria Rodríguez Barroso, Eugenio Martínez-Cámara, María Victoria Luzón, Francisco Herrera",https://doi.org/10.1016/j.knosys.2022.108588,,Journal Articles,
Robust backdoor injection with the capability of resisting network transfer,Inf. Sci.,2022,612 (1): 594-611,"Le Feng, Sheng Li, Zhenxing Qian, Xinpeng Zhang",https://doi.org/10.1016/j.ins.2022.08.123,,Journal Articles,
Backdoor-resistant identity-based proxy re-encryption for cloud-assisted wireless body area networks,Inf. Sci.,2022,604 (1): 80-96,"Yuyang Zhou, Liang Zhao, Yuqiao Jin, Fagen Li",https://doi.org/10.1016/j.ins.2022.05.007,,Journal Articles,
Susceptibility &amp; defense of satellite image-trained convolutional networks to backdoor attacks,Inf. Sci.,2022,603 (1): 244-261,"Ethan Brewer, Jason Lin, Daniel S. Miller Runfola",https://doi.org/10.1016/j.ins.2022.05.004,,Journal Articles,
Defense against backdoor attack in federated learning,Comput. Secur.,2022,121 (1): 102819,"Shiwei Lu, Ruihu Li, Wenbin Liu, Xuan Chen",https://doi.org/10.1016/j.cose.2022.102819,,Journal Articles,
Backdoor smoothing: Demystifying backdoor attacks on deep neural networks,Comput. Secur.,2022,120 (1): 102814,"Kathrin Grosse, Taesung Lee, Battista Biggio, Youngja Park, Michael Backes, Ian M. Molloy",https://doi.org/10.1016/j.cose.2022.102814,,Journal Articles,
The triggers that open the NLP model backdoors are hidden in the adversarial samples,Comput. Secur.,2022,118 (1): 102730,"Kun Shao, Yu Zhang, Junan Yang, Xiaoshuai Li, Hui Liu",https://doi.org/10.1016/j.cose.2022.102730,,Journal Articles,
PTB: Robust physical backdoor attacks against deep neural networks in real world,Comput. Secur.,2022,118 (1): 102726,"Mingfu Xue, Can He, Yinghao Wu, Shichang Sun, Yushu Zhang, Jian Wang, Weiqiang Liu",https://doi.org/10.1016/j.cose.2022.102726,,Journal Articles,
A collaborative deep learning microservice for backdoor defenses in Industrial IoT networks,Ad Hoc Networks,2022,124 (1): 102727,"Qin Liu, Liqiong Chen, Hongbo Jiang, Jie Wu, Tian Wang, Tao Peng, Guojun Wang",https://doi.org/10.1016/j.adhoc.2021.102727,,Journal Articles,
MP-BADNet+: Secure and effective backdoor attack detection and mitigation protocols among multi-participants in private DNNs,Peer-to-Peer Netw. Appl.,2022,15 (6): 2457-2473,"Congcong Chen, Lifei Wei, Lei Zhang, Ya Peng, Jianting Ning",https://doi.org/10.1007/s12083-022-01377-6,,Journal Articles,
VulnerGAN: a backdoor attack through vulnerability amplification against machine learning-based network intrusion detection systems,Sci. China Inf. Sci.,2022,65 (7): 1-19,"Guangrui Liu, Weizhe Zhang, Xinjie Li, Kaisheng Fan, Shui Yu",https://doi.org/10.1007/s11432-021-3455-1,,Journal Articles,
BlindNet backdoor: Attack on deep neural network using blind watermark,Multim. Tools Appl.,2022,81 (5): 6217-6234,"Hyun Kwon, Yongchul Kim",https://doi.org/10.1007/s11042-021-11135-0,,Journal Articles,
Active intellectual property protection for deep neural networks through stealthy backdoor and users&apos; identities authentication,Appl. Intell.,2022,52 (14): 16497-16511,"Mingfu Xue, Shichang Sun, Yushu Zhang, Jian Wang, Weiqiang Liu",https://doi.org/10.1007/s10489-022-03339-0,,Journal Articles,
A Generic Enhancer for Backdoor Attacks on Deep Neural Networks,ICONIP,2022, (1): 296-307,"Bilal Hussain Abbasi, Qi Zhong, Leo Yu Zhang, Shang Gao, Antonio Robles-Kelly, Robin Doss",https://doi.org/10.1007/978-981-99-1648-1_25,,Conference and Workshop Papers,
A Pragmatic Label-Specific Backdoor Attack,FCS,2022, (1): 149-162,"Yu Wang, Haomiao Yang, Jiasheng Li, Mengyu Ge",https://doi.org/10.1007/978-981-19-8445-7_10,,Conference and Workshop Papers,
Patch-Based Backdoors Detection and Mitigation with Feature Masking,SocialSec,2022, (1): 229-246,"Tao Wang, Xiaoyu Zhang, Yulin Jin, Chenyang Chen, Fei Zhu",https://doi.org/10.1007/978-981-19-7242-3_15,,Conference and Workshop Papers,
Image Watermarking Backdoor Attacks in CNN-Based Classification Tasks,ICPR Workshops,2022, (1): 3-16,"Giovanbattista Abbate, Irene Amerini, Roberto Caldelli",https://doi.org/10.1007/978-3-031-37745-7_1,,Conference and Workshop Papers,
Detecting and Mitigating Backdoor Attacks with Dynamic and Invisible Triggers,ICONIP,2022, (1): 216-227,"Zhibin Zheng, Zhongyun Hua, Leo Yu Zhang",https://doi.org/10.1007/978-3-031-30111-7_19,,Conference and Workshop Papers,
Efficient DNN Backdoor Detection Guided by Static Weight Analysis,Inscrypt,2022, (1): 408-428,"Qi Wang, Wenxin Li, Kang Yang, Yiru Zhao, Lei Zhao, Lina Wang",https://doi.org/10.1007/978-3-031-26553-2_22,,Conference and Workshop Papers,
COLLIDER: A Robust Training Framework for Backdoor Data,ACCV,2022, (1): 681-698,"Hadi M. Dolatabadi, Sarah M. Erfani, Christopher Leckie",https://doi.org/10.1007/978-3-031-26351-4_41,,Conference and Workshop Papers,
BadDet: Backdoor Attacks on Object Detection,ECCV Workshops,2022, (1): 396-412,"Shih-Han Chan, Yinpeng Dong, Jun Zhu, Xiaolu Zhang, Jun Zhou",https://doi.org/10.1007/978-3-031-25056-9_26,,Conference and Workshop Papers,
Big Brother Is Watching You: A Closer Look at Backdoor Construction,SPACE,2022, (1): 81-96,"Anubhab Baksi, Arghya Bhattacharjee, Jakub Breier, Takanori Isobe, Mridul Nandi",https://doi.org/10.1007/978-3-031-22829-2_5,,Conference and Workshop Papers,
Practical Backdoor Attack Against Speaker Recognition System,ISPEC,2022, (1): 468-484,"Yuxiao Luo, Jianwei Tai, Xiaoqi Jia, Shengzhi Zhang",https://doi.org/10.1007/978-3-031-21280-2_26,,Conference and Workshop Papers,
Natural Backdoor Attacks on Speech Recognition Models,ML4CS,2022, (1): 597-610,"Jinwen Xin, Xixiang Lyu, Jing Ma",https://doi.org/10.1007/978-3-031-20096-0_45,,Conference and Workshop Papers,
Data-Free Backdoor Removal Based on Channel Lipschitzness,ECCV,2022, (1): 175-191,"Runkai Zheng, Rongjun Tang, Jianze Li, Li Liu",https://doi.org/10.1007/978-3-031-20065-6_11,,Conference and Workshop Papers,
An Approach to Generation Triggers for Parrying Backdoor in Neural Networks,AGI,2022, (1): 304-314,Menisov Artem,https://doi.org/10.1007/978-3-031-19907-3_29,,Conference and Workshop Papers,
An Invisible Black-Box Backdoor Attack Through Frequency Domain,ECCV,2022, (1): 396-413,"Tong Wang, Yuan Yao, Feng Xu, Shengwei An, Hanghang Tong, Ting Wang",https://doi.org/10.1007/978-3-031-19778-9_23,,Conference and Workshop Papers,
RIBAC: Towards Robust and Imperceptible Backdoor Attack against Compact DNN,ECCV,2022, (1): 708-724,"Huy Phan, Cong Shi, Yi Xie, Tianfang Zhang, Zhuohang Li, Tianming Zhao, Jian Liu, Yan Wang, Yingying Chen, Bo Yuan",https://doi.org/10.1007/978-3-031-19772-7_41,,Conference and Workshop Papers,
Low-Poisoning Rate Invisible Backdoor Attack Based on Important Neurons,WASA,2022, (1): 375-383,"Xiugui Yang, Xiangyun Qian, Rui Zhang, Ning Huang, Hui Xia",https://doi.org/10.1007/978-3-031-19214-2_31,,Conference and Workshop Papers,
How to Backdoor (Classic) McEliece and How to Guard Against Backdoors,PQCrypto,2022, (1): 24-44,"Tobias Hemmert, Alexander May, Johannes Mittmann, Carl Richard Theodor Schneider",https://doi.org/10.1007/978-3-031-17234-2_2,,Conference and Workshop Papers,
The Devil Is in the GAN: Backdoor Attacks and Defenses in Deep Generative Models,ESORICS,2022, (1): 776-783,"Ambrish Rawat, Killian Levacher, Mathieu Sinn",https://doi.org/10.1007/978-3-031-17143-7_41,,Conference and Workshop Papers,
Kallima: A Clean-Label Framework for Textual Backdoor Attacks,ESORICS,2022, (1): 447-466,"Xiaoyi Chen, Yinpeng Dong, Zeyu Sun, Shengfang Zhai, Qingni Shen, Zhonghai Wu",https://doi.org/10.1007/978-3-031-17140-6_22,,Conference and Workshop Papers,
Backdoor Attack is a Devil in Federated GAN-Based Medical Image Synthesis,SASHIMI@MICCAI,2022, (1): 154-165,"Ruinan Jin, Xiaoxiao Li",https://doi.org/10.1007/978-3-031-16980-9_15,,Conference and Workshop Papers,
Verifying Neural Networks Against Backdoor Attacks,CAV,2022, (1): 171-192,"Long H. Pham, Jun Sun",https://doi.org/10.1007/978-3-031-13185-1_9,,Conference and Workshop Papers,
Energy-Based Learning for Preventing Backdoor Attack,KSEM,2022, (1): 706-721,"Xiangyu Gao, Meikang Qiu",https://doi.org/10.1007/978-3-031-10989-8_56,,Conference and Workshop Papers,
Combining Defences Against Data-Poisoning Based Backdoor Attacks on Neural Networks,DBSec,2022, (1): 28-47,"Andrea Milakovic, Rudolf Mayer",https://doi.org/10.1007/978-3-031-10684-2_3,,Conference and Workshop Papers,
Fooling a Face Recognition System with a Marker-Free Label-Consistent Backdoor Attack,ICIAP,2022, (1): 176-185,"Nino Cauli, Alessandro Ortis, Sebastiano Battiato",https://doi.org/10.1007/978-3-031-06430-2_15,,Conference and Workshop Papers,
Deep Learning Backdoors,Security and Artificial Intelligence,2022, (1): 313-334,"Shaofeng Li, Shiqing Ma, Minhui Xue, Benjamin Zi Hao Zhao",https://doi.org/10.1007/978-3-030-98795-4_13,,Parts in Books or Collections,
A multitarget backdooring attack on deep neural networks with random location trigger,Int. J. Intell. Syst.,2022,37 (3): 2567-2583,"Xiao Yu, Liu Cong, Mingwen Zheng, Yajie Wang, Xinrui Liu, Song Shuxiao, Ma Yuexuan, Zheng Jun",https://doi.org/10.1002/int.22785,,Journal Articles,
An anomaly detection approach for backdoored neural networks: face recognition as a case study,BIOSIG,2022, (1): 80-88,"Alexander Unnervik, Sébastien Marcel",https://dl.gi.de/handle/20.500.12116/39718,,Conference and Workshop Papers,
Deletion-Backdoors for Argumentation Frameworks with Collective Attacks,SAFA@COMMA,2022, (1): 98-110,"Wolfgang Dvorák, Matthias König, Stefan Woltran",https://ceur-ws.org/Vol-3236/paper8.pdf,,Conference and Workshop Papers,
Check Your Other Door! Creating Backdoor Attacks in the Frequency Domain,BMVC,2022, (1): 259,"Hasan Abed Al Kader Hammoud, Bernard Ghanem",https://bmvc2022.mpi-inf.mpg.de/259/,,Conference and Workshop Papers,
Label-Smoothed Backdoor Attack,arXiv/CoRR,2022,abs/2202.11203 (1): 1,"Minlong Peng, Zidi Xiong, Mingming Sun, Ping Li",https://arxiv.org/abs/2202.11203,,Informal and Other Publications,
Backdoor Defense in Federated Learning Using Differential Testing and Outlier Detection,arXiv/CoRR,2022,abs/2202.11196 (1): 1,"Yein Kim, Huili Chen, Farinaz Koushanfar",https://arxiv.org/abs/2202.11196,,Informal and Other Publications,
On the Effectiveness of Adversarial Training against Backdoor Attacks,arXiv/CoRR,2022,abs/2202.10627 (1): 1,"Yinghua Gao, Dongxian Wu, Jingfeng Zhang, Guanhao Gan, Shu-Tao Xia, Gang Niu, Masashi Sugiyama",https://arxiv.org/abs/2202.10627,,Informal and Other Publications,
Resurrecting Trust in Facial Recognition: Mitigating Backdoor Attacks in Face Recognition to Prevent Potential Privacy Breaches,arXiv/CoRR,2022,abs/2202.10320 (1): 1,"Reena Zelenkova, Jack Swallow, M. A. P. Chamikara, Dongxi Liu, Mohan Baruwal Chhetri, Seyit Camtepe, Marthie Grobler, Mahathir Almashor",https://arxiv.org/abs/2202.10320,,Informal and Other Publications,
Adversarial Fine-tuning for Backdoor Defense: Connect Adversarial Examples to Triggered Samples,arXiv/CoRR,2022,abs/2202.06312 (1): 1,"Bingxu Mu, Le Wang, Zhenxing Niu",https://arxiv.org/abs/2202.06312,,Informal and Other Publications,
False Memory Formation in Continual Learners Through Imperceptible Backdoor Trigger,arXiv/CoRR,2022,abs/2202.04479 (1): 1,"Muhammad Umer, Robi Polikar",https://arxiv.org/abs/2202.04479,,Informal and Other Publications,
ARIBA: Towards Accurate and Robust Identification of Backdoor Attacks in Federated Learning,arXiv/CoRR,2022,abs/2202.04311 (1): 1,"Yuxi Mi, Jihong Guan, Shuigeng Zhou",https://arxiv.org/abs/2202.04311,,Informal and Other Publications,
Backdoor Detection in Reinforcement Learning,arXiv/CoRR,2022,abs/2202.03609 (1): 1,"Junfeng Guo, Ang Li, Cong Liu",https://arxiv.org/abs/2202.03609,,Informal and Other Publications,
Imperceptible and Multi-channel Backdoor Attack against Deep Neural Networks,arXiv/CoRR,2022,abs/2201.13164 (1): 1,"Mingfu Xue, Shifeng Ni, Yinghao Wu, Yushu Zhang, Jian Wang, Weiqiang Liu",https://arxiv.org/abs/2201.13164,,Informal and Other Publications,
Backdoors Stuck At The Frontdoor: Multi-Agent Backdoor Attacks That Backfire,arXiv/CoRR,2022,abs/2201.12211 (1): 1,"Siddhartha Datta, Nigel Shadbolt",https://arxiv.org/abs/2201.12211,,Informal and Other Publications,
Hiding Behind Backdoors: Self-Obfuscation Against Generative Models,arXiv/CoRR,2022,abs/2201.09774 (1): 1,"Siddhartha Datta, Nigel Shadbolt",https://arxiv.org/abs/2201.09774,,Informal and Other Publications,
Dangerous Cloaking: Natural Trigger based Backdoor Attacks on Object Detectors in the Physical World,arXiv/CoRR,2022,abs/2201.08619 (1): 1,"Hua Ma, Yinshan Li, Yansong Gao, Alsharif Abuadbba, Zhi Zhang, Anmin Fu, Hyoungshick Kim, Said F. Al-Sarawi, Surya Nepal, Derek Abbott",https://arxiv.org/abs/2201.08619,,Informal and Other Publications,
Model Transferring Attacks to Backdoor HyperNetwork in Personalized Federated Learning,arXiv/CoRR,2022,abs/2201.07063 (1): 1,"Phung Lai, NhatHai Phan, Abdallah Khreishah, Issa Khalil, Xintao Wu",https://arxiv.org/abs/2201.07063,,Informal and Other Publications,
Neighboring Backdoor Attacks on Graph Convolutional Network,arXiv/CoRR,2022,abs/2201.06202 (1): 1,"Liang Chen, Qibiao Peng, Jintang Li, Yang Liu, Jiawei Chen, Yong Li, Zibin Zheng",https://arxiv.org/abs/2201.06202,,Informal and Other Publications,
RFLBAT: A Robust Federated Learning Algorithm against Backdoor Attack,arXiv/CoRR,2022,abs/2201.03772 (1): 1,"Yongkang Wang, Dihua Zhai, Yufeng Zhan, Yuanqing Xia",https://arxiv.org/abs/2201.03772,,Informal and Other Publications,
Rethink Stealthy Backdoor Attacks in Natural Language Processing,arXiv/CoRR,2022,abs/2201.02993 (1): 1,"Lingfeng Shen, Haiyun Jiang, Lemao Liu, Shuming Shi",https://arxiv.org/abs/2201.02993,,Informal and Other Publications,
Where to Attack: A Dynamic Locator Model for Backdoor Attack in Text Classifications,COLING,2022, (1): 984-993,"Heng-Yang Lu, Chenyou Fan, Jun Yang, Cong Hu, Wei Fang, Xiao-Jun Wu",https://aclanthology.org/2022.coling-1.82,,Conference and Workshop Papers,
Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class,NeurIPS,2022, (1): 1,"Khoa D. Doan, Yingjie Lao, Ping Li",http://papers.nips.cc/paper_files/paper/2022/hash/fa0126bb7ebad258bf4ffdbbac2dd787-Abstract-Conference.html,,Conference and Workshop Papers,
BadPrompt: Backdoor Attacks on Continuous Prompts,NeurIPS,2022, (1): 1,"Xiangrui Cai, Haidong Xu, Sihan Xu, Ying Zhang, Xiaojie Yuan",http://papers.nips.cc/paper_files/paper/2022/hash/f0722b58f02d7793acf7d328928f933a-Abstract-Conference.html,,Conference and Workshop Papers,
Training with More Confidence: Mitigating Injected and Natural Backdoors During Training,NeurIPS,2022, (1): 1,"Zhenting Wang, Hailun Ding, Juan Zhai, Shiqing Ma",http://papers.nips.cc/paper_files/paper/2022/hash/ec0c9ca85b4ea49c7ebfb503cf55f2ae-Abstract-Conference.html,,Conference and Workshop Papers,
Trap and Replace: Defending Backdoor Attacks by Trapping Them into an Easy-to-Replace Subnetwork,NeurIPS,2022, (1): 1,"Haotao Wang, Junyuan Hong, Aston Zhang, Jiayu Zhou, Zhangyang Wang",http://papers.nips.cc/paper_files/paper/2022/hash/ea06e6e9e80f1c3d382317fff67041ac-Abstract-Conference.html,,Conference and Workshop Papers,
Randomized Channel Shuffling: Minimal-Overhead Backdoor Attack Detection without Clean Datasets,NeurIPS,2022, (1): 1,"Ruisi Cai, Zhenyu Zhang, Tianlong Chen, Xiaohan Chen, Zhangyang Wang",http://papers.nips.cc/paper_files/paper/2022/hash/db1d5c63576587fc1d40d33a75190c71-Abstract-Conference.html,,Conference and Workshop Papers,
One-shot Neural Backdoor Erasing via Adversarial Weight Masking,NeurIPS,2022, (1): 1,"Shuwen Chai, Jinghui Chen",http://papers.nips.cc/paper_files/paper/2022/hash/8c0f7107ab85892ccf51f0a814957af1-Abstract-Conference.html,,Conference and Workshop Papers,
Finding Naturally Occurring Physical Backdoors in Image Datasets,NeurIPS,2022, (1): 1,"Emily Wenger, Roma Bhattacharjee, Arjun Nitin Bhagoji, Josephine Passananti, Emilio Andere, Heather Zheng, Ben Y. Zhao",http://papers.nips.cc/paper_files/paper/2022/hash/8af749935131cc8ea5dae4f6d8cdb304-Abstract-Datasets_and_Benchmarks.html,,Conference and Workshop Papers,
Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch,NeurIPS,2022, (1): 1,"Hossein Souri, Liam Fowl, Rama Chellappa, Micah Goldblum, Tom Goldstein",http://papers.nips.cc/paper_files/paper/2022/hash/79eec295a3cd5785e18c61383e7c996b-Abstract-Conference.html,,Conference and Workshop Papers,
Pre-activation Distributions Expose Backdoor Neurons,NeurIPS,2022, (1): 1,"Runkai Zheng, Rongjun Tang, Jianze Li, Li Liu",http://papers.nips.cc/paper_files/paper/2022/hash/76917808731dae9e6d62c2a7a6afb542-Abstract-Conference.html,,Conference and Workshop Papers,
Provable Defense against Backdoor Policies in Reinforcement Learning,NeurIPS,2022, (1): 1,"Shubham Kumar Bharti, Xuezhou Zhang, Adish Singla, Jerry Zhu",http://papers.nips.cc/paper_files/paper/2022/hash/5e67e6a814526079ad8505bf6d926fb6-Abstract-Conference.html,,Conference and Workshop Papers,
Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection,NeurIPS,2022, (1): 1,"Yiming Li, Yang Bai, Yong Jiang, Yong Yang, Shu-Tao Xia, Bo Li",http://papers.nips.cc/paper_files/paper/2022/hash/55bfedfd31489e5ae83c9ce8eec7b0e1-Abstract-Conference.html,,Conference and Workshop Papers,
BackdoorBench: A Comprehensive Benchmark of Backdoor Learning,NeurIPS,2022, (1): 1,"Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Chao Shen",http://papers.nips.cc/paper_files/paper/2022/hash/4491ea1c91aa2b22c373e5f1dfce234f-Abstract-Datasets_and_Benchmarks.html,,Conference and Workshop Papers,
Effective Backdoor Defense by Exploiting Sensitivity of Poisoned Samples,NeurIPS,2022, (1): 1,"Weixin Chen, Baoyuan Wu, Haoqian Wang",http://papers.nips.cc/paper_files/paper/2022/hash/3f9bbf77fbd858e5b6e39d39fe84ed2e-Abstract-Conference.html,,Conference and Workshop Papers,
Handcrafted Backdoors in Deep Neural Networks,NeurIPS,2022, (1): 1,"Sanghyun Hong, Nicholas Carlini, Alexey Kurakin",http://papers.nips.cc/paper_files/paper/2022/hash/3538a22cd3ceb8f009cc62b9e535c29f-Abstract-Conference.html,,Conference and Workshop Papers,
A Unified Evaluation of Textual Backdoor Learning: Frameworks and Benchmarks,NeurIPS,2022, (1): 1,"Ganqu Cui, Lifan Yuan, Bingxiang He, Yangyi Chen, Zhiyuan Liu, Maosong Sun",http://papers.nips.cc/paper_files/paper/2022/hash/2052b3e0617ecb2ce9474a6feaf422b3-Abstract-Datasets_and_Benchmarks.html,,Conference and Workshop Papers,
Moderate-fitting as a Natural Backdoor Defender for Pre-trained Language Models,NeurIPS,2022, (1): 1,"Biru Zhu, Yujia Qin, Ganqu Cui, Yangyi Chen, Weilin Zhao, Chong Fu, Yangdong Deng, Zhiyuan Liu, Jingang Wang, Wei Wu, Maosong Sun, Ming Gu",http://papers.nips.cc/paper_files/paper/2022/hash/0799492e7be38b66d10ead5e8809616d-Abstract-Conference.html,,Conference and Workshop Papers,
Graph Backdoor,USENIX Security Symposium,2021, (1): 1523-1540,"Zhaohan Xi, Ren Pang, Shouling Ji, Ting Wang",https://www.usenix.org/conference/usenixsecurity21/presentation/xi,,Conference and Workshop Papers,
Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection,USENIX Security Symposium,2021, (1): 1541-1558,"Di Tang, XiaoFeng Wang, Haixu Tang, Kehuan Zhang",https://www.usenix.org/conference/usenixsecurity21/presentation/tang-di,,Conference and Workshop Papers,
Explanation-Guided Backdoor Poisoning Attacks Against Malware Classifiers,USENIX Security Symposium,2021, (1): 1487-1504,"Giorgio Severi, Jim Meyer, Scott E. Coull, Alina Oprea",https://www.usenix.org/conference/usenixsecurity21/presentation/severi,,Conference and Workshop Papers,
Blind Backdoors in Deep Learning Models,USENIX Security Symposium,2021, (1): 1505-1521,"Eugene Bagdasaryan, Vitaly Shmatikov",https://www.usenix.org/conference/usenixsecurity21/presentation/bagdasaryan,,Conference and Workshop Papers,
Excess Capacity and Backdoor Poisoning,NeurIPS,2021, (1): 20373-20384,"Naren Manoj, Avrim Blum",https://proceedings.neurips.cc/paper/2021/hash/aaebdb8bb6b0e73f6c3c54a0ab0c6415-Abstract.html,,Conference and Workshop Papers,
Backdoor Attack with Imperceptible Input and Latent Modification,NeurIPS,2021, (1): 18944-18957,"Khoa D. Doan, Yingjie Lao, Ping Li",https://proceedings.neurips.cc/paper/2021/hash/9d99197e2ebf03fc388d09f1e94af89b-Abstract.html,,Conference and Workshop Papers,
Adversarial Neuron Pruning Purifies Backdoored Deep Models,NeurIPS,2021, (1): 16913-16925,"Dongxian Wu, Yisen Wang",https://proceedings.neurips.cc/paper/2021/hash/8cbe9ce23f42628c98f80fa0fac8b19a-Abstract.html,,Conference and Workshop Papers,
Anti-Backdoor Learning: Training Clean Models on Poisoned Data,NeurIPS,2021, (1): 14900-14912,"Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li, Xingjun Ma",https://proceedings.neurips.cc/paper/2021/hash/7d38b1e9bd793d3f45e0e212a729a93c-Abstract.html,,Conference and Workshop Papers,
WaNet - Imperceptible Warping-based Backdoor Attack,ICLR 2021 Poster,2021,,"Tuan Anh Nguyen, Anh Tuan Tran",https://openreview.net/pdf/db3277f5b47619abfe13880772b864960e98f643.pdf,,,[![github](/images/github_icon.svg) VinAIResearch/Warping-based_Backdoor_Attack-release](https://github.com/VinAIResearch/Warping-based_Backdoor_Attack-release)
BadNL: Backdoor Attacks Against NLP Models,ICML 2021 Workshop AML Poster,2021,,"Xiaoyi Chen, Ahmed Salem, Michael Backes, Shiqing Ma, Yang Zhang",https://openreview.net/pdf/cd42e8b674a13e8adb2af88c2edbc79a0a505235.pdf,,,
Fooling a Complete Neural Network Verifier,ICLR 2021 Poster,2021,,"Dániel Zombori, Balázs Bánhelyi, Tibor Csendes, István Megyeri, Márk Jelasity",https://openreview.net/pdf/77a36c9a49f48b9ddb12530a2f5dd127064dfae1.pdf,,,
Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching,ICLR 2021 Poster,2021,,"Jonas Geiping, Liam H Fowl, W. Ronny Huang, Wojciech Czaja, Gavin Taylor, Michael Moeller, Tom Goldstein",https://openreview.net/pdf/3a3c570da85848de52605f6669aae395d063027b.pdf,,,[![github](/images/github_icon.svg) JonasGeiping/poisoning-gradient-matching](https://github.com/JonasGeiping/poisoning-gradient-matching) + [![Papers with Code](/images/pwc_icon.svg) 1 community implementation](https://paperswithcode.com/paper/?openreview=01olnfLIbD)
Manipulating SGD with Data Ordering Attacks,NeurIPS 2021 Poster,2021,,"I Shumailov, Zakhar Shumaylov, Dmitry Kazhdan, Yiren Zhao, Nicolas Papernot, Murat A Erdogdu, Ross Anderson",https://openreview.net/pdf/38b5087efcece7a26b421cd3cd7e0a2a30c8096e.pdf,,,
Provably Efficient Causal Reinforcement Learning with Confounded Observational Data,NeurIPS 2021 Poster,2021,,"Lingxiao Wang, Zhuoran Yang, Zhaoran Wang",https://openreview.net/pdf/31505523e2732ba78bd7d563ea9be775dc246cba.pdf,,,
Backdoor Attack with Imperceptible Input and Latent Modification,NeurIPS 2021 Poster,2021,,"Khoa Doan, Yingjie Lao, Ping Li",https://openreview.net/pdf/24f28701a59039e99ed6fcaf1d797eaa35e67607.pdf,,,
WaNet - Imperceptible Warping-based Backdoor Attack,ICLR,2021, (1): 1,"Tuan Anh Nguyen, Anh Tuan Tran",https://openreview.net/forum?id=eEn8KTtJOx,,Conference and Workshop Papers,
Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks,ICLR,2021, (1): 1,"Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li, Xingjun Ma",https://openreview.net/forum?id=9l0K4OM-oXE,,Conference and Workshop Papers,
Backdoor Attacks Against Deep Learning Systems in the Physical World,CVPR,2021, (1): 6206-6215,"Emily Wenger, Josephine Passananti, Arjun Nitin Bhagoji, Yuanshun Yao, Haitao Zheng, Ben Y. Zhao",https://openaccess.thecvf.com/content/CVPR2021/html/Wenger_Backdoor_Attacks_Against_Deep_Learning_Systems_in_the_Physical_World_CVPR_2021_paper.html,,Conference and Workshop Papers,
How to Backdoor a Cipher,IACR Cryptol. ePrint Arch.,2021,2021 (1): 442,"Raluca Posteuca, Tomer Ashur",https://eprint.iacr.org/2021/442,,Informal and Other Publications,
Factoring Primes to Factor Moduli: Backdooring and Distributed Generation of Semiprimes,IACR Cryptol. ePrint Arch.,2021,2021 (1): 1610,Giuseppe Vitto,https://eprint.iacr.org/2021/1610,,Informal and Other Publications,
Recursive Backdoors for SAT,MFCS,2021, (1): 73:1-73:18,"Nikolas Mählmann, Sebastian Siebertz, Alexandre Vigny",https://doi.org/10.4230/LIPIcs.MFCS.2021.73,,Conference and Workshop Papers,
Reasoning Short Cuts in Infinite Domain Constraint Satisfaction: Algorithms and Lower Bounds for Backdoors,CP,2021, (1): 32:1-32:20,"Peter Jonsson, Victor Lagerkvist, Sebastian Ordyniak",https://doi.org/10.4230/LIPIcs.CP.2021.32,,Conference and Workshop Papers,
BACKDOORL: Backdoor Attack against Competitive Reinforcement Learning,IJCAI,2021, (1): 3699-3705,"Lun Wang, Zaynah Javed, Xian Wu, Wenbo Guo, Xinyu Xing, Dawn Song",https://doi.org/10.24963/ijcai.2021/509,,Conference and Workshop Papers,
Backdoor DNFs,IJCAI,2021, (1): 1403-1409,"Sebastian Ordyniak, André Schidler, Stefan Szeider",https://doi.org/10.24963/ijcai.2021/194,,Conference and Workshop Papers,
Pixdoor: A Pixel-space Backdoor Attack on Deep Learning Models,EUSIPCO,2021, (1): 681-685,"Iram Arshad, Mamoona Naveed Asghar, Yuansong Qiao, Brian Lee, Yuhang Ye",https://doi.org/10.23919/EUSIPCO54536.2021.9616118,,Conference and Workshop Papers,
BFClass: A Backdoor-free Text Classification Framework,EMNLP,2021, (1): 444-453,"Zichao Li, Dheeraj Mekala, Chengyu Dong, Jingbo Shang",https://doi.org/10.18653/v1/2021.findings-emnlp.40,,Conference and Workshop Papers,
ONION: A Simple and Effective Defense Against Textual Backdoor Attacks,EMNLP,2021, (1): 9558-9566,"Fanchao Qi, Yangyi Chen, Mukai Li, Yuan Yao, Zhiyuan Liu, Maosong Sun",https://doi.org/10.18653/v1/2021.emnlp-main.752,,Conference and Workshop Papers,
RAP: Robustness-Aware Perturbations for Defending against Backdoor Attacks on NLP Models,EMNLP,2021, (1): 8365-8381,"Wenkai Yang, Yankai Lin, Peng Li, Jie Zhou, Xu Sun",https://doi.org/10.18653/v1/2021.emnlp-main.659,,Conference and Workshop Papers,
Mind the Style of Text! Adversarial and Backdoor Attacks Based on Text Style Transfer,EMNLP,2021, (1): 4569-4580,"Fanchao Qi, Yangyi Chen, Xurui Zhang, Mukai Li, Zhiyuan Liu, Maosong Sun",https://doi.org/10.18653/v1/2021.emnlp-main.374,,Conference and Workshop Papers,
Backdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning,EMNLP,2021, (1): 3023-3032,"Linyang Li, Demin Song, Xiaonan Li, Jiehang Zeng, Ruotian Ma, Xipeng Qiu",https://doi.org/10.18653/v1/2021.emnlp-main.241,,Conference and Workshop Papers,
Rethinking Stealthiness of Backdoor Attack against NLP Models,ACL/IJCNLP,2021, (1): 5543-5557,"Wenkai Yang, Yankai Lin, Peng Li, Jie Zhou, Xu Sun",https://doi.org/10.18653/v1/2021.acl-long.431,,Conference and Workshop Papers,
Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution,ACL/IJCNLP,2021, (1): 4873-4883,"Fanchao Qi, Yuan Yao, Sophia Xu, Zhiyuan Liu, Maosong Sun",https://doi.org/10.18653/v1/2021.acl-long.377,,Conference and Workshop Papers,
Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger,ACL/IJCNLP,2021, (1): 443-453,"Fanchao Qi, Mukai Li, Yangyi Chen, Zhengyan Zhang, Zhiyuan Liu, Yasheng Wang, Maosong Sun",https://doi.org/10.18653/v1/2021.acl-long.37,,Conference and Workshop Papers,
Learning Pseudo-Backdoors for Mixed Integer Programs,SOCS,2021, (1): 170-172,"Aaron M. Ferber, Jialin Song, Bistra Dilkina, Yisong Yue",https://doi.org/10.1609/socs.v12i1.18573,,Conference and Workshop Papers,
Backdoor Decomposable Monotone Circuits and Propagation Complete Encodings,AAAI,2021, (1): 3832-3840,"Petr Kucera, Petr Savický",https://doi.org/10.1609/aaai.v35i5.16501,,Conference and Workshop Papers,
DeHiB: Deep Hidden Backdoor Attack on Semi-supervised Learning via Adversarial Perturbation,AAAI,2021, (1): 10585-10593,"Zhicong Yan, Gaolei Li, Yuan Tian, Jun Wu, Shenghong Li, Mingzhe Chen, H. Vincent Poor",https://doi.org/10.1609/aaai.v35i12.17266,,Conference and Workshop Papers,
Defending against Backdoors in Federated Learning with Robust Learning Rate,AAAI,2021, (1): 9268-9276,"Mustafa Safa Özdayi, Murat Kantarcioglu, Yulia R. Gel",https://doi.org/10.1609/aaai.v35i10.17118,,Conference and Workshop Papers,
Detecting Scene-Plausible Perceptible Backdoors in Trained DNNs Without Access to the Training Set,Neural Comput.,2021,33 (5): 1329-1371,"Zhen Xiang, David J. Miller, Hang Wang, George Kesidis",https://doi.org/10.1162/neco_a_01376,,Journal Articles,
PBDT: Python Backdoor Detection Model Based on Combined Features,Secur. Commun. Networks,2021,2021 (1): 9923234:1-9923234:13,"Yong Fang, Mingyu Xie, Cheng Huang",https://doi.org/10.1155/2021/9923234,,Journal Articles,
BadNL: Backdoor Attacks against NLP Models with Semantic-preserving Improvements,ACSAC,2021, (1): 554-569,"Xiaoyi Chen, Ahmed Salem, Dingfan Chen, Michael Backes, Shiqing Ma, Qingni Shen, Zhonghai Wu, Yang Zhang",https://doi.org/10.1145/3485832.3485837,,Conference and Workshop Papers,
A physically realizable backdoor attack on 3D point cloud deep learning: work-in-progress,CODES+ISSS,2021, (1): 27-28,"Chen Bian, Wei Jiang, Jinyu Zhan, Ziwei Song, Xiangyu Wen, Hong Lei",https://doi.org/10.1145/3478684.3479254,,Conference and Workshop Papers,
Generative strategy based backdoor attacks to 3D point clouds: work-in-progress,EMSOFT,2021, (1): 23-24,"Xiangyu Wen, Wei Jiang, Jinyu Zhan, Chen Bian, Ziwei Song",https://doi.org/10.1145/3477244.3477611,,Conference and Workshop Papers,
Backdoor Attack on Deep Neural Networks Triggered by Fault Injection Attack on Image Sensor Interface,ASHES@CCS,2021, (1): 63-72,"Tatsuya Oyama, Shunsuke Okura, Kota Yoshida, Takeshi Fujino",https://doi.org/10.1145/3474376.3487287,,Conference and Workshop Papers,
Anti-Distillation Backdoor Attacks: Backdoors Can Really Survive in Knowledge Distillation,ACM Multimedia,2021, (1): 826-834,"Yunjie Ge, Qian Wang, Baolin Zheng, Xinlu Zhuang, Qi Li, Chao Shen, Cong Wang",https://doi.org/10.1145/3474085.3475254,,Conference and Workshop Papers,
MP-BADNet: A Backdoor-Attack Detection and Identification Protocol among Multi-Participants in Private Deep Neural Networks,ACM TUR-C,2021, (1): 104-109,"Congcong Chen, Lifei Wei, Lei Zhang, Jianting Ning",https://doi.org/10.1145/3472634.3472660,,Conference and Workshop Papers,
Inaudible Manipulation of Voice-Enabled Devices Through BackDoor Using Robust Adversarial Audio Attacks: Invited Paper,WiseML@WiSec,2021, (1): 37-42,"Morriel Kasher, Michael Zhao, Aryeh Greenberg, Devin Gulati, Silvija Kokalj-Filipovic, Predrag Spasojevic",https://doi.org/10.1145/3468218.3469048,,Conference and Workshop Papers,
Explainability-based Backdoor Attacks Against Graph Neural Networks,WiseML@WiSec,2021, (1): 31-36,"Jing Xu, Minhui Xue, Stjepan Picek",https://doi.org/10.1145/3468218.3469046,,Conference and Workshop Papers,
AdvDoor: adversarial backdoor attack of deep learning system,ISSTA,2021, (1): 127-138,"Quan Zhang, Yifeng Ding, Yongqiang Tian, Jianmin Guo, Min Yuan, Yu Jiang",https://doi.org/10.1145/3460319.3464809,,Conference and Workshop Papers,
Backdoor Pre-trained Models Can Transfer to All,CCS,2021, (1): 3141-3158,"Lujia Shen, Shouling Ji, Xuhong Zhang, Jinfeng Li, Jing Chen, Jie Shi, Chengfang Fang, Jianwei Yin, Ting Wang",https://doi.org/10.1145/3460120.3485370,,Conference and Workshop Papers,
Hidden Backdoors in Human-Centric Language Models,CCS,2021, (1): 3123-3140,"Shaofeng Li, Hui Liu, Tian Dong, Benjamin Zi Hao Zhao, Minhui Xue, Haojin Zhu, Jialiang Lu",https://doi.org/10.1145/3460120.3484576,,Conference and Workshop Papers,
Backdoor Attacks to Graph Neural Networks,SACMAT,2021, (1): 15-26,"Zaixi Zhang, Jinyuan Jia, Binghui Wang, Neil Zhenqiang Gong",https://doi.org/10.1145/3450569.3463560,,Conference and Workshop Papers,
What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors,KDD,2021, (1): 1027-1035,"Yi-Shan Lin, Wen-Chuan Lee, Z. Berkay Celik",https://doi.org/10.1145/3447548.3467213,,Conference and Workshop Papers,
FederatedReverse: A Detection and Defense Method Against Backdoor Attacks in Federated Learning,IH&amp;MMSec,2021, (1): 51-62,"Chen Zhao, Yu Wen, Shuailou Li, Fucheng Liu, Dan Meng",https://doi.org/10.1145/3437880.3460403,,Conference and Workshop Papers,
On the Robustness of Backdoor-based Watermarking in Deep Neural Networks,IH&amp;MMSec,2021, (1): 177-188,"Masoumeh Shafieinejad, Nils Lukas, Jiaqi Wang, Xinda Li, Florian Kerschbaum",https://doi.org/10.1145/3437880.3460401,,Conference and Workshop Papers,
DeepSweep: An Evaluation Framework for Mitigating DNN Backdoor Attacks using Data Augmentation,AsiaCCS,2021, (1): 363-377,"Han Qiu, Yi Zeng, Shangwei Guo, Tianwei Zhang, Meikang Qiu, Bhavani Thuraisingham",https://doi.org/10.1145/3433210.3453108,,Conference and Workshop Papers,
The Design and Development of a Game to Study Backdoor Poisoning Attacks: The Backdoor Game,IUI,2021, (1): 423-433,"Zahra Ashktorab, Casey Dugan, James Johnson, Aabhas Sharma, Dustin Ramsey Torres, Ingrid Lange, Benjamin Hoover, Heiko Ludwig, Bryant Chen, Nathalie Baracaldo, Werner Geyer, Qian Pan",https://doi.org/10.1145/3397481.3450647,,Conference and Workshop Papers,
Robust Backdoor Attacks against Deep Neural Networks in Real Physical World,TrustCom,2021, (1): 620-626,"Mingfu Xue, Can He, Shichang Sun, Jian Wang, Weiqiang Liu",https://doi.org/10.1109/TrustCom53373.2021.00093,,Conference and Workshop Papers,
Deep Neural Backdoor in Semi-Supervised Learning: Threats and Countermeasures,IEEE Trans. Inf. Forensics Secur.,2021,16 (1): 4827-4842,"Zhicong Yan, Jun Wu, Gaolei Li, Shenghong Li, Mohsen Guizani",https://doi.org/10.1109/TIFS.2021.3116431,,Journal Articles,
Stop-and-Go: Exploring Backdoor Attacks on Deep Reinforcement Learning-Based Traffic Congestion Control Systems,IEEE Trans. Inf. Forensics Secur.,2021,16 (1): 4772-4787,"Yue Wang, Esha Sarkar, Wenqing Li, Michail Maniatakos, Saif Eddin Jabari",https://doi.org/10.1109/TIFS.2021.3114024,,Journal Articles,
Text Backdoor Detection Using an Interpretable RNN Abstract Model,IEEE Trans. Inf. Forensics Secur.,2021,16 (1): 4117-4132,"Ming Fan, Ziliang Si, Xiaofei Xie, Yang Liu, Ting Liu",https://doi.org/10.1109/TIFS.2021.3103064,,Journal Articles,
Invisible Backdoor Attacks on Deep Neural Networks Via Steganography and Regularization,IEEE Trans. Dependable Secur. Comput.,2021,18 (5): 2088-2105,"Shaofeng Li, Minhui Xue, Benjamin Zi Hao Zhao, Haojin Zhu, Xinpeng Zhang",https://doi.org/10.1109/TDSC.2020.3021407,,Journal Articles,
Bias Busters: Robustifying DL-Based Lithographic Hotspot Detectors Against Backdooring Attacks,IEEE Trans. Comput. Aided Des. Integr. Circuits Syst.,2021,40 (10): 2077-2089,"Kang Liu, Benjamin Tan, Gaurav Rajavendra Reddy, Siddharth Garg, Yiorgos Makris, Ramesh Karri",https://doi.org/10.1109/TCAD.2020.3033749,,Journal Articles,
Training Data Poisoning in ML-CAD: Backdooring DL-Based Lithographic Hotspot Detectors,IEEE Trans. Comput. Aided Des. Integr. Circuits Syst.,2021,40 (6): 1244-1257,"Kang Liu, Benjamin Tan, Ramesh Karri, Siddharth Garg",https://doi.org/10.1109/TCAD.2020.3024780,,Journal Articles,
Secure Federated Learning Model Verification: A Client-side Backdoor Triggered Watermarking Scheme,SMC,2021, (1): 2414-2419,"Xiyao Liu, Shuo Shao, Yue Yang, Kangming Wu, Wenyuan Yang, Hui Fang",https://doi.org/10.1109/SMC52423.2021.9658998,,Conference and Workshop Papers,
A Textual Clean-Label Backdoor Attack Strategy against Spam Detection,SIN,2021, (1): 1-8,"Fahri Anil Yerlikaya, Serif Bahtiyar",https://doi.org/10.1109/SIN54109.2021.9699173,,Conference and Workshop Papers,
Stability-Based Analysis and Defense against Backdoor Attacks on Edge Computing Services,IEEE Netw.,2021,35 (1): 163-169,"Yi Zhao, Ke Xu, Haiyang Wang, Bo Li, Ruoxi Jia",https://doi.org/10.1109/MNET.011.2000265,,Journal Articles,
Defense-Resistant Backdoor Attacks Against Deep Neural Networks in Outsourced Cloud Environment,IEEE J. Sel. Areas Commun.,2021,39 (8): 2617-2631,"Xueluan Gong, Yanjiao Chen, Qian Wang, Huayang Huang, Lingshuo Meng, Chao Shen, Qian Zhang",https://doi.org/10.1109/JSAC.2021.3087237,,Journal Articles,
BatFL: Backdoor Detection on Federated Learning in e-Health,IWQoS,2021, (1): 1-10,"Binhan Xi, Shaofeng Li, Jiachun Li, Hui Liu, Hong Liu, Haojin Zhu",https://doi.org/10.1109/IWQOS52092.2021.9521339,,Conference and Workshop Papers,
On-line Functional Testing of Memristor-mapped Deep Neural Networks using Backdoored Checksums,ITC,2021, (1): 83-92,"Ching-Yuan Chen, Krishnendu Chakrabarty",https://doi.org/10.1109/ITC50571.2021.00016,,Conference and Workshop Papers,
Invisible Poison: A Blackbox Clean Label Backdoor Attack to Deep Neural Networks,INFOCOM,2021, (1): 1-10,"Rui Ning, Jiang Li, Chunsheng Xin, Hongyi Wu",https://doi.org/10.1109/INFOCOM42981.2021.9488902,,Conference and Workshop Papers,
DeepPayload: Black-box Backdoor Attack on Deep Learning Models through Neural Payload Injection,ICSE,2021, (1): 263-274,"Yuanchun Li, Jiayi Hua, Haoyu Wang, Chunyang Chen, Yunxin Liu",https://doi.org/10.1109/ICSE43902.2021.00035,,Conference and Workshop Papers,
ROWBACK: RObust Watermarking for neural networks using BACKdoors,ICMLA,2021, (1): 1728-1735,"Nandish Chattopadhyay, Anupam Chattopadhyay",https://doi.org/10.1109/ICMLA52953.2021.00274,,Conference and Workshop Papers,
Identifying Physically Realizable Triggers for Backdoored Face Recognition Networks,ICIP,2021, (1): 3023-3027,"Ankita Raj, Ambar Pal, Chetan Arora",https://doi.org/10.1109/ICIP42928.2021.9506564,,Conference and Workshop Papers,
Simtrojan: Stealthy Backdoor Attack,ICIP,2021, (1): 819-823,"Yankun Ren, Longfei Li, Jun Zhou",https://doi.org/10.1109/ICIP42928.2021.9506313,,Conference and Workshop Papers,
BaFFLe: Backdoor Detection via Feedback-based Federated Learning,ICDCS,2021, (1): 852-863,"Sébastien Andreina, Giorgia Azzurra Marson, Helen Möllering, Ghassan Karame",https://doi.org/10.1109/ICDCS51616.2021.00086,,Conference and Workshop Papers,
PointBA: Towards Backdoor Attacks in 3D Point Cloud,ICCV,2021, (1): 16472-16481,"Xinke Li, Zhirui Chen, Yue Zhao, Zekun Tong, Yabang Zhao, Andrew Lim, Joey Tianyi Zhou",https://doi.org/10.1109/ICCV48922.2021.01618,,Conference and Workshop Papers,
Black-box Detection of Backdoor Attacks with Limited Information and Data,ICCV,2021, (1): 16462-16471,"Yinpeng Dong, Xiao Yang, Zhijie Deng, Tianyu Pang, Zihao Xiao, Hang Su, Jun Zhu",https://doi.org/10.1109/ICCV48922.2021.01617,,Conference and Workshop Papers,
Rethinking the Backdoor Attacks&apos; Triggers: A Frequency Perspective,ICCV,2021, (1): 16453-16461,"Yi Zeng, Won Park, Z. Morley Mao, Ruoxi Jia",https://doi.org/10.1109/ICCV48922.2021.01616,,Conference and Workshop Papers,
Invisible Backdoor Attack with Sample-Specific Triggers,ICCV,2021, (1): 16443-16452,"Yuezun Li, Yiming Li, Baoyuan Wu, Longkang Li, Ran He, Siwei Lyu",https://doi.org/10.1109/ICCV48922.2021.01615,,Conference and Workshop Papers,
CLEAR: Clean-up Sample-Targeted Backdoor in Neural Networks,ICCV,2021, (1): 16433-16442,"Liuwan Zhu, Rui Ning, Chunsheng Xin, Chonggang Wang, Hongyi Wu",https://doi.org/10.1109/ICCV48922.2021.01614,,Conference and Workshop Papers,
"LIRA: Learnable, Imperceptible and Robust Backdoor Attacks",ICCV,2021, (1): 11946-11956,"Khoa D. Doan, Yingjie Lao, Weijie Zhao, Ping Li",https://doi.org/10.1109/ICCV48922.2021.01175,,Conference and Workshop Papers,
A Backdoor Attack against 3D Point Cloud Classifiers,ICCV,2021, (1): 7577-7587,"Zhen Xiang, David J. Miller, Siheng Chen, Xi Li, George Kesidis",https://doi.org/10.1109/ICCV48922.2021.00750,,Conference and Workshop Papers,
Strong Data Augmentation Sanitizes Poisoning and Backdoor Attacks Without an Accuracy Tradeoff,ICASSP,2021, (1): 3855-3859,"Eitan Borgnia, Valeriia Cherepanova, Liam Fowl, Amin Ghiasi, Jonas Geiping, Micah Goldblum, Tom Goldstein, Arjun Gupta",https://doi.org/10.1109/ICASSP39728.2021.9414862,,Conference and Workshop Papers,
L-Red: Efficient Post-Training Detection of Imperceptible Backdoor Attacks Without Access to the Training Set,ICASSP,2021, (1): 3745-3749,"Zhen Xiang, David J. Miller, George Kesidis",https://doi.org/10.1109/ICASSP39728.2021.9414562,,Conference and Workshop Papers,
Backdoor Attack Against Speaker Verification,ICASSP,2021, (1): 2560-2564,"Tongqing Zhai, Yiming Li, Ziqi Zhang, Baoyuan Wu, Yong Jiang, Shu-Tao Xia",https://doi.org/10.1109/ICASSP39728.2021.9413468,,Conference and Workshop Papers,
Stand-in Backdoor: A Stealthy and Powerful Backdoor Attack,GLOBECOM,2021, (1): 1-6,"Shuang Li, Hongwei Li, Hanxiao Chen",https://doi.org/10.1109/GLOBECOM46510.2021.9685762,,Conference and Workshop Papers,
Backdoor Filter: Mitigating Visible Backdoor Triggers in Dataset,DTPI,2021, (1): 102-105,"Ziqi Wei, Junjian Shi, Yihe Duan, Ranyang Liu, Ye Han, Zheli Liu",https://doi.org/10.1109/DTPI52967.2021.9540109,,Conference and Workshop Papers,
Protecting Deep Cerebrospinal Fluid Cell Image Processing Models with Backdoor and Semi-Distillation,DICTA,2021, (1): 1-7,"Fang-Qi Li, Shi-Lin Wang, Zhen-Hai Wang",https://doi.org/10.1109/DICTA52665.2021.9647115,,Conference and Workshop Papers,
A Trigger Exploration Method for Backdoor Attacks on Deep Learning-Based Traffic Control Systems,CDC,2021, (1): 4394-4399,"Yue Wang, Michail Maniatakos, Saif Eddin Jabari",https://doi.org/10.1109/CDC45484.2021.9683577,,Conference and Workshop Papers,
A Synergetic Attack against Neural Network Classifiers combining Backdoor and Adversarial Examples,IEEE BigData,2021, (1): 834-846,"Guanxiong Liu, Issa Khalil, Abdallah Khreishah, NhatHai Phan",https://doi.org/10.1109/BigData52589.2021.9671964,,Conference and Workshop Papers,
Resisting Distributed Backdoor Attacks in Federated Learning: A Dynamic Norm Clipping Approach,IEEE BigData,2021, (1): 1172-1182,"Yifan Guo, Qianlong Wang, Tianxi Ji, Xufei Wang, Pan Li",https://doi.org/10.1109/BigData52589.2021.9671910,,Conference and Workshop Papers,
Covid-19 digital Contact-tracing: a doorway to well-being or a backdoor to security vulnerabilities?,IEEE BigData,2021, (1): 4297-4302,"Nishit Patel, David Cancel, Moitrayee Chatterjee, Md Shahinoor Rahman",https://doi.org/10.1109/BigData52589.2021.9671880,,Conference and Workshop Papers,
Use Procedural Noise to Achieve Backdoor Attack,IEEE Access,2021,9 (1): 127204-127216,"Xuan Chen, Yuena Ma, Shiwei Lu",https://doi.org/10.1109/ACCESS.2021.3110239,,Journal Articles,
A Master Key backdoor for universal impersonation attack against DNN-based face verification,Pattern Recognit. Lett.,2021,144 (1): 61-67,"Wei Guo, Benedetta Tondi, Mauro Barni",https://doi.org/10.1016/j.patrec.2021.01.009,,Journal Articles,
Mitigating backdoor attacks in LSTM-based text classification systems by Backdoor Keyword Identification,Neurocomputing,2021,452 (1): 253-262,"Chuanshuai Chen, Jiazhu Dai",https://doi.org/10.1016/j.neucom.2021.04.105,,Journal Articles,
Study of scale-free structures in feed-forward neural networks against backdoor attacks,ICT Express,2021,7 (2): 265-268,"Sara Kaviani, Insoo Sohn",https://doi.org/10.1016/j.icte.2020.11.004,,Journal Articles,
BDDR: An Effective Defense Against Textual Backdoor Attacks,Comput. Secur.,2021,110 (1): 102433,"Kun Shao, Junan Yang, Yang Ai, Hui Liu, Yu Zhang",https://doi.org/10.1016/j.cose.2021.102433,,Journal Articles,
Reverse engineering imperceptible backdoor attacks on deep neural networks for detection and training set cleansing,Comput. Secur.,2021,106 (1): 102280,"Zhen Xiang, David J. Miller, George Kesidis",https://doi.org/10.1016/j.cose.2021.102280,,Journal Articles,
Neural network laundering: Removing black-box backdoor watermarks from deep neural networks,Comput. Secur.,2021,106 (1): 102277,"William Aiken, Hyoungshick Kim, Simon S. Woo, Jungwoo Ryoo",https://doi.org/10.1016/j.cose.2021.102277,,Journal Articles,
Existence versus exploitation: the opacity of backdoors and backbones,Prog. Artif. Intell.,2021,10 (3): 297-308,"Lane A. Hemaspaandra, David E. Narváez",https://doi.org/10.1007/s13748-021-00234-6,,Journal Articles,
Backdoors hidden in facial features: a novel invisible backdoor attack against face recognition systems,Peer-to-Peer Netw. Appl.,2021,14 (3): 1458-1474,"Mingfu Xue, Can He, Jian Wang, Weiqiang Liu",https://doi.org/10.1007/s12083-020-01031-z,,Journal Articles,
Embedding asymmetric backdoors into the RSA key generator,J. Comput. Virol. Hacking Tech.,2021,17 (1): 37-46,Aleksandra V. Markelova,https://doi.org/10.1007/s11416-020-00363-x,,Journal Articles,
A Backdoor Embedding Method for Backdoor Detection in Deep Neural Networks,UbiSec,2021, (1): 1-12,"Meirong Liu, Hong Zheng, Qin Liu, Xiaofei Xing, Yinglong Dai",https://doi.org/10.1007/978-981-19-0468-4_1,,Conference and Workshop Papers,
A Random Multi-target Backdooring Attack on Deep Neural Networks,DMBD,2021, (1): 45-52,"Xinrui Liu, Xiao Yu, Zhibin Zhang, Quanxin Zhang, Yuanzhang Li, Yu-an Tan",https://doi.org/10.1007/978-981-16-7502-7_5,,Conference and Workshop Papers,
Backdoor Investigation and Incident Response: From Zero to Profit,ICDF2C,2021, (1): 229-247,"Anthony Cheuk Tung Lai, Ken Wai Kin Wong, Johnny Tsz Wun Wong, Austin Tsz Wai Lau, Alan Po Lun Ho, Shuai Wang, Jogesh Muppala",https://doi.org/10.1007/978-3-031-06365-7_14,,Conference and Workshop Papers,
Why is Your Trojan NOT Responding? A Quantitative Analysis of Failures in Backdoor Attacks of Neural Networks,ICA3PP,2021, (1): 754-771,"Xingbo Hu, Yibing Lan, Ruimin Gao, Guozhu Meng, Kai Chen",https://doi.org/10.1007/978-3-030-95391-1_47,,Conference and Workshop Papers,
Backdoor Attack of Graph Neural Networks Based on Subgraph Trigger,CollaborateCom,2021, (1): 276-296,"Yu Sheng, Rong Chen, Guanyu Cai, Li Kuang",https://doi.org/10.1007/978-3-030-92638-0_17,,Conference and Workshop Papers,
Countermeasures Against Backdoor Attacks Towards Malware Detectors,CANS,2021, (1): 295-314,"Shintaro Narisada, Yuki Matsumoto, Seira Hidano, Toshihiro Uchibayashi, Takuo Suganuma, Masahiro Hiji, Shinsaku Kiyomoto",https://doi.org/10.1007/978-3-030-92548-2_16,,Conference and Workshop Papers,
TridentShell: a Covert and Scalable Backdoor Injection Attack on Web Applications,ISC,2021, (1): 177-194,"Xiaobo Yu, Weizhi Meng, Lei Zhao, Yining Liu",https://doi.org/10.1007/978-3-030-91356-4_10,,Conference and Workshop Papers,
"Internet of Things backdoors: Resource management issues, security challenges, and detection methods",Trans. Emerg. Telecommun. Technol.,2021,32 (2): 1,"Soheil Hashemi, Mani Zarei",https://doi.org/10.1002/ett.4142,,Journal Articles,
Identifying and blocking the backdoors in Linux,RTA-CSIT,2021, (1): 193-197,"Enkli Ylli, Julian Fejzaj, Igli Tafa",https://ceur-ws.org/Vol-2872/short07.pdf,,Conference and Workshop Papers,
CatchBackdoor: Backdoor Testing by Critical Trojan Neural Path Identification via Differential Fuzzing,arXiv/CoRR,2021,abs/2112.13064 (1): 1,,https://arxiv.org/abs/2112.13064,,Withdrawn Items,
Defending Label Inference and Backdoor Attacks in Vertical Federated Learning,arXiv/CoRR,2021,abs/2112.05409 (1): 1,"Yang Liu, Zhihao Yi, Yan Kang, Yuanqin He, Wenhan Liu, Tianyuan Zou, Qiang Yang",https://arxiv.org/abs/2112.05409,,Informal and Other Publications,
Anomaly Localization in Model Gradients Under Backdoor Attacks Against Federated Learning,arXiv/CoRR,2021,abs/2111.14683 (1): 1,Zeki Bilgin,https://arxiv.org/abs/2111.14683,,Informal and Other Publications,
A General Framework for Defending Against Backdoor Attacks via Influence Graph,arXiv/CoRR,2021,abs/2111.14309 (1): 1,"Xiaofei Sun, Jiwei Li, Xiaoya Li, Ziyao Wang, Tianwei Zhang, Han Qiu, Fei Wu, Chun Fan",https://arxiv.org/abs/2111.14309,,Informal and Other Publications,
DBIA: Data-free Backdoor Injection Attack against Transformer Networks,arXiv/CoRR,2021,abs/2111.11870 (1): 1,"Peizhuo Lv, Hualong Ma, Jiachen Zhou, Ruigang Liang, Kai Chen, Shengzhi Zhang, Yunfei Yang",https://arxiv.org/abs/2111.11870,,Informal and Other Publications,
NTD: Non-Transferability Enabled Backdoor Detection,arXiv/CoRR,2021,abs/2111.11157 (1): 1,"Yinshan Li, Hua Ma, Zhi Zhang, Yansong Gao, Alsharif Abuadbba, Anmin Fu, Yifeng Zheng, Said F. Al-Sarawi, Derek Abbott",https://arxiv.org/abs/2111.11157,,Informal and Other Publications,
Backdoor Attack through Frequency Domain,arXiv/CoRR,2021,abs/2111.10991 (1): 1,"Tong Wang, Yuan Yao, Feng Xu, Shengwei An, Hanghang Tong, Ting Wang",https://arxiv.org/abs/2111.10991,,Informal and Other Publications,
An Overview of Backdoor Attacks Against Deep Neural Networks and Possible Defences,arXiv/CoRR,2021,abs/2111.08429 (1): 1,"Wei Guo, Benedetta Tondi, Mauro Barni",https://arxiv.org/abs/2111.08429,,Informal and Other Publications,
A Statistical Difference Reduction Method for Escaping Backdoor Detection,arXiv/CoRR,2021,abs/2111.05077 (1): 1,"Pengfei Xia, Hongjing Niu, Ziqiang Li, Bin Li",https://arxiv.org/abs/2111.05077,,Informal and Other Publications,
An Optimization Perspective on Realizing Backdoor Injection Attacks on Deep Neural Networks in Hardware,arXiv/CoRR,2021,abs/2110.07683 (1): 1,"M. Caner Tol, Saad Islam, Berk Sunar, Ziming Zhang",https://arxiv.org/abs/2110.07683,,Informal and Other Publications,
Widen The Backdoor To Let More Attackers In,arXiv/CoRR,2021,abs/2110.04571 (1): 1,"Siddhartha Datta, Giulio Lovisotto, Ivan Martinovic, Nigel Shadbolt",https://arxiv.org/abs/2110.04571,,Informal and Other Publications,
Backdoor Attacks on Federated Learning with Lottery Ticket Hypothesis,arXiv/CoRR,2021,abs/2109.10512 (1): 1,"Zeyuan Yin, Ye Yuan, Panfeng Guo, Pan Zhou",https://arxiv.org/abs/2109.10512,,Informal and Other Publications,
Clean-label Backdoor Attack against Deep Hashing based Retrieval,arXiv/CoRR,2021,abs/2109.08868 (1): 1,"Kuofeng Gao, Jiawang Bai, Bin Chen, Dongxian Wu, Shu-Tao Xia",https://arxiv.org/abs/2109.08868,,Informal and Other Publications,
Check Your Other Door! Establishing Backdoor Attacks in the Frequency Domain,arXiv/CoRR,2021,abs/2109.05507 (1): 1,"Hasan Abed Al Kader Hammoud, Bernard Ghanem",https://arxiv.org/abs/2109.05507,,Informal and Other Publications,
Backdoor Attack and Defense for Deep Regression,arXiv/CoRR,2021,abs/2109.02381 (1): 1,"Xi Li, George Kesidis, David J. Miller, Vladimir Lucic",https://arxiv.org/abs/2109.02381,,Informal and Other Publications,
Backdoor Attacks on Network Certification via Data Poisoning,arXiv/CoRR,2021,abs/2108.11299 (1): 1,"Tobias Lorenz, Marta Kwiatkowska, Mario Fritz",https://arxiv.org/abs/2108.11299,,Informal and Other Publications,
TRAPDOOR: Repurposing backdoors to detect dataset bias in machine learning-based genomic analysis,arXiv/CoRR,2021,abs/2108.10132 (1): 1,"Esha Sarkar, Michail Maniatakos",https://arxiv.org/abs/2108.10132,,Informal and Other Publications,
Quantization Backdoors to Deep Learning Models,arXiv/CoRR,2021,abs/2108.09187 (1): 1,"Hua Ma, Huming Qiu, Yansong Gao, Zhi Zhang, Alsharif Abuadbba, Anmin Fu, Said F. Al-Sarawi, Derek Abbott",https://arxiv.org/abs/2108.09187,,Informal and Other Publications,
The Devil is in the GAN: Defending Deep Generative Models Against Backdoor Attacks,arXiv/CoRR,2021,abs/2108.01644 (1): 1,"Ambrish Rawat, Killian Levacher, Mathieu Sinn",https://arxiv.org/abs/2108.01644,,Informal and Other Publications,
Can You Hear It? Backdoor Attacks via Ultrasonic Triggers,arXiv/CoRR,2021,abs/2107.14569 (1): 1,"Stefanos Koffas, Jing Xu, Mauro Conti, Stjepan Picek",https://arxiv.org/abs/2107.14569,,Informal and Other Publications,
Spinning Sequence-to-Sequence Models with Meta-Backdoors,arXiv/CoRR,2021,abs/2107.10443 (1): 1,,https://arxiv.org/abs/2107.10443,,Withdrawn Items,
Subnet Replacement: Deployment-stage backdoor attack against deep neural networks in gray-box setting,arXiv/CoRR,2021,abs/2107.07240 (1): 1,"Xiangyu Qi, Jifeng Zhu, Chulin Xie, Yong Yang",https://arxiv.org/abs/2107.07240,,Informal and Other Publications,
Machine Learning with Electronic Health Records is vulnerable to Backdoor Trigger Attacks,arXiv/CoRR,2021,abs/2106.07925 (1): 1,"Byunggill Joe, Akshay Mehra, Insik Shin, Jihun Hamm",https://arxiv.org/abs/2106.07925,,Informal and Other Publications,
Backdoor Learning Curves: Explaining Backdoor Poisoning Beyond Influence Functions,arXiv/CoRR,2021,abs/2106.07214 (1): 1,"Antonio Emanuele Cinà, Kathrin Grosse, Sebastiano Vascon, Ambra Demontis, Battista Biggio, Fabio Roli, Marcello Pelillo",https://arxiv.org/abs/2106.07214,,Informal and Other Publications,
Poisoning MorphNet for Clean-Label Backdoor Attack to Point Clouds,arXiv/CoRR,2021,abs/2105.04839 (1): 1,"Guiyu Tian, Wenhao Jiang, Wei Liu, Yadong Mu",https://arxiv.org/abs/2105.04839,,Informal and Other Publications,
SPECTRE: Defending Against Backdoor Attacks Using Robust Statistics,arXiv/CoRR,2021,abs/2104.11315 (1): 1,"Jonathan Hayase, Weihao Kong, Raghav Somani, Sewoong Oh",https://arxiv.org/abs/2104.11315,,Informal and Other Publications,
Backdoor Attack in the Physical World,arXiv/CoRR,2021,abs/2104.02361 (1): 1,"Yiming Li, Tongqing Zhai, Yong Jiang, Zhifeng Li, Shu-Tao Xia",https://arxiv.org/abs/2104.02361,,Informal and Other Publications,
RABA: A Robust Avatar Backdoor Attack on Deep Neural Network,arXiv/CoRR,2021,abs/2104.01026 (1): 1,"Ying He, Zhili Shen, Chang Xia, Jingyu Hua, Wei Tong, Sheng Zhong",https://arxiv.org/abs/2104.01026,,Informal and Other Publications,
TOP: Backdoor Detection in Neural Networks via Transferability of Perturbation,arXiv/CoRR,2021,abs/2103.10274 (1): 1,"Todd Huster, Emmanuel Ekwedike",https://arxiv.org/abs/2103.10274,,Informal and Other Publications,
EX-RAY: Distinguishing Injected Backdoor from Natural Features in Neural Networks by Examining Differential Feature Symmetry,arXiv/CoRR,2021,abs/2103.08820 (1): 1,"Yingqi Liu, Guangyu Shen, Guanhong Tao, Zhenting Wang, Shiqing Ma, Xiangyu Zhang",https://arxiv.org/abs/2103.08820,,Informal and Other Publications,
Hidden Backdoor Attack against Semantic Segmentation Models,arXiv/CoRR,2021,abs/2103.04038 (1): 1,"Yiming Li, Yanjie Li, Yalei Lv, Yong Jiang, Shu-Tao Xia",https://arxiv.org/abs/2103.04038,,Informal and Other Publications,
DP-InstaHide: Provably Defusing Poisoning and Backdoor Attacks with Differentially Private Data Augmentations,arXiv/CoRR,2021,abs/2103.02079 (1): 1,"Eitan Borgnia, Jonas Geiping, Valeriia Cherepanova, Liam Fowl, Arjun Gupta, Amin Ghiasi, Furong Huang, Micah Goldblum, Tom Goldstein",https://arxiv.org/abs/2103.02079,,Informal and Other Publications,
What Doesn&apos;t Kill You Makes You Robust(er): Adversarial Training against Poisons and Backdoors,arXiv/CoRR,2021,abs/2102.13624 (1): 1,"Jonas Geiping, Liam Fowl, Gowthami Somepalli, Micah Goldblum, Michael Moeller, Tom Goldstein",https://arxiv.org/abs/2102.13624,,Informal and Other Publications,
SAFELearning: Enable Backdoor Detectability In Federated Learning With Secure Aggregation,arXiv/CoRR,2021,abs/2102.02402 (1): 1,"Zhuosheng Zhang, Jiarui Li, Shucheng Yu, Christian Makaya",https://arxiv.org/abs/2102.02402,,Informal and Other Publications,
On Provable Backdoor Defense in Collaborative Learning,arXiv/CoRR,2021,abs/2101.08177 (1): 1,"Ximing Qiao, Yuhua Bai, Siping Hu, Ang Li, Yiran Chen, Hai Li",https://arxiv.org/abs/2101.08177,,Informal and Other Publications,
Red Alarm for Pre-trained Models: Universal Vulnerabilities by Neuron-Level Backdoor Attacks,arXiv/CoRR,2021,abs/2101.06969 (1): 1,"Zhengyan Zhang, Guangxuan Xiao, Yongwei Li, Tian Lv, Fanchao Qi, Zhiyuan Liu, Yasheng Wang, Xin Jiang, Maosong Sun",https://arxiv.org/abs/2101.06969,,Informal and Other Publications,
Explainability Matters: Backdoor Attacks on Medical Imaging,arXiv/CoRR,2021,abs/2101.00008 (1): 1,"Munachiso Nwadike, Takumi Miyawaki, Esha Sarkar, Michail Maniatakos, Farah Shamout",https://arxiv.org/abs/2101.00008,,Informal and Other Publications,
CRFL: Certifiably Robust Federated Learning against Backdoor Attacks,ICML,2021, (1): 11372-11382,"Chulin Xie, Minghao Chen, Pin-Yu Chen, Bo Li",http://proceedings.mlr.press/v139/xie21a.html,,Conference and Workshop Papers,
Backdoor Scanning for Deep Neural Networks through K-Arm Optimization,ICML,2021, (1): 9525-9536,"Guangyu Shen, Yingqi Liu, Guanhong Tao, Shengwei An, Qiuling Xu, Siyuan Cheng, Shiqing Ma, Xiangyu Zhang",http://proceedings.mlr.press/v139/shen21c.html,,Conference and Workshop Papers,
Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and Data Poisoning Attacks,ICML,2021, (1): 9389-9398,"Avi Schwarzschild, Micah Goldblum, Arjun Gupta, John P. Dickerson, Tom Goldstein",http://proceedings.mlr.press/v139/schwarzschild21a.html,,Conference and Workshop Papers,
Defense against backdoor attacks via robust covariance estimation,ICML,2021, (1): 4129-4139,"Jonathan Hayase, Weihao Kong, Raghav Somani, Sewoong Oh",http://proceedings.mlr.press/v139/hayase21a.html,,Conference and Workshop Papers,
"Attack of the Tails: Yes, You Really Can Backdoor Federated Learning",NeurIPS,2020, (1): 1,"Hongyi Wang, Kartik Sreenivasan, Shashank Rajput, Harit Vishwakarma, Saurabh Agarwal, Jy-yong Sohn, Kangwook Lee, Dimitris S. Papailiopoulos",https://proceedings.neurips.cc/paper/2020/hash/b8ffa41d4e492f0fad2f13e29e1762eb-Abstract.html,,Conference and Workshop Papers,
On the Trade-off between Adversarial and Backdoor Robustness,NeurIPS,2020, (1): 1,"Cheng-Hsin Weng, Yan-Ting Lee, Shan-Hung Wu",https://proceedings.neurips.cc/paper/2020/hash/8b4066554730ddfaa0266346bdc1b202-Abstract.html,,Conference and Workshop Papers,
Input-Aware Dynamic Backdoor Attack,NeurIPS,2020, (1): 1,"Tuan Anh Nguyen, Anh Tuan Tran",https://proceedings.neurips.cc/paper/2020/hash/234e691320c0ad5b45ee3c96d0d7b8f8-Abstract.html,,Conference and Workshop Papers,
On the Trade-off between Adversarial and Backdoor Robustness,NeurIPS 2020,2020,,"Cheng-Hsin Weng, Yan-Ting Lee, Shan-Hung (Brandon) Wu",https://openreview.nethttp://proceedings.neurips.cc/paper/2020/file/8b4066554730ddfaa0266346bdc1b202-Paper.pdf,,,
DBA: Distributed Backdoor Attacks against Federated Learning,ICLR,2020, (1): 1,"Chulin Xie, Keli Huang, Pin-Yu Chen, Bo Li",https://openreview.net/forum?id=rkgyS0VFvr,,Conference and Workshop Papers,
Robust anomaly detection and backdoor attack detection via differential privacy,ICLR,2020, (1): 1,"Min Du, Ruoxi Jia, Dawn Song",https://openreview.net/forum?id=SJx0q1rtvS,,Conference and Workshop Papers,
Clean-Label Backdoor Attacks on Video Recognition Models,CVPR,2020, (1): 14431-14440,"Shihao Zhao, Xingjun Ma, Xiang Zheng, James Bailey, Jingjing Chen, Yu-Gang Jiang",https://openaccess.thecvf.com/content_CVPR_2020/html/Zhao_Clean-Label_Backdoor_Attacks_on_Video_Recognition_Models_CVPR_2020_paper.html,,Conference and Workshop Papers,
Universal Litmus Patterns: Revealing Backdoor Attacks in CNNs,CVPR,2020, (1): 298-307,"Soheil Kolouri, Aniruddha Saha, Hamed Pirsiavash, Heiko Hoffmann",https://openaccess.thecvf.com/content_CVPR_2020/html/Kolouri_Universal_Litmus_Patterns_Revealing_Backdoor_Attacks_in_CNNs_CVPR_2020_paper.html,,Conference and Workshop Papers,
Systematic Evaluation of Backdoor Data Poisoning Attacks on Image Classifiers,CVPR Workshops,2020, (1): 3422-3431,"Loc Truong, Chace Jones, Brian Hutchinson, Andrew August, Brenda Praggastis, Robert Jasper, Nicole Nichols, Aaron Tuor",https://openaccess.thecvf.com/content_CVPRW_2020/html/w47/Truong_Systematic_Evaluation_of_Backdoor_Data_Poisoning_Attacks_on_Image_Classifiers_CVPRW_2020_paper.html,,Conference and Workshop Papers,
Backdoors into Two Occurrences,J. Satisf. Boolean Model. Comput.,2020,12 (1): 1-15,Jan Johannsen,https://doi.org/10.3233/sat-200125,,Journal Articles,
Hidden Trigger Backdoor Attacks,AAAI,2020, (1): 11957-11965,"Aniruddha Saha, Akshayvarun Subramanya, Hamed Pirsiavash",https://doi.org/10.1609/aaai.v34i07.6871,,Conference and Workshop Papers,
Multi-Targeted Backdoor: Indentifying Backdoor Attack for Multiple Deep Neural Networks,IEICE Trans. Inf. Syst.,2020,103-D (4): 883-887,"Hyun Kwon, Hyunsoo Yoon, Ki-Woong Park",https://doi.org/10.1587/transinf.2019EDL8170,,Journal Articles,
Trembling triggers: exploring the sensitivity of backdoors in DNN-based face recognition,EURASIP J. Inf. Secur.,2020,2020 (1): 12,"Cecilia Pasquini, Rainer Böhme",https://doi.org/10.1186/s13635-020-00104-z,,Journal Articles,
Disabling Backdoor and Identifying Poison Data by using Knowledge Distillation in Backdoor Attacks on Deep Neural Networks,AISec@CCS,2020, (1): 117-127,"Kota Yoshida, Takeshi Fujino",https://doi.org/10.1145/3411508.3421375,,Conference and Workshop Papers,
Detecting acoustic backdoor transmission of inaudible messages using deep learning,WiseML@WiSec,2020, (1): 80-85,"Silvija Kokalj-Filipovic, Morriel Kasher, Michael Zhao, Predrag Spasojevic",https://doi.org/10.1145/3395352.3402629,,Conference and Workshop Papers,
GangSweep: Sweep out Neural Backdoors by GAN,ACM Multimedia,2020, (1): 3173-3181,"Liuwan Zhu, Rui Ning, Cong Wang, Chunsheng Xin, Hongyi Wu",https://doi.org/10.1145/3394171.3413546,,Conference and Workshop Papers,
Embedding Backdoors as the Facial Features: Invisible Backdoor Attacks Against Face Recognition Systems,ACM TUR-C,2020, (1): 231-235,"Can He, Mingfu Xue, Jian Wang, Weiqiang Liu",https://doi.org/10.1145/3393527.3393567,,Conference and Workshop Papers,
TargetNet Backdoor: Attack on Deep Neural Network with Use of Different Triggers,ICIIT,2020, (1): 140-145,"Hyun Kwon, Jungmin Roh, Hyunsoo Yoon, Ki-Woong Park",https://doi.org/10.1145/3385209.3385216,,Conference and Workshop Papers,
FriendNet Backdoor: Indentifying Backdoor Attack that is safe for Friendly Deep Neural Network,ICSIM,2020, (1): 53-57,"Hyun Kwon, Hyunsoo Yoon, Ki-Woong Park",https://doi.org/10.1145/3378936.3378938,,Conference and Workshop Papers,
Backdoor Embedding in Convolutional Neural Network Models via Invisible Perturbation,CODASPY,2020, (1): 97-108,"Haoti Zhong, Cong Liao, Anna Cinzia Squicciarini, Sencun Zhu, David J. Miller",https://doi.org/10.1145/3374664.3375751,,Conference and Workshop Papers,
Composite Backdoor Attack for Deep Neural Network by Mixing Existing Benign Features,CCS,2020, (1): 113-131,"Junyu Lin, Lei Xu, Yingqi Liu, Xiangyu Zhang",https://doi.org/10.1145/3372297.3423362,,Conference and Workshop Papers,
Can Adversarial Weight Perturbations Inject Neural Backdoors,CIKM,2020, (1): 2029-2032,"Siddhant Garg, Adarsh Kumar, Vibhor Goel, Yingyu Liang",https://doi.org/10.1145/3340531.3412130,,Conference and Workshop Papers,
Backdooring and Poisoning Neural Networks with Image-Scaling Attacks,SP,2020, (1): 41-47,"Erwin Quiring, Konrad Rieck",https://doi.org/10.1109/SPW50608.2020.00024,,Conference and Workshop Papers,
Backdoor Attacks and Defenses for Deep Neural Networks in Outsourced Cloud Environments,IEEE Netw.,2020,34 (5): 141-147,"Yanjiao Chen, Xueluan Gong, Qian Wang, Xing Di, Huayang Huang",https://doi.org/10.1109/MNET.011.1900577,,Journal Articles,
"Revealing Perceptible Backdoors in DNNs, Without the Training Set, via the Maximum Achievable Misclassification Fraction Statistic",MLSP,2020, (1): 1-6,"Zhen Xiang, David J. Miller, Hang Wang, George Kesidis",https://doi.org/10.1109/MLSP49062.2020.9231861,,Conference and Workshop Papers,
Backdoor Suppression in Neural Networks using Input Fuzzing and Majority Voting,IEEE Des. Test,2020,37 (2): 103-110,"Esha Sarkar, Yousif Alkindi, Michail Maniatakos",https://doi.org/10.1109/MDAT.2020.2968275,,Journal Articles,
Defending Deep Learning Based Anomaly Detection Systems Against White-Box Adversarial Examples and Backdoor Attacks,ISTAS,2020, (1): 294-301,"Khaled Alrawashdeh, Stephen Goldsmith",https://doi.org/10.1109/ISTAS50296.2020.9462227,,Conference and Workshop Papers,
Targeted Forgetting and False Memory Formation in Continual Learners through Adversarial Backdoor Attacks,IJCNN,2020, (1): 1-8,"Muhammad Umer, Glenn Dawson, Robi Polikar",https://doi.org/10.1109/IJCNN48605.2020.9206809,,Conference and Workshop Papers,
Backdooring Convolutional Neural Networks via Targeted Weight Perturbations,IJCB,2020, (1): 1-9,"Jacob Dumford, Walter J. Scheirer",https://doi.org/10.1109/IJCB48548.2020.9304875,,Conference and Workshop Papers,
Application of complex systems in neural networks against Backdoor attacks,ICTC,2020, (1): 57-59,"Sara Kaviani, Insoo Sohn, Huaping Liu",https://doi.org/10.1109/ICTC49870.2020.9289220,,Conference and Workshop Papers,
Removing Backdoor-Based Watermarks in Neural Networks with Limited Data,ICPR,2020, (1): 10149-10156,"Xuankai Liu, Fengting Li, Bihan Wen, Qi Li",https://doi.org/10.1109/ICPR48806.2021.9412684,,Conference and Workshop Papers,
Segmentation Based Backdoor Attack Detection,ICMLC,2020, (1): 298-302,"Natasha Kees, Yaxuan Wang, Yiling Jiang, Fang Lue, Patrick P. K. Chan",https://doi.org/10.1109/ICMLC51923.2020.9469037,,Conference and Workshop Papers,
Towards Inspecting and Eliminating Trojan Backdoors in Deep Neural Networks,ICDM,2020, (1): 162-171,"Wenbo Guo, Lun Wang, Yan Xu, Xinyu Xing, Min Du, Dawn Song",https://doi.org/10.1109/ICDM50108.2020.00025,,Conference and Workshop Papers,
"Revealing Backdoors, Post-Training, in DNN Classifiers via Novel Inference on Optimized Perturbations Inducing Group Misclassification",ICASSP,2020, (1): 3827-3831,"Zhen Xiang, David J. Miller, George Kesidis",https://doi.org/10.1109/ICASSP40776.2020.9054581,,Conference and Workshop Papers,
Biometric Backdoors: A Poisoning Attack Against Unsupervised Template Updating,EuroS&amp;P,2020, (1): 184-197,"Giulio Lovisotto, Simon Eberz, Ivan Martinovic",https://doi.org/10.1109/EuroSP48549.2020.00020,,Conference and Workshop Papers,
Bypassing Backdoor Detection Algorithms in Deep Learning,EuroS&amp;P,2020, (1): 175-183,"Te Juin Lester Tan, Reza Shokri",https://doi.org/10.1109/EuroSP48549.2020.00019,,Conference and Workshop Papers,
Interpretability Derived Backdoor Attacks Detection in Deep Neural Networks: Work-in-Progress,EMSOFT,2020, (1): 13-14,"Xiangyu Wen, Wei Jiang, Jinyu Zhan, Xupeng Wang, Zhiyuan He",https://doi.org/10.1109/EMSOFT51651.2020.9244019,,Conference and Workshop Papers,
TrojDRL: Evaluation of Backdoor Attacks on Deep Reinforcement Learning,DAC,2020, (1): 1-6,"Panagiota Kiourti, Kacper Wardega, Susmit Jha, Wenchao Li",https://doi.org/10.1109/DAC18072.2020.9218663,,Conference and Workshop Papers,
Optimizing Deep Learning Based Intrusion Detection Systems Defense Against White-Box and Backdoor Adversarial Attacks Through a Genetic Algorithm,AIPR,2020, (1): 1-8,"Khaled Alrawashdeh, Stephen Goldsmith",https://doi.org/10.1109/AIPR50011.2020.9425293,,Conference and Workshop Papers,
Detecting Backdoor Attacks via Class Difference in Deep Neural Networks,IEEE Access,2020,8 (1): 191049-191056,Hyun Kwon,https://doi.org/10.1109/ACCESS.2020.3032411,,Journal Articles,
Scalable Backdoor Detection in Neural Networks,ECML/PKDD,2020, (1): 289-304,"Haripriya Harikumar, Vuong Le, Santu Rana, Sourangshu Bhattacharya, Sunil Gupta, Svetha Venkatesh",https://doi.org/10.1007/978-3-030-67661-2_18,,Conference and Workshop Papers,
A Defence Against Input-Agnostic Backdoor Attacks on Deep Neural Networks,ICISS,2020, (1): 69-80,"Yansong Gao, Surya Nepal",https://doi.org/10.1007/978-3-030-65610-2_4,,Conference and Workshop Papers,
Towards Defeating Backdoored Random Oracles: Indifferentiability with Bounded Adaptivity,TCC,2020, (1): 241-273,"Yevgeniy Dodis, Pooya Farshim, Sogol Mazaheri, Stefano Tessaro",https://doi.org/10.1007/978-3-030-64381-2_9,,Conference and Workshop Papers,
Reflection Backdoor: A Natural Backdoor Attack on Deep Neural Networks,ECCV,2020, (1): 182-199,"Yunfei Liu, Xingjun Ma, James Bailey, Feng Lu",https://doi.org/10.1007/978-3-030-58607-2_11,,Conference and Workshop Papers,
One-Pixel Signature: Characterizing CNN Models for Backdoor Detection,ECCV,2020, (1): 326-341,"Shanjiaoyang Huang, Weiqi Peng, Zhiwei Jia, Zhuowen Tu",https://doi.org/10.1007/978-3-030-58583-9_20,,Conference and Workshop Papers,
Escaping Backdoor Attack Detection of Deep Learning,SEC,2020, (1): 431-445,"Yayuan Xiong, Fengyuan Xu, Sheng Zhong, Qun Li",https://doi.org/10.1007/978-3-030-58201-2_29,,Conference and Workshop Papers,
The MALICIOUS Framework: Embedding Backdoors into Tweakable Block Ciphers,CRYPTO,2020, (1): 249-278,"Thomas Peyrin, Haoyang Wang",https://doi.org/10.1007/978-3-030-56877-1_9,,Conference and Workshop Papers,
TROJANZOO: Everything you ever wanted to know about neural backdoors (but were afraid to ask),arXiv/CoRR,2020,abs/2012.09302 (1): 1,"Ren Pang, Zheng Zhang, Xiangshan Gao, Zhaohan Xi, Shouling Ji, Peng Cheng, Ting Wang",https://arxiv.org/abs/2012.09302,,Informal and Other Publications,
HaS-Nets: A Heal and Select Mechanism to Defend DNNs Against Backdoor Attacks for Data Collection Scenarios,arXiv/CoRR,2020,abs/2012.07474 (1): 1,"Hassan Ali, Surya Nepal, Salil S. Kanhere, Sanjay Jha",https://arxiv.org/abs/2012.07474,,Informal and Other Publications,
Backdoor Attack with Sample-Specific Triggers,arXiv/CoRR,2020,abs/2012.03816 (1): 1,"Yuezun Li, Yiming Li, Baoyuan Wu, Longkang Li, Ran He, Siwei Lyu",https://arxiv.org/abs/2012.03816,,Informal and Other Publications,
Effect of backdoor attacks over the complexity of the latent space distribution,arXiv/CoRR,2020,abs/2012.01931 (1): 1,"Henry D. Chacon, Paul Rad",https://arxiv.org/abs/2012.01931,,Informal and Other Publications,
Dynamic backdoor attacks against federated learning,arXiv/CoRR,2020,abs/2011.07429 (1): 1,Anbu Huang,https://arxiv.org/abs/2011.07429,,Informal and Other Publications,
Detecting Backdoors in Neural Networks Using Novel Feature-Based Anomaly Detection,arXiv/CoRR,2020,abs/2011.02526 (1): 1,"Hao Fu, Akshaj Kumar Veldanda, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami",https://arxiv.org/abs/2011.02526,,Informal and Other Publications,
Mitigating Backdoor Attacks in Federated Learning,arXiv/CoRR,2020,abs/2011.01767 (1): 1,"Chen Wu, Xian Yang, Sencun Zhu, Prasenjit Mitra",https://arxiv.org/abs/2011.01767,,Informal and Other Publications,
EEG-Based Brain-Computer Interfaces Are Vulnerable to Backdoor Attacks,arXiv/CoRR,2020,abs/2011.00101 (1): 1,"Lubin Meng, Jian Huang, Zhigang Zeng, Xue Jiang, Shan Yu, Tzyy-Ping Jung, Chin-Teng Lin, Ricardo Chavarriaga, Dongrui Wu",https://arxiv.org/abs/2011.00101,,Informal and Other Publications,
On Evaluating Neural Network Backdoor Defenses,arXiv/CoRR,2020,abs/2010.12186 (1): 1,"Akshaj Kumar Veldanda, Siddharth Garg",https://arxiv.org/abs/2010.12186,,Informal and Other Publications,
"Poisoned classifiers are not only backdoored, they are fundamentally broken",arXiv/CoRR,2020,abs/2010.09080 (1): 1,"Mingjie Sun, Siddhant Agarwal, J. Zico Kolter",https://arxiv.org/abs/2010.09080,,Informal and Other Publications,
Open-sourced Dataset Protection via Backdoor Watermarking,arXiv/CoRR,2020,abs/2010.05821 (1): 1,"Yiming Li, Ziqi Zhang, Jiawang Bai, Baoyuan Wu, Yong Jiang, Shu-Tao Xia",https://arxiv.org/abs/2010.05821,,Informal and Other Publications,
Don&apos;t Trigger Me! A Triggerless Backdoor Attack Against Deep Neural Networks,arXiv/CoRR,2020,abs/2010.03282 (1): 1,"Ahmed Salem, Michael Backes, Yang Zhang",https://arxiv.org/abs/2010.03282,,Informal and Other Publications,
BAAAN: Backdoor Attacks Against Autoencoder and GAN-Based Machine Learning Models,arXiv/CoRR,2020,abs/2010.03007 (1): 1,"Ahmed Salem, Yannick Sautter, Michael Backes, Mathias Humbert, Yang Zhang",https://arxiv.org/abs/2010.03007,,Informal and Other Publications,
What Do You See? Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors,arXiv/CoRR,2020,abs/2009.10639 (1): 1,"Yi-Shan Lin, Wen-Chuan Lee, Z. Berkay Celik",https://arxiv.org/abs/2009.10639,,Informal and Other Publications,
Light Can Hack Your Face! Black-box Backdoor Attack on Face Recognition Systems,arXiv/CoRR,2020,abs/2009.06996 (1): 1,"Haoliang Li, Yufei Wang, Xiaofei Xie, Yang Liu, Shiqi Wang, Renjie Wan, Lap-Pui Chau, Alex C. Kot",https://arxiv.org/abs/2009.06996,,Informal and Other Publications,
Can Adversarial Weight Perturbations Inject Neural Backdoors?,arXiv/CoRR,2020,abs/2008.01761 (1): 1,"Siddhant Garg, Adarsh Kumar, Vibhor Goel, Yingyu Liang",https://arxiv.org/abs/2008.01761,,Informal and Other Publications,
Noise-response Analysis for Rapid Detection of Backdoors in Deep Neural Networks,arXiv/CoRR,2020,abs/2008.00123 (1): 1,"N. Benjamin Erichson, Dane Taylor, Qixuan Wu, Michael W. Mahoney",https://arxiv.org/abs/2008.00123,,Informal and Other Publications,
Towards a Backdoorless Network Architecture Based on Remote Attestation and Backdoor Inspection,arXiv/CoRR,2020,abs/2007.14748 (1): 1,"Takayuki Sasaki, Yusuke Shimada",https://arxiv.org/abs/2007.14748,,Informal and Other Publications,
Backdoor Attacks and Countermeasures on Deep Learning: A Comprehensive Review,arXiv/CoRR,2020,abs/2007.10760 (1): 1,"Yansong Gao, Bao Gia Doan, Zhi Zhang, Siqi Ma, Jiliang Zhang, Anmin Fu, Surya Nepal, Hyoungshick Kim",https://arxiv.org/abs/2007.10760,,Informal and Other Publications,
Backdoor attacks and defenses in feature-partitioned collaborative learning,arXiv/CoRR,2020,abs/2007.03608 (1): 1,"Yang Liu, Zhihao Yi, Tianjian Chen",https://arxiv.org/abs/2007.03608,,Informal and Other Publications,
Natural Backdoor Attack on Text Data,arXiv/CoRR,2020,abs/2006.16176 (1): 1,Lichao Sun,https://arxiv.org/abs/2006.16176,,Informal and Other Publications,
Backdoor Attacks on Facial Recognition in the Physical World,arXiv/CoRR,2020,abs/2006.14580 (1): 1,"Emily Wenger, Josephine Passananti, Yuanshun Yao, Haitao Zheng, Ben Y. Zhao",https://arxiv.org/abs/2006.14580,,Informal and Other Publications,
FaceHack: Triggering backdoored facial recognition systems using facial characteristics,arXiv/CoRR,2020,abs/2006.11623 (1): 1,"Esha Sarkar, Hadjer Benkraouda, Michail Maniatakos",https://arxiv.org/abs/2006.11623,,Informal and Other Publications,
Backdoor Attacks on Federated Meta-Learning,arXiv/CoRR,2020,abs/2006.07026 (1): 1,"Chien-Lun Chen, Leana Golubchik, Marco Paolieri",https://arxiv.org/abs/2006.07026,,Informal and Other Publications,
A new measure for overfitting and its implications for backdooring of deep learning,arXiv/CoRR,2020,abs/2006.06721 (1): 1,"Kathrin Grosse, Taesung Lee, Youngja Park, Michael Backes, Ian M. Molloy",https://arxiv.org/abs/2006.06721,,Informal and Other Publications,
BadNL: Backdoor Attacks Against NLP Models,arXiv/CoRR,2020,abs/2006.01043 (1): 1,"Xiaoyi Chen, Ahmed Salem, Michael Backes, Shiqing Ma, Yang Zhang",https://arxiv.org/abs/2006.01043,,Informal and Other Publications,
Rethinking the Trigger of Backdoor Attack,arXiv/CoRR,2020,abs/2004.04692 (1): 1,"Yiming Li, Tongqing Zhai, Baoyuan Wu, Yong Jiang, Zhifeng Li, Shutao Xia",https://arxiv.org/abs/2004.04692,,Informal and Other Publications,
Watch your back: Backdoor Attacks in Deep Reinforcement Learning-based Autonomous Vehicle Control Systems,arXiv/CoRR,2020,abs/2003.07859 (1): 1,"Yue Wang, Esha Sarkar, Michail Maniatakos, Saif Eddin Jabari",https://arxiv.org/abs/2003.07859,,Informal and Other Publications,
Exploring Backdoor Poisoning Attacks Against Malware Classifiers,arXiv/CoRR,2020,abs/2003.01031 (1): 1,"Giorgio Severi, Jim Meyer, Scott E. Coull, Alina Oprea",https://arxiv.org/abs/2003.01031,,Informal and Other Publications,
Exposing Backdoors in Robust Machine Learning Models,arXiv/CoRR,2020,abs/2003.00865 (1): 1,"Ezekiel O. Soremekun, Sakshi Udeshi, Sudipta Chattopadhyay, Andreas Zeller",https://arxiv.org/abs/2003.00865,,Informal and Other Publications,
Defending against Backdoor Attack on Deep Neural Networks,arXiv/CoRR,2020,abs/2002.12162 (1): 1,"Hao Cheng, Kaidi Xu, Sijia Liu, Pin-Yu Chen, Pu Zhao, Xue Lin",https://arxiv.org/abs/2002.12162,,Informal and Other Publications,
On Certifying Robustness against Backdoor Attacks via Randomized Smoothing,arXiv/CoRR,2020,abs/2002.11750 (1): 1,"Binghui Wang, Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong",https://arxiv.org/abs/2002.11750,,Informal and Other Publications,
NNoculation: Broad Spectrum and Targeted Treatment of Backdoored DNNs,arXiv/CoRR,2020,abs/2002.08313 (1): 1,"Akshaj Kumar Veldanda, Kang Liu, Benjamin Tan, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri, Brendan Dolan-Gavitt, Siddharth Garg",https://arxiv.org/abs/2002.08313,,Informal and Other Publications,
Cryptographic Primitives that Resist Backdooring and Subversion,,2020, (1): 1,Sogol Mazaheri,http://tuprints.ulb.tu-darmstadt.de/14550/,,Books and Theses,
A Causally Formulated Hazard Ratio Estimation through Backdoor Adjustment on Structural Causal Model,MLHC,2020, (1): 376-396,"Riddhiman Adib, Paul M. Griffin, Sheikh Iqbal Ahamed, Mohammad Adibuzzaman",http://proceedings.mlr.press/v126/adib20a.html,,Conference and Workshop Papers,
Differentiable Causal Backdoor Discovery,AISTATS,2020, (1): 3970-3979,"Limor Gultchin, Matt J. Kusner, Varun Kanade, Ricardo Silva",http://proceedings.mlr.press/v108/gultchin20a.html,,Conference and Workshop Papers,
How To Backdoor Federated Learning,AISTATS,2020, (1): 2938-2948,"Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, Vitaly Shmatikov",http://proceedings.mlr.press/v108/bagdasaryan20a.html,,Conference and Workshop Papers,
Backdooring Deep Learning Architectures: Threats and (some) Opportunities,ICISSP,2020, (1): 15-16,Mauro Barni,,,Conference and Workshop Papers,
Defending Neural Backdoors via Generative Distribution Modeling,NeurIPS,2019, (1): 14004-14013,"Ximing Qiao, Yukun Yang, Hai Li",https://proceedings.neurips.cc/paper/2019/hash/78211247db84d96acf4e00092a7fba80-Abstract.html,,Conference and Workshop Papers,
A Little Is Enough: Circumventing Defenses For Distributed Learning,NeurIPS 2019,2019,,"Gilad Baruch, Moran Baruch, Yoav Goldberg",https://openreview.net/pdf/0e06d529e439b0e87ebeee5bb8146b977d270b97.pdf,,,
I Want to Break Square-free: The 4p - 1 Factorization Method and Its RSA Backdoor Viability,ICETE,2019, (1): 25-36,"Vladimir Sedlacek, Dusan Klinec, Marek Sýs, Petr Svenda, Vashek Matyas",https://doi.org/10.5220/0007786600250036,,Conference and Workshop Papers,
Cryptography with Disposable Backdoors,Cryptogr.,2019,3 (3): 22,"Kai-Min Chung, Marios Georgiou, Ching-Yi Lai, Vassilis Zikas",https://doi.org/10.3390/cryptography3030022,,Journal Articles,
Interbank Networks and Backdoor Bailouts: Benefiting from Other Banks&apos; Government Guarantees,Manag. Sci.,2019,65 (8): 3673-3693,"Tim Eisert, Christian Eufinger",https://doi.org/10.1287/mnsc.2017.2968,,Journal Articles,
Walling up Backdoors in Intrusion Detection Systems,Big-DAMA@CoNEXT,2019, (1): 8-13,"Maximilian Bachl, Alexander Hartl, Joachim Fabini, Tanja Zseby",https://doi.org/10.1145/3359992.3366638,,Conference and Workshop Papers,
Latent Backdoor Attacks on Deep Neural Networks,CCS,2019, (1): 2041-2055,"Yuanshun Yao, Huiying Li, Haitao Zheng, Ben Y. Zhao",https://doi.org/10.1145/3319535.3354209,,Conference and Workshop Papers,
True2F: Backdoor-Resistant Authentication Tokens,IEEE Symposium on Security and Privacy,2019, (1): 398-416,"Emma Dauterman, Henry Corrigan-Gibbs, David Mazières, Dan Boneh, Dominic Rizzo",https://doi.org/10.1109/SP.2019.00048,,Conference and Workshop Papers,
Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks,IEEE Symposium on Security and Privacy,2019, (1): 707-723,"Bolun Wang, Yuanshun Yao, Shawn Shan, Huiying Li, Bimal Viswanath, Haitao Zheng, Ben Y. Zhao",https://doi.org/10.1109/SP.2019.00031,,Conference and Workshop Papers,
On Embedding Backdoor in Malware Detectors Using Machine Learning,PST,2019, (1): 1-5,"Shoichiro Sasaki, Seira Hidano, Toshihiro Uchibayashi, Takuo Suganuma, Masahiro Hiji, Shinsaku Kiyomoto",https://doi.org/10.1109/PST47121.2019.8949034,,Conference and Workshop Papers,
Luminance-based video backdoor attack against anti-spoofing rebroadcast detection,MMSP,2019, (1): 1-6,"Abhir Bhalerao, Kassem Kallas, Benedetta Tondi, Mauro Barni",https://doi.org/10.1109/MMSP.2019.8901711,,Conference and Workshop Papers,
A Benchmark Study Of Backdoor Data Poisoning Defenses For Deep Neural Network Classifiers And A Novel Defense,MLSP,2019, (1): 1-6,"Zhen Xiang, David J. Miller, George Kesidis",https://doi.org/10.1109/MLSP.2019.8918908,,Conference and Workshop Papers,
Is Backside the New Backdoor in Modern SoCs?: Invited Paper,ITC,2019, (1): 1-10,"Nidish Vashistha, M. Tanjidur Rahman, Olivia P. Paradis, Navid Asadizanjani",https://doi.org/10.1109/ITC44170.2019.9000127,,Conference and Workshop Papers,
A New Backdoor Attack in CNNS by Training Set Corruption Without Label Poisoning,ICIP,2019, (1): 101-105,"Mauro Barni, Kassem Kallas, Benedetta Tondi",https://doi.org/10.1109/ICIP.2019.8802997,,Conference and Workshop Papers,
A Backdoor Attack Against LSTM-Based Text Classification Systems,IEEE Access,2019,7 (1): 138872-138878,"Jiazhu Dai, Chuanshuai Chen, Yufeng Li",https://doi.org/10.1109/ACCESS.2019.2941376,,Journal Articles,
BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,IEEE Access,2019,7 (1): 47230-47244,"Tianyu Gu, Kang Liu, Brendan Dolan-Gavitt, Siddharth Garg",https://doi.org/10.1109/ACCESS.2019.2909068,,Journal Articles,
Towards Leveraging Backdoors in Qualitative Constraint Networks,KI,2019, (1): 308-315,"Michael Sioutis, Tomi Janhunen",https://doi.org/10.1007/978-3-030-30179-8_27,,Conference and Workshop Papers,
Backdoor Attacks in Neural Networks - A Systematic Evaluation on Multiple Traffic Sign Datasets,CD-MAKE,2019, (1): 285-300,"Huma Rehman, Andreas Ekelhart, Rudolf Mayer",https://doi.org/10.1007/978-3-030-29726-8_18,,Conference and Workshop Papers,
Existence Versus Exploitation: The Opacity of Backdoors and Backbones Under a Weak Assumption,SOFSEM,2019, (1): 247-259,"Lane A. Hemaspaandra, David E. Narváez",https://doi.org/10.1007/978-3-030-10801-4_20,,Conference and Workshop Papers,
Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering,SafeAI@AAAI,2019, (1): 1,"Bryant Chen, Wilka Carvalho, Nathalie Baracaldo, Heiko Ludwig, Benjamin Edwards, Taesung Lee, Ian M. Molloy, Biplav Srivastava",https://ceur-ws.org/Vol-2301/paper_18.pdf,,Conference and Workshop Papers,
Testing the Human Backdoor: Organizational Response to a Phishing Campaign,J. Univers. Comput. Sci.,2019,25 (11): 1458-1477,"Anze Mihelic, Matej Jevscek, Simon Vrhovec, Igor Bernik",http://www.jucs.org/jucs_25_11/testing_the_human_backdoor,,Journal Articles,
Label-Consistent Backdoor Attacks,arXiv/CoRR,2019,abs/1912.02771 (1): 1,"Alexander Turner, Dimitris Tsipras, Aleksander Madry",http://arxiv.org/abs/1912.02771,,Informal and Other Publications,
Poison as a Cure: Detecting &amp; Neutralizing Variable-Sized Backdoor Attacks in Deep Neural Networks,arXiv/CoRR,2019,abs/1911.08040 (1): 1,"Alvin Chan, Yew-Soon Ong",http://arxiv.org/abs/1911.08040,,Informal and Other Publications,
"Revealing Perceptible Backdoors, without the Training Set, via the Maximum Achievable Misclassification Fraction Statistic",arXiv/CoRR,2019,abs/1911.07970 (1): 1,"Zhen Xiang, David J. Miller, George Kesidis",http://arxiv.org/abs/1911.07970,,Informal and Other Publications,
Can You Really Backdoor Federated Learning?,arXiv/CoRR,2019,abs/1911.07963 (1): 1,"Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, H. Brendan McMahan",http://arxiv.org/abs/1911.07963,,Informal and Other Publications,
NeuronInspect: Detecting Backdoors in Neural Networks via Output Explanations,arXiv/CoRR,2019,abs/1911.07399 (1): 1,"Xijie Huang, Moustafa Alzantot, Mani B. Srivastava",http://arxiv.org/abs/1911.07399,,Informal and Other Publications,
The Tale of Evil Twins: Adversarial Inputs versus Backdoored Models,arXiv/CoRR,2019,abs/1911.01559 (1): 1,"Ren Pang, Xinyang Zhang, Shouling Ji, Yevgeniy Vorobeychik, Xiapu Luo, Ting Wang",http://arxiv.org/abs/1911.01559,,Informal and Other Publications,
Invisible Backdoor Attacks Against Deep Neural Networks,arXiv/CoRR,2019,abs/1909.02742 (1): 1,"Shaofeng Li, Benjamin Zi Hao Zhao, Jiahao Yu, Minhui Xue, Dali Kaafar, Haojin Zhu",http://arxiv.org/abs/1909.02742,,Informal and Other Publications,
TABOR: A Highly Accurate Approach to Inspecting and Restoring Trojan Backdoors in AI Systems,arXiv/CoRR,2019,abs/1908.01763 (1): 1,"Wenbo Guo, Lun Wang, Xinyu Xing, Min Du, Dawn Song",http://arxiv.org/abs/1908.01763,,Informal and Other Publications,
On the Robustness of the Backdoor-based Watermarking in Deep Neural Networks,arXiv/CoRR,2019,abs/1906.07745 (1): 1,"Masoumeh Shafieinejad, Jiaqi Wang, Nils Lukas, Florian Kerschbaum",http://arxiv.org/abs/1906.07745,,Informal and Other Publications,
Regula Sub-rosa: Latent Backdoor Attacks on Deep Neural Networks,arXiv/CoRR,2019,abs/1905.10447 (1): 1,"Yuanshun Yao, Huiying Li, Haitao Zheng, Ben Y. Zhao",http://arxiv.org/abs/1905.10447,,Informal and Other Publications,
Adversarial Audio: A New Information Hiding Method and Backdoor for DNN-based Speech Recognition Models,arXiv/CoRR,2019,abs/1904.03829 (1): 1,"Yehao Kong, Jiliang Zhang",http://arxiv.org/abs/1904.03829,,Informal and Other Publications,
BSEA-1 - A Stream Cipher Backdooring Technique,arXiv/CoRR,2019,abs/1903.11063 (1): 1,Eric Filiol,http://arxiv.org/abs/1903.11063,,Informal and Other Publications,
Design of intentional backdoors in sequential models,arXiv/CoRR,2019,abs/1902.09972 (1): 1,"Zhaoyuan Yang, Naresh Iyer, Johan Reimann, Nurali Virani",http://arxiv.org/abs/1902.09972,,Informal and Other Publications,
Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks by Backdooring,USENIX Security Symposium,2018, (1): 1615-1631,"Yossi Adi, Carsten Baum, Moustapha Cissé, Benny Pinkas, Joseph Keshet",https://www.usenix.org/conference/usenixsecurity18/presentation/adi,,Conference and Workshop Papers,
Spectral Signatures in Backdoor Attacks,NeurIPS,2018, (1): 8011-8021,"Brandon Tran, Jerry Li, Aleksander Madry",https://proceedings.neurips.cc/paper/2018/hash/280cf18baf4311c92aa5a042336587d3-Abstract.html,,Conference and Workshop Papers,
Backdoor detection systems for embedded devices,,2018, (1): 1,Sam L. Thomas,https://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.753100,,Books and Theses,
On the Existence of Non-Linear Invariants and Algebraic Polynomial Constructive Approach to Backdoors in Block Ciphers,IACR Cryptol. ePrint Arch.,2018,2018 (1): 807,Nicolas T. Courtois,https://eprint.iacr.org/2018/807,,Informal and Other Publications,
Cryptography with Dispensable Backdoors,IACR Cryptol. ePrint Arch.,2018,2018 (1): 352,"Kai-Min Chung, Marios Georgiou, Ching-Yi Lai, Vassilis Zikas",https://eprint.iacr.org/2018/352,,Informal and Other Publications,
On Cryptographic Attacks Using Backdoors for SAT,AAAI,2018, (1): 6641-6648,"Alexander A. Semenov, Oleg Zaikin, Ilya V. Otpuschennikov, Stepan Kochemazov, Alexey Ignatiev",https://doi.org/10.1609/aaai.v32i1.12205,,Conference and Workshop Papers,
Technical perspective: Backdoor engineering,Commun. ACM,2018,61 (11): 147,Markus G. Kuhn,https://doi.org/10.1145/3266289,,Journal Articles,
UFO - Hidden Backdoor Discovery and Security Verification in IoT Device Firmware,ISSRE Workshops,2018, (1): 18-23,"Chin-Wei Tien, Tsung-Ta Tsai, Ing-Yi Chen, Sy-Yen Kuo",https://doi.org/10.1109/ISSREW.2018.00-37,,Conference and Workshop Papers,
Backdoor Attacks on Neural Network Operations,GlobalSIP,2018, (1): 1154-1158,"Joseph Clements, Yingjie Lao",https://doi.org/10.1109/GlobalSIP.2018.8646335,,Conference and Workshop Papers,
Remote Desktop Backdoor Implementation with Reverse TCP Payload Using Open Source Tools for Instructional Use,EIT,2018, (1): 249-254,"Yaswanth Kolli, Tauheed Khan Mohd, Ahmad Y. Javaid",https://doi.org/10.1109/EIT.2018.8500174,,Conference and Workshop Papers,
Backdoored Hash Functions: Immunizing HMAC and HKDF,CSF,2018, (1): 105-118,"Marc Fischlin, Christian Janson, Sogol Mazaheri",https://doi.org/10.1109/CSF.2018.00015,,Conference and Workshop Papers,
Real-time Detection of Passive Backdoor Behaviors on Android System,CNS,2018, (1): 1-9,"Yao Yao, Lipeng Zhu, He Wang",https://doi.org/10.1109/CNS.2018.8433190,,Conference and Workshop Papers,
Learning-Sensitive Backdoors with Restarts,CP,2018, (1): 453-469,"Edward Zulkoski, Ruben Martins, Christoph M. Wintersteiger, Robert Robere, Jia Hui Liang, Krzysztof Czarnecki, Vijay Ganesh",https://doi.org/10.1007/978-3-319-98334-9_30,,Conference and Workshop Papers,
Combiners for Backdoored Random Oracles,CRYPTO,2018, (1): 272-302,"Balthazar Bauer, Pooya Farshim, Sogol Mazaheri",https://doi.org/10.1007/978-3-319-96881-0_10,,Conference and Workshop Papers,
ALIAS: A Modular Tool for Finding Backdoors for SAT,SAT,2018, (1): 419-427,"Stepan Kochemazov, Oleg Zaikin",https://doi.org/10.1007/978-3-319-94144-8_25,,Conference and Workshop Papers,
From Backdoor Key to Backdoor Completability: Improving a Known Measure of Hardness for the Satisfiable CSP,CPAIOR,2018, (1): 198-214,"Guillaume Escamocher, Mohamed Siala, Barry O&apos;Sullivan",https://doi.org/10.1007/978-3-319-93031-2_14,,Conference and Workshop Papers,
"Backdoors: Definition, Deniability and Detection",RAID,2018, (1): 92-113,"Sam L. Thomas, Aurélien Francillon",https://doi.org/10.1007/978-3-030-00470-5_5,,Conference and Workshop Papers,
Fine-Pruning: Defending Against Backdooring Attacks on Deep Neural Networks,RAID,2018, (1): 273-294,"Kang Liu, Brendan Dolan-Gavitt, Siddharth Garg",https://doi.org/10.1007/978-3-030-00470-5_13,,Conference and Workshop Papers,
How to Subvert Backdoored Encryption: Security Against Adversaries that Decrypt All Ciphertexts,IACR Cryptol. ePrint Arch.,2018,2018 (1): 212,"Thibaut Horel, Sunoo Park, Silas Richelson, Vinod Vaikuntanathan",http://eprint.iacr.org/2018/212,,Informal and Other Publications,
How a simple bug in ML compiler could be exploited for backdoors?,arXiv/CoRR,2018,abs/1811.10851 (1): 1,Baptiste David,http://arxiv.org/abs/1811.10851,,Informal and Other Publications,
Backdoor Decomposable Monotone Circuits and their Propagation Complete Encodings,arXiv/CoRR,2018,abs/1811.09435 (1): 1,"Petr Kucera, Petr Savický",http://arxiv.org/abs/1811.09435,,Informal and Other Publications,
Indiscreet Logs: Diffie-Hellman Backdoors in TLS,NDSS,2017, (1): 1,"Kristen Dorey, Nicholas Chang-Fong, Aleksander Essex",https://www.ndss-symposium.org/ndss2017/ndss-2017-programme/indiscreet-logs-persistent-diffie-hellman-backdoors-tls/,,Conference and Workshop Papers,
Mathematical Backdoors in Symmetric Encryption Systems - Proposal for a Backdoored AES-like Block Cipher,ICISSP,2017, (1): 622-631,"Arnaud Bannier, Eric Filiol",https://doi.org/10.5220/0006244406220631,,Conference and Workshop Papers,
Combining Treewidth and Backdoors for CSP,STACS,2017, (1): 36:1-36:17,"Robert Ganian, M. S. Ramanujan, Stefan Szeider",https://doi.org/10.4230/LIPIcs.STACS.2017.36,,Conference and Workshop Papers,
Backdoor Sets for CSP,The Constraint Satisfaction Problem,2017, (1): 137-157,"Serge Gaspers, Sebastian Ordyniak, Stefan Szeider",https://doi.org/10.4230/DFU.Vol7.15301.5,,Parts in Books or Collections,
Low-cost detection of backdoor malware,ICITST,2017, (1): 197-198,"Huicong Loi, Aspen Olmsted",https://doi.org/10.23919/ICITST.2017.8356377,,Conference and Workshop Papers,
Open Sesame! Design and Implementation of Backdoor to Secretly Unlock Android Devices,J. Internet Serv. Inf. Secur.,2017,7 (4): 35-44,"Junsung Cho, Geumhwan Cho, Sangwon Hyun, Hyoungshick Kim",https://doi.org/10.22667/JISIS.2017.11.30.035,,Journal Articles,
"BackDoor: Sounds that a microphone can record, but that humans can&apos;t hear",GetMobile Mob. Comput. Commun.,2017,21 (4): 25-29,"Nirupam Roy, Haitham Hassanieh, Romit Roy Choudhury",https://doi.org/10.1145/3191789.3191799,,Journal Articles,
BackDoor: Making Microphones Hear Inaudible Sounds,MobiSys,2017, (1): 2-14,"Nirupam Roy, Haitham Hassanieh, Romit Roy Choudhury",https://doi.org/10.1145/3081333.3081366,,Conference and Workshop Papers,
Backdoor attacks against learning systems,CNS,2017, (1): 1-9,"Yujie Ji, Xinyang Zhang, Ting Wang",https://doi.org/10.1109/CNS.2017.8228656,,Conference and Workshop Papers,
Stringer: Measuring the Importance of Static Data Comparisons to Detect Backdoors and Undocumented Functionality,ESORICS,2017, (1): 513-531,"Sam L. Thomas, Tom Chothia, Flavio D. Garcia",https://doi.org/10.1007/978-3-319-66399-9_28,,Conference and Workshop Papers,
Backdoor Treewidth for SAT,SAT,2017, (1): 20-37,"Robert Ganian, M. S. Ramanujan, Stefan Szeider",https://doi.org/10.1007/978-3-319-66263-3_2,,Conference and Workshop Papers,
Backdoor Trees for Answer Set Programming,ASPOCP@LPNMR,2017, (1): 1,"Johannes Klaus Fichte, Stefan Szeider",https://ceur-ws.org/Vol-1868/p9.pdf,,Conference and Workshop Papers,
Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning,arXiv/CoRR,2017,abs/1712.05526 (1): 1,"Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, Dawn Song",http://arxiv.org/abs/1712.05526,,Informal and Other Publications,
The Opacity of Backbones and Backdoors Under a Weak Assumption,arXiv/CoRR,2017,abs/1706.04582 (1): 1,"Lane A. Hemaspaandra, David E. Narváez",http://arxiv.org/abs/1706.04582,,Informal and Other Publications,
Backdoors for Linear Temporal Logic,IPEC,2016, (1): 23:1-23:17,"Arne Meier, Sebastian Ordyniak, Ramanujan Sridharan, Irena Schindler",https://doi.org/10.4230/LIPIcs.IPEC.2016.23,,Conference and Workshop Papers,
No backdoor required or expected,Commun. ACM,2016,59 (6): 8-9,,https://doi.org/10.1145/2931085,,Journal Articles,
Backdoors in Pseudorandom Number Generators: Possibility and Impossibility Results,CRYPTO,2016, (1): 403-432,"Jean Paul Degabriele, Kenneth G. Paterson, Jacob C. N. Schuldt, Joanne Woodage",https://doi.org/10.1007/978-3-662-53018-4_15,,Conference and Workshop Papers,
Controlled Randomness - A Defense Against Backdoors in Cryptographic Devices,Mycrypt,2016, (1): 215-232,"Lucjan Hanzlik, Kamil Kluczniak, Miroslaw Kutylowski",https://doi.org/10.1007/978-3-319-61273-7_11,,Conference and Workshop Papers,
Backdoors to Tractable Valued CSP,CP,2016, (1): 233-250,"Robert Ganian, M. S. Ramanujan, Stefan Szeider",https://doi.org/10.1007/978-3-319-44953-1_16,,Conference and Workshop Papers,
Strong Backdoors for Default Logic,SAT,2016, (1): 45-59,"Johannes Klaus Fichte, Arne Meier, Irina Schindler",https://doi.org/10.1007/978-3-319-40970-2_4,,Conference and Workshop Papers,
Backdoors to SAT,Encyclopedia of Algorithms,2016, (1): 167-170,Serge Gaspers,https://doi.org/10.1007/978-1-4939-2864-4_781,,Reference Works,
Detecting Stealthy Backdoors and Port Knocking Sequences through Flow Analysis,Prax. Inf.verarb. Kommun.,2016,38 (3-4): 97-104,"Felix von Eye, Michael Grabatin, Wolfgang Hommel",http://www.degruyter.com/view/j/piko.2015.38.issue-3-4/pik-2015-0011/pik-2015-0011.xml,,Journal Articles,
Indiscreet Logs: Persistent Diffie-Hellman Backdoors in TLS,IACR Cryptol. ePrint Arch.,2016,2016 (1): 999,"Kristen Dorey, Nicholas Chang-Fong, Aleksander Essex",http://eprint.iacr.org/2016/999,,Informal and Other Publications,
How to Backdoor Diffie-Hellman,IACR Cryptol. ePrint Arch.,2016,2016 (1): 644,David Wong,http://eprint.iacr.org/2016/644,,Informal and Other Publications,
DEcryption Contract ENforcement Tool (DECENT): A Practical Alternative to Government Decryption Backdoors,IACR Cryptol. ePrint Arch.,2016,2016 (1): 245,Peter Linder,http://eprint.iacr.org/2016/245,,Informal and Other Publications,
Strong Backdoors for Linear Temporal Logic,arXiv/CoRR,2016,abs/1602.04934 (1): 1,"Arne Meier, Sebastian Ordyniak, M. S. Ramanujan, Irena Schindler",http://arxiv.org/abs/1602.04934,,Informal and Other Publications,
Variable-Deletion Backdoors to Planning,AAAI,2015, (1): 3305-3312,"Martin Kronegger, Sebastian Ordyniak, Andreas Pfandler",https://doi.org/10.1609/aaai.v29i1.9662,,Conference and Workshop Papers,
Solving d-SAT via Backdoors to Small Treewidth,SODA,2015, (1): 630-641,"Fedor V. Fomin, Daniel Lokshtanov, Neeldhara Misra, M. S. Ramanujan, Saket Saurabh",https://doi.org/10.1137/1.9781611973730.43,,Conference and Workshop Papers,
Devil in a box: Installing backdoors in electronic door locks,PST,2015, (1): 139-144,"Seongyeol Oh, Joon-Sung Yang, Andrea Bianchi, Hyoungshick Kim",https://doi.org/10.1109/PST.2015.7232965,,Conference and Workshop Papers,
Covert remote syscall communication at kernel level: A SPOOKY backdoor,MALWARE,2015, (1): 74-81,"Florian Kerber, Dominik Teubert, Ulrike Meyer",https://doi.org/10.1109/MALWARE.2015.7413687,,Conference and Workshop Papers,
Integrated Sensor: A Backdoor for Hardware Trojan Insertions?,DSD,2015, (1): 415-422,"Xuan Thuy Ngo, Zakaria Najm, Shivam Bhasin, Debapriya Basu Roy, Jean-Luc Danger, Sylvain Guilley",https://doi.org/10.1109/DSD.2015.119,,Conference and Workshop Papers,
Internet-facing PLCs as a network backdoor,CNS,2015, (1): 524-532,"Johannes Klick, Stephan Lau, Daniel Marzin, Jan-Ole Malchow, Volker Roth",https://doi.org/10.1109/CNS.2015.7346865,,Conference and Workshop Papers,
Backdoors to tractable answer set programming,Artif. Intell.,2015,220 (1): 64-103,"Johannes Klaus Fichte, Stefan Szeider",https://doi.org/10.1016/j.artint.2014.12.001,,Journal Articles,
A Formal Treatment of Backdoored Pseudorandom Generators,EUROCRYPT,2015, (1): 101-126,"Yevgeniy Dodis, Chaya Ganesh, Alexander Golovnev, Ari Juels, Thomas Ristenpart",https://doi.org/10.1007/978-3-662-46800-5_5,,Conference and Workshop Papers,
Netzbasierte Erkennung von mittels Port Knocking verstecksten Dienstern und Backdoors,DFN-Forum Kommunikationstechnologien,2015, (1): 57-67,"Felix von Eye, Michael Grabatin, Wolfgang Hommel",https://dl.gi.de/handle/20.500.12116/2362,,Conference and Workshop Papers,
Backdoors into Heterogeneous Classes of SAT and CSP,AAAI,2014, (1): 2652-2658,"Serge Gaspers, Neeldhara Misra, Sebastian Ordyniak, Stefan Szeider, Stanislav Zivný",https://doi.org/10.1609/aaai.v28i1.9111,,Conference and Workshop Papers,
Backdoors to Planning,AAAI,2014, (1): 2300-2307,"Martin Kronegger, Sebastian Ordyniak, Andreas Pfandler",https://doi.org/10.1609/aaai.v28i1.9033,,Conference and Workshop Papers,
Backdoor,Datenschutz und Datensicherheit,2014,38 (2): 119,Dirk Fox,https://doi.org/10.1007/s11623-014-0045-5,,Journal Articles,
Tradeoffs in the complexity of backdoors to satisfiability: dynamic sub-solvers and learning during search,Ann. Math. Artif. Intell.,2014,70 (4): 399-431,"Bistra Dilkina, Carla P. Gomes, Ashish Sabharwal",https://doi.org/10.1007/s10472-014-9407-9,,Journal Articles,
Answer Set Solver Backdoors,JELIA,2014, (1): 674-683,"Emilia Oikarinen, Matti Järvisalo",https://doi.org/10.1007/978-3-319-11558-0_51,,Conference and Workshop Papers,
On Backdoors to Tractable Constraint Languages,CP,2014, (1): 224-239,"Clément Carbonnel, Martin C. Cooper, Emmanuel Hebrard",https://doi.org/10.1007/978-3-319-10428-7_18,,Conference and Workshop Papers,
Backdoors to q-Horn,STACS,2013, (1): 67-79,"Serge Gaspers, Sebastian Ordyniak, M. S. Ramanujan, Saket Saurabh, Stefan Szeider",https://doi.org/10.4230/LIPIcs.STACS.2013.67,,Conference and Workshop Papers,
Backdoors to Normality for Disjunctive Logic Programs,AAAI,2013, (1): 320-327,"Johannes Klaus Fichte, Stefan Szeider",https://doi.org/10.1609/aaai.v27i1.8624,,Conference and Workshop Papers,
Backdoors to Tractability of Answer-Set Programming,AAAI,2013, (1): 1662-1663,Johannes Klaus Fichte,https://doi.org/10.1609/aaai.v27i1.8505,,Conference and Workshop Papers,
Implementation and implications of a stealth hard-drive backdoor,ACSAC,2013, (1): 279-288,"Jonas Zaddach, Anil Kurmus, Davide Balzarotti, Erik-Oliver Blass, Aurélien Francillon, Travis Goodspeed, Moitrayee Gupta, Ioannis Koltsidas",https://doi.org/10.1145/2523649.2523661,,Conference and Workshop Papers,
Towards reducing the attack surface of software backdoors,CCS,2013, (1): 851-862,"Felix Schuster, Thorsten Holz",https://doi.org/10.1145/2508859.2516716,,Conference and Workshop Papers,
Vulnerability-Based Backdoors: Threats from Two-step Trojans,SERE,2013, (1): 169-177,"Kai Chen, Yingjun Zhang, Yifeng Lian",https://doi.org/10.1109/SERE.2013.19,,Conference and Workshop Papers,
Strong Backdoors to Bounded Treewidth SAT,FOCS,2013, (1): 489-498,"Serge Gaspers, Stefan Szeider",https://doi.org/10.1109/FOCS.2013.59,,Conference and Workshop Papers,
Preventing Backdoors in Server Applications with a Separated Software Architecture - (Short Paper),DIMVA,2013, (1): 197-206,"Felix Schuster, Stefan Rüster, Thorsten Holz",https://doi.org/10.1007/978-3-642-39235-1_12,,Conference and Workshop Papers,
Upper and Lower Bounds for Weak Backdoor Set Detection,SAT,2013, (1): 394-402,"Neeldhara Misra, Sebastian Ordyniak, Venkatesh Raman, Stefan Szeider",https://doi.org/10.1007/978-3-642-39071-5_29,,Conference and Workshop Papers,
Crowdsourcing Backdoor Identification for Combinatorial Optimization,IJCAI,2013, (1): 2840-2847,"Ronan LeBras, Richard Bernstein, Carla P. Gomes, Bart Selman, R. Bruce van Dover",http://www.aaai.org/ocs/index.php/IJCAI/IJCAI13/paper/view/6993,,Conference and Workshop Papers,
Backdoors to Abduction,IJCAI,2013, (1): 1046-1052,"Andreas Pfandler, Stefan Rümmele, Stefan Szeider",http://www.aaai.org/ocs/index.php/IJCAI/IJCAI13/paper/view/6912,,Conference and Workshop Papers,
Backdoors to the Tractability of Answer Set Programming,Theory Pract. Log. Program.,2013,13 (4-5-Online-Supplement): 1,Johannes Klaus Fichte,http://static.cambridge.org/resource/id/urn:cambridge.org:id:binary:20161018085635834-0697:S1471068413000112:tlp2013034.pdf,,Journal Articles,
A generalized backdoor criterion,arXiv/CoRR,2013,abs/1307.5636 (1): 1,"Marloes H. Maathuis, Diego Colombo",http://arxiv.org/abs/1307.5636,,Informal and Other Publications,
A Framework to Eliminate Backdoors from Response-Computable Authentication,IEEE Symposium on Security and Privacy,2012, (1): 3-17,"Shuaifu Dai, Tao Wei, Chao Zhang, Tielei Wang, Yu Ding, Zhenkai Liang, Wei Zou",https://doi.org/10.1109/SP.2012.10,,Conference and Workshop Papers,
Breakthrough Silicon Scanning Discovers Backdoor in Military Chip,CHES,2012, (1): 23-40,"Sergei Skorobogatov, Christopher Woods",https://doi.org/10.1007/978-3-642-33027-8_2,,Conference and Workshop Papers,
Strong Backdoors to Nested Satisfiability,SAT,2012, (1): 72-85,"Serge Gaspers, Stefan Szeider",https://doi.org/10.1007/978-3-642-31612-8_7,,Conference and Workshop Papers,
Backdoors to Acyclic SAT,ICALP,2012, (1): 363-374,"Serge Gaspers, Stefan Szeider",https://doi.org/10.1007/978-3-642-31594-7_31,,Conference and Workshop Papers,
Backdoors to Satisfaction,The Multivariate Algorithmic Revolution and Beyond,2012, (1): 287-317,"Serge Gaspers, Stefan Szeider",https://doi.org/10.1007/978-3-642-30891-8_15,,Conference and Workshop Papers,
Detecting Stealthy Backdoors with Association Rule Mining,Networking,2012, (1): 161-171,"Stefan Hommes, Radu State, Thomas Engel",https://doi.org/10.1007/978-3-642-30054-7_13,,Conference and Workshop Papers,
Backdoors to Tractable Answer-Set Programming,IJCAI,2011, (1): 863-868,"Johannes Klaus Fichte, Stefan Szeider",https://doi.org/10.5591/978-1-57735-516-8/IJCAI11-150,,Conference and Workshop Papers,
Trusting the open latent IC backdoors,STC@CCS,2011, (1): 1-2,Farinaz Koushanfar,https://doi.org/10.1145/2046582.2046584,,Conference and Workshop Papers,
TorusDesktop: pointing via the backdoor is sometimes shorter,CHI,2011, (1): 829-838,"Stéphane Huot, Olivier Chapuis, Pierre Dragicevic",https://doi.org/10.1145/1978942.1979064,,Conference and Workshop Papers,
Silencing Hardware Backdoors,IEEE Symposium on Security and Privacy,2011, (1): 49-63,"Adam Waksman, Simha Sethumadhavan",https://doi.org/10.1109/SP.2011.27,,Conference and Workshop Papers,
Finding Small Backdoors in SAT Instances,Canadian AI,2011, (1): 269-280,"Zijie Li, Peter van Beek",https://doi.org/10.1007/978-3-642-21043-3_33,,Conference and Workshop Papers,
Backdoor Branching,IPCO,2011, (1): 183-191,"Matteo Fischetti, Michele Monaci",https://doi.org/10.1007/978-3-642-20807-2_15,,Conference and Workshop Papers,
Static detection of application backdoors - Detecting both malicious software behavior and malicious indicators from the static analysis of executable code,Datenschutz und Datensicherheit,2010,34 (3): 149-155,"Chris Wysopal, Chris Eng, Tyler Shields",https://doi.org/10.1007/s11623-010-0024-4,,Journal Articles,
Simple Backdoors on RSA Modulus by Using RSA Vulnerability,IEICE Trans. Fundam. Electron. Commun. Comput. Sci.,2009,92-A (9): 2326-2332,"Hung-Min Sun, Mu-En Wu, Cheng-Ta Yang",https://doi.org/10.1587/transfun.E92.A.2326,,Journal Articles,
A study on intrusion protection techniques against Linux kernel backdoor,ICHIT,2009, (1): 86-90,"Jin Taek Kim, Jeong-Ho Kho, Min-Seok Hong, Choul Woong Son, Do-Won Lee, Sang-Jo Youk, Geuk Lee",https://doi.org/10.1145/1644993.1645009,,Conference and Workshop Papers,
A chipset level network backdoor: bypassing host-based firewall &amp; IDS,AsiaCCS,2009, (1): 125-134,"Sherri Sparks, Shawn Embleton, Cliff Changchun Zou",https://doi.org/10.1145/1533057.1533076,,Conference and Workshop Papers,
Backdoors in the Context of Learning,SAT,2009, (1): 73-79,"Bistra Dilkina, Carla P. Gomes, Ashish Sabharwal",https://doi.org/10.1007/978-3-642-02777-2_9,,Conference and Workshop Papers,
Backdoors to Combinatorial Optimization: Feasibility and Optimality,CPAIOR,2009, (1): 56-70,"Bistra Dilkina, Carla P. Gomes, Yuri Malitsky, Ashish Sabharwal, Meinolf Sellmann",https://doi.org/10.1007/978-3-642-01929-6_6,,Conference and Workshop Papers,
"CPU Bugs, CPU Backdoors and Consequences on Security",ESORICS,2008, (1): 580-599,Loïc Duflot,https://doi.org/10.1007/978-3-540-88313-5_37,,Conference and Workshop Papers,
A New Empirical Study of Weak Backdoors,CP,2008, (1): 618-623,"Peter Gregory, Maria Fox, Derek Long",https://doi.org/10.1007/978-3-540-85958-1_53,,Conference and Workshop Papers,
A New Bound for an NP-Hard Subclass of 3-SAT Using Backdoors,SAT,2008, (1): 161-167,"Stephan Kottler, Michael Kaufmann, Carsten Sinz",https://doi.org/10.1007/978-3-540-79719-7_16,,Conference and Workshop Papers,
Computation of Renameable Horn Backdoors,SAT,2008, (1): 154-160,"Stephan Kottler, Michael Kaufmann, Carsten Sinz",https://doi.org/10.1007/978-3-540-79719-7_15,,Conference and Workshop Papers,
Backdoor Trees,AAAI,2008, (1): 363-368,"Marko Samer, Stefan Szeider",http://www.aaai.org/Library/AAAI/2008/aaai08-057.php,,Conference and Workshop Papers,
"Tradeoffs in Backdoors: Inconsistency Detection, Dynamic Simplification, and Preprocessing",ISAIM,2008, (1): 1,"Bistra Dilkina, Carla P. Gomes, Ashish Sabharwal",http://isaim2008.unl.edu/PAPERS/TechnicalProgram/ISAIM2008_0068_52aac45cbd48da479711d1c960b7be35.pdf,,Conference and Workshop Papers,
Detecting and Guarding against Kernel Backdoors through Packet Flow Differentials,IEICE Trans. Commun.,2007,90-B (10): 2638-2645,"Cheolho Lee, Kiwook Sohn",https://doi.org/10.1093/ietcom/e90-b.10.2638,,Journal Articles,
A Timing-Resistant Elliptic Curve Backdoor in RSA,Inscrypt,2007, (1): 427-441,"Adam L. Young, Moti Yung",https://doi.org/10.1007/978-3-540-79499-8_33,,Conference and Workshop Papers,
From Horn Strong Backdoor Sets to Ordered Strong Backdoor Sets,MICAI,2007, (1): 105-117,"Lionel Paris, Richard Ostrowski, Pierre Siegel, Lakhdar Sais",https://doi.org/10.1007/978-3-540-76631-5_11,,Conference and Workshop Papers,
Tradeoffs in the Complexity of Backdoor Detection,CP,2007, (1): 256-270,"Bistra Dilkina, Carla P. Gomes, Ashish Sabharwal",https://doi.org/10.1007/978-3-540-74970-7_20,,Conference and Workshop Papers,
Backdoor Sets of Quantified Boolean Formulas,SAT,2007, (1): 230-243,"Marko Samer, Stefan Szeider",https://doi.org/10.1007/978-3-540-72788-0_23,,Conference and Workshop Papers,
Matched Formulas and Backdoor Sets,SAT,2007, (1): 94-99,Stefan Szeider,https://doi.org/10.1007/978-3-540-72788-0_12,,Conference and Workshop Papers,
COTS and other electronic voting backdoors,Commun. ACM,2006,49 (11): 112,"Rebecca T. Mercuri, Vincent J. Lipsio, Beth Feehan",https://doi.org/10.1145/1167838.1167866,,Journal Articles,
Computing Horn Strong Backdoor Sets Thanks to Local Search,ICTAI,2006, (1): 139-143,"Lionel Paris, Richard Ostrowski, Pierre Siegel, Lakhdar Sais",https://doi.org/10.1109/ICTAI.2006.43,,Conference and Workshop Papers,
An Elliptic Curve Backdoor Algorithm for RSASSA,Information Hiding,2006, (1): 355-374,"Adam L. Young, Moti Yung",https://doi.org/10.1007/978-3-540-74124-4_24,,Conference and Workshop Papers,
Backdoor Sets for DLL Subsolvers,J. Autom. Reason.,2005,35 (1-3): 73-88,Stefan Szeider,https://doi.org/10.1007/s10817-005-9007-9,,Journal Articles,
A Space Efficient Backdoor in RSA and Its Applications,Selected Areas in Cryptography,2005, (1): 128-143,"Adam L. Young, Moti Yung",https://doi.org/10.1007/11693383_9,,Conference and Workshop Papers,
Backbones and Backdoors in Satisfiability,AAAI,2005, (1): 1368-1373,"Philip Kilby, John K. Slaney, Sylvie Thiébaux, Toby Walsh",http://www.aaai.org/Library/AAAI/2005/aaai05-217.php,,Conference and Workshop Papers,
Backdoor Creativity: Collaborative Creativity in Technology Supported Teams,COOP,2004, (1): 99-114,"Hillevi Sundholm, Henrik Artman, Robert Ramberg",https://hdl.handle.net/20.500.12015/3039,,Conference and Workshop Papers,
Remote Repair of Operating System State Using Backdoors,ICAC,2004, (1): 256-263,"Aniruddha Bohra, Iulian Neamtiu, Pascal Gallard, Florin Sultan, Liviu Iftode",https://doi.ieeecomputersociety.org/10.1109/ICAC.2004.49,,Conference and Workshop Papers,
Detecting Backdoor Sets with Respect to Horn and Binary Clauses,SAT,2004, (1): 1,"Naomi Nishimura, Prabhakar Ragde, Stefan Szeider",http://www.satisfiability.org/SAT04/programme/51.pdf,,Conference and Workshop Papers,
The Backdoor Key: A Path to Understanding Problem Hardness,AAAI,2004, (1): 124-130,"Yongshao Ruan, Henry A. Kautz, Eric Horvitz",http://www.aaai.org/Library/AAAI/2004/aaai04-020.php,,Conference and Workshop Papers,
A self-checking signature scheme for checking backdoor security attacks in Internet,J. High Speed Networks,2004,13 (4): 309-317,"Mohammed Fadle Abdulla, C. P. Ravikumar",http://content.iospress.com/articles/journal-of-high-speed-networks/jhs251,,Journal Articles,
Backdoor Attacks on Black-Box Ciphers Exploiting Low-Entropy Plaintexts,ACISP,2003, (1): 297-311,"Adam L. Young, Moti Yung",https://doi.org/10.1007/3-540-45067-X_26,,Conference and Workshop Papers,
Simple Backdoors for RSA Key Generation,CT-RSA,2003, (1): 403-416,"Claude Crépeau, Alain Slakmon",https://doi.org/10.1007/3-540-36563-X_28,,Conference and Workshop Papers,
Backdoors To Typical Case Complexity,IJCAI,2003, (1): 1173-1178,"Ryan Williams, Carla P. Gomes, Bart Selman",http://ijcai.org/Proceedings/03/Papers/168.pdf,,Conference and Workshop Papers,
Automatic Backdoor Analysis with Network Intrusion Detection System and Integrated Service Checker,IAW,2003, (1): 122-126,"Jukka Juslin, Teemupekka Virtanen",,,Conference and Workshop Papers,
Simple backdoors to RSA key generation,IACR Cryptol. ePrint Arch.,2002,2002 (1): 183,"Claude Crépeau, Alain Slakmon",http://eprint.iacr.org/2002/183,,Informal and Other Publications,
Detecting Backdoors,USENIX Security Symposium,2000, (1): 1,"Yin Zhang, Vern Paxson",https://www.usenix.org/conference/9th-usenix-security-symposium/detecting-backdoors,,Conference and Workshop Papers,
VeRe: Verification Guided Synthesis for Repairing Deep Neural Networks,,,,"Jianan Ma, Pengfei Yang, Jingyi Wang, Youcheng Sun, Cheng-Chao Huang, Zhen Wang",https://pure.manchester.ac.uk/ws/portalfiles/portal/277365839/icse2024-vere.pdf,,,
Detecting Backdoor Attacks via Layer-wise Feature Analysis,OpenReview,,,"Najeeb Moharram Jebreel, Yiming Li, Josep Domingo-Ferrer, Shu-Tao Xia",https://openreview.net/pdf/fceec6cedb5cbcb82297f2e5a861cdbf21aab7af.pdf,,,
Interpreting Graph Neural Networks via Unrevealed Causal Learning,OpenReview,,,"Wanyu Lin, Hao Lan, Hao Wang, Baochun Li",https://openreview.net/pdf/fb9f0d795f4b618d589d1616a5c449ceee2e4ff7.pdf,,,
Dynamic Backdoor Attacks Against Deep Neural Networks,,,,"Ahmed Salem, Rui Wen, Michael Backes, Shiqing Ma, Yang Zhang",https://openreview.net/pdf/f6dbabd06db1c1d23533d53f3104bfa4e62cc6ae.pdf,,,
Delve into the Layer Choice of BP-based Attribution Explanations,OpenReview,,,"Guanhua Zheng, Jitao Sang, Duo Zhang, Haonan Wang, Changsheng Xu",https://openreview.net/pdf/ede9e7279b3b7b6aa5fadfc6eb9089af295e9d09.pdf,,,
DP-InstaHide: Data Augmentations Provably Enhance Guarantees Against Dataset Manipulations,OpenReview,,,"Eitan Borgnia, Jonas Geiping, Valeriia Cherepanova, Liam H Fowl, Arjun Gupta, Amin Ghiasi, Furong Huang, Micah Goldblum, Tom Goldstein",https://openreview.net/pdf/eab859351425b5d5bc29e562ccfc1e05bc1eed0b.pdf,,,
GINN: Fast GPU-TEE Based Integrity for Neural Network Training,,,,"Aref Asvadishirehjini, Murat Kantarcioglu, Bradley A. Malin",https://openreview.net/pdf/ea90589cdf26d8d458a3e43a88f85b8f193e8ccd.pdf,,,
Defense Against Textual Backdoor Attacks with Token Substitution,,,,Anonymous,https://openreview.net/pdf/ea482696b4261bae0a9d0ae9170140b5da572433.pdf,,,
Test-time Backdoor Mitigation for Black-Box Large Language Models with Defensive Demonstrations,,,,Anonymous,https://openreview.net/pdf/ea184c3172e04013e691253253e31d9e0423e067.pdf,,,
Sself: Robust Federated Learning against Stragglers and Adversaries,,,,"Jungwuk Park, Dong-Jun Han, Minseok Choi, Jaekyun Moon",https://openreview.net/pdf/e201319c3e9b74cfed5468dd8cd7824b9c983cf2.pdf,,,
Watermarking PLMs by Combining Contrastive Learning with Weight Perturbation,,,,Anonymous,https://openreview.net/pdf/dfda36bbea5a5008843b1a583d2e078de8044bef.pdf,,,
BadActs: A Universal Backdoor Defense in the Activation Space,,,,Anonymous,https://openreview.net/pdf/d4349acf4f86ba4c5618cff756e2f3fe1c35554e.pdf,,,
Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning,,,,Anonymous,https://openreview.net/pdf/cb430b74dbacfd3d065e890cb0b602ea00b2d835.pdf,,,
Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning,,,,Anonymous,https://openreview.net/pdf/c30563077d19d6ff2edabf7081f9e928bce2d4c8.pdf,,,
COMBAT: Alternated Training for Near-Perfect Clean-Label Backdoor Attacks,OpenReview,,,"Tran Ngoc Huynh, Dang Minh Nguyen, Tung Pham, Anh Tuan Tran",https://openreview.net/pdf/c182fdd518fe8ec0aeafeb8d1b2b55bb8e46a463.pdf,,,
Class-wise Visual Explanations for Deep Neural Networks,OpenReview,,,"Minhao Cheng, Zeyu Qin",https://openreview.net/pdf/c14c2c1a813b067760015531ed6b79febf98a7bc.pdf,,,
Removing Backdoors in Pre-trained Models by Regularized Continual Pre-training,OpenReview,,,"Biru Zhu, Ganqu Cui, Yangyi Chen, Yujia Qin, Lifan Yuan, Chong Fu, Yangdong Deng, Zhiyuan Liu, Maosong Sun, Ming Gu",https://openreview.net/pdf/b90599e4935794e4f111f07737fb0e5a485048f3.pdf,,,
"Last One Standing: A Comparative Analysis of Security and Privacy of Soft Prompt Tuning, LoRA, and In-Context Learning",,,,Anonymous,https://openreview.net/pdf/b1b3fc9597c9d083eb8c9386d773412670c078cc.pdf,,,
Learning to Poison Large Language Models During Instruction Tuning,,,,Anonymous,https://openreview.net/pdf/af2f0f303094c2a1858a5c4217ac1401adb39d26.pdf,,,
Defending against Backdoor Attacks in Natural Language Generation,,,,Anonymous,https://openreview.net/pdf/a796a30221296cb8ad258a6078d3e60b9b2da5be.pdf,,,
Interventional Few-Shot Learning,,,,Lukasz Bala,https://openreview.net/pdf/a3e8e20306d3900c32c022334a220001fd1f7868.pdf,,,
Acquiring Clean Language Models from Backdoor Poisoned Datasets by Downscaling Frequency Space,,,,Anonymous,https://openreview.net/pdf/9eb71f0c75e3630c53671cf8b0175e95463726f1.pdf,,,
BAFFLE: TOWARDS RESOLVING FEDERATED LEARNING’S DILEMMA - THWARTING BACKDOOR  AND INFERENCE ATTACKS,,,,"Thien Duc Nguyen, Phillip Rieger, Hossein Yalame, Helen Möllering, Hossein Fereidooni, Samuel Marchal, Markus Miettinen, Azalia Mirhoseini, Ahmad-Reza Sadeghi, Thomas Schneider, Shaza Zeitouni",https://openreview.net/pdf/9a628e0b39be7ca1cceb483ece7a4c21ab42c640.pdf,,,
SlothBomb: Efficiency Poisoning Attack against Dynamic Neural Networks,OpenReview,,,"Simin Chen, Hanlin Chen, Mirazul Haque, Cong Liu, Wei Yang",https://openreview.net/pdf/97a39e9e6ae3c0c4d954e834fc2c336aa7f578ca.pdf,,,
DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference,,,,Anonymous,https://openreview.net/pdf/8fe95791f155f5411fed66b91542b726cb2644da.pdf,,,
Clean-Label Backdoor Attacks,,,,"Alexander Turner, Dimitris Tsipras, Aleksander Madry",https://openreview.net/pdf/8d05f33ab5ec0b3fa39117b269adfa15a0b98ddd.pdf,,,
MARNET: Backdoor Attacks against Value-Decomposition Multi-Agent Reinforcement Learning,OpenReview,,,"Yanjiao Chen, Zhicong Zheng, Xueluan Gong",https://openreview.net/pdf/8ba0a6b607f4f781d65a4894fd982984e823fe4e.pdf,,,
Feature Synchronization in Backdoor Attacks,OpenReview,,,"Zihan Guan, Lichao Sun, Mengnan Du, Ninghao Liu",https://openreview.net/pdf/846d8a53ff56f5072ec29c23b053e1c97cb5785f.pdf,,,
Certified Watermarks for Neural Networks,,,,"Arpit Amit Bansal, Ping-yeh Chiang, Michael Curry, Hossein Souri, Rama Chellappa, John P Dickerson, Rajiv Jain, Tom Goldstein",https://openreview.net/pdf/7ccb1fcac9aa5cf20a3356589c284c72d18fdfe8.pdf,,,
Navigation as Attackers Wish? Towards Building Robust Embodied Agents under Federated Learning,,,,Anonymous,https://openreview.net/pdf/7b6ec6afa809e143dbbe47406161fb38d94f866f.pdf,,,
EFFECTIVE FREQUENCY-BASED BACKDOOR ATTACKS WITH LOW POISONING RATIOS,OpenReview,,,"Danni Yuan, Mingda Zhang, Shaokui Wei, Shicai Yang, Baoyuan Wu",https://openreview.net/pdf/7b68b04ba1f19cef7554d236f5e813b1279f055b.pdf,,,
Exploring the Universal Vulnerability of Prompt-based Learning Paradigm,,,,Anonymous,https://openreview.net/pdf/7a6a313717022caaf178fbc4540f5a031a141e1f.pdf,,,
Are vision transformers more robust than CNNs for Backdoor attacks?,OpenReview,,,"Akshayvarun Subramanya, Aniruddha Saha, Soroush Abbasi Koohpayegani, Ajinkya Tejankar, Hamed Pirsiavash",https://openreview.net/pdf/769d621c491a52ad7e98f7efa69949a09d56f6af.pdf,,,
Trojans and Adversarial Examples: A Lethal Combination,,,,"Guanxiong Liu, Issa Khalil, Abdallah Khreishah, Hai Phan",https://openreview.net/pdf/6c70f3c04ce551e071f1ed5fb2fb7910bd437f23.pdf,,,
DBA: Distributed Backdoor Attacks against Federated Learning,,,,"Chulin Xie, Keli Huang, Pin-Yu Chen, Bo Li",https://openreview.net/pdf/61dc789b9f12be96506a23ddb7670ac132a51d6d.pdf,,,[![github](/images/github_icon.svg) AI-secure/DBA](https://github.com/AI-secure/DBA) + [![Papers with Code](/images/pwc_icon.svg) 1 community implementation](https://paperswithcode.com/paper/?openreview=rkgyS0VFvr)
MetaPoison:   Learning to craft adversarial poisoning examples via meta-learning,,,,"W. Ronny Huang, Jonas Geiping, Liam Fowl, Gavin Taylor, Tom Goldstein",https://openreview.net/pdf/5f78928102aaa8be2c8a7134096ffecf8733f894.pdf,,,https://github.com/2350532677/metapoison
Fatty and Skinny: A Joint Training Method of Watermark Encoder and Decoder,,,,"Sanghyun Hong, Mahmoud Mohammadi, Noseong Park",https://openreview.net/pdf/599b84fb70332752b375b408dd50c91869f727e9.pdf,,,
Just How Toxic is Data Poisoning?  A Benchmark for Backdoor and Data Poisoning Attacks,,,,"Avi Schwarzschild, Micah Goldblum, Arjun Gupta, John P Dickerson, Tom Goldstein",https://openreview.net/pdf/51c0801d766028729a95dc23201520e869fdf8ad.pdf,,,
A concealed poisoning attack to reduce deep neural networks’ robustness against adversarial samples,,,,"Junhao Zheng, Patrick P. K. Chan, Huiyang Chi, Zhimin He",https://openreview.net/pdf/4cbf1c97cc354f4b6756059848d0025a949bbf58.pdf,,,
ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger,,,,Anonymous,https://openreview.net/pdf/47d3a467f8e3f041e0fe8d1f79ac9846beb4454f.pdf,,,
Shape Features Improve General Model Robustness,,,,"Chaowei Xiao, Mingjie Sun, Haonan Qiu, Han Liu, Mingyan Liu, Bo Li",https://openreview.net/pdf/47c36d06005b6d0ed9d288f9d4b05eb26216ce52.pdf,,,
Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models,,,,Anonymous,https://openreview.net/pdf/46916795d86b937cebb38791eca216d44b3dd5bf.pdf,,,
CBAs: Character-level Backdoor Attacks against Chinese Language Models,,,,Anonymous,https://openreview.net/pdf/4111314dc03e4f62952815dc19a57e3fbdfd41a1.pdf,,,
Backdoor Learning on Sequence to Sequence Models,,,,Anonymous,https://openreview.net/pdf/40ad452618e5bc0a68fe39092b3e8cde8a07c19b.pdf,,,
PromptFix: Few-shot Backdoor Removal via Adversarial Prompt Tuning,,,,Anonymous,https://openreview.net/pdf/3bf872d57de7d7b5f34fc9ade66a1b519d597b8b.pdf,,,
BITE: Textual Backdoor Attacks with Iterative Trigger Injection,,,,Anonymous,https://openreview.net/pdf/31c0a60252cda8e778765ad8aa144494cea80b5a.pdf,,,
CR-UTP: Certified Robustness against Universal Text Perturbations,,,,Anonymous,https://openreview.net/pdf/2d85c4ce9d86cbcfbccb8a1784c534b2f31df171.pdf,,,
Feature Grinding: Efficient Backdoor Sanitation in Deep Neural Networks,OpenReview,,,"Nils Lukas, Charles Zhang, Florian Kerschbaum",https://openreview.net/pdf/2a957c2a6cdb20875c59543b3de24ba82906d16b.pdf,,,
Mitigating input-causing confounding in multimodal learning via the backdoor adjustment,CML4Impact,,,"Taro Makino, Krzysztof J. Geras, Kyunghyun Cho",https://openreview.net/pdf/25a1b2b97204d87e63e6d72fc3b177f4b313abe9.pdf,,,
Generalizable Multi-Relational Graph Representation Learning:  A Message Intervention Approach,OpenReview,,,"Haoran Xin, Xinjiang Lu, Tong Xu, Dejing Dou, Hui Xiong",https://openreview.net/pdf/255644c9dee71e168941ff9a1afc5ab649533749.pdf,,,
Backdoor Attacks on Multilingual Machine Translation,,,,Anonymous,https://openreview.net/pdf/22729d5cbee3df7d426762c40bbe68861e26e326.pdf,,,
RVFR: Robust Vertical Federated Learning via Feature Subspace Recovery,OpenReview,,,"Jing Liu, Chulin Xie, Krishnaram Kenthapadi, Oluwasanmi O Koyejo, Bo Li",https://openreview.net/pdf/218cac5cc281bc853458722ad05a5e24ca21d133.pdf,,,
MEDIC: Model Backdoor Removal by Importance Driven Cloning,OpenReview,,,"Qiuling Xu, Guanhong Tao, Jean Honorio, Yingqi Liu, Shengwei An, Guangyu Shen, Siyuan Cheng, Xiangyu Zhang",https://openreview.net/pdf/2086e2dbd11b82dcaa26661291bcccf3c8081dc9.pdf,,,
BAAAN: Backdoor Attacks Against Auto-encoder and GAN-Based Machine Learning Models,,,,"Ahmed Salem, Yannick Sautter, Michael Backes, Mathias Humbert, Yang Zhang",https://openreview.net/pdf/18dba5149a566e40050818492fbee983f949b06e.pdf,,,
Does Adversarial Robustness Really Imply Backdoor Vulnerability?,OpenReview,,,"Yinghua Gao, Dongxian Wu, Jingfeng Zhang, Shu-Tao Xia, Gang Niu, Masashi Sugiyama",https://openreview.net/pdf/149e7de65f8fe1c4739d000b609d9b3a4db3148b.pdf,,,
Turning a Curse Into a Blessing: Enabling Data-Free Backdoor Unlearning via Stabilized Model Inversion,OpenReview,,,"Si Chen, Yi Zeng, Won Park, Tianhao Wang, Xun Chen, Lingjuan Lyu, Zhuoqing Mao, Ruoxi Jia",https://openreview.net/pdf/1324ba3b9a0f28c0414ba3a49258c5b38ca5213b.pdf,,,
Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks,,,,Anonymous,https://openreview.net/pdf/09ec283781ceeabec1fbbbfda26653cf25e8db09.pdf,,,
Characterizing convolutional neural networks with one-pixel signature,,,,"Shanjiaoyang Huang, Weiqi Peng, Zhuowen Tu",https://openreview.net/pdf/02454a76ff420d6bbda4e733bf172561c25c7e44.pdf,,,
SSDA: Secure Source-Free Domain Adaptation,,,,"Sabbir Ahmed, Abdullah Al Arafat, Mamshad Nayeem Rizve, Rahim Hossain, Zhishan Guo, Adnan Siraj Rakin",https://openaccess.thecvf.com/content/ICCV2023/html/Ahmed_SSDA_Secure_Source-Free_Domain_Adaptation_ICCV_2023_paper.html,,,
"LIRA: Learnable, Imperceptible and Robust Backdoor Attacks",,,,"Khoa D Doan, Yingjie Lao, Weijie Zhao, Ping Li",https://openaccess.thecvf.com/content/ICCV2021/papers/Doan_LIRA_Learnable_Imperceptible_and_Robust_Backdoor_Attacks_ICCV_2021_paper.pdf,,,
 Curse or Redemption? How Data Heterogeneity Affects the Robustness of Federated Learning,,,,Feng Yan,https://ojs.aaai.org/index.php/AAAI/article/view/17291/17098,,,
Stealthy and Flexible Trojan in Deep Learning Framework,,,,"Yajie Wang, Kongyang Chen, Yu-an Tan, Shuxin Huang, Wencong Ma, Yuanzhang Li",https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9747995,,,
A Feature-Based On-Line Detector to Remove Adversarial-Backdoors by Iterative Demarcation,,,,"Hao Fu, Akshaj Kumar Veldanda, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami",https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9673744,,,
Economics Assistant for Robustness Checks (EconARC): Identifying Confounders from Causal Knowledge Graphs,,,,"Fiona Anting Tan, See-Kiong Ng",https://hozo.jp/ISWC2023_PD-Industry-proc/ISWC2023_paper_414.pdf,,,
CASSOCK: Viable Backdoor Attacks against DNN in the Wall of Source-Specific Backdoor Defenses,,,,"Shang Wang, Yansong Gao, Anmin Fu, Zhi Zhang, Yuqing Zhang, Willy Susilo, Dongxi Liu",https://dl.acm.org/doi/abs/10.1145/3579856.3582829,,,
Opportunistic Backdoor Attacks: Exploring Human-imperceptible Vulnerabilities on Speech Recognition Systems,,,,Zhiping Cai,https://dl.acm.org/doi/abs/10.1145/3503161.3548261,,,
Risk-optimized Outlier Removal for Robust Point Cloud Classification,,,,"Xinke Li, Junchi Lu, Henghui Ding, Changsheng Sun, Joey Tianyi Zhou, Yeow Meng Chee",https://arxiv.org/pdf/2307.10875,,,
"Backdoor Attacks and Defenses in Federated Learning: Survey, Challenges and Future Research Directions",,,,Tuan Minh Nguyen,https://arxiv.org/pdf/2303.02213.pdf,,,
HufuNet: Embedding the Left Piece as Watermark and Keeping the Right Piece for Ownership Verification in Deep Neural Networks.,,,,"Peizhuo Lv, Li Pan, Shengzhi Zhang, Kai Chen, Ruigang Liang, Yue Zhao, Li Yingjiu",https://arxiv.org/pdf/2103.13628,,,
Feature Partition Aggregation: A Fast Certified Defense Against a Union of Sparse Adversarial Attacks,,,,"Zayd Hammoudeh, Daniel Lowd",https://arxiv.org/abs/2302.11628,,,
GPTs Don’t Keep Secrets: Searching for Backdoor Watermark Triggers in Autoregressive Language Models,,,,"Evan Lucas, Timothy Havens",https://aclanthology.org/2023.trustnlp-1.21.pdf,,,
Context-aware Information-theoretic Causal De-biasing for Interactive Sequence Labeling,,,,"Junda Wu, Rui Wang, Tong Yu, Ruiyi Zhang, Handong Zhao, Shuai Li, Ricardo Henao, Ani Nenkova",https://aclanthology.org/2022.findings-emnlp.251.pdf,,,
Backdoor DNFs,,,,Stefan Szeider,,,,
Can adversarial weight perturbations inject neural backdoors,,,,Adarsh Kumar,,,,
GangSweep: Sweep out Neural Backdoors by GAN,,,,Cong Wang,,,,
Interventional Few-Shot Learning,,,,Hanwang Zhang,,,,
Invisible Poison: A Blackbox Clean Label Backdoor Attack to Deep Neural Networks,,,,"RUI NING, Jiang Li, Chunsheng Xin, Hong Wu",,,,
LoneNeuron: a Highly-effective Feature-domain Neural Trojan using Invisible and Polymorphic Watermarks,,,,"Zeyan Liu, Fengjun Li, Zhu Li, Bo Luo",,,,
On the Trade-off between Adversarial and Backdoor Robustness,,,,"Zheng-Xin Weng, Yan-Ting Lee, Shan-Hung Wu",,,,
Opportunistic Backdoor Attacks: Exploring Human-imperceptible Vulnerabilities on Speech Recognition Systems,,,,Tongqing Zhou,,,,
Homophily-adjusted social influence estimation,arXiv,2024,2405.18413,"Hanh T. D. Pham, Daniel K. Sewell",https://arxiv.org/abs/2405.18413,05,,https://github.com/hanhtdpham/hanam
Fast-FedUL: A Training-Free Federated Unlearning with Provable Skew Resilience,arXiv,2024,2405.18040,"Thanh Trung Huynh, Trong Bang Nguyen, Phi Le Nguyen, Thanh Tam Nguyen, Matthias Weidlich, Quoc Viet Hung Nguyen, Karl Aberer",https://arxiv.org/abs/2405.18040,05,Accepted in ECML PKDD 2024,https://github.com/thanhtrunghuynh93/fastFedUL
Cross-Context Backdoor Attacks against Graph Prompt Learning,arXiv,2024,2405.17984,"Xiaoting Lyu, Yufei Han, Wei Wang, Hangwei Qian, Ivor Tsang, Xiangliang Zhang",https://arxiv.org/abs/2405.17984,05,Accepted by KDD 2024,
Towards Unified Robustness Against Both Backdoor and Adversarial Attacks,arXiv,2024,2405.17929,"Zhenxing Niu, Yuyao Sun, Qiguang Miao, Rong Jin, Gang Hua",https://arxiv.org/abs/2405.17929,05,,
Magnitude-based Neuron Pruning for Backdoor Defens,arXiv,2024,2405.17750,"Nan Li, Haoyu Jiang, Ping Yi",https://arxiv.org/abs/2405.17750,05,,
Rethinking Pruning for Backdoor Mitigation: An Optimization Perspective,arXiv,2024,2405.17746,"Nan Li, Haiyang Yu, Ping Yi",https://arxiv.org/abs/2405.17746,05,,
Ferrari: Federated Feature Unlearning via Optimizing Feature Sensitivity,arXiv,2024,2405.17462,"Hanlin Gu, WinKent Ong, Chee Seng Chan, Lixin Fan",https://arxiv.org/abs/2405.17462,05,"TLDR: The need for a ""right to be forgotten"" in Federated Learning has led to the development of the Ferrari framework, which efficiently unlearns sensitive features using a Lipschitz continuity-based metric, proven effective in extensive testing",
TrojFM: Resource-efficient Backdoor Attacks against Very Large Foundation Models,arXiv,2024,2405.16783,"Yuzhou. Nie, Yanting. Wang, Jinyuan. Jia, Michael J. De Lucia, Nathaniel D. Bastian, Wenbo. Guo, Dawn. Song",https://arxiv.org/abs/2405.16783,05,,
"Partial train and isolate, mitigate backdoor attack",arXiv,2024,2405.16488,"Yong Li, Han Gao",https://arxiv.org/abs/2405.16488,05,"9 pages, 2 figures",
Breaking the False Sense of Security in Backdoor Defense through Re-Activation Attack,arXiv,2024,2405.16134,"Mingli Zhu, Siyuan Liang, Baoyuan Wu",https://arxiv.org/abs/2405.16134,05,,
Mitigating Backdoor Attack by Injecting Proactive Defensive Backdoor,arXiv,2024,2405.16112,"Shaokui Wei, Hongyuan Zha, Baoyuan Wu",https://arxiv.org/abs/2405.16112,05,"13 pages, 5 figures and 5 tables",
BadGD: A unified data-centric framework to identify gradient descent vulnerabilities,arXiv,2024,2405.15979,"Chi-Hua Wang, Guang Cheng",https://arxiv.org/abs/2405.15979,05,"25 pages, 1 figure",
BDetCLIP: Multimodal Prompting Contrastive Test-Time Backdoor Detection,arXiv,2024,2405.15269,"Yuwei Niu, Shuo He, Qi Wei, Feng Liu, Lei Feng",https://arxiv.org/abs/2405.15269,05,,
Cooperative Backdoor Attack in Decentralized Reinforcement Learning with Theoretical Guarantee,arXiv,2024,2405.15245,"Mengtong Gao, Yifei Zou, Zuyuan Zhang, Xiuzhen Cheng, Dongxiao Yu",https://arxiv.org/abs/2405.15245,05,,
Are You Copying My Prompt? Protecting the Copyright of Vision Prompt for VPaaS via Watermark,arXiv,2024,2405.15161,"Huali Ren, Anli Yan, Chong-zhi Gao, Hongyang Yan, Zhenxin Zhang, Jin Li",https://arxiv.org/abs/2405.15161,05,"11 pages, 7 figures,",
Unified Neural Backdoor Removal with Only Few Clean Samples through Unlearning and Relearning,arXiv,2024,2405.14781,"Nay Myat Min, Long H. Pham, Jun Sun",https://arxiv.org/abs/2405.14781,05,,
Towards Imperceptible Backdoor Attack in Self-supervised Learning,arXiv,2024,2405.14672,"Hanrong Zhang, Zhenting Wang, Tingxu Han, Mingyu Jin, Chenlu Zhan, Mengnan Du, Hongwei Wang, Shiqing Ma",https://arxiv.org/abs/2405.14672,05,,https://github.com/Zhang-Henry/IMPERATIVE
DeepNcode: Encoding-Based Protection against Bit-Flip Attacks on Neural Networks,arXiv,2024,2405.13891,"Patrik Velčický, Jakub Breier, Xiaolu Hou, Mladen Kovačević",https://arxiv.org/abs/2405.13891,05,,
TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in Large Language Models,arXiv,2024,2405.13401,"Pengzhou Cheng, Yidong Ding, Tianjie Ju, Zongru Wu, Wei Du, Ping Yi, Zhuosheng Zhang, Gongshen Liu",https://arxiv.org/abs/2405.13401,05,"18 pages, 13 figures, 4 tables",
Interactive Simulations of Backdoors in Neural Networks,arXiv,2024,2405.13217,"Peter Bajcsy, Maxime Bros",https://arxiv.org/abs/2405.13217,05,"13 pages, 7 figures, 1 Table",
EmInspector: Combating Backdoor Attacks in Federated Self-Supervised Learning Through Embedding Inspection,arXiv,2024,2405.13080,"Yuwen Qian, Shuchi Wu, Kang Wei, Ming Ding, Di Xiao, Tao Xiang, Chuan Ma, Song Guo",https://arxiv.org/abs/2405.13080,05,"18 pages, 12 figures",https://github.com/ShuchiWu/EmInspector
Rethinking the Vulnerabilities of Face Recognition Systems:From a Practical Perspective,arXiv,2024,2405.12786,"Jiahao Chen, Zhiqiang Shen, Yuwen Pu, Chunyi Zhou, Shouling Ji",https://arxiv.org/abs/2405.12786,05,19 pages,
A Stealthy Backdoor Attack for Without-Label-Sharing Split Learning,arXiv,2024,2405.12751,"Yuwen Pu, Zhuoyuan Ding, Jiahao Chen, Chunyi Zhou, Qingming Li, Chunqiang Hu, Shouling Ji",https://arxiv.org/abs/2405.12751,05,15 pages,
Nearest is Not Dearest: Towards Practical Defense against Quantization-conditioned Backdoor Attacks,arXiv,2024,2405.12725,"Boheng Li, Yishuo Cai, Haowei Li, Feng Xue, Zhifeng Li, Yiming Li",https://arxiv.org/abs/2405.12725,05,"Accepted to CVPR 2024. 19 pages, 9 figures",https://github.com/AntigoneRandy/QuantBackdoor_EFRAP
How to Train a Backdoor-Robust Model on a Poisoned Dataset without Auxiliary Data?,arXiv,2024,2405.12719,"Yuwen Pu, Jiahao Chen, Chunyi Zhou, Zhou Feng, Qingming Li, Chunqiang Hu, Shouling Ji",https://arxiv.org/abs/2405.12719,05,"13 pages, under review",
SEEP: Training Dynamics Grounds Latent Representation Search for Mitigating Backdoor Poisoning Attacks,arXiv,2024,2405.11575,"Xuanli He, Qiongkai Xu, Jun Wang, Benjamin I. P. Rubinstein, Trevor Cohn",https://arxiv.org/abs/2405.11575,05,accepted to TACL,
An Invisible Backdoor Attack Based On Semantic Feature,arXiv,2024,2405.11551,Yangming Chen,https://arxiv.org/abs/2405.11551,05,,
BOSC: A Backdoor-based Framework for Open Set Synthetic Image Attribution,arXiv,2024,2405.11491,"Jun Wang, Benedetta Tondi, Mauro Barni",https://arxiv.org/abs/2405.11491,05,,
Measuring Impacts of Poisoning on Model Parameters and Embeddings for Large Language Models of Code,arXiv,2024,2405.11466,"Aftab Hussain, Md Rafiqul Islam Rabin, Mohammad Amin Alipour",https://arxiv.org/abs/2405.11466,05,"This work has been accepted at the 1st ACM International Conference on AI-powered Software (AIware), co-located with the ACM International Conference on the Foundations of Software Engineering (FSE) 2024, Porto de Galinhas, Brazil. arXiv admin note: substantial text overlap with arXiv:2402.12936",
BadActs: A Universal Backdoor Defense in the Activation Space,arXiv,2024,2405.11227,"Biao Yi, Sishuo Chen, Yiming Li, Tong Li, Baolei Zhang, Zheli Liu",https://arxiv.org/abs/2405.11227,05,ACL2024 Findings,
Rethinking Graph Backdoor Attacks: A Distribution-Preserving Perspective,arXiv,2024,2405.10757,"Zhiwei Zhang, Minhua Lin, Enyan Dai, Suhang Wang",https://arxiv.org/abs/2405.10757,05,,
Not All Prompts Are Secure: A Switchable Backdoor Attack Against Pre-trained Vision Transformers,arXiv,2024,2405.10612,"Sheng Yang, Jiawang Bai, Kuofeng Gao, Yong Yang, Yiming Li, Shu-tao Xia",https://arxiv.org/abs/2405.10612,05,,https://github.com/20000yshust/SWARM
IBD-PSC: Input-level Backdoor Detection via Parameter-oriented Scaling Consistency,arXiv,2024,2405.09786,"Linshan Hou, Ruili Feng, Zhongyun Hua, Wei Luo, Leo Yu Zhang, Yiming Li",https://arxiv.org/abs/2405.09786,05,"Accepted to ICML 2024, 29 pages",
Mask-based Invisible Backdoor Attacks on Object Detection,arXiv,2024,2405.09550,Jeongjin Shin,https://arxiv.org/abs/2405.09550,05,"7 pages, 3 figures",
Backdoor Removal for Generative Large Language Models,arXiv,2024,2405.07667,"Haoran Li, Yulin Chen, Zihao Zheng, Qi Hu, Chunkit Chan, Heshan Liu, Yangqiu Song",https://arxiv.org/abs/2405.07667,05,,
Concealing Backdoor Model Updates in Federated Learning by Trigger-Optimized Data Poisoning,arXiv,2024,2405.06206,"Yujie Zhang, Neil Gong, Michael K. Reiter",https://arxiv.org/abs/2405.06206,05,,
Poisoning-based Backdoor Attacks for Arbitrary Target Label with Positive Triggers,arXiv,2024,2405.05573,"Binxiao Huang, Jason Chun Lok, Chang Liu, Ngai Wong",https://arxiv.org/abs/2405.05573,05,,
Towards Robust Physical-world Backdoor Attacks on Lane Detection,arXiv,2024,2405.05553,"Xinwei Zhang, Aishan Liu, Tianyuan Zhang, Siyuan Liang, Xianglong Liu",https://arxiv.org/abs/2405.05553,05,,
Explanation as a Watermark: Towards Harmless and Multi-bit Model Ownership Verification via Watermarking Feature Attribution,arXiv,2024,2405.04825,"Shuo Shao, Yiming Li, Hongwei Yao, Yiling He, Zhan Qin, Kui Ren",https://arxiv.org/abs/2405.04825,05,,
Watermarking Neuromorphic Brains: Intellectual Property Protection in Spiking Neural Networks,arXiv,2024,2405.04049,"Hamed Poursiami, Ihsen Alouani, Maryam Parsa",https://arxiv.org/abs/2405.04049,05,"7 pages, 7 figures",
Unlearning Backdoor Attacks through Gradient-Based Model Pruning,arXiv,2024,2405.03918,"Kealan Dunnett, Reza Arablouei, Dimity Miller, Volkan Dedeoglu, Raja Jurdak",https://arxiv.org/abs/2405.03918,05,,
BadFusion: 2D-Oriented Backdoor Attacks against 3D Object Detection,arXiv,2024,2405.03884,"Saket S. Chaturvedi, Lan Zhang, Wenbin Zhang, Pan He, Xiaoyong Yuan",https://arxiv.org/abs/2405.03884,05,Accepted at IJCAI 2024 Conference,
DarkFed: A Data-Free Backdoor Attack in Federated Learning,arXiv,2024,2405.03299,"Minghui Li, Wei Wan, Yuxuan Ning, Shengshan Hu, Lulu Xue, Leo Yu Zhang, Yichen Wang",https://arxiv.org/abs/2405.03299,05,This paper has been accepted by IJCAI 2024,
Backdoor-based Explainable AI Benchmark for High Fidelity Evaluation of Attribution Methods,arXiv,2024,2405.02344,"Peiyu Yang, Naveed Akhtar, Jiantong Jiang, Ajmal Mian",https://arxiv.org/abs/2405.02344,05,,
Lazy Layers to Make Fine-Tuned Diffusion Models More Traceable,arXiv,2024,2405.00466,"Haozhe Liu, Wentian Zhang, Bing Li, Bernard Ghanem, Jürgen Schmidhuber",https://arxiv.org/abs/2405.00466,05,,
Transferring Troubles: Cross-Lingual Transferability of Backdoor Attacks in LLMs with Instruction Tuning,arXiv,2024,2404.19597,"Xuanli He, Jun Wang, Qiongkai Xu, Pasquale Minervini, Pontus Stenetorp, Benjamin I. P. Rubinstein, Trevor Cohn",https://arxiv.org/abs/2404.19597,04,work in progress,
Let's Focus: Focused Backdoor Attack against Federated Transfer Learning,arXiv,2024,2404.19420,"Marco Arazzi, Stefanos Koffas, Antonino Nocera, Stjepan Picek",https://arxiv.org/abs/2404.19420,04,,
Physical Backdoor: Towards Temperature-based Backdoor Attacks in the Physical World,arXiv,2024,2404.19417,"Wen Yin, Jian Lou, Pan Zhou, Yulai Xie, Dan Feng, Yuhua Sun, Tailai Zhang, Lichao Sun",https://arxiv.org/abs/2404.19417,04,"To appear in CVPR 2024.11pages, 8 figures and 4 tables",
Assessing Cybersecurity Vulnerabilities in Code Large Language Models,arXiv,2024,2404.18567,"Md Imran Hossen, Jianyi Zhang, Yinzhi Cao, Xiali Hei",https://arxiv.org/abs/2404.18567,04,,
Beyond Traditional Threats: A Persistent Backdoor Attack on Federated Learning,arXiv,2024,2404.17617,"Tao Liu, Yuhang Zhang, Zhu Feng, Zhiqin Yang, Chen Xu, Dapeng Man, Wu Yang",https://arxiv.org/abs/2404.17617,04,,https://github.com/PhD-TaoLiu/FCBA
Competition Report: Finding Universal Jailbreak Backdoors in Aligned LLMs,arXiv,2024,2404.14461,"Javier Rando, Francesco Croce, Kryštof Mitka, Stepan Shabalin, Maksym Andriushchenko, Nicolas Flammarion, Florian Tramèr",https://arxiv.org/abs/2404.14461,04,Competition Report,
Towards Robust Trajectory Representations: Isolating Environmental Confounders with Causal Learning,arXiv,2024,2404.14073,"Kang Luo, Yuanshao Zhu, Wei Chen, Kun Wang, Zhengyang Zhou, Sijie Ruan, Yuxuan Liang",https://arxiv.org/abs/2404.14073,04,The paper has been accepted by IJCAI 2024,
CloudFort: Enhancing Robustness of 3D Point Cloud Classification Against Backdoor Attacks via Spatial Partitioning and Ensemble Prediction,arXiv,2024,2404.14042,"Wenhao Lan, Yijun Yang, Haihua Shen, Shan Li",https://arxiv.org/abs/2404.14042,04,,
Dual Model Replacement:invisible Multi-target Backdoor Attack based on Federal Learning,arXiv,2024,2404.13946,"Rong Wang, Guichen Zhou, Mingjun Gao, Yunpeng Xiao",https://arxiv.org/abs/2404.13946,04,,
Concept Arithmetics for Circumventing Concept Inhibition in Diffusion Models,arXiv,2024,2404.13706,"Vitali Petsiuk, Kate Saenko",https://arxiv.org/abs/2404.13706,04,,
Trojan Detection in Large Language Models: Insights from The Trojan Detection Challenge,arXiv,2024,2404.13660,"Narek Maloyan, Ekansh Verma, Bulat Nutfullin, Bislan Ashinov",https://arxiv.org/abs/2404.13660,04,,
Backdoor Attacks and Defenses on Semantic-Symbol Reconstruction in Semantic Communications,arXiv,2024,2404.13279,"Yuan Zhou, Rose Qingyang Hu, Yi Qian",https://arxiv.org/abs/2404.13279,04,This paper has been accepted by IEEE ICC 2024,
Physical Backdoor Attack can Jeopardize Driving with Vision-Large-Language Models,arXiv,2024,2404.12916,"Zhenyang Ni, Rui Ye, Yuxi Wei, Zhen Xiang, Yanfeng Wang, Siheng Chen",https://arxiv.org/abs/2404.12916,04,,
LSP Framework: A Compensatory Model for Defeating Trigger Reverse Engineering via Label Smoothing Poisoning,arXiv,2024,2404.12852,"Beichen Li, Yuanfang Guo, Heqi Peng, Yangxi Li, Yunhong Wang",https://arxiv.org/abs/2404.12852,04,,
A Clean-graph Backdoor Attack against Graph Convolutional Networks with Poisoned Label Only,arXiv,2024,2404.12704,"Jiazhu Dai, Haoyu Sun",https://arxiv.org/abs/2404.12704,04,,
Decomposing and Editing Predictions by Modeling Model Computation,arXiv,2024,2404.11534,"Harshay Shah, Andrew Ilyas, Aleksander Madry",https://arxiv.org/abs/2404.11534,04,,https://github.com/MadryLab/modelcomponents
Detector Collapse: Backdooring Object Detection to Catastrophic Overload or Blindness,arXiv,2024,2404.11357,"Hangtao Zhang, Shengshan Hu, Yichen Wang, Leo Yu Zhang, Ziqi Zhou, Xianlong Wang, Yanjun Zhang, Chao Chen",https://arxiv.org/abs/2404.11357,04,Accepted by IJCAI-24,
The Victim and The Beneficiary: Exploiting a Poisoned Model to Train a Clean Model on Poisoned Data,arXiv,2024,2404.11265,"Zixuan Zhu, Rui Wang, Cong Zou, Lihua Jing",https://arxiv.org/abs/2404.11265,04,"13 pages, 6 figures, published to ICCV",https://github.com/Zixuan-Zhu/VaB
Causal Deconfounding via Confounder Disentanglement for Dual-Target Cross-Domain Recommendation,arXiv,2024,2404.11180,"Jiajie Zhu, Yan Wang, Feng Zhu, Zhu Sun",https://arxiv.org/abs/2404.11180,04,,
SpamDam: Towards Privacy-Preserving and Adversary-Resistant SMS Spam Detection,arXiv,2024,2404.09481,"Yekai Li, Rufan Zhang, Wenxin Rong, Xianghang Mi",https://arxiv.org/abs/2404.09481,04,,
On the critical path to implant backdoors and the effectiveness of potential mitigation techniques: Early learnings from XZ,arXiv,2024,2404.08987,"Mario Lins, René Mayrhofer, Michael Roland, Daniel Hofer, Martin Schwaighofer",https://arxiv.org/abs/2404.08987,04,,
Backdoor Contrastive Learning via Bi-level Trigger Optimization,arXiv,2024,2404.07863,"Weiyu Sun, Xinyu Zhang, Hao Lu, Yingcong Chen, Ting Wang, Jinghui Chen, Lu Lin",https://arxiv.org/abs/2404.07863,04,Accepted by ICLR 2024,https://github.com/SWY666/SSL-backdoor-BLTO
Fragile Model Watermark for integrity protection: leveraging boundary volatility and sensitive sample-pairing,arXiv,2024,2404.07572,"ZhenZhe Gao, Zhenjun Tang, Zhaoxia Yin, Baoyuan Wu, Yue Lu",https://arxiv.org/abs/2404.07572,04,The article has been accepted by IEEE International Conference on Multimedia and Expo 2024,
How to Craft Backdoors with Unlabeled Data Alone?,arXiv,2024,2404.06694,"Yifei Wang, Wenhan Ma, Stefanie Jegelka, Yisen Wang",https://arxiv.org/abs/2404.06694,04,Accepted at ICLR 2024 Workshop on Navigating and Addressing Data Problems for Foundation Models (DPFM),https://github.com/PKU-ML/nlb
Severity Controlled Text-to-Image Generative Model Bias Manipulation,arXiv,2024,2404.02530,"Jordan Vice, Naveed Akhtar, Richard Hartley, Ajmal Mian",https://arxiv.org/abs/2404.02530,04,"This research was supported by National Intelligence and Security Discovery Research Grants (project# NS220100007), funded by the Department of Defence Australia",
Exploring Backdoor Vulnerabilities of Chat Models,arXiv,2024,2404.02406,"Yunzhuo Hao, Wenkai Yang, Yankai Lin",https://arxiv.org/abs/2404.02406,04,Code and data are available at https://github.com/hychaochao/Chat-Models-Backdoor-Attacking,https://github.com/hychaochao/Chat-Models-Backdoor-Attacking
Backdoor Attack on Multilingual Machine Translation,arXiv,2024,2404.02393,"Jun Wang, Qiongkai Xu, Xuanli He, Benjamin I. P. Rubinstein, Trevor Cohn",https://arxiv.org/abs/2404.02393,04,NAACL main long paper,
Two Heads are Better than One: Nested PoE for Robust Defense Against Multi-Backdoors,arXiv,2024,2404.02356,"Victoria Graf, Qin Liu, Muhao Chen",https://arxiv.org/abs/2404.02356,04,Accepted by NAACL 2024 Main Conference,
Privacy Backdoors: Enhancing Membership Inference through Poisoning Pre-trained Models,arXiv,2024,2404.01231,"Yuxin Wen, Leo Marchyok, Sanghyun Hong, Jonas Geiping, Tom Goldstein, Nicholas Carlini",https://arxiv.org/abs/2404.01231,04,,
Poisoning Decentralized Collaborative Recommender System and Its Countermeasures,arXiv,2024,2404.01177,"Ruiqi Zheng, Liang Qu, Tong Chen, Kai Zheng, Yuhui Shi, Hongzhi Yin",https://arxiv.org/abs/2404.01177,04,,
UFID: A Unified Framework for Input-level Backdoor Detection on Diffusion Models,arXiv,2024,2404.01101,"Zihan Guan, Mengxuan Hu, Sheng Li, Anil Vullikanti",https://arxiv.org/abs/2404.01101,04,"20 pages,18 figures",https://github.com/GuanZihan/official_UFID
Privacy Backdoors: Stealing Data with Corrupted Pretrained Models,arXiv,2024,2404.00473,"Shanglun Feng, Florian Tramèr",https://arxiv.org/abs/2404.00473,04,Code at https://github.com/ShanglunFengatETHZ/PrivacyBackdoor,https://github.com/ShanglunFengatETHZ/PrivacyBackdoor
Shortcuts Arising from Contrast: Effective and Covert Clean-Label Attacks in Prompt-Based Learning,arXiv,2024,2404.00461,"Xiaopeng Xie, Ming Yan, Xiwen Zhou, Chenlong Zhao, Suli Wang, Yong Zhang, Joey Tianyi Zhou",https://arxiv.org/abs/2404.00461,04,"10 pages, 6 figures, conference",
A Backdoor Approach with Inverted Labels Using Dirty Label-Flipping Attacks,arXiv,2024,2404.00076,Orson Mengara,https://arxiv.org/abs/2404.00076,04,"Accept by ""IEEE Access"" let's take a look at our global approach to the DNN(s) model(s) deployment chain in production: Danger NLP-Speech (Trigger universal approach)",
De-confounded Data-free Knowledge Distillation for Handling Distribution Shifts,arXiv,2024,2403.19539,"Yuzheng Wang, Dingkang Yang, Zhaoyu Chen, Yang Liu, Siao Liu, Wenqiang Zhang, Lihua Zhang, Lizhe Qi",https://arxiv.org/abs/2403.19539,03,Accepted by CVPR24,
Spikewhisper: Temporal Spike Backdoor Attacks on Federated Neuromorphic Learning over Low-power Devices,arXiv,2024,2403.18607,"Hanqing Fu, Gaolei Li, Jun Wu, Jianhua Li, Xi Lin, Kai Zhou, Yuchen Liu",https://arxiv.org/abs/2403.18607,03,,
Manipulating Neural Path Planners via Slight Perturbations,arXiv,2024,2403.18256,"Zikang Xiong, Suresh Jagannathan",https://arxiv.org/abs/2403.18256,03,,
Securing GNNs: Explanation-Based Identification of Backdoored Training Graphs,arXiv,2024,2403.18136,"Jane Downer, Ren Wang, Binghui Wang",https://arxiv.org/abs/2403.18136,03,,
Evaluating the Efficacy of Prompt-Engineered Large Multimodal Models Versus Fine-Tuned Vision Transformers in Image-Based Security Applications,arXiv,2024,2403.17787,"Fouad Trad, Ali Chehab",https://arxiv.org/abs/2403.17787,03,,
LOTUS: Evasive and Resilient Backdoor Attacks through Sub-Partitioning,arXiv,2024,2403.17188,"Siyuan Cheng, Guanhong Tao, Yingqi Liu, Guangyu Shen, Shengwei An, Shiwei Feng, Xiangzhe Xu, Kaiyuan Zhang, Shiqing Ma, Xiangyu Zhang",https://arxiv.org/abs/2403.17188,03,IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2024),https://github.com/Megum1/LOTUS
Task-Agnostic Detector for Insertion-Based Backdoor Attacks,arXiv,2024,2403.17155,"Weimin Lyu, Xiao Lin, Songzhu Zheng, Lu Pang, Haibin Ling, Susmit Jha, Chao Chen",https://arxiv.org/abs/2403.17155,03,Findings of NAACL 2024,
Revealing Vulnerabilities of Neural Networks in Parameter Learning and Defense Against Explanation-Aware Backdoors,arXiv,2024,2403.16569,"Md Abdul Kadir, GowthamKrishna Addluri, Daniel Sonntag",https://arxiv.org/abs/2403.16569,03,,
Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion,arXiv,2024,2403.16365,"Hossein Souri, Arpit Bansal, Hamid Kazemi, Liam Fowl, Aniruddha Saha, Jonas Geiping, Andrew Gordon Wilson, Rama Chellappa, Tom Goldstein, Micah Goldblum",https://arxiv.org/abs/2403.16365,03,,https://github.com/hsouri/GDP
Unlearning Backdoor Threats: Enhancing Backdoor Defense in Multimodal Contrastive Learning via Local Token Unlearning,arXiv,2024,2403.16257,"Siyuan Liang, Kuanrong Liu, Jiajun Gong, Jiawei Liang, Yuan Xun, Ee-Chien Chang, Xiaochun Cao",https://arxiv.org/abs/2403.16257,03,"6 pages, 2 figures",
An Embarrassingly Simple Defense Against Backdoor Attacks On SSL,arXiv,2024,2403.15918,"Aryan Satpathy, Nilaksh Nilaksh, Dhruva Rajwade",https://arxiv.org/abs/2403.15918,03,"10 pages, 5 figures",https://github.com/Aryan-Satpathy/Backdoor
Clean-image Backdoor Attacks,arXiv,2024,2403.15010,"Dazhong Rong, Guoyao Yu, Shuheng Shen, Xinyi Fu, Peng Qian, Jianhai Chen, Qinming He, Xing Fu, Weiqiang Wang",https://arxiv.org/abs/2403.15010,03,,
"Threats, Attacks, and Defenses in Machine Unlearning: A Survey",arXiv,2024,2403.13682,"Ziyao Liu, Huanyi Ye, Chen Chen, Kwok-Yan Lam",https://arxiv.org/abs/2403.13682,03,,
BadEdit: Backdooring large language models by model editing,arXiv,2024,2403.13355,"Yanzhou Li, Tianlin Li, Kangjie Chen, Jian Zhang, Shangqing Liu, Wenhan Wang, Tianwei Zhang, Yang Liu",https://arxiv.org/abs/2403.13355,03,ICLR 2024,
Invisible Backdoor Attack Through Singular Value Decomposition,arXiv,2024,2403.13018,"Wenmin Chen, Xiaowei Xu",https://arxiv.org/abs/2403.13018,03,,
Impart: An Imperceptible and Effective Label-Specific Backdoor Attack,arXiv,2024,2403.13017,"Jingke Zhao, Zan Wang, Yongwei Wang, Lanjun Wang",https://arxiv.org/abs/2403.13017,03,,
CASPER: Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal Time Series Imputation,arXiv,2024,2403.11960,"Baoyu Jing, Dawei Zhou, Kan Ren, Carl Yang",https://arxiv.org/abs/2403.11960,03,Preprint. Work in progress,
Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency,arXiv,2024,2403.10717,"Soumyadeep Pal, Yuguang Yao, Ren Wang, Bingquan Shen, Sijia Liu",https://arxiv.org/abs/2403.10717,03,The Twelfth International Conference on Learning Representations (ICLR 2024),https://github.com/OPTML-Group/BackdoorMSPC
REPQC: Reverse Engineering and Backdooring Hardware Accelerators for Post-quantum Cryptography,arXiv,2024,2403.09352,"Samuel Pagliarini, Aikata Aikata, Malik Imran, Sujoy Sinha Roy",https://arxiv.org/abs/2403.09352,03,Accepted in AsiaCCS'24,
Advancing Security in AI Systems: A Novel Approach to Detecting Backdoors in Deep Neural Networks,arXiv,2024,2403.08208,"Khondoker Murad Hossain, Tim Oates",https://arxiv.org/abs/2403.08208,03,"6 pages, Accepted at the International Conference on Communications 2024. arXiv admin note: text overlap with arXiv:2212.08121",
Backdoor Attack with Mode Mixture Latent Modification,arXiv,2024,2403.07463,"Hongwei Zhang, Xiaoyin Xu, Dongsheng An, Xianfeng Gu, Min Zhang",https://arxiv.org/abs/2403.07463,03,,
Enhancing Adversarial Training with Prior Knowledge Distillation for Robust Image Compression,arXiv,2024,2403.06700,"Zhi Cao, Youneng Bao, Fanyang Meng, Chao Li, Wen Tan, Genhong Wang, Yongsheng Liang",https://arxiv.org/abs/2403.06700,03,,
Real is not True: Backdoor Attacks Against Deepfake Detection,arXiv,2024,2403.06610,"Hong Sun, Ziqiang Li, Lei Liu, Bin Li",https://arxiv.org/abs/2403.06610,03,BigDIA 2023,
AS-FIBA: Adaptive Selective Frequency-Injection for Backdoor Attack on Deep Face Restoration,arXiv,2024,2403.06430,"Zhenbo Song, Wenhao Gao, Kaihao Zhang, Wenhan Luo, Zhaoxin Fan, Jianfeng Lu",https://arxiv.org/abs/2403.06430,03,,
"Federated Learning: Attacks, Defenses, Opportunities, and Challenges",arXiv,2024,2403.06067,"Ghazaleh Shirvani, Saeid Ghasemshirazi, Behzad Beigzadeh",https://arxiv.org/abs/2403.06067,03,,
MirrorAttack: Backdoor Attack on 3D Point Cloud with a Distorting Mirror,arXiv,2024,2403.05847,"Yuhao Bian, Shengjing Tian, Xiuping Liu",https://arxiv.org/abs/2403.05847,03,15 pages,
On the Effectiveness of Distillation in Mitigating Backdoors in Pre-trained Encoder,arXiv,2024,2403.03846,"Tingxu Han, Shenghan Huang, Ziqi Ding, Weisong Sun, Yebo Feng, Chunrong Fang, Jun Li, Hanwei Qian, Cong Wu, Quanjun Zhang, Yang Liu, Zhenyu Chen",https://arxiv.org/abs/2403.03846,03,,
Causality-based Cross-Modal Representation Learning for Vision-and-Language Navigation,arXiv,2024,2403.03405,"Liuyi Wang, Zongtao He, Ronghao Dang, Huiyi Chen, Chengju Liu, Qijun Chen",https://arxiv.org/abs/2403.03405,03,16 pages,
Mitigating Label Flipping Attacks in Malicious URL Detectors Using Ensemble Trees,arXiv,2024,2403.02995,"Ehsan Nowroozi, Nada Jadalla, Samaneh Ghelichkhani, Alireza Jolfaei",https://arxiv.org/abs/2403.02995,03,,
A general approach to enhance the survivability of backdoor attacks by decision path coupling,arXiv,2024,2403.02950,"Yufei Zhao, Dingji Wang, Bihuan Chen, Ziqian Chen, Xin Peng",https://arxiv.org/abs/2403.02950,03,,
WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection,arXiv,2024,2403.01472,"Anudeex Shetty, Yue Teng, Ke He, Qiongkai Xu",https://arxiv.org/abs/2403.01472,03,Work in Progress,
DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference,arXiv,2024,2403.01166,"Jialong Wu, Linhai Zhang, Deyu Zhou, Guoqiang Xu",https://arxiv.org/abs/2403.01166,03,Our code and results will be available at https://github.com/callanwu/DINER,https://github.com/callanwu/DINER
LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario,arXiv,2024,2403.00108,"Hongyi Liu, Zirui Liu, Ruixiang Tang, Jiayi Yuan, Shaochen Zhong, Yu-Neng Chuang, Li Li, Rui Chen, Xia Hu",https://arxiv.org/abs/2403.00108,03,,
Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge,arXiv,2024,2402.19334,"Ansh Arora, Xuanli He, Maximilian Mozes, Srinibas Swain, Mark Dras, Qiongkai Xu",https://arxiv.org/abs/2402.19334,02,work in progress,
SynGhost: Imperceptible and Universal Task-agnostic Backdoor Attack in Pre-trained Language Models,arXiv,2024,2402.18945,"Pengzhou Cheng, Wei Du, Zongru Wu, Fengwei Zhang, Libo Chen, Gongshen Liu",https://arxiv.org/abs/2402.18945,02,"18 pages, 19 figures, 13 tables",
Model Pairing Using Embedding Translation for Backdoor Attack Detection on Open-Set Classification Tasks,arXiv,2024,2402.18718,"Alexander Unnervik, Hatef Otroshi Shahreza, Anjith George, Sébastien Marcel",https://arxiv.org/abs/2402.18718,02,Under review,
Model X-ray:Detect Backdoored Models via Decision Boundary,arXiv,2024,2402.17465,"Yanghao Su, Jie Zhang, Ting Xu, Tianwei Zhang, Weiming Zhang, Nenghai Yu",https://arxiv.org/abs/2402.17465,02,,
On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing Problem,arXiv,2024,2402.16926,"Georg Pichler, Marco Romanelli, Divya Prakash Manivannan, Prashanth Krishnamurthy, Farshad Khorrami, Siddharth Garg",https://arxiv.org/abs/2402.16926,02,,
Low-Frequency Black-Box Backdoor Attack via Evolutionary Algorithm,arXiv,2024,2402.15653,"Yanqi Qiao, Dazhuang Liu, Rui Wang, Kaitai Liang",https://arxiv.org/abs/2402.15653,02,,
Mudjacking: Patching Backdoor Vulnerabilities in Foundation Models,arXiv,2024,2402.14977,"Hongbin Liu, Michael K. Reiter, Neil Zhenqiang Gong",https://arxiv.org/abs/2402.14977,02,"To appear in USENIX Security Symposium, 2024",
Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment,arXiv,2024,2402.14968,"Jiongxiao Wang, Jiazhao Li, Yiquan Li, Xiangyu Qi, Junjie Hu, Yixuan Li, Patrick McDaniel, Muhao Chen, Bo Li, Chaowei Xiao",https://arxiv.org/abs/2402.14968,02,,
Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning,arXiv,2024,2402.14883,"Shen Li, Liuyi Yao, Jinyang Gao, Lan Zhang, Yaliang Li",https://arxiv.org/abs/2402.14883,02,,
Domain Generalization via Causal Adjustment for Cross-Domain Sentiment Analysis,arXiv,2024,2402.14536,"Siyin Wang, Jie Zhou, Qin Chen, Qi Zhang, Tao Gui, Xuanjing Huang",https://arxiv.org/abs/2402.14536,02,,
Corrective Machine Unlearning,arXiv,2024,2402.14015,"Shashwat Goel, Ameya Prabhu, Philip Torr, Ponnurangam Kumaraguru, Amartya Sanyal",https://arxiv.org/abs/2402.14015,02,"17 pages, 7 figures",
VL-Trojan: Multimodal Instruction Backdoor Attacks against Autoregressive Visual Language Models,arXiv,2024,2402.13851,"Jiawei Liang, Siyuan Liang, Man Luo, Aishan Liu, Dongchen Han, Ee-Chien Chang, Xiaochun Cao",https://arxiv.org/abs/2402.13851,02,,
Backdoor Attacks on Dense Passage Retrievers for Disseminating Misinformation,arXiv,2024,2402.13532,"Quanyu Long, Yue Deng, LeiLei Gan, Wenya Wang, Sinno Jialin Pan",https://arxiv.org/abs/2402.13532,02,,
Learning to Poison Large Language Models During Instruction Tuning,arXiv,2024,2402.13459,"Yao Qiang, Xiangyu Zhou, Saleh Zare Zade, Mohammad Amin Roshani, Douglas Zytko, Dongxiao Zhu",https://arxiv.org/abs/2402.13459,02,,
Measuring Impacts of Poisoning on Model Parameters and Neuron Activations: A Case Study of Poisoning CodeBERT,arXiv,2024,2402.12936,"Aftab Hussain, Md Rafiqul Islam Rabin, Navid Ayoobi, Mohammad Amin Alipour",https://arxiv.org/abs/2402.12936,02,,
Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning,arXiv,2024,2402.12168,"Shuai Zhao, Leilei Gan, Luu Anh Tuan, Jie Fu, Lingjuan Lyu, Meihuizi Jia, Jinming Wen",https://arxiv.org/abs/2402.12168,02,NAACL Findings 2024,
Acquiring Clean Language Models from Backdoor Poisoned Datasets by Downscaling Frequency Space,arXiv,2024,2402.12026,"Zongru Wu, Zhuosheng Zhang, Pengzhou Cheng, Gongshen Liu",https://arxiv.org/abs/2402.12026,02,,https://github.com/ZrW00/MuScleLoRA
Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection,arXiv,2024,2402.11473,"Jiawei Liang, Siyuan Liang, Aishan Liu, Xiaojun Jia, Junhao Kuang, Xiaochun Cao",https://arxiv.org/abs/2402.11473,02,ICLR 2024 Spotlight,https://github.com/JWLiang007/PFF
Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents,arXiv,2024,2402.11208,"Wenkai Yang, Xiaohan Bi, Yankai Lin, Sishuo Chen, Jie Zhou, Xu Sun",https://arxiv.org/abs/2402.11208,02,The first two authors contribute equally. Code and data are available at https://github.com/lancopku/agent-backdoor-attacks,https://github.com/lancopku/agent-backdoor-attacks
Backdoor Attack against One-Class Sequential Anomaly Detection Models,arXiv,2024,2402.10283,"He Cheng, Shuhan Yuan",https://arxiv.org/abs/2402.10283,02,This work is accepted by the PAKDD 2024. 12 pages,
A Trembling House of Cards? Mapping Adversarial Attacks against Language Agents,arXiv,2024,2402.10196,"Lingbo Mo, Zeyi Liao, Boyuan Zheng, Yu Su, Chaowei Xiao, Huan Sun",https://arxiv.org/abs/2402.10196,02,,
Instruction Backdoor Attacks Against Customized LLMs,arXiv,2024,2402.09179,"Rui Zhang, Hongwei Li, Rui Wen, Wenbo Jiang, Yuan Zhang, Michael Backes, Yun Shen, Yang Zhang",https://arxiv.org/abs/2402.09179,02,,
Test-Time Backdoor Attacks on Multimodal Large Language Models,arXiv,2024,2402.08577,"Dong Lu, Tianyu Pang, Chao Du, Qian Liu, Xianjun Yang, Min Lin",https://arxiv.org/abs/2402.08577,02,,https://sail-sg.github.io/AnyDoor/
OrderBkd: Textual backdoor attack through repositioning,arXiv,2024,2402.07689,"Irina Alekseevskaia, Konstantin Arkhipenko",https://arxiv.org/abs/2402.07689,02,,https://github.com/alekseevskaia/OrderBkd
Architectural Neural Backdoors from First Principles,arXiv,2024,2402.06957,"Harry Langford, Ilia Shumailov, Yiren Zhao, Robert Mullins, Nicolas Papernot",https://arxiv.org/abs/2402.06957,02,,
The last Dance : Robust backdoor attack via diffusion models and bayesian approach,arXiv,2024,2402.05967,Orson Mengara,https://arxiv.org/abs/2402.05967,02,"Preprint (Last update, will never be modified again( correction of a sketch)): audio backdoor attack on Hugging Face's Transformer pre-trained models. This attack incorporates state-of-the-art Bayesian techniques, a modified Fokker-Planck equation (via Yang-Mills), and a diffusion model approach",
Time-Distributed Backdoor Attacks on Federated Spiking Learning,arXiv,2024,2402.02886,"Gorka Abad, Stjepan Picek, Aitor Urbieta",https://arxiv.org/abs/2402.02886,02,,
DisDet: Exploring Detectability of Backdoor Attack on Diffusion Models,arXiv,2024,2402.02739,"Yang Sui, Huy Phan, Jinqi Xiao, Tianfang Zhang, Zijie Tang, Cong Shi, Yan Wang, Yingying Chen, Bo Yuan",https://arxiv.org/abs/2402.02739,02,,
Universal Post-Training Reverse-Engineering Defense Against Backdoors in Deep Neural Networks,arXiv,2024,2402.02034,"Xi Li, Hang Wang, David J. Miller, George Kesidis",https://arxiv.org/abs/2402.02034,02,,
TransTroj: Transferable Backdoor Attacks to Pre-trained Models via Embedding Indistinguishability,arXiv,2024,2401.15883,"Hao Wang, Tao Xiang, Shangwei Guo, Jialing He, Hangcheng Liu, Tianwei Zhang",https://arxiv.org/abs/2401.15883,01,"13 pages, 16 figures, 5 tables",https://github.com/haowang-cqu/TransTroj
"Multi-Trigger Backdoor Attacks: More Triggers, More Threats",arXiv,2024,2401.15295,"Yige Li, Xingjun Ma, Jiabo He, Hanxun Huang, Yu-Gang Jiang",https://arxiv.org/abs/2401.15295,01,,
MEA-Defender: A Robust Watermark against Model Extraction Attack,arXiv,2024,2401.15239,"Peizhuo Lv, Hualong Ma, Kai Chen, Jiachen Zhou, Shengzhi Zhang, Ruigang Liang, Shenchen Zhu, Pan Li, Yingjun Zhang",https://arxiv.org/abs/2401.15239,01,"To Appear in IEEE Symposium on Security and Privacy 2024 (IEEE S&P 2024), MAY 20-23, 2024, SAN FRANCISCO, CA, USA",
BackdoorBench: A Comprehensive Benchmark and Analysis of Backdoor Learning,arXiv,2024,2401.15002,"Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Mingli Zhu, Ruotong Wang, Li Liu, Chao Shen",https://arxiv.org/abs/2401.15002,01,,
WPDA: Frequency-based Backdoor Attack with Wavelet Packet Decomposition,arXiv,2024,2401.13578,"Zhengyao Song, Yongqiang Li, Danni Yuan, Li Liu, Shaokui Wei, Baoyuan Wu",https://arxiv.org/abs/2401.13578,01,"15 pages, 15 figures",
Instructional Fingerprinting of Large Language Models,arXiv,2024,2401.12255,"Jiashu Xu, Fei Wang, Mingyu Derek Ma, Pang Wei Koh, Chaowei Xiao, Muhao Chen",https://arxiv.org/abs/2401.12255,01,Accepted at NAACL 2024; 30 pages,https://cnut1648.github.io/Model-Fingerprint/
BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models,arXiv,2024,2401.12242,"Zhen Xiang, Fengqing Jiang, Zidi Xiong, Bhaskar Ramasubramanian, Radha Poovendran, Bo Li",https://arxiv.org/abs/2401.12242,01,Accepted to ICLR2024,
Learning Backdoors for Mixed Integer Programs with Contrastive Learning,arXiv,2024,2401.10467,"Junyang Cai, Taoan Huang, Bistra Dilkina",https://arxiv.org/abs/2401.10467,01,,
Hijacking Attacks against Neural Networks by Analyzing Training Data,arXiv,2024,2401.09740,"Yunjie Ge, Qian Wang, Huayang Huang, Qi Li, Cong Wang, Chao Shen, Lingchen Zhao, Peipei Jiang, Zheng Fang, Shenyi Zhang",https://arxiv.org/abs/2401.09740,01,"Full version with major polishing, compared to the Usenix Security 2024 edition",
Can We Trust the Unlabeled Target Data? Towards Backdoor Attack and Defense on Model Adaptation,arXiv,2024,2401.06030,"Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan",https://arxiv.org/abs/2401.06030,01,"11 pages, 4 figures",
Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning,arXiv,2024,2401.05949,"Shuai Zhao, Meihuizi Jia, Luu Anh Tuan, Fengjun Pan, Jinming Wen",https://arxiv.org/abs/2401.05949,01,,
Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training,arXiv,2024,2401.05566,"Evan Hubinger, Carson Denison, Jesse Mu, Mike Lambert, Meg Tong, Monte MacDiarmid, Tamera Lanham, Daniel M. Ziegler, Tim Maxwell, Newton Cheng, Adam Jermyn, Amanda Askell, Ansh Radhakrishnan, Cem Anil, David Duvenaud, Deep Ganguli, Fazl Barez, Jack Clark, Kamal Ndousse, Kshitij Sachan, Michael Sellitto, Mrinank Sharma, Nova DasSarma, Roger Grosse, Shauna Kravec",https://arxiv.org/abs/2401.05566,01,updated to add missing acknowledgements,
TEN-GUARD: Tensor Decomposition for Backdoor Attack Detection in Deep Neural Networks,arXiv,2024,2401.05432,"Khondoker Murad Hossain, Tim Oates",https://arxiv.org/abs/2401.05432,01,,
"Federated Unlearning: A Survey on Methods, Design Guidelines, and Evaluation Metrics",arXiv,2024,2401.05146,"Nicolò Romandini, Alessio Mora, Carlo Mazzocca, Rebecca Montanari, Paolo Bellavista",https://arxiv.org/abs/2401.05146,01,"23 pages, 8 figures, and 6 tables",
Detecting Face Synthesis Using a Concealed Fusion Model,arXiv,2024,2401.04257,"Roberto Leyva, Victor Sanchez, Gregory Epiphaniou, Carsten Maple",https://arxiv.org/abs/2401.04257,01,,
"The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline",arXiv,2024,2401.04136,"Haonan Wang, Qianli Shen, Yao Tong, Yang Zhang, Kenji Kawaguchi",https://arxiv.org/abs/2401.04136,01,Accepted for presentation at ICML 2024,
Inferring Properties of Graph Neural Networks,arXiv,2024,2401.03790,"Dat Nguyen, Hieu M. Vu, Cong-Thanh Le, Bach Le, David Lo, ThanhVu Nguyen, Corina Pasareanu",https://arxiv.org/abs/2401.03790,01,"20 pages main paper, 10 pages for appendix",
End-to-End Anti-Backdoor Learning on Images and Time Series,arXiv,2024,2401.03215,"Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, Yige Li, James Bailey",https://arxiv.org/abs/2401.03215,01,,
A backdoor attack against link prediction tasks with graph neural networks,arXiv,2024,2401.02663,"Jiazhu Dai, Haoyu Sun",https://arxiv.org/abs/2401.02663,01,,
MalModel: Hiding Malicious Payload in Mobile Deep Learning Models with Black-box Backdoor Attack,arXiv,2024,2401.02659,"Jiayi Hua, Kailong Wang, Meizhen Wang, Guangdong Bai, Xiapu Luo, Haoyu Wang",https://arxiv.org/abs/2401.02659,01,"Due to the limitation ""The abstract field cannot be longer than 1,920 characters"", the abstract here is shorter than that in the PDF file",
Adaptive Discounting of Training Time Attacks,arXiv,2024,2401.02652,"Ridhima Bector, Abhay Aradhya, Chai Quek, Zinovi Rabinovich",https://arxiv.org/abs/2401.02652,01,"19 pages, 7 figures",
Object-oriented backdoor attack against image captioning,arXiv,2024,2401.02600,"Meiling Li, Nan Zhong, Xinpeng Zhang, Zhenxing Qian, Sheng Li",https://arxiv.org/abs/2401.02600,01,,
Spy-Watermark: Robust Invisible Watermarking for Backdoor Attack,arXiv,2024,2401.02031,"Ruofei Wang, Renjie Wan, Zongyu Guo, Qing Guo, Rui Huang",https://arxiv.org/abs/2401.02031,01,Accepted by ICASSP2024,
Backdoor Attack on Unpaired Medical Image-Text Foundation Models: A Pilot Study on MedCLIP,arXiv,2024,2401.01911,"Ruinan Jin, Chun-Yin Huang, Chenyu You, Xiaoxiao Li",https://arxiv.org/abs/2401.01911,01,Paper Accepted at the 2nd IEEE Conference on Secure and Trustworthy Machine Learning,
The Art of Deception: Robust Backdoor Attack using Dynamic Stacking of Triggers,arXiv,2024,2401.01537,Orson Mengara,https://arxiv.org/abs/2401.01537,01,"Accepted by AAAI Workshop 2024, 8 pages",
Does Few-shot Learning Suffer from Backdoor Attacks?,arXiv,2024,2401.01377,"Xinwei Liu, Xiaojun Jia, Jindong Gu, Yuan Xun, Siyuan Liang, Xiaochun Cao",https://arxiv.org/abs/2401.01377,01,AAAI2024,
Imperio: Language-Guided Backdoor Attacks for Arbitrary Model Control,arXiv,2024,2401.01085,"Ka-Ho Chow, Wenqi Wei, Lei Yu",https://arxiv.org/abs/2401.01085,01,,
Is It Possible to Backdoor Face Forgery Detection with Natural Triggers?,arXiv,2024,2401.00414,"Xiaoxuan Han, Songlin Yang, Wei Wang, Ziwen He, Jing Dong",https://arxiv.org/abs/2401.00414,01,,
A clean-label graph backdoor attack method in node classification task,arXiv,2024,2401.00163,"Xiaogang Xing, Ming Xu, Yujing Bai, Dongdong Yang",https://arxiv.org/abs/2401.00163,01,14pages,
SSL-OTA: Unveiling Backdoor Threats in Self-Supervised Learning for Object Detection,arXiv,2024,2401.00137,"Qiannan Wang, Changchun Yin, Liming Fang, Lu Zhou, Zhe Liu, Run Wang, Chenhao Lin",https://arxiv.org/abs/2401.00137,01,,
Punctuation Matters! Stealthy Backdoor Attack for Language Models,arXiv,2023,2312.15867,"Xuan Sheng, Zhicheng Li, Zhaoyang Han, Xiangmao Chang, Piji Li",https://arxiv.org/abs/2312.15867,12,NLPCC 2023,
Pre-trained Trojan Attacks for Visual Recognition,arXiv,2023,2312.15172,"Aishan Liu, Xinwei Zhang, Yisong Xiao, Yuguang Zhou, Siyuan Liang, Jiakai Wang, Xianglong Liu, Xiaochun Cao, Dacheng Tao",https://arxiv.org/abs/2312.15172,12,19 pages,
Manipulating Trajectory Prediction with Backdoors,arXiv,2023,2312.13863,"Kaouther Messaoud, Kathrin Grosse, Mickael Chen, Matthieu Cord, Patrick Pérez, Alexandre Alahi",https://arxiv.org/abs/2312.13863,12,"9 pages, 7 figures",
Progressive Poisoned Data Isolation for Training-time Backdoor Defense,arXiv,2023,2312.12724,"Yiming Chen, Haiwei Wu, Jiantao Zhou",https://arxiv.org/abs/2312.12724,12,Accepted to AAAI2024,
BadRL: Sparse Targeted Backdoor Attack Against Reinforcement Learning,arXiv,2023,2312.12585,"Jing Cui, Yufei Han, Yuzhe Ma, Jianbin Jiao, Junge Zhang",https://arxiv.org/abs/2312.12585,12,Extended version of the submission accepted by AAAI 2024. It is revised by integrating review comments,
DataElixir: Purifying Poisoned Dataset to Mitigate Backdoor Attacks via Diffusion Models,arXiv,2023,2312.11057,"Jiachen Zhou, Peizhuo Lv, Yibing Lan, Guozhu Meng, Kai Chen, Hualong Ma",https://arxiv.org/abs/2312.11057,12,Accepted by AAAI2024,
UltraClean: A Simple Framework to Train Robust Neural Networks against Backdoor Attacks,arXiv,2023,2312.10657,"Bingyin Zhao, Yingjie Lao",https://arxiv.org/abs/2312.10657,12,,https://github.com/bxz9200/UltraClean
Decomposing Hard SAT Instances with Metaheuristic Optimization,arXiv,2023,2312.10436,"Daniil Chivilikhin, Artem Pavlenko, Alexander Semenov",https://arxiv.org/abs/2312.10436,12,This is a preprint of the paper published in Intern. J. Artificial Intelligence. 2023. V. 21. No. 2. P. 61-92,
FlowMur: A Stealthy and Practical Audio Backdoor Attack with Limited Knowledge,arXiv,2023,2312.09665,"Jiahe Lan, Jie Wang, Baochen Yan, Zheng Yan, Elisa Bertino",https://arxiv.org/abs/2312.09665,12,To appear at lEEE Symposium on Security & Privacy (Oakland) 2024,
On the Difficulty of Defending Contrastive Learning against Backdoor Attacks,arXiv,2023,2312.09057,"Changjiang Li, Ren Pang, Bochuan Cao, Zhaohan Xi, Jinghui Chen, Shouling Ji, Ting Wang",https://arxiv.org/abs/2312.09057,12,USENIX Security 24,
Defenses in Adversarial Machine Learning: A Survey,arXiv,2023,2312.08890,"Baoyuan Wu, Shaokui Wei, Mingli Zhu, Meixi Zheng, Zihao Zhu, Mingda Zhang, Hongrui Chen, Danni Yuan, Li Liu, Qingshan Liu",https://arxiv.org/abs/2312.08890,12,"21 pages, 5 figures, 2 tables, 237 reference papers",
"Data and Model Poisoning Backdoor Attacks on Wireless Federated Learning, and the Defense Mechanisms: A Comprehensive Survey",arXiv,2023,2312.08667,"Yichen Wan, Youyang Qu, Wei Ni, Yong Xiang, Longxiang Gao, Ekram Hossain",https://arxiv.org/abs/2312.08667,12,,
Erasing Self-Supervised Learning Backdoor by Cluster Activation Masking,arXiv,2023,2312.07955,"Shengsheng Qian, Yifei Wang, Dizhan Xue, Shengjie Zhang, Huaiwen Zhang, Changsheng Xu",https://arxiv.org/abs/2312.07955,12,,https://github.com/LivXue/PoisonCAM
AI Control: Improving Safety Despite Intentional Subversion,arXiv,2023,2312.06942,"Ryan Greenblatt, Buck Shlegeris, Kshitij Sachan, Fabien Roger",https://arxiv.org/abs/2312.06942,12,Edit: Fix minor typos and clarify abstract,
Performance-lossless Black-box Model Watermarking,arXiv,2023,2312.06488,"Na Zhao, Kejiang Chen, Weiming Zhang, Nenghai Yu",https://arxiv.org/abs/2312.06488,12,,
Activation Gradient based Poisoned Sample Detection Against Backdoor Attacks,arXiv,2023,2312.06230,"Danni Yuan, Shaokui Wei, Mingda Zhang, Li Liu, Baoyuan Wu",https://arxiv.org/abs/2312.06230,12,,
Enhancing Robustness of Foundation Model Representations under Provenance-related Distribution Shifts,arXiv,2023,2312.05435,"Xiruo Ding, Zhecheng Sheng, Brian Hur, Feng Chen, Serguei V. S. Pakhomov, Trevor Cohen",https://arxiv.org/abs/2312.05435,12,"Accepted in Workshop on Distribution Shifts, 37th Conference on Neural Information Processing Systems (NeurIPS 2023)",
BELT: Old-School Backdoor Attacks can Evade the State-of-the-Art Defense with Backdoor Exclusivity Lifting,arXiv,2023,2312.04902,"Huming Qiu, Junjie Sun, Mi Zhang, Xudong Pan, Min Yang",https://arxiv.org/abs/2312.04902,12,"To Appear in the 45th IEEE Symposium on Security and Privacy, May 20-23, 2024",
FedBayes: A Zero-Trust Federated Learning Aggregation to Defend Against Adversarial Attacks,arXiv,2023,2312.04587,"Marc Vucovich, Devin Quinn, Kevin Choi, Christopher Redino, Abdul Rahman, Edward Bowen",https://arxiv.org/abs/2312.04587,12,Accepted to IEEE CCWC 2024,
Towards Sample-specific Backdoor Attack with Clean Labels via Attribute Trigger,arXiv,2023,2312.04584,"Yiming Li, Mingyan Zhu, Junfeng Guo, Tao Wei, Shu-Tao Xia, Zhan Qin",https://arxiv.org/abs/2312.04584,12,14 pages,
FreqFed: A Frequency Analysis-Based Approach for Mitigating Poisoning Attacks in Federated Learning,arXiv,2023,2312.04432,"Hossein Fereidooni, Alessandro Pegoraro, Phillip Rieger, Alexandra Dmitrienko, Ahmad-Reza Sadeghi",https://arxiv.org/abs/2312.04432,12,"To appear in the Network and Distributed System Security (NDSS) Symposium 2024. 16 pages, 8 figures, 12 tables, 1 algorithm, 3 equations",
Synthesizing Physical Backdoor Datasets: An Automated Framework Leveraging Deep Generative Models,arXiv,2023,2312.03419,"Sze Jue Yang, Chinh D. La, Quang H. Nguyen, Kok-Seng Wong, Anh Tuan Tran, Chee Seng Chan, Khoa D. Doan",https://arxiv.org/abs/2312.03419,12,,
Who Leaked the Model? Tracking IP Infringers in Accountable Federated Learning,arXiv,2023,2312.03205,"Shuyang Yu, Junyuan Hong, Yi Zeng, Fei Wang, Ruoxi Jia, Jiayu Zhou",https://arxiv.org/abs/2312.03205,12,,
Robust Backdoor Detection for Deep Learning via Topological Evolution Dynamics,arXiv,2023,2312.02673,"Xiaoxing Mo, Yechao Zhang, Leo Yu Zhang, Wei Luo, Nan Sun, Shengshan Hu, Shang Gao, Yang Xiang",https://arxiv.org/abs/2312.02673,12,18 pages. To appear in IEEE Symposium on Security and Privacy 2024,
UCCA: A Verified Architecture for Compartmentalization of Untrusted Code Sections in Resource-Constrained Devices,arXiv,2023,2312.02348,"Liam Tyler, Ivan De Oliveira Nunes",https://arxiv.org/abs/2312.02348,12,,
OCGEC: One-class Graph Embedding Classification for DNN Backdoor Detection,arXiv,2023,2312.01585,"Haoyu Jiang, Haiyang Yu, Nan Li, Ping Yi",https://arxiv.org/abs/2312.01585,12,v2,https://github.com/jhy549/OCGEC
Universal Backdoor Attacks,arXiv,2023,2312.00157,"Benjamin Schneider, Nils Lukas, Florian Kerschbaum",https://arxiv.org/abs/2312.00157,12,Accepted for publication at ICLR 2024,https://github.com/Ben-Schneider-code/Universal-Backdoor-Attacks
Elijah: Eliminating Backdoors Injected in Diffusion Models via Distribution Shift,arXiv,2023,2312.00050,"Shengwei An, Sheng-Yen Chou, Kaiyuan Zhang, Qiuling Xu, Guanhong Tao, Guangyu Shen, Siyuan Cheng, Shiqing Ma, Pin-Yu Chen, Tsung-Yi Ho, Xiangyu Zhang",https://arxiv.org/abs/2312.00050,12,AAAI 2024,
Stealthy and Persistent Unalignment on Large Language Models via Backdoor Injections,arXiv,2023,2312.00027,"Yuanpu Cao, Bochuan Cao, Jinghui Chen",https://arxiv.org/abs/2312.00027,12,,
Unveiling Backdoor Risks Brought by Foundation Models in Heterogeneous Federated Learning,arXiv,2023,2311.18350,"Xi Li, Chen Wu, Jiaqi Wang",https://arxiv.org/abs/2311.18350,11,Jiaqi Wang is the corresponding author. arXiv admin note: text overlap with arXiv:2311.00144,
TARGET: Template-Transferable Backdoor Attack Against Prompt-based NLP Models via GPT4,arXiv,2023,2311.17429,"Zihao Tan, Qingliang Chen, Yongjian Huang, Chen Liang",https://arxiv.org/abs/2311.17429,11,,
Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective,arXiv,2023,2311.16646,"Ming-Yu Chung, Sheng-Yen Chou, Chia-Mu Yu, Pin-Yu Chen, Sy-Yen Kuo, Tsung-Yi Ho",https://arxiv.org/abs/2311.16646,11,"19 pages, 4 figures",
BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP,arXiv,2023,2311.16194,"Jiawang Bai, Kuofeng Gao, Shaobo Min, Shu-Tao Xia, Zhifeng Li, Wei Liu",https://arxiv.org/abs/2311.16194,11,"14 pages, 6 figures",
BAGEL: Backdoor Attacks against Federated Contrastive Learning,arXiv,2023,2311.16113,"Yao Huang, Kongyang Chen, Jiannong Cao, Jiaxing Shen, Shaowei Wang, Yun Peng, Weilong Peng, Kechao Cai",https://arxiv.org/abs/2311.16113,11,,
A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective,arXiv,2023,2311.16065,"Xianghua Xie, Chen Hu, Hanchi Ren, Jingjing Deng",https://arxiv.org/abs/2311.16065,11,https://github.com/Rand2AI/Awesome-Vulnerability-of-Federated-Learning,https://github.com/Rand2AI/Awesome-Vulnerability-of-Federated-Learning
Distributed Attacks over Federated Reinforcement Learning-enabled Cell Sleep Control,arXiv,2023,2311.15894,"Han Zhang, Hao Zhou, Medhat Elsayed, Majid Bavand, Raimundas Gaigalas, Yigit Ozcan, Melike Erol-Kantarci",https://arxiv.org/abs/2311.15894,11,,
Effective Backdoor Mitigation Depends on the Pre-training Objective,arXiv,2023,2311.14948,"Sahil Verma, Gantavya Bhatt, Avi Schwarzschild, Soumye Singhal, Arnav Mohanty Das, Chirag Shah, John P Dickerson, Jeff Bilmes",https://arxiv.org/abs/2311.14948,11,Accepted for oral presentation at BUGS workshop @ NeurIPS 2023 (https://neurips2023-bugs.github.io/),https://neurips2023-bugs.github.io/
Universal Jailbreak Backdoors from Poisoned Human Feedback,arXiv,2023,2311.14455,"Javier Rando, Florian Tramèr",https://arxiv.org/abs/2311.14455,11,Accepted as conference paper in ICLR 2024,
Efficient Trigger Word Insertion,arXiv,2023,2311.13957,"Yueqi Zeng, Ziqiang Li, Pengfei Xia, Lei Liu, Bin Li",https://arxiv.org/abs/2311.13957,11,,
Rethinking Radiology Report Generation via Causal Reasoning and Counterfactual Augmentation,arXiv,2023,2311.13307,"Xiao Song, Jiafan Liu, Yun Li, Wenbin Lei, Ruxin Wang",https://arxiv.org/abs/2311.13307,11,"10 pages,5 figures",
Attacks of fairness in Federated Learning,arXiv,2023,2311.12715,"Joseph Rance, Filip Svoboda",https://arxiv.org/abs/2311.12715,11,,
BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning,arXiv,2023,2311.12075,"Siyuan Liang, Mingli Zhu, Aishan Liu, Baoyuan Wu, Xiaochun Cao, Ee-Chien Chang",https://arxiv.org/abs/2311.12075,11,The paper lacks some work that needs to be cited,
Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI Systems,arXiv,2023,2311.11796,"Guangjing Wang, Ce Zhou, Yuanda Wang, Bocheng Chen, Hanqing Guo, Qiben Yan",https://arxiv.org/abs/2311.11796,11,,
TextGuard: Provable Defense against Backdoor Attacks on Text Classification,arXiv,2023,2311.11225,"Hengzhi Pei, Jinyuan Jia, Wenbo Guo, Bo Li, Dawn Song",https://arxiv.org/abs/2311.11225,11,Accepted by NDSS Symposium 2024,https://github.com/AI-secure/TextGuard
FedTruth: Byzantine-Robust and Backdoor-Resilient Federated Learning Framework,arXiv,2023,2311.10248,"Sheldon C. Ebron Jr., Kan Yang",https://arxiv.org/abs/2311.10248,11,,
Test-time Backdoor Mitigation for Black-Box Large Language Models with Defensive Demonstrations,arXiv,2023,2311.09763,"Wenjie Mo, Jiashu Xu, Qin Liu, Jiongxiao Wang, Jun Yan, Chaowei Xiao, Muhao Chen",https://arxiv.org/abs/2311.09763,11,,
On the Exploitability of Reinforcement Learning with Human Feedback for Large Language Models,arXiv,2023,2311.09641,"Jiongxiao Wang, Junlin Wu, Muhao Chen, Yevgeniy Vorobeychik, Chaowei Xiao",https://arxiv.org/abs/2311.09641,11,,
FunctionMarker: Watermarking Language Datasets via Knowledge Injection,arXiv,2023,2311.09535,"Shuai Li, Kejiang Chen, Kunsheng Tang, Wen Huang, Jie Zhang, Weiming Zhang, Nenghai Yu",https://arxiv.org/abs/2311.09535,11,,
Backdoor Activation Attack: Attack Large Language Models using Activation Steering for Safety-Alignment,arXiv,2023,2311.09433,"Haoran Wang, Kai Shu",https://arxiv.org/abs/2311.09433,11,,https://github.com/wang2226/Backdoor-Activation-Attack
Beyond Detection: Unveiling Fairness Vulnerabilities in Abusive Language Models,arXiv,2023,2311.09428,"Yueqing Liang, Lu Cheng, Ali Payani, Kai Shu",https://arxiv.org/abs/2311.09428,11,Under review,
Tabdoor: Backdoor Vulnerabilities in Transformer-based Neural Networks for Tabular Data,arXiv,2023,2311.07550,"Bart Pleiter, Behrad Tajalli, Stefanos Koffas, Gorka Abad, Jing Xu, Martha Larson, Stjepan Picek",https://arxiv.org/abs/2311.07550,11,,
Mitigating Backdoors within Deep Neural Networks in Data-limited Configuration,arXiv,2023,2311.07417,"Soroush Hashemifar, Saeed Parsa, Morteza Zakeri-Nasrabadi",https://arxiv.org/abs/2311.07417,11,,
Does Differential Privacy Prevent Backdoor Attacks in Practice?,arXiv,2023,2311.06227,"Fereshteh Razmi, Jian Lou, Li Xiong",https://arxiv.org/abs/2311.06227,11,,
Watermarking Vision-Language Pre-trained Models for Multi-modal Embedding as a Service,arXiv,2023,2311.05863,"Yuanmin Tang, Jing Yu, Keke Gai, Xiangyan Qu, Yue Hu, Gang Xiong, Qi Wu",https://arxiv.org/abs/2311.05863,11,,https://github.com/Pter61/vlpmarker
Trust your BMS: Designing a Lightweight Authentication Architecture for Industrial Networks,arXiv,2023,2311.05498,"Fikret Basic, Christian Steger, Christian Seifert, Robert Kofler",https://arxiv.org/abs/2311.05498,11,"Accepted copy for Publication at the 23rd International Conference on Industrial Technology (ICIT), IEEE, 2022",
SaFL: Sybil-aware Federated Learning with Application to Face Recognition,arXiv,2023,2311.04346,"Mahdi Ghafourian, Julian Fierrez, Ruben Vera-Rodriguez, Ruben Tolosana, Aythami Morales",https://arxiv.org/abs/2311.04346,11,,
AGNES: Abstraction-guided Framework for Deep Neural Networks Security,arXiv,2023,2311.04009,"Akshay Dhonthi, Marcello Eiermann, Ernst Moritz Hahn, Vahid Hashemi",https://arxiv.org/abs/2311.04009,11,"14 pages, 6 Figures, 4 Tables, Accepted at 25th International Conference on Verification, Model Checking, and Abstract Interpretation (VMCAI 2024)",
Can We Trust the Similarity Measurement in Federated Learning?,arXiv,2023,2311.03369,"Zhilin Wang, Qin Hu, Xukai Zou",https://arxiv.org/abs/2311.03369,11,,
From Trojan Horses to Castle Walls: Unveiling Bilateral Backdoor Effects in Diffusion Models,arXiv,2023,2311.02373,"Zhuoshi Pan, Yuguang Yao, Gaowen Liu, Bingquan Shen, H. Vicky Zhao, Ramana Rao Kompella, Sijia Liu",https://arxiv.org/abs/2311.02373,11,"10 pages, 6 figures, 7 tables",https://github.com/OPTML-Group/BiBadDiff
Backdoor Threats from Compromised Foundation Models to Federated Learning,arXiv,2023,2311.00144,"Xi Li, Songhe Wang, Chen Wu, Hao Zhou, Jiaqi Wang",https://arxiv.org/abs/2311.00144,11,This paper has been accepted by FL@FM-NeurIPS 23 (International Workshop on Federated Learning in the Age of Foundation Models in Conjunction with NeurIPS 2023). The corresponding author is Jiaqi Wang (jqwang@psu.edu),
Label Poisoning is All You Need,arXiv,2023,2310.18933,"Rishi D. Jha, Jonathan Hayase, Sewoong Oh",https://arxiv.org/abs/2310.18933,10,,
Setting the Trap: Capturing and Defeating Backdoors in Pretrained Language Models through Honeypots,arXiv,2023,2310.18633,"Ruixiang Tang, Jiayi Yuan, Yiming Li, Zirui Liu, Rui Chen, Xia Hu",https://arxiv.org/abs/2310.18633,10,,
Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers,arXiv,2023,2310.18603,"Wencong You, Zayd Hammoudeh, Daniel Lowd",https://arxiv.org/abs/2310.18603,10,Accepted at EMNLP 2023 Findings,
CBD: A Certified Backdoor Detector Based on Local Dominant Probability,arXiv,2023,2310.17498,"Zhen Xiang, Zidi Xiong, Bo Li",https://arxiv.org/abs/2310.17498,10,Accepted to NeurIPS 2023,
Causal Inference Using LLM-Guided Discovery,arXiv,2023,2310.15117,"Aniket Vashishtha, Abbavaram Gowtham Reddy, Abhinav Kumar, Saketh Bachu, Vineeth N Balasubramanian, Amit Sharma",https://arxiv.org/abs/2310.15117,10,,
On the Detection of Image-Scaling Attacks in Machine Learning,arXiv,2023,2310.15085,"Erwin Quiring, Andreas Müller, Konrad Rieck",https://arxiv.org/abs/2310.15085,10,Accepted at ACSAC'23,
Domain Watermark: Effective and Harmless Dataset Copyright Protection is Closed at Hand,arXiv,2023,2310.14942,"Junfeng Guo, Yiming Li, Lixu Wang, Shu-Tao Xia, Heng Huang, Cong Liu, Bo Li",https://arxiv.org/abs/2310.14942,10,This paper is accepted by NeurIPS 2023. The first two authors contributed equally to this work. 30 pages,https://github.com/JunfengGo/Domain-Watermark
Attention-Enhancing Backdoor Attacks Against BERT-based Models,arXiv,2023,2310.14480,"Weimin Lyu, Songzhu Zheng, Lu Pang, Haibin Ling, Chao Chen",https://arxiv.org/abs/2310.14480,10,Findings of EMNLP 2023,
FLTracer: Accurate Poisoning Attack Provenance in Federated Learning,arXiv,2023,2310.13424,"Xinyu Zhang, Qingyu Liu, Zhongjie Ba, Yuan Hong, Tianhang Zheng, Feng Lin, Li Lu, Kui Ren",https://arxiv.org/abs/2310.13424,10,"18 pages, 27 figures",https://github.com/Eyr3/FLTracer
SecurityNet: Assessing Machine Learning Vulnerabilities on Public Models,arXiv,2023,2310.12665,"Boyang Zhang, Zheng Li, Ziqing Yang, Xinlei He, Michael Backes, Mario Fritz, Yang Zhang",https://arxiv.org/abs/2310.12665,10,"To appear in the 33rd USENIX Security Symposium, August 2024, Philadelphia, PA, USA",
PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models,arXiv,2023,2310.12439,"Hongwei Yao, Jian Lou, Zhan Qin",https://arxiv.org/abs/2310.12439,10,"To Appear in IEEE ICASSP 2024, code is available at: https://github.com/grasses/PoisonPrompt",https://github.com/grasses/PoisonPrompt
WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks,arXiv,2023,2310.11595,"Jun Xia, Zhihao Yue, Yingbo Zhou, Zhiwei Ling, Xian Wei, Mingsong Chen",https://arxiv.org/abs/2310.11595,10,,
Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning,arXiv,2023,2310.11594,"Taejin Kim, Jiarui Li, Shubhranshu Singh, Nikhil Madaan, Carlee Joe-Wong",https://arxiv.org/abs/2310.11594,10,"8 pages, 6 main pages of text, 4 figures, 2 tables. Made for a Neurips workshop on backdoor attacks",
"Last One Standing: A Comparative Analysis of Security and Privacy of Soft Prompt Tuning, LoRA, and In-Context Learning",arXiv,2023,2310.11397,"Rui Wen, Tianhao Wang, Michael Backes, Yang Zhang, Ahmed Salem",https://arxiv.org/abs/2310.11397,10,,
Demystifying Poisoning Backdoor Attacks from a Statistical Perspective,arXiv,2023,2310.10780,"Ganghua Wang, Xun Xian, Jayanth Srinivasa, Ashish Kundu, Xuan Bi, Mingyi Hong, Jie Ding",https://arxiv.org/abs/2310.10780,10,,
Exploiting Machine Unlearning for Backdoor Attacks in Deep Learning System,arXiv,2023,2310.10659,"Peixin Zhang, Jun Sun, Mingtian Tan, Xinyu Wang",https://arxiv.org/abs/2310.10659,10,,
VFLAIR: A Research Library and Benchmark for Vertical Federated Learning,arXiv,2023,2310.09827,"Tianyuan Zou, Zixuan Gu, Yu He, Hideaki Takahashi, Yang Liu, Ya-Qin Zhang",https://arxiv.org/abs/2310.09827,10,"39 pages, 22 figures, 19 tabels",https://github.com/FLAIR-THU/VFLAIR
Explore the Effect of Data Selection on Poison Efficiency in Backdoor Attacks,arXiv,2023,2310.09744,"Ziqiang Li, Pengfei Xia, Hong Sun, Yueqi Zeng, Wei Zhang, Bin Li",https://arxiv.org/abs/2310.09744,10,Under Review,
Causality and Independence Enhancement for Biased Node Classification,arXiv,2023,2310.09586,"Guoxin Chen, Yongqing Wang, Fangda Guo, Qinglang Guo, Jiangli Shao, Huawei Shen, Xueqi Cheng",https://arxiv.org/abs/2310.09586,10,"10 pages, 5 figures, accepted by CIKM2023",
Defending Our Privacy With Backdoors,arXiv,2023,2310.08320,"Dominik Hintersdorf, Lukas Struppek, Daniel Neider, Kristian Kersting",https://arxiv.org/abs/2310.08320,10,"18 pages, 11 figures",
Invisible Threats: Backdoor Attack in OCR Systems,arXiv,2023,2310.08259,"Mauro Conti, Nicola Farronato, Stefanos Koffas, Luca Pajola, Stjepan Picek",https://arxiv.org/abs/2310.08259,10,,
Composite Backdoor Attacks Against Large Language Models,arXiv,2023,2310.07676,"Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang",https://arxiv.org/abs/2310.07676,10,"To Appear in Findings of the Association for Computational Linguistics: NAACL 2024, June 2024",
Prompt Backdoors in Visual Prompt Learning,arXiv,2023,2310.07632,"Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang",https://arxiv.org/abs/2310.07632,10,,
Genetic Algorithm-Based Dynamic Backdoor Attack on Federated Learning-Based Network Traffic Classification,arXiv,2023,2310.06855,"Mahmoud Nazzal, Nura Aljaafari, Ahmed Sawalmeh, Abdallah Khreishah, Muhammad Anan, Abdulelah Algosaibi, Mohammed Alnaeem, Adel Aldalbahi, Abdulaziz Alhumam, Conrado P. Vizcarra, Shadan Alhamed",https://arxiv.org/abs/2310.06855,10,,
Leveraging Diffusion-Based Image Variations for Robust Training on Poisoned Data,arXiv,2023,2310.06372,"Lukas Struppek, Martin B. Hentschel, Clifton Poth, Dominik Hintersdorf, Kristian Kersting",https://arxiv.org/abs/2310.06372,10,"Published at NeurIPS 2023 Workshop on Backdoors in Deep Learning: The Good, the Bad, and the Ugly",
High Dimensional Causal Inference with Variational Backdoor Adjustment,arXiv,2023,2310.06100,"Daniel Israel, Aditya Grover, Guy Van den Broeck",https://arxiv.org/abs/2310.06100,10,,
Better Safe than Sorry: Pre-training CLIP against Targeted Data Poisoning and Backdoor Attacks,arXiv,2023,2310.05862,"Wenhan Yang, Jingdong Gao, Baharan Mirzasoleiman",https://arxiv.org/abs/2310.05862,10,,
Confidence-driven Sampling for Backdoor Attacks,arXiv,2023,2310.05263,"Pengfei He, Han Xu, Yue Xing, Jie Ren, Yingqian Cui, Shenglai Zeng, Jiliang Tang, Makoto Yamada, Mohammad Sabokrou",https://arxiv.org/abs/2310.05263,10,,
Kick Bad Guys Out! Zero-Knowledge-Proof-Based Anomaly Detection in Federated Learning,arXiv,2023,2310.04055,"Shanshan Han, Wenxuan Wu, Baturalp Buyukates, Weizhao Jin, Qifan Zhang, Yuhang Yao, Salman Avestimehr, Chaoyang He",https://arxiv.org/abs/2310.04055,10,,
Backdoor Adjustment of Confounding by Provenance for Robust Text Classification of Multi-institutional Clinical Notes,arXiv,2023,2310.02451,"Xiruo Ding, Zhecheng Sheng, Meliha Yetişgen, Serguei Pakhomov, Trevor Cohen",https://arxiv.org/abs/2310.02451,10,Accepted in AMIA 2023 Annual Symposium,
FLEDGE: Ledger-based Federated Learning Resilient to Inference and Backdoor Attacks,arXiv,2023,2310.02113,"Jorge Castillo, Phillip Rieger, Hossein Fereidooni, Qian Chen, Ahmad Sadeghi",https://arxiv.org/abs/2310.02113,10,To appear in Annual Computer Security Applications Conference (ACSAC) 2023,
Towards Stable Backdoor Purification through Feature Shift Tuning,arXiv,2023,2310.01875,"Rui Min, Zeyu Qin, Li Shen, Minhao Cheng",https://arxiv.org/abs/2310.01875,10,NeurIPS 2023 paper. The first two authors contributed equally,https://github.com/AISafety-HKUST/stable_backdoor_purification
PETA: Parameter-Efficient Trojan Attacks,arXiv,2023,2310.00648,"Lauren Hong, Ting Wang",https://arxiv.org/abs/2310.00648,10,,
GhostEncoder: Stealthy Backdoor Attacks with Dynamic Triggers to Pre-trained Encoders in Self-supervised Learning,arXiv,2023,2310.00626,"Qiannan Wang, Changchun Yin, Zhe Liu, Liming Fang, Run Wang, Chenhao Lin",https://arxiv.org/abs/2310.00626,10,"24 pages,8 figures",
Watch Out! Simple Horizontal Class Backdoors Can Trivially Evade Defenses,arXiv,2023,2310.00542,"Hua Ma, Shang Wang, Yansong Gao, Zhi Zhang, Huming Qiu, Minhui Xue, Alsharif Abuadbba, Anmin Fu, Surya Nepal, Derek Abbott",https://arxiv.org/abs/2310.00542,10,To Appear in the 31st ACM Conference on Computer and Communications Security,
Post-Training Overfitting Mitigation in DNN Classifiers,arXiv,2023,2309.16827,"Hang Wang, David J. Miller, George Kesidis",https://arxiv.org/abs/2309.16827,09,,
Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective,arXiv,2023,2309.16456,"Zhen Qin, Feiyi Chen, Chen Zhi, Xueqiang Yan, Shuiguang Deng",https://arxiv.org/abs/2309.16456,09,Accepted by AAAI 2024. Codes are publicly available at https://github.com/zhenqincn/Snowball,https://github.com/zhenqincn/Snowball
VDC: Versatile Data Cleanser based on Visual-Linguistic Inconsistency by Multimodal Large Language Models,arXiv,2023,2309.16211,"Zihao Zhu, Mingda Zhang, Shaokui Wei, Bingzhe Wu, Baoyuan Wu",https://arxiv.org/abs/2309.16211,09,Accepted to ICLR 2024,https://github.com/zihao-ai/vdc
Seeing Is Not Always Believing: Invisible Collision Attack and Defence on Pre-Trained Models,arXiv,2023,2309.13579,"Minghang Deng, Zhong Zhang, Junming Shao",https://arxiv.org/abs/2309.13579,09,"10 pages, 4 figures",
Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks,arXiv,2023,2309.13256,"Zhaohan Xi, Tianyu Du, Changjiang Li, Ren Pang, Shouling Ji, Jinghui Chen, Fenglong Ma, Ting Wang",https://arxiv.org/abs/2309.13256,09,Accepted by NeurIPS'23,
MarkNerf:Watermarking for Neural Radiance Field,arXiv,2023,2309.11747,"Lifeng Chen, Jia Liu, Yan Ke, Wenquan Sun, Weina Dong, Xiaozhong Pan",https://arxiv.org/abs/2309.11747,09,,
Trojan Taxonomy in Quantum Computing,arXiv,2023,2309.10981,"Subrata Das, Swaroop Ghosh",https://arxiv.org/abs/2309.10981,09,"6 pages, 2 figures",
Steganography for Neural Radiance Fields by Backdooring,arXiv,2023,2309.10503,"Weina Dong, Jia Liu, Yan Ke, Lifeng Chen, Wenquan Sun, Xiaozhong Pan",https://arxiv.org/abs/2309.10503,09,"6 pages, 7 figures",
Robust Backdoor Attacks on Object Detection in Real World,arXiv,2023,2309.08953,"Yaguan Qian, Boyuan Ji, Shuke He, Shenhui Huang, Xiang Ling, Bin Wang, Wei Wang",https://arxiv.org/abs/2309.08953,09,"22 pages, 13figures",
Physical Invisible Backdoor Based on Camera Imaging,arXiv,2023,2309.07428,"Yusheng Guo, Nan Zhong, Zhenxing Qian, Xinpeng Zhang",https://arxiv.org/abs/2309.07428,09,,
MASTERKEY: Practical Backdoor Attack Against Speaker Verification Systems,arXiv,2023,2309.06981,"Hanqing Guo, Xun Chen, Junfeng Guo, Li Xiao, Qiben Yan",https://arxiv.org/abs/2309.06981,09,Accepted by Mobicom 2023,
Backdoor Attacks and Countermeasures in Natural Language Processing Models: A Comprehensive Security Review,arXiv,2023,2309.06055,"Pengzhou Cheng, Zongru Wu, Wei Du, Haodong Zhao, Wei Lu, Gongshen Liu",https://arxiv.org/abs/2309.06055,09,"21 pages, 4 figures",
Towards Robust Model Watermark via Reducing Parametric Vulnerability,arXiv,2023,2309.04777,"Guanhao Gan, Yiming Li, Dongxian Wu, Shu-Tao Xia",https://arxiv.org/abs/2309.04777,09,This paper is accepted by ICCV 2023,https://github.com/GuanhaoGan/robust-model-watermarking
One-to-Multiple Clean-Label Image Camouflage (OmClic) based Backdoor Attack on Deep Learning,arXiv,2023,2309.04036,"Guohong Wang, Hua Ma, Yansong Gao, Alsharif Abuadbba, Zhi Zhang, Wei Kang, Said F. Al-Sarawib, Gongxuan Zhang, Derek Abbott",https://arxiv.org/abs/2309.04036,09,,
Causal Structure Recovery of Linear Dynamical Systems: An FFT based Approach,arXiv,2023,2309.02571,"Mishfad Shaikh Veedu, James Melbourne, Murti V. Salapaka",https://arxiv.org/abs/2309.02571,09,34 pages,
Safe and Robust Watermark Injection with a Single OoD Image,arXiv,2023,2309.01786,"Shuyang Yu, Junyuan Hong, Haobo Zhang, Haotao Wang, Zhangyang Wang, Jiayu Zhou",https://arxiv.org/abs/2309.01786,09,,
BadSQA: Stealthy Backdoor Attacks Using Presence Events as Triggers in Non-Intrusive Speech Quality Assessment,arXiv,2023,2309.01480,"Ying Ren, Kailai Shen, Zhe Ye, Diqun Yan",https://arxiv.org/abs/2309.01480,09,"5 pages, 6 figures,conference",
FTA: Stealthy and Adaptive Backdoor Attack with Flexible Triggers on Federated Learning,arXiv,2023,2309.00127,"Yanqi Qiao, Dazhuang Liu, Congwen Chen, Rui Wang, Kaitai Liang",https://arxiv.org/abs/2309.00127,09,,
Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack,arXiv,2023,2308.16684,"Sze Jue Yang, Quang Nguyen, Chee Seng Chan, Khoa D. Doan",https://arxiv.org/abs/2308.16684,08,14 pages. This paper shows everyone can mount a powerful and stealthy backdoor attack with the widely-used lossy image compression,
MDTD: A Multi Domain Trojan Detector for Deep Neural Networks,arXiv,2023,2308.15673,"Arezoo Rajabi, Surudhi Asokraj, Fengqing Jiang, Luyao Niu, Bhaskar Ramasubramanian, Jim Ritcey, Radha Poovendran",https://arxiv.org/abs/2308.15673,08,Accepted to ACM Conference on Computer and Communications Security (ACM CCS) 2023,
A Comprehensive Overview of Backdoor Attacks in Large Language Models within Communication Networks,arXiv,2023,2308.14367,"Haomiao Yang, Kunlan Xiang, Mengyu Ge, Hongwei Li, Rongxing Lu, Shui Yu",https://arxiv.org/abs/2308.14367,08,,
LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors,arXiv,2023,2308.13904,"Chengkun Wei, Wenlong Meng, Zhikun Zhang, Min Chen, Minghu Zhao, Wenjing Fang, Lei Wang, Zihui Zhang, Wenzhi Chen",https://arxiv.org/abs/2308.13904,08,"To Appear in the Network and Distributed System Security (NDSS) Symposium 2024, 26 February - 1 March 2024, San Diego, CA, USA; typos corrected",
BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection,arXiv,2023,2308.12439,"Tinghao Xie, Xiangyu Qi, Ping He, Yiming Li, Jiachen T. Wang, Prateek Mittal",https://arxiv.org/abs/2308.12439,08,,
PatchBackdoor: Backdoor Attack against Deep Neural Networks without Model Modification,arXiv,2023,2308.11822,"Yizhen Yuan, Rui Kong, Shenghao Xie, Yuanchun Li, Yunxin Liu",https://arxiv.org/abs/2308.11822,08,accepted by ACM MM 2023,
Protect Federated Learning Against Backdoor Attacks via Data-Free Trigger Generation,arXiv,2023,2308.11333,"Yanxin Yang, Ming Hu, Yue Cao, Jun Xia, Yihao Huang, Yang Liu, Mingsong Chen",https://arxiv.org/abs/2308.11333,08,,
Temporal-Distributed Backdoor Attack Against Video Based Action Recognition,arXiv,2023,2308.11070,"Xi Li, Songhe Wang, Ruiquan Huang, Mahanth Gowda, George Kesidis",https://arxiv.org/abs/2308.11070,08,accepted by AAAI 2024,
Backdooring Textual Inversion for Concept Censorship,arXiv,2023,2308.10718,"Yutong Wu, Jie Zhang, Florian Kerschbaum, Tianwei Zhang",https://arxiv.org/abs/2308.10718,08,,https://concept-censorship.github.io
Hiding Backdoors within Event Sequence Data via Poisoning Attacks,arXiv,2023,2308.10201,"Elizaveta Kovtun, Alina Ermilova, Dmitry Berestnev, Alexey Zaytsev",https://arxiv.org/abs/2308.10201,08,,
Backdoor Mitigation by Correcting the Distribution of Neural Activations,arXiv,2023,2308.09850,"Xi Li, Zhen Xiang, David J. Miller, George Kesidis",https://arxiv.org/abs/2308.09850,08,,
Generating Hard Ising Instances With Planted Solutions Using Post-Quantum Cryptographic Protocols,arXiv,2023,2308.09704,"Salvatore Mandrà, Gianni Mossi, Eleanor G. Rieffel",https://arxiv.org/abs/2308.09704,08,,
"DFB: A Data-Free, Low-Budget, and High-Efficacy Clean-Label Backdoor Attack",arXiv,2023,2308.09487,"Binhao Ma, Jiahui Wang, Dejun Wang, Bo Meng",https://arxiv.org/abs/2308.09487,08,,
Causal SAR ATR with Limited Data via Dual Invariance,arXiv,2023,2308.09412,"Chenwei Wang, You Qin, Li Li, Siyi Luo, Yulin Huang, Jifang Pei, Yin Zhang, Jianyu Yang",https://arxiv.org/abs/2308.09412,08,,
Unveiling Causalities in SAR ATR: A Causal Interventional Approach for Limited Data,arXiv,2023,2308.09396,"Chenwei Wang, Xin Chen, You Qin, Siyi Luo, Yulin Huang, Jifang Pei, Jianyu Yang",https://arxiv.org/abs/2308.09396,08,,
Test-Time Backdoor Defense via Detecting and Repairing,arXiv,2023,2308.06107,"Jiyang Guan, Jian Liang, Ran He",https://arxiv.org/abs/2308.06107,08,,
FLShield: A Validation Based Federated Learning Framework to Defend Against Poisoning Attacks,arXiv,2023,2308.05832,"Ehsanul Kabir, Zeyu Song, Md Rafi Ur Rashid, Shagufta Mehnaz",https://arxiv.org/abs/2308.05832,08,,
SSL-Auth: An Authentication Framework by Fragile Watermarking for Pre-trained Encoders in Self-supervised Learning,arXiv,2023,2308.04673,"Xiaobei Li, Changchun Yin, Liyue Zhu, Xiaogang Xu, Liming Fang, Run Wang, Chenhao Lin",https://arxiv.org/abs/2308.04673,08,,
Improved Activation Clipping for Universal Backdoor Mitigation and Test-Time Detection,arXiv,2023,2308.04617,"Hang Wang, Zhen Xiang, David J. Miller, George Kesidis",https://arxiv.org/abs/2308.04617,08,,
Backdoor Federated Learning by Poisoning Backdoor-Critical Layers,arXiv,2023,2308.04466,"Haomin Zhuang, Mingxian Yu, Hao Wang, Yang Hua, Jian Li, Xu Yuan",https://arxiv.org/abs/2308.04466,08,Accepted to ICLR'24,
XGBD: Explanation-Guided Graph Backdoor Detection,arXiv,2023,2308.04406,"Zihan Guan, Mengnan Du, Ninghao Liu",https://arxiv.org/abs/2308.04406,08,"8 pages, 9 figures",https://github.com/GuanZihan/GNN_backdoor_detection
Breaking Speaker Recognition with PaddingBack,arXiv,2023,2308.04179,"Zhe Ye, Diqun Yan, Li Dong, Kailai Shen",https://arxiv.org/abs/2308.04179,08,,
TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal Backdoored Models,arXiv,2023,2308.03906,"Indranil Sur, Karan Sikka, Matthew Walmer, Kaushik Koneripalli, Anirban Roy, Xiao Lin, Ajay Divakaran, Susmit Jha",https://arxiv.org/abs/2308.03906,08,"Published as conference paper at ICCV 2023. 13 pages, 6 figures, 7 tables",https://github.com/SRI-CSL/TIJO
Diffusion Model in Causal Inference with Unmeasured Confounders,arXiv,2023,2308.03669,Tatsuhiro Shimizu,https://arxiv.org/abs/2308.03669,08,"14 pages, 18 figures",
ParaFuzz: An Interpretability-Driven Technique for Detecting Poisoned Samples in NLP,arXiv,2023,2308.02122,"Lu Yan, Zhuo Zhang, Guanhong Tao, Kaiyuan Zhang, Xuan Chen, Guangyu Shen, Xiangyu Zhang",https://arxiv.org/abs/2308.02122,08,,
FLAIRS: FPGA-Accelerated Inference-Resistant & Secure Federated Learning,arXiv,2023,2308.00553,"Huimin Li, Phillip Rieger, Shaza Zeitouni, Stjepan Picek, Ahmad-Reza Sadeghi",https://arxiv.org/abs/2308.00553,08,,
Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection,arXiv,2023,2307.16888,"Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai Wang, Vijay Srinivasan, Xiang Ren, Hongxia Jin",https://arxiv.org/abs/2307.16888,07,Accepted to NAACL 2024. Project page: https://poison-llm.github.io,https://poison-llm.github.io
BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models,arXiv,2023,2307.16489,"Jordan Vice, Naveed Akhtar, Richard Hartley, Ajmal Mian",https://arxiv.org/abs/2307.16489,07,"This research was supported by National Intelligence and Security Discovery Research Grants (project# NS220100007), funded by the Department of Defence Australia",https://github.com/JJ-Vice/BAGM
You Can Backdoor Personalized Federated Learning,arXiv,2023,2307.15971,"Tiandi Ye, Cen Chen, Yinggui Wang, Xiang Li, Ming Gao",https://arxiv.org/abs/2307.15971,07,Submitted to TKDD,https://github.com/BapFL/code
Beating Backdoor Attack at Its Own Game,arXiv,2023,2307.15539,"Min Liu, Alberto Sangiovanni-Vincentelli, Xiangyu Yue",https://arxiv.org/abs/2307.15539,07,Accepted to ICCV 2023,https://github.com/damianliumin/non-adversarial_backdoor
Backdoor Attacks for In-Context Learning with Language Models,arXiv,2023,2307.14692,"Nikhil Kandpal, Matthew Jagielski, Florian Tramèr, Nicholas Carlini",https://arxiv.org/abs/2307.14692,07,AdvML Frontiers Workshop 2023,
Backdoor Attacks against Voice Recognition Systems: A Survey,arXiv,2023,2307.13643,"Baochen Yan, Jiahe Lan, Zheng Yan",https://arxiv.org/abs/2307.13643,07,"33 pages, 7 figures",
Security and Privacy Issues of Federated Learning,arXiv,2023,2307.12181,Jahid Hasan,https://arxiv.org/abs/2307.12181,07,"6 pages, 2 figures",
Adversarial Feature Map Pruning for Backdoor,arXiv,2023,2307.11565,"Dong Huang, Qingwen Bu",https://arxiv.org/abs/2307.11565,07,Accepted to ICLR 2024,https://github.com/retsuh-bqw/FMP
3D-IDS: Doubly Disentangled Dynamic Intrusion Detection,arXiv,2023,2307.11079,"Chenyang Qiu, Yingsheng Geng, Junrui Lu, Kaida Chen, Shitong Zhu, Ya Su, Guoshun Nan, Can Zhang, Junsong Fu, Qimei Cui, Xiaofeng Tao",https://arxiv.org/abs/2307.11079,07,Accepted and appeared in the proceedings of the KDD 2023 Research Track,
Risk-optimized Outlier Removal for Robust 3D Point Cloud Classification,arXiv,2023,2307.10875,"Xinke Li, Junchi Lu, Henghui Ding, Changsheng Sun, Joey Tianyi Zhou, Chee Yeow Meng",https://arxiv.org/abs/2307.10875,07,,
Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples,arXiv,2023,2307.10562,"Shaokui Wei, Mingda Zhang, Hongyuan Zha, Baoyuan Wu",https://arxiv.org/abs/2307.10562,07,,
Attacking by Aligning: Clean-Label Backdoor Attacks on Object Detection,arXiv,2023,2307.10487,"Yize Cheng, Wenbin Hu, Minhao Cheng",https://arxiv.org/abs/2307.10487,07,,
A Dual Stealthy Backdoor: From Both Spatial and Frequency Perspectives,arXiv,2023,2307.10184,"Yudong Gao, Honglong Chen, Peng Sun, Junjian Li, Anqing Zhang, Zhibo Wang",https://arxiv.org/abs/2307.10184,07,"10 pages, 7 figures. Submit to ACM MM 2023",
Rethinking Backdoor Attacks,arXiv,2023,2307.10163,"Alaa Khaddaj, Guillaume Leclerc, Aleksandar Makelov, Kristian Georgiev, Hadi Salman, Andrew Ilyas, Aleksander Madry",https://arxiv.org/abs/2307.10163,07,ICML 2023,
Application of BadNets in Spam Filters,arXiv,2023,2307.09649,"Swagnik Roychoudhury, Akshaj Kumar Veldanda",https://arxiv.org/abs/2307.09649,07,"5 pages, 4 figures, submitted to ICDE23 ASTRIDE, https://astride-2023.github.io/assets/papers/CameraReady14.pdf",https://astride-2023.github.io/assets/papers/CameraReady14.pdf
QDoor: Exploiting Approximate Synthesis for Backdoor Attacks in Quantum Neural Networks,arXiv,2023,2307.09529,"Cheng Chu, Fan Chen, Philip Richerme, Lei Jiang",https://arxiv.org/abs/2307.09529,07,,
FedDefender: Backdoor Attack Defense in Federated Learning,arXiv,2023,2307.08672,"Waris Gill, Ali Anwar, Muhammad Ali Gulzar",https://arxiv.org/abs/2307.08672,07,Published in SE4SafeML 2023 (co-located with FSE 2023). See https://dl.acm.org/doi/abs/10.1145/3617574.3617858,
Towards Stealthy Backdoor Attacks against Speech Recognition via Elements of Sound,arXiv,2023,2307.08208,"Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao, Stefanos Koffas, Yiming Li",https://arxiv.org/abs/2307.08208,07,13 pages,https://github.com/HanboCai/BadSpeech_SoE
Boosting Backdoor Attack with A Learnable Poisoning Sample Selection Strategy,arXiv,2023,2307.07328,"Zihao Zhu, Mingda Zhang, Shaokui Wei, Li Shen, Yanbo Fan, Baoyuan Wu",https://arxiv.org/abs/2307.07328,07,,
Differential Analysis of Triggers and Benign Features for Black-Box DNN Backdoor Detection,arXiv,2023,2307.05422,"Hao Fu, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami",https://arxiv.org/abs/2307.05422,07,Published in the IEEE Transactions on Information Forensics and Security,
Exploring Encrypted Keyboards to Defeat Client-Side Scanning in End-to-End Encryption Systems,arXiv,2023,2307.03426,"Mashari Alatawi, Nitesh Saxena",https://arxiv.org/abs/2307.03426,07,"24 pages, 20 figures. Published in the 25th Annual International Conference on Information Security and Cryptology (ICISC), November/December 2022",
Federated Unlearning via Active Forgetting,arXiv,2023,2307.03363,"Yuyuan Li, Chaochao Chen, Xiaolin Zheng, Jiaming Zhang",https://arxiv.org/abs/2307.03363,07,,
Fedward: Flexible Federated Backdoor Defense Framework with Non-IID Data,arXiv,2023,2307.00356,"Zekai Chen, Fuyi Wang, Zhiwei Zheng, Ximeng Liu, Yujie Lin",https://arxiv.org/abs/2307.00356,07,Accepted by IEEE ICME 2023,
Efficient Backdoor Removal Through Natural Gradient Fine-tuning,arXiv,2023,2306.17441,"Nazmul Karim, Abdullah Al Arafat, Umar Khalid, Zhishan Guo, Naznin Rahnavard",https://arxiv.org/abs/2306.17441,06,,
Neural Polarizer: A Lightweight and Effective Backdoor Defense via Purifying Poisoned Features,arXiv,2023,2306.16697,"Mingli Zhu, Shaokui Wei, Hongyuan Zha, Baoyuan Wu",https://arxiv.org/abs/2306.16697,06,,
Enrollment-stage Backdoor Attacks on Speaker Recognition Systems via Adversarial Ultrasound,arXiv,2023,2306.16022,"Xinfeng Li, Junning Ze, Chen Yan, Yushi Cheng, Xiaoyu Ji, Wenyuan Xu",https://arxiv.org/abs/2306.16022,06,Published in Internet of Things Journal (IoT-J),
Fake the Real: Backdoor Attack on Deep Speech Classification via Voice Conversion,arXiv,2023,2306.15875,"Zhe Ye, Terui Mao, Li Dong, Diqun Yan",https://arxiv.org/abs/2306.15875,06,Accepted by INTERSPEECH 2023,
Adversarial Backdoor Attack by Naturalistic Data Poisoning on Trajectory Prediction in Autonomous Driving,arXiv,2023,2306.15755,"Mozhgan Pourkeshavarz, Mohammad Sabokrou, Amir Rasouli",https://arxiv.org/abs/2306.15755,06,,
Machine Learning needs Better Randomness Standards: Randomised Smoothing and PRNG-based attacks,arXiv,2023,2306.14043,"Pranav Dahiya, Ilia Shumailov, Ross Anderson",https://arxiv.org/abs/2306.14043,06,USENIX Security 2024 (https://www.usenix.org/conference/usenixsecurity24/presentation/dahiya),
A First Order Meta Stackelberg Method for Robust Federated Learning,arXiv,2023,2306.13800,"Yunian Pan, Tao Li, Henger Li, Tianyi Xu, Zizhan Zheng, Quanyan Zhu",https://arxiv.org/abs/2306.13800,06,Accepted to ICML 2023 Workshop on The 2nd New Frontiers In Adversarial Machine Learning. Associated technical report arXiv:2306.13273,
A First Order Meta Stackelberg Method for Robust Federated Learning (Technical Report),arXiv,2023,2306.13273,"Henger Li, Tianyi Xu, Tao Li, Yunian Pan, Quanyan Zhu, Zizhan Zheng",https://arxiv.org/abs/2306.13273,06,Accepted to ICML 2023 Workshop on The 2nd New Frontiers In Adversarial Machine Learning. Workshop Proceedings version: arXiv:2306.13800,
OVLA: Neural Network Ownership Verification using Latent Watermarks,arXiv,2023,2306.13215,"Feisi Fu, Wenchao Li",https://arxiv.org/abs/2306.13215,06,,
Hidden Backdoor Attack against Deep Learning-Based Wireless Signal Modulation Classifiers,arXiv,2023,2306.10753,"Yunsong Huang, Weicheng Liu, Hui-Ming Wang",https://arxiv.org/abs/2306.10753,06,,
Practical and General Backdoor Attacks against Vertical Federated Learning,arXiv,2023,2306.10746,"Yuexin Xuan, Xiaojun Chen, Zhendong Zhao, Bisheng Tang, Ye Dong",https://arxiv.org/abs/2306.10746,06,"17 pages, 7 figures, To appear in ECML PKDD 2023",
Can predictive models be used for causal inference?,arXiv,2023,2306.10551,"Maximilian Pichler, Florian Hartig",https://arxiv.org/abs/2306.10551,06,"47 pages, 4 figures",
Bkd-FedGNN: A Benchmark for Classification Backdoor Attacks on Federated Graph Neural Network,arXiv,2023,2306.10351,"Fan Liu, Siqi Lai, Yansong Ning, Hao Liu",https://arxiv.org/abs/2306.10351,06,,https://github.com/usail-hkust/BkdFedGCN
"Edge Learning for 6G-enabled Internet of Things: A Comprehensive Survey of Vulnerabilities, Datasets, and Defenses",arXiv,2023,2306.10309,"Mohamed Amine Ferrag, Othmane Friha, Burak Kantarci, Norbert Tihanyi, Lucas Cordeiro, Merouane Debbah, Djallel Hamouda, Muna Al-Hawawreh, Kim-Kwang Raymond Choo",https://arxiv.org/abs/2306.10309,06,This paper has been accepted for publication in IEEE Communications Surveys \& Tutorials,
Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios,arXiv,2023,2306.08386,"Ziqiang Li, Hong Sun, Pengfei Xia, Heng Li, Beihao Xia, Yi Wu, Bin Li",https://arxiv.org/abs/2306.08386,06,ICLR 2024,https://github.com/sunh1113/Efficient-backdoor-attacks-for-deep-neural-networks-in-real-world-scenarios
Multi-target Backdoor Attacks for Code Pre-trained Models,arXiv,2023,2306.08350,"Yanzhou Li, Shangqing Liu, Kangjie Chen, Xiaofei Xie, Tianwei Zhang, Yang Liu",https://arxiv.org/abs/2306.08350,06,ACL 2023 main conference,
A Proxy Attack-Free Strategy for Practically Improving the Poisoning Efficiency in Backdoor Attacks,arXiv,2023,2306.08313,"Ziqiang Li, Hong Sun, Pengfei Xia, Beihao Xia, Xue Rui, Wei Zhang, Qinglang Guo, Bin Li",https://arxiv.org/abs/2306.08313,06,Under review,
Privacy Inference-Empowered Stealthy Backdoor Attack on Federated Learning under Non-IID Scenarios,arXiv,2023,2306.08011,"Haochen Mei, Gaolei Li, Jun Wu, Longfei Zheng",https://arxiv.org/abs/2306.08011,06,It can be accepted IJCNN,
DHBE: Data-free Holistic Backdoor Erasing in Deep Neural Networks via Restricted Adversarial Distillation,arXiv,2023,2306.08009,"Zhicong Yan, Shenghong Li, Ruijie Zhao, Yuan Tian, Yuanyuan Zhao",https://arxiv.org/abs/2306.08009,06,It has been accepted by asiaccs,https://github.com/yanzhicong/DHBE
VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion Models,arXiv,2023,2306.06874,"Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho",https://arxiv.org/abs/2306.06874,06,"Accepted by NeurIPS 2023, NeurIPS 2023 BUGS Workshop Oral",
Backdoor Attack with Sparse and Invisible Trigger,arXiv,2023,2306.06209,"Yinghua Gao, Yiming Li, Xueluan Gong, Zhifeng Li, Shu-Tao Xia, Qian Wang",https://arxiv.org/abs/2306.06209,06,The first two authors contributed equally to this work. 13 pages,https://github.com/YinghuaGao/SIBA
Causal Inference With Outcome-Dependent Missingness And Self-Censoring,arXiv,2023,2306.05511,"Jacob M Chen, Daniel Malinsky, Rohit Bhattacharya",https://arxiv.org/abs/2306.05511,06,15 pages. In proceedings of the 39th Conference on Uncertainty in Artificial Intelligence,
G$^2$uardFL: Safeguarding Federated Learning Against Backdoor Attacks through Attributed Client Graph Clustering,arXiv,2023,2306.04984,"Hao Yu, Chuan Ma, Meng Liu, Tianyu Du, Ming Ding, Tao Xiang, Shouling Ji, Xinwang Liu",https://arxiv.org/abs/2306.04984,06,"19 pages, 7 figures",
Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations,arXiv,2023,2306.03600,"Torsten Krauß, Alexandra Dmitrienko",https://arxiv.org/abs/2306.03600,06,"25 pages, 14 figures, 23 tables, 11 equations",
Tree based Progressive Regression Model for Watch-Time Prediction in Short-video Recommendation,arXiv,2023,2306.03392,"Xiao Lin, Xiaokai Chen, Linfeng Song, Jingwei Liu, Biao Li, Peng Jiang",https://arxiv.org/abs/2306.03392,06,,
Revisiting Data-Free Knowledge Distillation with Poisoned Teachers,arXiv,2023,2306.02368,"Junyuan Hong, Yi Zeng, Shuyang Yu, Lingjuan Lyu, Ruoxi Jia, Jiayu Zhou",https://arxiv.org/abs/2306.02368,06,Accepted to ICML 2023,https://github.com/illidanlab/ABD
Mitigating Backdoor Attack Via Prerequisite Transformation,arXiv,2023,2306.01983,Han Gao,https://arxiv.org/abs/2306.01983,06,"7 pages,7 figures,2 tables",
Poisoning Network Flow Classifiers,arXiv,2023,2306.01655,"Giorgio Severi, Simona Boboila, Alina Oprea, John Holodnak, Kendra Kratkiewicz, Jason Matterer",https://arxiv.org/abs/2306.01655,06,"14 pages, 8 figures",
"Versatile Backdoor Attack with Visible, Semantic, Sample-Specific, and Compatible Triggers",arXiv,2023,2306.00816,"Ruotong Wang, Hongrui Chen, Zihao Zhu, Li Liu, Baoyuan Wu",https://arxiv.org/abs/2306.00816,06,,
Adversarial Clean Label Backdoor Attacks and Defenses on Text Classification Systems,arXiv,2023,2305.19607,"Ashim Gupta, Amrith Krishna",https://arxiv.org/abs/2305.19607,05,RepL4NLP 2023 at ACL 2023,
UMD: Unsupervised Model Detection for X2X Backdoor Attacks,arXiv,2023,2305.18651,"Zhen Xiang, Zidi Xiong, Bo Li",https://arxiv.org/abs/2305.18651,05,Proceedings of the 40th International Conference on Machine Learning,
Backdoor Attacks Against Incremental Learners: An Empirical Evaluation Study,arXiv,2023,2305.18384,"Yiqi Zhong, Xianming Liu, Deming Zhai, Junjun Jiang, Xiangyang Ji",https://arxiv.org/abs/2305.18384,05,,
NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models,arXiv,2023,2305.17826,"Kai Mei, Zheng Li, Zhenting Wang, Yang Zhang, Shiqing Ma",https://arxiv.org/abs/2305.17826,05,,https://github.com/RU-System-Software-and-Security/Notable
Backdooring Neural Code Search,arXiv,2023,2305.17506,"Weisong Sun, Yuchen Chen, Guanhong Tao, Chunrong Fang, Xiangyu Zhang, Quanjun Zhang, Bin Luo",https://arxiv.org/abs/2305.17506,05,Accepted to the 61st Annual Meeting of the Association for Computational Linguistics (ACL 2023),
IMBERT: Making BERT Immune to Insertion-based Backdoor Attacks,arXiv,2023,2305.16503,"Xuanli He, Jun Wang, Benjamin Rubinstein, Trevor Cohn",https://arxiv.org/abs/2305.16503,05,accepted to Third Workshop on Trustworthy Natural Language Processing,
Differentially-Private Decision Trees and Provable Robustness to Data Poisoning,arXiv,2023,2305.15394,"Daniël Vos, Jelle Vos, Tianyu Li, Zekeriya Erkin, Sicco Verwer",https://arxiv.org/abs/2305.15394,05,,
From Shortcuts to Triggers: Backdoor Defense with Denoised PoE,arXiv,2023,2305.14910,"Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen",https://arxiv.org/abs/2305.14910,05,Accepted by NAACL 2024 Main Conference,
Reconstructive Neuron Pruning for Backdoor Defense,arXiv,2023,2305.14876,"Yige Li, Xixiang Lyu, Xingjun Ma, Nodens Koren, Lingjuan Lyu, Bo Li, Yu-Gang Jiang",https://arxiv.org/abs/2305.14876,05,Accepted by ICML23,https://github.com/bboylyg/RNP
Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models,arXiv,2023,2305.14710,"Jiashu Xu, Mingyu Derek Ma, Fei Wang, Chaowei Xiao, Muhao Chen",https://arxiv.org/abs/2305.14710,05,NAACL 2024,
Watermarking Classification Dataset for Copyright Protection,arXiv,2023,2305.13257,"Yixin Liu, Hongsheng Hu, Xun Chen, Xuyun Zhang, Lichao Sun",https://arxiv.org/abs/2305.13257,05,,
Chest X-ray Image Classification: A Causal Perspective,arXiv,2023,2305.12072,"Weizhi Nie, Chen Zhang, Dan Song, Lina Zhao, Yunpeng Bai, Keliang Xie, Anan Liu",https://arxiv.org/abs/2305.12072,05,,
Mitigating Backdoor Poisoning Attacks through the Lens of Spurious Correlation,arXiv,2023,2305.11596,"Xuanli He, Qiongkai Xu, Jun Wang, Benjamin Rubinstein, Trevor Cohn",https://arxiv.org/abs/2305.11596,05,accepted to EMNLP2023 (main conference),
Personalization as a Shortcut for Few-Shot Backdoor Attack against Text-to-Image Diffusion Models,arXiv,2023,2305.10701,"Yihao Huang, Felix Juefei-Xu, Qing Guo, Jie Zhang, Yutong Wu, Ming Hu, Tianlin Li, Geguang Pu, Yang Liu",https://arxiv.org/abs/2305.10701,05,"16 pages, accepted by AAAI 2024",
Towards Invisible Backdoor Attacks in the Frequency Domain against Deep Neural Networks,arXiv,2023,2305.10596,"Xinrui Liu, Yajie Wang, Yu-an Tan, Kefan Qiu, Yuanzhang Li",https://arxiv.org/abs/2305.10596,05,arXiv admin note: text overlap with arXiv:2305.09677,
Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark,arXiv,2023,2305.10036,"Wenjun Peng, Jingwei Yi, Fangzhao Wu, Shangxi Wu, Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu, Guangzhong Sun, Xing Xie",https://arxiv.org/abs/2305.10036,05,Accepted by ACL 2023,
Unconfounded Propensity Estimation for Unbiased Ranking,arXiv,2023,2305.09918,"Dan Luo, Lixin Zou, Qingyao Ai, Zhiyu Chen, Chenliang Li, Dawei Yin, Brian D. Davison",https://arxiv.org/abs/2305.09918,05,"11 pages, 5 figures",
Stealthy Low-frequency Backdoor Attack against Deep Neural Networks,arXiv,2023,2305.09677,"Xinrui Liu, Yu-an Tan, Yajie Wang, Kefan Qiu, Yuanzhang Li",https://arxiv.org/abs/2305.09677,05,,
Pick your Poison: Undetectability versus Robustness in Data Poisoning Attacks,arXiv,2023,2305.09671,"Nils Lukas, Florian Kerschbaum",https://arxiv.org/abs/2305.09671,05,Preprint,
UOR: Universal Backdoor Attacks on Pre-trained Language Models,arXiv,2023,2305.09574,"Wei Du, Peixuan Li, Boqun Li, Haodong Zhao, Gongshen Liu",https://arxiv.org/abs/2305.09574,05,,
Manipulating Visually-aware Federated Recommender Systems and Its Countermeasures,arXiv,2023,2305.08183,"Wei Yuan, Shilong Yuan, Chaoqun Yang, Quoc Viet Hung Nguyen, Hongzhi Yin",https://arxiv.org/abs/2305.08183,05,,
Backdoor to the Hidden Ground State: Planted Vertex Cover Example,arXiv,2023,2305.06610,"Xin-Yi Fan, Hai-Jun Zhou",https://arxiv.org/abs/2305.06610,05,"Preprint format, double-spaced, single column, 12 pages",
A Deep Dive into NFT Rug Pulls,arXiv,2023,2305.06108,"Jintao Huang, Ningyu He, Kai Ma, Jiang Xiao, Haoyu Wang",https://arxiv.org/abs/2305.06108,05,,
BadCS: A Backdoor Attack Framework for Code search,arXiv,2023,2305.05503,"Shiyi Qi, Yuanhang Yang, Shuzhzeng Gao, Cuiyun Gao, Zenglin Xu",https://arxiv.org/abs/2305.05503,05,,
Turning Privacy-preserving Mechanisms against Federated Learning,arXiv,2023,2305.05355,"Marco Arazzi, Mauro Conti, Antonino Nocera, Stjepan Picek",https://arxiv.org/abs/2305.05355,05,,
Diffusion Theory as a Scalpel: Detecting and Purifying Poisonous Dimensions in Pre-trained Language Models Caused by Backdoor or Bias,arXiv,2023,2305.04547,"Zhiyuan Zhang, Deli Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun",https://arxiv.org/abs/2305.04547,05,Accepted by Findings of ACL 2023,
Text-to-Image Diffusion Models can be Easily Backdoored through Multimodal Data Poisoning,arXiv,2023,2305.04175,"Shengfang Zhai, Yinpeng Dong, Qingni Shen, Shi Pu, Yuejian Fang, Hang Su",https://arxiv.org/abs/2305.04175,05,Carmera-ready version. To appear in ACM MM 2023. Code will be released at: https://github.com/sf-zhai/BadT2I,https://github.com/sf-zhai/BadT2I
Attacking Pre-trained Recommendation,arXiv,2023,2305.03995,"Yiqing Wu, Ruobing Xie, Zhao Zhang, Yongchun Zhu, FuZhen Zhuang, Jie Zhou, Yongjun Xu, Qing He",https://arxiv.org/abs/2305.03995,05,Accepted by SIGIR 2023,
BadSAM: Exploring Security Vulnerabilities of SAM via Backdoor Attacks,arXiv,2023,2305.03289,"Zihan Guan, Mengxuan Hu, Zhongliang Zhou, Jielu Zhang, Sheng Li, Ninghao Liu",https://arxiv.org/abs/2305.03289,05,"2 pages, 3 figures",
Backdoor Learning on Sequence to Sequence Models,arXiv,2023,2305.02424,"Lichang Chen, Minhao Cheng, Heng Huang",https://arxiv.org/abs/2305.02424,05,14 pages,
Defending against Insertion-based Textual Backdoor Attacks via Attribution,arXiv,2023,2305.02394,"Jiazhao Li, Zhuofeng Wu, Wei Ping, Chaowei Xiao, V. G. Vinod Vydiswaran",https://arxiv.org/abs/2305.02394,05,Findings of ACL 2023. Camera-ready version,
Causal Interventions-based Few-Shot Named Entity Recognition,arXiv,2023,2305.01914,"Zhen Yang, Yongbin Liu, Chunping Ouyang",https://arxiv.org/abs/2305.01914,05,,
DABS: Data-Agnostic Backdoor attack at the Server in Federated Learning,arXiv,2023,2305.01267,"Wenqiang Sun, Sen Li, Yuchang Sun, Jun Zhang",https://arxiv.org/abs/2305.01267,05,Accepted by Backdoor Attacks and Defenses in Machine Learning (BANDS) Workshop at ICLR 2023,
Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models,arXiv,2023,2305.01219,"Shuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, Jie Fu",https://arxiv.org/abs/2305.01219,05,Accepted to appear at the main conference of EMNLP 2023,
FedGrad: Mitigating Backdoor Attacks in Federated Learning Through Local Ultimate Gradients Inspection,arXiv,2023,2305.00328,"Thuy Dung Nguyen, Anh Duy Nguyen, Kok-Seng Wong, Huy Hieu Pham, Thanh Hung Nguyen, Phi Le Nguyen, Truong Thao Nguyen",https://arxiv.org/abs/2305.00328,05,Accepted for presentation at the International Joint Conference on Neural Networks (IJCNN 2023),
Adversary Aware Continual Learning,arXiv,2023,2304.14483,"Muhammad Umer, Robi Polikar",https://arxiv.org/abs/2304.14483,04,,
ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger,arXiv,2023,2304.14475,"Jiazhao Li, Yijin Yang, Zhuofeng Wu, V. G. Vinod Vydiswaran, Chaowei Xiao",https://arxiv.org/abs/2304.14475,04,,
Chameleon: Adapting to Peer Images for Planting Durable Backdoors in Federated Learning,arXiv,2023,2304.12961,"Yanbo Dai, Songze Li",https://arxiv.org/abs/2304.12961,04,This paper was accepted to ICML 2023,
BadGPT: Exploring Security Vulnerabilities of ChatGPT via Backdoor Attacks to InstructGPT,arXiv,2023,2304.12298,"Jiawen Shi, Yixin Liu, Pan Zhou, Lichao Sun",https://arxiv.org/abs/2304.12298,04,This paper is accepted as a poster in NDSS2023,
Enhancing Fine-Tuning Based Backdoor Defense with Sharpness-Aware Minimization,arXiv,2023,2304.11823,"Mingli Zhu, Shaokui Wei, Li Shen, Yanbo Fan, Baoyuan Wu",https://arxiv.org/abs/2304.11823,04,,
Universal Adversarial Backdoor Attacks to Fool Vertical Federated Learning in Cloud-Edge Collaboration,arXiv,2023,2304.11432,"Peng Chen, Xin Du, Zhihui Lu, Hongfeng Chai",https://arxiv.org/abs/2304.11432,04,"14 pages, 7 figures",
RSBA: Robust Statistical Backdoor Attack under Privilege-Constrained Scenarios,arXiv,2023,2304.10985,"Xiaolei Liu, Ming Yi, Kangyi Ding, Bangzhou Xin, Yixiao Xu, Li Yan, Chao Shen",https://arxiv.org/abs/2304.10985,04,"11 pages, 10 figures",
Get Rid Of Your Trail: Remotely Erasing Backdoors in Federated Learning,arXiv,2023,2304.10638,"Manaar Alam, Hithem Lamri, Michail Maniatakos",https://arxiv.org/abs/2304.10638,04,,
"Anomalies, $η$ , $η$' as keys to glueballs",arXiv,2023,2304.09083,Jean-Marie Frère,https://arxiv.org/abs/2304.09083,04,Corfu workshop proceedings 2022,
BadVFL: Backdoor Attacks in Vertical Federated Learning,arXiv,2023,2304.08847,"Mohammad Naseri, Yufei Han, Emiliano De Cristofaro",https://arxiv.org/abs/2304.08847,04,Accepted for publication at the 45th IEEE Symposium on Security & Privacy (S&P 2024). Please cite accordingly,
Evil from Within: Machine Learning Backdoors through Hardware Trojans,arXiv,2023,2304.08411,"Alexander Warnecke, Julian Speith, Jan-Niklas Möller, Konrad Rieck, Christof Paar",https://arxiv.org/abs/2304.08411,04,,
Compositional Probabilistic and Causal Inference using Tractable Circuit Models,arXiv,2023,2304.08278,"Benjie Wang, Marta Kwiatkowska",https://arxiv.org/abs/2304.08278,04,"30 pages, AISTATS 2023",
Detecting Domain-Generation Algorithm (DGA) Based Fully-Qualified Domain Names (FQDNs) with Shannon Entropy,arXiv,2023,2304.07943,Adam Dorian Wong,https://arxiv.org/abs/2304.07943,04,,
Exploiting Logic Locking for a Neural Trojan Attack on Machine Learning Accelerators,arXiv,2023,2304.06017,"Hongye Xu, Dongfang Liu, Cory Merkel, Michael Zuzak",https://arxiv.org/abs/2304.06017,04,Accepted in GLSVLSI 2023,
Model Sparsity Can Simplify Machine Unlearning,arXiv,2023,2304.04934,"Jinghan Jia, Jiancheng Liu, Parikshit Ram, Yuguang Yao, Gaowen Liu, Yang Liu, Pranay Sharma, Sijia Liu",https://arxiv.org/abs/2304.04934,04,NeurIPS'23 spotlight,https://github.com/OPTML-Group/Unlearn-Sparse
UNICORN: A Unified Backdoor Trigger Inversion Framework,arXiv,2023,2304.02786,"Zhenting Wang, Kai Mei, Juan Zhai, Shiqing Ma",https://arxiv.org/abs/2304.02786,04,,https://github.com/RU-System-Software-and-Security/UNICORN
Rethinking the Trigger-injecting Position in Graph Backdoor Attack,arXiv,2023,2304.02277,"Jing Xu, Gorka Abad, Stjepan Picek",https://arxiv.org/abs/2304.02277,04,,
Defending Against Patch-based Backdoor Attacks on Self-Supervised Learning,arXiv,2023,2304.01482,"Ajinkya Tejankar, Maziar Sanjabi, Qifan Wang, Sinong Wang, Hamed Firooz, Hamed Pirsiavash, Liang Tan",https://arxiv.org/abs/2304.01482,04,Accepted to CVPR 2023,https://github.com/UCDvision/PatchSearch
Recover Triggered States: Protect Model Against Backdoor Attack in Reinforcement Learning,arXiv,2023,2304.00252,"Hao Chen, Chen Gong, Yizhe Wang, Xinwen Hou",https://arxiv.org/abs/2304.00252,04,,
Secure Federated Learning against Model Poisoning Attacks via Client Filtering,arXiv,2023,2304.00160,"Duygu Nur Yaldiz, Tuo Zhang, Salman Avestimehr",https://arxiv.org/abs/2304.00160,04,,
Detecting Backdoors During the Inference Stage Based on Corruption Robustness Consistency,arXiv,2023,2303.18191,"Xiaogeng Liu, Minghui Li, Haoyu Wang, Shengshan Hu, Dengpan Ye, Hai Jin, Libing Wu, Chaowei Xiao",https://arxiv.org/abs/2303.18191,03,Accepted by CVPR2023. Code is available at https://github.com/CGCL-codes/TeCo,https://github.com/CGCL-codes/TeCo
Rethinking interpretation: Input-agnostic saliency mapping of deep visual classifiers,arXiv,2023,2303.17836,"Naveed Akhtar, Mohammad A. A. K. Jalwana",https://arxiv.org/abs/2303.17836,03,Accepted for publication in AAAI 2023,
Graph Neural Networks for Hardware Vulnerability Analysis -- Can you Trust your GNN?,arXiv,2023,2303.16690,"Lilas Alrahis, Ozgur Sinanoglu",https://arxiv.org/abs/2303.16690,03,Will be presented at 2023 IEEE VLSI Test Symposium (VTS),
A Universal Identity Backdoor Attack against Speaker Verification based on Siamese Network,arXiv,2023,2303.16031,"Haodong Zhao, Wei Du, Junjie Guo, Gongshen Liu",https://arxiv.org/abs/2303.16031,03,Accepted by the Interspeech 2022. The first two authors contributed equally to this work,
Mask and Restore: Blind Backdoor Defense at Test Time with Masked Autoencoder,arXiv,2023,2303.15564,"Tao Sun, Lu Pang, Chao Chen, Haibin Ling",https://arxiv.org/abs/2303.15564,03,,https://github.com/tsun/BDMAE
Detecting Backdoors in Pre-trained Encoders,arXiv,2023,2303.15180,"Shiwei Feng, Guanhong Tao, Siyuan Cheng, Guangyu Shen, Xiangzhe Xu, Yingqi Liu, Kaiyuan Zhang, Shiqing Ma, Xiangyu Zhang",https://arxiv.org/abs/2303.15180,03,Accepted at CVPR 2023. Code is available at https://github.com/GiantSeaweed/DECREE,https://github.com/GiantSeaweed/DECREE
Backdoor Attacks with Input-unique Triggers in NLP,arXiv,2023,2303.14325,"Xukun Zhou, Jiwei Li, Tianwei Zhang, Lingjuan Lyu, Muqiao Yang, Jun He",https://arxiv.org/abs/2303.14325,03,,
Optimal Smoothing Distribution Exploration for Backdoor Neutralization in Deep Learning-based Traffic Systems,arXiv,2023,2303.14197,"Yue Wang, Wending Li, Michail Maniatakos, Saif Eddin Jabari",https://arxiv.org/abs/2303.14197,03,,
PoisonedGNN: Backdoor Attack on Graph Neural Networks-based Hardware Security Systems,arXiv,2023,2303.14009,"Lilas Alrahis, Satwik Patnaik, Muhammad Abdullah Hanif, Muhammad Shafique, Ozgur Sinanoglu",https://arxiv.org/abs/2303.14009,03,This manuscript is currently under review at IEEE Transactions on Computers,
Physical Backdoor Trigger Activation of Autonomous Vehicle using Reachability Analysis,arXiv,2023,2303.13992,"Wenqing Li, Yue Wang, Muhammad Shafique, Saif Eddin Jabari",https://arxiv.org/abs/2303.13992,03,,
Don't FREAK Out: A Frequency-Inspired Approach to Detecting Backdoor Poisoned Samples in DNNs,arXiv,2023,2303.13211,"Hasan Abed Al Kader Hammoud, Adel Bibi, Philip H. S. Torr, Bernard Ghanem",https://arxiv.org/abs/2303.13211,03,Accepted at CVPRW (The Art of Robustness),
Backdoor Defense via Adaptively Splitting Poisoned Dataset,arXiv,2023,2303.12993,"Kuofeng Gao, Yang Bai, Jindong Gu, Yong Yang, Shu-Tao Xia",https://arxiv.org/abs/2303.12993,03,Accepted by CVPR 2023,https://github.com/KuofengGao/ASD
Do Backdoors Assist Membership Inference Attacks?,arXiv,2023,2303.12589,"Yumeki Goto, Nami Ashizawa, Toshiki Shibahara, Naoto Yanai",https://arxiv.org/abs/2303.12589,03,,
Black-box Backdoor Defense via Zero-shot Image Purification,arXiv,2023,2303.12175,"Yucheng Shi, Mengnan Du, Xuansheng Wu, Zihan Guan, Jin Sun, Ninghao Liu",https://arxiv.org/abs/2303.12175,03,Accepted by NeurIPS 2023,https://github.com/sycny/ZIP
Influencer Backdoor Attack on Semantic Segmentation,arXiv,2023,2303.12054,"Haoheng Lan, Jindong Gu, Philip Torr, Hengshuang Zhao",https://arxiv.org/abs/2303.12054,03,,
Context De-confounded Emotion Recognition,arXiv,2023,2303.11921,"Dingkang Yang, Zhaoyu Chen, Yuzheng Wang, Shunli Wang, Mingcheng Li, Siao Liu, Xiao Zhao, Shuai Huang, Zhiyan Dong, Peng Zhai, Lihua Zhang",https://arxiv.org/abs/2303.11921,03,Accepted by CVPR 2023. CCIM is available at https://github.com/ydk122024/CCIM,https://github.com/ydk122024/CCIM
Did You Train on My Dataset? Towards Public Dataset Protection with Clean-Label Backdoor Watermarking,arXiv,2023,2303.11470,"Ruixiang Tang, Qizhang Feng, Ninghao Liu, Fan Yang, Xia Hu",https://arxiv.org/abs/2303.11470,03,,
Recursive Euclidean Distance Based Robust Aggregation Technique For Federated Learning,arXiv,2023,2303.11337,"Charuka Herath, Yogachandran Rahulamathavan, Xiaolan Liu",https://arxiv.org/abs/2303.11337,03,,
AdaptGuard: Defending Against Universal Attacks for Model Adaptation,arXiv,2023,2303.10594,"Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan",https://arxiv.org/abs/2303.10594,03,ICCV2023,https://github.com/TomSheng21/AdaptGuard
SSL-Cleanse: Trojan Detection and Mitigation in Self-Supervised Learning,arXiv,2023,2303.09079,"Mengxin Zheng, Jiaqi Xue, Zihao Wang, Xun Chen, Qian Lou, Lei Jiang, Xiaofeng Wang",https://arxiv.org/abs/2303.09079,03,"9 pages, 6 figures, 4 tables",
Interventional Bag Multi-Instance Learning On Whole-Slide Pathological Images,arXiv,2023,2303.06873,"Tiancheng Lin, Zhimiao Yu, Hongyu Hu, Yi Xu, Chang Wen Chen",https://arxiv.org/abs/2303.06873,03,Accepted by CVPR 2023; Code at https://github.com/HHHedo/IBMIL,https://github.com/HHHedo/IBMIL
Robust Contrastive Language-Image Pre-training against Data Poisoning and Backdoor Attacks,arXiv,2023,2303.06854,"Wenhan Yang, Jingdong Gao, Baharan Mirzasoleiman",https://arxiv.org/abs/2303.06854,03,,
Backdoor Defense via Deconfounded Representation Learning,arXiv,2023,2303.06818,"Zaixi Zhang, Qi Liu, Zhicai Wang, Zepu Lu, Qingyong Hu",https://arxiv.org/abs/2303.06818,03,Accepted by CVPR 2023,https://github.com/zaixizhang/CBD
Multi-metrics adaptively identifies backdoors in Federated learning,arXiv,2023,2303.06601,"Siquan Huang, Yijiang Li, Chong Chen, Leyu Shi, Ying Gao",https://arxiv.org/abs/2303.06601,03,"14 pages, 8 figures and 7 tables; 2023 IEEE/CVF International Conference on Computer Vision (ICCV)",
Learning the Wrong Lessons: Inserting Trojans During Knowledge Distillation,arXiv,2023,2303.05593,"Leonard Tang, Tom Shlomi, Alexander Cai",https://arxiv.org/abs/2303.05593,03,ICLR 2023 Workshop on Backdoor Attacks and Defenses in Machine Learning,
CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning,arXiv,2023,2303.03323,"Hritik Bansal, Nishad Singhi, Yu Yang, Fan Yin, Aditya Grover, Kai-Wei Chang",https://arxiv.org/abs/2303.03323,03,22 pages. Accepted at ICCV 2023,https://github.com/nishadsinghi/CleanCLIP
Learning to Backdoor Federated Learning,arXiv,2023,2303.03320,"Henger Li, Chen Wu, Sencun Zhu, Zizhan Zheng",https://arxiv.org/abs/2303.03320,03,,
"Backdoor Attacks and Defenses in Federated Learning: Survey, Challenges and Future Research Directions",arXiv,2023,2303.02213,"Thuy Dung Nguyen, Tuan Nguyen, Phi Le Nguyen, Hieu H. Pham, Khoa Doan, Kok-Seng Wong",https://arxiv.org/abs/2303.02213,03,,
NCL: Textual Backdoor Defense Using Noise-augmented Contrastive Learning,arXiv,2023,2303.01742,"Shengfang Zhai, Qingni Shen, Xiaoyi Chen, Weilong Wang, Cong Li, Yuejian Fang, Zhonghai Wu",https://arxiv.org/abs/2303.01742,03,"6 pages, 5 figures. To appear in ICASSP 2023",
Backdoor for Debias: Mitigating Model Bias with Backdoor Attack-based Artificial Bias,arXiv,2023,2303.01504,"Shangxi Wu, Qiuyang He, Fangzhao Wu, Jitao Sang, Yaowei Wang, Changsheng Xu",https://arxiv.org/abs/2303.01504,03,,
Unnoticeable Backdoor Attacks on Graph Neural Networks,arXiv,2023,2303.01263,"Enyan Dai, Minhua Lin, Xiang Zhang, Suhang Wang",https://arxiv.org/abs/2303.01263,03,,
Mitigating Backdoors in Federated Learning with FLD,arXiv,2023,2303.00302,"Yihang Lin, Pengyuan Zhou, Zhiqian Wu, Yong Liao",https://arxiv.org/abs/2303.00302,03,,
Single Image Backdoor Inversion via Robust Smoothed Classifiers,arXiv,2023,2303.00215,"Mingjie Sun, J. Zico Kolter",https://arxiv.org/abs/2303.00215,03,CVPR 2023. v2: improved writing,https://github.com/locuslab/smoothinv
Backdoor Attacks Against Deep Image Compression via Adaptive Frequency Trigger,arXiv,2023,2302.14677,"Yi Yu, Yufei Wang, Wenhan Yang, Shijian Lu, Yap-peng Tan, Alex C. Kot",https://arxiv.org/abs/2302.14677,02,Accepted by CVPR 2023,
FreeEagle: Detecting Complex Neural Trojans in Data-Free Cases,arXiv,2023,2302.14500,"Chong Fu, Xuhong Zhang, Shouling Ji, Ting Wang, Peng Lin, Yanghe Feng, Jianwei Yin",https://arxiv.org/abs/2302.14500,02,Accepted by USENIX Security 2023,
A semantic backdoor attack against Graph Convolutional Networks,arXiv,2023,2302.14353,"Jiazhu Dai, Zhipeng Xiong",https://arxiv.org/abs/2302.14353,02,,
SATBA: An Invisible Backdoor Attack Based On Spatial Attention,arXiv,2023,2302.13056,"Huasong Zhou, Xiaowei Xu, Xiaodong Wang, Leon Bevan Bullock",https://arxiv.org/abs/2302.13056,02,"9 pages, 9 figures",
Defending Against Backdoor Attacks by Layer-wise Feature Analysis,arXiv,2023,2302.12758,"Najeeb Moharram Jebreel, Josep Domingo-Ferrer, Yiming Li",https://arxiv.org/abs/2302.12758,02,This paper is accepted by PAKDD 2023,
Analyzing And Editing Inner Mechanisms Of Backdoored Language Models,arXiv,2023,2302.12461,"Max Lamparth, Anka Reuel",https://arxiv.org/abs/2302.12461,02,Final version accepted at FAccT 24,
Provable Robustness Against a Union of $\ell_0$ Adversarial Attacks,arXiv,2023,2302.11628,"Zayd Hammoudeh, Daniel Lowd",https://arxiv.org/abs/2302.11628,02,Accepted at AAAI 2024 -- Extended version including the supplementary material,
ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep Learning Paradigms,arXiv,2023,2302.11408,"Minzhou Pan, Yi Zeng, Lingjuan Lyu, Xue Lin, Ruoxi Jia",https://arxiv.org/abs/2302.11408,02,"18 pages, with 13 pages of main text",https://github.com/ruoxi-jia-group/ASSET
On Feasibility of Server-side Backdoor Attacks on Split Learning,arXiv,2023,2302.09578,"Behrad Tajalli, Oguzhan Ersoy, Stjepan Picek",https://arxiv.org/abs/2302.09578,02,,
Attacks in Adversarial Machine Learning: A Systematic Survey from the Life-cycle Perspective,arXiv,2023,2302.09457,"Baoyuan Wu, Zihao Zhu, Li Liu, Qingshan Liu, Zhaofeng He, Siwei Lyu",https://arxiv.org/abs/2302.09457,02,"35 pages, 4 figures, 10 tables, 313 reference papers",
RobustNLP: A Technique to Defend NLP Models Against Backdoor Attacks,arXiv,2023,2302.09420,Marwan Omar,https://arxiv.org/abs/2302.09420,02,,https://github.com/marwanomar1/Backdoor-Learning-for-NLP
Backdoor Attacks to Pre-trained Unified Foundation Models,arXiv,2023,2302.09360,"Zenghui Yuan, Yixin Liu, Kai Zhang, Pan Zhou, Lichao Sun",https://arxiv.org/abs/2302.09360,02,This paper is accepted as a poster for NDSS 2023,
SplitOut: Out-of-the-Box Training-Hijacking Detection in Split Learning via Outlier Detection,arXiv,2023,2302.08618,"Ege Erdogan, Unat Teksen, Mehmet Salih Celiktenyildiz, Alptekin Kupcu, A. Ercument Cicek",https://arxiv.org/abs/2302.08618,02,,
QTrojan: A Circuit Backdoor Against Quantum Neural Networks,arXiv,2023,2302.08090,"Cheng Chu, Lei Jiang, Martin Swany, Fan Chen",https://arxiv.org/abs/2302.08090,02,,
"Backdoor Learning for NLP: Recent Advances, Challenges, and Future Research Directions",arXiv,2023,2302.06801,Marwan Omar,https://arxiv.org/abs/2302.06801,02,,
Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural Networks with Neuromorphic Data,arXiv,2023,2302.06279,"Gorka Abad, Oguzhan Ersoy, Stjepan Picek, Aitor Urbieta",https://arxiv.org/abs/2302.06279,02,To appear in Network and Distributed System Security (NDSS) Symposium 2024,
Mithridates: Auditing and Boosting Backdoor Resistance of Machine Learning Pipelines,arXiv,2023,2302.04977,"Eugene Bagdasaryan, Vitaly Shmatikov",https://arxiv.org/abs/2302.04977,02,,
Imperceptible Sample-Specific Backdoor to DNN with Denoising Autoencoder,arXiv,2023,2302.04457,"Jiliang Zhang, Jing Xu, Zhi Zhang, Yansong Gao",https://arxiv.org/abs/2302.04457,02,"8 pages, 8 figures",
Training-free Lexical Backdoor Attacks on Language Models,arXiv,2023,2302.04116,"Yujin Huang, Terry Yue Zhuo, Qiongkai Xu, Han Hu, Xingliang Yuan, Chunyang Chen",https://arxiv.org/abs/2302.04116,02,"Accepted to International World Wide Web Conference 2023, Security, Privacy & Trust Track",https://github.com/Jinxhy/TFLexAttack
SCALE-UP: An Efficient Black-box Input-level Backdoor Detection via Analyzing Scaled Prediction Consistency,arXiv,2023,2302.03251,"Junfeng Guo, Yiming Li, Xun Chen, Hanqing Guo, Lichao Sun, Cong Liu",https://arxiv.org/abs/2302.03251,02,,https://github.com/JunfengGo/SCALE-UP
BackdoorBox: A Python Toolbox for Backdoor Learning,arXiv,2023,2302.01762,"Yiming Li, Mengxi Ya, Yang Bai, Yong Jiang, Shu-Tao Xia",https://arxiv.org/abs/2302.01762,02,BackdoorBox V0.1. The first two authors contributed equally to this toolbox. 13 pages,https://github.com/THUYimingLi/BackdoorBox
SoK: A Systematic Evaluation of Backdoor Trigger Characteristics in Image Classification,arXiv,2023,2302.01740,"Gorka Abad, Jing Xu, Stefanos Koffas, Behrad Tajalli, Stjepan Picek, Mauro Conti",https://arxiv.org/abs/2302.01740,02,,
Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks,arXiv,2023,2302.01677,"Zeyu Qin, Liuyi Yao, Daoyuan Chen, Yaliang Li, Bolin Ding, Minhao Cheng",https://arxiv.org/abs/2302.01677,02,KDD 2023,https://github.com/alibaba/FederatedScope/tree/backdoor-bench
Universal Soldier: Using Universal Adversarial Perturbations for Detecting Backdoor Attacks,arXiv,2023,2302.00747,"Xiaoyun Xu, Oguzhan Ersoy, Stjepan Picek",https://arxiv.org/abs/2302.00747,02,,
Salient Conditional Diffusion for Defending Against Backdoor Attacks,arXiv,2023,2301.13862,"Brandon B. May, N. Joseph Tatro, Dylan Walker, Piyush Kumar, Nathan Shnidman",https://arxiv.org/abs/2301.13862,01,"14 pages, 5 figures. Edit: Added new baselines",
Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering,arXiv,2023,2301.12318,"Rui Zhu, Di Tang, Siyuan Tang, Guanhong Tao, Shiqing Ma, Xiaofeng Wang, Haixu Tang",https://arxiv.org/abs/2301.12318,01,,
PECAN: A Deterministic Certified Defense Against Backdoor Attacks,arXiv,2023,2301.11824,"Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni",https://arxiv.org/abs/2301.11824,01,,
Distilling Cognitive Backdoor Patterns within an Image,arXiv,2023,2301.10908,"Hanxun Huang, Xingjun Ma, Sarah Erfani, James Bailey",https://arxiv.org/abs/2301.10908,01,ICLR2023,https://github.com/HanxunH/CognitiveDistillation
BDMMT: Backdoor Sample Detection for Language Models through Model Mutation Testing,arXiv,2023,2301.10412,"Jiali Wei, Ming Fan, Wenjing Jiao, Wuxia Jin, Ting Liu",https://arxiv.org/abs/2301.10412,01,,
Backdoor Attacks in Peer-to-Peer Federated Learning,arXiv,2023,2301.09732,"Gokberk Yar, Simona Boboila, Cristina Nita-Rotaru, Alina Oprea",https://arxiv.org/abs/2301.09732,01,,
BayBFed: Bayesian Backdoor Defense for Federated Learning,arXiv,2023,2301.09508,"Kavita Kumari, Phillip Rieger, Hossein Fereidooni, Murtuza Jadliwala, Ahmad-Reza Sadeghi",https://arxiv.org/abs/2301.09508,01,,
Towards Understanding How Self-training Tolerates Data Backdoor Poisoning,arXiv,2023,2301.08751,"Soumyadeep Pal, Ren Wang, Yuguang Yao, Sijia Liu",https://arxiv.org/abs/2301.08751,01,Accepted at SafeAI 2023: AAAI's Workshop on Artificial Intelligence Safety,
On the Vulnerability of Backdoor Defenses for Federated Learning,arXiv,2023,2301.08170,"Pei Fang, Jinghui Chen",https://arxiv.org/abs/2301.08170,01,"Accepted by AAAI 2023 (15 pages, 12 figures, 7 tables)",
BEAGLE: Forensics of Deep Learning Backdoor Attack for Better Defense,arXiv,2023,2301.06241,"Siyuan Cheng, Guanhong Tao, Yingqi Liu, Shengwei An, Xiangzhe Xu, Shiwei Feng, Guangyu Shen, Kaiyuan Zhang, Qiuling Xu, Shiqing Ma, Xiangyu Zhang",https://arxiv.org/abs/2301.06241,01,,
Universal Detection of Backdoor Attacks via Density-based Clustering and Centroids Analysis,arXiv,2023,2301.04554,"Wei Guo, Benedetta Tondi, Mauro Barni",https://arxiv.org/abs/2301.04554,01,,
Facial Misrecognition Systems: Simple Weight Manipulations Force DNNs to Err Only on Specific Persons,arXiv,2023,2301.03118,"Irad Zehavi, Adi Shamir",https://arxiv.org/abs/2301.03118,01,,
"Silent Killer: A Stealthy, Clean-Label, Black-Box Backdoor Attack",arXiv,2023,2301.02615,"Tzvi Lederer, Gallil Maimon, Lior Rokach",https://arxiv.org/abs/2301.02615,01,,
Stealthy Backdoor Attack for Code Models,arXiv,2023,2301.02496,"Zhou Yang, Bowen Xu, Jie M. Zhang, Hong Jin Kang, Jieke Shi, Junda He, David Lo",https://arxiv.org/abs/2301.02496,01,"18 pages, Under review of IEEE Transactions on Software Engineering",
Backdoor Attacks Against Dataset Distillation,arXiv,2023,2301.01197,"Yugeng Liu, Zheng Li, Michael Backes, Yun Shen, Yang Zhang",https://arxiv.org/abs/2301.01197,01,,
Mutual Information Regularization for Vertical Federated Learning,arXiv,2023,2301.01142,"Tianyuan Zou, Yang Liu, Ya-Qin Zhang",https://arxiv.org/abs/2301.01142,01,"12 pages, 9 figures",
"Look, Listen, and Attack: Backdoor Attacks Against Video Action Recognition",arXiv,2023,2301.00986,"Hasan Abed Al Kader Hammoud, Shuming Liu, Mohammed Alkhrashi, Fahad AlBalawi, Bernard Ghanem",https://arxiv.org/abs/2301.00986,01,,
Trojaning semi-supervised learning model via poisoning wild images on the web,arXiv,2023,2301.00435,"Le Feng, Zhenxing Qian, Sheng Li, Xinpeng Zhang",https://arxiv.org/abs/2301.00435,01,,
XMAM:X-raying Models with A Matrix to Reveal Backdoor Attacks for Federated Learning,arXiv,2022,2212.13675,"Jianyi Zhang, Fangjiao Zhang, Qichao Jin, Zhiqiang Wang, Xiaodong Lin, Xiali Hei",https://arxiv.org/abs/2212.13675,12,23 pages,
Mind Your Heart: Stealthy Backdoor Attack on Dynamic Deep Neural Network in Edge Computing,arXiv,2022,2212.11751,"Tian Dong, Ziyuan Zhang, Han Qiu, Tianwei Zhang, Hewu Li, Terry Wang",https://arxiv.org/abs/2212.11751,12,Accepted to IEEE INFOCOM 2023,
Vulnerabilities of Deep Learning-Driven Semantic Communications to Backdoor (Trojan) Attacks,arXiv,2022,2212.11205,"Yalin E. Sagduyu, Tugba Erpek, Sennur Ulukus, Aylin Yener",https://arxiv.org/abs/2212.11205,12,,
VSVC: Backdoor attack against Keyword Spotting based on Voiceprint Selection and Voice Conversion,arXiv,2022,2212.10103,"Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao, Shunhui Ji",https://arxiv.org/abs/2212.10103,12,"7 pages,5 figures",
Flareon: Stealthy any2any Backdoor Injection via Poisoned Augmentation,arXiv,2022,2212.09979,"Tianrui Qin, Xianghuan He, Xitong Gao, Yiren Zhao, Kejiang Ye, Cheng-Zhong Xu",https://arxiv.org/abs/2212.09979,12,,https://github.com/lafeat/flareon
Task-Oriented Communications for NextG: End-to-End Deep Learning and AI Security Aspects,arXiv,2022,2212.09668,"Yalin E. Sagduyu, Sennur Ulukus, Aylin Yener",https://arxiv.org/abs/2212.09668,12,,
AI Security for Geoscience and Remote Sensing: Challenges and Future Trends,arXiv,2022,2212.09360,"Yonghao Xu, Tao Bai, Weikang Yu, Shizhen Chang, Peter M. Atkinson, Pedram Ghamisi",https://arxiv.org/abs/2212.09360,12,,
Fine-Tuning Is All You Need to Mitigate Backdoor Attacks,arXiv,2022,2212.09067,"Zeyang Sha, Xinlei He, Pascal Berrang, Mathias Humbert, Yang Zhang",https://arxiv.org/abs/2212.09067,12,"17 pages, 17 figures",
Backdoor Attack Detection in Computer Vision by Applying Matrix Factorization on the Weights of Deep Networks,arXiv,2022,2212.08121,"Khondoker Murad Hossain, Tim Oates",https://arxiv.org/abs/2212.08121,12,"7 pages, 4 figures, 5 tables, AAAI Workshop on Safe AI 2023",
Backdoor Mitigation in Deep Neural Networks via Strategic Retraining,arXiv,2022,2212.07278,"Akshay Dhonthi, Ernst Moritz Hahn, Vahid Hashemi",https://arxiv.org/abs/2212.07278,12,"13 Pages, 7 Tables, 4 Figures. Accepted at the International Symposium of Formal Methods 2023 (FM 2023)",
How to Backdoor Diffusion Models?,arXiv,2022,2212.05400,"Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho",https://arxiv.org/abs/2212.05400,12,Accepted by CVPR 2023,https://github.com/IBM/BadDiffusion
"Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of Backdoor Effects in Trojaned Machine Learning Models",arXiv,2022,2212.04687,"Rui Zhu, Di Tang, Siyuan Tang, XiaoFeng Wang, Haixu Tang",https://arxiv.org/abs/2212.04687,12,,
XRand: Differentially Private Defense against Explanation-Guided Attacks,arXiv,2022,2212.04454,"Truc Nguyen, Phung Lai, NhatHai Phan, My T. Thai",https://arxiv.org/abs/2212.04454,12,To be published at AAAI 2023,
Pre-trained Encoders in Self-Supervised Learning Improve Secure and Privacy-preserving Supervised Learning,arXiv,2022,2212.03334,"Hongbin Liu, Wenjie Qu, Jinyuan Jia, Neil Zhenqiang Gong",https://arxiv.org/abs/2212.03334,12,,
Rethinking Backdoor Data Poisoning Attacks in the Context of Semi-Supervised Learning,arXiv,2022,2212.02582,"Marissa Connor, Vincent Emanuele",https://arxiv.org/abs/2212.02582,12,"18 pages, 14 figures",
FedCC: Robust Federated Learning against Model Poisoning Attacks,arXiv,2022,2212.01976,"Hyejun Jeong, Hamin Son, Seohu Lee, Jayun Hyun, Tai-Myoung Chung",https://arxiv.org/abs/2212.01976,12,,
Be Careful with Rotation: A Uniform Backdoor Pattern for 3D Shape,arXiv,2022,2211.16192,"Linkun Fan, Fazhi He, Qing Guo, Wei Tang, Xiaolin Hong, Bing Li",https://arxiv.org/abs/2211.16192,11,,
Backdoor Vulnerabilities in Normally Trained Deep Learning Models,arXiv,2022,2211.15929,"Guanhong Tao, Zhenting Wang, Siyuan Cheng, Shiqing Ma, Shengwei An, Yingqi Liu, Guangyu Shen, Zhuo Zhang, Yunshu Mao, Xiangyu Zhang",https://arxiv.org/abs/2211.15929,11,,
On the Security Vulnerabilities of Text-to-SQL Models,arXiv,2022,2211.15363,"Xutan Peng, Yipeng Zhang, Jingfeng Yang, Mark Stevenson",https://arxiv.org/abs/2211.15363,11,"Best Paper Candidate at ISSRE 2023. Replaced ""PLM"" with ""LLM"" for better visibility",
Navigation as Attackers Wish? Towards Building Robust Embodied Agents under Federated Learning,arXiv,2022,2211.14769,"Yunchao Zhang, Zonglin Di, Kaiwen Zhou, Cihang Xie, Xin Eric Wang",https://arxiv.org/abs/2211.14769,11,,
BadPrompt: Backdoor Attacks on Continuous Prompts,arXiv,2022,2211.14719,"Xiangrui Cai, Haidong Xu, Sihan Xu, Ying Zhang, Xiaojie Yuan",https://arxiv.org/abs/2211.14719,11,Accepted at NeurIPS 2022,https://github.com/papersPapers/BadPrompt
Backdoor Cleansing with Unlabeled Data,arXiv,2022,2211.12044,"Lu Pang, Tao Sun, Haibin Ling, Chao Chen",https://arxiv.org/abs/2211.12044,11,Accepted to CVPR 2023,https://github.com/luluppang/BCU
A Survey on Backdoor Attack and Defense in Natural Language Processing,arXiv,2022,2211.11958,"Xuan Sheng, Zhaoyang Han, Piji Li, Xiangmao Chang",https://arxiv.org/abs/2211.11958,11,"12 pages, QRS2022",
Backdoor Attacks on Multiagent Collaborative Systems,arXiv,2022,2211.11455,"Shuo Chen, Yue Qiu, Jie Zhang",https://arxiv.org/abs/2211.11455,11,11 pages,
Invisible Backdoor Attack with Dynamic Triggers against Person Re-identification,arXiv,2022,2211.10933,"Wenli Sun, Xinyang Jiang, Shuguang Dou, Dongsheng Li, Duoqian Miao, Cheng Deng, Cairong Zhao",https://arxiv.org/abs/2211.10933,11,,
Provable Defense against Backdoor Policies in Reinforcement Learning,arXiv,2022,2211.10530,"Shubham Kumar Bharti, Xuezhou Zhang, Adish Singla, Xiaojin Zhu",https://arxiv.org/abs/2211.10530,11,Accepted at Neurips 2022,
Computational Short Cuts in Infinite Domain Constraint Satisfaction,arXiv,2022,2211.10144,"Peter Jonsson, Victor Lagerkvist, Sebastian Ordyniak",https://arxiv.org/abs/2211.10144,11,,
UPTON: Preventing Authorship Leakage from Public Text Release via Data Poisoning,arXiv,2022,2211.09717,"Ziyao Wang, Thai Le, Dongwon Lee",https://arxiv.org/abs/2211.09717,11,,
PBSM: Backdoor attack against Keyword spotting based on pitch boosting and sound masking,arXiv,2022,2211.08697,"Hanbo Cai, Pengcheng Zhang, Hai Dong, Yan Xiao, Shunhui Ji",https://arxiv.org/abs/2211.08697,11,"5 pages, 4 figures",
CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive Learning,arXiv,2022,2211.08229,"Jinghuai Zhang, Hongbin Liu, Jinyuan Jia, Neil Zhenqiang Gong",https://arxiv.org/abs/2211.08229,11,CVPR 2024,
Backdoor Attacks for Remote Sensing Data with Wavelet Transform,arXiv,2022,2211.08044,"Nikolaus Dräger, Yonghao Xu, Pedram Ghamisi",https://arxiv.org/abs/2211.08044,11,,https://github.com/ndraeger/waba
Backdoor Attacks on Time Series: A Generative Approach,arXiv,2022,2211.07915,"Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani, James Bailey",https://arxiv.org/abs/2211.07915,11,,
Watermarking in Secure Federated Learning: A Verification Framework Based on Client-Side Backdooring,arXiv,2022,2211.07138,"Wenyuan Yang, Shuo Shao, Yue Yang, Xiyao Liu, Ximeng Liu, Zhihua Xia, Gerald Schaefer, Hui Fang",https://arxiv.org/abs/2211.07138,11,,
Untargeted Backdoor Attack against Object Detection,arXiv,2022,2211.05638,"Chengxiao Luo, Yiming Li, Yong Jiang, Shu-Tao Xia",https://arxiv.org/abs/2211.05638,11,This paper is accepted by ICASSP 2023. 5 pages,
Backdoor Defense via Suppressing Model Shortcuts,arXiv,2022,2211.05631,"Sheng Yang, Yiming Li, Yong Jiang, Shu-Tao Xia",https://arxiv.org/abs/2211.05631,11,This paper is accepted by ICASSP 2023. 5 pages,
MSDT: Masked Language Model Scoring Defense in Text Domain,arXiv,2022,2211.05371,"Jaechul Roh, Minhao Cheng, Yajun Fang",https://arxiv.org/abs/2211.05371,11,"5 pages, 1 figure, 4 tables, accepted as a conference paper at IEEE UV 2022, Boston, USA",https://github.com/jcroh0508/MSDT
Physics-Constrained Backdoor Attacks on Power System Fault Localization,arXiv,2022,2211.04445,"Jianing Bai, Ren Wang, Zuyi Li",https://arxiv.org/abs/2211.04445,11,,
Going In Style: Audio Backdoors Through Stylistic Transformations,arXiv,2022,2211.03117,"Stefanos Koffas, Luca Pajola, Stjepan Picek, Mauro Conti",https://arxiv.org/abs/2211.03117,11,Accepted to ICASSP '23 and the first two authors contributed equally,https://github.com/skoffas/going-in-style
Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis,arXiv,2022,2211.02408,"Lukas Struppek, Dominik Hintersdorf, Kristian Kersting",https://arxiv.org/abs/2211.02408,11,Published as a conference paper at ICCV 2023,
M-to-N Backdoor Paradigm: A Stealthy and Fuzzy Attack to Deep Learning Models,arXiv,2022,2211.01875,"Linshan Hou, Zhongyun Hua, Yuhong Li, Leo Yu Zhang",https://arxiv.org/abs/2211.01875,11,,
Dormant Neural Trojans,arXiv,2022,2211.01808,"Feisi Fu, Panagiota Kiourti, Wenchao Li",https://arxiv.org/abs/2211.01808,11,,
BATT: Backdoor Attack with Transformation-based Triggers,arXiv,2022,2211.01806,"Tong Xu, Yiming Li, Yong Jiang, Shu-Tao Xia",https://arxiv.org/abs/2211.01806,11,This paper is accepted by ICASSP 2023. 5 pages,
The Perils of Learning From Unlabeled Data: Backdoor Attacks on Semi-supervised Learning,arXiv,2022,2211.00453,"Virat Shejwalkar, Lingjuan Lyu, Amir Houmansadr",https://arxiv.org/abs/2211.00453,11,,
Poison Attack and Defense on Deep Source Code Processing Models,arXiv,2022,2210.17029,"Jia Li, Zhuo Li, Huangzhao Zhang, Ge Li, Zhi Jin, Xing Hu, Xin Xia",https://arxiv.org/abs/2210.17029,10,"23 pages, 9 figures",
Multi-feature Dataset for Windows PE Malware Classification,arXiv,2022,2210.16285,"Muhammad Irfan Yousuf, Izza Anwer, Tanzeela Shakir, Minahil Siddiqui, Maysoon Shahid",https://arxiv.org/abs/2210.16285,10,"9 Pages, 1 Figure, 5 Tables",
Rethinking the Reverse-engineering of Trojan Triggers,arXiv,2022,2210.15127,"Zhenting Wang, Kai Mei, Hailun Ding, Juan Zhai, Shiqing Ma",https://arxiv.org/abs/2210.15127,10,,https://github.com/RU-System-Software-and-Security/FeatureRE
Universal Evasion Attacks on Summarization Scoring,arXiv,2022,2210.14260,"Wenchuan Mu, Kwan Hui Lim",https://arxiv.org/abs/2210.14260,10,,
Motif-Backdoor: Rethinking the Backdoor Attack on Graph Neural Networks via Motifs,arXiv,2022,2210.13710,"Haibin Zheng, Haiyang Xiong, Jinyin Chen, Haonan Ma, Guohan Huang",https://arxiv.org/abs/2210.13710,10,,
Towards Out-of-Distribution Sequential Event Prediction: A Causal Treatment,arXiv,2022,2210.13005,"Chenxiao Yang, Qitian Wu, Qingsong Wen, Zhiqiang Zhou, Liang Sun, Junchi Yan",https://arxiv.org/abs/2210.13005,10,in NeurIPS 2022,
FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning,arXiv,2022,2210.12873,"Kaiyuan Zhang, Guanhong Tao, Qiuling Xu, Siyuan Cheng, Shengwei An, Yingqi Liu, Shiwei Feng, Guangyu Shen, Pin-Yu Chen, Shiqing Ma, Xiangyu Zhang",https://arxiv.org/abs/2210.12873,10,Accepted by ICLR 2023. Code is available at https://github.com/KaiyuanZh/FLIP,https://github.com/KaiyuanZh/FLIP
Neural Architectural Backdoors,arXiv,2022,2210.12179,"Ren Pang, Changjiang Li, Zhaohan Xi, Shouling Ji, Ting Wang",https://arxiv.org/abs/2210.12179,10,,
Detecting Backdoors in Deep Text Classifiers,arXiv,2022,2210.11264,"You Guo, Jun Wang, Trevor Cohn",https://arxiv.org/abs/2210.11264,10,"8 pages, 10 figures",
Emerging Threats in Deep Learning-Based Autonomous Driving: A Comprehensive Survey,arXiv,2022,2210.11237,"Hui Cao, Wenlong Zou, Yinkun Wang, Ting Song, Mengjun Liu",https://arxiv.org/abs/2210.11237,10,"28 pages,10 figures",
Apple of Sodom: Hidden Backdoors in Superior Sentence Embeddings via Contrastive Learning,arXiv,2022,2210.11082,"Xiaoyi Chen, Baisong Xin, Shengfang Zhai, Shiqing Ma, Qingni Shen, Zhonghai Wu",https://arxiv.org/abs/2210.11082,10,,
FedRecover: Recovering from Poisoning Attacks in Federated Learning using Historical Information,arXiv,2022,2210.10936,"Xiaoyu Cao, Jinyuan Jia, Zaixi Zhang, Neil Zhenqiang Gong",https://arxiv.org/abs/2210.10936,10,To appear in IEEE S&P 2023,
Backdoor Attack and Defense in Federated Generative Adversarial Network-based Medical Image Synthesis,arXiv,2022,2210.10886,"Ruinan Jin, Xiaoxiao Li",https://arxiv.org/abs/2210.10886,10,"25 pages, 7 figures. arXiv admin note: text overlap with arXiv:2207.00762",
Training set cleansing of backdoor poisoning by self-supervised representation learning,arXiv,2022,2210.10272,"H. Wang, S. Karami, O. Dia, H. Ritter, E. Emamjomeh-Zadeh, J. Chen, Z. Xiang, D. J. Miller, G. Kesidis",https://arxiv.org/abs/2210.10272,10,,
Fine-mixing: Mitigating Backdoors in Fine-tuned Language Models,arXiv,2022,2210.09545,"Zhiyuan Zhang, Lingjuan Lyu, Xingjun Ma, Chenguang Wang, Xu Sun",https://arxiv.org/abs/2210.09545,10,Accepted by Findings of EMNLP 2022,
Thinking Two Moves Ahead: Anticipating Other Users Improves Backdoor Attacks in Federated Learning,arXiv,2022,2210.09305,"Yuxin Wen, Jonas Geiping, Liam Fowl, Hossein Souri, Rama Chellappa, Micah Goldblum, Tom Goldstein",https://arxiv.org/abs/2210.09305,10,Code is available at \url{https://github.com/YuxinWenRick/thinking-two-moves-ahead},https://github.com/YuxinWenRick/thinking-two-moves-ahead
Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class,arXiv,2022,2210.09194,"Khoa D. Doan, Yingjie Lao, Ping Li",https://arxiv.org/abs/2210.09194,10,Accepted to NeurIPS 2022,
Expose Backdoors on the Way: A Feature-Based Efficient Defense against Textual Backdoor Attacks,arXiv,2022,2210.07907,"Sishuo Chen, Wenkai Yang, Zhiyuan Zhang, Xiaohan Bi, Xu Sun",https://arxiv.org/abs/2210.07907,10,Findings of EMNLP 2022,https://github.com/lancopku/DAN
CrowdGuard: Federated Backdoor Detection in Federated Learning,arXiv,2022,2210.07714,"Phillip Rieger, Torsten Krauß, Markus Miettinen, Alexandra Dmitrienko, Ahmad-Reza Sadeghi",https://arxiv.org/abs/2210.07714,10,"To appear in the Network and Distributed System Security (NDSS) Symposium 2024. Phillip Rieger and Torsten Krauß contributed equally to this contribution. 19 pages, 8 figures, 5 tables, 4 algorithms, 5 equations",
Watermarking Pre-trained Language Models with Backdooring,arXiv,2022,2210.07543,"Chenxi Gu, Chengsong Huang, Xiaoqing Zheng, Kai-Wei Chang, Cho-Jui Hsieh",https://arxiv.org/abs/2210.07543,10,,
An Embarrassingly Simple Backdoor Attack on Self-supervised Learning,arXiv,2022,2210.07346,"Changjiang Li, Ren Pang, Zhaohan Xi, Tianyu Du, Shouling Ji, Yuan Yao, Ting Wang",https://arxiv.org/abs/2210.07346,10,The 2023 International Conference on Computer Vision (ICCV '23),
Dim-Krum: Backdoor-Resistant Federated Learning for NLP with Dimension-wise Krum-Based Aggregation,arXiv,2022,2210.06894,"Zhiyuan Zhang, Qi Su, Xu Sun",https://arxiv.org/abs/2210.06894,10,Accepted by Findings of EMNLP 2022,
COLLIDER: A Robust Training Framework for Backdoor Data,arXiv,2022,2210.06704,"Hadi M. Dolatabadi, Sarah Erfani, Christopher Leckie",https://arxiv.org/abs/2210.06704,10,Accepted to the 16th Asian Conference on Computer Vision (ACCV 2022),
Understanding Impacts of Task Similarity on Backdoor Attack and Detection,arXiv,2022,2210.06509,"Di Tang, Rui Zhu, XiaoFeng Wang, Haixu Tang, Yi Chen",https://arxiv.org/abs/2210.06509,10,,
Trap and Replace: Defending Backdoor Attacks by Trapping Them into an Easy-to-Replace Subnetwork,arXiv,2022,2210.06428,"Haotao Wang, Junyuan Hong, Aston Zhang, Jiayu Zhou, Zhangyang Wang",https://arxiv.org/abs/2210.06428,10,Accepted by NeurIPS 2022. Code is available at https://github.com/VITA-Group/Trap-and-Replace-Backdoor-Defense,https://github.com/VITA-Group/Trap-and-Replace-Backdoor-Defense
Few-shot Backdoor Attacks via Neural Tangent Kernels,arXiv,2022,2210.05929,"Jonathan Hayase, Sewoong Oh",https://arxiv.org/abs/2210.05929,10,"20 pages, 13 figures",
BAFFLE: Hiding Backdoors in Offline Reinforcement Learning Datasets,arXiv,2022,2210.04688,"Chen Gong, Zhou Yang, Yunpeng Bai, Junda He, Jieke Shi, Kecen Li, Arunesh Sinha, Bowen Xu, Xinwen Hou, David Lo, Tianhao Wang",https://arxiv.org/abs/2210.04688,10,Accepted at IEEE S&P (Oakland) 2024,
Invariant Aggregator for Defending against Federated Backdoor Attacks,arXiv,2022,2210.01834,"Xiaoyang Wang, Dimitrios Dimitriadis, Sanmi Koyejo, Shruti Tople",https://arxiv.org/abs/2210.01834,10,AISTATS 2024 camera-ready,
Backdoor Attacks in the Supply Chain of Masked Image Modeling,arXiv,2022,2210.01632,"Xinyue Shen, Xinlei He, Zheng Li, Yun Shen, Michael Backes, Yang Zhang",https://arxiv.org/abs/2210.01632,10,,
Shielding Federated Learning: Mitigating Byzantine Attacks with Less Constraints,arXiv,2022,2210.01437,"Minghui Li, Wei Wan, Jianrong Lu, Shengshan Hu, Junyu Shi, Leo Yu Zhang, Man Zhou, Yifeng Zheng",https://arxiv.org/abs/2210.01437,10,"This paper has been accepted by the 18th International Conference on Mobility, Sensing and Networking (MSN 2022)",
Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection,arXiv,2022,2210.00875,"Yiming Li, Yang Bai, Yong Jiang, Yong Yang, Shu-Tao Xia, Bo Li",https://arxiv.org/abs/2210.00875,10,"This work is accepted by the NeurIPS 2022 (Oral, TOP 2%). The first two authors contributed equally to this work. 25 pages. We have fixed some typos in the previous version",https://github.com/THUYimingLi/Untargeted_Backdoor_Watermark
ImpNet: Imperceptible and blackbox-undetectable backdoors in compiled neural networks,arXiv,2022,2210.00108,"Eleanor Clifford, Ilia Shumailov, Yiren Zhao, Ross Anderson, Robert Mullins",https://arxiv.org/abs/2210.00108,10,"10 pages, 7 figures, to be published in IEEE Secure and Trustworthy Machine Learning 2024. For website see https://ml.backdoors.uk . For source code, see https://sr.ht/~ecc/ImpNet",
Augmentation Backdoors,arXiv,2022,2209.15139,"Joseph Rance, Yiren Zhao, Ilia Shumailov, Robert Mullins",https://arxiv.org/abs/2209.15139,09,"12 pages, 8 figures",
A Benchmark Comparison of Python Malware Detection Approaches,arXiv,2022,2209.13288,"Duc-Ly Vu, Zachary Newman, John Speed Meyers",https://arxiv.org/abs/2209.13288,09,"12 pages, 3 figures, 3 tables",
"The ""Beatrix'' Resurrections: Robust Backdoor Detection via Gram Matrices",arXiv,2022,2209.11715,"Wanlun Ma, Derui Wang, Ruoxi Sun, Minhui Xue, Sheng Wen, Yang Xiang",https://arxiv.org/abs/2209.11715,09,"18 pages, 23 figures. Accepted to NDSS 2023. Camera-ready version. Code availability: https://github.com/wanlunsec/Beatrix",https://github.com/wanlunsec/Beatrix
Multi-Tenant Cloud FPGA: A Survey on Security,arXiv,2022,2209.11158,"Muhammed Kawser Ahmed, Joel Mandebi, Sujan Kumar Saha, Christophe Bobda",https://arxiv.org/abs/2209.11158,09,,
BadRes: Reveal the Backdoors through Residual Connection,arXiv,2022,2209.07125,"Mingrui He, Tianyu Chen, Haoyi Zhou, Shanghang Zhang, Jianxin Li",https://arxiv.org/abs/2209.07125,09,"16pages, 9 figures",
$ρ$-GNF : A Novel Sensitivity Analysis Approach Under Unobserved Confounders,arXiv,2022,2209.07111,"Sourabh Balgi, Jose M. Peña, Adel Daoud",https://arxiv.org/abs/2209.07111,09,"10 main pages (+4 reference pages, +6 appendix), 8 Figures, Under review",
Black-box Dataset Ownership Verification via Backdoor Watermarking,arXiv,2022,2209.06015,"Yiming Li, Mingyan Zhu, Xue Yang, Yong Jiang, Tao Wei, Shu-Tao Xia",https://arxiv.org/abs/2209.06015,09,This paper is accepted by IEEE TIFS. 15 pages. The preliminary short version of this paper was posted on arXiv (arXiv:2010.05821) and presented in a non-archival NeurIPS Workshop (2020),https://github.com/THUYimingLi/DVBW
Universal Backdoor Attacks Detection via Adaptive Adversarial Probe,arXiv,2022,2209.05244,"Yuhang Wang, Huafeng Shi, Rui Min, Ruijia Wu, Siyuan Liang, Yichao Wu, Ding Liang, Aishan Liu",https://arxiv.org/abs/2209.05244,09,"8 pages, 8 figures",
Causal Intervention for Fairness in Multi-behavior Recommendation,arXiv,2022,2209.04589,"Xi Wang, Wenjie Wang, Fuli Feng, Wenge Rong, Chuantao Yin, Zhang Xiong",https://arxiv.org/abs/2209.04589,09,This paper is accepted by IEEE Transactions on Computational Social Systems,
SSL-WM: A Black-Box Watermarking Approach for Encoders Pre-trained by Self-supervised Learning,arXiv,2022,2209.03563,"Peizhuo Lv, Pan Li, Shenchen Zhu, Shengzhi Zhang, Kai Chen, Ruigang Liang, Chang Yue, Fan Xiang, Yuling Cai, Hualong Ma, Yingjun Zhang, Guozhu Meng",https://arxiv.org/abs/2209.03563,09,"To Appear in the Network and Distributed System Security (NDSS) Symposium 2024, 26 February - 1 March 2024, San Diego, CA, USA",
Defending Against Backdoor Attack on Graph Nerual Network by Explainability,arXiv,2022,2209.02902,"Bingchen Jiang, Zhao Li",https://arxiv.org/abs/2209.02902,09,"10 pages, 10 figures",
TransCAB: Transferable Clean-Annotation Backdoor to Object Detection with Natural Trigger in Real-World,arXiv,2022,2209.02339,"Hua Ma, Yinshan Li, Yansong Gao, Zhi Zhang, Alsharif Abuadbba, Anmin Fu, Said F. Al-Sarawi, Nepal Surya, Derek Abbott",https://arxiv.org/abs/2209.02339,09,,
Federated Zero-Shot Learning for Visual Recognition,arXiv,2022,2209.01994,"Zhi Chen, Yadan Luo, Sen Wang, Jingjing Li, Zi Huang",https://arxiv.org/abs/2209.01994,09,,
An Adaptive Black-box Defense against Trojan Attacks (TrojDef),arXiv,2022,2209.01721,"Guanxiong Liu, Abdallah Khreishah, Fatima Sharadgah, Issa Khalil",https://arxiv.org/abs/2209.01721,09,,
Solving the Capsulation Attack against Backdoor-based Deep Neural Network Watermarks by Reversing Triggers,arXiv,2022,2208.14127,"Fangqi Li, Shilin Wang, Yun Zhu",https://arxiv.org/abs/2208.14127,08,,
TrojViT: Trojan Insertion in Vision Transformers,arXiv,2022,2208.13049,"Mengxin Zheng, Qian Lou, Lei Jiang",https://arxiv.org/abs/2208.13049,08,"10 pages, 4 figures, 11 tables",https://github.com/mxzheng/TrojViT
Disentangle and Remerge: Interventional Knowledge Distillation for Few-Shot Object Detection from A Conditional Causal Perspective,arXiv,2022,2208.12681,"Jiangmeng Li, Yanan Zhang, Wenwen Qiang, Lingyu Si, Chengbo Jiao, Xiaohui Hu, Changwen Zheng, Fuchun Sun",https://arxiv.org/abs/2208.12681,08,Accepted by AAAI 2023,https://github.com/ZYN-1101/DandR.git
FedPrompt: Communication-Efficient and Privacy Preserving Prompt Tuning in Federated Learning,arXiv,2022,2208.12268,"Haodong Zhao, Wei Du, Fangqi Li, Peixuan Li, Gongshen Liu",https://arxiv.org/abs/2208.12268,08,,
Bidirectional Contrastive Split Learning for Visual Question Answering,arXiv,2022,2208.11435,"Yuwei Sun, Hideya Ochiai",https://arxiv.org/abs/2208.11435,08,Accepted for AAAI 2024,
RIBAC: Towards Robust and Imperceptible Backdoor Attack against Compact DNN,arXiv,2022,2208.10608,"Huy Phan, Cong Shi, Yi Xie, Tianfang Zhang, Zhuohang Li, Tianming Zhao, Jian Liu, Yan Wang, Yingying Chen, Bo Yuan",https://arxiv.org/abs/2208.10608,08,Code is available at https://github.com/huyvnphan/ECCV2022-RIBAC,https://github.com/huyvnphan/ECCV2022-RIBAC
An anomaly detection approach for backdoored neural networks: face recognition as a case study,arXiv,2022,2208.10231,"Alexander Unnervik, Sébastien Marcel",https://arxiv.org/abs/2208.10231,08,"Accepted at Biosig 2022, 8 pages, 4 figures",
Friendly Noise against Adversarial Noise: A Powerful Defense against Data Poisoning Attacks,arXiv,2022,2208.10224,"Tian Yu Liu, Yu Yang, Baharan Mirzasoleiman",https://arxiv.org/abs/2208.10224,08,Code available at: https://github.com/tianyu139/friendly-noise,https://github.com/tianyu139/friendly-noise
Dispersed Pixel Perturbation-based Imperceptible Backdoor Trigger for Image Classifier Models,arXiv,2022,2208.09336,"Yulong Wang, Minghui Zhao, Shenghong Li, Xin Yuan, Wei Ni",https://arxiv.org/abs/2208.09336,08,,
Imperceptible and Robust Backdoor Attack in 3D Point Cloud,arXiv,2022,2208.08052,"Kuofeng Gao, Jiawang Bai, Baoyuan Wu, Mengxi Ya, Shu-Tao Xia",https://arxiv.org/abs/2208.08052,08,,
Neural network fragile watermarking with no model performance degradation,arXiv,2022,2208.07585,"Zhaoxia Yin, Heng Yin, Xinpeng Zhang",https://arxiv.org/abs/2208.07585,08,Published in 2022 IEEE International Conference on Image Processing (ICIP),
Link-Backdoor: Backdoor Attack on Link Prediction via Node Injection,arXiv,2022,2208.06776,"Haibin Zheng, Haiyang Xiong, Haonan Ma, Guohan Huang, Jinyin Chen",https://arxiv.org/abs/2208.06776,08,,https://github.com/Seaocn/Link-Backdoor
Confidence Matters: Inspecting Backdoors in Deep Neural Networks via Distribution Transfer,arXiv,2022,2208.06592,"Tong Wang, Yuan Yao, Feng Xu, Miao Xu, Shengwei An, Ting Wang",https://arxiv.org/abs/2208.06592,08,,
Defense against Backdoor Attacks via Identifying and Purifying Bad Neurons,arXiv,2022,2208.06537,"Mingyuan Fan, Yang Liu, Cen Chen, Ximeng Liu, Wenzhong Guo",https://arxiv.org/abs/2208.06537,08,,
A Knowledge Distillation-Based Backdoor Attack in Federated Learning,arXiv,2022,2208.06176,"Yifan Wang, Wei Fan, Keke Yang, Naji Alhusaini, Jing Li",https://arxiv.org/abs/2208.06176,08,,
PerD: Perturbation Sensitivity-based Neural Trojan Detection Framework on NLP Applications,arXiv,2022,2208.04943,"Diego Garcia-soto, Huili Chen, Farinaz Koushanfar",https://arxiv.org/abs/2208.04943,08,,
Debiased Cross-modal Matching for Content-based Micro-video Background Music Recommendation,arXiv,2022,2208.03633,"Jinng Yi, Zhenzhong Chen",https://arxiv.org/abs/2208.03633,08,,https://github.com/jing-1/DebCM
Data-free Backdoor Removal based on Channel Lipschitzness,arXiv,2022,2208.03111,"Runkai Zheng, Rongjun Tang, Jianze Li, Li Liu",https://arxiv.org/abs/2208.03111,08,Accepted to ECCV 2022,https://github.com/rkteddy/channel-Lipschitzness-based-pruning
Deep Fidelity in DNN Watermarking: A Study of Backdoor Watermarking for Classification Models,arXiv,2022,2208.00563,"Guang Hua, Andrew Beng Jin Teoh",https://arxiv.org/abs/2208.00563,08,Published in Pattern Recognition,https://github.com/ghua-ac/dnn_watermark
FRIB: Low-poisoning Rate Invisible Backdoor Attack based on Feature Repair,arXiv,2022,2207.12863,"Hui Xia, Xiugui Yang, Xiangyun Qian, Rui Zhang",https://arxiv.org/abs/2207.12863,07,,
Versatile Weight Attack via Flipping Limited Bits,arXiv,2022,2207.12405,"Jiawang Bai, Baoyuan Wu, Zhifeng Li, Shu-tao Xia",https://arxiv.org/abs/2207.12405,07,Extension of our ICLR 2021 work: arXiv:2102.10496,
Technical Report: Assisting Backdoor Federated Learning with Whole Population Knowledge Alignment,arXiv,2022,2207.12327,"Tian Liu, Xueyang Hu, Tao Shu",https://arxiv.org/abs/2207.12327,07,,
Just Rotate it: Deploying Backdoor Attacks via Rotation Transformation,arXiv,2022,2207.10825,"Tong Wu, Tianhao Wang, Vikash Sehwag, Saeed Mahloujifar, Prateek Mittal",https://arxiv.org/abs/2207.10825,07,25 pages,
High-Level Approaches to Hardware Security: A Tutorial,arXiv,2022,2207.10466,"Hammond Pearce, Ramesh Karri, Benjamin Tan",https://arxiv.org/abs/2207.10466,07,"Accepted in IEEE TECS. 41 pages, 13 figures",
Backdoor Attacks on Crowd Counting,arXiv,2022,2207.05641,"Yuhua Sun, Tailai Zhang, Xingjun Ma, Pan Zhou, Jian Lou, Zichuan Xu, Xing Di, Yu Cheng,  Lichao",https://arxiv.org/abs/2207.05641,07,"To appear in ACMMM 2022. 10pages, 6 figures and 2 tables",
One-shot Neural Backdoor Erasing via Adversarial Weight Masking,arXiv,2022,2207.04497,"Shuwen Chai, Jinghui Chen",https://arxiv.org/abs/2207.04497,07,"Accepted by NeurIPS 2022 (19 pages, 6 figures, 10 tables)",
Invisible Backdoor Attacks Using Data Poisoning in the Frequency Domain,arXiv,2022,2207.04209,"Chang Yue, Peizhuo Lv, Ruigang Liang, Kai Chen",https://arxiv.org/abs/2207.04209,07,,
Defense Against Multi-target Trojan Attacks,arXiv,2022,2207.03895,"Haripriya Harikumar, Santu Rana, Kien Do, Sunil Gupta, Wei Zong, Willy Susilo, Svetha Venkastesh",https://arxiv.org/abs/2207.03895,07,,
FL-Defender: Combating Targeted Attacks in Federated Learning,arXiv,2022,2207.00872,"Najeeb Jebreel, Josep Domingo-Ferrer",https://arxiv.org/abs/2207.00872,07,,
Backdoor Attack is a Devil in Federated GAN-based Medical Image Synthesis,arXiv,2022,2207.00762,"Ruinan Jin, Xiaoxiao Li",https://arxiv.org/abs/2207.00762,07,"13 pages, 4 figures, Accepted by MICCAI 2022 SASHIMI Workshop",
Transferable Graph Backdoor Attack,arXiv,2022,2207.00425,"Shuiqiao Yang, Bao Gia Doan, Paul Montague, Olivier De Vel, Tamas Abraham, Seyit Camtepe, Damith C. Ranasinghe, Salil S. Kanhere",https://arxiv.org/abs/2207.00425,07,"Accepted by the 25th International Symposium on Research in Attacks, Intrusions, and Defenses",
BadHash: Invisible Backdoor Attacks against Deep Hashing with Clean Label,arXiv,2022,2207.00278,"Shengshan Hu, Ziqi Zhou, Yechao Zhang, Leo Yu Zhang, Yifeng Zheng, Yuanyuan HE, Hai Jin",https://arxiv.org/abs/2207.00278,07,"This paper has been accepted by the 30th ACM International Conference on Multimedia (MM '22, October 10--14, 2022, Lisboa, Portugal)",
Interventional Contrastive Learning with Meta Semantic Regularizer,arXiv,2022,2206.14702,"Wenwen Qiang, Jiangmeng Li, Changwen Zheng, Bing Su, Hui Xiong",https://arxiv.org/abs/2206.14702,06,Accepted by ICML 2022,
Auditing Visualizations: Transparency Methods Struggle to Detect Anomalous Behavior,arXiv,2022,2206.13498,"Jean-Stanislas Denain, Jacob Steinhardt",https://arxiv.org/abs/2206.13498,06,"Fixed backdoor localization results, made changes to abstract and introduction",
BackdoorBench: A Comprehensive Benchmark of Backdoor Learning,arXiv,2022,2206.12654,"Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Chao Shen",https://arxiv.org/abs/2206.12654,06,"Accepted at NeurIPS 2022 Datasets and Benchmarks Track; 44 pages; 8 backdoor attacks; 9 backdoor defenses; 8,000 pairs of attack-defense evaluations; several analysis and 5 analysis tools",https://backdoorbench.github.io
Defending Backdoor Attacks on Vision Transformer via Patch Processing,arXiv,2022,2206.12381,"Khoa D. Doan, Yingjie Lao, Peng Yang, Ping Li",https://arxiv.org/abs/2206.12381,06,,
Open Vocabulary Object Detection with Proposal Mining and Prediction Equalization,arXiv,2022,2206.11134,"Peixian Chen, Kekai Sheng, Mengdan Zhang, Mingbao Lin, Yunhang Shen, Shaohui Lin, Bo Ren, Ke Li",https://arxiv.org/abs/2206.11134,06,,
Natural Backdoor Datasets,arXiv,2022,2206.10673,"Emily Wenger, Roma Bhattacharjee, Arjun Nitin Bhagoji, Josephine Passananti, Emilio Andere, Haitao Zheng, Ben Y. Zhao",https://arxiv.org/abs/2206.10673,06,18 pages,
Neurotoxin: Durable Backdoors in Federated Learning,arXiv,2022,2206.10341,"Zhengming Zhang, Ashwinee Panda, Linyue Song, Yaoqing Yang, Michael W. Mahoney, Joseph E. Gonzalez, Kannan Ramchandran, Prateek Mittal",https://arxiv.org/abs/2206.10341,06,Appears in ICML 2022,
DECK: Model Hardening for Defending Pervasive Backdoors,arXiv,2022,2206.09272,"Guanhong Tao, Yingqi Liu, Siyuan Cheng, Shengwei An, Zhuo Zhang, Qiuling Xu, Guangyu Shen, Xiangyu Zhang",https://arxiv.org/abs/2206.09272,06,,
Is Multi-Modal Necessarily Better? Robustness Evaluation of Multi-modal Fake News Detection,arXiv,2022,2206.08788,"Jinyin Chen, Chengyu Jia, Haibin Zheng, Ruoxi Chen, Chenbo Fu",https://arxiv.org/abs/2206.08788,06,,
A Unified Evaluation of Textual Backdoor Learning: Frameworks and Benchmarks,arXiv,2022,2206.08514,"Ganqu Cui, Lifan Yuan, Bingxiang He, Yangyi Chen, Zhiyuan Liu, Maosong Sun",https://arxiv.org/abs/2206.08514,06,NeurIPS 2022 Datasets & Benchmarks; Toolkits avaliable at https://github.com/thunlp/OpenBackdoor,https://github.com/thunlp/OpenBackdoor
Backdoor Attacks on Vision Transformers,arXiv,2022,2206.08477,"Akshayvarun Subramanya, Aniruddha Saha, Soroush Abbasi Koohpayegani, Ajinkya Tejankar, Hamed Pirsiavash",https://arxiv.org/abs/2206.08477,06,,https://github.com/UCDvision/backdoor_transformer.git
Architectural Backdoors in Neural Networks,arXiv,2022,2206.07840,"Mikel Bober-Irizar, Ilia Shumailov, Yiren Zhao, Robert Mullins, Nicolas Papernot",https://arxiv.org/abs/2206.07840,06,,
Turning a Curse into a Blessing: Enabling In-Distribution-Data-Free Backdoor Removal via Stabilized Model Inversion,arXiv,2022,2206.07018,"Si Chen, Yi Zeng, Jiachen T. Wang, Won Park, Xun Chen, Lingjuan Lyu, Zhuoqing Mao, Ruoxi Jia",https://arxiv.org/abs/2206.07018,06,"Because of an equation and author informational error, this paper has been withdrawn by the submitter",
Enhancing Clean Label Backdoor Attack with Two-phase Specific Triggers,arXiv,2022,2206.04881,"Nan Luo, Yuanzhang Li, Yajie Wang, Shangbo Wu, Yu-an Tan, Quanxin Zhang",https://arxiv.org/abs/2206.04881,06,,
Membership Inference via Backdooring,arXiv,2022,2206.04823,"Hongsheng Hu, Zoran Salcic, Gillian Dobbie, Jinjun Chen, Lichao Sun, Xuyun Zhang",https://arxiv.org/abs/2206.04823,06,This paper has been accepted by IJCAI-22,
On the Permanence of Backdoors in Evolving Models,arXiv,2022,2206.04677,"Huiying Li, Arjun Nitin Bhagoji, Yuxin Chen, Haitao Zheng, Ben Y. Zhao",https://arxiv.org/abs/2206.04677,06,,
Contributor-Aware Defenses Against Adversarial Backdoor Attacks,arXiv,2022,2206.03583,"Glenn Dawson, Muhammad Umer, Robi Polikar",https://arxiv.org/abs/2206.03583,06,,
Kallima: A Clean-label Framework for Textual Backdoor Attacks,arXiv,2022,2206.01832,"Xiaoyi Chen, Yinpeng Dong, Zeyu Sun, Shengfang Zhai, Qingni Shen, Zhonghai Wu",https://arxiv.org/abs/2206.01832,06,,
A temporal chrominance trigger for clean-label backdoor attack against anti-spoof rebroadcast detection,arXiv,2022,2206.01102,"Wei Guo, Benedetta Tondi, Mauro Barni",https://arxiv.org/abs/2206.01102,06,,
CASSOCK: Viable Backdoor Attacks against DNN in The Wall of Source-Specific Backdoor Defences,arXiv,2022,2206.00145,"Shang Wang, Yansong Gao, Anmin Fu, Zhi Zhang, Yuqing Zhang, Willy Susilo, Dongxi Liu",https://arxiv.org/abs/2206.00145,06,"13 pages,14 figures",
BadDet: Backdoor Attacks on Object Detection,arXiv,2022,2205.14497,"Shih-Han Chan, Yinpeng Dong, Jun Zhu, Xiaolu Zhang, Jun Zhou",https://arxiv.org/abs/2205.14497,05,,
Deep Deconfounded Content-based Tag Recommendation for UGC with Causal Intervention,arXiv,2022,2205.14380,"Yaochen Zhu, Xubin Ren, Jing Yi, Zhenzhong Chen",https://arxiv.org/abs/2205.14380,05,,
Defending Against Stealthy Backdoor Attacks,arXiv,2022,2205.14246,"Sangeet Sagar, Abhinav Bhatt, Abhijith Srinivas Bidaralli",https://arxiv.org/abs/2205.14246,05,,
BagFlip: A Certified Defense against Data Poisoning,arXiv,2022,2205.13634,"Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni",https://arxiv.org/abs/2205.13634,05,Neurips 2022,
Towards A Proactive ML Approach for Detecting Backdoor Poison Samples,arXiv,2022,2205.13616,"Xiangyu Qi, Tinghao Xie, Jiachen T. Wang, Tong Wu, Saeed Mahloujifar, Prateek Mittal",https://arxiv.org/abs/2205.13616,05,USENIX Security 2023,
Circumventing Backdoor Defenses That Are Based on Latent Separability,arXiv,2022,2205.13613,"Xiangyu Qi, Tinghao Xie, Yiming Li, Saeed Mahloujifar, Prateek Mittal",https://arxiv.org/abs/2205.13613,05,,
PerDoor: Persistent Non-Uniform Backdoors in Federated Learning using Adversarial Perturbations,arXiv,2022,2205.13523,"Manaar Alam, Esha Sarkar, Michail Maniatakos",https://arxiv.org/abs/2205.13523,05,,
BITE: Textual Backdoor Attacks with Iterative Trigger Injection,arXiv,2022,2205.12700,"Jun Yan, Vansh Gupta, Xiang Ren",https://arxiv.org/abs/2205.12700,05,Accepted to ACL 2023,
Comprehensive Privacy Analysis on Federated Recommender System against Attribute Inference Attacks,arXiv,2022,2205.11857,"Shijie Zhang, Wei Yuan, Hongzhi Yin",https://arxiv.org/abs/2205.11857,05,,
Quarantine: Sparsity Can Uncover the Trojan Attack Trigger for Free,arXiv,2022,2205.11819,"Tianlong Chen, Zhenyu Zhang, Yihua Zhang, Shiyu Chang, Sijia Liu, Zhangyang Wang",https://arxiv.org/abs/2205.11819,05,,https://github.com/VITA-Group/Backdoor-LTH
WeDef: Weakly Supervised Backdoor Defense for Text Classification,arXiv,2022,2205.11803,"Lesheng Jin, Zihan Wang, Jingbo Shang",https://arxiv.org/abs/2205.11803,05,,
Towards a Defense Against Federated Backdoor Attacks Under Continuous Training,arXiv,2022,2205.11736,"Shuaiqi Wang, Jonathan Hayase, Giulia Fanti, Sewoong Oh",https://arxiv.org/abs/2205.11736,05,,
SafeNet: The Unreasonable Effectiveness of Ensembles in Private Collaborative Learning,arXiv,2022,2205.09986,"Harsh Chaudhari, Matthew Jagielski, Alina Oprea",https://arxiv.org/abs/2205.09986,05,,
Interpolating Compressed Parameter Subspaces,arXiv,2022,2205.09891,"Siddhartha Datta, Nigel Shadbolt",https://arxiv.org/abs/2205.09891,05,,
Backdoor Attacks on Bayesian Neural Networks using Reverse Distribution,arXiv,2022,2205.09167,"Zhixin Pan, Prabhat Mishra",https://arxiv.org/abs/2205.09167,05,"9 pages, 7 figures",
Verifying Neural Networks Against Backdoor Attacks,arXiv,2022,2205.06992,"Long H. Pham, Jun Sun",https://arxiv.org/abs/2205.06992,05,,
MM-BD: Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic,arXiv,2022,2205.06900,"Hang Wang, Zhen Xiang, David J. Miller, George Kesidis",https://arxiv.org/abs/2205.06900,05,,
Addressing Confounding Feature Issue for Causal Recommendation,arXiv,2022,2205.06532,"Xiangnan He, Yang Zhang, Fuli Feng, Chonggang Song, Lingling Yi, Guohui Ling, Yongdong Zhang",https://arxiv.org/abs/2205.06532,05,Accepted by TOIS 2022. Codes are available on Github: https://github.com/zyang1580/DCR,
Model-Contrastive Learning for Backdoor Defense,arXiv,2022,2205.04411,"Zhihao Yue, Jun Xia, Zhiwei Ling, Ming Hu, Ting Wang, Xian Wei, Mingsong Chen",https://arxiv.org/abs/2205.04411,05,,https://github.com/WeCanShow/MCL
Imperceptible Backdoor Attack: From Input Space to Feature Representation,arXiv,2022,2205.03190,"Nan Zhong, Zhenxing Qian, Xinpeng Zhang",https://arxiv.org/abs/2205.03190,05,IJCAI 2022,https://github.com/Ekko-zn/IJCAI2022-Backdoor
A Temporal-Pattern Backdoor Attack to Deep Reinforcement Learning,arXiv,2022,2205.02589,"Yinbo Yu, Jiajia Liu, Shouqing Li, Kepu Huang, Xudong Feng",https://arxiv.org/abs/2205.02589,05,,
Using Constraint Programming and Graph Representation Learning for Generating Interpretable Cloud Security Policies,arXiv,2022,2205.01240,"Mikhail Kazdagli, Mohit Tiwari, Akshat Kumar",https://arxiv.org/abs/2205.01240,05,to be published in IJCAI/ECAI'22,
Backdoor Attacks in Federated Learning by Rare Embeddings and Gradient Ensembling,arXiv,2022,2204.14017,"KiYoon Yoo, Nojun Kwak",https://arxiv.org/abs/2204.14017,04,"Accepted to EMNLP 2022, 9 pages and Appendix",
Detecting Backdoor Poisoning Attacks on Deep Neural Networks by Heatmap Clustering,arXiv,2022,2204.12848,"Lukas Schulth, Christian Berghoff, Matthias Neu",https://arxiv.org/abs/2204.12848,04,,
Data-Efficient Backdoor Attacks,arXiv,2022,2204.12281,"Pengfei Xia, Ziqiang Li, Wei Zhang, Bin Li",https://arxiv.org/abs/2204.12281,04,Accepted to IJCAI 2022 Long Oral,https://github.com/xpf/Data-Efficient-Backdoor-Attacks
Eliminating Backdoor Triggers for Deep Neural Networks Using Attention Relation Graph Distillation,arXiv,2022,2204.09975,"Jun Xia, Ting Wang, Jiepin Ding, Xian Wei, Mingsong Chen",https://arxiv.org/abs/2204.09975,04,,
Backdooring Explainable Machine Learning,arXiv,2022,2204.09498,"Maximilian Noppel, Lukas Peter, Christian Wressnegger",https://arxiv.org/abs/2204.09498,04,,
Causality-based Neural Network Repair,arXiv,2022,2204.09274,"Bing Sun, Jun Sun, Hong Long Pham, Jie Shi",https://arxiv.org/abs/2204.09274,04,,
Planting Undetectable Backdoors in Machine Learning Models,arXiv,2022,2204.06974,"Shafi Goldwasser, Michael P. Kim, Vinod Vaikuntanathan, Or Zamir",https://arxiv.org/abs/2204.06974,04,,
Towards A Critical Evaluation of Robustness for Deep Learning Backdoor Countermeasures,arXiv,2022,2204.06273,"Huming Qiu, Hua Ma, Zhi Zhang, Alsharif Abuadbba, Wei Kang, Anmin Fu, Yansong Gao",https://arxiv.org/abs/2204.06273,04,,
AdaTest:Reinforcement Learning and Adaptive Sampling for On-chip Hardware Trojan Detection,arXiv,2022,2204.06117,"Huili Chen, Xinqiao Zhang, Ke Huang, Farinaz Koushanfar",https://arxiv.org/abs/2204.06117,04,,
Machine Learning Security against Data Poisoning: Are We There Yet?,arXiv,2022,2204.05986,"Antonio Emanuele Cinà, Kathrin Grosse, Ambra Demontis, Battista Biggio, Fabio Roli, Marcello Pelillo",https://arxiv.org/abs/2204.05986,04,"preprint, 10 pages, 3 figures. Paper accepted to the IEEE Computer - Special Issue on Trustworthy AI",
Backdoor Attack against NLP models with Robustness-Aware Perturbation defense,arXiv,2022,2204.05758,"Shaik Mohammed Maqsood, Viveros Manuela Ceron, Addluri GowthamKrishna",https://arxiv.org/abs/2204.05758,04,,
Narcissus: A Practical Clean-Label Backdoor Attack with Limited Information,arXiv,2022,2204.05255,"Yi Zeng, Minzhou Pan, Hoang Anh Just, Lingjuan Lyu, Meikang Qiu, Ruoxi Jia",https://arxiv.org/abs/2204.05255,04,13 pages of the main text,
Exploring the Universal Vulnerability of Prompt-based Learning Paradigm,arXiv,2022,2204.05239,"Lei Xu, Yangyi Chen, Ganqu Cui, Hongcheng Gao, Zhiyuan Liu",https://arxiv.org/abs/2204.05239,04,Accepted to Findings of NAACL 2022,https://github.com/leix28/prompt-universal-vulnerability
Knowledge-Free Black-Box Watermark and Ownership Proof for Image Classification Neural Networks,arXiv,2022,2204.04522,"Fangqi Li, Shilin Wang",https://arxiv.org/abs/2204.04522,04,11 pages,
An Adaptive Black-box Backdoor Detection Method for Deep Neural Networks,arXiv,2022,2204.04329,"Xinqiao Zhang, Huili Chen, Ke Huang, Farinaz Koushanfar",https://arxiv.org/abs/2204.04329,04,arXiv admin note: substantial text overlap with arXiv:2102.01815,https://github.com/xinqiaozhang/adatrojan
Trojan Horse Training for Breaking Defenses against Backdoor Attacks in Deep Learning,arXiv,2022,2203.15506,"Arezoo Rajabi, Bhaskar Ramasubramanian, Radha Poovendran",https://arxiv.org/abs/2203.15506,03,Submitted to conference,
OrphicX: A Causality-Inspired Latent Variable Model for Interpreting Graph Neural Networks,arXiv,2022,2203.15209,"Wanyu Lin, Hao Lan, Hao Wang, Baochun Li",https://arxiv.org/abs/2203.15209,03,"Accepted by CVPR 2022, an oral presentation, source code: https://github.com/WanyuGroup/CVPR2022-OrphicX",https://github.com/WanyuGroup/CVPR2022-OrphicX
PiDAn: A Coherence Optimization Approach for Backdoor Attack Detection and Mitigation in Deep Neural Networks,arXiv,2022,2203.09289,"Yue Wang, Wenqing Li, Esha Sarkar, Muhammad Shafique, Michail Maniatakos, Saif Eddin Jabari",https://arxiv.org/abs/2203.09289,03,,
Sniper Backdoor: Single Client Targeted Backdoor Attack in Federated Learning,arXiv,2022,2203.08689,"Gorka Abad, Servio Paguada, Oguzhan Ersoy, Stjepan Picek, Víctor Julio Ramírez-Durán, Aitor Urbieta",https://arxiv.org/abs/2203.08689,03,,
Model Inversion Attack against Transfer Learning: Inverting a Model without Accessing It,arXiv,2022,2203.06570,"Dayong Ye, Huiqiang Chen, Shuai Zhou, Tianqing Zhu, Wanlei Zhou, Shouling Ji",https://arxiv.org/abs/2203.06570,03,,
Low-Loss Subspace Compression for Clean Gains against Multi-Agent Backdoor Attacks,arXiv,2022,2203.03692,"Siddhartha Datta, Nigel Shadbolt",https://arxiv.org/abs/2203.03692,03,,
Dynamic Backdoors with Global Average Pooling,arXiv,2022,2203.02079,"Stefanos Koffas, Stjepan Picek, Mauro Conti",https://arxiv.org/abs/2203.02079,03,,
Physical Backdoor Attacks to Lane Detection Systems in Autonomous Driving,arXiv,2022,2203.00858,"Xingshuo Han, Guowen Xu, Yuan Zhou, Xuehuan Yang, Jiwei Li, Tianwei Zhang",https://arxiv.org/abs/2203.00858,03,Accepted by ACM MultiMedia 2022,
Label-Smoothed Backdoor Attack,arXiv,2022,2202.11203,"Minlong Peng, Zidi Xiong, Mingming Sun, Ping Li",https://arxiv.org/abs/2202.11203,02,Backdoor Attack,https://github.com/v-mipeng/LabelSmoothedAttack.git
Backdoor Defense in Federated Learning Using Differential Testing and Outlier Detection,arXiv,2022,2202.11196,"Yein Kim, Huili Chen, Farinaz Koushanfar",https://arxiv.org/abs/2202.11196,02,,
Partial Identification with Noisy Covariates: A Robust Optimization Approach,arXiv,2022,2202.10665,"Wenshuo Guo, Mingzhang Yin, Yixin Wang, Michael I. Jordan",https://arxiv.org/abs/2202.10665,02,Proceedings of Conference on Causal Learning and Reasoning (CLeaR) 2022,
On the Effectiveness of Adversarial Training against Backdoor Attacks,arXiv,2022,2202.10627,"Yinghua Gao, Dongxian Wu, Jingfeng Zhang, Guanhao Gan, Shu-Tao Xia, Gang Niu, Masashi Sugiyama",https://arxiv.org/abs/2202.10627,02,,
Debiasing Backdoor Attack: A Benign Application of Backdoor Attack in Eliminating Data Bias,arXiv,2022,2202.10582,"Shangxi Wu, Qiuyang He, Yi Zhang, Jitao Sang",https://arxiv.org/abs/2202.10582,02,,
Resurrecting Trust in Facial Recognition: Mitigating Backdoor Attacks in Face Recognition to Prevent Potential Privacy Breaches,arXiv,2022,2202.10320,"Reena Zelenkova, Jack Swallow, M. A. P. Chamikara, Dongxi Liu, Mohan Baruwal Chhetri, Seyit Camtepe, Marthie Grobler, Mahathir Almashor",https://arxiv.org/abs/2202.10320,02,15 pages,
SAT Backdoors: Depth Beats Size,arXiv,2022,2202.08326,"Jan Dreier, Sebastian Ordyniak, Stefan Szeider",https://arxiv.org/abs/2202.08326,02,,
Threats to Pre-trained Language Models: Survey and Taxonomy,arXiv,2022,2202.06862,"Shangwei Guo, Chunlong Xie, Jiwei Li, Lingjuan Lyu, Tianwei Zhang",https://arxiv.org/abs/2202.06862,02,,
Training with More Confidence: Mitigating Injected and Natural Backdoors During Training,arXiv,2022,2202.06382,"Zhenting Wang, Hailun Ding, Juan Zhai, Shiqing Ma",https://arxiv.org/abs/2202.06382,02,,https://github.com/RU-System-Software-and-Security/NONE
Progressive Backdoor Erasing via connecting Backdoor and Adversarial Attacks,arXiv,2022,2202.06312,"Bingxu Mu, Zhenxing Niu, Le Wang, Xue Wang, Rong Jin, Gang Hua",https://arxiv.org/abs/2202.06312,02,,
Constrained Optimization with Dynamic Bound-scaling for Effective NLPBackdoor Defense,arXiv,2022,2202.05749,"Guangyu Shen, Yingqi Liu, Guanhong Tao, Qiuling Xu, Zhuo Zhang, Shengwei An, Shiqing Ma, Xiangyu Zhang",https://arxiv.org/abs/2202.05749,02,,
Jigsaw Puzzle: Selective Backdoor Attack to Subvert Malware Classifiers,arXiv,2022,2202.05470,"Limin Yang, Zhi Chen, Jacopo Cortellazzi, Feargus Pendlebury, Kevin Tu, Fabio Pierazzi, Lorenzo Cavallaro, Gang Wang",https://arxiv.org/abs/2202.05470,02,"18 pages, 3 figures",
False Memory Formation in Continual Learners Through Imperceptible Backdoor Trigger,arXiv,2022,2202.04479,"Muhammad Umer, Robi Polikar",https://arxiv.org/abs/2202.04479,02,,
Identifying Backdoor Attacks in Federated Learning via Anomaly Detection,arXiv,2022,2202.04311,"Yuxi Mi, Yiheng Sun, Jihong Guan, Shuigeng Zhou",https://arxiv.org/abs/2202.04311,02,APWeb-WAIM 2023,
PolicyCleanse: Backdoor Detection and Mitigation in Reinforcement Learning,arXiv,2022,2202.03609,"Junfeng Guo, Ang Li, Cong Liu",https://arxiv.org/abs/2202.03609,02,Accepted by ICCV 2023,
Backdoor Defense via Decoupling the Training Process,arXiv,2022,2202.03423,"Kunzhe Huang, Yiming Li, Baoyuan Wu, Zhan Qin, Kui Ren",https://arxiv.org/abs/2202.03423,02,This work is accepted by the ICLR 2022. The first two authors contributed equally to this work. 25 pages,https://github.com/SCLBD/DBD
More is Better (Mostly): On the Backdoor Attacks in Federated Graph Neural Networks,arXiv,2022,2202.03195,"Jing Xu, Rui Wang, Stefanos Koffas, Kaitai Liang, Stjepan Picek",https://arxiv.org/abs/2202.03195,02,"15 pages, 13 figures",
BEAS: Blockchain Enabled Asynchronous & Secure Federated Machine Learning,arXiv,2022,2202.02817,"Arup Mondal, Harpreet Virk, Debayan Gupta",https://arxiv.org/abs/2202.02817,02,The Third AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI-22) at the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22),
AntidoteRT: Run-time Detection and Correction of Poison Attacks on Neural Networks,arXiv,2022,2202.01179,"Muhammad Usman, Youcheng Sun, Divya Gopinath, Corina S. Pasareanu",https://arxiv.org/abs/2202.01179,02,,
Few-Shot Backdoor Attacks on Visual Object Tracking,arXiv,2022,2201.13178,"Yiming Li, Haoxiang Zhong, Xingjun Ma, Yong Jiang, Shu-Tao Xia",https://arxiv.org/abs/2201.13178,01,"This work is accepted by the ICLR 2022. The first two authors contributed equally to this work. In this version, we fix some typos and errors contained in the last one. 21 pages",
Imperceptible and Multi-channel Backdoor Attack against Deep Neural Networks,arXiv,2022,2201.13164,"Mingfu Xue, Shifeng Ni, Yinghao Wu, Yushu Zhang, Jian Wang, Weiqiang Liu",https://arxiv.org/abs/2201.13164,01,,
A new idea for RSA backdoors,arXiv,2022,2201.13153,Marco Cesati,https://arxiv.org/abs/2201.13153,01,"19 pages, 5 figures",
Backdoors Stuck At The Frontdoor: Multi-Agent Backdoor Attacks That Backfire,arXiv,2022,2201.12211,"Siddhartha Datta, Nigel Shadbolt",https://arxiv.org/abs/2201.12211,01,,
Identifying a Training-Set Attack's Target Using Renormalized Influence Estimation,arXiv,2022,2201.10055,"Zayd Hammoudeh, Daniel Lowd",https://arxiv.org/abs/2201.10055,01,Accepted at CCS'2022 -- Extended version including the supplementary material,https://github.com/ZaydH/target_identification
Hiding Behind Backdoors: Self-Obfuscation Against Generative Models,arXiv,2022,2201.09774,"Siddhartha Datta, Nigel Shadbolt",https://arxiv.org/abs/2201.09774,01,,
Backdoor Defense with Machine Unlearning,arXiv,2022,2201.09538,"Yang Liu, Mingyuan Fan, Cen Chen, Ximeng Liu, Zhuo Ma, Li Wang, Jianfeng Ma",https://arxiv.org/abs/2201.09538,01,,
Federated Unlearning with Knowledge Distillation,arXiv,2022,2201.09441,"Chen Wu, Sencun Zhu, Prasenjit Mitra",https://arxiv.org/abs/2201.09441,01,,
On the Satisfaction Probability of $k$-CNF Formulas,arXiv,2022,2201.08895,Till Tantau,https://arxiv.org/abs/2201.08895,01,"43 pages, version updated after the presentation of the results at the CCC 2022 conference",
Dangerous Cloaking: Natural Trigger based Backdoor Attacks on Object Detectors in the Physical World,arXiv,2022,2201.08619,"Hua Ma, Yinshan Li, Yansong Gao, Alsharif Abuadbba, Zhi Zhang, Anmin Fu, Hyoungshick Kim, Said F. Al-Sarawi, Nepal Surya, Derek Abbott",https://arxiv.org/abs/2201.08619,01,,
"Blockchain-based Collaborated Federated Learning for Improved Security, Privacy and Reliability",arXiv,2022,2201.08551,"Amir Afaq, Zeeshan Ahmed, Noman Haider, Muhammad Imran",https://arxiv.org/abs/2201.08551,01,Preliminary work,
Post-Training Detection of Backdoor Attacks for Two-Class and Multi-Attack Scenarios,arXiv,2022,2201.08474,"Zhen Xiang, David J. Miller, George Kesidis",https://arxiv.org/abs/2201.08474,01,Accepted to ICLR2022,https://github.com/zhenxianglance/2ClassBADetection
Watermarking Pre-trained Encoders in Contrastive Learning,arXiv,2022,2201.08217,"Yutong Wu, Han Qiu, Tianwei Zhang, Jiwei L, Meikang Qiu",https://arxiv.org/abs/2201.08217,01,,
How to Backdoor HyperNetwork in Personalized Federated Learning?,arXiv,2022,2201.07063,"Phung Lai, NhatHai Phan, Issa Khalil, Abdallah Khreishah, Xintao Wu",https://arxiv.org/abs/2201.07063,01,,
Towards Adversarial Evaluations for Inexact Machine Unlearning,arXiv,2022,2201.06640,"Shashwat Goel, Ameya Prabhu, Amartya Sanyal, Ser-Nam Lim, Philip Torr, Ponnurangam Kumaraguru",https://arxiv.org/abs/2201.06640,01,Tech Report,
Neighboring Backdoor Attacks on Graph Convolutional Network,arXiv,2022,2201.06202,"Liang Chen, Qibiao Peng, Jintang Li, Yang Liu, Jiawei Chen, Yong Li, Zibin Zheng",https://arxiv.org/abs/2201.06202,01,12 pages,
RFLBAT: A Robust Federated Learning Algorithm against Backdoor Attack,arXiv,2022,2201.03772,"Yongkang Wang, Dihua Zhai, Yufeng Zhan, Yuanqing Xia",https://arxiv.org/abs/2201.03772,01,,
Rethink the Evaluation for Attack Strength of Backdoor Attacks in Natural Language Processing,arXiv,2022,2201.02993,"Lingfeng Shen, Haiyun Jiang, Lemao Liu, Shuming Shi",https://arxiv.org/abs/2201.02993,01,,
DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection,arXiv,2022,2201.00763,"Phillip Rieger, Thien Duc Nguyen, Markus Miettinen, Ahmad-Reza Sadeghi",https://arxiv.org/abs/2201.00763,01,"18 pages, 8 figures; to appear in the Network and Distributed System Security Symposium (NDSS)",
Compression-Resistant Backdoor Attack against Deep Neural Networks,arXiv,2022,2201.00672,"Mingfu Xue, Xin Wang, Shichang Sun, Yushu Zhang, Jian Wang, Weiqiang Liu",https://arxiv.org/abs/2201.00672,01,,
Causal Attention for Interpretable and Generalizable Graph Classification,arXiv,2021,2112.15089,"Yongduo Sui, Xiang Wang, Jiancan Wu, Min Lin, Xiangnan He, Tat-Seng Chua",https://arxiv.org/abs/2112.15089,12,Accepted to KDD 2022,
Few-shot Backdoor Defense Using Shapley Estimation,arXiv,2021,2112.14889,"Jiyang Guan, Zhuozhuo Tu, Ran He, Dacheng Tao",https://arxiv.org/abs/2112.14889,12,,
CatchBackdoor: Backdoor Testing by Critical Trojan Neural Path Identification via Differential Fuzzing,arXiv,2021,2112.13064,"Haibo Jin, Ruoxi Chen, Jinyin Chen, Yao Cheng, Chong Fu, Ting Wang, Yue Yu, Zhaoyan Ming",https://arxiv.org/abs/2112.13064,12,There are some problems in the experiment so we need to withdraw this paper. We will upload the new version after revision,
Dual-Key Multimodal Backdoors for Visual Question Answering,arXiv,2021,2112.07668,"Matthew Walmer, Karan Sikka, Indranil Sur, Abhinav Shrivastava, Susmit Jha",https://arxiv.org/abs/2112.07668,12,"Published as conference paper at CVPR 2022. 22 pages, 11 figures, 12 tables",
Protecting Your NLG Models with Semantic and Robust Watermarks,arXiv,2021,2112.05428,"Tao Xiang, Chunlong Xie, Shangwei Guo, Jiwei Li, Tianwei Zhang",https://arxiv.org/abs/2112.05428,12,,
Batch Label Inference and Replacement Attacks in Black-Boxed Vertical Federated Learning,arXiv,2021,2112.05409,"Yang Liu, Tianyuan Zou, Yan Kang, Wenhan Liu, Yuanqin He, Zhihao Yi, Qiang Yang",https://arxiv.org/abs/2112.05409,12,"13 pages, 9 figures, 3 tables, related previous work see arXiv:2007.03608",
Spinning Language Models: Risks of Propaganda-As-A-Service and Countermeasures,arXiv,2021,2112.05224,"Eugene Bagdasaryan, Vitaly Shmatikov",https://arxiv.org/abs/2112.05224,12,IEEE S&P 2022. arXiv admin note: text overlap with arXiv:2107.10443,
Test-Time Detection of Backdoor Triggers for Poisoned Deep Neural Networks,arXiv,2021,2112.03350,"Xi Li, Zhen Xiang, David J. Miller, George Kesidis",https://arxiv.org/abs/2112.03350,12,,
FIBA: Frequency-Injection based Backdoor Attack in Medical Image Analysis,arXiv,2021,2112.01148,"Yu Feng, Benteng Ma, Jing Zhang, Shanshan Zhao, Yong Xia, Dacheng Tao",https://arxiv.org/abs/2112.01148,12,Accepted by CVPR 2022,https://github.com/HazardFY/FIBA
CoviChain: A Blockchain Based COVID-19 Vaccination Passport,arXiv,2021,2112.01097,"Philip Bradish, Sarang Chaudhari, Michael Clear, Hitesh Tewari",https://arxiv.org/abs/2112.01097,12,,
Weakly-Supervised Video Object Grounding via Causal Intervention,arXiv,2021,2112.00475,"Wei Wang, Junyu Gao, Changsheng Xu",https://arxiv.org/abs/2112.00475,12,,
Anomaly Localization in Model Gradients Under Backdoor Attacks Against Federated Learning,arXiv,2021,2111.14683,Zeki Bilgin,https://arxiv.org/abs/2111.14683,11,13 pages and the code is available,https://github.com/ArcelikAcikKaynak/Federated_Learning.git
A General Framework for Defending Against Backdoor Attacks via Influence Graph,arXiv,2021,2111.14309,"Xiaofei Sun, Jiwei Li, Xiaoya Li, Ziyao Wang, Tianwei Zhang, Han Qiu, Fei Wu, Chun Fan",https://arxiv.org/abs/2111.14309,11,,
A Kernel Test for Causal Association via Noise Contrastive Backdoor Adjustment,arXiv,2021,2111.13226,"Robert Hu, Dino Sejdinovic, Robin J. Evans",https://arxiv.org/abs/2111.13226,11,,https://github.com/MrHuff/kgformula
Towards Practical Deployment-Stage Backdoor Attack on Deep Neural Networks,arXiv,2021,2111.12965,"Xiangyu Qi, Tinghao Xie, Ruizhe Pan, Jifeng Zhu, Yong Yang, Kai Bu",https://arxiv.org/abs/2111.12965,11,,
DBIA: Data-free Backdoor Injection Attack against Transformer Networks,arXiv,2021,2111.11870,"Peizhuo Lv, Hualong Ma, Jiachen Zhou, Ruigang Liang, Kai Chen, Shengzhi Zhang, Yunfei Yang",https://arxiv.org/abs/2111.11870,11,,
NTD: Non-Transferability Enabled Backdoor Detection,arXiv,2021,2111.11157,"Yinshan Li, Hua Ma, Zhi Zhang, Yansong Gao, Alsharif Abuadbba, Anmin Fu, Yifeng Zheng, Said F. Al-Sarawi, Derek Abbott",https://arxiv.org/abs/2111.11157,11,,
Backdoor Attack through Frequency Domain,arXiv,2021,2111.10991,"Tong Wang, Yuan Yao, Feng Xu, Shengwei An, Hanghang Tong, Ting Wang",https://arxiv.org/abs/2111.10991,11,,
TnT Attacks! Universal Naturalistic Adversarial Patches Against Deep Neural Network Systems,arXiv,2021,2111.09999,"Bao Gia Doan, Minhui Xue, Shiqing Ma, Ehsan Abbasnejad, Damith C. Ranasinghe",https://arxiv.org/abs/2111.09999,11,Accepted for publication in the IEEE Transactions on Information Forensics & Security (TIFS),
An Overview of Backdoor Attacks Against Deep Neural Networks and Possible Defences,arXiv,2021,2111.08429,"Wei Guo, Benedetta Tondi, Mauro Barni",https://arxiv.org/abs/2111.08429,11,,
Triggerless Backdoor Attack for NLP Tasks with Clean Labels,arXiv,2021,2111.07970,"Leilei Gan, Jiwei Li, Tianwei Zhang, Xiaoya Li, Yuxian Meng, Fei Wu, Yi Yang, Shangwei Guo, Chun Fan",https://arxiv.org/abs/2111.07970,11,Accepted to appear at the main conference of NAACL 2022,
Enhancing Backdoor Attacks with Multi-Level MMD Regularization,arXiv,2021,2111.05077,"Pengfei Xia, Hongjing Niu, Ziqiang Li, Bin Li",https://arxiv.org/abs/2111.05077,11,,https://github.com/xpf/Multi-Level-MMD-Regularization
"Federated Learning Attacks Revisited: A Critical Discussion of Gaps, Assumptions, and Evaluation Setups",arXiv,2021,2111.03363,"Aidmar Wainakh, Ephraim Zimmer, Sandeep Subedi, Jens Keim, Tim Grube, Shankar Karuppayah, Alejandro Sanchez Guinea, Max Mühlhäuser",https://arxiv.org/abs/2111.03363,11,"In Section 5.2, incomplete information are mentioned on reference [9] (""How To Backdoor Federated Learning""). This part of text will be revised and enriched",
Backdoor Pre-trained Models Can Transfer to All,arXiv,2021,2111.00197,"Lujia Shen, Shouling Ji, Xuhong Zhang, Jinfeng Li, Jing Chen, Jie Shi, Chengfang Fang, Jianwei Yin, Ting Wang",https://arxiv.org/abs/2111.00197,11,,
AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value Analysis,arXiv,2021,2110.14880,"Junfeng Guo, Ang Li, Cong Liu",https://arxiv.org/abs/2110.14880,10,,
Adversarial Neuron Pruning Purifies Backdoored Deep Models,arXiv,2021,2110.14430,"Dongxian Wu, Yisen Wang",https://arxiv.org/abs/2110.14430,10,To appear in NeurIPS 2021,
Qu-ANTI-zation: Exploiting Quantization Artifacts for Achieving Adversarial Outcomes,arXiv,2021,2110.13541,"Sanghyun Hong, Michael-Andrei Panaitescu-Liess, Yiğitcan Kaya, Tudor Dumitraş",https://arxiv.org/abs/2110.13541,10,Accepted to NeurIPS 2021 [Poster],https://github.com/Secure-AI-Systems-Group/Qu-ANTI-zation
Semantic Host-free Trojan Attack,arXiv,2021,2110.13414,"Haripriya Harikumar, Kien Do, Santu Rana, Sunil Gupta, Svetha Venkatesh",https://arxiv.org/abs/2110.13414,10,,
CoProtector: Protect Open-Source Code against Unauthorized Training Usage with Data Poisoning,arXiv,2021,2110.12925,"Zhensu Sun, Xiaoning Du, Fu Song, Mingze Ni, Li Li",https://arxiv.org/abs/2110.12925,10,"8 pages, accepted to WWW 2022",
Anti-Backdoor Learning: Training Clean Models on Poisoned Data,arXiv,2021,2110.11571,"Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li, Xingjun Ma",https://arxiv.org/abs/2110.11571,10,Accepted to NeurIPS 2021,https://github.com/bboylyg/ABL
Watermarking Graph Neural Networks based on Backdoor Attacks,arXiv,2021,2110.11024,"Jing Xu, Stefanos Koffas, Oguzhan Ersoy, Stjepan Picek",https://arxiv.org/abs/2110.11024,10,"18 pages, 9 figures",
PipAttack: Poisoning Federated Recommender Systems forManipulating Item Promotion,arXiv,2021,2110.10926,"Shijie Zhang, Hongzhi Yin, Tong Chen, Zi Huang, Quoc Viet Hung Nguyen, Lizhen Cui",https://arxiv.org/abs/2110.10926,10,Proceedings of the 15th ACM International Conference on Web Search and Data Mining (WSDM '22),
Detecting Backdoor Attacks Against Point Cloud Classifiers,arXiv,2021,2110.10354,"Zhen Xiang, David J. Miller, Siheng Chen, Xi Li, George Kesidis",https://arxiv.org/abs/2110.10354,10,,
Finding Backdoors to Integer Programs: A Monte Carlo Tree Search Framework,arXiv,2021,2110.08423,"Elias B. Khalil, Pashootan Vaezipoor, Bistra Dilkina",https://arxiv.org/abs/2110.08423,10,Published in the Proceedings of AAAI 2022,
Trigger Hunting with a Topological Prior for Trojan Detection,arXiv,2021,2110.08335,"Xiaoling Hu, Xiao Lin, Michael Cogswell, Yi Yao, Susmit Jha, Chao Chen",https://arxiv.org/abs/2110.08335,10,"17 pages, 10 figures",
Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks,arXiv,2021,2110.08247,"Yangyi Chen, Fanchao Qi, Hongcheng Gao, Zhiyuan Liu, Maosong Sun",https://arxiv.org/abs/2110.08247,10,"Accepted to EMNLP 2022, main conference",https://github.com/thunlp/StyleAttack
RAP: Robustness-Aware Perturbations for Defending against Backdoor Attacks on NLP Models,arXiv,2021,2110.07831,"Wenkai Yang, Yankai Lin, Peng Li, Jie Zhou, Xu Sun",https://arxiv.org/abs/2110.07831,10,"EMNLP 2021 (main conference), long paper, camera-ready version",https://github.com/lancopku/RAP
Don't Knock! Rowhammer at the Backdoor of DNN Models,arXiv,2021,2110.07683,"M. Caner Tol, Saad Islam, Andrew J. Adiletta, Berk Sunar, Ziming Zhang",https://arxiv.org/abs/2110.07683,10,2023 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN),
Bugs in our Pockets: The Risks of Client-Side Scanning,arXiv,2021,2110.07450,"Hal Abelson, Ross Anderson, Steven M. Bellovin, Josh Benaloh, Matt Blaze, Jon Callas, Whitfield Diffie, Susan Landau, Peter G. Neumann, Ronald L. Rivest, Jeffrey I. Schiller, Bruce Schneier, Vanessa Teague, Carmela Troncoso",https://arxiv.org/abs/2110.07450,10,"46 pages, 3 figures",
Mind the Style of Text! Adversarial and Backdoor Attacks Based on Text Style Transfer,arXiv,2021,2110.07139,"Fanchao Qi, Yangyi Chen, Xurui Zhang, Mukai Li, Zhiyuan Liu, Maosong Sun",https://arxiv.org/abs/2110.07139,10,Accepted by the main conference of EMNLP 2021 as a long paper. The camera-ready version,https://github.com/thunlp/StyleAttack
Poison Forensics: Traceback of Data Poisoning Attacks in Neural Networks,arXiv,2021,2110.06904,"Shawn Shan, Arjun Nitin Bhagoji, Haitao Zheng, Ben Y. Zhao",https://arxiv.org/abs/2110.06904,10,18 pages,
Widen The Backdoor To Let More Attackers In,arXiv,2021,2110.04571,"Siddhartha Datta, Giulio Lovisotto, Ivan Martinovic, Nigel Shadbolt",https://arxiv.org/abs/2110.04571,10,,
Dyn-Backdoor: Backdoor Attack on Dynamic Link Prediction,arXiv,2021,2110.03875,"Jinyin Chen, Haiyang Xiong, Haibin Zheng, Jian Zhang, Guodong Jiang, Yi Liu",https://arxiv.org/abs/2110.03875,10,"11 pages,6 figures",
Adversarial Unlearning of Backdoors via Implicit Hypergradient,arXiv,2021,2110.03735,"Yi Zeng, Si Chen, Won Park, Z. Morley Mao, Ming Jin, Ruoxi Jia",https://arxiv.org/abs/2110.03735,10,In proceeding of the Tenth International Conference on Learning Representations (ICLR 2022),
BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models,arXiv,2021,2110.02467,"Kangjie Chen, Yuxian Meng, Xiaofei Sun, Shangwei Guo, Tianwei Zhang, Jiwei Li, Chun Fan",https://arxiv.org/abs/2110.02467,10,,
Securing Federated Learning: A Covert Communication-based Approach,arXiv,2021,2110.02221,"Yuan-Ai Xie, Jiawen Kang, Dusit Niyato, Nguyen Thi Thanh Van, Nguyen Cong Luong, Zhixin Liu, Han Yu",https://arxiv.org/abs/2110.02221,10,,
When can relative risks provide causal estimates?,arXiv,2021,2110.01688,A. J. Webster,https://arxiv.org/abs/2110.01688,10,2 figures,
Security Review of Ethereum Beacon Clients,arXiv,2021,2109.11677,"Jean-Philippe Aumasson, Denis Kolegov, Evangelia Stathopoulou",https://arxiv.org/abs/2109.11677,09,"43 pages, 3 figures, 3 tables",
FooBaR: Fault Fooling Backdoor Attack on Neural Network Training,arXiv,2021,2109.11249,"Jakub Breier, Xiaolu Hou, Martín Ochoa, Jesus Solano",https://arxiv.org/abs/2109.11249,09,Published in IEEE TDSC,
BFClass: A Backdoor-free Text Classification Framework,arXiv,2021,2109.10855,"Zichao Li, Dheeraj Mekala, Chengyu Dong, Jingbo Shang",https://arxiv.org/abs/2109.10855,09,Accepted to appear in Findings of EMNLP 2021,
Backdoor Attacks on Federated Learning with Lottery Ticket Hypothesis,arXiv,2021,2109.10512,"Zeyuan Yin, Ye Yuan, Panfeng Guo, Pan Zhou",https://arxiv.org/abs/2109.10512,09,,
Backdoor Attack on Hash-based Image Retrieval via Clean-label Data Poisoning,arXiv,2021,2109.08868,"Kuofeng Gao, Jiawang Bai, Bin Chen, Dongxian Wu, Shu-Tao Xia",https://arxiv.org/abs/2109.08868,09,Accepted by BMVC 2023,https://github.com/KuofengGao/CIBA
Honey or Poison? Solving the Trigger Curse in Few-shot Event Detection via Causal Intervention,arXiv,2021,2109.05747,"Jiawei Chen, Hongyu Lin, Xianpei Han, Le Sun",https://arxiv.org/abs/2109.05747,09,Accepted to the main conference of EMNLP2021,
Check Your Other Door! Creating Backdoor Attacks in the Frequency Domain,arXiv,2021,2109.05507,"Hasan Abed Al Kader Hammoud, Bernard Ghanem",https://arxiv.org/abs/2109.05507,09,Accepted to BMVC 2022,
SanitAIs: Unsupervised Data Augmentation to Sanitize Trojaned Neural Networks,arXiv,2021,2109.04566,"Kiran Karra, Chace Ashcraft, Cash Costello",https://arxiv.org/abs/2109.04566,09,"7 pages, 5 figures",
Trojan Signatures in DNN Weights,arXiv,2021,2109.02836,"Greg Fields, Mohammad Samragh, Mojan Javaheripi, Farinaz Koushanfar, Tara Javidi",https://arxiv.org/abs/2109.02836,09,"8 pages, 13 figures",
Backdoor Attack and Defense for Deep Regression,arXiv,2021,2109.02381,"Xi Li, George Kesidis, David J. Miller, Vladimir Lucic",https://arxiv.org/abs/2109.02381,09,,
How to Inject Backdoors with Better Consistency: Logit Anchoring on Clean Data,arXiv,2021,2109.01300,"Zhiyuan Zhang, Lingjuan Lyu, Weiqiang Wang, Lichao Sun, Xu Sun",https://arxiv.org/abs/2109.01300,09,Accepted by ICLR 2022,
A Synergetic Attack against Neural Network Classifiers combining Backdoor and Adversarial Examples,arXiv,2021,2109.01275,"Guanxiong Liu, Issa Khalil, Abdallah Khreishah, NhatHai Phan",https://arxiv.org/abs/2109.01275,09,,
Excess Capacity and Backdoor Poisoning,arXiv,2021,2109.00685,"Naren Sarayu Manoj, Avrim Blum",https://arxiv.org/abs/2109.00685,09,Accepted to NeurIPS 2021,
Trade or Trick? Detecting and Characterizing Scam Tokens on Uniswap Decentralized Exchange,arXiv,2021,2109.00229,"Pengcheng Xia, Haoyu wang, Bingyu Gao, Weihang Su, Zhou Yu, Xiapu Luo, Chao Zhang, Xusheng Xiao, Guoai Xu",https://arxiv.org/abs/2109.00229,09,,
Backdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning,arXiv,2021,2108.13888,"Linyang Li, Demin Song, Xiaonan Li, Jiehang Zeng, Ruotian Ma, Xipeng Qiu",https://arxiv.org/abs/2108.13888,08,Accepted by EMNLP2021 main conference,
TRAPDOOR: Repurposing backdoors to detect dataset bias in machine learning-based genomic analysis,arXiv,2021,2108.10132,"Esha Sarkar, Michail Maniatakos",https://arxiv.org/abs/2108.10132,08,,
Quantization Backdoors to Deep Learning Commercial Frameworks,arXiv,2021,2108.09187,"Hua Ma, Huming Qiu, Yansong Gao, Zhi Zhang, Alsharif Abuadbba, Minhui Xue, Anmin Fu, Zhang Jiliang, Said Al-Sarawi, Derek Abbott",https://arxiv.org/abs/2108.09187,08,,
Poison Ink: Robust and Invisible Backdoor Attack,arXiv,2021,2108.02488,"Jie Zhang, Dongdong Chen, Qidong Huang, Jing Liao, Weiming Zhang, Huamin Feng, Gang Hua, Nenghai Yu",https://arxiv.org/abs/2108.02488,08,IEEE Transactions on Image Processing (TIP),
The Devil is in the GAN: Backdoor Attacks and Defenses in Deep Generative Models,arXiv,2021,2108.01644,"Ambrish Rawat, Killian Levacher, Mathieu Sinn",https://arxiv.org/abs/2108.01644,08,"17 pages, 11 figures, 3 tables",
Causal Inference in Educational Systems: A Graphical Modeling Approach,arXiv,2021,2108.00654,"Manie Tadayon, Greg Pottie",https://arxiv.org/abs/2108.00654,08,,
BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning,arXiv,2021,2108.00352,"Jinyuan Jia, Yupei Liu, Neil Zhenqiang Gong",https://arxiv.org/abs/2108.00352,08,"To appear in IEEE Symposium on Security and Privacy, 2022",https://github.com/jjy1994/BadEncoder
Can You Hear It? Backdoor Attacks via Ultrasonic Triggers,arXiv,2021,2107.14569,"Stefanos Koffas, Jing Xu, Mauro Conti, Stjepan Picek",https://arxiv.org/abs/2107.14569,07,,
Towards Unbiased Visual Emotion Recognition via Causal Intervention,arXiv,2021,2107.12096,"Yuedong Chen, Xu Yang, Tat-Jen Cham, Jianfei Cai",https://arxiv.org/abs/2107.12096,07,"Accepted to ACM Multimedia 2022, code is available at https://github.com/donydchen/causal_emotion",https://github.com/donydchen/causal_emotion
Spinning Sequence-to-Sequence Models with Meta-Backdoors,arXiv,2021,2107.10443,"Eugene Bagdasaryan, Vitaly Shmatikov",https://arxiv.org/abs/2107.10443,07,"Outdated. Superseded by arXiv:2112.05224 and published at IEEE S&P'22 with title: ""Spinning Language Models: Risks of Propaganda-As-A-Service and Countermeasures""",
Structural Watermarking to Deep Neural Networks via Network Channel Pruning,arXiv,2021,2107.08688,"Xiangyu Zhao, Yinzhe Yao, Hanzhou Wu, Xinpeng Zhang",https://arxiv.org/abs/2107.08688,07,Accepted by IEEE International Workshop on Information Forensics and Security 2021,
Subnet Replacement: Deployment-stage backdoor attack against deep neural networks in gray-box setting,arXiv,2021,2107.07240,"Xiangyu Qi, Jifeng Zhu, Chulin Xie, Yong Yang",https://arxiv.org/abs/2107.07240,07,"6 pages, 3 figures, ICLR 2021 Workshop on Security and Safety in Machine Learning System",
Understanding the Security of Deepfake Detection,arXiv,2021,2107.02045,"Xiaoyu Cao, Neil Zhenqiang Gong",https://arxiv.org/abs/2107.02045,07,To appear in ICDF2C 2021,
Interventional Video Grounding with Dual Contrastive Learning,arXiv,2021,2106.11013,"Guoshun Nan, Rui Qiao, Yao Xiao, Jun Liu, Sicong Leng, Hao Zhang, Wei Lu",https://arxiv.org/abs/2106.11013,06,Accepted in CVPR 2021,
Poisoning and Backdooring Contrastive Learning,arXiv,2021,2106.09667,"Nicholas Carlini, Andreas Terzis",https://arxiv.org/abs/2106.09667,06,,
De-biasing Distantly Supervised Named Entity Recognition via Causal Intervention,arXiv,2021,2106.09233,"Wenkai Zhang, Hongyu Lin, Xianpei Han, Le Sun",https://arxiv.org/abs/2106.09233,06,Accepted to ACL2021(main conference),
Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch,arXiv,2021,2106.08970,"Hossein Souri, Liam Fowl, Rama Chellappa, Micah Goldblum, Tom Goldstein",https://arxiv.org/abs/2106.08970,06,NeurIPS 2022,https://github.com/hsouri/Sleeper-Agent
CRFL: Certifiably Robust Federated Learning against Backdoor Attacks,arXiv,2021,2106.08283,"Chulin Xie, Minghao Chen, Pin-Yu Chen, Bo Li",https://arxiv.org/abs/2106.08283,06,ICML 2021,https://github.com/AI-secure/CRFL
Detect and remove watermark in deep neural networks via generative adversarial networks,arXiv,2021,2106.08104,"Haoqi Wang, Mingfu Xue, Shichang Sun, Yushu Zhang, Jian Wang, Weiqiang Liu",https://arxiv.org/abs/2106.08104,06,,
Machine Learning with Electronic Health Records is vulnerable to Backdoor Trigger Attacks,arXiv,2021,2106.07925,"Byunggill Joe, Akshay Mehra, Insik Shin, Jihun Hamm",https://arxiv.org/abs/2106.07925,06,,
Backdoor Learning Curves: Explaining Backdoor Poisoning Beyond Influence Functions,arXiv,2021,2106.07214,"Antonio Emanuele Cinà, Kathrin Grosse, Sebastiano Vascon, Ambra Demontis, Battista Biggio, Fabio Roli, Marcello Pelillo",https://arxiv.org/abs/2106.07214,06,preprint; 28 pages,
Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution,arXiv,2021,2106.06361,"Fanchao Qi, Yuan Yao, Sophia Xu, Zhiyuan Liu, Maosong Sun",https://arxiv.org/abs/2106.06361,06,Accepted by the main conference of ACL-IJCNLP as a long paper. Camera-ready version,https://github.com/thunlp/BkdAtk-LWS
A Unified Framework for Task-Driven Data Quality Management,arXiv,2021,2106.05484,"Tianhao Wang, Yi Zeng, Ming Jin, Ruoxi Jia",https://arxiv.org/abs/2106.05484,06,,
Learning Pseudo-Backdoors for Mixed Integer Programs,arXiv,2021,2106.05080,"Aaron Ferber, Jialin Song, Bistra Dilkina, Yisong Yue",https://arxiv.org/abs/2106.05080,06,"2 pages, 1 page reference, SOCS extended abstract",
Handcrafted Backdoors in Deep Neural Networks,arXiv,2021,2106.04690,"Sanghyun Hong, Nicholas Carlini, Alexey Kurakin",https://arxiv.org/abs/2106.04690,06,Accepted to NeurIPS 2022 [Oral],
Defending Against Backdoor Attacks in Natural Language Generation,arXiv,2021,2106.01810,"Xiaofei Sun, Xiaoya Li, Yuxian Meng, Xiang Ao, Lingjuan Lyu, Jiwei Li, Tianwei Zhang",https://arxiv.org/abs/2106.01810,06,To appear at AAAI 2023,
Deconfounded Video Moment Retrieval with Causal Intervention,arXiv,2021,2106.01534,"Xun Yang, Fuli Feng, Wei Ji, Meng Wang, Tat-Seng Chua",https://arxiv.org/abs/2106.01534,06,This work has been accepted by SIGIR 2021,https://github.com/Xun-Yang/Causal_Video_Moment_Retrieval
Detecting Backdoor in Deep Neural Networks via Intentional Adversarial Perturbations,arXiv,2021,2105.14259,"Mingfu Xue, Yinghao Wu, Zhiyu Wu, Yushu Zhang, Jian Wang, Weiqiang Liu",https://arxiv.org/abs/2105.14259,05,,
Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger,arXiv,2021,2105.12400,"Fanchao Qi, Mukai Li, Yangyi Chen, Zhengyan Zhang, Zhiyuan Liu, Yasheng Wang, Maosong Sun",https://arxiv.org/abs/2105.12400,05,Accepted by ACL-IJCNLP 2021 as a long paper. Camera-ready version,https://github.com/thunlp/HiddenKiller
Intrusion Detection System in Smart Home Network Using Bidirectional LSTM and Convolutional Neural Networks Hybrid Model,arXiv,2021,2105.12096,"Nelly Elsayed, Zaghloul Saad Zaghloul, Sylvia Worlali Azumah, Chengcheng Li",https://arxiv.org/abs/2105.12096,05,"4 pages, 6 figures, Accepted in the MWSCAS 2021. This material is based upon work supported by the National Science Foundation under Grant No. (CNS-1801593). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation",
Deconfounded Recommendation for Alleviating Bias Amplification,arXiv,2021,2105.10648,"Wenjie Wang, Fuli Feng, Xiangnan He, Xiang Wang, Tat-Seng Chua",https://arxiv.org/abs/2105.10648,05,,
Backdoor Attacks on Self-Supervised Learning,arXiv,2021,2105.10123,"Aniruddha Saha, Ajinkya Tejankar, Soroush Abbasi Koohpayegani, Hamed Pirsiavash",https://arxiv.org/abs/2105.10123,05,CVPR 2022 (Oral),https://github.com/UMBCvision/SSL-Backdoor
DeepObliviate: A Powerful Charm for Erasing Data Residual Memory in Deep Neural Networks,arXiv,2021,2105.06209,"Yingzhe He, Guozhu Meng, Kai Chen, Jinwen He, Xingbo Hu",https://arxiv.org/abs/2105.06209,05,"16 pages, 10 figures, conference",
Poisoning MorphNet for Clean-Label Backdoor Attack to Point Clouds,arXiv,2021,2105.04839,"Guiyu Tian, Wenhao Jiang, Wei Liu, Yadong Mu",https://arxiv.org/abs/2105.04839,05,,
Incompatibility Clustering as a Defense Against Backdoor Poisoning Attacks,arXiv,2021,2105.03692,"Charles Jin, Melinda Sun, Martin Rinard",https://arxiv.org/abs/2105.03692,05,ICLR 2023. Code is available at https://github.com/charlesjin/compatibility_clustering/,https://github.com/charlesjin/compatibility_clustering/
BACKDOORL: Backdoor Attack against Competitive Reinforcement Learning,arXiv,2021,2105.00579,"Lun Wang, Zaynah Javed, Xian Wu, Wenbo Guo, Xinyu Xing, Dawn Song",https://arxiv.org/abs/2105.00579,05,,
A Master Key Backdoor for Universal Impersonation Attack against DNN-based Face Verification,arXiv,2021,2105.00249,"Wei Guo, Benedetta Tondi, Mauro Barni",https://arxiv.org/abs/2105.00249,05,,
Hidden Backdoors in Human-Centric Language Models,arXiv,2021,2105.00164,"Shaofeng Li, Hui Liu, Tian Dong, Benjamin Zi Hao Zhao, Minhui Xue, Haojin Zhu, Jialiang Lu",https://arxiv.org/abs/2105.00164,05,,
Stealthy Backdoors as Compression Artifacts,arXiv,2021,2104.15129,"Yulong Tian, Fnu Suya, Fengyuan Xu, David Evans",https://arxiv.org/abs/2104.15129,04,"20 pages, 9 figures, 14 tables",
Interventional Aspect-Based Sentiment Analysis,arXiv,2021,2104.11681,"Zhen Bi, Ningyu Zhang, Ganqiang Ye, Haiyang Yu, Xi Chen, Huajun Chen",https://arxiv.org/abs/2104.11681,04,Work in progress,
SPECTRE: Defending Against Backdoor Attacks Using Robust Statistics,arXiv,2021,2104.11315,"Jonathan Hayase, Weihao Kong, Raghav Somani, Sewoong Oh",https://arxiv.org/abs/2104.11315,04,29 pages 19 figures,https://github.com/SewoongLab/spectre-defense
Manipulating SGD with Data Ordering Attacks,arXiv,2021,2104.09667,"Ilia Shumailov, Zakhar Shumaylov, Dmitry Kazhdan, Yiren Zhao, Nicolas Papernot, Murat A. Erdogdu, Ross Anderson",https://arxiv.org/abs/2104.09667,04,,
Protecting the Intellectual Properties of Deep Neural Networks with an Additional Class and Steganographic Images,arXiv,2021,2104.09203,"Shichang Sun, Mingfu Xue, Jian Wang, Weiqiang Liu",https://arxiv.org/abs/2104.09203,04,,
Robust Backdoor Attacks against Deep Neural Networks in Real Physical World,arXiv,2021,2104.07395,"Mingfu Xue, Can He, Shichang Sun, Jian Wang, Weiqiang Liu",https://arxiv.org/abs/2104.07395,04,,
Towards Causal Federated Learning For Enhanced Robustness and Privacy,arXiv,2021,2104.06557,"Sreya Francis, Irene Tenison, Irina Rish",https://arxiv.org/abs/2104.06557,04,,
A Backdoor Attack against 3D Point Cloud Classifiers,arXiv,2021,2104.05808,"Zhen Xiang, David J. Miller, Siheng Chen, Xi Li, George Kesidis",https://arxiv.org/abs/2104.05808,04,,
Reversible Watermarking in Deep Convolutional Neural Networks for Integrity Authentication,arXiv,2021,2104.04268,"Xiquan Guan, Huamin Feng, Weiming Zhang, Hang Zhou, Jie Zhang, Nenghai Yu",https://arxiv.org/abs/2104.04268,04,Accepted to ACM MM 2020,
Explainability-based Backdoor Attacks Against Graph Neural Networks,arXiv,2021,2104.03674,"Jing Xu,  Minhui,  Xue, Stjepan Picek",https://arxiv.org/abs/2104.03674,04,"6 pages, 4 figures",
Rethinking the Backdoor Attacks' Triggers: A Frequency Perspective,arXiv,2021,2104.03413,"Yi Zeng, Won Park, Z. Morley Mao, Ruoxi Jia",https://arxiv.org/abs/2104.03413,04,,
Backdoor Attack in the Physical World,arXiv,2021,2104.02361,"Yiming Li, Tongqing Zhai, Yong Jiang, Zhifeng Li, Shu-Tao Xia",https://arxiv.org/abs/2104.02361,04,"This work was done when Yiming Li was an intern at Tencent AI Lab, supported by the Tencent Rhino-Bird Elite Training Program (2020). This is a 6-pages short version of our ongoing work, `Rethinking the Trigger of Backdoor Attack' (arXiv:2004.04692). It is accepted by the non-archival ICLR 2021 workshop on Robust and Reliable Machine Learning in the Real World. arXiv admin note: substantial text overlap with arXiv:2004.04692",
SGBA: A Stealthy Scapegoat Backdoor Attack against Deep Neural Networks,arXiv,2021,2104.01026,"Ying He, Zhili Shen, Chang Xia, Jingyu Hua, Wei Tong, Sheng Zhong",https://arxiv.org/abs/2104.01026,04,,
PointBA: Towards Backdoor Attacks in 3D Point Cloud,arXiv,2021,2103.16074,"Xinke Li, Zhirui Chen, Yue Zhao, Zekun Tong, Yabang Zhao, Andrew Lim, Joey Tianyi Zhou",https://arxiv.org/abs/2103.16074,03,Accepted by ICCV 2021,
Learning Domain Invariant Representations for Generalizable Person Re-Identification,arXiv,2021,2103.15890,"Yi-Fan Zhang, Zhang Zhang, Da Li, Zhen Jia, Liang Wang, Tieniu Tan",https://arxiv.org/abs/2103.15890,03,,
Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability of the Embedding Layers in NLP Models,arXiv,2021,2103.15543,"Wenkai Yang, Lei Li, Zhiyuan Zhang, Xuancheng Ren, Xu Sun, Bin He",https://arxiv.org/abs/2103.15543,03,"NAACL-HLT 2021, Long Paper",https://github.com/lancopku/Embedding-Poisoning
Fooling LiDAR Perception via Adversarial Trajectory Perturbation,arXiv,2021,2103.15326,"Yiming Li, Congcong Wen, Felix Juefei-Xu, Chen Feng",https://arxiv.org/abs/2103.15326,03,2021 IEEE International Conference on Computer Vision (ICCV) [Oral Presentation],https://ai4ce.github.io/FLAT/
On the Hierarchical Community Structure of Practical Boolean Formulas,arXiv,2021,2103.14992,"Chunxiao Li, Jonathan Chung, Soham Mukherjee, Marc Vinyals, Noah Fleming, Antonina Kolokolova, Alice Mu, Vijay Ganesh",https://arxiv.org/abs/2103.14992,03,,
HufuNet: Embedding the Left Piece as Watermark and Keeping the Right Piece for Ownership Verification in Deep Neural Networks,arXiv,2021,2103.13628,"Peizhuo Lv, Pan Li, Shengzhi Zhang, Kai Chen, Ruigang Liang, Yue Zhao, Yingjiu Li",https://arxiv.org/abs/2103.13628,03,,
Black-box Detection of Backdoor Attacks with Limited Information and Data,arXiv,2021,2103.13127,"Yinpeng Dong, Xiao Yang, Zhijie Deng, Tianyu Pang, Zihao Xiao, Hang Su, Jun Zhu",https://arxiv.org/abs/2103.13127,03,,
TOP: Backdoor Detection in Neural Networks via Transferability of Perturbation,arXiv,2021,2103.10274,"Todd Huster, Emmanuel Ekwedike",https://arxiv.org/abs/2103.10274,03,,
EX-RAY: Distinguishing Injected Backdoor from Natural Features in Neural Networks by Examining Differential Feature Symmetry,arXiv,2021,2103.08820,"Yingqi Liu, Guangyu Shen, Guanhong Tao, Zhenting Wang, Shiqing Ma, Xiangyu Zhang",https://arxiv.org/abs/2103.08820,03,21 pages,
T-Miner: A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification,arXiv,2021,2103.04264,"Ahmadreza Azizi, Ibrahim Asadullah Tahmid, Asim Waheed, Neal Mangaokar, Jiameng Pu, Mobin Javed, Chandan K. Reddy, Bimal Viswanath",https://arxiv.org/abs/2103.04264,03,"Accepted to Usenix Security 2021; First two authors contributed equally to this work; 18 pages, 11 tables",
Hidden Backdoor Attack against Semantic Segmentation Models,arXiv,2021,2103.04038,"Yiming Li, Yanjie Li, Yalei Lv, Yong Jiang, Shu-Tao Xia",https://arxiv.org/abs/2103.04038,03,"This is a 6-pages short version of our ongoing work. It is accepted by the non-archival ICLR workshop on Security and Safety in Machine Learning Systems, 2021. The first two authors contributed equally to this work",
DP-InstaHide: Provably Defusing Poisoning and Backdoor Attacks with Differentially Private Data Augmentations,arXiv,2021,2103.02079,"Eitan Borgnia, Jonas Geiping, Valeriia Cherepanova, Liam Fowl, Arjun Gupta, Amin Ghiasi, Furong Huang, Micah Goldblum, Tom Goldstein",https://arxiv.org/abs/2103.02079,03,"11 pages, 5 figures",
What Doesn't Kill You Makes You Robust(er): How to Adversarially Train against Data Poisoning,arXiv,2021,2102.13624,"Jonas Geiping, Liam Fowl, Gowthami Somepalli, Micah Goldblum, Michael Moeller, Tom Goldstein",https://arxiv.org/abs/2102.13624,02,"25 pages, 15 figures",
Targeted Attack against Deep Neural Networks via Flipping Limited Weight Bits,arXiv,2021,2102.10496,"Jiawang Bai, Baoyuan Wu, Yong Zhang, Yiming Li, Zhifeng Li, Shu-Tao Xia",https://arxiv.org/abs/2102.10496,02,Accepted by ICLR 2021,
WaNet -- Imperceptible Warping-based Backdoor Attack,arXiv,2021,2102.10369,"Anh Nguyen, Anh Tran",https://arxiv.org/abs/2102.10369,02,Accepted to ICLR 2021,
Necessary and sufficient graphical conditions for optimal adjustment sets in causal graphical models with hidden variables,arXiv,2021,2102.10324,Jakob Runge,https://arxiv.org/abs/2102.10324,02,"41 pages, published as spotlight paper in 35th Conference on Neural Information Processing Systems (NeurIPS 2021); this version has an updated Supplementary Material with corrected proofs (also updated in NeurIPS proceedings)",https://github.com/jakobrunge/tigramite
Adversarial Targeted Forgetting in Regularization and Generative Based Continual Learning Models,arXiv,2021,2102.08355,"Muhammad Umer, Robi Polikar",https://arxiv.org/abs/2102.08355,02,arXiv admin note: text overlap with arXiv:2002.07111,
Meta Federated Learning,arXiv,2021,2102.05561,"Omid Aramoon, Pin-Yu Chen, Gang Qu, Yuan Tian",https://arxiv.org/abs/2102.05561,02,"11 pages, 5 figures",
Robust Federated Learning with Attack-Adaptive Aggregation,arXiv,2021,2102.05257,"Ching Pui Wan, Qifeng Chen",https://arxiv.org/abs/2102.05257,02,"14 pages, submitted to FTL-IJCAI'21",
Backdoor Scanning for Deep Neural Networks through K-Arm Optimization,arXiv,2021,2102.05123,"Guangyu Shen, Yingqi Liu, Guanhong Tao, Shengwei An, Qiuling Xu, Siyuan Cheng, Shiqing Ma, Xiangyu Zhang",https://arxiv.org/abs/2102.05123,02,,
Recursive Backdoors for SAT,arXiv,2021,2102.04707,"Nikolas Mählmann, Sebastian Siebertz, Alexandre Vigny",https://arxiv.org/abs/2102.04707,02,,
SAFELearning: Enable Backdoor Detectability In Federated Learning With Secure Aggregation,arXiv,2021,2102.02402,"Zhuosheng Zhang, Jiarui Li, Shucheng Yu, Christian Makaya",https://arxiv.org/abs/2102.02402,02,,
Curse or Redemption? How Data Heterogeneity Affects the Robustness of Federated Learning,arXiv,2021,2102.00655,"Syed Zawad, Ahsan Ali, Pin-Yu Chen, Ali Anwar, Yi Zhou, Nathalie Baracaldo, Yuan Tian, Feng Yan",https://arxiv.org/abs/2102.00655,02,Accepted in AAAI 2021,
Graph Embedding for Recommendation against Attribute Inference Attacks,arXiv,2021,2101.12549,"Shijie Zhang, Hongzhi Yin, Tong Chen, Zi Huang, Lizhen Cui, Xiangliang Zhang",https://arxiv.org/abs/2101.12549,01,,
On Provable Backdoor Defense in Collaborative Learning,arXiv,2021,2101.08177,"Ximing Qiao, Yuhua Bai, Siping Hu, Ang Li, Yiran Chen, Hai Li",https://arxiv.org/abs/2101.08177,01,,
Red Alarm for Pre-trained Models: Universal Vulnerability to Neuron-Level Backdoor Attacks,arXiv,2021,2101.06969,"Zhengyan Zhang, Guangxuan Xiao, Yongwei Li, Tian Lv, Fanchao Qi, Zhiyuan Liu, Yasheng Wang, Xin Jiang, Maosong Sun",https://arxiv.org/abs/2101.06969,01,Published in Machine Intelligence Research (https://link.springer.com/article/10.1007/s11633-022-1377-5),https://github.com/thunlp/NeuBA
What Do Deep Nets Learn? Class-wise Patterns Revealed in the Input Space,arXiv,2021,2101.06898,"Shihao Zhao, Xingjun Ma, Yisen Wang, James Bailey, Bo Li, Yu-Gang Jiang",https://arxiv.org/abs/2101.06898,01,,
DeepPayload: Black-box Backdoor Attack on Deep Learning Models through Neural Payload Injection,arXiv,2021,2101.06896,"Yuanchun Li, Jiayi Hua, Haoyu Wang, Chunyang Chen, Yunxin Liu",https://arxiv.org/abs/2101.06896,01,ICSE 2021,
Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks,arXiv,2021,2101.05930,"Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li, Xingjun Ma",https://arxiv.org/abs/2101.05930,01,"19 pages, 14 figures, ICLR 2021",https://github.com/bboylyg/NAD
FLAME: Taming Backdoors in Federated Learning (Extended Version 1),arXiv,2021,2101.02281,"Thien Duc Nguyen, Phillip Rieger, Huili Chen, Hossein Yalame, Helen Möllering, Hossein Fereidooni, Samuel Marchal, Markus Miettinen, Azalia Mirhoseini, Shaza Zeitouni, Farinaz Koushanfar, Ahmad-Reza Sadeghi, Thomas Schneider",https://arxiv.org/abs/2101.02281,01,"This extended version incorporates a novel section (Section 10) that provides a comprehensive analysis of recent proposed attacks, notably ""3DFed: Adaptive and extensible framework for covert backdoor attack in federated learning"" by Li et al. This new section addresses flawed assertions made in the papers that aim to bypass FLAME or misinterpreted its fundamental design principles",
Explainability Matters: Backdoor Attacks on Medical Imaging,arXiv,2021,2101.00008,"Munachiso Nwadike, Takumi Miyawaki, Esha Sarkar, Michail Maniatakos, Farah Shamout",https://arxiv.org/abs/2101.00008,01,,
Deep Feature Space Trojan Attack of Neural Networks by Controlled Detoxification,arXiv,2020,2012.11212,"Siyuan Cheng, Yingqi Liu, Shiqing Ma, Xiangyu Zhang",https://arxiv.org/abs/2012.11212,12,,
"Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses",arXiv,2020,2012.10544,"Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, Avi Schwarzschild, Dawn Song, Aleksander Madry, Bo Li, Tom Goldstein",https://arxiv.org/abs/2012.10544,12,,
"TrojanZoo: Towards Unified, Holistic, and Practical Evaluation of Neural Backdoors",arXiv,2020,2012.09302,"Ren Pang, Zheng Zhang, Xiangshan Gao, Zhaohan Xi, Shouling Ji, Peng Cheng, Xiapu Luo, Ting Wang",https://arxiv.org/abs/2012.09302,12,Accepted as a full paper at EuroS&P 2022,
HaS-Nets: A Heal and Select Mechanism to Defend DNNs Against Backdoor Attacks for Data Collection Scenarios,arXiv,2020,2012.07474,"Hassan Ali, Surya Nepal, Salil S. Kanhere, Sanjay Jha",https://arxiv.org/abs/2012.07474,12,"21 pages, 36 figures, conference paper",
Budgeted and Non-budgeted Causal Bandits,arXiv,2020,2012.07058,"Vineet Nair, Vishakha Patil, Gaurav Sinha",https://arxiv.org/abs/2012.07058,12,,
DeepSweep: An Evaluation Framework for Mitigating DNN Backdoor Attacks using Data Augmentation,arXiv,2020,2012.07006,"Han Qiu, Yi Zeng, Shangwei Guo, Tianwei Zhang, Meikang Qiu, Bhavani Thuraisingham",https://arxiv.org/abs/2012.07006,12,,
Federated Mimic Learning for Privacy Preserving Intrusion Detection,arXiv,2020,2012.06974,"Noor Ali Al-Athba Al-Marri, Bekir Sait Ciftler, Mohamed Abdallah",https://arxiv.org/abs/2012.06974,12,"6 pages, 6 figures, accepted to Blackseacom 2020",
Invisible Backdoor Attack with Sample-Specific Triggers,arXiv,2020,2012.03816,"Yuezun Li, Yiming Li, Baoyuan Wu, Longkang Li, Ran He, Siwei Lyu",https://arxiv.org/abs/2012.03816,12,It is accepted by ICCV 2021,
Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks,arXiv,2020,2012.03765,"Jinyuan Jia, Yupei Liu, Xiaoyu Cao, Neil Zhenqiang Gong",https://arxiv.org/abs/2012.03765,12,"To appear in AAAI Conference on Artificial Intelligence, 2022",
Detecting Trojaned DNNs Using Counterfactual Attributions,arXiv,2020,2012.02275,"Karan Sikka, Indranil Sur, Susmit Jha, Anirban Roy, Ajay Divakaran",https://arxiv.org/abs/2012.02275,12,,
Effect of backdoor attacks over the complexity of the latent space distribution,arXiv,2020,2012.01931,"Henry D. Chacon, Paul Rad",https://arxiv.org/abs/2012.01931,12,,
Backdoor Attacks on the DNN Interpretation System,arXiv,2020,2011.10698,"Shihong Fang, Anna Choromanska",https://arxiv.org/abs/2011.10698,11,"Published at the 2022 AAAI Conference on Artificial Intelligence (AAAI), 2022",
ONION: A Simple and Effective Defense Against Textual Backdoor Attacks,arXiv,2020,2011.10369,"Fanchao Qi, Yangyi Chen, Mukai Li, Yuan Yao, Zhiyuan Liu, Maosong Sun",https://arxiv.org/abs/2011.10369,11,Accepted by the main conference of EMNLP 2021 as a short paper. The camera-ready version,https://github.com/thunlp/ONION
Strong Data Augmentation Sanitizes Poisoning and Backdoor Attacks Without an Accuracy Tradeoff,arXiv,2020,2011.09527,"Eitan Borgnia, Valeriia Cherepanova, Liam Fowl, Amin Ghiasi, Jonas Geiping, Micah Goldblum, Tom Goldstein, Arjun Gupta",https://arxiv.org/abs/2011.09527,11,Authors ordered alphabetically,
Dynamic backdoor attacks against federated learning,arXiv,2020,2011.07429,Anbu Huang,https://arxiv.org/abs/2011.07429,11,8 pages,
Detecting Backdoors in Neural Networks Using Novel Feature-Based Anomaly Detection,arXiv,2020,2011.02526,"Hao Fu, Akshaj Kumar Veldanda, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami",https://arxiv.org/abs/2011.02526,11,,
BaFFLe: Backdoor detection via Feedback-based Federated Learning,arXiv,2020,2011.02167,"Sebastien Andreina, Giorgia Azzurra Marson, Helen Möllering, Ghassan Karame",https://arxiv.org/abs/2011.02167,11,"11 pages, 5 figures; to appear in the 41st IEEE International Conference on Distributed Computing Systems (ICDCS'21)",
Mitigating Backdoor Attacks in Federated Learning,arXiv,2020,2011.01767,"Chen Wu, Xian Yang, Sencun Zhu, Prasenjit Mitra",https://arxiv.org/abs/2011.01767,11,,
EEG-Based Brain-Computer Interfaces Are Vulnerable to Backdoor Attacks,arXiv,2020,2011.00101,"Lubin Meng, Jian Huang, Zhigang Zeng, Xue Jiang, Shan Yu, Tzyy-Ping Jung, Chin-Teng Lin, Ricardo Chavarriaga, Dongrui Wu",https://arxiv.org/abs/2011.00101,11,,
On Evaluating Neural Network Backdoor Defenses,arXiv,2020,2010.12186,"Akshaj Veldanda, Siddharth Garg",https://arxiv.org/abs/2010.12186,10,,
Backdoor Attack against Speaker Verification,arXiv,2020,2010.11607,"Tongqing Zhai, Yiming Li, Ziqi Zhang, Baoyuan Wu, Yong Jiang, Shu-Tao Xia",https://arxiv.org/abs/2010.11607,10,Accepted by the ICASSP 2021. The first two authors contributed equally to this work,https://github.com/zhaitongqing233/Backdoor-attack-against-speaker-verification
L-RED: Efficient Post-Training Detection of Imperceptible Backdoor Attacks without Access to the Training Set,arXiv,2020,2010.09987,"Zhen Xiang, David J. Miller, George Kesidis",https://arxiv.org/abs/2010.09987,10,,
"Poisoned classifiers are not only backdoored, they are fundamentally broken",arXiv,2020,2010.09080,"Mingjie Sun, Siddhant Agarwal, J. Zico Kolter",https://arxiv.org/abs/2010.09080,10,,
GOAT: GPU Outsourcing of Deep Learning Training With Asynchronous Probabilistic Integrity Verification Inside Trusted Execution Environment,arXiv,2020,2010.08855,"Aref Asvadishirehjini, Murat Kantarcioglu, Bradley Malin",https://arxiv.org/abs/2010.08855,10,,
Embedding and Extraction of Knowledge in Tree Ensemble Classifiers,arXiv,2020,2010.08281,"Wei Huang, Xingyu Zhao, Xiaowei Huang",https://arxiv.org/abs/2010.08281,10,,
Input-Aware Dynamic Backdoor Attack,arXiv,2020,2010.08138,"Anh Nguyen, Anh Tran",https://arxiv.org/abs/2010.08138,10,Accepted to NeurIPS 2020,https://github.com/VinAIResearch/input-aware-backdoor-attack-release
Federated Learning in Adversarial Settings,arXiv,2020,2010.07808,"Raouf Kerkouche, Gergely Ács, Claude Castelluccia",https://arxiv.org/abs/2010.07808,10,,
Reverse Engineering Imperceptible Backdoor Attacks on Deep Neural Networks for Detection and Training Set Cleansing,arXiv,2020,2010.07489,"Zhen Xiang, David J. Miller, George Kesidis",https://arxiv.org/abs/2010.07489,10,,
BlockFLA: Accountable Federated Learning via Hybrid Blockchain Architecture,arXiv,2020,2010.07427,"Harsh Bimal Desai, Mustafa Safa Ozdayi, Murat Kantarcioglu",https://arxiv.org/abs/2010.07427,10,,
Open-sourced Dataset Protection via Backdoor Watermarking,arXiv,2020,2010.05821,"Yiming Li, Ziqi Zhang, Jiawang Bai, Baoyuan Wu, Yong Jiang, Shu-Tao Xia",https://arxiv.org/abs/2010.05821,10,"Accepted by the NeurIPS Workshop on Dataset Curation and Security, 2020. 6 pages",
Don't Trigger Me! A Triggerless Backdoor Attack Against Deep Neural Networks,arXiv,2020,2010.03282,"Ahmed Salem, Michael Backes, Yang Zhang",https://arxiv.org/abs/2010.03282,10,,
BAAAN: Backdoor Attacks Against Autoencoder and GAN-Based Machine Learning Models,arXiv,2020,2010.03007,"Ahmed Salem, Yannick Sautter, Michael Backes, Mathias Humbert, Yang Zhang",https://arxiv.org/abs/2010.03007,10,,
Poison Attacks against Text Datasets with Conditional Adversarially Regularized Autoencoder,arXiv,2020,2010.02684,"Alvin Chan, Yi Tay, Yew-Soon Ong, Aston Zhang",https://arxiv.org/abs/2010.02684,10,"Accepted in EMNLP-Findings 2020, Camera Ready Version",
Interventional Few-Shot Learning,arXiv,2020,2009.13000,"Zhongqi Yue, Hanwang Zhang, Qianru Sun, Xian-Sheng Hua",https://arxiv.org/abs/2009.13000,09,Accepted by NeurIPS 2020,https://github.com/yue-zhongqi/ifsl
What Do You See? Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors,arXiv,2020,2009.10639,"Yi-Shan Lin, Wen-Chuan Lee, Z. Berkay Celik",https://arxiv.org/abs/2009.10639,09,,
Light Can Hack Your Face! Black-box Backdoor Attack on Face Recognition Systems,arXiv,2020,2009.06996,"Haoliang Li, Yufei Wang, Xiaofei Xie, Yang Liu, Shiqi Wang, Renjie Wan, Lap-Pui Chau, Alex C. Kot",https://arxiv.org/abs/2009.06996,09,First two authors contributed equally,
Semantic-preserving Reinforcement Learning Attack Against Graph Neural Networks for Malware Detection,arXiv,2020,2009.05602,"Lan Zhang, Peng Liu, Yoon-Ho Choi, Ping Chen",https://arxiv.org/abs/2009.05602,09,,
Local and Central Differential Privacy for Robustness and Privacy in Federated Learning,arXiv,2020,2009.03561,"Mohammad Naseri, Jamie Hayes, Emiliano De Cristofaro",https://arxiv.org/abs/2009.03561,09,,
CLEANN: Accelerated Trojan Shield for Embedded Neural Networks,arXiv,2020,2009.02326,"Mojan Javaheripi, Mohammad Samragh, Gregory Fields, Tara Javidi, Farinaz Koushanfar",https://arxiv.org/abs/2009.02326,09,,
One-pixel Signature: Characterizing CNN Models for Backdoor Detection,arXiv,2020,2008.07711,"Shanjiaoyang Huang, Weiqi Peng, Zhiwei Jia, Zhuowen Tu",https://arxiv.org/abs/2008.07711,08,Accepted at ECCV 2020,
WAFFLE: Watermarking in Federated Learning,arXiv,2020,2008.07298,"Buse Gul Atli, Yuxi Xia, Samuel Marchal, N. Asokan",https://arxiv.org/abs/2008.07298,08,"Will appear in the proceedings of SRDS 2021; 14 pages, 11 figures, 10 tables",
DeVLBert: Learning Deconfounded Visio-Linguistic Representations,arXiv,2020,2008.06884,"Shengyu Zhang, Tan Jiang, Tan Wang, Kun Kuang, Zhou Zhao, Jianke Zhu, Jin Yu, Hongxia Yang, Fei Wu",https://arxiv.org/abs/2008.06884,08,"10 pages, 4 figures, to appear in ACM MM 2020 proceedings",
Control instabilities and incite slow-slip in generalized Burridge-Knopoff models,arXiv,2020,2008.03755,Ioannis Stefanou,https://arxiv.org/abs/2008.03755,08,,
Can Adversarial Weight Perturbations Inject Neural Backdoors?,arXiv,2020,2008.01761,"Siddhant Garg, Adarsh Kumar, Vibhor Goel, Yingyu Liang",https://arxiv.org/abs/2008.01761,08,Accepted as a conference paper at CIKM 2020,
Removing Backdoor-Based Watermarks in Neural Networks with Limited Data,arXiv,2020,2008.00407,"Xuankai Liu, Fengting Li, Bihan Wen, Qi Li",https://arxiv.org/abs/2008.00407,08,,
Noise-Response Analysis of Deep Neural Networks Quantifies Robustness and Fingerprints Structural Malware,arXiv,2020,2008.00123,"N. Benjamin Erichson, Dane Taylor, Qixuan Wu, Michael W. Mahoney",https://arxiv.org/abs/2008.00123,08,"9 pages, 7 figures, accepted to the SIAM International Conference on Data Mining (SDM 21)",
Towards Class-Oriented Poisoning Attacks Against Neural Networks,arXiv,2020,2008.00047,"Bingyin Zhao, Yingjie Lao",https://arxiv.org/abs/2008.00047,08,"14 pages, 9 figures, accepted by Winter Conference on Applications of Computer Vision (WACV) 2022",
Practical Detection of Trojan Neural Networks: Data-Limited and Data-Free Cases,arXiv,2020,2007.15802,"Ren Wang, Gaoyuan Zhang, Sijia Liu, Pin-Yu Chen, Jinjun Xiong, Meng Wang",https://arxiv.org/abs/2007.15802,07,,
Towards a Backdoorless Network Architecture Based on Remote Attestation and Backdoor Inspection,arXiv,2020,2007.14748,"Takayuki Sasaki, Yusuke Shimada",https://arxiv.org/abs/2007.14748,07,,
Cassandra: Detecting Trojaned Networks from Adversarial Perturbations,arXiv,2020,2007.14433,"Xiaoyu Zhang, Ajmal Mian, Rohit Gupta, Nazanin Rahnavard, Mubarak Shah",https://arxiv.org/abs/2007.14433,07,,
Mitigating backdoor attacks in LSTM-based Text Classification Systems by Backdoor Keyword Identification,arXiv,2020,2007.12070,"Chuanshuai Chen, Jiazhu Dai",https://arxiv.org/abs/2007.12070,07,,
Backdoor Attacks and Countermeasures on Deep Learning: A Comprehensive Review,arXiv,2020,2007.10760,"Yansong Gao, Bao Gia Doan, Zhi Zhang, Siqi Ma, Jiliang Zhang, Anmin Fu, Surya Nepal, Hyoungshick Kim",https://arxiv.org/abs/2007.10760,07,"29 pages, 9 figures, 2 tables",
Backdoor Learning: A Survey,arXiv,2020,2007.08745,"Yiming Li, Yong Jiang, Zhifeng Li, Shu-Tao Xia",https://arxiv.org/abs/2007.08745,07,17 pages. A curated list of backdoor learning resources in this paper is presented in the Github Repo (https://github.com/THUYimingLi/backdoor-learning-resources). We will try our best to continuously maintain this Github Repo,https://github.com/THUYimingLi/backdoor-learning-resources
Deep Learning Backdoors,arXiv,2020,2007.08273,"Shaofeng Li, Shiqing Ma, Minhui Xue, Benjamin Zi Hao Zhao",https://arxiv.org/abs/2007.08273,07,,
Bounding The Number of Linear Regions in Local Area for Neural Networks with ReLU Activations,arXiv,2020,2007.06803,"Rui Zhu, Bo Lin, Haixu Tang",https://arxiv.org/abs/2007.06803,07,"11 pages, 3 figures",
"Attack of the Tails: Yes, You Really Can Backdoor Federated Learning",arXiv,2020,2007.05084,"Hongyi Wang, Kartik Sreenivasan, Shashank Rajput, Harit Vishwakarma, Saurabh Agarwal, Jy-yong Sohn, Kangwook Lee, Dimitris Papailiopoulos",https://arxiv.org/abs/2007.05084,07,,
Defending against Backdoors in Federated Learning with Robust Learning Rate,arXiv,2020,2007.03767,"Mustafa Safa Ozdayi, Murat Kantarcioglu, Yulia R. Gel",https://arxiv.org/abs/2007.03767,07,Published at AAAI 2021,
Backdoor attacks and defenses in feature-partitioned collaborative learning,arXiv,2020,2007.03608,"Yang Liu, Zhihao Yi, Tianjian Chen",https://arxiv.org/abs/2007.03608,07,to be published in FL-ICML 2020 workshop,
Reflection Backdoor: A Natural Backdoor Attack on Deep Neural Networks,arXiv,2020,2007.02343,"Yunfei Liu, Xingjun Ma, James Bailey, Feng Lu",https://arxiv.org/abs/2007.02343,07,Accepted by ECCV-2020,
Natural Backdoor Attack on Text Data,arXiv,2020,2006.16176,Lichao Sun,https://arxiv.org/abs/2006.16176,06,under submission,
Can We Mitigate Backdoor Attack Using Adversarial Detection Methods?,arXiv,2020,2006.14871,"Kaidi Jin, Tianwei Zhang, Chao Shen, Yufei Chen, Ming Fan, Chenhao Lin, Ting Liu",https://arxiv.org/abs/2006.14871,06,Accepted by IEEE TDSC,
Backdoor Attacks Against Deep Learning Systems in the Physical World,arXiv,2020,2006.14580,"Emily Wenger, Josephine Passananti, Arjun Bhagoji, Yuanshun Yao, Haitao Zheng, Ben Y. Zhao",https://arxiv.org/abs/2006.14580,06,Accepted to the 2021 Conference on Computer Vision and Pattern Recognition (CVPR 2021); 14 pages,
Subpopulation Data Poisoning Attacks,arXiv,2020,2006.14026,"Matthew Jagielski, Giorgio Severi, Niklas Pousette Harger, Alina Oprea",https://arxiv.org/abs/2006.14026,06,"May12 update: add sever + backdoor defenses, comparison to witches' brew attack, better comparison to related work, transferability of representations for cmatch",
A Causally Formulated Hazard Ratio Estimation through Backdoor Adjustment on Structural Causal Model,arXiv,2020,2006.12573,"Riddhiman Adib, Paul Griffin, Sheikh Iqbal Ahamed, Mohammad Adibuzzaman",https://arxiv.org/abs/2006.12573,06,"19 pages, Accepted at Machine Learning for Healthcare 2020",
Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and Data Poisoning Attacks,arXiv,2020,2006.12557,"Avi Schwarzschild, Micah Goldblum, Arjun Gupta, John P Dickerson, Tom Goldstein",https://arxiv.org/abs/2006.12557,06,"19 pages, 4 figures",
Graph Backdoor,arXiv,2020,2006.11890,"Zhaohan Xi, Ren Pang, Shouling Ji, Ting Wang",https://arxiv.org/abs/2006.11890,06,"USENIX Security Symposium 2021, implementation: https://github.com/HarrialX/GraphBackdoor",https://github.com/HarrialX/GraphBackdoor
FaceHack: Triggering backdoored facial recognition systems using facial characteristics,arXiv,2020,2006.11623,"Esha Sarkar, Hadjer Benkraouda, Michail Maniatakos",https://arxiv.org/abs/2006.11623,06,,
Backdoor Attacks to Graph Neural Networks,arXiv,2020,2006.11165,"Zaixi Zhang, Jinyuan Jia, Binghui Wang, Neil Zhenqiang Gong",https://arxiv.org/abs/2006.11165,06,"In ACM SACMAT, 2021",
Backdoor Attacks on Federated Meta-Learning,arXiv,2020,2006.07026,"Chien-Lun Chen, Leana Golubchik, Marco Paolieri",https://arxiv.org/abs/2006.07026,06,"13 pages, 19 figures, NeurIPS Workshop on Scalability, Privacy, and Security in Federated Learning (NeurIPS-SpicyFL), 2020",
Backdoors in Neural Models of Source Code,arXiv,2020,2006.06841,"Goutham Ramakrishnan, Aws Albarghouthi",https://arxiv.org/abs/2006.06841,06,,
Backdoor Smoothing: Demystifying Backdoor Attacks on Deep Neural Networks,arXiv,2020,2006.06721,"Kathrin Grosse, Taesung Lee, Battista Biggio, Youngja Park, Michael Backes, Ian Molloy",https://arxiv.org/abs/2006.06721,06,"9 pages, 7 figures, under submission",
Scalable Backdoor Detection in Neural Networks,arXiv,2020,2006.05646,"Haripriya Harikumar, Vuong Le, Santu Rana, Sourangshu Bhattacharya, Sunil Gupta, Svetha Venkatesh",https://arxiv.org/abs/2006.05646,06,,
BadNL: Backdoor Attacks against NLP Models with Semantic-preserving Improvements,arXiv,2020,2006.01043,"Xiaoyi Chen, Ahmed Salem, Dingfan Chen, Michael Backes, Shiqing Ma, Qingni Shen, Zhonghai Wu, Yang Zhang",https://arxiv.org/abs/2006.01043,06,To appear in Annual Computer Security Applications Conference (ACSAC) 2021,
Improved torsion point attacks on SIDH variants,arXiv,2020,2005.14681,"Victoria de Quehen, Péter Kutas, Chris Leonardi, Chloe Martindale, Lorenz Panny, Christophe Petit, Katherine E. Stange",https://arxiv.org/abs/2005.14681,05,37 pages including 3 appendices,
NeuroAttack: Undermining Spiking Neural Networks Security through Externally Triggered Bit-Flips,arXiv,2020,2005.08041,"Valerio Venceslai, Alberto Marchisio, Ihsen Alouani, Maurizio Martina, Muhammad Shafique",https://arxiv.org/abs/2005.08041,05,Accepted for publication at the 2020 International Joint Conference on Neural Networks (IJCNN),
Adversarial examples are useful too!,arXiv,2020,2005.06107,Ali Borji,https://arxiv.org/abs/2005.06107,05,,
Enabling Deletion in Append-Only Blockchains (Short Summary / Work in Progress),arXiv,2020,2005.06026,Michael Kuperberg,https://arxiv.org/abs/2005.06026,05,"4 pages, 2 figures",
Blind Backdoors in Deep Learning Models,arXiv,2020,2005.03823,"Eugene Bagdasaryan, Vitaly Shmatikov",https://arxiv.org/abs/2005.03823,05,,
Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,arXiv,2020,2005.00060,"Pu Zhao, Pin-Yu Chen, Payel Das, Karthikeyan Natesan Ramamurthy, Xue Lin",https://arxiv.org/abs/2005.00060,05,accepted by ICLR 2020,
Bias Busters: Robustifying DL-based Lithographic Hotspot Detectors Against Backdooring Attacks,arXiv,2020,2004.12492,"Kang Liu, Benjamin Tan, Gaurav Rajavendra Reddy, Siddharth Garg, Yiorgos Makris, Ramesh Karri",https://arxiv.org/abs/2004.12492,04,,
Systematic Evaluation of Backdoor Data Poisoning Attacks on Image Classifiers,arXiv,2020,2004.11514,"Loc Truong, Chace Jones, Brian Hutchinson, Andrew August, Brenda Praggastis, Robert Jasper, Nicole Nichols, Aaron Tuor",https://arxiv.org/abs/2004.11514,04,,
Neural Network Laundering: Removing Black-Box Backdoor Watermarks from Deep Neural Networks,arXiv,2020,2004.11368,"William Aiken, Hyoungshick Kim, Simon Woo",https://arxiv.org/abs/2004.11368,04,"15 pages, 12 figures, 8 tables, formatted for ASIACCS 2020",
Weight Poisoning Attacks on Pre-trained Models,arXiv,2020,2004.06660,"Keita Kurita, Paul Michel, Graham Neubig",https://arxiv.org/abs/2004.06660,04,Published as a long paper at ACL 2020,https://github.com/neulab/RIPPLe
Rethinking the Trigger of Backdoor Attack,arXiv,2020,2004.04692,"Yiming Li, Tongqing Zhai, Baoyuan Wu, Yong Jiang, Zhifeng Li, Shutao Xia",https://arxiv.org/abs/2004.04692,04,18 pages,
How to transform the Apple's application 'Find My' into a toolbox for whistleblowers,arXiv,2020,2004.00108,Amadou Moctar Kane,https://arxiv.org/abs/2004.00108,04,18 pages,
Estimating Treatment Effects with Observed Confounders and Mediators,arXiv,2020,2003.11991,"Shantanu Gupta, Zachary C. Lipton, David Childers",https://arxiv.org/abs/2003.11991,03,,
PoisHygiene: Detecting and Mitigating Poisoning Attacks in Neural Networks,arXiv,2020,2003.11110,"Junfeng Guo, Ting Wang, Cong Liu",https://arxiv.org/abs/2003.11110,03,,
RAB: Provable Robustness Against Backdoor Attacks,arXiv,2020,2003.08904,"Maurice Weber, Xiaojun Xu, Bojan Karlaš, Ce Zhang, Bo Li",https://arxiv.org/abs/2003.08904,03,IEEE Symposium on Security and Privacy 2023,
Backdooring and Poisoning Neural Networks with Image-Scaling Attacks,arXiv,2020,2003.08633,"Erwin Quiring, Konrad Rieck",https://arxiv.org/abs/2003.08633,03,IEEE Deep Learning and Security Workshop (DLS) 2020,
Stop-and-Go: Exploring Backdoor Attacks on Deep Reinforcement Learning-based Traffic Congestion Control Systems,arXiv,2020,2003.07859,"Yue Wang, Esha Sarkar, Wenqing Li, Michail Maniatakos, Saif Eddin Jabari",https://arxiv.org/abs/2003.07859,03,,
Towards Probabilistic Verification of Machine Unlearning,arXiv,2020,2003.04247,"David Marco Sommer, Liwei Song, Sameer Wagh, Prateek Mittal",https://arxiv.org/abs/2003.04247,03,code is available at https://github.com/inspire-group/unlearning-verification,https://github.com/inspire-group/unlearning-verification
Deconfounded Image Captioning: A Causal Retrospect,arXiv,2020,2003.03923,"Xu Yang, Hanwang Zhang, Jianfei Cai",https://arxiv.org/abs/2003.03923,03,,
Dynamic Backdoor Attacks Against Machine Learning Models,arXiv,2020,2003.03675,"Ahmed Salem, Rui Wen, Michael Backes, Shiqing Ma, Yang Zhang",https://arxiv.org/abs/2003.03675,03,,
Clean-Label Backdoor Attacks on Video Recognition Models,arXiv,2020,2003.03030,"Shihao Zhao, Xingjun Ma, Xiang Zheng, James Bailey, Jingjing Chen, Yu-Gang Jiang",https://arxiv.org/abs/2003.03030,03,CVPR2020,
Analyzing Accuracy Loss in Randomized Smoothing Defenses,arXiv,2020,2003.01595,"Yue Gao, Harrison Rosenberg, Kassem Fawaz, Somesh Jha, Justin Hsu",https://arxiv.org/abs/2003.01595,03,"19 pages, 6 figures, 2 tables",
Differentiable Causal Backdoor Discovery,arXiv,2020,2003.01461,"Limor Gultchin, Matt J. Kusner, Varun Kanade, Ricardo Silva",https://arxiv.org/abs/2003.01461,03,"Published in the Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS) 2020, Palermo, Italy",
Explanation-Guided Backdoor Poisoning Attacks Against Malware Classifiers,arXiv,2020,2003.01031,"Giorgio Severi, Jim Meyer, Scott Coull, Alina Oprea",https://arxiv.org/abs/2003.01031,03,"18 pages, 5 figures. To appear in USENIX Security 2021",
Towards Backdoor Attacks and Defense in Robust Machine Learning Models,arXiv,2020,2003.00865,"Ezekiel Soremekun, Sakshi Udeshi, Sudipta Chattopadhyay",https://arxiv.org/abs/2003.00865,03,"Accepted in Computers & Security, 2023",
Defending against Backdoor Attack on Deep Neural Networks,arXiv,2020,2002.12162,"Kaidi Xu, Sijia Liu, Pin-Yu Chen, Pu Zhao, Xue Lin",https://arxiv.org/abs/2002.12162,02,This workshop manuscript is not a publication and will not be published anywhere,
On Certifying Robustness against Backdoor Attacks via Randomized Smoothing,arXiv,2020,2002.11750,"Binghui Wang, Xiaoyu Cao, Jinyuan jia, Neil Zhenqiang Gong",https://arxiv.org/abs/2002.11750,02,"CVPR 2020 Workshop on Adversarial Machine Learning in Computer Vision, 2020. DeepMind Best Extended Abstract",
NNoculation: Catching BadNets in the Wild,arXiv,2020,2002.08313,"Akshaj Kumar Veldanda, Kang Liu, Benjamin Tan, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri, Brendan Dolan-Gavitt, Siddharth Garg",https://arxiv.org/abs/2002.08313,02,,
Targeted Forgetting and False Memory Formation in Continual Learners through Adversarial Backdoor Attacks,arXiv,2020,2002.07111,"Muhammad Umer, Glenn Dawson, Robi Polikar",https://arxiv.org/abs/2002.07111,02,,
Radioactive data: tracing through training,arXiv,2020,2002.00937,"Alexandre Sablayrolles, Matthijs Douze, Cordelia Schmid, Hervé Jégou",https://arxiv.org/abs/2002.00937,02,,
Learning to Detect Malicious Clients for Robust Federated Learning,arXiv,2020,2002.00211,"Suyi Li, Yong Cheng, Wei Wang, Yang Liu, Tianjian Chen",https://arxiv.org/abs/2002.00211,02,"7 pages, 5 figures",
Backdoor Attacks against Transfer Learning with Pre-trained Deep Learning Models,arXiv,2020,2001.03274,"Shuo Wang, Surya Nepal, Carsten Rudolph, Marthie Grobler, Shangyu Chen, Tianle Chen",https://arxiv.org/abs/2001.03274,01,,
Key-dependent Security of Stream Ciphers,arXiv,2020,2001.00515,Eric Filiol,https://arxiv.org/abs/2001.00515,01,"11 pages + 1 figure. This work has been presented in two parts at the Kaz'Hack'Stan 2019 conference in Nur-Sultan, Kazakhstan and at BSides Lisbon 2019, Lisbon, Portugal",
Attack-Resistant Federated Learning with Residual-based Reweighting,arXiv,2019,1912.11464,"Shuhao Fu, Chulin Xie, Bo Li, Qifeng Chen",https://arxiv.org/abs/1912.11464,12,"8 pages, 6 figures and 4 tables",
Label-Consistent Backdoor Attacks,arXiv,2019,1912.02771,"Alexander Turner, Dimitris Tsipras, Aleksander Madry",https://arxiv.org/abs/1912.02771,12,,
Deep Probabilistic Models to Detect Data Poisoning Attacks,arXiv,2019,1912.01206,"Mahesh Subedar, Nilesh Ahuja, Ranganath Krishnan, Ibrahima J. Ndiour, Omesh Tickoo",https://arxiv.org/abs/1912.01206,12,To appear in Bayesian Deep Learning Workshop at NeurIPS 2019,
Design and Evaluation of a Multi-Domain Trojan Detection Method on Deep Neural Networks,arXiv,2019,1911.10312,"Yansong Gao, Yeonjae Kim, Bao Gia Doan, Zhi Zhang, Gongxuan Zhang, Surya Nepal, Damith C. Ranasinghe, Hyoungshick Kim",https://arxiv.org/abs/1911.10312,11,14 pages,
Poison as a Cure: Detecting & Neutralizing Variable-Sized Backdoor Attacks in Deep Neural Networks,arXiv,2019,1911.08040,"Alvin Chan, Yew-Soon Ong",https://arxiv.org/abs/1911.08040,11,,
"Revealing Perceptible Backdoors, without the Training Set, via the Maximum Achievable Misclassification Fraction Statistic",arXiv,2019,1911.07970,"Zhen Xiang, David J. Miller, Hang Wang, George Kesidis",https://arxiv.org/abs/1911.07970,11,,
Can You Really Backdoor Federated Learning?,arXiv,2019,1911.07963,"Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, H. Brendan McMahan",https://arxiv.org/abs/1911.07963,11,To appear at the 2nd International Workshop on Federated Learning for Data Privacy and Confidentiality at NeurIPS 2019,
Hacking Neural Networks: A Short Introduction,arXiv,2019,1911.07658,Michael Kissner,https://arxiv.org/abs/1911.07658,11,,
NeuronInspect: Detecting Backdoors in Neural Networks via Output Explanations,arXiv,2019,1911.07399,"Xijie Huang, Moustafa Alzantot, Mani Srivastava",https://arxiv.org/abs/1911.07399,11,"8 pages, 13 figures",
Robust Anomaly Detection and Backdoor Attack Detection Via Differential Privacy,arXiv,2019,1911.07116,"Min Du, Ruoxi Jia, Dawn Song",https://arxiv.org/abs/1911.07116,11,,
Machine Learning Based Network Vulnerability Analysis of Industrial Internet of Things,arXiv,2019,1911.05771,"Maede Zolanvari, Marcio A. Teixeira, Lav Gupta, Khaled M. Khan, Raj Jain",https://arxiv.org/abs/1911.05771,11,,
A Tale of Evil Twins: Adversarial Inputs versus Poisoned Models,arXiv,2019,1911.01559,"Ren Pang, Hua Shen, Xinyang Zhang, Shouling Ji, Yevgeniy Vorobeychik, Xiapu Luo, Alex Liu, Ting Wang",https://arxiv.org/abs/1911.01559,11,Accepted as a full paper at ACM CCS 2020,
Zephyr: Hiding Metadata in a Messaging System,arXiv,2019,1910.13337,Friedrich Doku,https://arxiv.org/abs/1910.13337,10,,
Shielding Collaborative Learning: Mitigating Poisoning Attacks through Client-Side Detection,arXiv,2019,1910.13111,"Lingchen Zhao, Shengshan Hu, Qian Wang, Jianlin Jiang, Chao Shen, Xiangyang Luo, Pengfei Hu",https://arxiv.org/abs/1910.13111,10,,
Trojan Attacks on Wireless Signal Classification with Adversarial Machine Learning,arXiv,2019,1910.10766,"Kemal Davaslioglu, Yalin E. Sagduyu",https://arxiv.org/abs/1910.10766,10,"2019 - IEEE International Symposium on Dynamic Spectrum Access Networks (DySPAN) Workshop on Data-Driven Dynamic Spectrum Sharing, 6 pages, 7 figures",
Defending Neural Backdoors via Generative Distribution Modeling,arXiv,2019,1910.04749,"Ximing Qiao, Yukun Yang, Hai Li",https://arxiv.org/abs/1910.04749,10,,
Piracy Resistant Watermarks for Deep Neural Networks,arXiv,2019,1910.01226,"Huiying Li, Emily Wenger, Shawn Shan, Ben Y. Zhao, Haitao Zheng",https://arxiv.org/abs/1910.01226,10,18 pages,
Interdiction in Practice -- Hardware Trojan Against a High-Security USB Flash Drive,arXiv,2019,1910.00947,"Pawel Swierczynski, Marc Fyrbiak, Philipp Koppe, Amir Moradi, Christof Paar",https://arxiv.org/abs/1910.00947,10,,
Hidden Trigger Backdoor Attacks,arXiv,2019,1910.00033,"Aniruddha Saha, Akshayvarun Subramanya, Hamed Pirsiavash",https://arxiv.org/abs/1910.00033,10,AAAI 2020 - Main Technical Track (Oral),
Walling up Backdoors in Intrusion Detection Systems,arXiv,2019,1909.07866,"Maximilian Bachl, Alexander Hartl, Joachim Fabini, Tanja Zseby",https://arxiv.org/abs/1909.07866,09,,
Invisible Backdoor Attacks on Deep Neural Networks via Steganography and Regularization,arXiv,2019,1909.02742,"Shaofeng Li, Minhui Xue, Benjamin Zi Hao Zhao, Haojin Zhu, Xinpeng Zhang",https://arxiv.org/abs/1909.02742,09,,
Detection of Backdoors in Trained Classifiers Without Access to the Training Set,arXiv,2019,1908.10498,"Zhen Xiang, David J. Miller, George Kesidis",https://arxiv.org/abs/1908.10498,08,,
Februus: Input Purification Defense Against Trojan Attacks on Deep Neural Network Systems,arXiv,2019,1908.03369,"Bao Gia Doan, Ehsan Abbasnejad, Damith C. Ranasinghe",https://arxiv.org/abs/1908.03369,08,"16 pages, to appear in the 36th Annual Computer Security Applications Conference (ACSAC 2020)",
Model Agnostic Defence against Backdoor Attacks in Machine Learning,arXiv,2019,1908.02203,"Sakshi Udeshi, Shanshan Peng, Gerald Woo, Lionell Loh, Louth Rawshan, Sudipta Chattopadhyay",https://arxiv.org/abs/1908.02203,08,"IEEE Transactions on Reliability, 2022",
TABOR: A Highly Accurate Approach to Inspecting and Restoring Trojan Backdoors in AI Systems,arXiv,2019,1908.01763,"Wenbo Guo, Lun Wang, Xinyu Xing, Min Du, Dawn Song",https://arxiv.org/abs/1908.01763,08,,
Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection,arXiv,2019,1908.00686,"Di Tang, XiaoFeng Wang, Haixu Tang, Kehuan Zhang",https://arxiv.org/abs/1908.00686,08,,
How to Manipulate CNNs to Make Them Lie: the GradCAM Case,arXiv,2019,1907.10901,"Tom Viering, Ziqi Wang, Marco Loog, Elmar Eisemann",https://arxiv.org/abs/1907.10901,07,"Presented at BMVC 2019: Workshop on Interpretable and Explainable Machine Vision, Cardiff, UK. Updated to BMVC template",
Data Structures Meet Cryptography: 3SUM with Preprocessing,arXiv,2019,1907.08355,"Alexander Golovnev, Siyao Guo, Thibaut Horel, Sunoo Park, Vinod Vaikuntanathan",https://arxiv.org/abs/1907.08355,07,,
Universal Litmus Patterns: Revealing Backdoor Attacks in CNNs,arXiv,2019,1906.10842,"Soheil Kolouri, Aniruddha Saha, Hamed Pirsiavash, Heiko Hoffmann",https://arxiv.org/abs/1906.10842,06,CVPR 2020 Oral,https://umbcvision.github.io/Universal-Litmus-Patterns/
On the Robustness of the Backdoor-based Watermarking in Deep Neural Networks,arXiv,2019,1906.07745,"Masoumeh Shafieinejad, Jiaqi Wang, Nils Lukas, Xinda Li, Florian Kerschbaum",https://arxiv.org/abs/1906.07745,06,,
Bypassing Backdoor Detection Algorithms in Deep Learning,arXiv,2019,1905.13409,"Te Juin Lester Tan, Reza Shokri",https://arxiv.org/abs/1905.13409,05,IEEE European Symposium on Security and Privacy 2020,
A backdoor attack against LSTM-based text classification systems,arXiv,2019,1905.12457,"Jiazhu Dai, Chuanshuai Chen",https://arxiv.org/abs/1905.12457,05,,
Regula Sub-rosa: Latent Backdoor Attacks on Deep Neural Networks,arXiv,2019,1905.10447,"Yuanshun Yao, Huiying Li, Haitao Zheng, Ben Y. Zhao",https://arxiv.org/abs/1905.10447,05,,
Biometric Backdoors: A Poisoning Attack Against Unsupervised Template Updating,arXiv,2019,1905.09162,"Giulio Lovisotto, Simon Eberz, Ivan Martinovic",https://arxiv.org/abs/1905.09162,05,12 pages,
An Analysis of Pre-installed Android Software,arXiv,2019,1905.02713,"Julien Gamba, Mohammed Rashed, Abbas Razaghpanah, Juan Tapiador, Narseo Vallina-Rodriguez",https://arxiv.org/abs/1905.02713,05,,
A Benchmark API Call Dataset for Windows PE Malware Classification,arXiv,2019,1905.01999,"Ferhat Ozgur Catak, Ahmet Faruk Yazı",https://arxiv.org/abs/1905.01999,05,Updated version,
Adversarial Learning in Statistical Classification: A Comprehensive Review of Defenses Against Attacks,arXiv,2019,1904.06292,"David J. Miller, Zhen Xiang, George Kesidis",https://arxiv.org/abs/1904.06292,04,,
Adversarial Audio: A New Information Hiding Method and Backdoor for DNN-based Speech Recognition Models,arXiv,2019,1904.03829,"Yehao Kong, Jiliang Zhang",https://arxiv.org/abs/1904.03829,04,Submitted to RAID2019,
BSEA-1 - A Stream Cipher Backdooring Technique,arXiv,2019,1903.11063,Eric Filiol,https://arxiv.org/abs/1903.11063,03,"This work has been presented at the Ruscrypto 2019 conference in Moscow (March 21th, 2019). This paper concerns the continuation of our research work initiated in arXiv:1702.0647. As such, it takes up a reduced part of the abstract and introduction (section 1). All the other sections are totally different.",
How to Prove Your Model Belongs to You: A Blind-Watermark based Framework to Protect Intellectual Property of DNN,arXiv,2019,1903.01743,"Zheng Li, Chengyu Hu, Yang Zhang, Shanqing Guo",https://arxiv.org/abs/1903.01743,03,To be published in ACSAC'19,
A new Backdoor Attack in CNNs by training set corruption without label poisoning,arXiv,2019,1902.11237,"Mauro Barni, Kassem Kallas, Benedetta Tondi",https://arxiv.org/abs/1902.11237,02,,
Design of intentional backdoors in sequential models,arXiv,2019,1902.09972,"Zhaoyuan Yang, Naresh Iyer, Johan Reimann, Nurali Virani",https://arxiv.org/abs/1902.09972,02,,
DeepHoops: Evaluating Micro-Actions in Basketball Using Deep Feature Representations of Spatio-Temporal Data,arXiv,2019,1902.08081,"Anthony Sicilia, Konstantinos Pelechrinis, Kirk Goldsberry",https://arxiv.org/abs/1902.08081,02,Working paper,
STRIP: A Defence Against Trojan Attacks on Deep Neural Networks,arXiv,2019,1902.06531,"Yansong Gao, Chang Xu, Derui Wang, Shiping Chen, Damith C. Ranasinghe, Surya Nepal",https://arxiv.org/abs/1902.06531,02,13 pages,
A Little Is Enough: Circumventing Defenses For Distributed Learning,arXiv,2019,1902.06156,"Moran Baruch, Gilad Baruch, Yoav Goldberg",https://arxiv.org/abs/1902.06156,02,,
"Causal Calculus in the Presence of Cycles, Latent Confounders and Selection Bias",arXiv,2019,1901.00433,"Patrick Forré, Joris M. Mooij",https://arxiv.org/abs/1901.00433,01,Accepted for publication in Conference on Uncertainty in Artificial Intelligence 2019 (UAI-2019),
Reaching Data Confidentiality and Model Accountability on the CalTrain,arXiv,2018,1812.03230,"Zhongshu Gu, Hani Jamjoom, Dong Su, Heqing Huang, Jialong Zhang, Tengfei Ma, Dimitrios Pendarakis, Ian Molloy",https://arxiv.org/abs/1812.03230,12,,
Backdooring Convolutional Neural Networks via Targeted Weight Perturbations,arXiv,2018,1812.03128,"Jacob Dumford, Walter Scheirer",https://arxiv.org/abs/1812.03128,12,,
How a simple bug in ML compiler could be exploited for backdoors?,arXiv,2018,1811.10851,Baptiste David,https://arxiv.org/abs/1811.10851,11,"8 pages, 15 figures, 5 sections. White paper of the talk presented at ZeroNight 2018 in Saint-Petersburg",
Backdoor Decomposable Monotone Circuits and their Propagation Complete Encodings,arXiv,2018,1811.09435,"Petr Kučera, Petr Savický",https://arxiv.org/abs/1811.09435,11,"The paper was significantly rewritten to improve readability, it is now an extended version of the paper accepted to AAAI 2021",
Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering,arXiv,2018,1811.03728,"Bryant Chen, Wilka Carvalho, Nathalie Baracaldo, Heiko Ludwig, Benjamin Edwards, Taesung Lee, Ian Molloy, Biplav Srivastava",https://arxiv.org/abs/1811.03728,11,,
Spectral Signatures in Backdoor Attacks,arXiv,2018,1811.00636,"Brandon Tran, Jerry Li, Aleksander Madry",https://arxiv.org/abs/1811.00636,11,"16 pages, accepted to NIPS 2018",
Learning with Bad Training Data via Iterative Trimmed Loss Minimization,arXiv,2018,1810.11874,"Yanyao Shen, Sujay Sanghavi",https://arxiv.org/abs/1810.11874,10,,
Shallow-Deep Networks: Understanding and Mitigating Network Overthinking,arXiv,2018,1810.07052,"Yigitcan Kaya, Sanghyun Hong, Tudor Dumitras",https://arxiv.org/abs/1810.07052,10,Accepted to ICML2019. Source code here: www.shallowdeep.network,
True2F: Backdoor-resistant authentication tokens,arXiv,2018,1810.04660,"Emma Dauterman, Henry Corrigan-Gibbs, David Mazières, Dan Boneh, Dominic Rizzo",https://arxiv.org/abs/1810.04660,10,,
Backdoor Embedding in Convolutional Neural Network Models via Invisible Perturbation,arXiv,2018,1808.10307,"Cong Liao, Haoti Zhong, Anna Squicciarini, Sencun Zhu, David Miller",https://arxiv.org/abs/1808.10307,08,,
Integrated Server for Measurement-Device-Independent Quantum Key Distribution Network,arXiv,2018,1808.08586,"Ci-Yu Wang, Jun Gao, Zhi-Qiang Jiao, Lu-Feng Qiao, Ruo-Jing Ren, Zhen Feng, Yuan Chen, Zeng-Quan Yan, Yao Wang, Hao Tang, Xian-Min Jin",https://arxiv.org/abs/1808.08586,08,"5 pages, 4 figures, 1 table",
Are You Tampering With My Data?,arXiv,2018,1808.06809,"Michele Alberti, Vinaychandran Pondenkandath, Marcel Würsch, Manuel Bouillon, Mathias Seuret, Rolf Ingold, Marcus Liwicki",https://arxiv.org/abs/1808.06809,08,18 pages,
Mitigating Sybils in Federated Learning Poisoning,arXiv,2018,1808.04866,"Clement Fung, Chris J. M. Yoon, Ivan Beschastnikh",https://arxiv.org/abs/1808.04866,08,"16 pages, Extended technical version of conference paper ""The Limitations of Federated Learning in Sybil Settings"" accepted at RAID 2020",https://github.com/DistributedML/FoolsGold
A Secure Multiple Elliptic Curves Digital Signature Algorithm for Blockchain,arXiv,2018,1808.02988,"Wei Bi, Xiaoyun Jia, Maolin Zheng",https://arxiv.org/abs/1808.02988,08,,
How To Backdoor Federated Learning,arXiv,2018,1807.00459,"Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, Vitaly Shmatikov",https://arxiv.org/abs/1807.00459,07,,
Built-in Vulnerabilities to Imperceptible Adversarial Perturbations,arXiv,2018,1806.07409,"Thomas Tanay, Jerone T. A. Andrews, Lewis D. Griffin",https://arxiv.org/abs/1806.07409,06,,
An Effective Privacy-Preserving Data Coding in Peer-To-Peer Network,arXiv,2018,1806.05430,"Ngoc Hong Tran, Cao-Vien Phung, Binh Quoc Nguyen, Leila Bahri",https://arxiv.org/abs/1806.05430,06,"20 pages, 9 figures, 13 references, 1 table, 3 algorithms, 6 definitions",
Fine-Pruning: Defending Against Backdooring Attacks on Deep Neural Networks,arXiv,2018,1805.12185,"Kang Liu, Brendan Dolan-Gavitt, Siddharth Garg",https://arxiv.org/abs/1805.12185,05,,
On Cryptographic Attacks Using Backdoors for SAT,arXiv,2018,1803.04646,"Alexander Semenov, Oleg Zaikin, Ilya Otpuschennikov, Stepan Kochemazov, Alexey Ignatiev",https://arxiv.org/abs/1803.04646,03,,
How to Subvert Backdoored Encryption: Security Against Adversaries that Decrypt All Ciphertexts,arXiv,2018,1802.07381,"Thibaut Horel, Sunoo Park, Silas Richelson, Vinod Vaikuntanathan",https://arxiv.org/abs/1802.07381,02,,
Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks by Backdooring,arXiv,2018,1802.04633,"Yossi Adi, Carsten Baum, Moustapha Cisse, Benny Pinkas, Joseph Keshet",https://arxiv.org/abs/1802.04633,02,,
Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning,arXiv,2017,1712.05526,"Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, Dawn Song",https://arxiv.org/abs/1712.05526,12,,
Software Distribution Transparency and Auditability,arXiv,2017,1711.07278,"Benjamin Hof, Georg Carle",https://arxiv.org/abs/1711.07278,11,,
A Touch of Evil: High-Assurance Cryptographic Hardware from Untrusted Components,arXiv,2017,1709.03817,"Vasilios Mavroudis, Andrea Cerulli, Petr Svenda, Dan Cvrcek, Dusan Klinec, George Danezis",https://arxiv.org/abs/1709.03817,09,,
BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain,arXiv,2017,1708.06733,"Tianyu Gu, Brendan Dolan-Gavitt, Siddharth Garg",https://arxiv.org/abs/1708.06733,08,,
Relating Complexity-theoretic Parameters with SAT Solver Performance,arXiv,2017,1706.08611,"Edward Zulkoski, Ruben Martins, Christoph Wintersteiger, Robert Robere, Jia Liang, Krzysztof Czarnecki, Vijay Ganesh",https://arxiv.org/abs/1706.08611,06,,
Solving Integer Linear Programs with a Small Number of Global Variables and Constraints,arXiv,2017,1706.06084,"Pavel Dvořák, Eduard Eiben, Robert Ganian, Dušan Knop, Sebastian Ordyniak",https://arxiv.org/abs/1706.06084,06,24 pages; an extended abstract appeared in proceedings of IJCAI 2017,
Existence versus Exploitation: The Opacity of Backbones and Backdoors Under a Weak Assumption,arXiv,2017,1706.04582,"Lane A. Hemaspaandra, David E. Narváez",https://arxiv.org/abs/1706.04582,06,,
Software-Defined Adversarial Trajectory Sampling,arXiv,2017,1705.00370,"Kashyap Thimmaraju, Liron Schiff, Stefan Schmid",https://arxiv.org/abs/1705.00370,05,"SDN Security, Trajectory Sampling, Forwarding Attacks, Malicious Router, Malicious Data Plane, Compromised Data Plane, Data Plane Security",
Mathematical Backdoors in Symmetric Encryption Systems - Proposal for a Backdoored AES-like Block Cipher,arXiv,2017,1702.06475,"Arnaud Bannier, Eric Filiol",https://arxiv.org/abs/1702.06475,02,This work has been presented at the FORmal Methods for Security Engineering (ForSE) conference 2017,
Post-Quantum Cryptography(PQC): Generalized ElGamal Cipher over GF(251^8),arXiv,2017,1702.03587,Pedro Hecht,https://arxiv.org/abs/1702.03587,02,"6 pages, 6 Tables, 14 Figures",
Backdoors to Tractable Valued CSP,arXiv,2016,1612.05733,"Robert Ganian, M. S. Ramanujan, Stefan Szeider",https://arxiv.org/abs/1612.05733,12,Accepted to CP 2016,
Application-layer Fault-Tolerance Protocols,arXiv,2016,1611.02273,Vincenzo De Florio,https://arxiv.org/abs/1611.02273,11,"Preprint of ""Application-layer Fault-Tolerance Protocols"", De Florio V., IGI Global, Hershey, PA 17033, USA, January 2009. ISBN: 978-1-60566-182-7. 378 pages. arXiv admin note: substantial text overlap with arXiv:1611.01690",
Combining Treewidth and Backdoors for CSP,arXiv,2016,1610.03298,"Robert Ganian, M. S. Ramanujan, Stefan Szeider",https://arxiv.org/abs/1610.03298,10,,
A Survey of Symbolic Execution Techniques,arXiv,2016,1610.00502,"Roberto Baldoni, Emilio Coppa, Daniele Cono D'Elia, Camil Demetrescu, Irene Finocchi",https://arxiv.org/abs/1610.00502,10,"This is the authors pre-print copy. If you are considering citing this survey, we would appreciate if you could use the following BibTeX entry: http://goo.gl/Hf5Fvc",
Strong Backdoors for Default Logic,arXiv,2016,1602.06052,"Johannes K. Fichte, Arne Meier, Irina Schindler",https://arxiv.org/abs/1602.06052,02,,
Strong Backdoors for Linear Temporal Logic,arXiv,2016,1602.04934,"Arne Meier, Sebastian Ordyniak, M. S. Ramanujan, Irena Schindler",https://arxiv.org/abs/1602.04934,02,,
Creation of backdoors in quantum communications via laser damage,arXiv,2015,1510.03148,"Vadim Makarov, Jean-Philippe Bourgoin, Poompong Chaiwongkhot, Mathieu Gagné, Thomas Jennewein, Sarah Kaiser, Raman Kashyap, Matthieu Legré, Carter Minshull, Shihan Sajeed",https://arxiv.org/abs/1510.03148,10,"Changed the title to match the journal version. 9 pages, 5 figures",
Backdoors into Heterogeneous Classes of SAT and CSP,arXiv,2015,1509.05725,"Serge Gaspers, Neeldhara Misra, Sebastian Ordyniak, Stefan Szeider, Stanislav Živný",https://arxiv.org/abs/1509.05725,09,"to appear in JCSS, full version of an AAAI 2014 paper",
